{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Berita</th>\n",
       "      <th>Label</th>\n",
       "      <th>Category_id</th>\n",
       "      <th>Word2Vec Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ayah', 'pinrang', 'tangkap', 'sandera', 'anc...</td>\n",
       "      <td>keluarga</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1796092838048935, 0.4170130491256714, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['duga', 'anak', 'bawa', 'orang', 'kenal', 'at...</td>\n",
       "      <td>orang asing</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.10238317400217056, 0.2470414936542511, 0.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['dpa', 'laku', 'damping', 'korban', 'laku', '...</td>\n",
       "      <td>teman</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.35820725560188293, 0.20362965762615204, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['inara', 'rusli', 'bawa', 'kunci', 'bukti', '...</td>\n",
       "      <td>keluarga</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.16313651204109192, 0.26164698600769043, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['viral', 'video', 'bocah', 'ikat', 'tiang', '...</td>\n",
       "      <td>orang asing</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.2542842924594879, 0.24875245988368988, 0.26...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Berita        Label  \\\n",
       "0  ['ayah', 'pinrang', 'tangkap', 'sandera', 'anc...     keluarga   \n",
       "1  ['duga', 'anak', 'bawa', 'orang', 'kenal', 'at...  orang asing   \n",
       "2  ['dpa', 'laku', 'damping', 'korban', 'laku', '...        teman   \n",
       "3  ['inara', 'rusli', 'bawa', 'kunci', 'bukti', '...     keluarga   \n",
       "4  ['viral', 'video', 'bocah', 'ikat', 'tiang', '...  orang asing   \n",
       "\n",
       "   Category_id                                    Word2Vec Vector  \n",
       "0            0  [0.1796092838048935, 0.4170130491256714, -0.04...  \n",
       "1            4  [0.10238317400217056, 0.2470414936542511, 0.27...  \n",
       "2            3  [0.35820725560188293, 0.20362965762615204, 0.2...  \n",
       "3            0  [0.16313651204109192, 0.26164698600769043, 0.2...  \n",
       "4            4  [0.2542842924594879, 0.24875245988368988, 0.26...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = \"Data Splitting/with_val/Train_Data.csv\"\n",
    "train_df = pd.read_csv(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Berita</th>\n",
       "      <th>Label</th>\n",
       "      <th>Category_id</th>\n",
       "      <th>Word2Vec Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['kali', 'anak', 'selebgram', 'aghnia', 'aniay...</td>\n",
       "      <td>pengasuh</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.3540416359901428, 0.3076167106628418, 0.085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['heboh', 'anak', 'vincent', 'rompies', 'libat...</td>\n",
       "      <td>teman</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.28507089614868164, 0.20352721214294434, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['keras', 'sma', 'negeri', 'tasikmalaya', 'mas...</td>\n",
       "      <td>teman</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.277415931224823, 0.2662486135959625, 0.2400...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['poin', 'kpai', 'kawal', 'bullying', 'geng', ...</td>\n",
       "      <td>teman</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.28439921140670776, 0.27106228470802307, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['duga', 'hamil', 'jual', 'anak', 'hasil', 'se...</td>\n",
       "      <td>keluarga</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.4781922698020935, 0.3863716125488281, 0.245...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Berita     Label  Category_id  \\\n",
       "0  ['kali', 'anak', 'selebgram', 'aghnia', 'aniay...  pengasuh            1   \n",
       "1  ['heboh', 'anak', 'vincent', 'rompies', 'libat...     teman            3   \n",
       "2  ['keras', 'sma', 'negeri', 'tasikmalaya', 'mas...     teman            3   \n",
       "3  ['poin', 'kpai', 'kawal', 'bullying', 'geng', ...     teman            3   \n",
       "4  ['duga', 'hamil', 'jual', 'anak', 'hasil', 'se...  keluarga            0   \n",
       "\n",
       "                                     Word2Vec Vector  \n",
       "0  [0.3540416359901428, 0.3076167106628418, 0.085...  \n",
       "1  [0.28507089614868164, 0.20352721214294434, 0.1...  \n",
       "2  [0.277415931224823, 0.2662486135959625, 0.2400...  \n",
       "3  [0.28439921140670776, 0.27106228470802307, 0.3...  \n",
       "4  [0.4781922698020935, 0.3863716125488281, 0.245...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = \"Data Splitting/with_val/Val_Data.csv\"\n",
    "val_df = pd.read_csv(val_df)\n",
    "val_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing The Data for Neural Network Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the locations\n",
    "X_train = train_df['Word2Vec Vector']\n",
    "y_train = train_df['Category_id']\n",
    "X_val = val_df['Word2Vec Vector']\n",
    "y_val = val_df['Category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17960928  0.41701305 -0.04744937 ...  0.40574414  0.245582\n",
      "   0.08898055]\n",
      " [ 0.10238317  0.24704149  0.27464882 ...  0.08813259  0.30407691\n",
      "   0.43934801]\n",
      " [ 0.35820726  0.20362966  0.2630544  ...  0.2579141   0.35038081\n",
      "   0.36289123]\n",
      " ...\n",
      " [ 0.27806711  0.24155277  0.24423018 ...  0.28065443  0.53148139\n",
      "   0.43777528]\n",
      " [ 0.42479664  0.10447986 -0.03571824 ...  0.26021251  0.16793445\n",
      "   0.25592601]\n",
      " [ 0.35719058  0.26109946  0.15572512 ...  0.1309738   0.32690907\n",
      "   0.12616619]]\n",
      "[[ 0.35404164  0.30761671  0.08512706 ...  0.2467062   0.2330083\n",
      "   0.29866689]\n",
      " [ 0.2850709   0.20352721  0.14480667 ...  0.20088911  0.2974396\n",
      "   0.22488372]\n",
      " [ 0.27741593  0.26624861  0.24004306 ...  0.2734699   0.46699813\n",
      "   0.09709835]\n",
      " ...\n",
      " [ 0.34807277  0.34124702 -0.12281044 ...  0.40926725  0.36617047\n",
      "   0.1402137 ]\n",
      " [ 0.26805174  0.2869263   0.12354009 ...  0.36130354  0.19468924\n",
      "   0.23578319]\n",
      " [ 0.27741507  0.2287111  -0.0033286  ...  0.2329713   0.16494793\n",
      "   0.14489825]]\n"
     ]
    }
   ],
   "source": [
    "# Convert string to float\n",
    "X_train = np.array([list(map(float, row.strip(\"[]\").split(','))) for row in X_train])\n",
    "print(X_train)\n",
    "X_train = X_train.T\n",
    "\n",
    "X_val = np.array([list(map(float, row.strip(\"[]\").split(','))) for row in X_val])\n",
    "print(X_val)\n",
    "X_val = X_val.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17960928,  0.10238317,  0.35820726, ...,  0.27806711,\n",
       "         0.42479664,  0.35719058],\n",
       "       [ 0.41701305,  0.24704149,  0.20362966, ...,  0.24155277,\n",
       "         0.10447986,  0.26109946],\n",
       "       [-0.04744937,  0.27464882,  0.2630544 , ...,  0.24423018,\n",
       "        -0.03571824,  0.15572512],\n",
       "       ...,\n",
       "       [ 0.40574414,  0.08813259,  0.2579141 , ...,  0.28065443,\n",
       "         0.26021251,  0.1309738 ],\n",
       "       [ 0.245582  ,  0.30407691,  0.35038081, ...,  0.53148139,\n",
       "         0.16793445,  0.32690907],\n",
       "       [ 0.08898055,  0.43934801,  0.36289123, ...,  0.43777528,\n",
       "         0.25592601,  0.12616619]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35404164,  0.2850709 ,  0.27741593, ...,  0.34807277,\n",
       "         0.26805174,  0.27741507],\n",
       "       [ 0.30761671,  0.20352721,  0.26624861, ...,  0.34124702,\n",
       "         0.2869263 ,  0.2287111 ],\n",
       "       [ 0.08512706,  0.14480667,  0.24004306, ..., -0.12281044,\n",
       "         0.12354009, -0.0033286 ],\n",
       "       ...,\n",
       "       [ 0.2467062 ,  0.20088911,  0.2734699 , ...,  0.40926725,\n",
       "         0.36130354,  0.2329713 ],\n",
       "       [ 0.2330083 ,  0.2974396 ,  0.46699813, ...,  0.36617047,\n",
       "         0.19468924,  0.16494793],\n",
       "       [ 0.29866689,  0.22488372,  0.09709835, ...,  0.1402137 ,\n",
       "         0.23578319,  0.14489825]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_Train:  (100, 780)\n",
      "Shape y_Train:  (780,)\n",
      "Shape X_Val:  (100, 97)\n",
      "Shape y_Val:  (97,)\n"
     ]
    }
   ],
   "source": [
    "# Make it suitable for my Neural Network input\n",
    "print(\"Shape X_Train: \", X_train.shape)\n",
    "print(\"Shape y_Train: \", y_train.shape)\n",
    "print(\"Shape X_Val: \", X_val.shape)\n",
    "print(\"Shape y_Val: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Type: <class 'numpy.ndarray'>\n",
      "y_train Type: <class 'numpy.ndarray'>\n",
      "X_val Type: <class 'numpy.ndarray'>\n",
      "y_val Type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train Type:\", type(X_train))\n",
    "print(\"y_train Type:\", type(y_train))\n",
    "print(\"X_val Type:\", type(X_val))\n",
    "print(\"y_val Type:\", type(y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Y2 (Node Hidden Layer 1 = 60, Learning Rate = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neural_Network_Val import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Z2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.379877, Train Acc: 0.170513 | Val Loss: 0.382389, Val Acc: 0.216495\n",
      "Epoch 2 - Train Loss: 0.372308, Train Acc: 0.170513 | Val Loss: 0.376031, Val Acc: 0.247423\n",
      "Epoch 3 - Train Loss: 0.365594, Train Acc: 0.188462 | Val Loss: 0.370379, Val Acc: 0.309278\n",
      "Epoch 4 - Train Loss: 0.359627, Train Acc: 0.241026 | Val Loss: 0.365337, Val Acc: 0.360825\n",
      "Epoch 5 - Train Loss: 0.354307, Train Acc: 0.306410 | Val Loss: 0.360818, Val Acc: 0.381443\n",
      "Epoch 6 - Train Loss: 0.349544, Train Acc: 0.373077 | Val Loss: 0.356746, Val Acc: 0.422680\n",
      "Epoch 7 - Train Loss: 0.345260, Train Acc: 0.417949 | Val Loss: 0.353054, Val Acc: 0.432990\n",
      "Epoch 8 - Train Loss: 0.341385, Train Acc: 0.460256 | Val Loss: 0.349685, Val Acc: 0.443299\n",
      "Epoch 9 - Train Loss: 0.337858, Train Acc: 0.491026 | Val Loss: 0.346589, Val Acc: 0.453608\n",
      "Epoch 10 - Train Loss: 0.334629, Train Acc: 0.497436 | Val Loss: 0.343727, Val Acc: 0.474227\n",
      "Epoch 11 - Train Loss: 0.331653, Train Acc: 0.500000 | Val Loss: 0.341063, Val Acc: 0.474227\n",
      "Epoch 12 - Train Loss: 0.328895, Train Acc: 0.502564 | Val Loss: 0.338571, Val Acc: 0.474227\n",
      "Epoch 13 - Train Loss: 0.326325, Train Acc: 0.503846 | Val Loss: 0.336226, Val Acc: 0.474227\n",
      "Epoch 14 - Train Loss: 0.323917, Train Acc: 0.503846 | Val Loss: 0.334011, Val Acc: 0.474227\n",
      "Epoch 15 - Train Loss: 0.321651, Train Acc: 0.503846 | Val Loss: 0.331907, Val Acc: 0.474227\n",
      "Epoch 16 - Train Loss: 0.319508, Train Acc: 0.503846 | Val Loss: 0.329903, Val Acc: 0.474227\n",
      "Epoch 17 - Train Loss: 0.317475, Train Acc: 0.503846 | Val Loss: 0.327988, Val Acc: 0.474227\n",
      "Epoch 18 - Train Loss: 0.315542, Train Acc: 0.503846 | Val Loss: 0.326152, Val Acc: 0.474227\n",
      "Epoch 19 - Train Loss: 0.313696, Train Acc: 0.503846 | Val Loss: 0.324389, Val Acc: 0.474227\n",
      "Epoch 20 - Train Loss: 0.311931, Train Acc: 0.503846 | Val Loss: 0.322693, Val Acc: 0.474227\n",
      "Epoch 21 - Train Loss: 0.310240, Train Acc: 0.503846 | Val Loss: 0.321058, Val Acc: 0.474227\n",
      "Epoch 22 - Train Loss: 0.308616, Train Acc: 0.503846 | Val Loss: 0.319482, Val Acc: 0.474227\n",
      "Epoch 23 - Train Loss: 0.307056, Train Acc: 0.503846 | Val Loss: 0.317962, Val Acc: 0.474227\n",
      "Epoch 24 - Train Loss: 0.305556, Train Acc: 0.503846 | Val Loss: 0.316493, Val Acc: 0.474227\n",
      "Epoch 25 - Train Loss: 0.304112, Train Acc: 0.503846 | Val Loss: 0.315075, Val Acc: 0.474227\n",
      "Epoch 26 - Train Loss: 0.302723, Train Acc: 0.503846 | Val Loss: 0.313705, Val Acc: 0.474227\n",
      "Epoch 27 - Train Loss: 0.301385, Train Acc: 0.503846 | Val Loss: 0.312382, Val Acc: 0.474227\n",
      "Epoch 28 - Train Loss: 0.300096, Train Acc: 0.503846 | Val Loss: 0.311104, Val Acc: 0.474227\n",
      "Epoch 29 - Train Loss: 0.298855, Train Acc: 0.503846 | Val Loss: 0.309870, Val Acc: 0.474227\n",
      "Epoch 30 - Train Loss: 0.297659, Train Acc: 0.503846 | Val Loss: 0.308679, Val Acc: 0.474227\n",
      "Epoch 31 - Train Loss: 0.296509, Train Acc: 0.503846 | Val Loss: 0.307530, Val Acc: 0.474227\n",
      "Epoch 32 - Train Loss: 0.295403, Train Acc: 0.503846 | Val Loss: 0.306422, Val Acc: 0.474227\n",
      "Epoch 33 - Train Loss: 0.294338, Train Acc: 0.503846 | Val Loss: 0.305354, Val Acc: 0.474227\n",
      "Epoch 34 - Train Loss: 0.293315, Train Acc: 0.503846 | Val Loss: 0.304324, Val Acc: 0.474227\n",
      "Epoch 35 - Train Loss: 0.292332, Train Acc: 0.503846 | Val Loss: 0.303333, Val Acc: 0.474227\n",
      "Epoch 36 - Train Loss: 0.291388, Train Acc: 0.503846 | Val Loss: 0.302380, Val Acc: 0.474227\n",
      "Epoch 37 - Train Loss: 0.290481, Train Acc: 0.503846 | Val Loss: 0.301462, Val Acc: 0.474227\n",
      "Epoch 38 - Train Loss: 0.289612, Train Acc: 0.503846 | Val Loss: 0.300580, Val Acc: 0.474227\n",
      "Epoch 39 - Train Loss: 0.288778, Train Acc: 0.503846 | Val Loss: 0.299732, Val Acc: 0.474227\n",
      "Epoch 40 - Train Loss: 0.287979, Train Acc: 0.503846 | Val Loss: 0.298917, Val Acc: 0.474227\n",
      "Epoch 41 - Train Loss: 0.287214, Train Acc: 0.503846 | Val Loss: 0.298136, Val Acc: 0.474227\n",
      "Epoch 42 - Train Loss: 0.286482, Train Acc: 0.503846 | Val Loss: 0.297387, Val Acc: 0.474227\n",
      "Epoch 43 - Train Loss: 0.285781, Train Acc: 0.503846 | Val Loss: 0.296668, Val Acc: 0.474227\n",
      "Epoch 44 - Train Loss: 0.285111, Train Acc: 0.503846 | Val Loss: 0.295979, Val Acc: 0.474227\n",
      "Epoch 45 - Train Loss: 0.284470, Train Acc: 0.503846 | Val Loss: 0.295318, Val Acc: 0.474227\n",
      "Epoch 46 - Train Loss: 0.283858, Train Acc: 0.503846 | Val Loss: 0.294685, Val Acc: 0.474227\n",
      "Epoch 47 - Train Loss: 0.283273, Train Acc: 0.503846 | Val Loss: 0.294078, Val Acc: 0.474227\n",
      "Epoch 48 - Train Loss: 0.282714, Train Acc: 0.503846 | Val Loss: 0.293497, Val Acc: 0.474227\n",
      "Epoch 49 - Train Loss: 0.282180, Train Acc: 0.503846 | Val Loss: 0.292940, Val Acc: 0.474227\n",
      "Epoch 50 - Train Loss: 0.281671, Train Acc: 0.503846 | Val Loss: 0.292406, Val Acc: 0.474227\n",
      "Epoch 51 - Train Loss: 0.281184, Train Acc: 0.503846 | Val Loss: 0.291895, Val Acc: 0.474227\n",
      "Epoch 52 - Train Loss: 0.280719, Train Acc: 0.503846 | Val Loss: 0.291405, Val Acc: 0.474227\n",
      "Epoch 53 - Train Loss: 0.280276, Train Acc: 0.503846 | Val Loss: 0.290935, Val Acc: 0.474227\n",
      "Epoch 54 - Train Loss: 0.279852, Train Acc: 0.503846 | Val Loss: 0.290484, Val Acc: 0.474227\n",
      "Epoch 55 - Train Loss: 0.279448, Train Acc: 0.503846 | Val Loss: 0.290053, Val Acc: 0.474227\n",
      "Epoch 56 - Train Loss: 0.279062, Train Acc: 0.503846 | Val Loss: 0.289639, Val Acc: 0.474227\n",
      "Epoch 57 - Train Loss: 0.278694, Train Acc: 0.503846 | Val Loss: 0.289242, Val Acc: 0.474227\n",
      "Epoch 58 - Train Loss: 0.278342, Train Acc: 0.503846 | Val Loss: 0.288862, Val Acc: 0.474227\n",
      "Epoch 59 - Train Loss: 0.278006, Train Acc: 0.503846 | Val Loss: 0.288496, Val Acc: 0.474227\n",
      "Epoch 60 - Train Loss: 0.277685, Train Acc: 0.503846 | Val Loss: 0.288146, Val Acc: 0.474227\n",
      "Epoch 61 - Train Loss: 0.277378, Train Acc: 0.503846 | Val Loss: 0.287810, Val Acc: 0.474227\n",
      "Epoch 62 - Train Loss: 0.277086, Train Acc: 0.503846 | Val Loss: 0.287487, Val Acc: 0.474227\n",
      "Epoch 63 - Train Loss: 0.276805, Train Acc: 0.503846 | Val Loss: 0.287176, Val Acc: 0.474227\n",
      "Epoch 64 - Train Loss: 0.276537, Train Acc: 0.503846 | Val Loss: 0.286878, Val Acc: 0.474227\n",
      "Epoch 65 - Train Loss: 0.276281, Train Acc: 0.503846 | Val Loss: 0.286591, Val Acc: 0.474227\n",
      "Epoch 66 - Train Loss: 0.276036, Train Acc: 0.503846 | Val Loss: 0.286315, Val Acc: 0.474227\n",
      "Epoch 67 - Train Loss: 0.275800, Train Acc: 0.503846 | Val Loss: 0.286050, Val Acc: 0.474227\n",
      "Epoch 68 - Train Loss: 0.275575, Train Acc: 0.503846 | Val Loss: 0.285794, Val Acc: 0.474227\n",
      "Epoch 69 - Train Loss: 0.275359, Train Acc: 0.503846 | Val Loss: 0.285547, Val Acc: 0.474227\n",
      "Epoch 70 - Train Loss: 0.275152, Train Acc: 0.503846 | Val Loss: 0.285309, Val Acc: 0.474227\n",
      "Epoch 71 - Train Loss: 0.274953, Train Acc: 0.503846 | Val Loss: 0.285079, Val Acc: 0.474227\n",
      "Epoch 72 - Train Loss: 0.274762, Train Acc: 0.503846 | Val Loss: 0.284857, Val Acc: 0.474227\n",
      "Epoch 73 - Train Loss: 0.274578, Train Acc: 0.503846 | Val Loss: 0.284643, Val Acc: 0.474227\n",
      "Epoch 74 - Train Loss: 0.274402, Train Acc: 0.503846 | Val Loss: 0.284436, Val Acc: 0.474227\n",
      "Epoch 75 - Train Loss: 0.274232, Train Acc: 0.503846 | Val Loss: 0.284235, Val Acc: 0.474227\n",
      "Epoch 76 - Train Loss: 0.274068, Train Acc: 0.503846 | Val Loss: 0.284041, Val Acc: 0.474227\n",
      "Epoch 77 - Train Loss: 0.273911, Train Acc: 0.503846 | Val Loss: 0.283853, Val Acc: 0.474227\n",
      "Epoch 78 - Train Loss: 0.273760, Train Acc: 0.503846 | Val Loss: 0.283671, Val Acc: 0.474227\n",
      "Epoch 79 - Train Loss: 0.273614, Train Acc: 0.503846 | Val Loss: 0.283494, Val Acc: 0.474227\n",
      "Epoch 80 - Train Loss: 0.273473, Train Acc: 0.503846 | Val Loss: 0.283322, Val Acc: 0.474227\n",
      "Epoch 81 - Train Loss: 0.273337, Train Acc: 0.503846 | Val Loss: 0.283156, Val Acc: 0.474227\n",
      "Epoch 82 - Train Loss: 0.273205, Train Acc: 0.503846 | Val Loss: 0.282994, Val Acc: 0.474227\n",
      "Epoch 83 - Train Loss: 0.273078, Train Acc: 0.503846 | Val Loss: 0.282837, Val Acc: 0.474227\n",
      "Epoch 84 - Train Loss: 0.272956, Train Acc: 0.503846 | Val Loss: 0.282684, Val Acc: 0.474227\n",
      "Epoch 85 - Train Loss: 0.272837, Train Acc: 0.503846 | Val Loss: 0.282535, Val Acc: 0.474227\n",
      "Epoch 86 - Train Loss: 0.272722, Train Acc: 0.503846 | Val Loss: 0.282390, Val Acc: 0.474227\n",
      "Epoch 87 - Train Loss: 0.272611, Train Acc: 0.503846 | Val Loss: 0.282249, Val Acc: 0.474227\n",
      "Epoch 88 - Train Loss: 0.272503, Train Acc: 0.503846 | Val Loss: 0.282112, Val Acc: 0.474227\n",
      "Epoch 89 - Train Loss: 0.272399, Train Acc: 0.503846 | Val Loss: 0.281978, Val Acc: 0.474227\n",
      "Epoch 90 - Train Loss: 0.272297, Train Acc: 0.503846 | Val Loss: 0.281847, Val Acc: 0.474227\n",
      "Epoch 91 - Train Loss: 0.272199, Train Acc: 0.503846 | Val Loss: 0.281720, Val Acc: 0.474227\n",
      "Epoch 92 - Train Loss: 0.272103, Train Acc: 0.503846 | Val Loss: 0.281595, Val Acc: 0.474227\n",
      "Epoch 93 - Train Loss: 0.272010, Train Acc: 0.503846 | Val Loss: 0.281474, Val Acc: 0.474227\n",
      "Epoch 94 - Train Loss: 0.271919, Train Acc: 0.503846 | Val Loss: 0.281355, Val Acc: 0.474227\n",
      "Epoch 95 - Train Loss: 0.271831, Train Acc: 0.503846 | Val Loss: 0.281239, Val Acc: 0.474227\n",
      "Epoch 96 - Train Loss: 0.271746, Train Acc: 0.503846 | Val Loss: 0.281126, Val Acc: 0.474227\n",
      "Epoch 97 - Train Loss: 0.271662, Train Acc: 0.503846 | Val Loss: 0.281016, Val Acc: 0.474227\n",
      "Epoch 98 - Train Loss: 0.271581, Train Acc: 0.503846 | Val Loss: 0.280907, Val Acc: 0.474227\n",
      "Epoch 99 - Train Loss: 0.271502, Train Acc: 0.503846 | Val Loss: 0.280801, Val Acc: 0.474227\n",
      "Epoch 100 - Train Loss: 0.271424, Train Acc: 0.503846 | Val Loss: 0.280696, Val Acc: 0.474227\n",
      "Epoch 101 - Train Loss: 0.271349, Train Acc: 0.503846 | Val Loss: 0.280595, Val Acc: 0.474227\n",
      "Epoch 102 - Train Loss: 0.271276, Train Acc: 0.503846 | Val Loss: 0.280495, Val Acc: 0.474227\n",
      "Epoch 103 - Train Loss: 0.271204, Train Acc: 0.503846 | Val Loss: 0.280397, Val Acc: 0.474227\n",
      "Epoch 104 - Train Loss: 0.271134, Train Acc: 0.503846 | Val Loss: 0.280301, Val Acc: 0.474227\n",
      "Epoch 105 - Train Loss: 0.271065, Train Acc: 0.503846 | Val Loss: 0.280207, Val Acc: 0.474227\n",
      "Epoch 106 - Train Loss: 0.270998, Train Acc: 0.503846 | Val Loss: 0.280115, Val Acc: 0.474227\n",
      "Epoch 107 - Train Loss: 0.270933, Train Acc: 0.503846 | Val Loss: 0.280024, Val Acc: 0.474227\n",
      "Epoch 108 - Train Loss: 0.270869, Train Acc: 0.503846 | Val Loss: 0.279935, Val Acc: 0.474227\n",
      "Epoch 109 - Train Loss: 0.270806, Train Acc: 0.503846 | Val Loss: 0.279848, Val Acc: 0.474227\n",
      "Epoch 110 - Train Loss: 0.270744, Train Acc: 0.503846 | Val Loss: 0.279762, Val Acc: 0.474227\n",
      "Epoch 111 - Train Loss: 0.270684, Train Acc: 0.503846 | Val Loss: 0.279678, Val Acc: 0.474227\n",
      "Epoch 112 - Train Loss: 0.270625, Train Acc: 0.503846 | Val Loss: 0.279596, Val Acc: 0.474227\n",
      "Epoch 113 - Train Loss: 0.270567, Train Acc: 0.503846 | Val Loss: 0.279514, Val Acc: 0.474227\n",
      "Epoch 114 - Train Loss: 0.270510, Train Acc: 0.503846 | Val Loss: 0.279435, Val Acc: 0.474227\n",
      "Epoch 115 - Train Loss: 0.270455, Train Acc: 0.503846 | Val Loss: 0.279356, Val Acc: 0.474227\n",
      "Epoch 116 - Train Loss: 0.270400, Train Acc: 0.503846 | Val Loss: 0.279279, Val Acc: 0.474227\n",
      "Epoch 117 - Train Loss: 0.270347, Train Acc: 0.503846 | Val Loss: 0.279203, Val Acc: 0.474227\n",
      "Epoch 118 - Train Loss: 0.270295, Train Acc: 0.503846 | Val Loss: 0.279129, Val Acc: 0.474227\n",
      "Epoch 119 - Train Loss: 0.270243, Train Acc: 0.503846 | Val Loss: 0.279055, Val Acc: 0.474227\n",
      "Epoch 120 - Train Loss: 0.270193, Train Acc: 0.503846 | Val Loss: 0.278983, Val Acc: 0.474227\n",
      "Epoch 121 - Train Loss: 0.270143, Train Acc: 0.503846 | Val Loss: 0.278912, Val Acc: 0.474227\n",
      "Epoch 122 - Train Loss: 0.270095, Train Acc: 0.503846 | Val Loss: 0.278843, Val Acc: 0.474227\n",
      "Epoch 123 - Train Loss: 0.270047, Train Acc: 0.503846 | Val Loss: 0.278774, Val Acc: 0.474227\n",
      "Epoch 124 - Train Loss: 0.270000, Train Acc: 0.503846 | Val Loss: 0.278706, Val Acc: 0.474227\n",
      "Epoch 125 - Train Loss: 0.269954, Train Acc: 0.503846 | Val Loss: 0.278640, Val Acc: 0.474227\n",
      "Epoch 126 - Train Loss: 0.269908, Train Acc: 0.503846 | Val Loss: 0.278574, Val Acc: 0.474227\n",
      "Epoch 127 - Train Loss: 0.269863, Train Acc: 0.503846 | Val Loss: 0.278510, Val Acc: 0.474227\n",
      "Epoch 128 - Train Loss: 0.269819, Train Acc: 0.503846 | Val Loss: 0.278447, Val Acc: 0.474227\n",
      "Epoch 129 - Train Loss: 0.269775, Train Acc: 0.503846 | Val Loss: 0.278385, Val Acc: 0.474227\n",
      "Epoch 130 - Train Loss: 0.269732, Train Acc: 0.503846 | Val Loss: 0.278323, Val Acc: 0.474227\n",
      "Epoch 131 - Train Loss: 0.269690, Train Acc: 0.503846 | Val Loss: 0.278263, Val Acc: 0.474227\n",
      "Epoch 132 - Train Loss: 0.269648, Train Acc: 0.503846 | Val Loss: 0.278204, Val Acc: 0.474227\n",
      "Epoch 133 - Train Loss: 0.269607, Train Acc: 0.503846 | Val Loss: 0.278146, Val Acc: 0.474227\n",
      "Epoch 134 - Train Loss: 0.269567, Train Acc: 0.503846 | Val Loss: 0.278088, Val Acc: 0.474227\n",
      "Epoch 135 - Train Loss: 0.269527, Train Acc: 0.503846 | Val Loss: 0.278032, Val Acc: 0.474227\n",
      "Epoch 136 - Train Loss: 0.269487, Train Acc: 0.503846 | Val Loss: 0.277976, Val Acc: 0.474227\n",
      "Epoch 137 - Train Loss: 0.269448, Train Acc: 0.503846 | Val Loss: 0.277921, Val Acc: 0.474227\n",
      "Epoch 138 - Train Loss: 0.269410, Train Acc: 0.503846 | Val Loss: 0.277867, Val Acc: 0.474227\n",
      "Epoch 139 - Train Loss: 0.269372, Train Acc: 0.503846 | Val Loss: 0.277813, Val Acc: 0.474227\n",
      "Epoch 140 - Train Loss: 0.269334, Train Acc: 0.503846 | Val Loss: 0.277760, Val Acc: 0.474227\n",
      "Epoch 141 - Train Loss: 0.269298, Train Acc: 0.503846 | Val Loss: 0.277708, Val Acc: 0.474227\n",
      "Epoch 142 - Train Loss: 0.269261, Train Acc: 0.503846 | Val Loss: 0.277656, Val Acc: 0.474227\n",
      "Epoch 143 - Train Loss: 0.269225, Train Acc: 0.503846 | Val Loss: 0.277605, Val Acc: 0.474227\n",
      "Epoch 144 - Train Loss: 0.269189, Train Acc: 0.503846 | Val Loss: 0.277555, Val Acc: 0.474227\n",
      "Epoch 145 - Train Loss: 0.269154, Train Acc: 0.503846 | Val Loss: 0.277505, Val Acc: 0.474227\n",
      "Epoch 146 - Train Loss: 0.269119, Train Acc: 0.503846 | Val Loss: 0.277456, Val Acc: 0.474227\n",
      "Epoch 147 - Train Loss: 0.269085, Train Acc: 0.503846 | Val Loss: 0.277408, Val Acc: 0.474227\n",
      "Epoch 148 - Train Loss: 0.269051, Train Acc: 0.503846 | Val Loss: 0.277360, Val Acc: 0.474227\n",
      "Epoch 149 - Train Loss: 0.269017, Train Acc: 0.503846 | Val Loss: 0.277313, Val Acc: 0.474227\n",
      "Epoch 150 - Train Loss: 0.268983, Train Acc: 0.503846 | Val Loss: 0.277266, Val Acc: 0.474227\n",
      "Epoch 151 - Train Loss: 0.268950, Train Acc: 0.503846 | Val Loss: 0.277220, Val Acc: 0.474227\n",
      "Epoch 152 - Train Loss: 0.268917, Train Acc: 0.503846 | Val Loss: 0.277174, Val Acc: 0.474227\n",
      "Epoch 153 - Train Loss: 0.268885, Train Acc: 0.503846 | Val Loss: 0.277129, Val Acc: 0.474227\n",
      "Epoch 154 - Train Loss: 0.268853, Train Acc: 0.503846 | Val Loss: 0.277085, Val Acc: 0.474227\n",
      "Epoch 155 - Train Loss: 0.268821, Train Acc: 0.503846 | Val Loss: 0.277040, Val Acc: 0.474227\n",
      "Epoch 156 - Train Loss: 0.268789, Train Acc: 0.503846 | Val Loss: 0.276997, Val Acc: 0.474227\n",
      "Epoch 157 - Train Loss: 0.268758, Train Acc: 0.503846 | Val Loss: 0.276954, Val Acc: 0.474227\n",
      "Epoch 158 - Train Loss: 0.268727, Train Acc: 0.503846 | Val Loss: 0.276911, Val Acc: 0.474227\n",
      "Epoch 159 - Train Loss: 0.268696, Train Acc: 0.503846 | Val Loss: 0.276869, Val Acc: 0.474227\n",
      "Epoch 160 - Train Loss: 0.268666, Train Acc: 0.503846 | Val Loss: 0.276827, Val Acc: 0.474227\n",
      "Epoch 161 - Train Loss: 0.268635, Train Acc: 0.503846 | Val Loss: 0.276786, Val Acc: 0.474227\n",
      "Epoch 162 - Train Loss: 0.268605, Train Acc: 0.503846 | Val Loss: 0.276746, Val Acc: 0.474227\n",
      "Epoch 163 - Train Loss: 0.268576, Train Acc: 0.503846 | Val Loss: 0.276706, Val Acc: 0.474227\n",
      "Epoch 164 - Train Loss: 0.268546, Train Acc: 0.503846 | Val Loss: 0.276666, Val Acc: 0.474227\n",
      "Epoch 165 - Train Loss: 0.268516, Train Acc: 0.503846 | Val Loss: 0.276627, Val Acc: 0.474227\n",
      "Epoch 166 - Train Loss: 0.268487, Train Acc: 0.503846 | Val Loss: 0.276588, Val Acc: 0.474227\n",
      "Epoch 167 - Train Loss: 0.268458, Train Acc: 0.503846 | Val Loss: 0.276550, Val Acc: 0.474227\n",
      "Epoch 168 - Train Loss: 0.268429, Train Acc: 0.503846 | Val Loss: 0.276512, Val Acc: 0.474227\n",
      "Epoch 169 - Train Loss: 0.268401, Train Acc: 0.503846 | Val Loss: 0.276474, Val Acc: 0.474227\n",
      "Epoch 170 - Train Loss: 0.268372, Train Acc: 0.503846 | Val Loss: 0.276437, Val Acc: 0.474227\n",
      "Epoch 171 - Train Loss: 0.268344, Train Acc: 0.503846 | Val Loss: 0.276400, Val Acc: 0.474227\n",
      "Epoch 172 - Train Loss: 0.268316, Train Acc: 0.503846 | Val Loss: 0.276363, Val Acc: 0.474227\n",
      "Epoch 173 - Train Loss: 0.268288, Train Acc: 0.503846 | Val Loss: 0.276327, Val Acc: 0.474227\n",
      "Epoch 174 - Train Loss: 0.268260, Train Acc: 0.503846 | Val Loss: 0.276292, Val Acc: 0.474227\n",
      "Epoch 175 - Train Loss: 0.268232, Train Acc: 0.503846 | Val Loss: 0.276256, Val Acc: 0.474227\n",
      "Epoch 176 - Train Loss: 0.268205, Train Acc: 0.503846 | Val Loss: 0.276221, Val Acc: 0.474227\n",
      "Epoch 177 - Train Loss: 0.268178, Train Acc: 0.503846 | Val Loss: 0.276187, Val Acc: 0.474227\n",
      "Epoch 178 - Train Loss: 0.268150, Train Acc: 0.503846 | Val Loss: 0.276152, Val Acc: 0.474227\n",
      "Epoch 179 - Train Loss: 0.268123, Train Acc: 0.503846 | Val Loss: 0.276118, Val Acc: 0.474227\n",
      "Epoch 180 - Train Loss: 0.268097, Train Acc: 0.503846 | Val Loss: 0.276085, Val Acc: 0.474227\n",
      "Epoch 181 - Train Loss: 0.268070, Train Acc: 0.503846 | Val Loss: 0.276051, Val Acc: 0.474227\n",
      "Epoch 182 - Train Loss: 0.268044, Train Acc: 0.503846 | Val Loss: 0.276018, Val Acc: 0.474227\n",
      "Epoch 183 - Train Loss: 0.268017, Train Acc: 0.503846 | Val Loss: 0.275985, Val Acc: 0.474227\n",
      "Epoch 184 - Train Loss: 0.267991, Train Acc: 0.503846 | Val Loss: 0.275953, Val Acc: 0.474227\n",
      "Epoch 185 - Train Loss: 0.267965, Train Acc: 0.503846 | Val Loss: 0.275920, Val Acc: 0.474227\n",
      "Epoch 186 - Train Loss: 0.267939, Train Acc: 0.503846 | Val Loss: 0.275888, Val Acc: 0.474227\n",
      "Epoch 187 - Train Loss: 0.267913, Train Acc: 0.503846 | Val Loss: 0.275856, Val Acc: 0.474227\n",
      "Epoch 188 - Train Loss: 0.267888, Train Acc: 0.503846 | Val Loss: 0.275825, Val Acc: 0.474227\n",
      "Epoch 189 - Train Loss: 0.267862, Train Acc: 0.503846 | Val Loss: 0.275793, Val Acc: 0.474227\n",
      "Epoch 190 - Train Loss: 0.267836, Train Acc: 0.503846 | Val Loss: 0.275762, Val Acc: 0.474227\n",
      "Epoch 191 - Train Loss: 0.267811, Train Acc: 0.503846 | Val Loss: 0.275731, Val Acc: 0.474227\n",
      "Epoch 192 - Train Loss: 0.267786, Train Acc: 0.503846 | Val Loss: 0.275700, Val Acc: 0.474227\n",
      "Epoch 193 - Train Loss: 0.267760, Train Acc: 0.503846 | Val Loss: 0.275669, Val Acc: 0.474227\n",
      "Epoch 194 - Train Loss: 0.267735, Train Acc: 0.503846 | Val Loss: 0.275639, Val Acc: 0.474227\n",
      "Epoch 195 - Train Loss: 0.267710, Train Acc: 0.503846 | Val Loss: 0.275608, Val Acc: 0.474227\n",
      "Epoch 196 - Train Loss: 0.267685, Train Acc: 0.503846 | Val Loss: 0.275578, Val Acc: 0.474227\n",
      "Epoch 197 - Train Loss: 0.267660, Train Acc: 0.503846 | Val Loss: 0.275549, Val Acc: 0.474227\n",
      "Epoch 198 - Train Loss: 0.267636, Train Acc: 0.503846 | Val Loss: 0.275519, Val Acc: 0.474227\n",
      "Epoch 199 - Train Loss: 0.267611, Train Acc: 0.503846 | Val Loss: 0.275490, Val Acc: 0.474227\n",
      "Epoch 200 - Train Loss: 0.267586, Train Acc: 0.503846 | Val Loss: 0.275461, Val Acc: 0.474227\n",
      "Epoch 201 - Train Loss: 0.267561, Train Acc: 0.503846 | Val Loss: 0.275432, Val Acc: 0.474227\n",
      "Epoch 202 - Train Loss: 0.267536, Train Acc: 0.503846 | Val Loss: 0.275403, Val Acc: 0.474227\n",
      "Epoch 203 - Train Loss: 0.267512, Train Acc: 0.503846 | Val Loss: 0.275374, Val Acc: 0.474227\n",
      "Epoch 204 - Train Loss: 0.267487, Train Acc: 0.503846 | Val Loss: 0.275346, Val Acc: 0.474227\n",
      "Epoch 205 - Train Loss: 0.267462, Train Acc: 0.503846 | Val Loss: 0.275318, Val Acc: 0.474227\n",
      "Epoch 206 - Train Loss: 0.267438, Train Acc: 0.503846 | Val Loss: 0.275290, Val Acc: 0.474227\n",
      "Epoch 207 - Train Loss: 0.267414, Train Acc: 0.503846 | Val Loss: 0.275262, Val Acc: 0.474227\n",
      "Epoch 208 - Train Loss: 0.267389, Train Acc: 0.503846 | Val Loss: 0.275235, Val Acc: 0.474227\n",
      "Epoch 209 - Train Loss: 0.267365, Train Acc: 0.503846 | Val Loss: 0.275208, Val Acc: 0.474227\n",
      "Epoch 210 - Train Loss: 0.267341, Train Acc: 0.503846 | Val Loss: 0.275180, Val Acc: 0.474227\n",
      "Epoch 211 - Train Loss: 0.267317, Train Acc: 0.503846 | Val Loss: 0.275153, Val Acc: 0.474227\n",
      "Epoch 212 - Train Loss: 0.267293, Train Acc: 0.503846 | Val Loss: 0.275126, Val Acc: 0.474227\n",
      "Epoch 213 - Train Loss: 0.267269, Train Acc: 0.503846 | Val Loss: 0.275099, Val Acc: 0.474227\n",
      "Epoch 214 - Train Loss: 0.267246, Train Acc: 0.503846 | Val Loss: 0.275072, Val Acc: 0.474227\n",
      "Epoch 215 - Train Loss: 0.267222, Train Acc: 0.503846 | Val Loss: 0.275045, Val Acc: 0.474227\n",
      "Epoch 216 - Train Loss: 0.267198, Train Acc: 0.503846 | Val Loss: 0.275019, Val Acc: 0.474227\n",
      "Epoch 217 - Train Loss: 0.267174, Train Acc: 0.503846 | Val Loss: 0.274992, Val Acc: 0.474227\n",
      "Epoch 218 - Train Loss: 0.267151, Train Acc: 0.503846 | Val Loss: 0.274966, Val Acc: 0.474227\n",
      "Epoch 219 - Train Loss: 0.267127, Train Acc: 0.503846 | Val Loss: 0.274940, Val Acc: 0.474227\n",
      "Epoch 220 - Train Loss: 0.267104, Train Acc: 0.503846 | Val Loss: 0.274914, Val Acc: 0.474227\n",
      "Epoch 221 - Train Loss: 0.267080, Train Acc: 0.503846 | Val Loss: 0.274888, Val Acc: 0.474227\n",
      "Epoch 222 - Train Loss: 0.267057, Train Acc: 0.503846 | Val Loss: 0.274862, Val Acc: 0.474227\n",
      "Epoch 223 - Train Loss: 0.267033, Train Acc: 0.503846 | Val Loss: 0.274837, Val Acc: 0.474227\n",
      "Epoch 224 - Train Loss: 0.267010, Train Acc: 0.503846 | Val Loss: 0.274811, Val Acc: 0.474227\n",
      "Epoch 225 - Train Loss: 0.266986, Train Acc: 0.503846 | Val Loss: 0.274786, Val Acc: 0.474227\n",
      "Epoch 226 - Train Loss: 0.266963, Train Acc: 0.503846 | Val Loss: 0.274760, Val Acc: 0.474227\n",
      "Epoch 227 - Train Loss: 0.266940, Train Acc: 0.503846 | Val Loss: 0.274735, Val Acc: 0.474227\n",
      "Epoch 228 - Train Loss: 0.266916, Train Acc: 0.503846 | Val Loss: 0.274710, Val Acc: 0.474227\n",
      "Epoch 229 - Train Loss: 0.266893, Train Acc: 0.503846 | Val Loss: 0.274684, Val Acc: 0.474227\n",
      "Epoch 230 - Train Loss: 0.266870, Train Acc: 0.503846 | Val Loss: 0.274659, Val Acc: 0.474227\n",
      "Epoch 231 - Train Loss: 0.266847, Train Acc: 0.503846 | Val Loss: 0.274634, Val Acc: 0.474227\n",
      "Epoch 232 - Train Loss: 0.266824, Train Acc: 0.503846 | Val Loss: 0.274609, Val Acc: 0.474227\n",
      "Epoch 233 - Train Loss: 0.266801, Train Acc: 0.503846 | Val Loss: 0.274584, Val Acc: 0.474227\n",
      "Epoch 234 - Train Loss: 0.266778, Train Acc: 0.503846 | Val Loss: 0.274560, Val Acc: 0.474227\n",
      "Epoch 235 - Train Loss: 0.266755, Train Acc: 0.503846 | Val Loss: 0.274535, Val Acc: 0.474227\n",
      "Epoch 236 - Train Loss: 0.266733, Train Acc: 0.503846 | Val Loss: 0.274510, Val Acc: 0.474227\n",
      "Epoch 237 - Train Loss: 0.266710, Train Acc: 0.503846 | Val Loss: 0.274486, Val Acc: 0.474227\n",
      "Epoch 238 - Train Loss: 0.266687, Train Acc: 0.503846 | Val Loss: 0.274461, Val Acc: 0.474227\n",
      "Epoch 239 - Train Loss: 0.266665, Train Acc: 0.503846 | Val Loss: 0.274437, Val Acc: 0.474227\n",
      "Epoch 240 - Train Loss: 0.266642, Train Acc: 0.503846 | Val Loss: 0.274413, Val Acc: 0.474227\n",
      "Epoch 241 - Train Loss: 0.266619, Train Acc: 0.503846 | Val Loss: 0.274389, Val Acc: 0.474227\n",
      "Epoch 242 - Train Loss: 0.266597, Train Acc: 0.503846 | Val Loss: 0.274365, Val Acc: 0.474227\n",
      "Epoch 243 - Train Loss: 0.266574, Train Acc: 0.503846 | Val Loss: 0.274341, Val Acc: 0.474227\n",
      "Epoch 244 - Train Loss: 0.266552, Train Acc: 0.503846 | Val Loss: 0.274317, Val Acc: 0.474227\n",
      "Epoch 245 - Train Loss: 0.266529, Train Acc: 0.503846 | Val Loss: 0.274293, Val Acc: 0.474227\n",
      "Epoch 246 - Train Loss: 0.266507, Train Acc: 0.503846 | Val Loss: 0.274270, Val Acc: 0.474227\n",
      "Epoch 247 - Train Loss: 0.266485, Train Acc: 0.503846 | Val Loss: 0.274246, Val Acc: 0.474227\n",
      "Epoch 248 - Train Loss: 0.266462, Train Acc: 0.503846 | Val Loss: 0.274223, Val Acc: 0.474227\n",
      "Epoch 249 - Train Loss: 0.266440, Train Acc: 0.503846 | Val Loss: 0.274199, Val Acc: 0.474227\n",
      "Epoch 250 - Train Loss: 0.266417, Train Acc: 0.503846 | Val Loss: 0.274176, Val Acc: 0.474227\n",
      "Epoch 251 - Train Loss: 0.266395, Train Acc: 0.503846 | Val Loss: 0.274152, Val Acc: 0.474227\n",
      "Epoch 252 - Train Loss: 0.266373, Train Acc: 0.503846 | Val Loss: 0.274129, Val Acc: 0.474227\n",
      "Epoch 253 - Train Loss: 0.266350, Train Acc: 0.503846 | Val Loss: 0.274106, Val Acc: 0.474227\n",
      "Epoch 254 - Train Loss: 0.266328, Train Acc: 0.503846 | Val Loss: 0.274083, Val Acc: 0.474227\n",
      "Epoch 255 - Train Loss: 0.266306, Train Acc: 0.503846 | Val Loss: 0.274060, Val Acc: 0.474227\n",
      "Epoch 256 - Train Loss: 0.266284, Train Acc: 0.503846 | Val Loss: 0.274037, Val Acc: 0.474227\n",
      "Epoch 257 - Train Loss: 0.266261, Train Acc: 0.503846 | Val Loss: 0.274014, Val Acc: 0.474227\n",
      "Epoch 258 - Train Loss: 0.266239, Train Acc: 0.503846 | Val Loss: 0.273991, Val Acc: 0.474227\n",
      "Epoch 259 - Train Loss: 0.266217, Train Acc: 0.503846 | Val Loss: 0.273969, Val Acc: 0.474227\n",
      "Epoch 260 - Train Loss: 0.266195, Train Acc: 0.503846 | Val Loss: 0.273946, Val Acc: 0.474227\n",
      "Epoch 261 - Train Loss: 0.266173, Train Acc: 0.503846 | Val Loss: 0.273923, Val Acc: 0.474227\n",
      "Epoch 262 - Train Loss: 0.266150, Train Acc: 0.503846 | Val Loss: 0.273901, Val Acc: 0.474227\n",
      "Epoch 263 - Train Loss: 0.266128, Train Acc: 0.503846 | Val Loss: 0.273878, Val Acc: 0.474227\n",
      "Epoch 264 - Train Loss: 0.266106, Train Acc: 0.503846 | Val Loss: 0.273856, Val Acc: 0.474227\n",
      "Epoch 265 - Train Loss: 0.266084, Train Acc: 0.503846 | Val Loss: 0.273834, Val Acc: 0.474227\n",
      "Epoch 266 - Train Loss: 0.266062, Train Acc: 0.503846 | Val Loss: 0.273811, Val Acc: 0.474227\n",
      "Epoch 267 - Train Loss: 0.266040, Train Acc: 0.503846 | Val Loss: 0.273789, Val Acc: 0.474227\n",
      "Epoch 268 - Train Loss: 0.266018, Train Acc: 0.503846 | Val Loss: 0.273767, Val Acc: 0.474227\n",
      "Epoch 269 - Train Loss: 0.265996, Train Acc: 0.503846 | Val Loss: 0.273745, Val Acc: 0.474227\n",
      "Epoch 270 - Train Loss: 0.265974, Train Acc: 0.503846 | Val Loss: 0.273723, Val Acc: 0.474227\n",
      "Epoch 271 - Train Loss: 0.265952, Train Acc: 0.503846 | Val Loss: 0.273701, Val Acc: 0.474227\n",
      "Epoch 272 - Train Loss: 0.265930, Train Acc: 0.503846 | Val Loss: 0.273679, Val Acc: 0.474227\n",
      "Epoch 273 - Train Loss: 0.265909, Train Acc: 0.503846 | Val Loss: 0.273657, Val Acc: 0.474227\n",
      "Epoch 274 - Train Loss: 0.265887, Train Acc: 0.503846 | Val Loss: 0.273635, Val Acc: 0.474227\n",
      "Epoch 275 - Train Loss: 0.265865, Train Acc: 0.503846 | Val Loss: 0.273614, Val Acc: 0.474227\n",
      "Epoch 276 - Train Loss: 0.265843, Train Acc: 0.503846 | Val Loss: 0.273592, Val Acc: 0.474227\n",
      "Epoch 277 - Train Loss: 0.265821, Train Acc: 0.503846 | Val Loss: 0.273570, Val Acc: 0.474227\n",
      "Epoch 278 - Train Loss: 0.265799, Train Acc: 0.503846 | Val Loss: 0.273548, Val Acc: 0.474227\n",
      "Epoch 279 - Train Loss: 0.265777, Train Acc: 0.503846 | Val Loss: 0.273527, Val Acc: 0.474227\n",
      "Epoch 280 - Train Loss: 0.265756, Train Acc: 0.503846 | Val Loss: 0.273505, Val Acc: 0.474227\n",
      "Epoch 281 - Train Loss: 0.265734, Train Acc: 0.503846 | Val Loss: 0.273484, Val Acc: 0.474227\n",
      "Epoch 282 - Train Loss: 0.265712, Train Acc: 0.503846 | Val Loss: 0.273462, Val Acc: 0.474227\n",
      "Epoch 283 - Train Loss: 0.265690, Train Acc: 0.503846 | Val Loss: 0.273441, Val Acc: 0.474227\n",
      "Epoch 284 - Train Loss: 0.265668, Train Acc: 0.503846 | Val Loss: 0.273419, Val Acc: 0.474227\n",
      "Epoch 285 - Train Loss: 0.265647, Train Acc: 0.503846 | Val Loss: 0.273398, Val Acc: 0.474227\n",
      "Epoch 286 - Train Loss: 0.265625, Train Acc: 0.503846 | Val Loss: 0.273377, Val Acc: 0.474227\n",
      "Epoch 287 - Train Loss: 0.265603, Train Acc: 0.503846 | Val Loss: 0.273355, Val Acc: 0.474227\n",
      "Epoch 288 - Train Loss: 0.265581, Train Acc: 0.503846 | Val Loss: 0.273334, Val Acc: 0.474227\n",
      "Epoch 289 - Train Loss: 0.265560, Train Acc: 0.503846 | Val Loss: 0.273313, Val Acc: 0.474227\n",
      "Epoch 290 - Train Loss: 0.265538, Train Acc: 0.503846 | Val Loss: 0.273292, Val Acc: 0.474227\n",
      "Epoch 291 - Train Loss: 0.265516, Train Acc: 0.503846 | Val Loss: 0.273271, Val Acc: 0.474227\n",
      "Epoch 292 - Train Loss: 0.265494, Train Acc: 0.503846 | Val Loss: 0.273249, Val Acc: 0.474227\n",
      "Epoch 293 - Train Loss: 0.265473, Train Acc: 0.503846 | Val Loss: 0.273228, Val Acc: 0.474227\n",
      "Epoch 294 - Train Loss: 0.265451, Train Acc: 0.503846 | Val Loss: 0.273207, Val Acc: 0.474227\n",
      "Epoch 295 - Train Loss: 0.265429, Train Acc: 0.503846 | Val Loss: 0.273186, Val Acc: 0.474227\n",
      "Epoch 296 - Train Loss: 0.265407, Train Acc: 0.503846 | Val Loss: 0.273165, Val Acc: 0.474227\n",
      "Epoch 297 - Train Loss: 0.265385, Train Acc: 0.503846 | Val Loss: 0.273144, Val Acc: 0.474227\n",
      "Epoch 298 - Train Loss: 0.265364, Train Acc: 0.503846 | Val Loss: 0.273123, Val Acc: 0.474227\n",
      "Epoch 299 - Train Loss: 0.265342, Train Acc: 0.503846 | Val Loss: 0.273102, Val Acc: 0.474227\n",
      "Epoch 300 - Train Loss: 0.265320, Train Acc: 0.503846 | Val Loss: 0.273082, Val Acc: 0.474227\n",
      "Epoch 301 - Train Loss: 0.265298, Train Acc: 0.503846 | Val Loss: 0.273061, Val Acc: 0.474227\n",
      "Epoch 302 - Train Loss: 0.265276, Train Acc: 0.503846 | Val Loss: 0.273040, Val Acc: 0.474227\n",
      "Epoch 303 - Train Loss: 0.265254, Train Acc: 0.503846 | Val Loss: 0.273019, Val Acc: 0.474227\n",
      "Epoch 304 - Train Loss: 0.265233, Train Acc: 0.503846 | Val Loss: 0.272998, Val Acc: 0.474227\n",
      "Epoch 305 - Train Loss: 0.265211, Train Acc: 0.503846 | Val Loss: 0.272977, Val Acc: 0.474227\n",
      "Epoch 306 - Train Loss: 0.265189, Train Acc: 0.503846 | Val Loss: 0.272957, Val Acc: 0.474227\n",
      "Epoch 307 - Train Loss: 0.265167, Train Acc: 0.503846 | Val Loss: 0.272936, Val Acc: 0.474227\n",
      "Epoch 308 - Train Loss: 0.265145, Train Acc: 0.503846 | Val Loss: 0.272915, Val Acc: 0.474227\n",
      "Epoch 309 - Train Loss: 0.265124, Train Acc: 0.503846 | Val Loss: 0.272895, Val Acc: 0.474227\n",
      "Epoch 310 - Train Loss: 0.265102, Train Acc: 0.503846 | Val Loss: 0.272874, Val Acc: 0.474227\n",
      "Epoch 311 - Train Loss: 0.265080, Train Acc: 0.503846 | Val Loss: 0.272853, Val Acc: 0.474227\n",
      "Epoch 312 - Train Loss: 0.265058, Train Acc: 0.503846 | Val Loss: 0.272833, Val Acc: 0.474227\n",
      "Epoch 313 - Train Loss: 0.265036, Train Acc: 0.503846 | Val Loss: 0.272812, Val Acc: 0.474227\n",
      "Epoch 314 - Train Loss: 0.265015, Train Acc: 0.503846 | Val Loss: 0.272792, Val Acc: 0.474227\n",
      "Epoch 315 - Train Loss: 0.264993, Train Acc: 0.503846 | Val Loss: 0.272771, Val Acc: 0.474227\n",
      "Epoch 316 - Train Loss: 0.264971, Train Acc: 0.503846 | Val Loss: 0.272751, Val Acc: 0.474227\n",
      "Epoch 317 - Train Loss: 0.264950, Train Acc: 0.503846 | Val Loss: 0.272730, Val Acc: 0.474227\n",
      "Epoch 318 - Train Loss: 0.264928, Train Acc: 0.503846 | Val Loss: 0.272710, Val Acc: 0.474227\n",
      "Epoch 319 - Train Loss: 0.264906, Train Acc: 0.503846 | Val Loss: 0.272689, Val Acc: 0.474227\n",
      "Epoch 320 - Train Loss: 0.264885, Train Acc: 0.503846 | Val Loss: 0.272669, Val Acc: 0.474227\n",
      "Epoch 321 - Train Loss: 0.264863, Train Acc: 0.503846 | Val Loss: 0.272648, Val Acc: 0.474227\n",
      "Epoch 322 - Train Loss: 0.264842, Train Acc: 0.503846 | Val Loss: 0.272628, Val Acc: 0.474227\n",
      "Epoch 323 - Train Loss: 0.264820, Train Acc: 0.503846 | Val Loss: 0.272608, Val Acc: 0.474227\n",
      "Epoch 324 - Train Loss: 0.264799, Train Acc: 0.503846 | Val Loss: 0.272587, Val Acc: 0.474227\n",
      "Epoch 325 - Train Loss: 0.264778, Train Acc: 0.503846 | Val Loss: 0.272567, Val Acc: 0.474227\n",
      "Epoch 326 - Train Loss: 0.264756, Train Acc: 0.503846 | Val Loss: 0.272547, Val Acc: 0.474227\n",
      "Epoch 327 - Train Loss: 0.264735, Train Acc: 0.503846 | Val Loss: 0.272526, Val Acc: 0.474227\n",
      "Epoch 328 - Train Loss: 0.264713, Train Acc: 0.503846 | Val Loss: 0.272505, Val Acc: 0.474227\n",
      "Epoch 329 - Train Loss: 0.264692, Train Acc: 0.503846 | Val Loss: 0.272485, Val Acc: 0.474227\n",
      "Epoch 330 - Train Loss: 0.264670, Train Acc: 0.503846 | Val Loss: 0.272464, Val Acc: 0.474227\n",
      "Epoch 331 - Train Loss: 0.264649, Train Acc: 0.503846 | Val Loss: 0.272444, Val Acc: 0.474227\n",
      "Epoch 332 - Train Loss: 0.264627, Train Acc: 0.503846 | Val Loss: 0.272423, Val Acc: 0.474227\n",
      "Epoch 333 - Train Loss: 0.264606, Train Acc: 0.503846 | Val Loss: 0.272403, Val Acc: 0.474227\n",
      "Epoch 334 - Train Loss: 0.264585, Train Acc: 0.503846 | Val Loss: 0.272382, Val Acc: 0.474227\n",
      "Epoch 335 - Train Loss: 0.264563, Train Acc: 0.503846 | Val Loss: 0.272362, Val Acc: 0.474227\n",
      "Epoch 336 - Train Loss: 0.264542, Train Acc: 0.503846 | Val Loss: 0.272341, Val Acc: 0.474227\n",
      "Epoch 337 - Train Loss: 0.264521, Train Acc: 0.503846 | Val Loss: 0.272321, Val Acc: 0.474227\n",
      "Epoch 338 - Train Loss: 0.264499, Train Acc: 0.503846 | Val Loss: 0.272301, Val Acc: 0.474227\n",
      "Epoch 339 - Train Loss: 0.264478, Train Acc: 0.503846 | Val Loss: 0.272280, Val Acc: 0.474227\n",
      "Epoch 340 - Train Loss: 0.264457, Train Acc: 0.503846 | Val Loss: 0.272260, Val Acc: 0.474227\n",
      "Epoch 341 - Train Loss: 0.264436, Train Acc: 0.503846 | Val Loss: 0.272240, Val Acc: 0.474227\n",
      "Epoch 342 - Train Loss: 0.264414, Train Acc: 0.503846 | Val Loss: 0.272220, Val Acc: 0.474227\n",
      "Epoch 343 - Train Loss: 0.264393, Train Acc: 0.503846 | Val Loss: 0.272199, Val Acc: 0.474227\n",
      "Epoch 344 - Train Loss: 0.264372, Train Acc: 0.503846 | Val Loss: 0.272179, Val Acc: 0.474227\n",
      "Epoch 345 - Train Loss: 0.264351, Train Acc: 0.503846 | Val Loss: 0.272159, Val Acc: 0.474227\n",
      "Epoch 346 - Train Loss: 0.264329, Train Acc: 0.503846 | Val Loss: 0.272139, Val Acc: 0.474227\n",
      "Epoch 347 - Train Loss: 0.264308, Train Acc: 0.503846 | Val Loss: 0.272119, Val Acc: 0.474227\n",
      "Epoch 348 - Train Loss: 0.264287, Train Acc: 0.503846 | Val Loss: 0.272099, Val Acc: 0.474227\n",
      "Epoch 349 - Train Loss: 0.264266, Train Acc: 0.503846 | Val Loss: 0.272079, Val Acc: 0.474227\n",
      "Epoch 350 - Train Loss: 0.264244, Train Acc: 0.503846 | Val Loss: 0.272058, Val Acc: 0.474227\n",
      "Epoch 351 - Train Loss: 0.264223, Train Acc: 0.503846 | Val Loss: 0.272038, Val Acc: 0.474227\n",
      "Epoch 352 - Train Loss: 0.264202, Train Acc: 0.503846 | Val Loss: 0.272018, Val Acc: 0.474227\n",
      "Epoch 353 - Train Loss: 0.264181, Train Acc: 0.503846 | Val Loss: 0.271998, Val Acc: 0.474227\n",
      "Epoch 354 - Train Loss: 0.264160, Train Acc: 0.503846 | Val Loss: 0.271978, Val Acc: 0.474227\n",
      "Epoch 355 - Train Loss: 0.264138, Train Acc: 0.503846 | Val Loss: 0.271958, Val Acc: 0.474227\n",
      "Epoch 356 - Train Loss: 0.264117, Train Acc: 0.503846 | Val Loss: 0.271938, Val Acc: 0.474227\n",
      "Epoch 357 - Train Loss: 0.264096, Train Acc: 0.503846 | Val Loss: 0.271918, Val Acc: 0.474227\n",
      "Epoch 358 - Train Loss: 0.264075, Train Acc: 0.503846 | Val Loss: 0.271898, Val Acc: 0.474227\n",
      "Epoch 359 - Train Loss: 0.264054, Train Acc: 0.503846 | Val Loss: 0.271878, Val Acc: 0.474227\n",
      "Epoch 360 - Train Loss: 0.264032, Train Acc: 0.503846 | Val Loss: 0.271858, Val Acc: 0.474227\n",
      "Epoch 361 - Train Loss: 0.264011, Train Acc: 0.503846 | Val Loss: 0.271838, Val Acc: 0.474227\n",
      "Epoch 362 - Train Loss: 0.263990, Train Acc: 0.503846 | Val Loss: 0.271817, Val Acc: 0.474227\n",
      "Epoch 363 - Train Loss: 0.263969, Train Acc: 0.503846 | Val Loss: 0.271797, Val Acc: 0.474227\n",
      "Epoch 364 - Train Loss: 0.263948, Train Acc: 0.503846 | Val Loss: 0.271777, Val Acc: 0.474227\n",
      "Epoch 365 - Train Loss: 0.263926, Train Acc: 0.503846 | Val Loss: 0.271757, Val Acc: 0.474227\n",
      "Epoch 366 - Train Loss: 0.263905, Train Acc: 0.503846 | Val Loss: 0.271737, Val Acc: 0.474227\n",
      "Epoch 367 - Train Loss: 0.263884, Train Acc: 0.503846 | Val Loss: 0.271717, Val Acc: 0.474227\n",
      "Epoch 368 - Train Loss: 0.263863, Train Acc: 0.503846 | Val Loss: 0.271697, Val Acc: 0.474227\n",
      "Epoch 369 - Train Loss: 0.263842, Train Acc: 0.503846 | Val Loss: 0.271678, Val Acc: 0.474227\n",
      "Epoch 370 - Train Loss: 0.263820, Train Acc: 0.503846 | Val Loss: 0.271658, Val Acc: 0.474227\n",
      "Epoch 371 - Train Loss: 0.263799, Train Acc: 0.503846 | Val Loss: 0.271638, Val Acc: 0.474227\n",
      "Epoch 372 - Train Loss: 0.263778, Train Acc: 0.503846 | Val Loss: 0.271618, Val Acc: 0.474227\n",
      "Epoch 373 - Train Loss: 0.263757, Train Acc: 0.503846 | Val Loss: 0.271598, Val Acc: 0.474227\n",
      "Epoch 374 - Train Loss: 0.263736, Train Acc: 0.503846 | Val Loss: 0.271578, Val Acc: 0.474227\n",
      "Epoch 375 - Train Loss: 0.263714, Train Acc: 0.503846 | Val Loss: 0.271558, Val Acc: 0.474227\n",
      "Epoch 376 - Train Loss: 0.263693, Train Acc: 0.503846 | Val Loss: 0.271538, Val Acc: 0.474227\n",
      "Epoch 377 - Train Loss: 0.263672, Train Acc: 0.503846 | Val Loss: 0.271518, Val Acc: 0.474227\n",
      "Epoch 378 - Train Loss: 0.263651, Train Acc: 0.503846 | Val Loss: 0.271499, Val Acc: 0.474227\n",
      "Epoch 379 - Train Loss: 0.263630, Train Acc: 0.503846 | Val Loss: 0.271479, Val Acc: 0.474227\n",
      "Epoch 380 - Train Loss: 0.263609, Train Acc: 0.503846 | Val Loss: 0.271459, Val Acc: 0.474227\n",
      "Epoch 381 - Train Loss: 0.263588, Train Acc: 0.503846 | Val Loss: 0.271439, Val Acc: 0.474227\n",
      "Epoch 382 - Train Loss: 0.263566, Train Acc: 0.503846 | Val Loss: 0.271419, Val Acc: 0.474227\n",
      "Epoch 383 - Train Loss: 0.263545, Train Acc: 0.503846 | Val Loss: 0.271399, Val Acc: 0.474227\n",
      "Epoch 384 - Train Loss: 0.263524, Train Acc: 0.503846 | Val Loss: 0.271379, Val Acc: 0.474227\n",
      "Epoch 385 - Train Loss: 0.263503, Train Acc: 0.503846 | Val Loss: 0.271359, Val Acc: 0.474227\n",
      "Epoch 386 - Train Loss: 0.263482, Train Acc: 0.503846 | Val Loss: 0.271340, Val Acc: 0.474227\n",
      "Epoch 387 - Train Loss: 0.263461, Train Acc: 0.503846 | Val Loss: 0.271320, Val Acc: 0.474227\n",
      "Epoch 388 - Train Loss: 0.263440, Train Acc: 0.503846 | Val Loss: 0.271300, Val Acc: 0.474227\n",
      "Epoch 389 - Train Loss: 0.263419, Train Acc: 0.503846 | Val Loss: 0.271280, Val Acc: 0.474227\n",
      "Epoch 390 - Train Loss: 0.263398, Train Acc: 0.503846 | Val Loss: 0.271260, Val Acc: 0.474227\n",
      "Epoch 391 - Train Loss: 0.263376, Train Acc: 0.503846 | Val Loss: 0.271240, Val Acc: 0.474227\n",
      "Epoch 392 - Train Loss: 0.263355, Train Acc: 0.503846 | Val Loss: 0.271220, Val Acc: 0.474227\n",
      "Epoch 393 - Train Loss: 0.263334, Train Acc: 0.503846 | Val Loss: 0.271200, Val Acc: 0.474227\n",
      "Epoch 394 - Train Loss: 0.263313, Train Acc: 0.503846 | Val Loss: 0.271181, Val Acc: 0.474227\n",
      "Epoch 395 - Train Loss: 0.263292, Train Acc: 0.503846 | Val Loss: 0.271161, Val Acc: 0.474227\n",
      "Epoch 396 - Train Loss: 0.263271, Train Acc: 0.503846 | Val Loss: 0.271141, Val Acc: 0.474227\n",
      "Epoch 397 - Train Loss: 0.263250, Train Acc: 0.503846 | Val Loss: 0.271121, Val Acc: 0.474227\n",
      "Epoch 398 - Train Loss: 0.263229, Train Acc: 0.503846 | Val Loss: 0.271101, Val Acc: 0.474227\n",
      "Epoch 399 - Train Loss: 0.263208, Train Acc: 0.503846 | Val Loss: 0.271081, Val Acc: 0.474227\n",
      "Epoch 400 - Train Loss: 0.263187, Train Acc: 0.503846 | Val Loss: 0.271062, Val Acc: 0.474227\n",
      "Epoch 401 - Train Loss: 0.263166, Train Acc: 0.503846 | Val Loss: 0.271042, Val Acc: 0.474227\n",
      "Epoch 402 - Train Loss: 0.263145, Train Acc: 0.503846 | Val Loss: 0.271022, Val Acc: 0.474227\n",
      "Epoch 403 - Train Loss: 0.263123, Train Acc: 0.503846 | Val Loss: 0.271002, Val Acc: 0.474227\n",
      "Epoch 404 - Train Loss: 0.263102, Train Acc: 0.503846 | Val Loss: 0.270982, Val Acc: 0.474227\n",
      "Epoch 405 - Train Loss: 0.263081, Train Acc: 0.503846 | Val Loss: 0.270962, Val Acc: 0.474227\n",
      "Epoch 406 - Train Loss: 0.263060, Train Acc: 0.503846 | Val Loss: 0.270942, Val Acc: 0.474227\n",
      "Epoch 407 - Train Loss: 0.263039, Train Acc: 0.503846 | Val Loss: 0.270922, Val Acc: 0.474227\n",
      "Epoch 408 - Train Loss: 0.263018, Train Acc: 0.503846 | Val Loss: 0.270902, Val Acc: 0.474227\n",
      "Epoch 409 - Train Loss: 0.262997, Train Acc: 0.503846 | Val Loss: 0.270883, Val Acc: 0.474227\n",
      "Epoch 410 - Train Loss: 0.262976, Train Acc: 0.503846 | Val Loss: 0.270863, Val Acc: 0.474227\n",
      "Epoch 411 - Train Loss: 0.262955, Train Acc: 0.503846 | Val Loss: 0.270843, Val Acc: 0.474227\n",
      "Epoch 412 - Train Loss: 0.262934, Train Acc: 0.503846 | Val Loss: 0.270823, Val Acc: 0.474227\n",
      "Epoch 413 - Train Loss: 0.262913, Train Acc: 0.503846 | Val Loss: 0.270803, Val Acc: 0.474227\n",
      "Epoch 414 - Train Loss: 0.262892, Train Acc: 0.503846 | Val Loss: 0.270783, Val Acc: 0.474227\n",
      "Epoch 415 - Train Loss: 0.262871, Train Acc: 0.503846 | Val Loss: 0.270763, Val Acc: 0.474227\n",
      "Epoch 416 - Train Loss: 0.262850, Train Acc: 0.503846 | Val Loss: 0.270744, Val Acc: 0.474227\n",
      "Epoch 417 - Train Loss: 0.262829, Train Acc: 0.503846 | Val Loss: 0.270724, Val Acc: 0.474227\n",
      "Epoch 418 - Train Loss: 0.262808, Train Acc: 0.503846 | Val Loss: 0.270704, Val Acc: 0.474227\n",
      "Epoch 419 - Train Loss: 0.262787, Train Acc: 0.503846 | Val Loss: 0.270684, Val Acc: 0.474227\n",
      "Epoch 420 - Train Loss: 0.262766, Train Acc: 0.503846 | Val Loss: 0.270664, Val Acc: 0.474227\n",
      "Epoch 421 - Train Loss: 0.262745, Train Acc: 0.503846 | Val Loss: 0.270644, Val Acc: 0.474227\n",
      "Epoch 422 - Train Loss: 0.262724, Train Acc: 0.503846 | Val Loss: 0.270625, Val Acc: 0.474227\n",
      "Epoch 423 - Train Loss: 0.262703, Train Acc: 0.503846 | Val Loss: 0.270605, Val Acc: 0.474227\n",
      "Epoch 424 - Train Loss: 0.262682, Train Acc: 0.503846 | Val Loss: 0.270585, Val Acc: 0.474227\n",
      "Epoch 425 - Train Loss: 0.262661, Train Acc: 0.503846 | Val Loss: 0.270565, Val Acc: 0.474227\n",
      "Epoch 426 - Train Loss: 0.262640, Train Acc: 0.503846 | Val Loss: 0.270546, Val Acc: 0.474227\n",
      "Epoch 427 - Train Loss: 0.262619, Train Acc: 0.503846 | Val Loss: 0.270526, Val Acc: 0.474227\n",
      "Epoch 428 - Train Loss: 0.262598, Train Acc: 0.503846 | Val Loss: 0.270506, Val Acc: 0.474227\n",
      "Epoch 429 - Train Loss: 0.262577, Train Acc: 0.503846 | Val Loss: 0.270486, Val Acc: 0.474227\n",
      "Epoch 430 - Train Loss: 0.262556, Train Acc: 0.503846 | Val Loss: 0.270467, Val Acc: 0.474227\n",
      "Epoch 431 - Train Loss: 0.262535, Train Acc: 0.503846 | Val Loss: 0.270447, Val Acc: 0.474227\n",
      "Epoch 432 - Train Loss: 0.262514, Train Acc: 0.503846 | Val Loss: 0.270427, Val Acc: 0.474227\n",
      "Epoch 433 - Train Loss: 0.262493, Train Acc: 0.503846 | Val Loss: 0.270407, Val Acc: 0.474227\n",
      "Epoch 434 - Train Loss: 0.262473, Train Acc: 0.503846 | Val Loss: 0.270388, Val Acc: 0.474227\n",
      "Epoch 435 - Train Loss: 0.262452, Train Acc: 0.503846 | Val Loss: 0.270368, Val Acc: 0.474227\n",
      "Epoch 436 - Train Loss: 0.262431, Train Acc: 0.503846 | Val Loss: 0.270348, Val Acc: 0.474227\n",
      "Epoch 437 - Train Loss: 0.262410, Train Acc: 0.503846 | Val Loss: 0.270328, Val Acc: 0.474227\n",
      "Epoch 438 - Train Loss: 0.262389, Train Acc: 0.503846 | Val Loss: 0.270309, Val Acc: 0.474227\n",
      "Epoch 439 - Train Loss: 0.262368, Train Acc: 0.503846 | Val Loss: 0.270289, Val Acc: 0.474227\n",
      "Epoch 440 - Train Loss: 0.262347, Train Acc: 0.503846 | Val Loss: 0.270269, Val Acc: 0.474227\n",
      "Epoch 441 - Train Loss: 0.262326, Train Acc: 0.503846 | Val Loss: 0.270249, Val Acc: 0.474227\n",
      "Epoch 442 - Train Loss: 0.262305, Train Acc: 0.503846 | Val Loss: 0.270230, Val Acc: 0.474227\n",
      "Epoch 443 - Train Loss: 0.262284, Train Acc: 0.503846 | Val Loss: 0.270210, Val Acc: 0.474227\n",
      "Epoch 444 - Train Loss: 0.262263, Train Acc: 0.503846 | Val Loss: 0.270190, Val Acc: 0.474227\n",
      "Epoch 445 - Train Loss: 0.262242, Train Acc: 0.503846 | Val Loss: 0.270170, Val Acc: 0.474227\n",
      "Epoch 446 - Train Loss: 0.262221, Train Acc: 0.503846 | Val Loss: 0.270151, Val Acc: 0.474227\n",
      "Epoch 447 - Train Loss: 0.262200, Train Acc: 0.503846 | Val Loss: 0.270131, Val Acc: 0.474227\n",
      "Epoch 448 - Train Loss: 0.262179, Train Acc: 0.503846 | Val Loss: 0.270111, Val Acc: 0.474227\n",
      "Epoch 449 - Train Loss: 0.262159, Train Acc: 0.503846 | Val Loss: 0.270092, Val Acc: 0.474227\n",
      "Epoch 450 - Train Loss: 0.262138, Train Acc: 0.503846 | Val Loss: 0.270072, Val Acc: 0.474227\n",
      "Epoch 451 - Train Loss: 0.262117, Train Acc: 0.503846 | Val Loss: 0.270052, Val Acc: 0.474227\n",
      "Epoch 452 - Train Loss: 0.262096, Train Acc: 0.503846 | Val Loss: 0.270032, Val Acc: 0.474227\n",
      "Epoch 453 - Train Loss: 0.262075, Train Acc: 0.503846 | Val Loss: 0.270013, Val Acc: 0.474227\n",
      "Epoch 454 - Train Loss: 0.262054, Train Acc: 0.503846 | Val Loss: 0.269993, Val Acc: 0.474227\n",
      "Epoch 455 - Train Loss: 0.262033, Train Acc: 0.503846 | Val Loss: 0.269973, Val Acc: 0.474227\n",
      "Epoch 456 - Train Loss: 0.262012, Train Acc: 0.503846 | Val Loss: 0.269954, Val Acc: 0.474227\n",
      "Epoch 457 - Train Loss: 0.261991, Train Acc: 0.503846 | Val Loss: 0.269934, Val Acc: 0.474227\n",
      "Epoch 458 - Train Loss: 0.261970, Train Acc: 0.503846 | Val Loss: 0.269914, Val Acc: 0.474227\n",
      "Epoch 459 - Train Loss: 0.261950, Train Acc: 0.503846 | Val Loss: 0.269895, Val Acc: 0.474227\n",
      "Epoch 460 - Train Loss: 0.261929, Train Acc: 0.503846 | Val Loss: 0.269875, Val Acc: 0.474227\n",
      "Epoch 461 - Train Loss: 0.261908, Train Acc: 0.503846 | Val Loss: 0.269855, Val Acc: 0.474227\n",
      "Epoch 462 - Train Loss: 0.261887, Train Acc: 0.503846 | Val Loss: 0.269836, Val Acc: 0.474227\n",
      "Epoch 463 - Train Loss: 0.261866, Train Acc: 0.503846 | Val Loss: 0.269816, Val Acc: 0.474227\n",
      "Epoch 464 - Train Loss: 0.261845, Train Acc: 0.503846 | Val Loss: 0.269796, Val Acc: 0.474227\n",
      "Epoch 465 - Train Loss: 0.261825, Train Acc: 0.503846 | Val Loss: 0.269777, Val Acc: 0.474227\n",
      "Epoch 466 - Train Loss: 0.261804, Train Acc: 0.503846 | Val Loss: 0.269757, Val Acc: 0.474227\n",
      "Epoch 467 - Train Loss: 0.261783, Train Acc: 0.503846 | Val Loss: 0.269737, Val Acc: 0.474227\n",
      "Epoch 468 - Train Loss: 0.261762, Train Acc: 0.503846 | Val Loss: 0.269718, Val Acc: 0.474227\n",
      "Epoch 469 - Train Loss: 0.261741, Train Acc: 0.503846 | Val Loss: 0.269698, Val Acc: 0.474227\n",
      "Epoch 470 - Train Loss: 0.261720, Train Acc: 0.503846 | Val Loss: 0.269678, Val Acc: 0.474227\n",
      "Epoch 471 - Train Loss: 0.261700, Train Acc: 0.503846 | Val Loss: 0.269659, Val Acc: 0.474227\n",
      "Epoch 472 - Train Loss: 0.261679, Train Acc: 0.503846 | Val Loss: 0.269639, Val Acc: 0.474227\n",
      "Epoch 473 - Train Loss: 0.261658, Train Acc: 0.503846 | Val Loss: 0.269619, Val Acc: 0.474227\n",
      "Epoch 474 - Train Loss: 0.261637, Train Acc: 0.503846 | Val Loss: 0.269600, Val Acc: 0.474227\n",
      "Epoch 475 - Train Loss: 0.261616, Train Acc: 0.503846 | Val Loss: 0.269580, Val Acc: 0.474227\n",
      "Epoch 476 - Train Loss: 0.261596, Train Acc: 0.503846 | Val Loss: 0.269560, Val Acc: 0.474227\n",
      "Epoch 477 - Train Loss: 0.261575, Train Acc: 0.503846 | Val Loss: 0.269541, Val Acc: 0.474227\n",
      "Epoch 478 - Train Loss: 0.261554, Train Acc: 0.503846 | Val Loss: 0.269521, Val Acc: 0.474227\n",
      "Epoch 479 - Train Loss: 0.261533, Train Acc: 0.503846 | Val Loss: 0.269502, Val Acc: 0.474227\n",
      "Epoch 480 - Train Loss: 0.261512, Train Acc: 0.503846 | Val Loss: 0.269482, Val Acc: 0.474227\n",
      "Epoch 481 - Train Loss: 0.261492, Train Acc: 0.503846 | Val Loss: 0.269462, Val Acc: 0.474227\n",
      "Epoch 482 - Train Loss: 0.261471, Train Acc: 0.503846 | Val Loss: 0.269443, Val Acc: 0.474227\n",
      "Epoch 483 - Train Loss: 0.261450, Train Acc: 0.503846 | Val Loss: 0.269423, Val Acc: 0.474227\n",
      "Epoch 484 - Train Loss: 0.261429, Train Acc: 0.503846 | Val Loss: 0.269403, Val Acc: 0.474227\n",
      "Epoch 485 - Train Loss: 0.261409, Train Acc: 0.503846 | Val Loss: 0.269384, Val Acc: 0.474227\n",
      "Epoch 486 - Train Loss: 0.261388, Train Acc: 0.503846 | Val Loss: 0.269364, Val Acc: 0.474227\n",
      "Epoch 487 - Train Loss: 0.261367, Train Acc: 0.503846 | Val Loss: 0.269345, Val Acc: 0.474227\n",
      "Epoch 488 - Train Loss: 0.261346, Train Acc: 0.503846 | Val Loss: 0.269325, Val Acc: 0.474227\n",
      "Epoch 489 - Train Loss: 0.261326, Train Acc: 0.503846 | Val Loss: 0.269306, Val Acc: 0.474227\n",
      "Epoch 490 - Train Loss: 0.261305, Train Acc: 0.503846 | Val Loss: 0.269286, Val Acc: 0.474227\n",
      "Epoch 491 - Train Loss: 0.261284, Train Acc: 0.503846 | Val Loss: 0.269266, Val Acc: 0.474227\n",
      "Epoch 492 - Train Loss: 0.261264, Train Acc: 0.503846 | Val Loss: 0.269247, Val Acc: 0.474227\n",
      "Epoch 493 - Train Loss: 0.261243, Train Acc: 0.503846 | Val Loss: 0.269227, Val Acc: 0.474227\n",
      "Epoch 494 - Train Loss: 0.261222, Train Acc: 0.503846 | Val Loss: 0.269208, Val Acc: 0.474227\n",
      "Epoch 495 - Train Loss: 0.261202, Train Acc: 0.503846 | Val Loss: 0.269188, Val Acc: 0.474227\n",
      "Epoch 496 - Train Loss: 0.261181, Train Acc: 0.503846 | Val Loss: 0.269169, Val Acc: 0.474227\n",
      "Epoch 497 - Train Loss: 0.261160, Train Acc: 0.503846 | Val Loss: 0.269149, Val Acc: 0.474227\n",
      "Epoch 498 - Train Loss: 0.261140, Train Acc: 0.503846 | Val Loss: 0.269130, Val Acc: 0.474227\n",
      "Epoch 499 - Train Loss: 0.261119, Train Acc: 0.503846 | Val Loss: 0.269110, Val Acc: 0.474227\n",
      "Epoch 500 - Train Loss: 0.261099, Train Acc: 0.503846 | Val Loss: 0.269091, Val Acc: 0.474227\n",
      "Epoch 501 - Train Loss: 0.261078, Train Acc: 0.503846 | Val Loss: 0.269071, Val Acc: 0.474227\n",
      "Epoch 502 - Train Loss: 0.261057, Train Acc: 0.503846 | Val Loss: 0.269052, Val Acc: 0.474227\n",
      "Epoch 503 - Train Loss: 0.261036, Train Acc: 0.503846 | Val Loss: 0.269032, Val Acc: 0.474227\n",
      "Epoch 504 - Train Loss: 0.261016, Train Acc: 0.503846 | Val Loss: 0.269013, Val Acc: 0.474227\n",
      "Epoch 505 - Train Loss: 0.260995, Train Acc: 0.503846 | Val Loss: 0.268993, Val Acc: 0.474227\n",
      "Epoch 506 - Train Loss: 0.260975, Train Acc: 0.503846 | Val Loss: 0.268974, Val Acc: 0.474227\n",
      "Epoch 507 - Train Loss: 0.260954, Train Acc: 0.503846 | Val Loss: 0.268954, Val Acc: 0.474227\n",
      "Epoch 508 - Train Loss: 0.260933, Train Acc: 0.503846 | Val Loss: 0.268935, Val Acc: 0.474227\n",
      "Epoch 509 - Train Loss: 0.260912, Train Acc: 0.503846 | Val Loss: 0.268915, Val Acc: 0.474227\n",
      "Epoch 510 - Train Loss: 0.260892, Train Acc: 0.503846 | Val Loss: 0.268895, Val Acc: 0.474227\n",
      "Epoch 511 - Train Loss: 0.260871, Train Acc: 0.503846 | Val Loss: 0.268876, Val Acc: 0.474227\n",
      "Epoch 512 - Train Loss: 0.260850, Train Acc: 0.503846 | Val Loss: 0.268856, Val Acc: 0.474227\n",
      "Epoch 513 - Train Loss: 0.260830, Train Acc: 0.503846 | Val Loss: 0.268837, Val Acc: 0.474227\n",
      "Epoch 514 - Train Loss: 0.260809, Train Acc: 0.503846 | Val Loss: 0.268817, Val Acc: 0.474227\n",
      "Epoch 515 - Train Loss: 0.260788, Train Acc: 0.503846 | Val Loss: 0.268798, Val Acc: 0.474227\n",
      "Epoch 516 - Train Loss: 0.260768, Train Acc: 0.503846 | Val Loss: 0.268778, Val Acc: 0.474227\n",
      "Epoch 517 - Train Loss: 0.260747, Train Acc: 0.503846 | Val Loss: 0.268759, Val Acc: 0.474227\n",
      "Epoch 518 - Train Loss: 0.260726, Train Acc: 0.503846 | Val Loss: 0.268739, Val Acc: 0.474227\n",
      "Epoch 519 - Train Loss: 0.260706, Train Acc: 0.503846 | Val Loss: 0.268720, Val Acc: 0.474227\n",
      "Epoch 520 - Train Loss: 0.260685, Train Acc: 0.503846 | Val Loss: 0.268700, Val Acc: 0.474227\n",
      "Epoch 521 - Train Loss: 0.260665, Train Acc: 0.503846 | Val Loss: 0.268681, Val Acc: 0.474227\n",
      "Epoch 522 - Train Loss: 0.260644, Train Acc: 0.503846 | Val Loss: 0.268661, Val Acc: 0.474227\n",
      "Epoch 523 - Train Loss: 0.260623, Train Acc: 0.503846 | Val Loss: 0.268642, Val Acc: 0.474227\n",
      "Epoch 524 - Train Loss: 0.260603, Train Acc: 0.503846 | Val Loss: 0.268622, Val Acc: 0.474227\n",
      "Epoch 525 - Train Loss: 0.260582, Train Acc: 0.503846 | Val Loss: 0.268603, Val Acc: 0.474227\n",
      "Epoch 526 - Train Loss: 0.260561, Train Acc: 0.503846 | Val Loss: 0.268583, Val Acc: 0.474227\n",
      "Epoch 527 - Train Loss: 0.260541, Train Acc: 0.503846 | Val Loss: 0.268564, Val Acc: 0.474227\n",
      "Epoch 528 - Train Loss: 0.260520, Train Acc: 0.503846 | Val Loss: 0.268544, Val Acc: 0.474227\n",
      "Epoch 529 - Train Loss: 0.260499, Train Acc: 0.503846 | Val Loss: 0.268525, Val Acc: 0.474227\n",
      "Epoch 530 - Train Loss: 0.260479, Train Acc: 0.503846 | Val Loss: 0.268505, Val Acc: 0.474227\n",
      "Epoch 531 - Train Loss: 0.260458, Train Acc: 0.503846 | Val Loss: 0.268486, Val Acc: 0.474227\n",
      "Epoch 532 - Train Loss: 0.260437, Train Acc: 0.503846 | Val Loss: 0.268466, Val Acc: 0.474227\n",
      "Epoch 533 - Train Loss: 0.260417, Train Acc: 0.503846 | Val Loss: 0.268447, Val Acc: 0.474227\n",
      "Epoch 534 - Train Loss: 0.260396, Train Acc: 0.503846 | Val Loss: 0.268428, Val Acc: 0.474227\n",
      "Epoch 535 - Train Loss: 0.260375, Train Acc: 0.503846 | Val Loss: 0.268408, Val Acc: 0.474227\n",
      "Epoch 536 - Train Loss: 0.260355, Train Acc: 0.503846 | Val Loss: 0.268389, Val Acc: 0.474227\n",
      "Epoch 537 - Train Loss: 0.260334, Train Acc: 0.503846 | Val Loss: 0.268369, Val Acc: 0.474227\n",
      "Epoch 538 - Train Loss: 0.260314, Train Acc: 0.503846 | Val Loss: 0.268350, Val Acc: 0.474227\n",
      "Epoch 539 - Train Loss: 0.260293, Train Acc: 0.503846 | Val Loss: 0.268330, Val Acc: 0.474227\n",
      "Epoch 540 - Train Loss: 0.260272, Train Acc: 0.503846 | Val Loss: 0.268311, Val Acc: 0.474227\n",
      "Epoch 541 - Train Loss: 0.260252, Train Acc: 0.503846 | Val Loss: 0.268291, Val Acc: 0.474227\n",
      "Epoch 542 - Train Loss: 0.260231, Train Acc: 0.503846 | Val Loss: 0.268272, Val Acc: 0.474227\n",
      "Epoch 543 - Train Loss: 0.260210, Train Acc: 0.503846 | Val Loss: 0.268252, Val Acc: 0.474227\n",
      "Epoch 544 - Train Loss: 0.260190, Train Acc: 0.503846 | Val Loss: 0.268233, Val Acc: 0.474227\n",
      "Epoch 545 - Train Loss: 0.260169, Train Acc: 0.503846 | Val Loss: 0.268213, Val Acc: 0.474227\n",
      "Epoch 546 - Train Loss: 0.260148, Train Acc: 0.503846 | Val Loss: 0.268194, Val Acc: 0.474227\n",
      "Epoch 547 - Train Loss: 0.260128, Train Acc: 0.503846 | Val Loss: 0.268174, Val Acc: 0.474227\n",
      "Epoch 548 - Train Loss: 0.260107, Train Acc: 0.503846 | Val Loss: 0.268155, Val Acc: 0.474227\n",
      "Epoch 549 - Train Loss: 0.260086, Train Acc: 0.503846 | Val Loss: 0.268135, Val Acc: 0.474227\n",
      "Epoch 550 - Train Loss: 0.260066, Train Acc: 0.503846 | Val Loss: 0.268116, Val Acc: 0.474227\n",
      "Epoch 551 - Train Loss: 0.260045, Train Acc: 0.503846 | Val Loss: 0.268096, Val Acc: 0.474227\n",
      "Epoch 552 - Train Loss: 0.260025, Train Acc: 0.503846 | Val Loss: 0.268077, Val Acc: 0.474227\n",
      "Epoch 553 - Train Loss: 0.260004, Train Acc: 0.503846 | Val Loss: 0.268057, Val Acc: 0.474227\n",
      "Epoch 554 - Train Loss: 0.259983, Train Acc: 0.503846 | Val Loss: 0.268038, Val Acc: 0.474227\n",
      "Epoch 555 - Train Loss: 0.259963, Train Acc: 0.503846 | Val Loss: 0.268018, Val Acc: 0.474227\n",
      "Epoch 556 - Train Loss: 0.259942, Train Acc: 0.503846 | Val Loss: 0.267999, Val Acc: 0.474227\n",
      "Epoch 557 - Train Loss: 0.259921, Train Acc: 0.503846 | Val Loss: 0.267979, Val Acc: 0.474227\n",
      "Epoch 558 - Train Loss: 0.259901, Train Acc: 0.503846 | Val Loss: 0.267960, Val Acc: 0.474227\n",
      "Epoch 559 - Train Loss: 0.259880, Train Acc: 0.503846 | Val Loss: 0.267940, Val Acc: 0.474227\n",
      "Epoch 560 - Train Loss: 0.259860, Train Acc: 0.503846 | Val Loss: 0.267921, Val Acc: 0.474227\n",
      "Epoch 561 - Train Loss: 0.259839, Train Acc: 0.503846 | Val Loss: 0.267901, Val Acc: 0.474227\n",
      "Epoch 562 - Train Loss: 0.259818, Train Acc: 0.503846 | Val Loss: 0.267882, Val Acc: 0.474227\n",
      "Epoch 563 - Train Loss: 0.259798, Train Acc: 0.503846 | Val Loss: 0.267862, Val Acc: 0.474227\n",
      "Epoch 564 - Train Loss: 0.259777, Train Acc: 0.503846 | Val Loss: 0.267843, Val Acc: 0.474227\n",
      "Epoch 565 - Train Loss: 0.259756, Train Acc: 0.503846 | Val Loss: 0.267823, Val Acc: 0.474227\n",
      "Epoch 566 - Train Loss: 0.259736, Train Acc: 0.503846 | Val Loss: 0.267804, Val Acc: 0.474227\n",
      "Epoch 567 - Train Loss: 0.259715, Train Acc: 0.503846 | Val Loss: 0.267784, Val Acc: 0.474227\n",
      "Epoch 568 - Train Loss: 0.259694, Train Acc: 0.503846 | Val Loss: 0.267765, Val Acc: 0.474227\n",
      "Epoch 569 - Train Loss: 0.259674, Train Acc: 0.503846 | Val Loss: 0.267745, Val Acc: 0.474227\n",
      "Epoch 570 - Train Loss: 0.259653, Train Acc: 0.503846 | Val Loss: 0.267726, Val Acc: 0.474227\n",
      "Epoch 571 - Train Loss: 0.259632, Train Acc: 0.503846 | Val Loss: 0.267706, Val Acc: 0.474227\n",
      "Epoch 572 - Train Loss: 0.259612, Train Acc: 0.503846 | Val Loss: 0.267687, Val Acc: 0.474227\n",
      "Epoch 573 - Train Loss: 0.259591, Train Acc: 0.503846 | Val Loss: 0.267667, Val Acc: 0.474227\n",
      "Epoch 574 - Train Loss: 0.259571, Train Acc: 0.503846 | Val Loss: 0.267648, Val Acc: 0.474227\n",
      "Epoch 575 - Train Loss: 0.259550, Train Acc: 0.503846 | Val Loss: 0.267629, Val Acc: 0.474227\n",
      "Epoch 576 - Train Loss: 0.259529, Train Acc: 0.503846 | Val Loss: 0.267609, Val Acc: 0.474227\n",
      "Epoch 577 - Train Loss: 0.259509, Train Acc: 0.503846 | Val Loss: 0.267590, Val Acc: 0.474227\n",
      "Epoch 578 - Train Loss: 0.259488, Train Acc: 0.503846 | Val Loss: 0.267570, Val Acc: 0.474227\n",
      "Epoch 579 - Train Loss: 0.259468, Train Acc: 0.503846 | Val Loss: 0.267551, Val Acc: 0.474227\n",
      "Epoch 580 - Train Loss: 0.259447, Train Acc: 0.503846 | Val Loss: 0.267531, Val Acc: 0.474227\n",
      "Epoch 581 - Train Loss: 0.259427, Train Acc: 0.503846 | Val Loss: 0.267512, Val Acc: 0.474227\n",
      "Epoch 582 - Train Loss: 0.259406, Train Acc: 0.503846 | Val Loss: 0.267492, Val Acc: 0.474227\n",
      "Epoch 583 - Train Loss: 0.259386, Train Acc: 0.503846 | Val Loss: 0.267473, Val Acc: 0.474227\n",
      "Epoch 584 - Train Loss: 0.259365, Train Acc: 0.503846 | Val Loss: 0.267453, Val Acc: 0.474227\n",
      "Epoch 585 - Train Loss: 0.259344, Train Acc: 0.503846 | Val Loss: 0.267434, Val Acc: 0.474227\n",
      "Epoch 586 - Train Loss: 0.259324, Train Acc: 0.503846 | Val Loss: 0.267415, Val Acc: 0.474227\n",
      "Epoch 587 - Train Loss: 0.259303, Train Acc: 0.503846 | Val Loss: 0.267395, Val Acc: 0.474227\n",
      "Epoch 588 - Train Loss: 0.259283, Train Acc: 0.503846 | Val Loss: 0.267376, Val Acc: 0.474227\n",
      "Epoch 589 - Train Loss: 0.259262, Train Acc: 0.503846 | Val Loss: 0.267356, Val Acc: 0.474227\n",
      "Epoch 590 - Train Loss: 0.259242, Train Acc: 0.503846 | Val Loss: 0.267337, Val Acc: 0.474227\n",
      "Epoch 591 - Train Loss: 0.259221, Train Acc: 0.503846 | Val Loss: 0.267317, Val Acc: 0.474227\n",
      "Epoch 592 - Train Loss: 0.259201, Train Acc: 0.503846 | Val Loss: 0.267298, Val Acc: 0.474227\n",
      "Epoch 593 - Train Loss: 0.259180, Train Acc: 0.503846 | Val Loss: 0.267278, Val Acc: 0.474227\n",
      "Epoch 594 - Train Loss: 0.259160, Train Acc: 0.503846 | Val Loss: 0.267259, Val Acc: 0.474227\n",
      "Epoch 595 - Train Loss: 0.259139, Train Acc: 0.503846 | Val Loss: 0.267240, Val Acc: 0.474227\n",
      "Epoch 596 - Train Loss: 0.259119, Train Acc: 0.503846 | Val Loss: 0.267220, Val Acc: 0.474227\n",
      "Epoch 597 - Train Loss: 0.259098, Train Acc: 0.503846 | Val Loss: 0.267201, Val Acc: 0.474227\n",
      "Epoch 598 - Train Loss: 0.259078, Train Acc: 0.503846 | Val Loss: 0.267181, Val Acc: 0.474227\n",
      "Epoch 599 - Train Loss: 0.259057, Train Acc: 0.503846 | Val Loss: 0.267162, Val Acc: 0.474227\n",
      "Epoch 600 - Train Loss: 0.259037, Train Acc: 0.503846 | Val Loss: 0.267143, Val Acc: 0.474227\n",
      "Epoch 601 - Train Loss: 0.259016, Train Acc: 0.503846 | Val Loss: 0.267123, Val Acc: 0.474227\n",
      "Epoch 602 - Train Loss: 0.258996, Train Acc: 0.503846 | Val Loss: 0.267104, Val Acc: 0.474227\n",
      "Epoch 603 - Train Loss: 0.258975, Train Acc: 0.503846 | Val Loss: 0.267085, Val Acc: 0.474227\n",
      "Epoch 604 - Train Loss: 0.258955, Train Acc: 0.503846 | Val Loss: 0.267066, Val Acc: 0.474227\n",
      "Epoch 605 - Train Loss: 0.258934, Train Acc: 0.503846 | Val Loss: 0.267046, Val Acc: 0.474227\n",
      "Epoch 606 - Train Loss: 0.258914, Train Acc: 0.503846 | Val Loss: 0.267027, Val Acc: 0.474227\n",
      "Epoch 607 - Train Loss: 0.258893, Train Acc: 0.503846 | Val Loss: 0.267008, Val Acc: 0.474227\n",
      "Epoch 608 - Train Loss: 0.258873, Train Acc: 0.503846 | Val Loss: 0.266988, Val Acc: 0.474227\n",
      "Epoch 609 - Train Loss: 0.258852, Train Acc: 0.503846 | Val Loss: 0.266969, Val Acc: 0.474227\n",
      "Epoch 610 - Train Loss: 0.258831, Train Acc: 0.503846 | Val Loss: 0.266950, Val Acc: 0.474227\n",
      "Epoch 611 - Train Loss: 0.258811, Train Acc: 0.503846 | Val Loss: 0.266930, Val Acc: 0.474227\n",
      "Epoch 612 - Train Loss: 0.258790, Train Acc: 0.503846 | Val Loss: 0.266911, Val Acc: 0.474227\n",
      "Epoch 613 - Train Loss: 0.258770, Train Acc: 0.503846 | Val Loss: 0.266892, Val Acc: 0.474227\n",
      "Epoch 614 - Train Loss: 0.258749, Train Acc: 0.503846 | Val Loss: 0.266872, Val Acc: 0.474227\n",
      "Epoch 615 - Train Loss: 0.258729, Train Acc: 0.503846 | Val Loss: 0.266853, Val Acc: 0.474227\n",
      "Epoch 616 - Train Loss: 0.258708, Train Acc: 0.503846 | Val Loss: 0.266834, Val Acc: 0.474227\n",
      "Epoch 617 - Train Loss: 0.258688, Train Acc: 0.503846 | Val Loss: 0.266814, Val Acc: 0.474227\n",
      "Epoch 618 - Train Loss: 0.258667, Train Acc: 0.503846 | Val Loss: 0.266795, Val Acc: 0.474227\n",
      "Epoch 619 - Train Loss: 0.258647, Train Acc: 0.503846 | Val Loss: 0.266776, Val Acc: 0.474227\n",
      "Epoch 620 - Train Loss: 0.258626, Train Acc: 0.503846 | Val Loss: 0.266757, Val Acc: 0.474227\n",
      "Epoch 621 - Train Loss: 0.258606, Train Acc: 0.503846 | Val Loss: 0.266737, Val Acc: 0.474227\n",
      "Epoch 622 - Train Loss: 0.258585, Train Acc: 0.503846 | Val Loss: 0.266718, Val Acc: 0.474227\n",
      "Epoch 623 - Train Loss: 0.258565, Train Acc: 0.503846 | Val Loss: 0.266699, Val Acc: 0.474227\n",
      "Epoch 624 - Train Loss: 0.258544, Train Acc: 0.503846 | Val Loss: 0.266680, Val Acc: 0.474227\n",
      "Epoch 625 - Train Loss: 0.258524, Train Acc: 0.503846 | Val Loss: 0.266660, Val Acc: 0.474227\n",
      "Epoch 626 - Train Loss: 0.258503, Train Acc: 0.503846 | Val Loss: 0.266641, Val Acc: 0.474227\n",
      "Epoch 627 - Train Loss: 0.258483, Train Acc: 0.503846 | Val Loss: 0.266622, Val Acc: 0.474227\n",
      "Epoch 628 - Train Loss: 0.258462, Train Acc: 0.503846 | Val Loss: 0.266603, Val Acc: 0.474227\n",
      "Epoch 629 - Train Loss: 0.258442, Train Acc: 0.503846 | Val Loss: 0.266583, Val Acc: 0.474227\n",
      "Epoch 630 - Train Loss: 0.258421, Train Acc: 0.503846 | Val Loss: 0.266564, Val Acc: 0.474227\n",
      "Epoch 631 - Train Loss: 0.258401, Train Acc: 0.503846 | Val Loss: 0.266545, Val Acc: 0.474227\n",
      "Epoch 632 - Train Loss: 0.258380, Train Acc: 0.503846 | Val Loss: 0.266526, Val Acc: 0.474227\n",
      "Epoch 633 - Train Loss: 0.258360, Train Acc: 0.503846 | Val Loss: 0.266507, Val Acc: 0.474227\n",
      "Epoch 634 - Train Loss: 0.258339, Train Acc: 0.503846 | Val Loss: 0.266487, Val Acc: 0.474227\n",
      "Epoch 635 - Train Loss: 0.258319, Train Acc: 0.503846 | Val Loss: 0.266468, Val Acc: 0.474227\n",
      "Epoch 636 - Train Loss: 0.258298, Train Acc: 0.503846 | Val Loss: 0.266449, Val Acc: 0.474227\n",
      "Epoch 637 - Train Loss: 0.258278, Train Acc: 0.503846 | Val Loss: 0.266430, Val Acc: 0.474227\n",
      "Epoch 638 - Train Loss: 0.258257, Train Acc: 0.503846 | Val Loss: 0.266411, Val Acc: 0.474227\n",
      "Epoch 639 - Train Loss: 0.258237, Train Acc: 0.503846 | Val Loss: 0.266391, Val Acc: 0.474227\n",
      "Epoch 640 - Train Loss: 0.258216, Train Acc: 0.503846 | Val Loss: 0.266372, Val Acc: 0.474227\n",
      "Epoch 641 - Train Loss: 0.258196, Train Acc: 0.503846 | Val Loss: 0.266353, Val Acc: 0.474227\n",
      "Epoch 642 - Train Loss: 0.258175, Train Acc: 0.503846 | Val Loss: 0.266334, Val Acc: 0.474227\n",
      "Epoch 643 - Train Loss: 0.258155, Train Acc: 0.503846 | Val Loss: 0.266314, Val Acc: 0.474227\n",
      "Epoch 644 - Train Loss: 0.258134, Train Acc: 0.503846 | Val Loss: 0.266295, Val Acc: 0.474227\n",
      "Epoch 645 - Train Loss: 0.258114, Train Acc: 0.503846 | Val Loss: 0.266276, Val Acc: 0.474227\n",
      "Epoch 646 - Train Loss: 0.258093, Train Acc: 0.503846 | Val Loss: 0.266257, Val Acc: 0.474227\n",
      "Epoch 647 - Train Loss: 0.258073, Train Acc: 0.503846 | Val Loss: 0.266238, Val Acc: 0.474227\n",
      "Epoch 648 - Train Loss: 0.258052, Train Acc: 0.503846 | Val Loss: 0.266218, Val Acc: 0.474227\n",
      "Epoch 649 - Train Loss: 0.258032, Train Acc: 0.503846 | Val Loss: 0.266199, Val Acc: 0.474227\n",
      "Epoch 650 - Train Loss: 0.258012, Train Acc: 0.503846 | Val Loss: 0.266180, Val Acc: 0.474227\n",
      "Epoch 651 - Train Loss: 0.257991, Train Acc: 0.503846 | Val Loss: 0.266161, Val Acc: 0.474227\n",
      "Epoch 652 - Train Loss: 0.257971, Train Acc: 0.503846 | Val Loss: 0.266142, Val Acc: 0.474227\n",
      "Epoch 653 - Train Loss: 0.257950, Train Acc: 0.503846 | Val Loss: 0.266122, Val Acc: 0.474227\n",
      "Epoch 654 - Train Loss: 0.257930, Train Acc: 0.503846 | Val Loss: 0.266103, Val Acc: 0.474227\n",
      "Epoch 655 - Train Loss: 0.257909, Train Acc: 0.503846 | Val Loss: 0.266084, Val Acc: 0.474227\n",
      "Epoch 656 - Train Loss: 0.257889, Train Acc: 0.503846 | Val Loss: 0.266065, Val Acc: 0.474227\n",
      "Epoch 657 - Train Loss: 0.257868, Train Acc: 0.503846 | Val Loss: 0.266045, Val Acc: 0.474227\n",
      "Epoch 658 - Train Loss: 0.257848, Train Acc: 0.503846 | Val Loss: 0.266026, Val Acc: 0.474227\n",
      "Epoch 659 - Train Loss: 0.257827, Train Acc: 0.503846 | Val Loss: 0.266007, Val Acc: 0.474227\n",
      "Epoch 660 - Train Loss: 0.257807, Train Acc: 0.503846 | Val Loss: 0.265988, Val Acc: 0.474227\n",
      "Epoch 661 - Train Loss: 0.257787, Train Acc: 0.503846 | Val Loss: 0.265968, Val Acc: 0.474227\n",
      "Epoch 662 - Train Loss: 0.257766, Train Acc: 0.503846 | Val Loss: 0.265949, Val Acc: 0.474227\n",
      "Epoch 663 - Train Loss: 0.257746, Train Acc: 0.503846 | Val Loss: 0.265930, Val Acc: 0.474227\n",
      "Epoch 664 - Train Loss: 0.257725, Train Acc: 0.503846 | Val Loss: 0.265911, Val Acc: 0.474227\n",
      "Epoch 665 - Train Loss: 0.257705, Train Acc: 0.503846 | Val Loss: 0.265891, Val Acc: 0.474227\n",
      "Epoch 666 - Train Loss: 0.257684, Train Acc: 0.503846 | Val Loss: 0.265872, Val Acc: 0.474227\n",
      "Epoch 667 - Train Loss: 0.257664, Train Acc: 0.503846 | Val Loss: 0.265853, Val Acc: 0.474227\n",
      "Epoch 668 - Train Loss: 0.257643, Train Acc: 0.503846 | Val Loss: 0.265834, Val Acc: 0.474227\n",
      "Epoch 669 - Train Loss: 0.257623, Train Acc: 0.503846 | Val Loss: 0.265814, Val Acc: 0.474227\n",
      "Epoch 670 - Train Loss: 0.257602, Train Acc: 0.503846 | Val Loss: 0.265795, Val Acc: 0.474227\n",
      "Epoch 671 - Train Loss: 0.257582, Train Acc: 0.503846 | Val Loss: 0.265776, Val Acc: 0.474227\n",
      "Epoch 672 - Train Loss: 0.257562, Train Acc: 0.503846 | Val Loss: 0.265756, Val Acc: 0.474227\n",
      "Epoch 673 - Train Loss: 0.257541, Train Acc: 0.503846 | Val Loss: 0.265737, Val Acc: 0.474227\n",
      "Epoch 674 - Train Loss: 0.257521, Train Acc: 0.503846 | Val Loss: 0.265718, Val Acc: 0.474227\n",
      "Epoch 675 - Train Loss: 0.257500, Train Acc: 0.503846 | Val Loss: 0.265698, Val Acc: 0.474227\n",
      "Epoch 676 - Train Loss: 0.257480, Train Acc: 0.503846 | Val Loss: 0.265679, Val Acc: 0.474227\n",
      "Epoch 677 - Train Loss: 0.257459, Train Acc: 0.503846 | Val Loss: 0.265660, Val Acc: 0.474227\n",
      "Epoch 678 - Train Loss: 0.257439, Train Acc: 0.503846 | Val Loss: 0.265640, Val Acc: 0.474227\n",
      "Epoch 679 - Train Loss: 0.257418, Train Acc: 0.503846 | Val Loss: 0.265621, Val Acc: 0.474227\n",
      "Epoch 680 - Train Loss: 0.257398, Train Acc: 0.503846 | Val Loss: 0.265602, Val Acc: 0.474227\n",
      "Epoch 681 - Train Loss: 0.257378, Train Acc: 0.503846 | Val Loss: 0.265582, Val Acc: 0.474227\n",
      "Epoch 682 - Train Loss: 0.257357, Train Acc: 0.503846 | Val Loss: 0.265563, Val Acc: 0.474227\n",
      "Epoch 683 - Train Loss: 0.257337, Train Acc: 0.503846 | Val Loss: 0.265544, Val Acc: 0.474227\n",
      "Epoch 684 - Train Loss: 0.257316, Train Acc: 0.503846 | Val Loss: 0.265525, Val Acc: 0.474227\n",
      "Epoch 685 - Train Loss: 0.257296, Train Acc: 0.503846 | Val Loss: 0.265505, Val Acc: 0.474227\n",
      "Epoch 686 - Train Loss: 0.257275, Train Acc: 0.503846 | Val Loss: 0.265486, Val Acc: 0.474227\n",
      "Epoch 687 - Train Loss: 0.257255, Train Acc: 0.503846 | Val Loss: 0.265467, Val Acc: 0.474227\n",
      "Epoch 688 - Train Loss: 0.257235, Train Acc: 0.503846 | Val Loss: 0.265447, Val Acc: 0.474227\n",
      "Epoch 689 - Train Loss: 0.257214, Train Acc: 0.503846 | Val Loss: 0.265428, Val Acc: 0.474227\n",
      "Epoch 690 - Train Loss: 0.257194, Train Acc: 0.503846 | Val Loss: 0.265408, Val Acc: 0.474227\n",
      "Epoch 691 - Train Loss: 0.257173, Train Acc: 0.503846 | Val Loss: 0.265389, Val Acc: 0.474227\n",
      "Epoch 692 - Train Loss: 0.257153, Train Acc: 0.503846 | Val Loss: 0.265370, Val Acc: 0.474227\n",
      "Epoch 693 - Train Loss: 0.257132, Train Acc: 0.503846 | Val Loss: 0.265350, Val Acc: 0.474227\n",
      "Epoch 694 - Train Loss: 0.257112, Train Acc: 0.503846 | Val Loss: 0.265331, Val Acc: 0.474227\n",
      "Epoch 695 - Train Loss: 0.257092, Train Acc: 0.503846 | Val Loss: 0.265311, Val Acc: 0.474227\n",
      "Epoch 696 - Train Loss: 0.257071, Train Acc: 0.503846 | Val Loss: 0.265292, Val Acc: 0.474227\n",
      "Epoch 697 - Train Loss: 0.257051, Train Acc: 0.503846 | Val Loss: 0.265273, Val Acc: 0.474227\n",
      "Epoch 698 - Train Loss: 0.257030, Train Acc: 0.503846 | Val Loss: 0.265253, Val Acc: 0.474227\n",
      "Epoch 699 - Train Loss: 0.257010, Train Acc: 0.503846 | Val Loss: 0.265234, Val Acc: 0.474227\n",
      "Epoch 700 - Train Loss: 0.256990, Train Acc: 0.503846 | Val Loss: 0.265214, Val Acc: 0.474227\n",
      "Epoch 701 - Train Loss: 0.256969, Train Acc: 0.503846 | Val Loss: 0.265195, Val Acc: 0.474227\n",
      "Epoch 702 - Train Loss: 0.256949, Train Acc: 0.503846 | Val Loss: 0.265176, Val Acc: 0.474227\n",
      "Epoch 703 - Train Loss: 0.256928, Train Acc: 0.503846 | Val Loss: 0.265156, Val Acc: 0.474227\n",
      "Epoch 704 - Train Loss: 0.256908, Train Acc: 0.503846 | Val Loss: 0.265137, Val Acc: 0.474227\n",
      "Epoch 705 - Train Loss: 0.256888, Train Acc: 0.503846 | Val Loss: 0.265117, Val Acc: 0.474227\n",
      "Epoch 706 - Train Loss: 0.256867, Train Acc: 0.503846 | Val Loss: 0.265098, Val Acc: 0.474227\n",
      "Epoch 707 - Train Loss: 0.256847, Train Acc: 0.503846 | Val Loss: 0.265079, Val Acc: 0.474227\n",
      "Epoch 708 - Train Loss: 0.256826, Train Acc: 0.503846 | Val Loss: 0.265059, Val Acc: 0.474227\n",
      "Epoch 709 - Train Loss: 0.256806, Train Acc: 0.503846 | Val Loss: 0.265040, Val Acc: 0.474227\n",
      "Epoch 710 - Train Loss: 0.256786, Train Acc: 0.503846 | Val Loss: 0.265020, Val Acc: 0.474227\n",
      "Epoch 711 - Train Loss: 0.256765, Train Acc: 0.503846 | Val Loss: 0.265001, Val Acc: 0.474227\n",
      "Epoch 712 - Train Loss: 0.256745, Train Acc: 0.503846 | Val Loss: 0.264982, Val Acc: 0.474227\n",
      "Epoch 713 - Train Loss: 0.256724, Train Acc: 0.503846 | Val Loss: 0.264962, Val Acc: 0.474227\n",
      "Epoch 714 - Train Loss: 0.256704, Train Acc: 0.503846 | Val Loss: 0.264943, Val Acc: 0.474227\n",
      "Epoch 715 - Train Loss: 0.256684, Train Acc: 0.503846 | Val Loss: 0.264923, Val Acc: 0.474227\n",
      "Epoch 716 - Train Loss: 0.256663, Train Acc: 0.503846 | Val Loss: 0.264904, Val Acc: 0.474227\n",
      "Epoch 717 - Train Loss: 0.256643, Train Acc: 0.503846 | Val Loss: 0.264885, Val Acc: 0.474227\n",
      "Epoch 718 - Train Loss: 0.256622, Train Acc: 0.503846 | Val Loss: 0.264865, Val Acc: 0.474227\n",
      "Epoch 719 - Train Loss: 0.256602, Train Acc: 0.503846 | Val Loss: 0.264846, Val Acc: 0.474227\n",
      "Epoch 720 - Train Loss: 0.256582, Train Acc: 0.503846 | Val Loss: 0.264826, Val Acc: 0.474227\n",
      "Epoch 721 - Train Loss: 0.256561, Train Acc: 0.503846 | Val Loss: 0.264807, Val Acc: 0.474227\n",
      "Epoch 722 - Train Loss: 0.256541, Train Acc: 0.503846 | Val Loss: 0.264788, Val Acc: 0.474227\n",
      "Epoch 723 - Train Loss: 0.256520, Train Acc: 0.503846 | Val Loss: 0.264768, Val Acc: 0.474227\n",
      "Epoch 724 - Train Loss: 0.256500, Train Acc: 0.503846 | Val Loss: 0.264749, Val Acc: 0.474227\n",
      "Epoch 725 - Train Loss: 0.256480, Train Acc: 0.503846 | Val Loss: 0.264730, Val Acc: 0.474227\n",
      "Epoch 726 - Train Loss: 0.256459, Train Acc: 0.503846 | Val Loss: 0.264710, Val Acc: 0.474227\n",
      "Epoch 727 - Train Loss: 0.256439, Train Acc: 0.503846 | Val Loss: 0.264691, Val Acc: 0.474227\n",
      "Epoch 728 - Train Loss: 0.256418, Train Acc: 0.503846 | Val Loss: 0.264671, Val Acc: 0.474227\n",
      "Epoch 729 - Train Loss: 0.256398, Train Acc: 0.503846 | Val Loss: 0.264652, Val Acc: 0.474227\n",
      "Epoch 730 - Train Loss: 0.256378, Train Acc: 0.503846 | Val Loss: 0.264633, Val Acc: 0.474227\n",
      "Epoch 731 - Train Loss: 0.256357, Train Acc: 0.503846 | Val Loss: 0.264613, Val Acc: 0.474227\n",
      "Epoch 732 - Train Loss: 0.256337, Train Acc: 0.503846 | Val Loss: 0.264594, Val Acc: 0.474227\n",
      "Epoch 733 - Train Loss: 0.256316, Train Acc: 0.503846 | Val Loss: 0.264575, Val Acc: 0.474227\n",
      "Epoch 734 - Train Loss: 0.256296, Train Acc: 0.503846 | Val Loss: 0.264555, Val Acc: 0.474227\n",
      "Epoch 735 - Train Loss: 0.256276, Train Acc: 0.503846 | Val Loss: 0.264536, Val Acc: 0.474227\n",
      "Epoch 736 - Train Loss: 0.256255, Train Acc: 0.503846 | Val Loss: 0.264517, Val Acc: 0.474227\n",
      "Epoch 737 - Train Loss: 0.256235, Train Acc: 0.503846 | Val Loss: 0.264497, Val Acc: 0.474227\n",
      "Epoch 738 - Train Loss: 0.256214, Train Acc: 0.503846 | Val Loss: 0.264478, Val Acc: 0.474227\n",
      "Epoch 739 - Train Loss: 0.256194, Train Acc: 0.503846 | Val Loss: 0.264459, Val Acc: 0.474227\n",
      "Epoch 740 - Train Loss: 0.256174, Train Acc: 0.503846 | Val Loss: 0.264439, Val Acc: 0.474227\n",
      "Epoch 741 - Train Loss: 0.256153, Train Acc: 0.503846 | Val Loss: 0.264420, Val Acc: 0.474227\n",
      "Epoch 742 - Train Loss: 0.256133, Train Acc: 0.503846 | Val Loss: 0.264400, Val Acc: 0.474227\n",
      "Epoch 743 - Train Loss: 0.256112, Train Acc: 0.503846 | Val Loss: 0.264381, Val Acc: 0.474227\n",
      "Epoch 744 - Train Loss: 0.256092, Train Acc: 0.503846 | Val Loss: 0.264362, Val Acc: 0.474227\n",
      "Epoch 745 - Train Loss: 0.256072, Train Acc: 0.503846 | Val Loss: 0.264342, Val Acc: 0.474227\n",
      "Epoch 746 - Train Loss: 0.256051, Train Acc: 0.503846 | Val Loss: 0.264323, Val Acc: 0.474227\n",
      "Epoch 747 - Train Loss: 0.256031, Train Acc: 0.503846 | Val Loss: 0.264303, Val Acc: 0.474227\n",
      "Epoch 748 - Train Loss: 0.256010, Train Acc: 0.503846 | Val Loss: 0.264284, Val Acc: 0.474227\n",
      "Epoch 749 - Train Loss: 0.255990, Train Acc: 0.503846 | Val Loss: 0.264265, Val Acc: 0.474227\n",
      "Epoch 750 - Train Loss: 0.255970, Train Acc: 0.503846 | Val Loss: 0.264245, Val Acc: 0.474227\n",
      "Epoch 751 - Train Loss: 0.255949, Train Acc: 0.503846 | Val Loss: 0.264226, Val Acc: 0.474227\n",
      "Epoch 752 - Train Loss: 0.255929, Train Acc: 0.503846 | Val Loss: 0.264206, Val Acc: 0.474227\n",
      "Epoch 753 - Train Loss: 0.255908, Train Acc: 0.503846 | Val Loss: 0.264187, Val Acc: 0.474227\n",
      "Epoch 754 - Train Loss: 0.255888, Train Acc: 0.503846 | Val Loss: 0.264168, Val Acc: 0.474227\n",
      "Epoch 755 - Train Loss: 0.255867, Train Acc: 0.503846 | Val Loss: 0.264148, Val Acc: 0.474227\n",
      "Epoch 756 - Train Loss: 0.255847, Train Acc: 0.503846 | Val Loss: 0.264129, Val Acc: 0.474227\n",
      "Epoch 757 - Train Loss: 0.255827, Train Acc: 0.503846 | Val Loss: 0.264109, Val Acc: 0.474227\n",
      "Epoch 758 - Train Loss: 0.255806, Train Acc: 0.503846 | Val Loss: 0.264090, Val Acc: 0.474227\n",
      "Epoch 759 - Train Loss: 0.255786, Train Acc: 0.503846 | Val Loss: 0.264070, Val Acc: 0.474227\n",
      "Epoch 760 - Train Loss: 0.255765, Train Acc: 0.503846 | Val Loss: 0.264051, Val Acc: 0.474227\n",
      "Epoch 761 - Train Loss: 0.255745, Train Acc: 0.503846 | Val Loss: 0.264032, Val Acc: 0.474227\n",
      "Epoch 762 - Train Loss: 0.255724, Train Acc: 0.503846 | Val Loss: 0.264012, Val Acc: 0.474227\n",
      "Epoch 763 - Train Loss: 0.255704, Train Acc: 0.503846 | Val Loss: 0.263993, Val Acc: 0.474227\n",
      "Epoch 764 - Train Loss: 0.255684, Train Acc: 0.503846 | Val Loss: 0.263973, Val Acc: 0.474227\n",
      "Epoch 765 - Train Loss: 0.255663, Train Acc: 0.503846 | Val Loss: 0.263954, Val Acc: 0.474227\n",
      "Epoch 766 - Train Loss: 0.255643, Train Acc: 0.503846 | Val Loss: 0.263934, Val Acc: 0.474227\n",
      "Epoch 767 - Train Loss: 0.255622, Train Acc: 0.503846 | Val Loss: 0.263915, Val Acc: 0.474227\n",
      "Epoch 768 - Train Loss: 0.255602, Train Acc: 0.503846 | Val Loss: 0.263895, Val Acc: 0.474227\n",
      "Epoch 769 - Train Loss: 0.255582, Train Acc: 0.503846 | Val Loss: 0.263876, Val Acc: 0.474227\n",
      "Epoch 770 - Train Loss: 0.255561, Train Acc: 0.503846 | Val Loss: 0.263857, Val Acc: 0.474227\n",
      "Epoch 771 - Train Loss: 0.255541, Train Acc: 0.503846 | Val Loss: 0.263837, Val Acc: 0.474227\n",
      "Epoch 772 - Train Loss: 0.255520, Train Acc: 0.503846 | Val Loss: 0.263818, Val Acc: 0.474227\n",
      "Epoch 773 - Train Loss: 0.255500, Train Acc: 0.503846 | Val Loss: 0.263798, Val Acc: 0.474227\n",
      "Epoch 774 - Train Loss: 0.255479, Train Acc: 0.503846 | Val Loss: 0.263779, Val Acc: 0.474227\n",
      "Epoch 775 - Train Loss: 0.255459, Train Acc: 0.503846 | Val Loss: 0.263759, Val Acc: 0.474227\n",
      "Epoch 776 - Train Loss: 0.255439, Train Acc: 0.503846 | Val Loss: 0.263740, Val Acc: 0.474227\n",
      "Epoch 777 - Train Loss: 0.255418, Train Acc: 0.503846 | Val Loss: 0.263720, Val Acc: 0.474227\n",
      "Epoch 778 - Train Loss: 0.255398, Train Acc: 0.503846 | Val Loss: 0.263701, Val Acc: 0.474227\n",
      "Epoch 779 - Train Loss: 0.255377, Train Acc: 0.503846 | Val Loss: 0.263681, Val Acc: 0.474227\n",
      "Epoch 780 - Train Loss: 0.255357, Train Acc: 0.503846 | Val Loss: 0.263662, Val Acc: 0.474227\n",
      "Epoch 781 - Train Loss: 0.255336, Train Acc: 0.503846 | Val Loss: 0.263643, Val Acc: 0.474227\n",
      "Epoch 782 - Train Loss: 0.255316, Train Acc: 0.503846 | Val Loss: 0.263623, Val Acc: 0.474227\n",
      "Epoch 783 - Train Loss: 0.255295, Train Acc: 0.503846 | Val Loss: 0.263604, Val Acc: 0.474227\n",
      "Epoch 784 - Train Loss: 0.255275, Train Acc: 0.503846 | Val Loss: 0.263584, Val Acc: 0.474227\n",
      "Epoch 785 - Train Loss: 0.255255, Train Acc: 0.503846 | Val Loss: 0.263565, Val Acc: 0.474227\n",
      "Epoch 786 - Train Loss: 0.255234, Train Acc: 0.503846 | Val Loss: 0.263545, Val Acc: 0.474227\n",
      "Epoch 787 - Train Loss: 0.255214, Train Acc: 0.503846 | Val Loss: 0.263526, Val Acc: 0.474227\n",
      "Epoch 788 - Train Loss: 0.255193, Train Acc: 0.503846 | Val Loss: 0.263506, Val Acc: 0.474227\n",
      "Epoch 789 - Train Loss: 0.255173, Train Acc: 0.503846 | Val Loss: 0.263487, Val Acc: 0.474227\n",
      "Epoch 790 - Train Loss: 0.255152, Train Acc: 0.503846 | Val Loss: 0.263467, Val Acc: 0.474227\n",
      "Epoch 791 - Train Loss: 0.255132, Train Acc: 0.503846 | Val Loss: 0.263448, Val Acc: 0.474227\n",
      "Epoch 792 - Train Loss: 0.255111, Train Acc: 0.503846 | Val Loss: 0.263428, Val Acc: 0.474227\n",
      "Epoch 793 - Train Loss: 0.255091, Train Acc: 0.503846 | Val Loss: 0.263409, Val Acc: 0.474227\n",
      "Epoch 794 - Train Loss: 0.255071, Train Acc: 0.503846 | Val Loss: 0.263389, Val Acc: 0.474227\n",
      "Epoch 795 - Train Loss: 0.255050, Train Acc: 0.503846 | Val Loss: 0.263370, Val Acc: 0.474227\n",
      "Epoch 796 - Train Loss: 0.255030, Train Acc: 0.503846 | Val Loss: 0.263350, Val Acc: 0.474227\n",
      "Epoch 797 - Train Loss: 0.255009, Train Acc: 0.503846 | Val Loss: 0.263331, Val Acc: 0.474227\n",
      "Epoch 798 - Train Loss: 0.254989, Train Acc: 0.503846 | Val Loss: 0.263311, Val Acc: 0.474227\n",
      "Epoch 799 - Train Loss: 0.254968, Train Acc: 0.503846 | Val Loss: 0.263292, Val Acc: 0.474227\n",
      "Epoch 800 - Train Loss: 0.254948, Train Acc: 0.503846 | Val Loss: 0.263272, Val Acc: 0.474227\n",
      "Epoch 801 - Train Loss: 0.254927, Train Acc: 0.503846 | Val Loss: 0.263253, Val Acc: 0.474227\n",
      "Epoch 802 - Train Loss: 0.254907, Train Acc: 0.503846 | Val Loss: 0.263233, Val Acc: 0.474227\n",
      "Epoch 803 - Train Loss: 0.254886, Train Acc: 0.503846 | Val Loss: 0.263214, Val Acc: 0.474227\n",
      "Epoch 804 - Train Loss: 0.254866, Train Acc: 0.503846 | Val Loss: 0.263194, Val Acc: 0.474227\n",
      "Epoch 805 - Train Loss: 0.254846, Train Acc: 0.503846 | Val Loss: 0.263175, Val Acc: 0.474227\n",
      "Epoch 806 - Train Loss: 0.254825, Train Acc: 0.503846 | Val Loss: 0.263155, Val Acc: 0.474227\n",
      "Epoch 807 - Train Loss: 0.254805, Train Acc: 0.503846 | Val Loss: 0.263136, Val Acc: 0.474227\n",
      "Epoch 808 - Train Loss: 0.254784, Train Acc: 0.503846 | Val Loss: 0.263116, Val Acc: 0.474227\n",
      "Epoch 809 - Train Loss: 0.254764, Train Acc: 0.503846 | Val Loss: 0.263097, Val Acc: 0.474227\n",
      "Epoch 810 - Train Loss: 0.254743, Train Acc: 0.503846 | Val Loss: 0.263077, Val Acc: 0.474227\n",
      "Epoch 811 - Train Loss: 0.254723, Train Acc: 0.503846 | Val Loss: 0.263057, Val Acc: 0.474227\n",
      "Epoch 812 - Train Loss: 0.254702, Train Acc: 0.503846 | Val Loss: 0.263038, Val Acc: 0.474227\n",
      "Epoch 813 - Train Loss: 0.254682, Train Acc: 0.503846 | Val Loss: 0.263018, Val Acc: 0.474227\n",
      "Epoch 814 - Train Loss: 0.254661, Train Acc: 0.503846 | Val Loss: 0.262999, Val Acc: 0.474227\n",
      "Epoch 815 - Train Loss: 0.254641, Train Acc: 0.503846 | Val Loss: 0.262979, Val Acc: 0.474227\n",
      "Epoch 816 - Train Loss: 0.254620, Train Acc: 0.503846 | Val Loss: 0.262960, Val Acc: 0.474227\n",
      "Epoch 817 - Train Loss: 0.254600, Train Acc: 0.503846 | Val Loss: 0.262940, Val Acc: 0.474227\n",
      "Epoch 818 - Train Loss: 0.254579, Train Acc: 0.503846 | Val Loss: 0.262921, Val Acc: 0.474227\n",
      "Epoch 819 - Train Loss: 0.254559, Train Acc: 0.503846 | Val Loss: 0.262901, Val Acc: 0.474227\n",
      "Epoch 820 - Train Loss: 0.254538, Train Acc: 0.503846 | Val Loss: 0.262882, Val Acc: 0.474227\n",
      "Epoch 821 - Train Loss: 0.254518, Train Acc: 0.503846 | Val Loss: 0.262862, Val Acc: 0.474227\n",
      "Epoch 822 - Train Loss: 0.254498, Train Acc: 0.503846 | Val Loss: 0.262843, Val Acc: 0.474227\n",
      "Epoch 823 - Train Loss: 0.254477, Train Acc: 0.503846 | Val Loss: 0.262823, Val Acc: 0.474227\n",
      "Epoch 824 - Train Loss: 0.254457, Train Acc: 0.503846 | Val Loss: 0.262803, Val Acc: 0.474227\n",
      "Epoch 825 - Train Loss: 0.254436, Train Acc: 0.503846 | Val Loss: 0.262784, Val Acc: 0.474227\n",
      "Epoch 826 - Train Loss: 0.254416, Train Acc: 0.503846 | Val Loss: 0.262764, Val Acc: 0.474227\n",
      "Epoch 827 - Train Loss: 0.254395, Train Acc: 0.503846 | Val Loss: 0.262745, Val Acc: 0.474227\n",
      "Epoch 828 - Train Loss: 0.254375, Train Acc: 0.503846 | Val Loss: 0.262725, Val Acc: 0.474227\n",
      "Epoch 829 - Train Loss: 0.254354, Train Acc: 0.503846 | Val Loss: 0.262706, Val Acc: 0.474227\n",
      "Epoch 830 - Train Loss: 0.254334, Train Acc: 0.503846 | Val Loss: 0.262686, Val Acc: 0.474227\n",
      "Epoch 831 - Train Loss: 0.254313, Train Acc: 0.503846 | Val Loss: 0.262666, Val Acc: 0.474227\n",
      "Epoch 832 - Train Loss: 0.254293, Train Acc: 0.503846 | Val Loss: 0.262647, Val Acc: 0.474227\n",
      "Epoch 833 - Train Loss: 0.254272, Train Acc: 0.503846 | Val Loss: 0.262627, Val Acc: 0.474227\n",
      "Epoch 834 - Train Loss: 0.254252, Train Acc: 0.503846 | Val Loss: 0.262608, Val Acc: 0.474227\n",
      "Epoch 835 - Train Loss: 0.254231, Train Acc: 0.503846 | Val Loss: 0.262588, Val Acc: 0.474227\n",
      "Epoch 836 - Train Loss: 0.254211, Train Acc: 0.503846 | Val Loss: 0.262569, Val Acc: 0.474227\n",
      "Epoch 837 - Train Loss: 0.254190, Train Acc: 0.503846 | Val Loss: 0.262549, Val Acc: 0.474227\n",
      "Epoch 838 - Train Loss: 0.254170, Train Acc: 0.503846 | Val Loss: 0.262529, Val Acc: 0.474227\n",
      "Epoch 839 - Train Loss: 0.254149, Train Acc: 0.503846 | Val Loss: 0.262510, Val Acc: 0.474227\n",
      "Epoch 840 - Train Loss: 0.254129, Train Acc: 0.503846 | Val Loss: 0.262490, Val Acc: 0.474227\n",
      "Epoch 841 - Train Loss: 0.254108, Train Acc: 0.503846 | Val Loss: 0.262471, Val Acc: 0.474227\n",
      "Epoch 842 - Train Loss: 0.254088, Train Acc: 0.503846 | Val Loss: 0.262451, Val Acc: 0.474227\n",
      "Epoch 843 - Train Loss: 0.254067, Train Acc: 0.503846 | Val Loss: 0.262431, Val Acc: 0.474227\n",
      "Epoch 844 - Train Loss: 0.254047, Train Acc: 0.503846 | Val Loss: 0.262412, Val Acc: 0.474227\n",
      "Epoch 845 - Train Loss: 0.254026, Train Acc: 0.503846 | Val Loss: 0.262392, Val Acc: 0.474227\n",
      "Epoch 846 - Train Loss: 0.254006, Train Acc: 0.503846 | Val Loss: 0.262372, Val Acc: 0.474227\n",
      "Epoch 847 - Train Loss: 0.253985, Train Acc: 0.503846 | Val Loss: 0.262353, Val Acc: 0.474227\n",
      "Epoch 848 - Train Loss: 0.253965, Train Acc: 0.503846 | Val Loss: 0.262333, Val Acc: 0.474227\n",
      "Epoch 849 - Train Loss: 0.253944, Train Acc: 0.503846 | Val Loss: 0.262314, Val Acc: 0.474227\n",
      "Epoch 850 - Train Loss: 0.253924, Train Acc: 0.503846 | Val Loss: 0.262294, Val Acc: 0.474227\n",
      "Epoch 851 - Train Loss: 0.253903, Train Acc: 0.503846 | Val Loss: 0.262274, Val Acc: 0.474227\n",
      "Epoch 852 - Train Loss: 0.253883, Train Acc: 0.503846 | Val Loss: 0.262255, Val Acc: 0.474227\n",
      "Epoch 853 - Train Loss: 0.253862, Train Acc: 0.503846 | Val Loss: 0.262235, Val Acc: 0.474227\n",
      "Epoch 854 - Train Loss: 0.253842, Train Acc: 0.503846 | Val Loss: 0.262215, Val Acc: 0.474227\n",
      "Epoch 855 - Train Loss: 0.253821, Train Acc: 0.503846 | Val Loss: 0.262196, Val Acc: 0.474227\n",
      "Epoch 856 - Train Loss: 0.253801, Train Acc: 0.503846 | Val Loss: 0.262176, Val Acc: 0.474227\n",
      "Epoch 857 - Train Loss: 0.253780, Train Acc: 0.503846 | Val Loss: 0.262157, Val Acc: 0.474227\n",
      "Epoch 858 - Train Loss: 0.253760, Train Acc: 0.503846 | Val Loss: 0.262137, Val Acc: 0.474227\n",
      "Epoch 859 - Train Loss: 0.253739, Train Acc: 0.503846 | Val Loss: 0.262117, Val Acc: 0.474227\n",
      "Epoch 860 - Train Loss: 0.253719, Train Acc: 0.503846 | Val Loss: 0.262098, Val Acc: 0.474227\n",
      "Epoch 861 - Train Loss: 0.253698, Train Acc: 0.503846 | Val Loss: 0.262078, Val Acc: 0.474227\n",
      "Epoch 862 - Train Loss: 0.253678, Train Acc: 0.503846 | Val Loss: 0.262059, Val Acc: 0.474227\n",
      "Epoch 863 - Train Loss: 0.253657, Train Acc: 0.503846 | Val Loss: 0.262039, Val Acc: 0.474227\n",
      "Epoch 864 - Train Loss: 0.253637, Train Acc: 0.503846 | Val Loss: 0.262019, Val Acc: 0.474227\n",
      "Epoch 865 - Train Loss: 0.253616, Train Acc: 0.503846 | Val Loss: 0.262000, Val Acc: 0.474227\n",
      "Epoch 866 - Train Loss: 0.253596, Train Acc: 0.503846 | Val Loss: 0.261980, Val Acc: 0.474227\n",
      "Epoch 867 - Train Loss: 0.253575, Train Acc: 0.503846 | Val Loss: 0.261960, Val Acc: 0.474227\n",
      "Epoch 868 - Train Loss: 0.253555, Train Acc: 0.503846 | Val Loss: 0.261941, Val Acc: 0.474227\n",
      "Epoch 869 - Train Loss: 0.253534, Train Acc: 0.503846 | Val Loss: 0.261921, Val Acc: 0.474227\n",
      "Epoch 870 - Train Loss: 0.253514, Train Acc: 0.503846 | Val Loss: 0.261901, Val Acc: 0.474227\n",
      "Epoch 871 - Train Loss: 0.253493, Train Acc: 0.503846 | Val Loss: 0.261882, Val Acc: 0.474227\n",
      "Epoch 872 - Train Loss: 0.253473, Train Acc: 0.503846 | Val Loss: 0.261862, Val Acc: 0.474227\n",
      "Epoch 873 - Train Loss: 0.253452, Train Acc: 0.503846 | Val Loss: 0.261843, Val Acc: 0.474227\n",
      "Epoch 874 - Train Loss: 0.253432, Train Acc: 0.503846 | Val Loss: 0.261823, Val Acc: 0.474227\n",
      "Epoch 875 - Train Loss: 0.253411, Train Acc: 0.503846 | Val Loss: 0.261803, Val Acc: 0.474227\n",
      "Epoch 876 - Train Loss: 0.253391, Train Acc: 0.503846 | Val Loss: 0.261784, Val Acc: 0.474227\n",
      "Epoch 877 - Train Loss: 0.253370, Train Acc: 0.503846 | Val Loss: 0.261764, Val Acc: 0.474227\n",
      "Epoch 878 - Train Loss: 0.253350, Train Acc: 0.503846 | Val Loss: 0.261744, Val Acc: 0.474227\n",
      "Epoch 879 - Train Loss: 0.253329, Train Acc: 0.503846 | Val Loss: 0.261725, Val Acc: 0.474227\n",
      "Epoch 880 - Train Loss: 0.253309, Train Acc: 0.503846 | Val Loss: 0.261705, Val Acc: 0.474227\n",
      "Epoch 881 - Train Loss: 0.253288, Train Acc: 0.503846 | Val Loss: 0.261685, Val Acc: 0.474227\n",
      "Epoch 882 - Train Loss: 0.253268, Train Acc: 0.503846 | Val Loss: 0.261666, Val Acc: 0.474227\n",
      "Epoch 883 - Train Loss: 0.253247, Train Acc: 0.503846 | Val Loss: 0.261646, Val Acc: 0.474227\n",
      "Epoch 884 - Train Loss: 0.253227, Train Acc: 0.503846 | Val Loss: 0.261626, Val Acc: 0.474227\n",
      "Epoch 885 - Train Loss: 0.253206, Train Acc: 0.503846 | Val Loss: 0.261607, Val Acc: 0.474227\n",
      "Epoch 886 - Train Loss: 0.253185, Train Acc: 0.503846 | Val Loss: 0.261587, Val Acc: 0.474227\n",
      "Epoch 887 - Train Loss: 0.253165, Train Acc: 0.503846 | Val Loss: 0.261567, Val Acc: 0.474227\n",
      "Epoch 888 - Train Loss: 0.253144, Train Acc: 0.503846 | Val Loss: 0.261548, Val Acc: 0.474227\n",
      "Epoch 889 - Train Loss: 0.253124, Train Acc: 0.503846 | Val Loss: 0.261528, Val Acc: 0.474227\n",
      "Epoch 890 - Train Loss: 0.253103, Train Acc: 0.503846 | Val Loss: 0.261508, Val Acc: 0.474227\n",
      "Epoch 891 - Train Loss: 0.253083, Train Acc: 0.503846 | Val Loss: 0.261489, Val Acc: 0.474227\n",
      "Epoch 892 - Train Loss: 0.253062, Train Acc: 0.503846 | Val Loss: 0.261469, Val Acc: 0.474227\n",
      "Epoch 893 - Train Loss: 0.253042, Train Acc: 0.503846 | Val Loss: 0.261449, Val Acc: 0.474227\n",
      "Epoch 894 - Train Loss: 0.253021, Train Acc: 0.503846 | Val Loss: 0.261430, Val Acc: 0.474227\n",
      "Epoch 895 - Train Loss: 0.253001, Train Acc: 0.503846 | Val Loss: 0.261410, Val Acc: 0.474227\n",
      "Epoch 896 - Train Loss: 0.252980, Train Acc: 0.503846 | Val Loss: 0.261390, Val Acc: 0.474227\n",
      "Epoch 897 - Train Loss: 0.252959, Train Acc: 0.503846 | Val Loss: 0.261370, Val Acc: 0.474227\n",
      "Epoch 898 - Train Loss: 0.252939, Train Acc: 0.503846 | Val Loss: 0.261351, Val Acc: 0.474227\n",
      "Epoch 899 - Train Loss: 0.252918, Train Acc: 0.503846 | Val Loss: 0.261331, Val Acc: 0.474227\n",
      "Epoch 900 - Train Loss: 0.252898, Train Acc: 0.503846 | Val Loss: 0.261311, Val Acc: 0.474227\n",
      "Epoch 901 - Train Loss: 0.252877, Train Acc: 0.503846 | Val Loss: 0.261292, Val Acc: 0.474227\n",
      "Epoch 902 - Train Loss: 0.252857, Train Acc: 0.503846 | Val Loss: 0.261272, Val Acc: 0.474227\n",
      "Epoch 903 - Train Loss: 0.252836, Train Acc: 0.503846 | Val Loss: 0.261252, Val Acc: 0.474227\n",
      "Epoch 904 - Train Loss: 0.252816, Train Acc: 0.503846 | Val Loss: 0.261233, Val Acc: 0.474227\n",
      "Epoch 905 - Train Loss: 0.252795, Train Acc: 0.503846 | Val Loss: 0.261213, Val Acc: 0.474227\n",
      "Epoch 906 - Train Loss: 0.252774, Train Acc: 0.503846 | Val Loss: 0.261193, Val Acc: 0.474227\n",
      "Epoch 907 - Train Loss: 0.252754, Train Acc: 0.503846 | Val Loss: 0.261174, Val Acc: 0.474227\n",
      "Epoch 908 - Train Loss: 0.252733, Train Acc: 0.503846 | Val Loss: 0.261154, Val Acc: 0.474227\n",
      "Epoch 909 - Train Loss: 0.252713, Train Acc: 0.503846 | Val Loss: 0.261134, Val Acc: 0.474227\n",
      "Epoch 910 - Train Loss: 0.252692, Train Acc: 0.503846 | Val Loss: 0.261114, Val Acc: 0.474227\n",
      "Epoch 911 - Train Loss: 0.252672, Train Acc: 0.503846 | Val Loss: 0.261095, Val Acc: 0.474227\n",
      "Epoch 912 - Train Loss: 0.252651, Train Acc: 0.503846 | Val Loss: 0.261075, Val Acc: 0.474227\n",
      "Epoch 913 - Train Loss: 0.252630, Train Acc: 0.503846 | Val Loss: 0.261055, Val Acc: 0.474227\n",
      "Epoch 914 - Train Loss: 0.252610, Train Acc: 0.503846 | Val Loss: 0.261036, Val Acc: 0.474227\n",
      "Epoch 915 - Train Loss: 0.252589, Train Acc: 0.503846 | Val Loss: 0.261016, Val Acc: 0.474227\n",
      "Epoch 916 - Train Loss: 0.252569, Train Acc: 0.503846 | Val Loss: 0.260996, Val Acc: 0.474227\n",
      "Epoch 917 - Train Loss: 0.252548, Train Acc: 0.503846 | Val Loss: 0.260976, Val Acc: 0.474227\n",
      "Epoch 918 - Train Loss: 0.252528, Train Acc: 0.503846 | Val Loss: 0.260957, Val Acc: 0.474227\n",
      "Epoch 919 - Train Loss: 0.252507, Train Acc: 0.503846 | Val Loss: 0.260937, Val Acc: 0.474227\n",
      "Epoch 920 - Train Loss: 0.252486, Train Acc: 0.503846 | Val Loss: 0.260917, Val Acc: 0.474227\n",
      "Epoch 921 - Train Loss: 0.252466, Train Acc: 0.503846 | Val Loss: 0.260897, Val Acc: 0.474227\n",
      "Epoch 922 - Train Loss: 0.252445, Train Acc: 0.503846 | Val Loss: 0.260878, Val Acc: 0.474227\n",
      "Epoch 923 - Train Loss: 0.252425, Train Acc: 0.503846 | Val Loss: 0.260858, Val Acc: 0.474227\n",
      "Epoch 924 - Train Loss: 0.252404, Train Acc: 0.503846 | Val Loss: 0.260838, Val Acc: 0.474227\n",
      "Epoch 925 - Train Loss: 0.252383, Train Acc: 0.503846 | Val Loss: 0.260818, Val Acc: 0.474227\n",
      "Epoch 926 - Train Loss: 0.252363, Train Acc: 0.503846 | Val Loss: 0.260799, Val Acc: 0.474227\n",
      "Epoch 927 - Train Loss: 0.252342, Train Acc: 0.503846 | Val Loss: 0.260779, Val Acc: 0.474227\n",
      "Epoch 928 - Train Loss: 0.252322, Train Acc: 0.503846 | Val Loss: 0.260759, Val Acc: 0.474227\n",
      "Epoch 929 - Train Loss: 0.252301, Train Acc: 0.503846 | Val Loss: 0.260739, Val Acc: 0.474227\n",
      "Epoch 930 - Train Loss: 0.252280, Train Acc: 0.503846 | Val Loss: 0.260720, Val Acc: 0.474227\n",
      "Epoch 931 - Train Loss: 0.252260, Train Acc: 0.503846 | Val Loss: 0.260700, Val Acc: 0.474227\n",
      "Epoch 932 - Train Loss: 0.252239, Train Acc: 0.503846 | Val Loss: 0.260680, Val Acc: 0.474227\n",
      "Epoch 933 - Train Loss: 0.252219, Train Acc: 0.503846 | Val Loss: 0.260660, Val Acc: 0.474227\n",
      "Epoch 934 - Train Loss: 0.252198, Train Acc: 0.503846 | Val Loss: 0.260641, Val Acc: 0.474227\n",
      "Epoch 935 - Train Loss: 0.252177, Train Acc: 0.503846 | Val Loss: 0.260621, Val Acc: 0.474227\n",
      "Epoch 936 - Train Loss: 0.252157, Train Acc: 0.503846 | Val Loss: 0.260601, Val Acc: 0.474227\n",
      "Epoch 937 - Train Loss: 0.252136, Train Acc: 0.503846 | Val Loss: 0.260581, Val Acc: 0.474227\n",
      "Epoch 938 - Train Loss: 0.252116, Train Acc: 0.503846 | Val Loss: 0.260562, Val Acc: 0.474227\n",
      "Epoch 939 - Train Loss: 0.252095, Train Acc: 0.503846 | Val Loss: 0.260542, Val Acc: 0.474227\n",
      "Epoch 940 - Train Loss: 0.252074, Train Acc: 0.503846 | Val Loss: 0.260522, Val Acc: 0.474227\n",
      "Epoch 941 - Train Loss: 0.252054, Train Acc: 0.503846 | Val Loss: 0.260502, Val Acc: 0.474227\n",
      "Epoch 942 - Train Loss: 0.252033, Train Acc: 0.503846 | Val Loss: 0.260482, Val Acc: 0.474227\n",
      "Epoch 943 - Train Loss: 0.252012, Train Acc: 0.503846 | Val Loss: 0.260463, Val Acc: 0.474227\n",
      "Epoch 944 - Train Loss: 0.251992, Train Acc: 0.503846 | Val Loss: 0.260443, Val Acc: 0.474227\n",
      "Epoch 945 - Train Loss: 0.251971, Train Acc: 0.503846 | Val Loss: 0.260423, Val Acc: 0.474227\n",
      "Epoch 946 - Train Loss: 0.251951, Train Acc: 0.503846 | Val Loss: 0.260403, Val Acc: 0.474227\n",
      "Epoch 947 - Train Loss: 0.251930, Train Acc: 0.503846 | Val Loss: 0.260384, Val Acc: 0.474227\n",
      "Epoch 948 - Train Loss: 0.251909, Train Acc: 0.503846 | Val Loss: 0.260364, Val Acc: 0.474227\n",
      "Epoch 949 - Train Loss: 0.251889, Train Acc: 0.503846 | Val Loss: 0.260344, Val Acc: 0.474227\n",
      "Epoch 950 - Train Loss: 0.251868, Train Acc: 0.503846 | Val Loss: 0.260324, Val Acc: 0.474227\n",
      "Epoch 951 - Train Loss: 0.251847, Train Acc: 0.503846 | Val Loss: 0.260304, Val Acc: 0.474227\n",
      "Epoch 952 - Train Loss: 0.251827, Train Acc: 0.503846 | Val Loss: 0.260285, Val Acc: 0.474227\n",
      "Epoch 953 - Train Loss: 0.251806, Train Acc: 0.503846 | Val Loss: 0.260265, Val Acc: 0.474227\n",
      "Epoch 954 - Train Loss: 0.251786, Train Acc: 0.503846 | Val Loss: 0.260245, Val Acc: 0.474227\n",
      "Epoch 955 - Train Loss: 0.251765, Train Acc: 0.503846 | Val Loss: 0.260225, Val Acc: 0.474227\n",
      "Epoch 956 - Train Loss: 0.251744, Train Acc: 0.503846 | Val Loss: 0.260205, Val Acc: 0.474227\n",
      "Epoch 957 - Train Loss: 0.251724, Train Acc: 0.503846 | Val Loss: 0.260186, Val Acc: 0.474227\n",
      "Epoch 958 - Train Loss: 0.251703, Train Acc: 0.503846 | Val Loss: 0.260166, Val Acc: 0.474227\n",
      "Epoch 959 - Train Loss: 0.251682, Train Acc: 0.503846 | Val Loss: 0.260146, Val Acc: 0.474227\n",
      "Epoch 960 - Train Loss: 0.251662, Train Acc: 0.503846 | Val Loss: 0.260126, Val Acc: 0.474227\n",
      "Epoch 961 - Train Loss: 0.251641, Train Acc: 0.503846 | Val Loss: 0.260106, Val Acc: 0.474227\n",
      "Epoch 962 - Train Loss: 0.251620, Train Acc: 0.503846 | Val Loss: 0.260087, Val Acc: 0.474227\n",
      "Epoch 963 - Train Loss: 0.251600, Train Acc: 0.503846 | Val Loss: 0.260067, Val Acc: 0.474227\n",
      "Epoch 964 - Train Loss: 0.251579, Train Acc: 0.503846 | Val Loss: 0.260047, Val Acc: 0.474227\n",
      "Epoch 965 - Train Loss: 0.251559, Train Acc: 0.503846 | Val Loss: 0.260027, Val Acc: 0.474227\n",
      "Epoch 966 - Train Loss: 0.251538, Train Acc: 0.503846 | Val Loss: 0.260007, Val Acc: 0.474227\n",
      "Epoch 967 - Train Loss: 0.251517, Train Acc: 0.503846 | Val Loss: 0.259987, Val Acc: 0.474227\n",
      "Epoch 968 - Train Loss: 0.251497, Train Acc: 0.503846 | Val Loss: 0.259968, Val Acc: 0.474227\n",
      "Epoch 969 - Train Loss: 0.251476, Train Acc: 0.503846 | Val Loss: 0.259948, Val Acc: 0.474227\n",
      "Epoch 970 - Train Loss: 0.251455, Train Acc: 0.503846 | Val Loss: 0.259928, Val Acc: 0.474227\n",
      "Epoch 971 - Train Loss: 0.251435, Train Acc: 0.503846 | Val Loss: 0.259908, Val Acc: 0.474227\n",
      "Epoch 972 - Train Loss: 0.251414, Train Acc: 0.503846 | Val Loss: 0.259888, Val Acc: 0.474227\n",
      "Epoch 973 - Train Loss: 0.251393, Train Acc: 0.503846 | Val Loss: 0.259869, Val Acc: 0.474227\n",
      "Epoch 974 - Train Loss: 0.251373, Train Acc: 0.503846 | Val Loss: 0.259849, Val Acc: 0.474227\n",
      "Epoch 975 - Train Loss: 0.251352, Train Acc: 0.503846 | Val Loss: 0.259829, Val Acc: 0.474227\n",
      "Epoch 976 - Train Loss: 0.251331, Train Acc: 0.503846 | Val Loss: 0.259809, Val Acc: 0.474227\n",
      "Epoch 977 - Train Loss: 0.251311, Train Acc: 0.503846 | Val Loss: 0.259789, Val Acc: 0.474227\n",
      "Epoch 978 - Train Loss: 0.251290, Train Acc: 0.503846 | Val Loss: 0.259769, Val Acc: 0.474227\n",
      "Epoch 979 - Train Loss: 0.251269, Train Acc: 0.503846 | Val Loss: 0.259750, Val Acc: 0.474227\n",
      "Epoch 980 - Train Loss: 0.251249, Train Acc: 0.503846 | Val Loss: 0.259730, Val Acc: 0.474227\n",
      "Epoch 981 - Train Loss: 0.251228, Train Acc: 0.503846 | Val Loss: 0.259710, Val Acc: 0.474227\n",
      "Epoch 982 - Train Loss: 0.251207, Train Acc: 0.503846 | Val Loss: 0.259690, Val Acc: 0.474227\n",
      "Epoch 983 - Train Loss: 0.251187, Train Acc: 0.503846 | Val Loss: 0.259670, Val Acc: 0.474227\n",
      "Epoch 984 - Train Loss: 0.251166, Train Acc: 0.503846 | Val Loss: 0.259650, Val Acc: 0.474227\n",
      "Epoch 985 - Train Loss: 0.251145, Train Acc: 0.503846 | Val Loss: 0.259630, Val Acc: 0.474227\n",
      "Epoch 986 - Train Loss: 0.251125, Train Acc: 0.503846 | Val Loss: 0.259611, Val Acc: 0.474227\n",
      "Epoch 987 - Train Loss: 0.251104, Train Acc: 0.503846 | Val Loss: 0.259591, Val Acc: 0.474227\n",
      "Epoch 988 - Train Loss: 0.251083, Train Acc: 0.503846 | Val Loss: 0.259571, Val Acc: 0.474227\n",
      "Epoch 989 - Train Loss: 0.251063, Train Acc: 0.503846 | Val Loss: 0.259551, Val Acc: 0.474227\n",
      "Epoch 990 - Train Loss: 0.251042, Train Acc: 0.503846 | Val Loss: 0.259531, Val Acc: 0.474227\n",
      "Epoch 991 - Train Loss: 0.251021, Train Acc: 0.503846 | Val Loss: 0.259511, Val Acc: 0.474227\n",
      "Epoch 992 - Train Loss: 0.251001, Train Acc: 0.503846 | Val Loss: 0.259491, Val Acc: 0.474227\n",
      "Epoch 993 - Train Loss: 0.250980, Train Acc: 0.505128 | Val Loss: 0.259472, Val Acc: 0.474227\n",
      "Epoch 994 - Train Loss: 0.250959, Train Acc: 0.505128 | Val Loss: 0.259452, Val Acc: 0.474227\n",
      "Epoch 995 - Train Loss: 0.250939, Train Acc: 0.505128 | Val Loss: 0.259432, Val Acc: 0.474227\n",
      "Epoch 996 - Train Loss: 0.250918, Train Acc: 0.505128 | Val Loss: 0.259412, Val Acc: 0.474227\n",
      "Epoch 997 - Train Loss: 0.250897, Train Acc: 0.505128 | Val Loss: 0.259392, Val Acc: 0.474227\n",
      "Epoch 998 - Train Loss: 0.250876, Train Acc: 0.505128 | Val Loss: 0.259372, Val Acc: 0.474227\n",
      "Epoch 999 - Train Loss: 0.250856, Train Acc: 0.505128 | Val Loss: 0.259352, Val Acc: 0.474227\n",
      "Epoch 1000 - Train Loss: 0.250835, Train Acc: 0.505128 | Val Loss: 0.259332, Val Acc: 0.474227\n",
      "Epoch 1001 - Train Loss: 0.250814, Train Acc: 0.505128 | Val Loss: 0.259313, Val Acc: 0.474227\n",
      "Epoch 1002 - Train Loss: 0.250794, Train Acc: 0.505128 | Val Loss: 0.259293, Val Acc: 0.474227\n",
      "Epoch 1003 - Train Loss: 0.250773, Train Acc: 0.505128 | Val Loss: 0.259273, Val Acc: 0.474227\n",
      "Epoch 1004 - Train Loss: 0.250752, Train Acc: 0.505128 | Val Loss: 0.259253, Val Acc: 0.474227\n",
      "Epoch 1005 - Train Loss: 0.250731, Train Acc: 0.505128 | Val Loss: 0.259233, Val Acc: 0.474227\n",
      "Epoch 1006 - Train Loss: 0.250711, Train Acc: 0.505128 | Val Loss: 0.259213, Val Acc: 0.474227\n",
      "Epoch 1007 - Train Loss: 0.250690, Train Acc: 0.505128 | Val Loss: 0.259193, Val Acc: 0.474227\n",
      "Epoch 1008 - Train Loss: 0.250669, Train Acc: 0.505128 | Val Loss: 0.259173, Val Acc: 0.474227\n",
      "Epoch 1009 - Train Loss: 0.250649, Train Acc: 0.505128 | Val Loss: 0.259153, Val Acc: 0.474227\n",
      "Epoch 1010 - Train Loss: 0.250628, Train Acc: 0.505128 | Val Loss: 0.259134, Val Acc: 0.474227\n",
      "Epoch 1011 - Train Loss: 0.250607, Train Acc: 0.505128 | Val Loss: 0.259114, Val Acc: 0.474227\n",
      "Epoch 1012 - Train Loss: 0.250586, Train Acc: 0.505128 | Val Loss: 0.259094, Val Acc: 0.474227\n",
      "Epoch 1013 - Train Loss: 0.250566, Train Acc: 0.505128 | Val Loss: 0.259074, Val Acc: 0.474227\n",
      "Epoch 1014 - Train Loss: 0.250545, Train Acc: 0.505128 | Val Loss: 0.259054, Val Acc: 0.474227\n",
      "Epoch 1015 - Train Loss: 0.250524, Train Acc: 0.505128 | Val Loss: 0.259034, Val Acc: 0.474227\n",
      "Epoch 1016 - Train Loss: 0.250504, Train Acc: 0.505128 | Val Loss: 0.259014, Val Acc: 0.474227\n",
      "Epoch 1017 - Train Loss: 0.250483, Train Acc: 0.505128 | Val Loss: 0.258994, Val Acc: 0.474227\n",
      "Epoch 1018 - Train Loss: 0.250462, Train Acc: 0.505128 | Val Loss: 0.258974, Val Acc: 0.474227\n",
      "Epoch 1019 - Train Loss: 0.250441, Train Acc: 0.505128 | Val Loss: 0.258954, Val Acc: 0.474227\n",
      "Epoch 1020 - Train Loss: 0.250421, Train Acc: 0.505128 | Val Loss: 0.258934, Val Acc: 0.474227\n",
      "Epoch 1021 - Train Loss: 0.250400, Train Acc: 0.505128 | Val Loss: 0.258914, Val Acc: 0.474227\n",
      "Epoch 1022 - Train Loss: 0.250379, Train Acc: 0.505128 | Val Loss: 0.258894, Val Acc: 0.474227\n",
      "Epoch 1023 - Train Loss: 0.250358, Train Acc: 0.505128 | Val Loss: 0.258875, Val Acc: 0.474227\n",
      "Epoch 1024 - Train Loss: 0.250338, Train Acc: 0.505128 | Val Loss: 0.258855, Val Acc: 0.474227\n",
      "Epoch 1025 - Train Loss: 0.250317, Train Acc: 0.505128 | Val Loss: 0.258835, Val Acc: 0.474227\n",
      "Epoch 1026 - Train Loss: 0.250296, Train Acc: 0.505128 | Val Loss: 0.258815, Val Acc: 0.474227\n",
      "Epoch 1027 - Train Loss: 0.250275, Train Acc: 0.505128 | Val Loss: 0.258795, Val Acc: 0.474227\n",
      "Epoch 1028 - Train Loss: 0.250254, Train Acc: 0.505128 | Val Loss: 0.258775, Val Acc: 0.474227\n",
      "Epoch 1029 - Train Loss: 0.250234, Train Acc: 0.505128 | Val Loss: 0.258755, Val Acc: 0.474227\n",
      "Epoch 1030 - Train Loss: 0.250213, Train Acc: 0.505128 | Val Loss: 0.258735, Val Acc: 0.474227\n",
      "Epoch 1031 - Train Loss: 0.250192, Train Acc: 0.505128 | Val Loss: 0.258715, Val Acc: 0.474227\n",
      "Epoch 1032 - Train Loss: 0.250171, Train Acc: 0.505128 | Val Loss: 0.258695, Val Acc: 0.474227\n",
      "Epoch 1033 - Train Loss: 0.250151, Train Acc: 0.505128 | Val Loss: 0.258675, Val Acc: 0.474227\n",
      "Epoch 1034 - Train Loss: 0.250130, Train Acc: 0.505128 | Val Loss: 0.258655, Val Acc: 0.474227\n",
      "Epoch 1035 - Train Loss: 0.250109, Train Acc: 0.505128 | Val Loss: 0.258635, Val Acc: 0.474227\n",
      "Epoch 1036 - Train Loss: 0.250088, Train Acc: 0.505128 | Val Loss: 0.258615, Val Acc: 0.474227\n",
      "Epoch 1037 - Train Loss: 0.250068, Train Acc: 0.505128 | Val Loss: 0.258595, Val Acc: 0.474227\n",
      "Epoch 1038 - Train Loss: 0.250047, Train Acc: 0.505128 | Val Loss: 0.258575, Val Acc: 0.474227\n",
      "Epoch 1039 - Train Loss: 0.250026, Train Acc: 0.505128 | Val Loss: 0.258555, Val Acc: 0.474227\n",
      "Epoch 1040 - Train Loss: 0.250005, Train Acc: 0.505128 | Val Loss: 0.258535, Val Acc: 0.474227\n",
      "Epoch 1041 - Train Loss: 0.249984, Train Acc: 0.505128 | Val Loss: 0.258515, Val Acc: 0.474227\n",
      "Epoch 1042 - Train Loss: 0.249964, Train Acc: 0.505128 | Val Loss: 0.258495, Val Acc: 0.474227\n",
      "Epoch 1043 - Train Loss: 0.249943, Train Acc: 0.505128 | Val Loss: 0.258475, Val Acc: 0.474227\n",
      "Epoch 1044 - Train Loss: 0.249922, Train Acc: 0.505128 | Val Loss: 0.258455, Val Acc: 0.474227\n",
      "Epoch 1045 - Train Loss: 0.249901, Train Acc: 0.505128 | Val Loss: 0.258435, Val Acc: 0.474227\n",
      "Epoch 1046 - Train Loss: 0.249880, Train Acc: 0.505128 | Val Loss: 0.258415, Val Acc: 0.474227\n",
      "Epoch 1047 - Train Loss: 0.249859, Train Acc: 0.505128 | Val Loss: 0.258395, Val Acc: 0.474227\n",
      "Epoch 1048 - Train Loss: 0.249839, Train Acc: 0.505128 | Val Loss: 0.258375, Val Acc: 0.474227\n",
      "Epoch 1049 - Train Loss: 0.249818, Train Acc: 0.505128 | Val Loss: 0.258355, Val Acc: 0.474227\n",
      "Epoch 1050 - Train Loss: 0.249797, Train Acc: 0.505128 | Val Loss: 0.258335, Val Acc: 0.474227\n",
      "Epoch 1051 - Train Loss: 0.249776, Train Acc: 0.505128 | Val Loss: 0.258315, Val Acc: 0.474227\n",
      "Epoch 1052 - Train Loss: 0.249755, Train Acc: 0.505128 | Val Loss: 0.258295, Val Acc: 0.474227\n",
      "Epoch 1053 - Train Loss: 0.249734, Train Acc: 0.505128 | Val Loss: 0.258275, Val Acc: 0.474227\n",
      "Epoch 1054 - Train Loss: 0.249714, Train Acc: 0.505128 | Val Loss: 0.258255, Val Acc: 0.474227\n",
      "Epoch 1055 - Train Loss: 0.249693, Train Acc: 0.505128 | Val Loss: 0.258235, Val Acc: 0.474227\n",
      "Epoch 1056 - Train Loss: 0.249672, Train Acc: 0.505128 | Val Loss: 0.258215, Val Acc: 0.474227\n",
      "Epoch 1057 - Train Loss: 0.249651, Train Acc: 0.505128 | Val Loss: 0.258195, Val Acc: 0.474227\n",
      "Epoch 1058 - Train Loss: 0.249630, Train Acc: 0.505128 | Val Loss: 0.258175, Val Acc: 0.474227\n",
      "Epoch 1059 - Train Loss: 0.249609, Train Acc: 0.505128 | Val Loss: 0.258155, Val Acc: 0.474227\n",
      "Epoch 1060 - Train Loss: 0.249589, Train Acc: 0.505128 | Val Loss: 0.258135, Val Acc: 0.474227\n",
      "Epoch 1061 - Train Loss: 0.249568, Train Acc: 0.505128 | Val Loss: 0.258115, Val Acc: 0.474227\n",
      "Epoch 1062 - Train Loss: 0.249547, Train Acc: 0.505128 | Val Loss: 0.258095, Val Acc: 0.474227\n",
      "Epoch 1063 - Train Loss: 0.249526, Train Acc: 0.505128 | Val Loss: 0.258075, Val Acc: 0.474227\n",
      "Epoch 1064 - Train Loss: 0.249505, Train Acc: 0.505128 | Val Loss: 0.258055, Val Acc: 0.474227\n",
      "Epoch 1065 - Train Loss: 0.249484, Train Acc: 0.505128 | Val Loss: 0.258035, Val Acc: 0.474227\n",
      "Epoch 1066 - Train Loss: 0.249464, Train Acc: 0.505128 | Val Loss: 0.258015, Val Acc: 0.474227\n",
      "Epoch 1067 - Train Loss: 0.249443, Train Acc: 0.505128 | Val Loss: 0.257995, Val Acc: 0.474227\n",
      "Epoch 1068 - Train Loss: 0.249422, Train Acc: 0.505128 | Val Loss: 0.257975, Val Acc: 0.474227\n",
      "Epoch 1069 - Train Loss: 0.249401, Train Acc: 0.505128 | Val Loss: 0.257955, Val Acc: 0.474227\n",
      "Epoch 1070 - Train Loss: 0.249380, Train Acc: 0.505128 | Val Loss: 0.257935, Val Acc: 0.474227\n",
      "Epoch 1071 - Train Loss: 0.249359, Train Acc: 0.505128 | Val Loss: 0.257914, Val Acc: 0.474227\n",
      "Epoch 1072 - Train Loss: 0.249338, Train Acc: 0.505128 | Val Loss: 0.257894, Val Acc: 0.474227\n",
      "Epoch 1073 - Train Loss: 0.249317, Train Acc: 0.505128 | Val Loss: 0.257874, Val Acc: 0.474227\n",
      "Epoch 1074 - Train Loss: 0.249297, Train Acc: 0.505128 | Val Loss: 0.257854, Val Acc: 0.474227\n",
      "Epoch 1075 - Train Loss: 0.249276, Train Acc: 0.505128 | Val Loss: 0.257834, Val Acc: 0.474227\n",
      "Epoch 1076 - Train Loss: 0.249255, Train Acc: 0.505128 | Val Loss: 0.257814, Val Acc: 0.474227\n",
      "Epoch 1077 - Train Loss: 0.249234, Train Acc: 0.505128 | Val Loss: 0.257794, Val Acc: 0.474227\n",
      "Epoch 1078 - Train Loss: 0.249213, Train Acc: 0.505128 | Val Loss: 0.257774, Val Acc: 0.474227\n",
      "Epoch 1079 - Train Loss: 0.249192, Train Acc: 0.505128 | Val Loss: 0.257754, Val Acc: 0.474227\n",
      "Epoch 1080 - Train Loss: 0.249171, Train Acc: 0.505128 | Val Loss: 0.257734, Val Acc: 0.474227\n",
      "Epoch 1081 - Train Loss: 0.249150, Train Acc: 0.505128 | Val Loss: 0.257714, Val Acc: 0.474227\n",
      "Epoch 1082 - Train Loss: 0.249129, Train Acc: 0.505128 | Val Loss: 0.257694, Val Acc: 0.474227\n",
      "Epoch 1083 - Train Loss: 0.249109, Train Acc: 0.505128 | Val Loss: 0.257674, Val Acc: 0.474227\n",
      "Epoch 1084 - Train Loss: 0.249088, Train Acc: 0.505128 | Val Loss: 0.257654, Val Acc: 0.474227\n",
      "Epoch 1085 - Train Loss: 0.249067, Train Acc: 0.505128 | Val Loss: 0.257634, Val Acc: 0.474227\n",
      "Epoch 1086 - Train Loss: 0.249046, Train Acc: 0.505128 | Val Loss: 0.257614, Val Acc: 0.474227\n",
      "Epoch 1087 - Train Loss: 0.249025, Train Acc: 0.505128 | Val Loss: 0.257594, Val Acc: 0.474227\n",
      "Epoch 1088 - Train Loss: 0.249004, Train Acc: 0.505128 | Val Loss: 0.257574, Val Acc: 0.474227\n",
      "Epoch 1089 - Train Loss: 0.248983, Train Acc: 0.505128 | Val Loss: 0.257554, Val Acc: 0.474227\n",
      "Epoch 1090 - Train Loss: 0.248962, Train Acc: 0.505128 | Val Loss: 0.257534, Val Acc: 0.474227\n",
      "Epoch 1091 - Train Loss: 0.248941, Train Acc: 0.505128 | Val Loss: 0.257514, Val Acc: 0.474227\n",
      "Epoch 1092 - Train Loss: 0.248921, Train Acc: 0.505128 | Val Loss: 0.257494, Val Acc: 0.474227\n",
      "Epoch 1093 - Train Loss: 0.248900, Train Acc: 0.505128 | Val Loss: 0.257474, Val Acc: 0.474227\n",
      "Epoch 1094 - Train Loss: 0.248879, Train Acc: 0.505128 | Val Loss: 0.257454, Val Acc: 0.474227\n",
      "Epoch 1095 - Train Loss: 0.248858, Train Acc: 0.505128 | Val Loss: 0.257433, Val Acc: 0.474227\n",
      "Epoch 1096 - Train Loss: 0.248837, Train Acc: 0.505128 | Val Loss: 0.257413, Val Acc: 0.474227\n",
      "Epoch 1097 - Train Loss: 0.248816, Train Acc: 0.505128 | Val Loss: 0.257393, Val Acc: 0.474227\n",
      "Epoch 1098 - Train Loss: 0.248795, Train Acc: 0.505128 | Val Loss: 0.257373, Val Acc: 0.474227\n",
      "Epoch 1099 - Train Loss: 0.248774, Train Acc: 0.505128 | Val Loss: 0.257353, Val Acc: 0.474227\n",
      "Epoch 1100 - Train Loss: 0.248753, Train Acc: 0.505128 | Val Loss: 0.257333, Val Acc: 0.474227\n",
      "Epoch 1101 - Train Loss: 0.248732, Train Acc: 0.505128 | Val Loss: 0.257313, Val Acc: 0.474227\n",
      "Epoch 1102 - Train Loss: 0.248712, Train Acc: 0.505128 | Val Loss: 0.257293, Val Acc: 0.474227\n",
      "Epoch 1103 - Train Loss: 0.248691, Train Acc: 0.505128 | Val Loss: 0.257273, Val Acc: 0.474227\n",
      "Epoch 1104 - Train Loss: 0.248670, Train Acc: 0.505128 | Val Loss: 0.257253, Val Acc: 0.474227\n",
      "Epoch 1105 - Train Loss: 0.248649, Train Acc: 0.505128 | Val Loss: 0.257233, Val Acc: 0.474227\n",
      "Epoch 1106 - Train Loss: 0.248628, Train Acc: 0.506410 | Val Loss: 0.257213, Val Acc: 0.474227\n",
      "Epoch 1107 - Train Loss: 0.248607, Train Acc: 0.506410 | Val Loss: 0.257193, Val Acc: 0.474227\n",
      "Epoch 1108 - Train Loss: 0.248586, Train Acc: 0.506410 | Val Loss: 0.257173, Val Acc: 0.474227\n",
      "Epoch 1109 - Train Loss: 0.248565, Train Acc: 0.506410 | Val Loss: 0.257153, Val Acc: 0.474227\n",
      "Epoch 1110 - Train Loss: 0.248544, Train Acc: 0.506410 | Val Loss: 0.257133, Val Acc: 0.474227\n",
      "Epoch 1111 - Train Loss: 0.248523, Train Acc: 0.506410 | Val Loss: 0.257113, Val Acc: 0.474227\n",
      "Epoch 1112 - Train Loss: 0.248502, Train Acc: 0.506410 | Val Loss: 0.257092, Val Acc: 0.474227\n",
      "Epoch 1113 - Train Loss: 0.248481, Train Acc: 0.506410 | Val Loss: 0.257072, Val Acc: 0.474227\n",
      "Epoch 1114 - Train Loss: 0.248460, Train Acc: 0.506410 | Val Loss: 0.257052, Val Acc: 0.474227\n",
      "Epoch 1115 - Train Loss: 0.248440, Train Acc: 0.506410 | Val Loss: 0.257032, Val Acc: 0.474227\n",
      "Epoch 1116 - Train Loss: 0.248419, Train Acc: 0.506410 | Val Loss: 0.257012, Val Acc: 0.474227\n",
      "Epoch 1117 - Train Loss: 0.248398, Train Acc: 0.506410 | Val Loss: 0.256992, Val Acc: 0.474227\n",
      "Epoch 1118 - Train Loss: 0.248377, Train Acc: 0.506410 | Val Loss: 0.256972, Val Acc: 0.474227\n",
      "Epoch 1119 - Train Loss: 0.248356, Train Acc: 0.506410 | Val Loss: 0.256952, Val Acc: 0.474227\n",
      "Epoch 1120 - Train Loss: 0.248335, Train Acc: 0.506410 | Val Loss: 0.256932, Val Acc: 0.474227\n",
      "Epoch 1121 - Train Loss: 0.248314, Train Acc: 0.506410 | Val Loss: 0.256912, Val Acc: 0.474227\n",
      "Epoch 1122 - Train Loss: 0.248293, Train Acc: 0.506410 | Val Loss: 0.256891, Val Acc: 0.474227\n",
      "Epoch 1123 - Train Loss: 0.248272, Train Acc: 0.506410 | Val Loss: 0.256871, Val Acc: 0.474227\n",
      "Epoch 1124 - Train Loss: 0.248251, Train Acc: 0.506410 | Val Loss: 0.256851, Val Acc: 0.474227\n",
      "Epoch 1125 - Train Loss: 0.248230, Train Acc: 0.506410 | Val Loss: 0.256831, Val Acc: 0.474227\n",
      "Epoch 1126 - Train Loss: 0.248209, Train Acc: 0.506410 | Val Loss: 0.256811, Val Acc: 0.474227\n",
      "Epoch 1127 - Train Loss: 0.248188, Train Acc: 0.506410 | Val Loss: 0.256791, Val Acc: 0.474227\n",
      "Epoch 1128 - Train Loss: 0.248167, Train Acc: 0.506410 | Val Loss: 0.256771, Val Acc: 0.474227\n",
      "Epoch 1129 - Train Loss: 0.248146, Train Acc: 0.506410 | Val Loss: 0.256751, Val Acc: 0.474227\n",
      "Epoch 1130 - Train Loss: 0.248125, Train Acc: 0.506410 | Val Loss: 0.256730, Val Acc: 0.474227\n",
      "Epoch 1131 - Train Loss: 0.248104, Train Acc: 0.506410 | Val Loss: 0.256710, Val Acc: 0.474227\n",
      "Epoch 1132 - Train Loss: 0.248083, Train Acc: 0.506410 | Val Loss: 0.256690, Val Acc: 0.474227\n",
      "Epoch 1133 - Train Loss: 0.248062, Train Acc: 0.506410 | Val Loss: 0.256670, Val Acc: 0.474227\n",
      "Epoch 1134 - Train Loss: 0.248041, Train Acc: 0.506410 | Val Loss: 0.256650, Val Acc: 0.474227\n",
      "Epoch 1135 - Train Loss: 0.248021, Train Acc: 0.506410 | Val Loss: 0.256630, Val Acc: 0.474227\n",
      "Epoch 1136 - Train Loss: 0.248000, Train Acc: 0.506410 | Val Loss: 0.256609, Val Acc: 0.474227\n",
      "Epoch 1137 - Train Loss: 0.247979, Train Acc: 0.506410 | Val Loss: 0.256589, Val Acc: 0.474227\n",
      "Epoch 1138 - Train Loss: 0.247958, Train Acc: 0.506410 | Val Loss: 0.256569, Val Acc: 0.474227\n",
      "Epoch 1139 - Train Loss: 0.247937, Train Acc: 0.506410 | Val Loss: 0.256549, Val Acc: 0.474227\n",
      "Epoch 1140 - Train Loss: 0.247916, Train Acc: 0.506410 | Val Loss: 0.256529, Val Acc: 0.474227\n",
      "Epoch 1141 - Train Loss: 0.247895, Train Acc: 0.506410 | Val Loss: 0.256509, Val Acc: 0.474227\n",
      "Epoch 1142 - Train Loss: 0.247874, Train Acc: 0.506410 | Val Loss: 0.256488, Val Acc: 0.474227\n",
      "Epoch 1143 - Train Loss: 0.247853, Train Acc: 0.506410 | Val Loss: 0.256468, Val Acc: 0.474227\n",
      "Epoch 1144 - Train Loss: 0.247832, Train Acc: 0.506410 | Val Loss: 0.256448, Val Acc: 0.474227\n",
      "Epoch 1145 - Train Loss: 0.247811, Train Acc: 0.506410 | Val Loss: 0.256428, Val Acc: 0.474227\n",
      "Epoch 1146 - Train Loss: 0.247790, Train Acc: 0.506410 | Val Loss: 0.256408, Val Acc: 0.474227\n",
      "Epoch 1147 - Train Loss: 0.247769, Train Acc: 0.506410 | Val Loss: 0.256388, Val Acc: 0.474227\n",
      "Epoch 1148 - Train Loss: 0.247748, Train Acc: 0.506410 | Val Loss: 0.256367, Val Acc: 0.474227\n",
      "Epoch 1149 - Train Loss: 0.247727, Train Acc: 0.506410 | Val Loss: 0.256347, Val Acc: 0.474227\n",
      "Epoch 1150 - Train Loss: 0.247706, Train Acc: 0.507692 | Val Loss: 0.256327, Val Acc: 0.474227\n",
      "Epoch 1151 - Train Loss: 0.247685, Train Acc: 0.507692 | Val Loss: 0.256307, Val Acc: 0.474227\n",
      "Epoch 1152 - Train Loss: 0.247664, Train Acc: 0.507692 | Val Loss: 0.256287, Val Acc: 0.474227\n",
      "Epoch 1153 - Train Loss: 0.247643, Train Acc: 0.508974 | Val Loss: 0.256266, Val Acc: 0.474227\n",
      "Epoch 1154 - Train Loss: 0.247622, Train Acc: 0.508974 | Val Loss: 0.256246, Val Acc: 0.474227\n",
      "Epoch 1155 - Train Loss: 0.247601, Train Acc: 0.508974 | Val Loss: 0.256226, Val Acc: 0.474227\n",
      "Epoch 1156 - Train Loss: 0.247580, Train Acc: 0.508974 | Val Loss: 0.256206, Val Acc: 0.474227\n",
      "Epoch 1157 - Train Loss: 0.247559, Train Acc: 0.508974 | Val Loss: 0.256185, Val Acc: 0.474227\n",
      "Epoch 1158 - Train Loss: 0.247538, Train Acc: 0.508974 | Val Loss: 0.256165, Val Acc: 0.474227\n",
      "Epoch 1159 - Train Loss: 0.247517, Train Acc: 0.508974 | Val Loss: 0.256145, Val Acc: 0.474227\n",
      "Epoch 1160 - Train Loss: 0.247496, Train Acc: 0.508974 | Val Loss: 0.256125, Val Acc: 0.474227\n",
      "Epoch 1161 - Train Loss: 0.247475, Train Acc: 0.508974 | Val Loss: 0.256105, Val Acc: 0.474227\n",
      "Epoch 1162 - Train Loss: 0.247454, Train Acc: 0.508974 | Val Loss: 0.256084, Val Acc: 0.474227\n",
      "Epoch 1163 - Train Loss: 0.247433, Train Acc: 0.508974 | Val Loss: 0.256064, Val Acc: 0.474227\n",
      "Epoch 1164 - Train Loss: 0.247412, Train Acc: 0.508974 | Val Loss: 0.256044, Val Acc: 0.474227\n",
      "Epoch 1165 - Train Loss: 0.247391, Train Acc: 0.508974 | Val Loss: 0.256024, Val Acc: 0.474227\n",
      "Epoch 1166 - Train Loss: 0.247370, Train Acc: 0.508974 | Val Loss: 0.256003, Val Acc: 0.474227\n",
      "Epoch 1167 - Train Loss: 0.247349, Train Acc: 0.508974 | Val Loss: 0.255983, Val Acc: 0.474227\n",
      "Epoch 1168 - Train Loss: 0.247328, Train Acc: 0.508974 | Val Loss: 0.255963, Val Acc: 0.474227\n",
      "Epoch 1169 - Train Loss: 0.247307, Train Acc: 0.508974 | Val Loss: 0.255943, Val Acc: 0.474227\n",
      "Epoch 1170 - Train Loss: 0.247286, Train Acc: 0.508974 | Val Loss: 0.255922, Val Acc: 0.474227\n",
      "Epoch 1171 - Train Loss: 0.247265, Train Acc: 0.508974 | Val Loss: 0.255902, Val Acc: 0.474227\n",
      "Epoch 1172 - Train Loss: 0.247244, Train Acc: 0.508974 | Val Loss: 0.255882, Val Acc: 0.474227\n",
      "Epoch 1173 - Train Loss: 0.247223, Train Acc: 0.508974 | Val Loss: 0.255862, Val Acc: 0.474227\n",
      "Epoch 1174 - Train Loss: 0.247202, Train Acc: 0.508974 | Val Loss: 0.255842, Val Acc: 0.474227\n",
      "Epoch 1175 - Train Loss: 0.247181, Train Acc: 0.508974 | Val Loss: 0.255821, Val Acc: 0.474227\n",
      "Epoch 1176 - Train Loss: 0.247160, Train Acc: 0.508974 | Val Loss: 0.255801, Val Acc: 0.474227\n",
      "Epoch 1177 - Train Loss: 0.247138, Train Acc: 0.508974 | Val Loss: 0.255781, Val Acc: 0.474227\n",
      "Epoch 1178 - Train Loss: 0.247117, Train Acc: 0.508974 | Val Loss: 0.255761, Val Acc: 0.474227\n",
      "Epoch 1179 - Train Loss: 0.247096, Train Acc: 0.508974 | Val Loss: 0.255740, Val Acc: 0.474227\n",
      "Epoch 1180 - Train Loss: 0.247075, Train Acc: 0.508974 | Val Loss: 0.255720, Val Acc: 0.474227\n",
      "Epoch 1181 - Train Loss: 0.247054, Train Acc: 0.508974 | Val Loss: 0.255700, Val Acc: 0.474227\n",
      "Epoch 1182 - Train Loss: 0.247033, Train Acc: 0.508974 | Val Loss: 0.255680, Val Acc: 0.474227\n",
      "Epoch 1183 - Train Loss: 0.247012, Train Acc: 0.510256 | Val Loss: 0.255659, Val Acc: 0.474227\n",
      "Epoch 1184 - Train Loss: 0.246991, Train Acc: 0.510256 | Val Loss: 0.255639, Val Acc: 0.474227\n",
      "Epoch 1185 - Train Loss: 0.246970, Train Acc: 0.510256 | Val Loss: 0.255619, Val Acc: 0.474227\n",
      "Epoch 1186 - Train Loss: 0.246949, Train Acc: 0.510256 | Val Loss: 0.255599, Val Acc: 0.474227\n",
      "Epoch 1187 - Train Loss: 0.246928, Train Acc: 0.510256 | Val Loss: 0.255578, Val Acc: 0.474227\n",
      "Epoch 1188 - Train Loss: 0.246907, Train Acc: 0.510256 | Val Loss: 0.255558, Val Acc: 0.474227\n",
      "Epoch 1189 - Train Loss: 0.246886, Train Acc: 0.510256 | Val Loss: 0.255538, Val Acc: 0.474227\n",
      "Epoch 1190 - Train Loss: 0.246865, Train Acc: 0.510256 | Val Loss: 0.255517, Val Acc: 0.474227\n",
      "Epoch 1191 - Train Loss: 0.246844, Train Acc: 0.510256 | Val Loss: 0.255497, Val Acc: 0.474227\n",
      "Epoch 1192 - Train Loss: 0.246823, Train Acc: 0.510256 | Val Loss: 0.255477, Val Acc: 0.474227\n",
      "Epoch 1193 - Train Loss: 0.246801, Train Acc: 0.510256 | Val Loss: 0.255457, Val Acc: 0.474227\n",
      "Epoch 1194 - Train Loss: 0.246780, Train Acc: 0.510256 | Val Loss: 0.255436, Val Acc: 0.474227\n",
      "Epoch 1195 - Train Loss: 0.246759, Train Acc: 0.510256 | Val Loss: 0.255416, Val Acc: 0.474227\n",
      "Epoch 1196 - Train Loss: 0.246738, Train Acc: 0.510256 | Val Loss: 0.255396, Val Acc: 0.474227\n",
      "Epoch 1197 - Train Loss: 0.246717, Train Acc: 0.510256 | Val Loss: 0.255375, Val Acc: 0.474227\n",
      "Epoch 1198 - Train Loss: 0.246696, Train Acc: 0.510256 | Val Loss: 0.255355, Val Acc: 0.474227\n",
      "Epoch 1199 - Train Loss: 0.246675, Train Acc: 0.510256 | Val Loss: 0.255335, Val Acc: 0.474227\n",
      "Epoch 1200 - Train Loss: 0.246654, Train Acc: 0.510256 | Val Loss: 0.255314, Val Acc: 0.474227\n",
      "Epoch 1201 - Train Loss: 0.246633, Train Acc: 0.510256 | Val Loss: 0.255294, Val Acc: 0.474227\n",
      "Epoch 1202 - Train Loss: 0.246611, Train Acc: 0.510256 | Val Loss: 0.255274, Val Acc: 0.474227\n",
      "Epoch 1203 - Train Loss: 0.246590, Train Acc: 0.510256 | Val Loss: 0.255253, Val Acc: 0.474227\n",
      "Epoch 1204 - Train Loss: 0.246569, Train Acc: 0.510256 | Val Loss: 0.255233, Val Acc: 0.474227\n",
      "Epoch 1205 - Train Loss: 0.246548, Train Acc: 0.510256 | Val Loss: 0.255213, Val Acc: 0.474227\n",
      "Epoch 1206 - Train Loss: 0.246527, Train Acc: 0.510256 | Val Loss: 0.255192, Val Acc: 0.474227\n",
      "Epoch 1207 - Train Loss: 0.246506, Train Acc: 0.510256 | Val Loss: 0.255172, Val Acc: 0.474227\n",
      "Epoch 1208 - Train Loss: 0.246485, Train Acc: 0.510256 | Val Loss: 0.255152, Val Acc: 0.474227\n",
      "Epoch 1209 - Train Loss: 0.246464, Train Acc: 0.511538 | Val Loss: 0.255131, Val Acc: 0.474227\n",
      "Epoch 1210 - Train Loss: 0.246443, Train Acc: 0.511538 | Val Loss: 0.255111, Val Acc: 0.474227\n",
      "Epoch 1211 - Train Loss: 0.246421, Train Acc: 0.511538 | Val Loss: 0.255091, Val Acc: 0.474227\n",
      "Epoch 1212 - Train Loss: 0.246400, Train Acc: 0.511538 | Val Loss: 0.255070, Val Acc: 0.474227\n",
      "Epoch 1213 - Train Loss: 0.246379, Train Acc: 0.511538 | Val Loss: 0.255050, Val Acc: 0.474227\n",
      "Epoch 1214 - Train Loss: 0.246358, Train Acc: 0.511538 | Val Loss: 0.255030, Val Acc: 0.474227\n",
      "Epoch 1215 - Train Loss: 0.246337, Train Acc: 0.511538 | Val Loss: 0.255009, Val Acc: 0.474227\n",
      "Epoch 1216 - Train Loss: 0.246316, Train Acc: 0.511538 | Val Loss: 0.254989, Val Acc: 0.474227\n",
      "Epoch 1217 - Train Loss: 0.246295, Train Acc: 0.511538 | Val Loss: 0.254969, Val Acc: 0.474227\n",
      "Epoch 1218 - Train Loss: 0.246273, Train Acc: 0.511538 | Val Loss: 0.254948, Val Acc: 0.474227\n",
      "Epoch 1219 - Train Loss: 0.246252, Train Acc: 0.511538 | Val Loss: 0.254928, Val Acc: 0.474227\n",
      "Epoch 1220 - Train Loss: 0.246231, Train Acc: 0.511538 | Val Loss: 0.254908, Val Acc: 0.474227\n",
      "Epoch 1221 - Train Loss: 0.246210, Train Acc: 0.511538 | Val Loss: 0.254887, Val Acc: 0.474227\n",
      "Epoch 1222 - Train Loss: 0.246189, Train Acc: 0.511538 | Val Loss: 0.254867, Val Acc: 0.474227\n",
      "Epoch 1223 - Train Loss: 0.246168, Train Acc: 0.511538 | Val Loss: 0.254847, Val Acc: 0.474227\n",
      "Epoch 1224 - Train Loss: 0.246147, Train Acc: 0.511538 | Val Loss: 0.254826, Val Acc: 0.474227\n",
      "Epoch 1225 - Train Loss: 0.246125, Train Acc: 0.511538 | Val Loss: 0.254806, Val Acc: 0.474227\n",
      "Epoch 1226 - Train Loss: 0.246104, Train Acc: 0.511538 | Val Loss: 0.254786, Val Acc: 0.474227\n",
      "Epoch 1227 - Train Loss: 0.246083, Train Acc: 0.511538 | Val Loss: 0.254765, Val Acc: 0.474227\n",
      "Epoch 1228 - Train Loss: 0.246062, Train Acc: 0.511538 | Val Loss: 0.254745, Val Acc: 0.474227\n",
      "Epoch 1229 - Train Loss: 0.246041, Train Acc: 0.511538 | Val Loss: 0.254725, Val Acc: 0.474227\n",
      "Epoch 1230 - Train Loss: 0.246020, Train Acc: 0.511538 | Val Loss: 0.254704, Val Acc: 0.474227\n",
      "Epoch 1231 - Train Loss: 0.245998, Train Acc: 0.511538 | Val Loss: 0.254684, Val Acc: 0.474227\n",
      "Epoch 1232 - Train Loss: 0.245977, Train Acc: 0.511538 | Val Loss: 0.254664, Val Acc: 0.474227\n",
      "Epoch 1233 - Train Loss: 0.245956, Train Acc: 0.511538 | Val Loss: 0.254643, Val Acc: 0.474227\n",
      "Epoch 1234 - Train Loss: 0.245935, Train Acc: 0.511538 | Val Loss: 0.254623, Val Acc: 0.474227\n",
      "Epoch 1235 - Train Loss: 0.245914, Train Acc: 0.511538 | Val Loss: 0.254602, Val Acc: 0.474227\n",
      "Epoch 1236 - Train Loss: 0.245892, Train Acc: 0.511538 | Val Loss: 0.254582, Val Acc: 0.474227\n",
      "Epoch 1237 - Train Loss: 0.245871, Train Acc: 0.511538 | Val Loss: 0.254562, Val Acc: 0.474227\n",
      "Epoch 1238 - Train Loss: 0.245850, Train Acc: 0.511538 | Val Loss: 0.254541, Val Acc: 0.474227\n",
      "Epoch 1239 - Train Loss: 0.245829, Train Acc: 0.511538 | Val Loss: 0.254521, Val Acc: 0.474227\n",
      "Epoch 1240 - Train Loss: 0.245808, Train Acc: 0.511538 | Val Loss: 0.254501, Val Acc: 0.474227\n",
      "Epoch 1241 - Train Loss: 0.245787, Train Acc: 0.512821 | Val Loss: 0.254480, Val Acc: 0.474227\n",
      "Epoch 1242 - Train Loss: 0.245765, Train Acc: 0.512821 | Val Loss: 0.254460, Val Acc: 0.474227\n",
      "Epoch 1243 - Train Loss: 0.245744, Train Acc: 0.512821 | Val Loss: 0.254440, Val Acc: 0.474227\n",
      "Epoch 1244 - Train Loss: 0.245723, Train Acc: 0.512821 | Val Loss: 0.254419, Val Acc: 0.474227\n",
      "Epoch 1245 - Train Loss: 0.245702, Train Acc: 0.512821 | Val Loss: 0.254399, Val Acc: 0.474227\n",
      "Epoch 1246 - Train Loss: 0.245680, Train Acc: 0.512821 | Val Loss: 0.254378, Val Acc: 0.474227\n",
      "Epoch 1247 - Train Loss: 0.245659, Train Acc: 0.512821 | Val Loss: 0.254358, Val Acc: 0.474227\n",
      "Epoch 1248 - Train Loss: 0.245638, Train Acc: 0.512821 | Val Loss: 0.254337, Val Acc: 0.474227\n",
      "Epoch 1249 - Train Loss: 0.245617, Train Acc: 0.512821 | Val Loss: 0.254317, Val Acc: 0.474227\n",
      "Epoch 1250 - Train Loss: 0.245596, Train Acc: 0.512821 | Val Loss: 0.254297, Val Acc: 0.474227\n",
      "Epoch 1251 - Train Loss: 0.245574, Train Acc: 0.512821 | Val Loss: 0.254276, Val Acc: 0.474227\n",
      "Epoch 1252 - Train Loss: 0.245553, Train Acc: 0.512821 | Val Loss: 0.254256, Val Acc: 0.474227\n",
      "Epoch 1253 - Train Loss: 0.245532, Train Acc: 0.512821 | Val Loss: 0.254235, Val Acc: 0.474227\n",
      "Epoch 1254 - Train Loss: 0.245511, Train Acc: 0.512821 | Val Loss: 0.254215, Val Acc: 0.474227\n",
      "Epoch 1255 - Train Loss: 0.245489, Train Acc: 0.512821 | Val Loss: 0.254195, Val Acc: 0.474227\n",
      "Epoch 1256 - Train Loss: 0.245468, Train Acc: 0.512821 | Val Loss: 0.254174, Val Acc: 0.474227\n",
      "Epoch 1257 - Train Loss: 0.245447, Train Acc: 0.512821 | Val Loss: 0.254154, Val Acc: 0.474227\n",
      "Epoch 1258 - Train Loss: 0.245426, Train Acc: 0.512821 | Val Loss: 0.254133, Val Acc: 0.474227\n",
      "Epoch 1259 - Train Loss: 0.245404, Train Acc: 0.512821 | Val Loss: 0.254113, Val Acc: 0.474227\n",
      "Epoch 1260 - Train Loss: 0.245383, Train Acc: 0.512821 | Val Loss: 0.254092, Val Acc: 0.474227\n",
      "Epoch 1261 - Train Loss: 0.245362, Train Acc: 0.512821 | Val Loss: 0.254072, Val Acc: 0.474227\n",
      "Epoch 1262 - Train Loss: 0.245341, Train Acc: 0.512821 | Val Loss: 0.254052, Val Acc: 0.474227\n",
      "Epoch 1263 - Train Loss: 0.245319, Train Acc: 0.512821 | Val Loss: 0.254031, Val Acc: 0.474227\n",
      "Epoch 1264 - Train Loss: 0.245298, Train Acc: 0.512821 | Val Loss: 0.254011, Val Acc: 0.474227\n",
      "Epoch 1265 - Train Loss: 0.245277, Train Acc: 0.512821 | Val Loss: 0.253990, Val Acc: 0.474227\n",
      "Epoch 1266 - Train Loss: 0.245255, Train Acc: 0.512821 | Val Loss: 0.253970, Val Acc: 0.474227\n",
      "Epoch 1267 - Train Loss: 0.245234, Train Acc: 0.512821 | Val Loss: 0.253949, Val Acc: 0.474227\n",
      "Epoch 1268 - Train Loss: 0.245213, Train Acc: 0.512821 | Val Loss: 0.253929, Val Acc: 0.474227\n",
      "Epoch 1269 - Train Loss: 0.245192, Train Acc: 0.512821 | Val Loss: 0.253908, Val Acc: 0.474227\n",
      "Epoch 1270 - Train Loss: 0.245170, Train Acc: 0.512821 | Val Loss: 0.253888, Val Acc: 0.474227\n",
      "Epoch 1271 - Train Loss: 0.245149, Train Acc: 0.512821 | Val Loss: 0.253868, Val Acc: 0.474227\n",
      "Epoch 1272 - Train Loss: 0.245128, Train Acc: 0.512821 | Val Loss: 0.253847, Val Acc: 0.474227\n",
      "Epoch 1273 - Train Loss: 0.245107, Train Acc: 0.512821 | Val Loss: 0.253827, Val Acc: 0.474227\n",
      "Epoch 1274 - Train Loss: 0.245085, Train Acc: 0.512821 | Val Loss: 0.253806, Val Acc: 0.474227\n",
      "Epoch 1275 - Train Loss: 0.245064, Train Acc: 0.512821 | Val Loss: 0.253786, Val Acc: 0.474227\n",
      "Epoch 1276 - Train Loss: 0.245043, Train Acc: 0.512821 | Val Loss: 0.253765, Val Acc: 0.474227\n",
      "Epoch 1277 - Train Loss: 0.245021, Train Acc: 0.512821 | Val Loss: 0.253745, Val Acc: 0.474227\n",
      "Epoch 1278 - Train Loss: 0.245000, Train Acc: 0.512821 | Val Loss: 0.253724, Val Acc: 0.474227\n",
      "Epoch 1279 - Train Loss: 0.244979, Train Acc: 0.512821 | Val Loss: 0.253704, Val Acc: 0.474227\n",
      "Epoch 1280 - Train Loss: 0.244958, Train Acc: 0.512821 | Val Loss: 0.253683, Val Acc: 0.474227\n",
      "Epoch 1281 - Train Loss: 0.244936, Train Acc: 0.512821 | Val Loss: 0.253663, Val Acc: 0.474227\n",
      "Epoch 1282 - Train Loss: 0.244915, Train Acc: 0.512821 | Val Loss: 0.253642, Val Acc: 0.474227\n",
      "Epoch 1283 - Train Loss: 0.244894, Train Acc: 0.512821 | Val Loss: 0.253622, Val Acc: 0.474227\n",
      "Epoch 1284 - Train Loss: 0.244872, Train Acc: 0.512821 | Val Loss: 0.253601, Val Acc: 0.474227\n",
      "Epoch 1285 - Train Loss: 0.244851, Train Acc: 0.512821 | Val Loss: 0.253581, Val Acc: 0.474227\n",
      "Epoch 1286 - Train Loss: 0.244830, Train Acc: 0.512821 | Val Loss: 0.253560, Val Acc: 0.474227\n",
      "Epoch 1287 - Train Loss: 0.244809, Train Acc: 0.512821 | Val Loss: 0.253540, Val Acc: 0.474227\n",
      "Epoch 1288 - Train Loss: 0.244787, Train Acc: 0.512821 | Val Loss: 0.253519, Val Acc: 0.474227\n",
      "Epoch 1289 - Train Loss: 0.244766, Train Acc: 0.512821 | Val Loss: 0.253499, Val Acc: 0.474227\n",
      "Epoch 1290 - Train Loss: 0.244745, Train Acc: 0.512821 | Val Loss: 0.253478, Val Acc: 0.474227\n",
      "Epoch 1291 - Train Loss: 0.244723, Train Acc: 0.512821 | Val Loss: 0.253458, Val Acc: 0.474227\n",
      "Epoch 1292 - Train Loss: 0.244702, Train Acc: 0.512821 | Val Loss: 0.253437, Val Acc: 0.474227\n",
      "Epoch 1293 - Train Loss: 0.244681, Train Acc: 0.512821 | Val Loss: 0.253417, Val Acc: 0.474227\n",
      "Epoch 1294 - Train Loss: 0.244659, Train Acc: 0.512821 | Val Loss: 0.253396, Val Acc: 0.474227\n",
      "Epoch 1295 - Train Loss: 0.244638, Train Acc: 0.512821 | Val Loss: 0.253375, Val Acc: 0.474227\n",
      "Epoch 1296 - Train Loss: 0.244617, Train Acc: 0.514103 | Val Loss: 0.253355, Val Acc: 0.474227\n",
      "Epoch 1297 - Train Loss: 0.244595, Train Acc: 0.514103 | Val Loss: 0.253334, Val Acc: 0.474227\n",
      "Epoch 1298 - Train Loss: 0.244574, Train Acc: 0.514103 | Val Loss: 0.253314, Val Acc: 0.474227\n",
      "Epoch 1299 - Train Loss: 0.244553, Train Acc: 0.514103 | Val Loss: 0.253293, Val Acc: 0.474227\n",
      "Epoch 1300 - Train Loss: 0.244531, Train Acc: 0.514103 | Val Loss: 0.253273, Val Acc: 0.474227\n",
      "Epoch 1301 - Train Loss: 0.244510, Train Acc: 0.514103 | Val Loss: 0.253252, Val Acc: 0.474227\n",
      "Epoch 1302 - Train Loss: 0.244489, Train Acc: 0.515385 | Val Loss: 0.253232, Val Acc: 0.474227\n",
      "Epoch 1303 - Train Loss: 0.244467, Train Acc: 0.515385 | Val Loss: 0.253211, Val Acc: 0.474227\n",
      "Epoch 1304 - Train Loss: 0.244446, Train Acc: 0.515385 | Val Loss: 0.253191, Val Acc: 0.474227\n",
      "Epoch 1305 - Train Loss: 0.244425, Train Acc: 0.515385 | Val Loss: 0.253170, Val Acc: 0.474227\n",
      "Epoch 1306 - Train Loss: 0.244403, Train Acc: 0.515385 | Val Loss: 0.253149, Val Acc: 0.474227\n",
      "Epoch 1307 - Train Loss: 0.244382, Train Acc: 0.515385 | Val Loss: 0.253129, Val Acc: 0.474227\n",
      "Epoch 1308 - Train Loss: 0.244361, Train Acc: 0.515385 | Val Loss: 0.253108, Val Acc: 0.474227\n",
      "Epoch 1309 - Train Loss: 0.244339, Train Acc: 0.515385 | Val Loss: 0.253088, Val Acc: 0.474227\n",
      "Epoch 1310 - Train Loss: 0.244318, Train Acc: 0.515385 | Val Loss: 0.253067, Val Acc: 0.474227\n",
      "Epoch 1311 - Train Loss: 0.244297, Train Acc: 0.515385 | Val Loss: 0.253046, Val Acc: 0.474227\n",
      "Epoch 1312 - Train Loss: 0.244275, Train Acc: 0.515385 | Val Loss: 0.253026, Val Acc: 0.474227\n",
      "Epoch 1313 - Train Loss: 0.244254, Train Acc: 0.515385 | Val Loss: 0.253005, Val Acc: 0.474227\n",
      "Epoch 1314 - Train Loss: 0.244233, Train Acc: 0.515385 | Val Loss: 0.252985, Val Acc: 0.474227\n",
      "Epoch 1315 - Train Loss: 0.244211, Train Acc: 0.515385 | Val Loss: 0.252964, Val Acc: 0.474227\n",
      "Epoch 1316 - Train Loss: 0.244190, Train Acc: 0.515385 | Val Loss: 0.252944, Val Acc: 0.474227\n",
      "Epoch 1317 - Train Loss: 0.244169, Train Acc: 0.515385 | Val Loss: 0.252923, Val Acc: 0.474227\n",
      "Epoch 1318 - Train Loss: 0.244147, Train Acc: 0.515385 | Val Loss: 0.252902, Val Acc: 0.474227\n",
      "Epoch 1319 - Train Loss: 0.244126, Train Acc: 0.515385 | Val Loss: 0.252882, Val Acc: 0.474227\n",
      "Epoch 1320 - Train Loss: 0.244105, Train Acc: 0.515385 | Val Loss: 0.252861, Val Acc: 0.474227\n",
      "Epoch 1321 - Train Loss: 0.244083, Train Acc: 0.515385 | Val Loss: 0.252840, Val Acc: 0.474227\n",
      "Epoch 1322 - Train Loss: 0.244062, Train Acc: 0.515385 | Val Loss: 0.252820, Val Acc: 0.474227\n",
      "Epoch 1323 - Train Loss: 0.244040, Train Acc: 0.515385 | Val Loss: 0.252799, Val Acc: 0.474227\n",
      "Epoch 1324 - Train Loss: 0.244019, Train Acc: 0.515385 | Val Loss: 0.252779, Val Acc: 0.474227\n",
      "Epoch 1325 - Train Loss: 0.243998, Train Acc: 0.515385 | Val Loss: 0.252758, Val Acc: 0.474227\n",
      "Epoch 1326 - Train Loss: 0.243976, Train Acc: 0.515385 | Val Loss: 0.252737, Val Acc: 0.474227\n",
      "Epoch 1327 - Train Loss: 0.243955, Train Acc: 0.515385 | Val Loss: 0.252717, Val Acc: 0.474227\n",
      "Epoch 1328 - Train Loss: 0.243933, Train Acc: 0.515385 | Val Loss: 0.252696, Val Acc: 0.474227\n",
      "Epoch 1329 - Train Loss: 0.243912, Train Acc: 0.515385 | Val Loss: 0.252675, Val Acc: 0.474227\n",
      "Epoch 1330 - Train Loss: 0.243891, Train Acc: 0.515385 | Val Loss: 0.252655, Val Acc: 0.474227\n",
      "Epoch 1331 - Train Loss: 0.243869, Train Acc: 0.515385 | Val Loss: 0.252634, Val Acc: 0.474227\n",
      "Epoch 1332 - Train Loss: 0.243848, Train Acc: 0.515385 | Val Loss: 0.252613, Val Acc: 0.474227\n",
      "Epoch 1333 - Train Loss: 0.243826, Train Acc: 0.515385 | Val Loss: 0.252593, Val Acc: 0.474227\n",
      "Epoch 1334 - Train Loss: 0.243805, Train Acc: 0.515385 | Val Loss: 0.252572, Val Acc: 0.474227\n",
      "Epoch 1335 - Train Loss: 0.243784, Train Acc: 0.515385 | Val Loss: 0.252551, Val Acc: 0.474227\n",
      "Epoch 1336 - Train Loss: 0.243762, Train Acc: 0.515385 | Val Loss: 0.252531, Val Acc: 0.474227\n",
      "Epoch 1337 - Train Loss: 0.243741, Train Acc: 0.515385 | Val Loss: 0.252510, Val Acc: 0.474227\n",
      "Epoch 1338 - Train Loss: 0.243719, Train Acc: 0.516667 | Val Loss: 0.252489, Val Acc: 0.474227\n",
      "Epoch 1339 - Train Loss: 0.243698, Train Acc: 0.516667 | Val Loss: 0.252469, Val Acc: 0.474227\n",
      "Epoch 1340 - Train Loss: 0.243676, Train Acc: 0.516667 | Val Loss: 0.252448, Val Acc: 0.474227\n",
      "Epoch 1341 - Train Loss: 0.243655, Train Acc: 0.516667 | Val Loss: 0.252427, Val Acc: 0.474227\n",
      "Epoch 1342 - Train Loss: 0.243634, Train Acc: 0.516667 | Val Loss: 0.252407, Val Acc: 0.474227\n",
      "Epoch 1343 - Train Loss: 0.243612, Train Acc: 0.516667 | Val Loss: 0.252386, Val Acc: 0.474227\n",
      "Epoch 1344 - Train Loss: 0.243591, Train Acc: 0.516667 | Val Loss: 0.252365, Val Acc: 0.474227\n",
      "Epoch 1345 - Train Loss: 0.243569, Train Acc: 0.516667 | Val Loss: 0.252345, Val Acc: 0.474227\n",
      "Epoch 1346 - Train Loss: 0.243548, Train Acc: 0.516667 | Val Loss: 0.252324, Val Acc: 0.474227\n",
      "Epoch 1347 - Train Loss: 0.243526, Train Acc: 0.516667 | Val Loss: 0.252303, Val Acc: 0.474227\n",
      "Epoch 1348 - Train Loss: 0.243505, Train Acc: 0.516667 | Val Loss: 0.252282, Val Acc: 0.474227\n",
      "Epoch 1349 - Train Loss: 0.243484, Train Acc: 0.516667 | Val Loss: 0.252262, Val Acc: 0.474227\n",
      "Epoch 1350 - Train Loss: 0.243462, Train Acc: 0.516667 | Val Loss: 0.252241, Val Acc: 0.474227\n",
      "Epoch 1351 - Train Loss: 0.243441, Train Acc: 0.516667 | Val Loss: 0.252220, Val Acc: 0.474227\n",
      "Epoch 1352 - Train Loss: 0.243419, Train Acc: 0.516667 | Val Loss: 0.252199, Val Acc: 0.474227\n",
      "Epoch 1353 - Train Loss: 0.243398, Train Acc: 0.516667 | Val Loss: 0.252179, Val Acc: 0.474227\n",
      "Epoch 1354 - Train Loss: 0.243376, Train Acc: 0.516667 | Val Loss: 0.252158, Val Acc: 0.474227\n",
      "Epoch 1355 - Train Loss: 0.243355, Train Acc: 0.516667 | Val Loss: 0.252137, Val Acc: 0.474227\n",
      "Epoch 1356 - Train Loss: 0.243333, Train Acc: 0.516667 | Val Loss: 0.252116, Val Acc: 0.474227\n",
      "Epoch 1357 - Train Loss: 0.243312, Train Acc: 0.516667 | Val Loss: 0.252096, Val Acc: 0.474227\n",
      "Epoch 1358 - Train Loss: 0.243290, Train Acc: 0.516667 | Val Loss: 0.252075, Val Acc: 0.474227\n",
      "Epoch 1359 - Train Loss: 0.243269, Train Acc: 0.516667 | Val Loss: 0.252054, Val Acc: 0.474227\n",
      "Epoch 1360 - Train Loss: 0.243247, Train Acc: 0.516667 | Val Loss: 0.252033, Val Acc: 0.474227\n",
      "Epoch 1361 - Train Loss: 0.243226, Train Acc: 0.516667 | Val Loss: 0.252012, Val Acc: 0.474227\n",
      "Epoch 1362 - Train Loss: 0.243205, Train Acc: 0.516667 | Val Loss: 0.251992, Val Acc: 0.474227\n",
      "Epoch 1363 - Train Loss: 0.243183, Train Acc: 0.516667 | Val Loss: 0.251971, Val Acc: 0.474227\n",
      "Epoch 1364 - Train Loss: 0.243162, Train Acc: 0.516667 | Val Loss: 0.251950, Val Acc: 0.474227\n",
      "Epoch 1365 - Train Loss: 0.243140, Train Acc: 0.516667 | Val Loss: 0.251929, Val Acc: 0.474227\n",
      "Epoch 1366 - Train Loss: 0.243119, Train Acc: 0.516667 | Val Loss: 0.251909, Val Acc: 0.474227\n",
      "Epoch 1367 - Train Loss: 0.243097, Train Acc: 0.516667 | Val Loss: 0.251888, Val Acc: 0.474227\n",
      "Epoch 1368 - Train Loss: 0.243076, Train Acc: 0.517949 | Val Loss: 0.251867, Val Acc: 0.474227\n",
      "Epoch 1369 - Train Loss: 0.243054, Train Acc: 0.517949 | Val Loss: 0.251846, Val Acc: 0.474227\n",
      "Epoch 1370 - Train Loss: 0.243033, Train Acc: 0.517949 | Val Loss: 0.251825, Val Acc: 0.474227\n",
      "Epoch 1371 - Train Loss: 0.243011, Train Acc: 0.517949 | Val Loss: 0.251805, Val Acc: 0.474227\n",
      "Epoch 1372 - Train Loss: 0.242990, Train Acc: 0.517949 | Val Loss: 0.251784, Val Acc: 0.474227\n",
      "Epoch 1373 - Train Loss: 0.242968, Train Acc: 0.517949 | Val Loss: 0.251763, Val Acc: 0.474227\n",
      "Epoch 1374 - Train Loss: 0.242947, Train Acc: 0.519231 | Val Loss: 0.251742, Val Acc: 0.474227\n",
      "Epoch 1375 - Train Loss: 0.242925, Train Acc: 0.519231 | Val Loss: 0.251721, Val Acc: 0.474227\n",
      "Epoch 1376 - Train Loss: 0.242904, Train Acc: 0.519231 | Val Loss: 0.251700, Val Acc: 0.474227\n",
      "Epoch 1377 - Train Loss: 0.242882, Train Acc: 0.519231 | Val Loss: 0.251680, Val Acc: 0.474227\n",
      "Epoch 1378 - Train Loss: 0.242861, Train Acc: 0.519231 | Val Loss: 0.251659, Val Acc: 0.474227\n",
      "Epoch 1379 - Train Loss: 0.242839, Train Acc: 0.519231 | Val Loss: 0.251638, Val Acc: 0.474227\n",
      "Epoch 1380 - Train Loss: 0.242818, Train Acc: 0.519231 | Val Loss: 0.251617, Val Acc: 0.474227\n",
      "Epoch 1381 - Train Loss: 0.242796, Train Acc: 0.519231 | Val Loss: 0.251596, Val Acc: 0.474227\n",
      "Epoch 1382 - Train Loss: 0.242775, Train Acc: 0.520513 | Val Loss: 0.251576, Val Acc: 0.474227\n",
      "Epoch 1383 - Train Loss: 0.242753, Train Acc: 0.520513 | Val Loss: 0.251555, Val Acc: 0.474227\n",
      "Epoch 1384 - Train Loss: 0.242732, Train Acc: 0.520513 | Val Loss: 0.251534, Val Acc: 0.474227\n",
      "Epoch 1385 - Train Loss: 0.242710, Train Acc: 0.520513 | Val Loss: 0.251513, Val Acc: 0.474227\n",
      "Epoch 1386 - Train Loss: 0.242689, Train Acc: 0.520513 | Val Loss: 0.251492, Val Acc: 0.474227\n",
      "Epoch 1387 - Train Loss: 0.242667, Train Acc: 0.520513 | Val Loss: 0.251471, Val Acc: 0.474227\n",
      "Epoch 1388 - Train Loss: 0.242646, Train Acc: 0.520513 | Val Loss: 0.251450, Val Acc: 0.474227\n",
      "Epoch 1389 - Train Loss: 0.242624, Train Acc: 0.520513 | Val Loss: 0.251430, Val Acc: 0.474227\n",
      "Epoch 1390 - Train Loss: 0.242603, Train Acc: 0.520513 | Val Loss: 0.251409, Val Acc: 0.474227\n",
      "Epoch 1391 - Train Loss: 0.242581, Train Acc: 0.520513 | Val Loss: 0.251388, Val Acc: 0.474227\n",
      "Epoch 1392 - Train Loss: 0.242560, Train Acc: 0.520513 | Val Loss: 0.251367, Val Acc: 0.474227\n",
      "Epoch 1393 - Train Loss: 0.242538, Train Acc: 0.520513 | Val Loss: 0.251346, Val Acc: 0.474227\n",
      "Epoch 1394 - Train Loss: 0.242517, Train Acc: 0.520513 | Val Loss: 0.251325, Val Acc: 0.474227\n",
      "Epoch 1395 - Train Loss: 0.242495, Train Acc: 0.520513 | Val Loss: 0.251305, Val Acc: 0.474227\n",
      "Epoch 1396 - Train Loss: 0.242474, Train Acc: 0.520513 | Val Loss: 0.251284, Val Acc: 0.474227\n",
      "Epoch 1397 - Train Loss: 0.242452, Train Acc: 0.520513 | Val Loss: 0.251263, Val Acc: 0.474227\n",
      "Epoch 1398 - Train Loss: 0.242430, Train Acc: 0.520513 | Val Loss: 0.251242, Val Acc: 0.474227\n",
      "Epoch 1399 - Train Loss: 0.242409, Train Acc: 0.520513 | Val Loss: 0.251221, Val Acc: 0.474227\n",
      "Epoch 1400 - Train Loss: 0.242387, Train Acc: 0.520513 | Val Loss: 0.251200, Val Acc: 0.474227\n",
      "Epoch 1401 - Train Loss: 0.242366, Train Acc: 0.520513 | Val Loss: 0.251179, Val Acc: 0.474227\n",
      "Epoch 1402 - Train Loss: 0.242344, Train Acc: 0.520513 | Val Loss: 0.251159, Val Acc: 0.474227\n",
      "Epoch 1403 - Train Loss: 0.242323, Train Acc: 0.520513 | Val Loss: 0.251138, Val Acc: 0.474227\n",
      "Epoch 1404 - Train Loss: 0.242301, Train Acc: 0.520513 | Val Loss: 0.251117, Val Acc: 0.474227\n",
      "Epoch 1405 - Train Loss: 0.242280, Train Acc: 0.520513 | Val Loss: 0.251096, Val Acc: 0.474227\n",
      "Epoch 1406 - Train Loss: 0.242258, Train Acc: 0.520513 | Val Loss: 0.251075, Val Acc: 0.474227\n",
      "Epoch 1407 - Train Loss: 0.242237, Train Acc: 0.520513 | Val Loss: 0.251054, Val Acc: 0.474227\n",
      "Epoch 1408 - Train Loss: 0.242215, Train Acc: 0.520513 | Val Loss: 0.251033, Val Acc: 0.474227\n",
      "Epoch 1409 - Train Loss: 0.242193, Train Acc: 0.520513 | Val Loss: 0.251013, Val Acc: 0.474227\n",
      "Epoch 1410 - Train Loss: 0.242172, Train Acc: 0.520513 | Val Loss: 0.250992, Val Acc: 0.474227\n",
      "Epoch 1411 - Train Loss: 0.242150, Train Acc: 0.520513 | Val Loss: 0.250971, Val Acc: 0.474227\n",
      "Epoch 1412 - Train Loss: 0.242129, Train Acc: 0.520513 | Val Loss: 0.250950, Val Acc: 0.474227\n",
      "Epoch 1413 - Train Loss: 0.242107, Train Acc: 0.520513 | Val Loss: 0.250929, Val Acc: 0.474227\n",
      "Epoch 1414 - Train Loss: 0.242086, Train Acc: 0.520513 | Val Loss: 0.250908, Val Acc: 0.474227\n",
      "Epoch 1415 - Train Loss: 0.242064, Train Acc: 0.520513 | Val Loss: 0.250887, Val Acc: 0.474227\n",
      "Epoch 1416 - Train Loss: 0.242042, Train Acc: 0.520513 | Val Loss: 0.250866, Val Acc: 0.474227\n",
      "Epoch 1417 - Train Loss: 0.242021, Train Acc: 0.520513 | Val Loss: 0.250845, Val Acc: 0.474227\n",
      "Epoch 1418 - Train Loss: 0.241999, Train Acc: 0.520513 | Val Loss: 0.250824, Val Acc: 0.474227\n",
      "Epoch 1419 - Train Loss: 0.241978, Train Acc: 0.520513 | Val Loss: 0.250803, Val Acc: 0.474227\n",
      "Epoch 1420 - Train Loss: 0.241956, Train Acc: 0.520513 | Val Loss: 0.250782, Val Acc: 0.474227\n",
      "Epoch 1421 - Train Loss: 0.241934, Train Acc: 0.520513 | Val Loss: 0.250762, Val Acc: 0.474227\n",
      "Epoch 1422 - Train Loss: 0.241913, Train Acc: 0.520513 | Val Loss: 0.250741, Val Acc: 0.474227\n",
      "Epoch 1423 - Train Loss: 0.241891, Train Acc: 0.520513 | Val Loss: 0.250720, Val Acc: 0.474227\n",
      "Epoch 1424 - Train Loss: 0.241870, Train Acc: 0.520513 | Val Loss: 0.250699, Val Acc: 0.474227\n",
      "Epoch 1425 - Train Loss: 0.241848, Train Acc: 0.520513 | Val Loss: 0.250678, Val Acc: 0.474227\n",
      "Epoch 1426 - Train Loss: 0.241826, Train Acc: 0.520513 | Val Loss: 0.250657, Val Acc: 0.474227\n",
      "Epoch 1427 - Train Loss: 0.241805, Train Acc: 0.520513 | Val Loss: 0.250636, Val Acc: 0.474227\n",
      "Epoch 1428 - Train Loss: 0.241783, Train Acc: 0.520513 | Val Loss: 0.250615, Val Acc: 0.474227\n",
      "Epoch 1429 - Train Loss: 0.241762, Train Acc: 0.520513 | Val Loss: 0.250594, Val Acc: 0.474227\n",
      "Epoch 1430 - Train Loss: 0.241740, Train Acc: 0.520513 | Val Loss: 0.250573, Val Acc: 0.474227\n",
      "Epoch 1431 - Train Loss: 0.241718, Train Acc: 0.520513 | Val Loss: 0.250552, Val Acc: 0.474227\n",
      "Epoch 1432 - Train Loss: 0.241697, Train Acc: 0.520513 | Val Loss: 0.250531, Val Acc: 0.474227\n",
      "Epoch 1433 - Train Loss: 0.241675, Train Acc: 0.520513 | Val Loss: 0.250510, Val Acc: 0.474227\n",
      "Epoch 1434 - Train Loss: 0.241654, Train Acc: 0.520513 | Val Loss: 0.250489, Val Acc: 0.474227\n",
      "Epoch 1435 - Train Loss: 0.241632, Train Acc: 0.520513 | Val Loss: 0.250468, Val Acc: 0.474227\n",
      "Epoch 1436 - Train Loss: 0.241610, Train Acc: 0.520513 | Val Loss: 0.250447, Val Acc: 0.474227\n",
      "Epoch 1437 - Train Loss: 0.241589, Train Acc: 0.520513 | Val Loss: 0.250426, Val Acc: 0.474227\n",
      "Epoch 1438 - Train Loss: 0.241567, Train Acc: 0.520513 | Val Loss: 0.250405, Val Acc: 0.474227\n",
      "Epoch 1439 - Train Loss: 0.241546, Train Acc: 0.520513 | Val Loss: 0.250384, Val Acc: 0.474227\n",
      "Epoch 1440 - Train Loss: 0.241524, Train Acc: 0.520513 | Val Loss: 0.250363, Val Acc: 0.474227\n",
      "Epoch 1441 - Train Loss: 0.241502, Train Acc: 0.520513 | Val Loss: 0.250342, Val Acc: 0.474227\n",
      "Epoch 1442 - Train Loss: 0.241481, Train Acc: 0.520513 | Val Loss: 0.250321, Val Acc: 0.474227\n",
      "Epoch 1443 - Train Loss: 0.241459, Train Acc: 0.520513 | Val Loss: 0.250300, Val Acc: 0.474227\n",
      "Epoch 1444 - Train Loss: 0.241437, Train Acc: 0.520513 | Val Loss: 0.250279, Val Acc: 0.474227\n",
      "Epoch 1445 - Train Loss: 0.241416, Train Acc: 0.520513 | Val Loss: 0.250258, Val Acc: 0.474227\n",
      "Epoch 1446 - Train Loss: 0.241394, Train Acc: 0.520513 | Val Loss: 0.250237, Val Acc: 0.474227\n",
      "Epoch 1447 - Train Loss: 0.241373, Train Acc: 0.520513 | Val Loss: 0.250216, Val Acc: 0.474227\n",
      "Epoch 1448 - Train Loss: 0.241351, Train Acc: 0.520513 | Val Loss: 0.250195, Val Acc: 0.474227\n",
      "Epoch 1449 - Train Loss: 0.241329, Train Acc: 0.520513 | Val Loss: 0.250174, Val Acc: 0.474227\n",
      "Epoch 1450 - Train Loss: 0.241308, Train Acc: 0.520513 | Val Loss: 0.250153, Val Acc: 0.474227\n",
      "Epoch 1451 - Train Loss: 0.241286, Train Acc: 0.520513 | Val Loss: 0.250132, Val Acc: 0.474227\n",
      "Epoch 1452 - Train Loss: 0.241264, Train Acc: 0.520513 | Val Loss: 0.250111, Val Acc: 0.474227\n",
      "Epoch 1453 - Train Loss: 0.241243, Train Acc: 0.520513 | Val Loss: 0.250090, Val Acc: 0.474227\n",
      "Epoch 1454 - Train Loss: 0.241221, Train Acc: 0.520513 | Val Loss: 0.250069, Val Acc: 0.474227\n",
      "Epoch 1455 - Train Loss: 0.241199, Train Acc: 0.520513 | Val Loss: 0.250048, Val Acc: 0.474227\n",
      "Epoch 1456 - Train Loss: 0.241178, Train Acc: 0.520513 | Val Loss: 0.250027, Val Acc: 0.474227\n",
      "Epoch 1457 - Train Loss: 0.241156, Train Acc: 0.520513 | Val Loss: 0.250006, Val Acc: 0.474227\n",
      "Epoch 1458 - Train Loss: 0.241135, Train Acc: 0.520513 | Val Loss: 0.249985, Val Acc: 0.474227\n",
      "Epoch 1459 - Train Loss: 0.241113, Train Acc: 0.520513 | Val Loss: 0.249964, Val Acc: 0.474227\n",
      "Epoch 1460 - Train Loss: 0.241091, Train Acc: 0.520513 | Val Loss: 0.249943, Val Acc: 0.474227\n",
      "Epoch 1461 - Train Loss: 0.241070, Train Acc: 0.520513 | Val Loss: 0.249922, Val Acc: 0.474227\n",
      "Epoch 1462 - Train Loss: 0.241048, Train Acc: 0.520513 | Val Loss: 0.249901, Val Acc: 0.474227\n",
      "Epoch 1463 - Train Loss: 0.241026, Train Acc: 0.520513 | Val Loss: 0.249879, Val Acc: 0.474227\n",
      "Epoch 1464 - Train Loss: 0.241005, Train Acc: 0.520513 | Val Loss: 0.249858, Val Acc: 0.474227\n",
      "Epoch 1465 - Train Loss: 0.240983, Train Acc: 0.520513 | Val Loss: 0.249837, Val Acc: 0.474227\n",
      "Epoch 1466 - Train Loss: 0.240961, Train Acc: 0.520513 | Val Loss: 0.249816, Val Acc: 0.474227\n",
      "Epoch 1467 - Train Loss: 0.240940, Train Acc: 0.521795 | Val Loss: 0.249795, Val Acc: 0.474227\n",
      "Epoch 1468 - Train Loss: 0.240918, Train Acc: 0.521795 | Val Loss: 0.249774, Val Acc: 0.474227\n",
      "Epoch 1469 - Train Loss: 0.240896, Train Acc: 0.521795 | Val Loss: 0.249753, Val Acc: 0.474227\n",
      "Epoch 1470 - Train Loss: 0.240874, Train Acc: 0.521795 | Val Loss: 0.249732, Val Acc: 0.474227\n",
      "Epoch 1471 - Train Loss: 0.240853, Train Acc: 0.521795 | Val Loss: 0.249711, Val Acc: 0.474227\n",
      "Epoch 1472 - Train Loss: 0.240831, Train Acc: 0.521795 | Val Loss: 0.249690, Val Acc: 0.474227\n",
      "Epoch 1473 - Train Loss: 0.240809, Train Acc: 0.521795 | Val Loss: 0.249669, Val Acc: 0.474227\n",
      "Epoch 1474 - Train Loss: 0.240788, Train Acc: 0.521795 | Val Loss: 0.249648, Val Acc: 0.474227\n",
      "Epoch 1475 - Train Loss: 0.240766, Train Acc: 0.521795 | Val Loss: 0.249626, Val Acc: 0.474227\n",
      "Epoch 1476 - Train Loss: 0.240744, Train Acc: 0.521795 | Val Loss: 0.249605, Val Acc: 0.474227\n",
      "Epoch 1477 - Train Loss: 0.240723, Train Acc: 0.521795 | Val Loss: 0.249584, Val Acc: 0.474227\n",
      "Epoch 1478 - Train Loss: 0.240701, Train Acc: 0.523077 | Val Loss: 0.249563, Val Acc: 0.474227\n",
      "Epoch 1479 - Train Loss: 0.240679, Train Acc: 0.523077 | Val Loss: 0.249542, Val Acc: 0.474227\n",
      "Epoch 1480 - Train Loss: 0.240658, Train Acc: 0.523077 | Val Loss: 0.249521, Val Acc: 0.474227\n",
      "Epoch 1481 - Train Loss: 0.240636, Train Acc: 0.523077 | Val Loss: 0.249500, Val Acc: 0.474227\n",
      "Epoch 1482 - Train Loss: 0.240614, Train Acc: 0.523077 | Val Loss: 0.249479, Val Acc: 0.474227\n",
      "Epoch 1483 - Train Loss: 0.240592, Train Acc: 0.523077 | Val Loss: 0.249458, Val Acc: 0.474227\n",
      "Epoch 1484 - Train Loss: 0.240571, Train Acc: 0.524359 | Val Loss: 0.249437, Val Acc: 0.474227\n",
      "Epoch 1485 - Train Loss: 0.240549, Train Acc: 0.524359 | Val Loss: 0.249416, Val Acc: 0.474227\n",
      "Epoch 1486 - Train Loss: 0.240527, Train Acc: 0.524359 | Val Loss: 0.249394, Val Acc: 0.474227\n",
      "Epoch 1487 - Train Loss: 0.240506, Train Acc: 0.524359 | Val Loss: 0.249373, Val Acc: 0.474227\n",
      "Epoch 1488 - Train Loss: 0.240484, Train Acc: 0.524359 | Val Loss: 0.249352, Val Acc: 0.474227\n",
      "Epoch 1489 - Train Loss: 0.240462, Train Acc: 0.524359 | Val Loss: 0.249331, Val Acc: 0.474227\n",
      "Epoch 1490 - Train Loss: 0.240441, Train Acc: 0.524359 | Val Loss: 0.249310, Val Acc: 0.474227\n",
      "Epoch 1491 - Train Loss: 0.240419, Train Acc: 0.524359 | Val Loss: 0.249289, Val Acc: 0.474227\n",
      "Epoch 1492 - Train Loss: 0.240397, Train Acc: 0.524359 | Val Loss: 0.249268, Val Acc: 0.474227\n",
      "Epoch 1493 - Train Loss: 0.240376, Train Acc: 0.524359 | Val Loss: 0.249247, Val Acc: 0.474227\n",
      "Epoch 1494 - Train Loss: 0.240354, Train Acc: 0.524359 | Val Loss: 0.249225, Val Acc: 0.474227\n",
      "Epoch 1495 - Train Loss: 0.240332, Train Acc: 0.524359 | Val Loss: 0.249204, Val Acc: 0.474227\n",
      "Epoch 1496 - Train Loss: 0.240310, Train Acc: 0.524359 | Val Loss: 0.249183, Val Acc: 0.474227\n",
      "Epoch 1497 - Train Loss: 0.240289, Train Acc: 0.524359 | Val Loss: 0.249162, Val Acc: 0.474227\n",
      "Epoch 1498 - Train Loss: 0.240267, Train Acc: 0.524359 | Val Loss: 0.249141, Val Acc: 0.474227\n",
      "Epoch 1499 - Train Loss: 0.240245, Train Acc: 0.524359 | Val Loss: 0.249120, Val Acc: 0.474227\n",
      "Epoch 1500 - Train Loss: 0.240224, Train Acc: 0.524359 | Val Loss: 0.249099, Val Acc: 0.474227\n",
      "Epoch 1501 - Train Loss: 0.240202, Train Acc: 0.524359 | Val Loss: 0.249078, Val Acc: 0.474227\n",
      "Epoch 1502 - Train Loss: 0.240180, Train Acc: 0.524359 | Val Loss: 0.249057, Val Acc: 0.474227\n",
      "Epoch 1503 - Train Loss: 0.240159, Train Acc: 0.524359 | Val Loss: 0.249036, Val Acc: 0.474227\n",
      "Epoch 1504 - Train Loss: 0.240137, Train Acc: 0.524359 | Val Loss: 0.249015, Val Acc: 0.474227\n",
      "Epoch 1505 - Train Loss: 0.240115, Train Acc: 0.524359 | Val Loss: 0.248994, Val Acc: 0.474227\n",
      "Epoch 1506 - Train Loss: 0.240093, Train Acc: 0.524359 | Val Loss: 0.248973, Val Acc: 0.474227\n",
      "Epoch 1507 - Train Loss: 0.240072, Train Acc: 0.525641 | Val Loss: 0.248951, Val Acc: 0.474227\n",
      "Epoch 1508 - Train Loss: 0.240050, Train Acc: 0.525641 | Val Loss: 0.248930, Val Acc: 0.474227\n",
      "Epoch 1509 - Train Loss: 0.240028, Train Acc: 0.525641 | Val Loss: 0.248909, Val Acc: 0.474227\n",
      "Epoch 1510 - Train Loss: 0.240007, Train Acc: 0.525641 | Val Loss: 0.248888, Val Acc: 0.474227\n",
      "Epoch 1511 - Train Loss: 0.239985, Train Acc: 0.525641 | Val Loss: 0.248867, Val Acc: 0.474227\n",
      "Epoch 1512 - Train Loss: 0.239963, Train Acc: 0.525641 | Val Loss: 0.248846, Val Acc: 0.474227\n",
      "Epoch 1513 - Train Loss: 0.239941, Train Acc: 0.525641 | Val Loss: 0.248825, Val Acc: 0.474227\n",
      "Epoch 1514 - Train Loss: 0.239920, Train Acc: 0.525641 | Val Loss: 0.248804, Val Acc: 0.474227\n",
      "Epoch 1515 - Train Loss: 0.239898, Train Acc: 0.525641 | Val Loss: 0.248783, Val Acc: 0.474227\n",
      "Epoch 1516 - Train Loss: 0.239876, Train Acc: 0.525641 | Val Loss: 0.248762, Val Acc: 0.474227\n",
      "Epoch 1517 - Train Loss: 0.239854, Train Acc: 0.525641 | Val Loss: 0.248741, Val Acc: 0.474227\n",
      "Epoch 1518 - Train Loss: 0.239833, Train Acc: 0.525641 | Val Loss: 0.248720, Val Acc: 0.474227\n",
      "Epoch 1519 - Train Loss: 0.239811, Train Acc: 0.525641 | Val Loss: 0.248699, Val Acc: 0.474227\n",
      "Epoch 1520 - Train Loss: 0.239789, Train Acc: 0.525641 | Val Loss: 0.248678, Val Acc: 0.474227\n",
      "Epoch 1521 - Train Loss: 0.239768, Train Acc: 0.525641 | Val Loss: 0.248657, Val Acc: 0.474227\n",
      "Epoch 1522 - Train Loss: 0.239746, Train Acc: 0.525641 | Val Loss: 0.248636, Val Acc: 0.474227\n",
      "Epoch 1523 - Train Loss: 0.239724, Train Acc: 0.525641 | Val Loss: 0.248614, Val Acc: 0.474227\n",
      "Epoch 1524 - Train Loss: 0.239702, Train Acc: 0.525641 | Val Loss: 0.248593, Val Acc: 0.474227\n",
      "Epoch 1525 - Train Loss: 0.239681, Train Acc: 0.525641 | Val Loss: 0.248572, Val Acc: 0.474227\n",
      "Epoch 1526 - Train Loss: 0.239659, Train Acc: 0.525641 | Val Loss: 0.248551, Val Acc: 0.474227\n",
      "Epoch 1527 - Train Loss: 0.239637, Train Acc: 0.525641 | Val Loss: 0.248530, Val Acc: 0.474227\n",
      "Epoch 1528 - Train Loss: 0.239616, Train Acc: 0.525641 | Val Loss: 0.248509, Val Acc: 0.474227\n",
      "Epoch 1529 - Train Loss: 0.239594, Train Acc: 0.525641 | Val Loss: 0.248488, Val Acc: 0.474227\n",
      "Epoch 1530 - Train Loss: 0.239572, Train Acc: 0.525641 | Val Loss: 0.248467, Val Acc: 0.474227\n",
      "Epoch 1531 - Train Loss: 0.239550, Train Acc: 0.525641 | Val Loss: 0.248446, Val Acc: 0.474227\n",
      "Epoch 1532 - Train Loss: 0.239529, Train Acc: 0.525641 | Val Loss: 0.248425, Val Acc: 0.474227\n",
      "Epoch 1533 - Train Loss: 0.239507, Train Acc: 0.525641 | Val Loss: 0.248404, Val Acc: 0.474227\n",
      "Epoch 1534 - Train Loss: 0.239485, Train Acc: 0.525641 | Val Loss: 0.248383, Val Acc: 0.474227\n",
      "Epoch 1535 - Train Loss: 0.239463, Train Acc: 0.525641 | Val Loss: 0.248362, Val Acc: 0.474227\n",
      "Epoch 1536 - Train Loss: 0.239442, Train Acc: 0.525641 | Val Loss: 0.248341, Val Acc: 0.474227\n",
      "Epoch 1537 - Train Loss: 0.239420, Train Acc: 0.525641 | Val Loss: 0.248320, Val Acc: 0.474227\n",
      "Epoch 1538 - Train Loss: 0.239398, Train Acc: 0.525641 | Val Loss: 0.248299, Val Acc: 0.474227\n",
      "Epoch 1539 - Train Loss: 0.239376, Train Acc: 0.525641 | Val Loss: 0.248278, Val Acc: 0.474227\n",
      "Epoch 1540 - Train Loss: 0.239355, Train Acc: 0.525641 | Val Loss: 0.248256, Val Acc: 0.474227\n",
      "Epoch 1541 - Train Loss: 0.239333, Train Acc: 0.525641 | Val Loss: 0.248235, Val Acc: 0.474227\n",
      "Epoch 1542 - Train Loss: 0.239311, Train Acc: 0.525641 | Val Loss: 0.248214, Val Acc: 0.474227\n",
      "Epoch 1543 - Train Loss: 0.239290, Train Acc: 0.525641 | Val Loss: 0.248193, Val Acc: 0.474227\n",
      "Epoch 1544 - Train Loss: 0.239268, Train Acc: 0.525641 | Val Loss: 0.248172, Val Acc: 0.474227\n",
      "Epoch 1545 - Train Loss: 0.239246, Train Acc: 0.525641 | Val Loss: 0.248151, Val Acc: 0.474227\n",
      "Epoch 1546 - Train Loss: 0.239224, Train Acc: 0.525641 | Val Loss: 0.248130, Val Acc: 0.474227\n",
      "Epoch 1547 - Train Loss: 0.239203, Train Acc: 0.526923 | Val Loss: 0.248109, Val Acc: 0.474227\n",
      "Epoch 1548 - Train Loss: 0.239181, Train Acc: 0.526923 | Val Loss: 0.248088, Val Acc: 0.474227\n",
      "Epoch 1549 - Train Loss: 0.239159, Train Acc: 0.526923 | Val Loss: 0.248067, Val Acc: 0.474227\n",
      "Epoch 1550 - Train Loss: 0.239137, Train Acc: 0.526923 | Val Loss: 0.248046, Val Acc: 0.474227\n",
      "Epoch 1551 - Train Loss: 0.239116, Train Acc: 0.526923 | Val Loss: 0.248024, Val Acc: 0.474227\n",
      "Epoch 1552 - Train Loss: 0.239094, Train Acc: 0.526923 | Val Loss: 0.248003, Val Acc: 0.474227\n",
      "Epoch 1553 - Train Loss: 0.239072, Train Acc: 0.526923 | Val Loss: 0.247982, Val Acc: 0.474227\n",
      "Epoch 1554 - Train Loss: 0.239050, Train Acc: 0.526923 | Val Loss: 0.247961, Val Acc: 0.474227\n",
      "Epoch 1555 - Train Loss: 0.239029, Train Acc: 0.526923 | Val Loss: 0.247940, Val Acc: 0.474227\n",
      "Epoch 1556 - Train Loss: 0.239007, Train Acc: 0.526923 | Val Loss: 0.247919, Val Acc: 0.474227\n",
      "Epoch 1557 - Train Loss: 0.238985, Train Acc: 0.526923 | Val Loss: 0.247898, Val Acc: 0.474227\n",
      "Epoch 1558 - Train Loss: 0.238963, Train Acc: 0.526923 | Val Loss: 0.247877, Val Acc: 0.474227\n",
      "Epoch 1559 - Train Loss: 0.238942, Train Acc: 0.526923 | Val Loss: 0.247856, Val Acc: 0.474227\n",
      "Epoch 1560 - Train Loss: 0.238920, Train Acc: 0.526923 | Val Loss: 0.247835, Val Acc: 0.474227\n",
      "Epoch 1561 - Train Loss: 0.238898, Train Acc: 0.526923 | Val Loss: 0.247813, Val Acc: 0.474227\n",
      "Epoch 1562 - Train Loss: 0.238876, Train Acc: 0.526923 | Val Loss: 0.247792, Val Acc: 0.474227\n",
      "Epoch 1563 - Train Loss: 0.238855, Train Acc: 0.526923 | Val Loss: 0.247771, Val Acc: 0.474227\n",
      "Epoch 1564 - Train Loss: 0.238833, Train Acc: 0.526923 | Val Loss: 0.247750, Val Acc: 0.474227\n",
      "Epoch 1565 - Train Loss: 0.238811, Train Acc: 0.526923 | Val Loss: 0.247729, Val Acc: 0.474227\n",
      "Epoch 1566 - Train Loss: 0.238789, Train Acc: 0.526923 | Val Loss: 0.247708, Val Acc: 0.474227\n",
      "Epoch 1567 - Train Loss: 0.238768, Train Acc: 0.526923 | Val Loss: 0.247687, Val Acc: 0.474227\n",
      "Epoch 1568 - Train Loss: 0.238746, Train Acc: 0.526923 | Val Loss: 0.247666, Val Acc: 0.474227\n",
      "Epoch 1569 - Train Loss: 0.238724, Train Acc: 0.526923 | Val Loss: 0.247644, Val Acc: 0.474227\n",
      "Epoch 1570 - Train Loss: 0.238702, Train Acc: 0.526923 | Val Loss: 0.247623, Val Acc: 0.474227\n",
      "Epoch 1571 - Train Loss: 0.238681, Train Acc: 0.526923 | Val Loss: 0.247602, Val Acc: 0.474227\n",
      "Epoch 1572 - Train Loss: 0.238659, Train Acc: 0.526923 | Val Loss: 0.247581, Val Acc: 0.474227\n",
      "Epoch 1573 - Train Loss: 0.238637, Train Acc: 0.526923 | Val Loss: 0.247560, Val Acc: 0.474227\n",
      "Epoch 1574 - Train Loss: 0.238615, Train Acc: 0.526923 | Val Loss: 0.247539, Val Acc: 0.474227\n",
      "Epoch 1575 - Train Loss: 0.238594, Train Acc: 0.526923 | Val Loss: 0.247518, Val Acc: 0.474227\n",
      "Epoch 1576 - Train Loss: 0.238572, Train Acc: 0.526923 | Val Loss: 0.247496, Val Acc: 0.474227\n",
      "Epoch 1577 - Train Loss: 0.238550, Train Acc: 0.526923 | Val Loss: 0.247475, Val Acc: 0.474227\n",
      "Epoch 1578 - Train Loss: 0.238528, Train Acc: 0.526923 | Val Loss: 0.247454, Val Acc: 0.474227\n",
      "Epoch 1579 - Train Loss: 0.238506, Train Acc: 0.526923 | Val Loss: 0.247433, Val Acc: 0.474227\n",
      "Epoch 1580 - Train Loss: 0.238485, Train Acc: 0.526923 | Val Loss: 0.247412, Val Acc: 0.474227\n",
      "Epoch 1581 - Train Loss: 0.238463, Train Acc: 0.526923 | Val Loss: 0.247391, Val Acc: 0.474227\n",
      "Epoch 1582 - Train Loss: 0.238441, Train Acc: 0.526923 | Val Loss: 0.247370, Val Acc: 0.474227\n",
      "Epoch 1583 - Train Loss: 0.238419, Train Acc: 0.526923 | Val Loss: 0.247348, Val Acc: 0.474227\n",
      "Epoch 1584 - Train Loss: 0.238398, Train Acc: 0.526923 | Val Loss: 0.247327, Val Acc: 0.474227\n",
      "Epoch 1585 - Train Loss: 0.238376, Train Acc: 0.526923 | Val Loss: 0.247306, Val Acc: 0.474227\n",
      "Epoch 1586 - Train Loss: 0.238354, Train Acc: 0.526923 | Val Loss: 0.247285, Val Acc: 0.474227\n",
      "Epoch 1587 - Train Loss: 0.238332, Train Acc: 0.526923 | Val Loss: 0.247264, Val Acc: 0.474227\n",
      "Epoch 1588 - Train Loss: 0.238310, Train Acc: 0.526923 | Val Loss: 0.247243, Val Acc: 0.474227\n",
      "Epoch 1589 - Train Loss: 0.238289, Train Acc: 0.526923 | Val Loss: 0.247222, Val Acc: 0.474227\n",
      "Epoch 1590 - Train Loss: 0.238267, Train Acc: 0.526923 | Val Loss: 0.247200, Val Acc: 0.474227\n",
      "Epoch 1591 - Train Loss: 0.238245, Train Acc: 0.526923 | Val Loss: 0.247179, Val Acc: 0.474227\n",
      "Epoch 1592 - Train Loss: 0.238223, Train Acc: 0.526923 | Val Loss: 0.247158, Val Acc: 0.474227\n",
      "Epoch 1593 - Train Loss: 0.238201, Train Acc: 0.526923 | Val Loss: 0.247137, Val Acc: 0.474227\n",
      "Epoch 1594 - Train Loss: 0.238180, Train Acc: 0.526923 | Val Loss: 0.247116, Val Acc: 0.474227\n",
      "Epoch 1595 - Train Loss: 0.238158, Train Acc: 0.526923 | Val Loss: 0.247095, Val Acc: 0.474227\n",
      "Epoch 1596 - Train Loss: 0.238136, Train Acc: 0.526923 | Val Loss: 0.247074, Val Acc: 0.474227\n",
      "Epoch 1597 - Train Loss: 0.238114, Train Acc: 0.526923 | Val Loss: 0.247052, Val Acc: 0.474227\n",
      "Epoch 1598 - Train Loss: 0.238093, Train Acc: 0.526923 | Val Loss: 0.247031, Val Acc: 0.474227\n",
      "Epoch 1599 - Train Loss: 0.238071, Train Acc: 0.526923 | Val Loss: 0.247010, Val Acc: 0.474227\n",
      "Epoch 1600 - Train Loss: 0.238049, Train Acc: 0.526923 | Val Loss: 0.246989, Val Acc: 0.474227\n",
      "Epoch 1601 - Train Loss: 0.238027, Train Acc: 0.526923 | Val Loss: 0.246968, Val Acc: 0.474227\n",
      "Epoch 1602 - Train Loss: 0.238005, Train Acc: 0.526923 | Val Loss: 0.246947, Val Acc: 0.474227\n",
      "Epoch 1603 - Train Loss: 0.237984, Train Acc: 0.526923 | Val Loss: 0.246926, Val Acc: 0.474227\n",
      "Epoch 1604 - Train Loss: 0.237962, Train Acc: 0.526923 | Val Loss: 0.246904, Val Acc: 0.474227\n",
      "Epoch 1605 - Train Loss: 0.237940, Train Acc: 0.526923 | Val Loss: 0.246883, Val Acc: 0.474227\n",
      "Epoch 1606 - Train Loss: 0.237918, Train Acc: 0.526923 | Val Loss: 0.246862, Val Acc: 0.474227\n",
      "Epoch 1607 - Train Loss: 0.237896, Train Acc: 0.526923 | Val Loss: 0.246841, Val Acc: 0.474227\n",
      "Epoch 1608 - Train Loss: 0.237875, Train Acc: 0.528205 | Val Loss: 0.246820, Val Acc: 0.474227\n",
      "Epoch 1609 - Train Loss: 0.237853, Train Acc: 0.528205 | Val Loss: 0.246799, Val Acc: 0.474227\n",
      "Epoch 1610 - Train Loss: 0.237831, Train Acc: 0.528205 | Val Loss: 0.246777, Val Acc: 0.474227\n",
      "Epoch 1611 - Train Loss: 0.237809, Train Acc: 0.528205 | Val Loss: 0.246756, Val Acc: 0.474227\n",
      "Epoch 1612 - Train Loss: 0.237787, Train Acc: 0.528205 | Val Loss: 0.246735, Val Acc: 0.474227\n",
      "Epoch 1613 - Train Loss: 0.237766, Train Acc: 0.528205 | Val Loss: 0.246714, Val Acc: 0.474227\n",
      "Epoch 1614 - Train Loss: 0.237744, Train Acc: 0.529487 | Val Loss: 0.246693, Val Acc: 0.474227\n",
      "Epoch 1615 - Train Loss: 0.237722, Train Acc: 0.529487 | Val Loss: 0.246672, Val Acc: 0.474227\n",
      "Epoch 1616 - Train Loss: 0.237700, Train Acc: 0.529487 | Val Loss: 0.246650, Val Acc: 0.474227\n",
      "Epoch 1617 - Train Loss: 0.237678, Train Acc: 0.529487 | Val Loss: 0.246629, Val Acc: 0.474227\n",
      "Epoch 1618 - Train Loss: 0.237656, Train Acc: 0.529487 | Val Loss: 0.246608, Val Acc: 0.474227\n",
      "Epoch 1619 - Train Loss: 0.237635, Train Acc: 0.529487 | Val Loss: 0.246587, Val Acc: 0.474227\n",
      "Epoch 1620 - Train Loss: 0.237613, Train Acc: 0.529487 | Val Loss: 0.246566, Val Acc: 0.474227\n",
      "Epoch 1621 - Train Loss: 0.237591, Train Acc: 0.529487 | Val Loss: 0.246544, Val Acc: 0.474227\n",
      "Epoch 1622 - Train Loss: 0.237569, Train Acc: 0.529487 | Val Loss: 0.246523, Val Acc: 0.474227\n",
      "Epoch 1623 - Train Loss: 0.237547, Train Acc: 0.529487 | Val Loss: 0.246502, Val Acc: 0.474227\n",
      "Epoch 1624 - Train Loss: 0.237526, Train Acc: 0.529487 | Val Loss: 0.246481, Val Acc: 0.474227\n",
      "Epoch 1625 - Train Loss: 0.237504, Train Acc: 0.529487 | Val Loss: 0.246460, Val Acc: 0.474227\n",
      "Epoch 1626 - Train Loss: 0.237482, Train Acc: 0.529487 | Val Loss: 0.246438, Val Acc: 0.474227\n",
      "Epoch 1627 - Train Loss: 0.237460, Train Acc: 0.529487 | Val Loss: 0.246417, Val Acc: 0.474227\n",
      "Epoch 1628 - Train Loss: 0.237438, Train Acc: 0.529487 | Val Loss: 0.246396, Val Acc: 0.474227\n",
      "Epoch 1629 - Train Loss: 0.237416, Train Acc: 0.529487 | Val Loss: 0.246375, Val Acc: 0.474227\n",
      "Epoch 1630 - Train Loss: 0.237395, Train Acc: 0.529487 | Val Loss: 0.246354, Val Acc: 0.474227\n",
      "Epoch 1631 - Train Loss: 0.237373, Train Acc: 0.529487 | Val Loss: 0.246333, Val Acc: 0.474227\n",
      "Epoch 1632 - Train Loss: 0.237351, Train Acc: 0.529487 | Val Loss: 0.246311, Val Acc: 0.474227\n",
      "Epoch 1633 - Train Loss: 0.237329, Train Acc: 0.529487 | Val Loss: 0.246290, Val Acc: 0.474227\n",
      "Epoch 1634 - Train Loss: 0.237307, Train Acc: 0.529487 | Val Loss: 0.246269, Val Acc: 0.474227\n",
      "Epoch 1635 - Train Loss: 0.237285, Train Acc: 0.529487 | Val Loss: 0.246248, Val Acc: 0.474227\n",
      "Epoch 1636 - Train Loss: 0.237264, Train Acc: 0.529487 | Val Loss: 0.246227, Val Acc: 0.474227\n",
      "Epoch 1637 - Train Loss: 0.237242, Train Acc: 0.529487 | Val Loss: 0.246205, Val Acc: 0.474227\n",
      "Epoch 1638 - Train Loss: 0.237220, Train Acc: 0.529487 | Val Loss: 0.246184, Val Acc: 0.474227\n",
      "Epoch 1639 - Train Loss: 0.237198, Train Acc: 0.529487 | Val Loss: 0.246163, Val Acc: 0.474227\n",
      "Epoch 1640 - Train Loss: 0.237176, Train Acc: 0.529487 | Val Loss: 0.246142, Val Acc: 0.474227\n",
      "Epoch 1641 - Train Loss: 0.237154, Train Acc: 0.529487 | Val Loss: 0.246121, Val Acc: 0.474227\n",
      "Epoch 1642 - Train Loss: 0.237133, Train Acc: 0.529487 | Val Loss: 0.246099, Val Acc: 0.474227\n",
      "Epoch 1643 - Train Loss: 0.237111, Train Acc: 0.529487 | Val Loss: 0.246078, Val Acc: 0.474227\n",
      "Epoch 1644 - Train Loss: 0.237089, Train Acc: 0.529487 | Val Loss: 0.246057, Val Acc: 0.474227\n",
      "Epoch 1645 - Train Loss: 0.237067, Train Acc: 0.529487 | Val Loss: 0.246036, Val Acc: 0.474227\n",
      "Epoch 1646 - Train Loss: 0.237045, Train Acc: 0.529487 | Val Loss: 0.246014, Val Acc: 0.474227\n",
      "Epoch 1647 - Train Loss: 0.237023, Train Acc: 0.529487 | Val Loss: 0.245993, Val Acc: 0.474227\n",
      "Epoch 1648 - Train Loss: 0.237002, Train Acc: 0.529487 | Val Loss: 0.245972, Val Acc: 0.474227\n",
      "Epoch 1649 - Train Loss: 0.236980, Train Acc: 0.529487 | Val Loss: 0.245951, Val Acc: 0.474227\n",
      "Epoch 1650 - Train Loss: 0.236958, Train Acc: 0.529487 | Val Loss: 0.245930, Val Acc: 0.474227\n",
      "Epoch 1651 - Train Loss: 0.236936, Train Acc: 0.530769 | Val Loss: 0.245908, Val Acc: 0.474227\n",
      "Epoch 1652 - Train Loss: 0.236914, Train Acc: 0.530769 | Val Loss: 0.245887, Val Acc: 0.474227\n",
      "Epoch 1653 - Train Loss: 0.236892, Train Acc: 0.530769 | Val Loss: 0.245866, Val Acc: 0.474227\n",
      "Epoch 1654 - Train Loss: 0.236870, Train Acc: 0.532051 | Val Loss: 0.245845, Val Acc: 0.474227\n",
      "Epoch 1655 - Train Loss: 0.236849, Train Acc: 0.532051 | Val Loss: 0.245823, Val Acc: 0.474227\n",
      "Epoch 1656 - Train Loss: 0.236827, Train Acc: 0.532051 | Val Loss: 0.245802, Val Acc: 0.474227\n",
      "Epoch 1657 - Train Loss: 0.236805, Train Acc: 0.532051 | Val Loss: 0.245781, Val Acc: 0.474227\n",
      "Epoch 1658 - Train Loss: 0.236783, Train Acc: 0.532051 | Val Loss: 0.245760, Val Acc: 0.474227\n",
      "Epoch 1659 - Train Loss: 0.236761, Train Acc: 0.532051 | Val Loss: 0.245739, Val Acc: 0.474227\n",
      "Epoch 1660 - Train Loss: 0.236739, Train Acc: 0.532051 | Val Loss: 0.245717, Val Acc: 0.474227\n",
      "Epoch 1661 - Train Loss: 0.236718, Train Acc: 0.532051 | Val Loss: 0.245696, Val Acc: 0.474227\n",
      "Epoch 1662 - Train Loss: 0.236696, Train Acc: 0.532051 | Val Loss: 0.245675, Val Acc: 0.474227\n",
      "Epoch 1663 - Train Loss: 0.236674, Train Acc: 0.532051 | Val Loss: 0.245654, Val Acc: 0.474227\n",
      "Epoch 1664 - Train Loss: 0.236652, Train Acc: 0.532051 | Val Loss: 0.245633, Val Acc: 0.474227\n",
      "Epoch 1665 - Train Loss: 0.236630, Train Acc: 0.532051 | Val Loss: 0.245611, Val Acc: 0.474227\n",
      "Epoch 1666 - Train Loss: 0.236608, Train Acc: 0.533333 | Val Loss: 0.245590, Val Acc: 0.474227\n",
      "Epoch 1667 - Train Loss: 0.236586, Train Acc: 0.533333 | Val Loss: 0.245569, Val Acc: 0.484536\n",
      "Epoch 1668 - Train Loss: 0.236565, Train Acc: 0.533333 | Val Loss: 0.245548, Val Acc: 0.484536\n",
      "Epoch 1669 - Train Loss: 0.236543, Train Acc: 0.533333 | Val Loss: 0.245526, Val Acc: 0.484536\n",
      "Epoch 1670 - Train Loss: 0.236521, Train Acc: 0.533333 | Val Loss: 0.245505, Val Acc: 0.484536\n",
      "Epoch 1671 - Train Loss: 0.236499, Train Acc: 0.533333 | Val Loss: 0.245484, Val Acc: 0.484536\n",
      "Epoch 1672 - Train Loss: 0.236477, Train Acc: 0.533333 | Val Loss: 0.245463, Val Acc: 0.484536\n",
      "Epoch 1673 - Train Loss: 0.236455, Train Acc: 0.533333 | Val Loss: 0.245441, Val Acc: 0.484536\n",
      "Epoch 1674 - Train Loss: 0.236434, Train Acc: 0.533333 | Val Loss: 0.245420, Val Acc: 0.484536\n",
      "Epoch 1675 - Train Loss: 0.236412, Train Acc: 0.533333 | Val Loss: 0.245399, Val Acc: 0.484536\n",
      "Epoch 1676 - Train Loss: 0.236390, Train Acc: 0.533333 | Val Loss: 0.245378, Val Acc: 0.484536\n",
      "Epoch 1677 - Train Loss: 0.236368, Train Acc: 0.533333 | Val Loss: 0.245357, Val Acc: 0.484536\n",
      "Epoch 1678 - Train Loss: 0.236346, Train Acc: 0.533333 | Val Loss: 0.245335, Val Acc: 0.484536\n",
      "Epoch 1679 - Train Loss: 0.236324, Train Acc: 0.533333 | Val Loss: 0.245314, Val Acc: 0.484536\n",
      "Epoch 1680 - Train Loss: 0.236302, Train Acc: 0.533333 | Val Loss: 0.245293, Val Acc: 0.484536\n",
      "Epoch 1681 - Train Loss: 0.236281, Train Acc: 0.533333 | Val Loss: 0.245272, Val Acc: 0.484536\n",
      "Epoch 1682 - Train Loss: 0.236259, Train Acc: 0.534615 | Val Loss: 0.245250, Val Acc: 0.484536\n",
      "Epoch 1683 - Train Loss: 0.236237, Train Acc: 0.534615 | Val Loss: 0.245229, Val Acc: 0.484536\n",
      "Epoch 1684 - Train Loss: 0.236215, Train Acc: 0.534615 | Val Loss: 0.245208, Val Acc: 0.484536\n",
      "Epoch 1685 - Train Loss: 0.236193, Train Acc: 0.534615 | Val Loss: 0.245187, Val Acc: 0.484536\n",
      "Epoch 1686 - Train Loss: 0.236171, Train Acc: 0.534615 | Val Loss: 0.245165, Val Acc: 0.484536\n",
      "Epoch 1687 - Train Loss: 0.236149, Train Acc: 0.534615 | Val Loss: 0.245144, Val Acc: 0.484536\n",
      "Epoch 1688 - Train Loss: 0.236128, Train Acc: 0.535897 | Val Loss: 0.245123, Val Acc: 0.484536\n",
      "Epoch 1689 - Train Loss: 0.236106, Train Acc: 0.535897 | Val Loss: 0.245102, Val Acc: 0.484536\n",
      "Epoch 1690 - Train Loss: 0.236084, Train Acc: 0.535897 | Val Loss: 0.245081, Val Acc: 0.484536\n",
      "Epoch 1691 - Train Loss: 0.236062, Train Acc: 0.535897 | Val Loss: 0.245059, Val Acc: 0.484536\n",
      "Epoch 1692 - Train Loss: 0.236040, Train Acc: 0.535897 | Val Loss: 0.245038, Val Acc: 0.484536\n",
      "Epoch 1693 - Train Loss: 0.236018, Train Acc: 0.535897 | Val Loss: 0.245017, Val Acc: 0.484536\n",
      "Epoch 1694 - Train Loss: 0.235997, Train Acc: 0.535897 | Val Loss: 0.244996, Val Acc: 0.484536\n",
      "Epoch 1695 - Train Loss: 0.235975, Train Acc: 0.535897 | Val Loss: 0.244974, Val Acc: 0.484536\n",
      "Epoch 1696 - Train Loss: 0.235953, Train Acc: 0.535897 | Val Loss: 0.244953, Val Acc: 0.494845\n",
      "Epoch 1697 - Train Loss: 0.235931, Train Acc: 0.535897 | Val Loss: 0.244932, Val Acc: 0.494845\n",
      "Epoch 1698 - Train Loss: 0.235909, Train Acc: 0.535897 | Val Loss: 0.244911, Val Acc: 0.494845\n",
      "Epoch 1699 - Train Loss: 0.235887, Train Acc: 0.535897 | Val Loss: 0.244890, Val Acc: 0.494845\n",
      "Epoch 1700 - Train Loss: 0.235866, Train Acc: 0.535897 | Val Loss: 0.244868, Val Acc: 0.494845\n",
      "Epoch 1701 - Train Loss: 0.235844, Train Acc: 0.535897 | Val Loss: 0.244847, Val Acc: 0.494845\n",
      "Epoch 1702 - Train Loss: 0.235822, Train Acc: 0.535897 | Val Loss: 0.244826, Val Acc: 0.494845\n",
      "Epoch 1703 - Train Loss: 0.235800, Train Acc: 0.535897 | Val Loss: 0.244805, Val Acc: 0.494845\n",
      "Epoch 1704 - Train Loss: 0.235778, Train Acc: 0.535897 | Val Loss: 0.244783, Val Acc: 0.494845\n",
      "Epoch 1705 - Train Loss: 0.235756, Train Acc: 0.535897 | Val Loss: 0.244762, Val Acc: 0.494845\n",
      "Epoch 1706 - Train Loss: 0.235735, Train Acc: 0.535897 | Val Loss: 0.244741, Val Acc: 0.494845\n",
      "Epoch 1707 - Train Loss: 0.235713, Train Acc: 0.535897 | Val Loss: 0.244720, Val Acc: 0.494845\n",
      "Epoch 1708 - Train Loss: 0.235691, Train Acc: 0.535897 | Val Loss: 0.244698, Val Acc: 0.494845\n",
      "Epoch 1709 - Train Loss: 0.235669, Train Acc: 0.535897 | Val Loss: 0.244677, Val Acc: 0.494845\n",
      "Epoch 1710 - Train Loss: 0.235647, Train Acc: 0.535897 | Val Loss: 0.244656, Val Acc: 0.494845\n",
      "Epoch 1711 - Train Loss: 0.235625, Train Acc: 0.535897 | Val Loss: 0.244635, Val Acc: 0.494845\n",
      "Epoch 1712 - Train Loss: 0.235604, Train Acc: 0.535897 | Val Loss: 0.244613, Val Acc: 0.494845\n",
      "Epoch 1713 - Train Loss: 0.235582, Train Acc: 0.537179 | Val Loss: 0.244592, Val Acc: 0.494845\n",
      "Epoch 1714 - Train Loss: 0.235560, Train Acc: 0.537179 | Val Loss: 0.244571, Val Acc: 0.494845\n",
      "Epoch 1715 - Train Loss: 0.235538, Train Acc: 0.537179 | Val Loss: 0.244550, Val Acc: 0.494845\n",
      "Epoch 1716 - Train Loss: 0.235516, Train Acc: 0.537179 | Val Loss: 0.244528, Val Acc: 0.494845\n",
      "Epoch 1717 - Train Loss: 0.235494, Train Acc: 0.537179 | Val Loss: 0.244507, Val Acc: 0.494845\n",
      "Epoch 1718 - Train Loss: 0.235473, Train Acc: 0.537179 | Val Loss: 0.244486, Val Acc: 0.494845\n",
      "Epoch 1719 - Train Loss: 0.235451, Train Acc: 0.537179 | Val Loss: 0.244465, Val Acc: 0.494845\n",
      "Epoch 1720 - Train Loss: 0.235429, Train Acc: 0.537179 | Val Loss: 0.244443, Val Acc: 0.494845\n",
      "Epoch 1721 - Train Loss: 0.235407, Train Acc: 0.537179 | Val Loss: 0.244422, Val Acc: 0.494845\n",
      "Epoch 1722 - Train Loss: 0.235385, Train Acc: 0.537179 | Val Loss: 0.244401, Val Acc: 0.494845\n",
      "Epoch 1723 - Train Loss: 0.235363, Train Acc: 0.537179 | Val Loss: 0.244380, Val Acc: 0.494845\n",
      "Epoch 1724 - Train Loss: 0.235342, Train Acc: 0.537179 | Val Loss: 0.244358, Val Acc: 0.494845\n",
      "Epoch 1725 - Train Loss: 0.235320, Train Acc: 0.537179 | Val Loss: 0.244337, Val Acc: 0.494845\n",
      "Epoch 1726 - Train Loss: 0.235298, Train Acc: 0.537179 | Val Loss: 0.244316, Val Acc: 0.494845\n",
      "Epoch 1727 - Train Loss: 0.235276, Train Acc: 0.537179 | Val Loss: 0.244294, Val Acc: 0.494845\n",
      "Epoch 1728 - Train Loss: 0.235254, Train Acc: 0.537179 | Val Loss: 0.244273, Val Acc: 0.494845\n",
      "Epoch 1729 - Train Loss: 0.235232, Train Acc: 0.537179 | Val Loss: 0.244252, Val Acc: 0.494845\n",
      "Epoch 1730 - Train Loss: 0.235210, Train Acc: 0.537179 | Val Loss: 0.244231, Val Acc: 0.494845\n",
      "Epoch 1731 - Train Loss: 0.235189, Train Acc: 0.537179 | Val Loss: 0.244209, Val Acc: 0.494845\n",
      "Epoch 1732 - Train Loss: 0.235167, Train Acc: 0.537179 | Val Loss: 0.244188, Val Acc: 0.494845\n",
      "Epoch 1733 - Train Loss: 0.235145, Train Acc: 0.537179 | Val Loss: 0.244167, Val Acc: 0.494845\n",
      "Epoch 1734 - Train Loss: 0.235123, Train Acc: 0.537179 | Val Loss: 0.244146, Val Acc: 0.494845\n",
      "Epoch 1735 - Train Loss: 0.235101, Train Acc: 0.537179 | Val Loss: 0.244124, Val Acc: 0.494845\n",
      "Epoch 1736 - Train Loss: 0.235079, Train Acc: 0.537179 | Val Loss: 0.244103, Val Acc: 0.494845\n",
      "Epoch 1737 - Train Loss: 0.235058, Train Acc: 0.537179 | Val Loss: 0.244082, Val Acc: 0.494845\n",
      "Epoch 1738 - Train Loss: 0.235036, Train Acc: 0.537179 | Val Loss: 0.244061, Val Acc: 0.494845\n",
      "Epoch 1739 - Train Loss: 0.235014, Train Acc: 0.537179 | Val Loss: 0.244039, Val Acc: 0.494845\n",
      "Epoch 1740 - Train Loss: 0.234992, Train Acc: 0.537179 | Val Loss: 0.244018, Val Acc: 0.494845\n",
      "Epoch 1741 - Train Loss: 0.234970, Train Acc: 0.537179 | Val Loss: 0.243997, Val Acc: 0.494845\n",
      "Epoch 1742 - Train Loss: 0.234948, Train Acc: 0.537179 | Val Loss: 0.243976, Val Acc: 0.494845\n",
      "Epoch 1743 - Train Loss: 0.234927, Train Acc: 0.538462 | Val Loss: 0.243954, Val Acc: 0.494845\n",
      "Epoch 1744 - Train Loss: 0.234905, Train Acc: 0.538462 | Val Loss: 0.243933, Val Acc: 0.494845\n",
      "Epoch 1745 - Train Loss: 0.234883, Train Acc: 0.538462 | Val Loss: 0.243912, Val Acc: 0.494845\n",
      "Epoch 1746 - Train Loss: 0.234861, Train Acc: 0.538462 | Val Loss: 0.243891, Val Acc: 0.494845\n",
      "Epoch 1747 - Train Loss: 0.234839, Train Acc: 0.538462 | Val Loss: 0.243869, Val Acc: 0.494845\n",
      "Epoch 1748 - Train Loss: 0.234818, Train Acc: 0.538462 | Val Loss: 0.243848, Val Acc: 0.494845\n",
      "Epoch 1749 - Train Loss: 0.234796, Train Acc: 0.538462 | Val Loss: 0.243827, Val Acc: 0.494845\n",
      "Epoch 1750 - Train Loss: 0.234774, Train Acc: 0.538462 | Val Loss: 0.243806, Val Acc: 0.494845\n",
      "Epoch 1751 - Train Loss: 0.234752, Train Acc: 0.538462 | Val Loss: 0.243784, Val Acc: 0.494845\n",
      "Epoch 1752 - Train Loss: 0.234730, Train Acc: 0.538462 | Val Loss: 0.243763, Val Acc: 0.494845\n",
      "Epoch 1753 - Train Loss: 0.234708, Train Acc: 0.538462 | Val Loss: 0.243742, Val Acc: 0.494845\n",
      "Epoch 1754 - Train Loss: 0.234687, Train Acc: 0.539744 | Val Loss: 0.243721, Val Acc: 0.494845\n",
      "Epoch 1755 - Train Loss: 0.234665, Train Acc: 0.539744 | Val Loss: 0.243699, Val Acc: 0.494845\n",
      "Epoch 1756 - Train Loss: 0.234643, Train Acc: 0.539744 | Val Loss: 0.243678, Val Acc: 0.494845\n",
      "Epoch 1757 - Train Loss: 0.234621, Train Acc: 0.539744 | Val Loss: 0.243657, Val Acc: 0.494845\n",
      "Epoch 1758 - Train Loss: 0.234599, Train Acc: 0.539744 | Val Loss: 0.243636, Val Acc: 0.494845\n",
      "Epoch 1759 - Train Loss: 0.234578, Train Acc: 0.539744 | Val Loss: 0.243615, Val Acc: 0.494845\n",
      "Epoch 1760 - Train Loss: 0.234556, Train Acc: 0.539744 | Val Loss: 0.243593, Val Acc: 0.494845\n",
      "Epoch 1761 - Train Loss: 0.234534, Train Acc: 0.539744 | Val Loss: 0.243572, Val Acc: 0.494845\n",
      "Epoch 1762 - Train Loss: 0.234512, Train Acc: 0.539744 | Val Loss: 0.243551, Val Acc: 0.494845\n",
      "Epoch 1763 - Train Loss: 0.234490, Train Acc: 0.539744 | Val Loss: 0.243530, Val Acc: 0.494845\n",
      "Epoch 1764 - Train Loss: 0.234469, Train Acc: 0.539744 | Val Loss: 0.243508, Val Acc: 0.494845\n",
      "Epoch 1765 - Train Loss: 0.234447, Train Acc: 0.539744 | Val Loss: 0.243487, Val Acc: 0.494845\n",
      "Epoch 1766 - Train Loss: 0.234425, Train Acc: 0.541026 | Val Loss: 0.243466, Val Acc: 0.494845\n",
      "Epoch 1767 - Train Loss: 0.234403, Train Acc: 0.541026 | Val Loss: 0.243445, Val Acc: 0.494845\n",
      "Epoch 1768 - Train Loss: 0.234381, Train Acc: 0.541026 | Val Loss: 0.243423, Val Acc: 0.494845\n",
      "Epoch 1769 - Train Loss: 0.234360, Train Acc: 0.541026 | Val Loss: 0.243402, Val Acc: 0.494845\n",
      "Epoch 1770 - Train Loss: 0.234338, Train Acc: 0.541026 | Val Loss: 0.243381, Val Acc: 0.494845\n",
      "Epoch 1771 - Train Loss: 0.234316, Train Acc: 0.541026 | Val Loss: 0.243360, Val Acc: 0.494845\n",
      "Epoch 1772 - Train Loss: 0.234294, Train Acc: 0.541026 | Val Loss: 0.243338, Val Acc: 0.494845\n",
      "Epoch 1773 - Train Loss: 0.234272, Train Acc: 0.541026 | Val Loss: 0.243317, Val Acc: 0.494845\n",
      "Epoch 1774 - Train Loss: 0.234250, Train Acc: 0.541026 | Val Loss: 0.243296, Val Acc: 0.494845\n",
      "Epoch 1775 - Train Loss: 0.234229, Train Acc: 0.542308 | Val Loss: 0.243275, Val Acc: 0.494845\n",
      "Epoch 1776 - Train Loss: 0.234207, Train Acc: 0.542308 | Val Loss: 0.243253, Val Acc: 0.494845\n",
      "Epoch 1777 - Train Loss: 0.234185, Train Acc: 0.542308 | Val Loss: 0.243232, Val Acc: 0.494845\n",
      "Epoch 1778 - Train Loss: 0.234163, Train Acc: 0.542308 | Val Loss: 0.243211, Val Acc: 0.494845\n",
      "Epoch 1779 - Train Loss: 0.234141, Train Acc: 0.542308 | Val Loss: 0.243190, Val Acc: 0.494845\n",
      "Epoch 1780 - Train Loss: 0.234120, Train Acc: 0.542308 | Val Loss: 0.243168, Val Acc: 0.494845\n",
      "Epoch 1781 - Train Loss: 0.234098, Train Acc: 0.542308 | Val Loss: 0.243147, Val Acc: 0.494845\n",
      "Epoch 1782 - Train Loss: 0.234076, Train Acc: 0.542308 | Val Loss: 0.243126, Val Acc: 0.494845\n",
      "Epoch 1783 - Train Loss: 0.234054, Train Acc: 0.542308 | Val Loss: 0.243105, Val Acc: 0.494845\n",
      "Epoch 1784 - Train Loss: 0.234032, Train Acc: 0.542308 | Val Loss: 0.243083, Val Acc: 0.494845\n",
      "Epoch 1785 - Train Loss: 0.234011, Train Acc: 0.542308 | Val Loss: 0.243062, Val Acc: 0.494845\n",
      "Epoch 1786 - Train Loss: 0.233989, Train Acc: 0.542308 | Val Loss: 0.243041, Val Acc: 0.494845\n",
      "Epoch 1787 - Train Loss: 0.233967, Train Acc: 0.542308 | Val Loss: 0.243020, Val Acc: 0.494845\n",
      "Epoch 1788 - Train Loss: 0.233945, Train Acc: 0.542308 | Val Loss: 0.242998, Val Acc: 0.494845\n",
      "Epoch 1789 - Train Loss: 0.233923, Train Acc: 0.542308 | Val Loss: 0.242977, Val Acc: 0.494845\n",
      "Epoch 1790 - Train Loss: 0.233902, Train Acc: 0.542308 | Val Loss: 0.242956, Val Acc: 0.494845\n",
      "Epoch 1791 - Train Loss: 0.233880, Train Acc: 0.542308 | Val Loss: 0.242935, Val Acc: 0.494845\n",
      "Epoch 1792 - Train Loss: 0.233858, Train Acc: 0.542308 | Val Loss: 0.242913, Val Acc: 0.494845\n",
      "Epoch 1793 - Train Loss: 0.233836, Train Acc: 0.542308 | Val Loss: 0.242892, Val Acc: 0.494845\n",
      "Epoch 1794 - Train Loss: 0.233814, Train Acc: 0.542308 | Val Loss: 0.242871, Val Acc: 0.494845\n",
      "Epoch 1795 - Train Loss: 0.233793, Train Acc: 0.542308 | Val Loss: 0.242850, Val Acc: 0.494845\n",
      "Epoch 1796 - Train Loss: 0.233771, Train Acc: 0.542308 | Val Loss: 0.242828, Val Acc: 0.494845\n",
      "Epoch 1797 - Train Loss: 0.233749, Train Acc: 0.542308 | Val Loss: 0.242807, Val Acc: 0.494845\n",
      "Epoch 1798 - Train Loss: 0.233727, Train Acc: 0.542308 | Val Loss: 0.242786, Val Acc: 0.494845\n",
      "Epoch 1799 - Train Loss: 0.233705, Train Acc: 0.542308 | Val Loss: 0.242765, Val Acc: 0.494845\n",
      "Epoch 1800 - Train Loss: 0.233684, Train Acc: 0.542308 | Val Loss: 0.242743, Val Acc: 0.494845\n",
      "Epoch 1801 - Train Loss: 0.233662, Train Acc: 0.543590 | Val Loss: 0.242722, Val Acc: 0.494845\n",
      "Epoch 1802 - Train Loss: 0.233640, Train Acc: 0.543590 | Val Loss: 0.242701, Val Acc: 0.494845\n",
      "Epoch 1803 - Train Loss: 0.233618, Train Acc: 0.543590 | Val Loss: 0.242680, Val Acc: 0.494845\n",
      "Epoch 1804 - Train Loss: 0.233596, Train Acc: 0.543590 | Val Loss: 0.242658, Val Acc: 0.494845\n",
      "Epoch 1805 - Train Loss: 0.233575, Train Acc: 0.543590 | Val Loss: 0.242637, Val Acc: 0.494845\n",
      "Epoch 1806 - Train Loss: 0.233553, Train Acc: 0.543590 | Val Loss: 0.242616, Val Acc: 0.494845\n",
      "Epoch 1807 - Train Loss: 0.233531, Train Acc: 0.543590 | Val Loss: 0.242595, Val Acc: 0.494845\n",
      "Epoch 1808 - Train Loss: 0.233509, Train Acc: 0.543590 | Val Loss: 0.242573, Val Acc: 0.494845\n",
      "Epoch 1809 - Train Loss: 0.233487, Train Acc: 0.543590 | Val Loss: 0.242552, Val Acc: 0.494845\n",
      "Epoch 1810 - Train Loss: 0.233466, Train Acc: 0.543590 | Val Loss: 0.242531, Val Acc: 0.494845\n",
      "Epoch 1811 - Train Loss: 0.233444, Train Acc: 0.543590 | Val Loss: 0.242510, Val Acc: 0.494845\n",
      "Epoch 1812 - Train Loss: 0.233422, Train Acc: 0.543590 | Val Loss: 0.242488, Val Acc: 0.494845\n",
      "Epoch 1813 - Train Loss: 0.233400, Train Acc: 0.543590 | Val Loss: 0.242467, Val Acc: 0.494845\n",
      "Epoch 1814 - Train Loss: 0.233379, Train Acc: 0.543590 | Val Loss: 0.242446, Val Acc: 0.494845\n",
      "Epoch 1815 - Train Loss: 0.233357, Train Acc: 0.543590 | Val Loss: 0.242425, Val Acc: 0.494845\n",
      "Epoch 1816 - Train Loss: 0.233335, Train Acc: 0.543590 | Val Loss: 0.242403, Val Acc: 0.494845\n",
      "Epoch 1817 - Train Loss: 0.233313, Train Acc: 0.543590 | Val Loss: 0.242382, Val Acc: 0.494845\n",
      "Epoch 1818 - Train Loss: 0.233291, Train Acc: 0.543590 | Val Loss: 0.242361, Val Acc: 0.494845\n",
      "Epoch 1819 - Train Loss: 0.233270, Train Acc: 0.543590 | Val Loss: 0.242340, Val Acc: 0.494845\n",
      "Epoch 1820 - Train Loss: 0.233248, Train Acc: 0.543590 | Val Loss: 0.242318, Val Acc: 0.494845\n",
      "Epoch 1821 - Train Loss: 0.233226, Train Acc: 0.543590 | Val Loss: 0.242297, Val Acc: 0.505155\n",
      "Epoch 1822 - Train Loss: 0.233204, Train Acc: 0.543590 | Val Loss: 0.242276, Val Acc: 0.505155\n",
      "Epoch 1823 - Train Loss: 0.233182, Train Acc: 0.543590 | Val Loss: 0.242254, Val Acc: 0.505155\n",
      "Epoch 1824 - Train Loss: 0.233161, Train Acc: 0.543590 | Val Loss: 0.242233, Val Acc: 0.505155\n",
      "Epoch 1825 - Train Loss: 0.233139, Train Acc: 0.543590 | Val Loss: 0.242212, Val Acc: 0.505155\n",
      "Epoch 1826 - Train Loss: 0.233117, Train Acc: 0.543590 | Val Loss: 0.242191, Val Acc: 0.505155\n",
      "Epoch 1827 - Train Loss: 0.233095, Train Acc: 0.544872 | Val Loss: 0.242169, Val Acc: 0.505155\n",
      "Epoch 1828 - Train Loss: 0.233074, Train Acc: 0.544872 | Val Loss: 0.242148, Val Acc: 0.505155\n",
      "Epoch 1829 - Train Loss: 0.233052, Train Acc: 0.544872 | Val Loss: 0.242127, Val Acc: 0.505155\n",
      "Epoch 1830 - Train Loss: 0.233030, Train Acc: 0.544872 | Val Loss: 0.242105, Val Acc: 0.505155\n",
      "Epoch 1831 - Train Loss: 0.233008, Train Acc: 0.544872 | Val Loss: 0.242084, Val Acc: 0.505155\n",
      "Epoch 1832 - Train Loss: 0.232986, Train Acc: 0.544872 | Val Loss: 0.242063, Val Acc: 0.505155\n",
      "Epoch 1833 - Train Loss: 0.232965, Train Acc: 0.544872 | Val Loss: 0.242042, Val Acc: 0.505155\n",
      "Epoch 1834 - Train Loss: 0.232943, Train Acc: 0.544872 | Val Loss: 0.242020, Val Acc: 0.505155\n",
      "Epoch 1835 - Train Loss: 0.232921, Train Acc: 0.544872 | Val Loss: 0.241999, Val Acc: 0.505155\n",
      "Epoch 1836 - Train Loss: 0.232899, Train Acc: 0.544872 | Val Loss: 0.241978, Val Acc: 0.505155\n",
      "Epoch 1837 - Train Loss: 0.232878, Train Acc: 0.544872 | Val Loss: 0.241957, Val Acc: 0.505155\n",
      "Epoch 1838 - Train Loss: 0.232856, Train Acc: 0.546154 | Val Loss: 0.241935, Val Acc: 0.505155\n",
      "Epoch 1839 - Train Loss: 0.232834, Train Acc: 0.546154 | Val Loss: 0.241914, Val Acc: 0.505155\n",
      "Epoch 1840 - Train Loss: 0.232812, Train Acc: 0.547436 | Val Loss: 0.241893, Val Acc: 0.505155\n",
      "Epoch 1841 - Train Loss: 0.232790, Train Acc: 0.547436 | Val Loss: 0.241871, Val Acc: 0.505155\n",
      "Epoch 1842 - Train Loss: 0.232769, Train Acc: 0.547436 | Val Loss: 0.241850, Val Acc: 0.505155\n",
      "Epoch 1843 - Train Loss: 0.232747, Train Acc: 0.547436 | Val Loss: 0.241829, Val Acc: 0.505155\n",
      "Epoch 1844 - Train Loss: 0.232725, Train Acc: 0.547436 | Val Loss: 0.241808, Val Acc: 0.505155\n",
      "Epoch 1845 - Train Loss: 0.232703, Train Acc: 0.547436 | Val Loss: 0.241786, Val Acc: 0.505155\n",
      "Epoch 1846 - Train Loss: 0.232682, Train Acc: 0.547436 | Val Loss: 0.241765, Val Acc: 0.505155\n",
      "Epoch 1847 - Train Loss: 0.232660, Train Acc: 0.547436 | Val Loss: 0.241744, Val Acc: 0.505155\n",
      "Epoch 1848 - Train Loss: 0.232638, Train Acc: 0.548718 | Val Loss: 0.241723, Val Acc: 0.505155\n",
      "Epoch 1849 - Train Loss: 0.232616, Train Acc: 0.548718 | Val Loss: 0.241701, Val Acc: 0.505155\n",
      "Epoch 1850 - Train Loss: 0.232594, Train Acc: 0.548718 | Val Loss: 0.241680, Val Acc: 0.505155\n",
      "Epoch 1851 - Train Loss: 0.232573, Train Acc: 0.548718 | Val Loss: 0.241659, Val Acc: 0.505155\n",
      "Epoch 1852 - Train Loss: 0.232551, Train Acc: 0.548718 | Val Loss: 0.241638, Val Acc: 0.505155\n",
      "Epoch 1853 - Train Loss: 0.232529, Train Acc: 0.548718 | Val Loss: 0.241616, Val Acc: 0.505155\n",
      "Epoch 1854 - Train Loss: 0.232507, Train Acc: 0.548718 | Val Loss: 0.241595, Val Acc: 0.505155\n",
      "Epoch 1855 - Train Loss: 0.232486, Train Acc: 0.548718 | Val Loss: 0.241574, Val Acc: 0.505155\n",
      "Epoch 1856 - Train Loss: 0.232464, Train Acc: 0.548718 | Val Loss: 0.241553, Val Acc: 0.505155\n",
      "Epoch 1857 - Train Loss: 0.232442, Train Acc: 0.550000 | Val Loss: 0.241531, Val Acc: 0.505155\n",
      "Epoch 1858 - Train Loss: 0.232420, Train Acc: 0.550000 | Val Loss: 0.241510, Val Acc: 0.505155\n",
      "Epoch 1859 - Train Loss: 0.232399, Train Acc: 0.550000 | Val Loss: 0.241489, Val Acc: 0.505155\n",
      "Epoch 1860 - Train Loss: 0.232377, Train Acc: 0.550000 | Val Loss: 0.241468, Val Acc: 0.505155\n",
      "Epoch 1861 - Train Loss: 0.232355, Train Acc: 0.550000 | Val Loss: 0.241446, Val Acc: 0.505155\n",
      "Epoch 1862 - Train Loss: 0.232333, Train Acc: 0.550000 | Val Loss: 0.241425, Val Acc: 0.505155\n",
      "Epoch 1863 - Train Loss: 0.232311, Train Acc: 0.550000 | Val Loss: 0.241404, Val Acc: 0.505155\n",
      "Epoch 1864 - Train Loss: 0.232290, Train Acc: 0.550000 | Val Loss: 0.241383, Val Acc: 0.505155\n",
      "Epoch 1865 - Train Loss: 0.232268, Train Acc: 0.550000 | Val Loss: 0.241361, Val Acc: 0.505155\n",
      "Epoch 1866 - Train Loss: 0.232246, Train Acc: 0.550000 | Val Loss: 0.241340, Val Acc: 0.505155\n",
      "Epoch 1867 - Train Loss: 0.232224, Train Acc: 0.550000 | Val Loss: 0.241319, Val Acc: 0.505155\n",
      "Epoch 1868 - Train Loss: 0.232203, Train Acc: 0.550000 | Val Loss: 0.241298, Val Acc: 0.505155\n",
      "Epoch 1869 - Train Loss: 0.232181, Train Acc: 0.550000 | Val Loss: 0.241276, Val Acc: 0.505155\n",
      "Epoch 1870 - Train Loss: 0.232159, Train Acc: 0.550000 | Val Loss: 0.241255, Val Acc: 0.505155\n",
      "Epoch 1871 - Train Loss: 0.232137, Train Acc: 0.550000 | Val Loss: 0.241234, Val Acc: 0.505155\n",
      "Epoch 1872 - Train Loss: 0.232116, Train Acc: 0.550000 | Val Loss: 0.241213, Val Acc: 0.505155\n",
      "Epoch 1873 - Train Loss: 0.232094, Train Acc: 0.550000 | Val Loss: 0.241191, Val Acc: 0.505155\n",
      "Epoch 1874 - Train Loss: 0.232072, Train Acc: 0.550000 | Val Loss: 0.241170, Val Acc: 0.505155\n",
      "Epoch 1875 - Train Loss: 0.232050, Train Acc: 0.550000 | Val Loss: 0.241149, Val Acc: 0.505155\n",
      "Epoch 1876 - Train Loss: 0.232029, Train Acc: 0.550000 | Val Loss: 0.241128, Val Acc: 0.505155\n",
      "Epoch 1877 - Train Loss: 0.232007, Train Acc: 0.550000 | Val Loss: 0.241106, Val Acc: 0.505155\n",
      "Epoch 1878 - Train Loss: 0.231985, Train Acc: 0.550000 | Val Loss: 0.241085, Val Acc: 0.505155\n",
      "Epoch 1879 - Train Loss: 0.231963, Train Acc: 0.550000 | Val Loss: 0.241064, Val Acc: 0.505155\n",
      "Epoch 1880 - Train Loss: 0.231941, Train Acc: 0.550000 | Val Loss: 0.241043, Val Acc: 0.505155\n",
      "Epoch 1881 - Train Loss: 0.231920, Train Acc: 0.550000 | Val Loss: 0.241021, Val Acc: 0.505155\n",
      "Epoch 1882 - Train Loss: 0.231898, Train Acc: 0.550000 | Val Loss: 0.241000, Val Acc: 0.505155\n",
      "Epoch 1883 - Train Loss: 0.231876, Train Acc: 0.550000 | Val Loss: 0.240979, Val Acc: 0.505155\n",
      "Epoch 1884 - Train Loss: 0.231854, Train Acc: 0.550000 | Val Loss: 0.240958, Val Acc: 0.505155\n",
      "Epoch 1885 - Train Loss: 0.231833, Train Acc: 0.550000 | Val Loss: 0.240936, Val Acc: 0.505155\n",
      "Epoch 1886 - Train Loss: 0.231811, Train Acc: 0.550000 | Val Loss: 0.240915, Val Acc: 0.505155\n",
      "Epoch 1887 - Train Loss: 0.231789, Train Acc: 0.550000 | Val Loss: 0.240894, Val Acc: 0.505155\n",
      "Epoch 1888 - Train Loss: 0.231767, Train Acc: 0.550000 | Val Loss: 0.240873, Val Acc: 0.505155\n",
      "Epoch 1889 - Train Loss: 0.231746, Train Acc: 0.550000 | Val Loss: 0.240852, Val Acc: 0.505155\n",
      "Epoch 1890 - Train Loss: 0.231724, Train Acc: 0.550000 | Val Loss: 0.240830, Val Acc: 0.505155\n",
      "Epoch 1891 - Train Loss: 0.231702, Train Acc: 0.550000 | Val Loss: 0.240809, Val Acc: 0.505155\n",
      "Epoch 1892 - Train Loss: 0.231680, Train Acc: 0.550000 | Val Loss: 0.240788, Val Acc: 0.505155\n",
      "Epoch 1893 - Train Loss: 0.231659, Train Acc: 0.550000 | Val Loss: 0.240767, Val Acc: 0.505155\n",
      "Epoch 1894 - Train Loss: 0.231637, Train Acc: 0.551282 | Val Loss: 0.240745, Val Acc: 0.505155\n",
      "Epoch 1895 - Train Loss: 0.231615, Train Acc: 0.551282 | Val Loss: 0.240724, Val Acc: 0.505155\n",
      "Epoch 1896 - Train Loss: 0.231593, Train Acc: 0.552564 | Val Loss: 0.240703, Val Acc: 0.505155\n",
      "Epoch 1897 - Train Loss: 0.231572, Train Acc: 0.552564 | Val Loss: 0.240682, Val Acc: 0.505155\n",
      "Epoch 1898 - Train Loss: 0.231550, Train Acc: 0.552564 | Val Loss: 0.240660, Val Acc: 0.505155\n",
      "Epoch 1899 - Train Loss: 0.231528, Train Acc: 0.552564 | Val Loss: 0.240639, Val Acc: 0.505155\n",
      "Epoch 1900 - Train Loss: 0.231506, Train Acc: 0.552564 | Val Loss: 0.240618, Val Acc: 0.505155\n",
      "Epoch 1901 - Train Loss: 0.231485, Train Acc: 0.552564 | Val Loss: 0.240597, Val Acc: 0.505155\n",
      "Epoch 1902 - Train Loss: 0.231463, Train Acc: 0.552564 | Val Loss: 0.240576, Val Acc: 0.505155\n",
      "Epoch 1903 - Train Loss: 0.231441, Train Acc: 0.552564 | Val Loss: 0.240554, Val Acc: 0.505155\n",
      "Epoch 1904 - Train Loss: 0.231419, Train Acc: 0.552564 | Val Loss: 0.240533, Val Acc: 0.505155\n",
      "Epoch 1905 - Train Loss: 0.231398, Train Acc: 0.552564 | Val Loss: 0.240512, Val Acc: 0.505155\n",
      "Epoch 1906 - Train Loss: 0.231376, Train Acc: 0.552564 | Val Loss: 0.240491, Val Acc: 0.505155\n",
      "Epoch 1907 - Train Loss: 0.231354, Train Acc: 0.552564 | Val Loss: 0.240470, Val Acc: 0.505155\n",
      "Epoch 1908 - Train Loss: 0.231332, Train Acc: 0.552564 | Val Loss: 0.240448, Val Acc: 0.505155\n",
      "Epoch 1909 - Train Loss: 0.231311, Train Acc: 0.552564 | Val Loss: 0.240427, Val Acc: 0.505155\n",
      "Epoch 1910 - Train Loss: 0.231289, Train Acc: 0.552564 | Val Loss: 0.240406, Val Acc: 0.505155\n",
      "Epoch 1911 - Train Loss: 0.231267, Train Acc: 0.552564 | Val Loss: 0.240385, Val Acc: 0.505155\n",
      "Epoch 1912 - Train Loss: 0.231245, Train Acc: 0.552564 | Val Loss: 0.240364, Val Acc: 0.505155\n",
      "Epoch 1913 - Train Loss: 0.231224, Train Acc: 0.552564 | Val Loss: 0.240342, Val Acc: 0.505155\n",
      "Epoch 1914 - Train Loss: 0.231202, Train Acc: 0.552564 | Val Loss: 0.240321, Val Acc: 0.505155\n",
      "Epoch 1915 - Train Loss: 0.231180, Train Acc: 0.552564 | Val Loss: 0.240300, Val Acc: 0.505155\n",
      "Epoch 1916 - Train Loss: 0.231158, Train Acc: 0.552564 | Val Loss: 0.240279, Val Acc: 0.505155\n",
      "Epoch 1917 - Train Loss: 0.231137, Train Acc: 0.552564 | Val Loss: 0.240257, Val Acc: 0.505155\n",
      "Epoch 1918 - Train Loss: 0.231115, Train Acc: 0.552564 | Val Loss: 0.240236, Val Acc: 0.505155\n",
      "Epoch 1919 - Train Loss: 0.231093, Train Acc: 0.552564 | Val Loss: 0.240215, Val Acc: 0.505155\n",
      "Epoch 1920 - Train Loss: 0.231071, Train Acc: 0.552564 | Val Loss: 0.240194, Val Acc: 0.505155\n",
      "Epoch 1921 - Train Loss: 0.231050, Train Acc: 0.552564 | Val Loss: 0.240173, Val Acc: 0.505155\n",
      "Epoch 1922 - Train Loss: 0.231028, Train Acc: 0.552564 | Val Loss: 0.240151, Val Acc: 0.505155\n",
      "Epoch 1923 - Train Loss: 0.231006, Train Acc: 0.552564 | Val Loss: 0.240130, Val Acc: 0.505155\n",
      "Epoch 1924 - Train Loss: 0.230984, Train Acc: 0.552564 | Val Loss: 0.240109, Val Acc: 0.505155\n",
      "Epoch 1925 - Train Loss: 0.230963, Train Acc: 0.553846 | Val Loss: 0.240088, Val Acc: 0.505155\n",
      "Epoch 1926 - Train Loss: 0.230941, Train Acc: 0.553846 | Val Loss: 0.240067, Val Acc: 0.505155\n",
      "Epoch 1927 - Train Loss: 0.230919, Train Acc: 0.553846 | Val Loss: 0.240045, Val Acc: 0.505155\n",
      "Epoch 1928 - Train Loss: 0.230897, Train Acc: 0.553846 | Val Loss: 0.240024, Val Acc: 0.505155\n",
      "Epoch 1929 - Train Loss: 0.230876, Train Acc: 0.553846 | Val Loss: 0.240003, Val Acc: 0.505155\n",
      "Epoch 1930 - Train Loss: 0.230854, Train Acc: 0.553846 | Val Loss: 0.239982, Val Acc: 0.505155\n",
      "Epoch 1931 - Train Loss: 0.230832, Train Acc: 0.553846 | Val Loss: 0.239960, Val Acc: 0.505155\n",
      "Epoch 1932 - Train Loss: 0.230811, Train Acc: 0.553846 | Val Loss: 0.239939, Val Acc: 0.505155\n",
      "Epoch 1933 - Train Loss: 0.230789, Train Acc: 0.553846 | Val Loss: 0.239918, Val Acc: 0.505155\n",
      "Epoch 1934 - Train Loss: 0.230767, Train Acc: 0.553846 | Val Loss: 0.239897, Val Acc: 0.505155\n",
      "Epoch 1935 - Train Loss: 0.230745, Train Acc: 0.553846 | Val Loss: 0.239876, Val Acc: 0.505155\n",
      "Epoch 1936 - Train Loss: 0.230724, Train Acc: 0.553846 | Val Loss: 0.239854, Val Acc: 0.505155\n",
      "Epoch 1937 - Train Loss: 0.230702, Train Acc: 0.553846 | Val Loss: 0.239833, Val Acc: 0.505155\n",
      "Epoch 1938 - Train Loss: 0.230680, Train Acc: 0.553846 | Val Loss: 0.239812, Val Acc: 0.505155\n",
      "Epoch 1939 - Train Loss: 0.230658, Train Acc: 0.553846 | Val Loss: 0.239791, Val Acc: 0.505155\n",
      "Epoch 1940 - Train Loss: 0.230637, Train Acc: 0.552564 | Val Loss: 0.239770, Val Acc: 0.505155\n",
      "Epoch 1941 - Train Loss: 0.230615, Train Acc: 0.552564 | Val Loss: 0.239748, Val Acc: 0.505155\n",
      "Epoch 1942 - Train Loss: 0.230593, Train Acc: 0.552564 | Val Loss: 0.239727, Val Acc: 0.505155\n",
      "Epoch 1943 - Train Loss: 0.230572, Train Acc: 0.552564 | Val Loss: 0.239706, Val Acc: 0.505155\n",
      "Epoch 1944 - Train Loss: 0.230550, Train Acc: 0.552564 | Val Loss: 0.239685, Val Acc: 0.505155\n",
      "Epoch 1945 - Train Loss: 0.230528, Train Acc: 0.552564 | Val Loss: 0.239664, Val Acc: 0.505155\n",
      "Epoch 1946 - Train Loss: 0.230506, Train Acc: 0.552564 | Val Loss: 0.239642, Val Acc: 0.505155\n",
      "Epoch 1947 - Train Loss: 0.230485, Train Acc: 0.552564 | Val Loss: 0.239621, Val Acc: 0.505155\n",
      "Epoch 1948 - Train Loss: 0.230463, Train Acc: 0.552564 | Val Loss: 0.239600, Val Acc: 0.505155\n",
      "Epoch 1949 - Train Loss: 0.230441, Train Acc: 0.552564 | Val Loss: 0.239579, Val Acc: 0.505155\n",
      "Epoch 1950 - Train Loss: 0.230419, Train Acc: 0.552564 | Val Loss: 0.239557, Val Acc: 0.505155\n",
      "Epoch 1951 - Train Loss: 0.230398, Train Acc: 0.552564 | Val Loss: 0.239536, Val Acc: 0.505155\n",
      "Epoch 1952 - Train Loss: 0.230376, Train Acc: 0.552564 | Val Loss: 0.239515, Val Acc: 0.505155\n",
      "Epoch 1953 - Train Loss: 0.230354, Train Acc: 0.552564 | Val Loss: 0.239494, Val Acc: 0.505155\n",
      "Epoch 1954 - Train Loss: 0.230333, Train Acc: 0.553846 | Val Loss: 0.239473, Val Acc: 0.505155\n",
      "Epoch 1955 - Train Loss: 0.230311, Train Acc: 0.553846 | Val Loss: 0.239451, Val Acc: 0.505155\n",
      "Epoch 1956 - Train Loss: 0.230289, Train Acc: 0.553846 | Val Loss: 0.239430, Val Acc: 0.505155\n",
      "Epoch 1957 - Train Loss: 0.230267, Train Acc: 0.553846 | Val Loss: 0.239409, Val Acc: 0.505155\n",
      "Epoch 1958 - Train Loss: 0.230246, Train Acc: 0.553846 | Val Loss: 0.239388, Val Acc: 0.505155\n",
      "Epoch 1959 - Train Loss: 0.230224, Train Acc: 0.553846 | Val Loss: 0.239366, Val Acc: 0.505155\n",
      "Epoch 1960 - Train Loss: 0.230202, Train Acc: 0.553846 | Val Loss: 0.239345, Val Acc: 0.505155\n",
      "Epoch 1961 - Train Loss: 0.230181, Train Acc: 0.553846 | Val Loss: 0.239324, Val Acc: 0.505155\n",
      "Epoch 1962 - Train Loss: 0.230159, Train Acc: 0.553846 | Val Loss: 0.239303, Val Acc: 0.505155\n",
      "Epoch 1963 - Train Loss: 0.230137, Train Acc: 0.553846 | Val Loss: 0.239282, Val Acc: 0.505155\n",
      "Epoch 1964 - Train Loss: 0.230115, Train Acc: 0.553846 | Val Loss: 0.239260, Val Acc: 0.505155\n",
      "Epoch 1965 - Train Loss: 0.230094, Train Acc: 0.553846 | Val Loss: 0.239239, Val Acc: 0.505155\n",
      "Epoch 1966 - Train Loss: 0.230072, Train Acc: 0.553846 | Val Loss: 0.239218, Val Acc: 0.505155\n",
      "Epoch 1967 - Train Loss: 0.230050, Train Acc: 0.553846 | Val Loss: 0.239197, Val Acc: 0.505155\n",
      "Epoch 1968 - Train Loss: 0.230029, Train Acc: 0.553846 | Val Loss: 0.239176, Val Acc: 0.505155\n",
      "Epoch 1969 - Train Loss: 0.230007, Train Acc: 0.553846 | Val Loss: 0.239154, Val Acc: 0.505155\n",
      "Epoch 1970 - Train Loss: 0.229985, Train Acc: 0.553846 | Val Loss: 0.239133, Val Acc: 0.505155\n",
      "Epoch 1971 - Train Loss: 0.229964, Train Acc: 0.553846 | Val Loss: 0.239112, Val Acc: 0.505155\n",
      "Epoch 1972 - Train Loss: 0.229942, Train Acc: 0.555128 | Val Loss: 0.239091, Val Acc: 0.505155\n",
      "Epoch 1973 - Train Loss: 0.229920, Train Acc: 0.555128 | Val Loss: 0.239070, Val Acc: 0.505155\n",
      "Epoch 1974 - Train Loss: 0.229898, Train Acc: 0.555128 | Val Loss: 0.239048, Val Acc: 0.505155\n",
      "Epoch 1975 - Train Loss: 0.229877, Train Acc: 0.555128 | Val Loss: 0.239027, Val Acc: 0.505155\n",
      "Epoch 1976 - Train Loss: 0.229855, Train Acc: 0.555128 | Val Loss: 0.239006, Val Acc: 0.505155\n",
      "Epoch 1977 - Train Loss: 0.229833, Train Acc: 0.555128 | Val Loss: 0.238985, Val Acc: 0.505155\n",
      "Epoch 1978 - Train Loss: 0.229812, Train Acc: 0.555128 | Val Loss: 0.238964, Val Acc: 0.505155\n",
      "Epoch 1979 - Train Loss: 0.229790, Train Acc: 0.555128 | Val Loss: 0.238942, Val Acc: 0.505155\n",
      "Epoch 1980 - Train Loss: 0.229768, Train Acc: 0.555128 | Val Loss: 0.238921, Val Acc: 0.505155\n",
      "Epoch 1981 - Train Loss: 0.229746, Train Acc: 0.555128 | Val Loss: 0.238900, Val Acc: 0.505155\n",
      "Epoch 1982 - Train Loss: 0.229725, Train Acc: 0.555128 | Val Loss: 0.238879, Val Acc: 0.505155\n",
      "Epoch 1983 - Train Loss: 0.229703, Train Acc: 0.555128 | Val Loss: 0.238858, Val Acc: 0.505155\n",
      "Epoch 1984 - Train Loss: 0.229681, Train Acc: 0.555128 | Val Loss: 0.238836, Val Acc: 0.505155\n",
      "Epoch 1985 - Train Loss: 0.229660, Train Acc: 0.555128 | Val Loss: 0.238815, Val Acc: 0.505155\n",
      "Epoch 1986 - Train Loss: 0.229638, Train Acc: 0.555128 | Val Loss: 0.238794, Val Acc: 0.505155\n",
      "Epoch 1987 - Train Loss: 0.229616, Train Acc: 0.555128 | Val Loss: 0.238773, Val Acc: 0.505155\n",
      "Epoch 1988 - Train Loss: 0.229595, Train Acc: 0.555128 | Val Loss: 0.238752, Val Acc: 0.505155\n",
      "Epoch 1989 - Train Loss: 0.229573, Train Acc: 0.555128 | Val Loss: 0.238730, Val Acc: 0.505155\n",
      "Epoch 1990 - Train Loss: 0.229551, Train Acc: 0.555128 | Val Loss: 0.238709, Val Acc: 0.505155\n",
      "Epoch 1991 - Train Loss: 0.229530, Train Acc: 0.555128 | Val Loss: 0.238688, Val Acc: 0.505155\n",
      "Epoch 1992 - Train Loss: 0.229508, Train Acc: 0.555128 | Val Loss: 0.238667, Val Acc: 0.505155\n",
      "Epoch 1993 - Train Loss: 0.229486, Train Acc: 0.555128 | Val Loss: 0.238645, Val Acc: 0.505155\n",
      "Epoch 1994 - Train Loss: 0.229464, Train Acc: 0.555128 | Val Loss: 0.238624, Val Acc: 0.505155\n",
      "Epoch 1995 - Train Loss: 0.229443, Train Acc: 0.555128 | Val Loss: 0.238603, Val Acc: 0.505155\n",
      "Epoch 1996 - Train Loss: 0.229421, Train Acc: 0.555128 | Val Loss: 0.238582, Val Acc: 0.505155\n",
      "Epoch 1997 - Train Loss: 0.229399, Train Acc: 0.555128 | Val Loss: 0.238561, Val Acc: 0.505155\n",
      "Epoch 1998 - Train Loss: 0.229378, Train Acc: 0.555128 | Val Loss: 0.238539, Val Acc: 0.505155\n",
      "Epoch 1999 - Train Loss: 0.229356, Train Acc: 0.555128 | Val Loss: 0.238518, Val Acc: 0.505155\n",
      "Epoch 2000 - Train Loss: 0.229334, Train Acc: 0.555128 | Val Loss: 0.238497, Val Acc: 0.505155\n",
      "Epoch 2001 - Train Loss: 0.229313, Train Acc: 0.555128 | Val Loss: 0.238476, Val Acc: 0.505155\n",
      "Epoch 2002 - Train Loss: 0.229291, Train Acc: 0.555128 | Val Loss: 0.238455, Val Acc: 0.505155\n",
      "Epoch 2003 - Train Loss: 0.229269, Train Acc: 0.555128 | Val Loss: 0.238433, Val Acc: 0.505155\n",
      "Epoch 2004 - Train Loss: 0.229248, Train Acc: 0.555128 | Val Loss: 0.238412, Val Acc: 0.505155\n",
      "Epoch 2005 - Train Loss: 0.229226, Train Acc: 0.555128 | Val Loss: 0.238391, Val Acc: 0.505155\n",
      "Epoch 2006 - Train Loss: 0.229204, Train Acc: 0.555128 | Val Loss: 0.238370, Val Acc: 0.505155\n",
      "Epoch 2007 - Train Loss: 0.229183, Train Acc: 0.555128 | Val Loss: 0.238349, Val Acc: 0.505155\n",
      "Epoch 2008 - Train Loss: 0.229161, Train Acc: 0.555128 | Val Loss: 0.238327, Val Acc: 0.505155\n",
      "Epoch 2009 - Train Loss: 0.229139, Train Acc: 0.555128 | Val Loss: 0.238306, Val Acc: 0.505155\n",
      "Epoch 2010 - Train Loss: 0.229117, Train Acc: 0.555128 | Val Loss: 0.238285, Val Acc: 0.505155\n",
      "Epoch 2011 - Train Loss: 0.229096, Train Acc: 0.555128 | Val Loss: 0.238264, Val Acc: 0.505155\n",
      "Epoch 2012 - Train Loss: 0.229074, Train Acc: 0.555128 | Val Loss: 0.238243, Val Acc: 0.505155\n",
      "Epoch 2013 - Train Loss: 0.229052, Train Acc: 0.555128 | Val Loss: 0.238221, Val Acc: 0.505155\n",
      "Epoch 2014 - Train Loss: 0.229031, Train Acc: 0.555128 | Val Loss: 0.238200, Val Acc: 0.505155\n",
      "Epoch 2015 - Train Loss: 0.229009, Train Acc: 0.555128 | Val Loss: 0.238179, Val Acc: 0.505155\n",
      "Epoch 2016 - Train Loss: 0.228987, Train Acc: 0.555128 | Val Loss: 0.238158, Val Acc: 0.505155\n",
      "Epoch 2017 - Train Loss: 0.228966, Train Acc: 0.555128 | Val Loss: 0.238137, Val Acc: 0.505155\n",
      "Epoch 2018 - Train Loss: 0.228944, Train Acc: 0.555128 | Val Loss: 0.238115, Val Acc: 0.505155\n",
      "Epoch 2019 - Train Loss: 0.228922, Train Acc: 0.555128 | Val Loss: 0.238094, Val Acc: 0.505155\n",
      "Epoch 2020 - Train Loss: 0.228901, Train Acc: 0.555128 | Val Loss: 0.238073, Val Acc: 0.505155\n",
      "Epoch 2021 - Train Loss: 0.228879, Train Acc: 0.555128 | Val Loss: 0.238052, Val Acc: 0.505155\n",
      "Epoch 2022 - Train Loss: 0.228857, Train Acc: 0.555128 | Val Loss: 0.238031, Val Acc: 0.505155\n",
      "Epoch 2023 - Train Loss: 0.228836, Train Acc: 0.555128 | Val Loss: 0.238010, Val Acc: 0.505155\n",
      "Epoch 2024 - Train Loss: 0.228814, Train Acc: 0.555128 | Val Loss: 0.237988, Val Acc: 0.505155\n",
      "Epoch 2025 - Train Loss: 0.228792, Train Acc: 0.555128 | Val Loss: 0.237967, Val Acc: 0.505155\n",
      "Epoch 2026 - Train Loss: 0.228771, Train Acc: 0.555128 | Val Loss: 0.237946, Val Acc: 0.505155\n",
      "Epoch 2027 - Train Loss: 0.228749, Train Acc: 0.555128 | Val Loss: 0.237925, Val Acc: 0.505155\n",
      "Epoch 2028 - Train Loss: 0.228727, Train Acc: 0.555128 | Val Loss: 0.237904, Val Acc: 0.505155\n",
      "Epoch 2029 - Train Loss: 0.228706, Train Acc: 0.555128 | Val Loss: 0.237882, Val Acc: 0.505155\n",
      "Epoch 2030 - Train Loss: 0.228684, Train Acc: 0.555128 | Val Loss: 0.237861, Val Acc: 0.505155\n",
      "Epoch 2031 - Train Loss: 0.228662, Train Acc: 0.555128 | Val Loss: 0.237840, Val Acc: 0.505155\n",
      "Epoch 2032 - Train Loss: 0.228641, Train Acc: 0.555128 | Val Loss: 0.237819, Val Acc: 0.505155\n",
      "Epoch 2033 - Train Loss: 0.228619, Train Acc: 0.555128 | Val Loss: 0.237798, Val Acc: 0.505155\n",
      "Epoch 2034 - Train Loss: 0.228598, Train Acc: 0.555128 | Val Loss: 0.237777, Val Acc: 0.505155\n",
      "Epoch 2035 - Train Loss: 0.228576, Train Acc: 0.555128 | Val Loss: 0.237755, Val Acc: 0.505155\n",
      "Epoch 2036 - Train Loss: 0.228554, Train Acc: 0.555128 | Val Loss: 0.237734, Val Acc: 0.505155\n",
      "Epoch 2037 - Train Loss: 0.228533, Train Acc: 0.555128 | Val Loss: 0.237713, Val Acc: 0.505155\n",
      "Epoch 2038 - Train Loss: 0.228511, Train Acc: 0.555128 | Val Loss: 0.237692, Val Acc: 0.505155\n",
      "Epoch 2039 - Train Loss: 0.228489, Train Acc: 0.555128 | Val Loss: 0.237671, Val Acc: 0.505155\n",
      "Epoch 2040 - Train Loss: 0.228468, Train Acc: 0.555128 | Val Loss: 0.237650, Val Acc: 0.505155\n",
      "Epoch 2041 - Train Loss: 0.228446, Train Acc: 0.555128 | Val Loss: 0.237629, Val Acc: 0.505155\n",
      "Epoch 2042 - Train Loss: 0.228424, Train Acc: 0.555128 | Val Loss: 0.237607, Val Acc: 0.505155\n",
      "Epoch 2043 - Train Loss: 0.228403, Train Acc: 0.555128 | Val Loss: 0.237586, Val Acc: 0.505155\n",
      "Epoch 2044 - Train Loss: 0.228381, Train Acc: 0.555128 | Val Loss: 0.237565, Val Acc: 0.505155\n",
      "Epoch 2045 - Train Loss: 0.228359, Train Acc: 0.555128 | Val Loss: 0.237544, Val Acc: 0.505155\n",
      "Epoch 2046 - Train Loss: 0.228338, Train Acc: 0.555128 | Val Loss: 0.237523, Val Acc: 0.505155\n",
      "Epoch 2047 - Train Loss: 0.228316, Train Acc: 0.555128 | Val Loss: 0.237502, Val Acc: 0.505155\n",
      "Epoch 2048 - Train Loss: 0.228295, Train Acc: 0.555128 | Val Loss: 0.237481, Val Acc: 0.505155\n",
      "Epoch 2049 - Train Loss: 0.228273, Train Acc: 0.555128 | Val Loss: 0.237459, Val Acc: 0.505155\n",
      "Epoch 2050 - Train Loss: 0.228251, Train Acc: 0.555128 | Val Loss: 0.237438, Val Acc: 0.505155\n",
      "Epoch 2051 - Train Loss: 0.228230, Train Acc: 0.555128 | Val Loss: 0.237417, Val Acc: 0.505155\n",
      "Epoch 2052 - Train Loss: 0.228208, Train Acc: 0.557692 | Val Loss: 0.237396, Val Acc: 0.505155\n",
      "Epoch 2053 - Train Loss: 0.228186, Train Acc: 0.560256 | Val Loss: 0.237375, Val Acc: 0.505155\n",
      "Epoch 2054 - Train Loss: 0.228165, Train Acc: 0.560256 | Val Loss: 0.237354, Val Acc: 0.505155\n",
      "Epoch 2055 - Train Loss: 0.228143, Train Acc: 0.560256 | Val Loss: 0.237333, Val Acc: 0.505155\n",
      "Epoch 2056 - Train Loss: 0.228121, Train Acc: 0.560256 | Val Loss: 0.237311, Val Acc: 0.505155\n",
      "Epoch 2057 - Train Loss: 0.228100, Train Acc: 0.560256 | Val Loss: 0.237290, Val Acc: 0.505155\n",
      "Epoch 2058 - Train Loss: 0.228078, Train Acc: 0.560256 | Val Loss: 0.237269, Val Acc: 0.505155\n",
      "Epoch 2059 - Train Loss: 0.228057, Train Acc: 0.560256 | Val Loss: 0.237248, Val Acc: 0.505155\n",
      "Epoch 2060 - Train Loss: 0.228035, Train Acc: 0.560256 | Val Loss: 0.237227, Val Acc: 0.505155\n",
      "Epoch 2061 - Train Loss: 0.228013, Train Acc: 0.560256 | Val Loss: 0.237206, Val Acc: 0.505155\n",
      "Epoch 2062 - Train Loss: 0.227992, Train Acc: 0.561538 | Val Loss: 0.237185, Val Acc: 0.505155\n",
      "Epoch 2063 - Train Loss: 0.227970, Train Acc: 0.561538 | Val Loss: 0.237163, Val Acc: 0.505155\n",
      "Epoch 2064 - Train Loss: 0.227948, Train Acc: 0.561538 | Val Loss: 0.237142, Val Acc: 0.505155\n",
      "Epoch 2065 - Train Loss: 0.227927, Train Acc: 0.561538 | Val Loss: 0.237121, Val Acc: 0.505155\n",
      "Epoch 2066 - Train Loss: 0.227905, Train Acc: 0.561538 | Val Loss: 0.237100, Val Acc: 0.505155\n",
      "Epoch 2067 - Train Loss: 0.227884, Train Acc: 0.561538 | Val Loss: 0.237079, Val Acc: 0.505155\n",
      "Epoch 2068 - Train Loss: 0.227862, Train Acc: 0.561538 | Val Loss: 0.237058, Val Acc: 0.505155\n",
      "Epoch 2069 - Train Loss: 0.227840, Train Acc: 0.561538 | Val Loss: 0.237037, Val Acc: 0.505155\n",
      "Epoch 2070 - Train Loss: 0.227819, Train Acc: 0.561538 | Val Loss: 0.237016, Val Acc: 0.505155\n",
      "Epoch 2071 - Train Loss: 0.227797, Train Acc: 0.561538 | Val Loss: 0.236994, Val Acc: 0.505155\n",
      "Epoch 2072 - Train Loss: 0.227776, Train Acc: 0.561538 | Val Loss: 0.236973, Val Acc: 0.505155\n",
      "Epoch 2073 - Train Loss: 0.227754, Train Acc: 0.561538 | Val Loss: 0.236952, Val Acc: 0.505155\n",
      "Epoch 2074 - Train Loss: 0.227732, Train Acc: 0.561538 | Val Loss: 0.236931, Val Acc: 0.505155\n",
      "Epoch 2075 - Train Loss: 0.227711, Train Acc: 0.561538 | Val Loss: 0.236910, Val Acc: 0.505155\n",
      "Epoch 2076 - Train Loss: 0.227689, Train Acc: 0.561538 | Val Loss: 0.236889, Val Acc: 0.505155\n",
      "Epoch 2077 - Train Loss: 0.227668, Train Acc: 0.561538 | Val Loss: 0.236868, Val Acc: 0.505155\n",
      "Epoch 2078 - Train Loss: 0.227646, Train Acc: 0.561538 | Val Loss: 0.236847, Val Acc: 0.505155\n",
      "Epoch 2079 - Train Loss: 0.227624, Train Acc: 0.561538 | Val Loss: 0.236826, Val Acc: 0.505155\n",
      "Epoch 2080 - Train Loss: 0.227603, Train Acc: 0.561538 | Val Loss: 0.236804, Val Acc: 0.505155\n",
      "Epoch 2081 - Train Loss: 0.227581, Train Acc: 0.561538 | Val Loss: 0.236783, Val Acc: 0.505155\n",
      "Epoch 2082 - Train Loss: 0.227560, Train Acc: 0.561538 | Val Loss: 0.236762, Val Acc: 0.505155\n",
      "Epoch 2083 - Train Loss: 0.227538, Train Acc: 0.562821 | Val Loss: 0.236741, Val Acc: 0.505155\n",
      "Epoch 2084 - Train Loss: 0.227516, Train Acc: 0.562821 | Val Loss: 0.236720, Val Acc: 0.505155\n",
      "Epoch 2085 - Train Loss: 0.227495, Train Acc: 0.562821 | Val Loss: 0.236699, Val Acc: 0.505155\n",
      "Epoch 2086 - Train Loss: 0.227473, Train Acc: 0.562821 | Val Loss: 0.236678, Val Acc: 0.505155\n",
      "Epoch 2087 - Train Loss: 0.227452, Train Acc: 0.562821 | Val Loss: 0.236657, Val Acc: 0.505155\n",
      "Epoch 2088 - Train Loss: 0.227430, Train Acc: 0.562821 | Val Loss: 0.236636, Val Acc: 0.505155\n",
      "Epoch 2089 - Train Loss: 0.227408, Train Acc: 0.562821 | Val Loss: 0.236615, Val Acc: 0.505155\n",
      "Epoch 2090 - Train Loss: 0.227387, Train Acc: 0.562821 | Val Loss: 0.236593, Val Acc: 0.505155\n",
      "Epoch 2091 - Train Loss: 0.227365, Train Acc: 0.562821 | Val Loss: 0.236572, Val Acc: 0.505155\n",
      "Epoch 2092 - Train Loss: 0.227344, Train Acc: 0.562821 | Val Loss: 0.236551, Val Acc: 0.505155\n",
      "Epoch 2093 - Train Loss: 0.227322, Train Acc: 0.562821 | Val Loss: 0.236530, Val Acc: 0.505155\n",
      "Epoch 2094 - Train Loss: 0.227300, Train Acc: 0.562821 | Val Loss: 0.236509, Val Acc: 0.505155\n",
      "Epoch 2095 - Train Loss: 0.227279, Train Acc: 0.562821 | Val Loss: 0.236488, Val Acc: 0.505155\n",
      "Epoch 2096 - Train Loss: 0.227257, Train Acc: 0.562821 | Val Loss: 0.236467, Val Acc: 0.505155\n",
      "Epoch 2097 - Train Loss: 0.227236, Train Acc: 0.562821 | Val Loss: 0.236446, Val Acc: 0.505155\n",
      "Epoch 2098 - Train Loss: 0.227214, Train Acc: 0.562821 | Val Loss: 0.236425, Val Acc: 0.505155\n",
      "Epoch 2099 - Train Loss: 0.227193, Train Acc: 0.564103 | Val Loss: 0.236404, Val Acc: 0.505155\n",
      "Epoch 2100 - Train Loss: 0.227171, Train Acc: 0.564103 | Val Loss: 0.236383, Val Acc: 0.505155\n",
      "Epoch 2101 - Train Loss: 0.227149, Train Acc: 0.564103 | Val Loss: 0.236361, Val Acc: 0.505155\n",
      "Epoch 2102 - Train Loss: 0.227128, Train Acc: 0.565385 | Val Loss: 0.236340, Val Acc: 0.505155\n",
      "Epoch 2103 - Train Loss: 0.227106, Train Acc: 0.565385 | Val Loss: 0.236319, Val Acc: 0.505155\n",
      "Epoch 2104 - Train Loss: 0.227085, Train Acc: 0.565385 | Val Loss: 0.236298, Val Acc: 0.505155\n",
      "Epoch 2105 - Train Loss: 0.227063, Train Acc: 0.565385 | Val Loss: 0.236277, Val Acc: 0.505155\n",
      "Epoch 2106 - Train Loss: 0.227042, Train Acc: 0.565385 | Val Loss: 0.236256, Val Acc: 0.505155\n",
      "Epoch 2107 - Train Loss: 0.227020, Train Acc: 0.565385 | Val Loss: 0.236235, Val Acc: 0.505155\n",
      "Epoch 2108 - Train Loss: 0.226999, Train Acc: 0.565385 | Val Loss: 0.236214, Val Acc: 0.505155\n",
      "Epoch 2109 - Train Loss: 0.226977, Train Acc: 0.565385 | Val Loss: 0.236193, Val Acc: 0.505155\n",
      "Epoch 2110 - Train Loss: 0.226955, Train Acc: 0.565385 | Val Loss: 0.236172, Val Acc: 0.505155\n",
      "Epoch 2111 - Train Loss: 0.226934, Train Acc: 0.565385 | Val Loss: 0.236150, Val Acc: 0.505155\n",
      "Epoch 2112 - Train Loss: 0.226912, Train Acc: 0.565385 | Val Loss: 0.236129, Val Acc: 0.505155\n",
      "Epoch 2113 - Train Loss: 0.226891, Train Acc: 0.565385 | Val Loss: 0.236108, Val Acc: 0.505155\n",
      "Epoch 2114 - Train Loss: 0.226869, Train Acc: 0.565385 | Val Loss: 0.236087, Val Acc: 0.505155\n",
      "Epoch 2115 - Train Loss: 0.226848, Train Acc: 0.565385 | Val Loss: 0.236066, Val Acc: 0.505155\n",
      "Epoch 2116 - Train Loss: 0.226826, Train Acc: 0.565385 | Val Loss: 0.236045, Val Acc: 0.505155\n",
      "Epoch 2117 - Train Loss: 0.226805, Train Acc: 0.565385 | Val Loss: 0.236024, Val Acc: 0.505155\n",
      "Epoch 2118 - Train Loss: 0.226783, Train Acc: 0.565385 | Val Loss: 0.236003, Val Acc: 0.505155\n",
      "Epoch 2119 - Train Loss: 0.226761, Train Acc: 0.565385 | Val Loss: 0.235982, Val Acc: 0.505155\n",
      "Epoch 2120 - Train Loss: 0.226740, Train Acc: 0.565385 | Val Loss: 0.235961, Val Acc: 0.505155\n",
      "Epoch 2121 - Train Loss: 0.226718, Train Acc: 0.565385 | Val Loss: 0.235940, Val Acc: 0.505155\n",
      "Epoch 2122 - Train Loss: 0.226697, Train Acc: 0.565385 | Val Loss: 0.235918, Val Acc: 0.505155\n",
      "Epoch 2123 - Train Loss: 0.226675, Train Acc: 0.565385 | Val Loss: 0.235897, Val Acc: 0.505155\n",
      "Epoch 2124 - Train Loss: 0.226654, Train Acc: 0.565385 | Val Loss: 0.235876, Val Acc: 0.505155\n",
      "Epoch 2125 - Train Loss: 0.226632, Train Acc: 0.565385 | Val Loss: 0.235855, Val Acc: 0.505155\n",
      "Epoch 2126 - Train Loss: 0.226611, Train Acc: 0.565385 | Val Loss: 0.235834, Val Acc: 0.505155\n",
      "Epoch 2127 - Train Loss: 0.226589, Train Acc: 0.565385 | Val Loss: 0.235813, Val Acc: 0.505155\n",
      "Epoch 2128 - Train Loss: 0.226568, Train Acc: 0.565385 | Val Loss: 0.235792, Val Acc: 0.505155\n",
      "Epoch 2129 - Train Loss: 0.226546, Train Acc: 0.565385 | Val Loss: 0.235771, Val Acc: 0.505155\n",
      "Epoch 2130 - Train Loss: 0.226525, Train Acc: 0.565385 | Val Loss: 0.235750, Val Acc: 0.505155\n",
      "Epoch 2131 - Train Loss: 0.226503, Train Acc: 0.565385 | Val Loss: 0.235729, Val Acc: 0.505155\n",
      "Epoch 2132 - Train Loss: 0.226482, Train Acc: 0.565385 | Val Loss: 0.235708, Val Acc: 0.515464\n",
      "Epoch 2133 - Train Loss: 0.226460, Train Acc: 0.565385 | Val Loss: 0.235687, Val Acc: 0.515464\n",
      "Epoch 2134 - Train Loss: 0.226439, Train Acc: 0.565385 | Val Loss: 0.235666, Val Acc: 0.515464\n",
      "Epoch 2135 - Train Loss: 0.226417, Train Acc: 0.565385 | Val Loss: 0.235645, Val Acc: 0.515464\n",
      "Epoch 2136 - Train Loss: 0.226395, Train Acc: 0.565385 | Val Loss: 0.235624, Val Acc: 0.515464\n",
      "Epoch 2137 - Train Loss: 0.226374, Train Acc: 0.565385 | Val Loss: 0.235602, Val Acc: 0.515464\n",
      "Epoch 2138 - Train Loss: 0.226352, Train Acc: 0.565385 | Val Loss: 0.235581, Val Acc: 0.515464\n",
      "Epoch 2139 - Train Loss: 0.226331, Train Acc: 0.565385 | Val Loss: 0.235560, Val Acc: 0.515464\n",
      "Epoch 2140 - Train Loss: 0.226309, Train Acc: 0.566667 | Val Loss: 0.235539, Val Acc: 0.515464\n",
      "Epoch 2141 - Train Loss: 0.226288, Train Acc: 0.566667 | Val Loss: 0.235518, Val Acc: 0.515464\n",
      "Epoch 2142 - Train Loss: 0.226266, Train Acc: 0.566667 | Val Loss: 0.235497, Val Acc: 0.515464\n",
      "Epoch 2143 - Train Loss: 0.226245, Train Acc: 0.566667 | Val Loss: 0.235476, Val Acc: 0.515464\n",
      "Epoch 2144 - Train Loss: 0.226223, Train Acc: 0.566667 | Val Loss: 0.235455, Val Acc: 0.515464\n",
      "Epoch 2145 - Train Loss: 0.226202, Train Acc: 0.566667 | Val Loss: 0.235434, Val Acc: 0.515464\n",
      "Epoch 2146 - Train Loss: 0.226180, Train Acc: 0.566667 | Val Loss: 0.235413, Val Acc: 0.515464\n",
      "Epoch 2147 - Train Loss: 0.226159, Train Acc: 0.566667 | Val Loss: 0.235392, Val Acc: 0.515464\n",
      "Epoch 2148 - Train Loss: 0.226137, Train Acc: 0.566667 | Val Loss: 0.235371, Val Acc: 0.515464\n",
      "Epoch 2149 - Train Loss: 0.226116, Train Acc: 0.566667 | Val Loss: 0.235350, Val Acc: 0.515464\n",
      "Epoch 2150 - Train Loss: 0.226094, Train Acc: 0.566667 | Val Loss: 0.235329, Val Acc: 0.515464\n",
      "Epoch 2151 - Train Loss: 0.226073, Train Acc: 0.566667 | Val Loss: 0.235308, Val Acc: 0.515464\n",
      "Epoch 2152 - Train Loss: 0.226051, Train Acc: 0.566667 | Val Loss: 0.235287, Val Acc: 0.515464\n",
      "Epoch 2153 - Train Loss: 0.226030, Train Acc: 0.566667 | Val Loss: 0.235266, Val Acc: 0.515464\n",
      "Epoch 2154 - Train Loss: 0.226008, Train Acc: 0.566667 | Val Loss: 0.235245, Val Acc: 0.515464\n",
      "Epoch 2155 - Train Loss: 0.225987, Train Acc: 0.566667 | Val Loss: 0.235224, Val Acc: 0.515464\n",
      "Epoch 2156 - Train Loss: 0.225965, Train Acc: 0.566667 | Val Loss: 0.235203, Val Acc: 0.515464\n",
      "Epoch 2157 - Train Loss: 0.225944, Train Acc: 0.566667 | Val Loss: 0.235182, Val Acc: 0.515464\n",
      "Epoch 2158 - Train Loss: 0.225922, Train Acc: 0.566667 | Val Loss: 0.235161, Val Acc: 0.515464\n",
      "Epoch 2159 - Train Loss: 0.225901, Train Acc: 0.566667 | Val Loss: 0.235140, Val Acc: 0.515464\n",
      "Epoch 2160 - Train Loss: 0.225879, Train Acc: 0.566667 | Val Loss: 0.235119, Val Acc: 0.515464\n",
      "Epoch 2161 - Train Loss: 0.225858, Train Acc: 0.566667 | Val Loss: 0.235098, Val Acc: 0.515464\n",
      "Epoch 2162 - Train Loss: 0.225836, Train Acc: 0.566667 | Val Loss: 0.235077, Val Acc: 0.515464\n",
      "Epoch 2163 - Train Loss: 0.225815, Train Acc: 0.566667 | Val Loss: 0.235056, Val Acc: 0.515464\n",
      "Epoch 2164 - Train Loss: 0.225793, Train Acc: 0.566667 | Val Loss: 0.235035, Val Acc: 0.515464\n",
      "Epoch 2165 - Train Loss: 0.225772, Train Acc: 0.567949 | Val Loss: 0.235014, Val Acc: 0.515464\n",
      "Epoch 2166 - Train Loss: 0.225750, Train Acc: 0.567949 | Val Loss: 0.234993, Val Acc: 0.515464\n",
      "Epoch 2167 - Train Loss: 0.225729, Train Acc: 0.569231 | Val Loss: 0.234972, Val Acc: 0.515464\n",
      "Epoch 2168 - Train Loss: 0.225707, Train Acc: 0.569231 | Val Loss: 0.234951, Val Acc: 0.515464\n",
      "Epoch 2169 - Train Loss: 0.225686, Train Acc: 0.569231 | Val Loss: 0.234930, Val Acc: 0.515464\n",
      "Epoch 2170 - Train Loss: 0.225665, Train Acc: 0.569231 | Val Loss: 0.234909, Val Acc: 0.515464\n",
      "Epoch 2171 - Train Loss: 0.225643, Train Acc: 0.569231 | Val Loss: 0.234888, Val Acc: 0.515464\n",
      "Epoch 2172 - Train Loss: 0.225622, Train Acc: 0.569231 | Val Loss: 0.234867, Val Acc: 0.515464\n",
      "Epoch 2173 - Train Loss: 0.225600, Train Acc: 0.569231 | Val Loss: 0.234846, Val Acc: 0.515464\n",
      "Epoch 2174 - Train Loss: 0.225579, Train Acc: 0.569231 | Val Loss: 0.234825, Val Acc: 0.515464\n",
      "Epoch 2175 - Train Loss: 0.225557, Train Acc: 0.569231 | Val Loss: 0.234804, Val Acc: 0.515464\n",
      "Epoch 2176 - Train Loss: 0.225536, Train Acc: 0.569231 | Val Loss: 0.234783, Val Acc: 0.515464\n",
      "Epoch 2177 - Train Loss: 0.225514, Train Acc: 0.569231 | Val Loss: 0.234762, Val Acc: 0.515464\n",
      "Epoch 2178 - Train Loss: 0.225493, Train Acc: 0.569231 | Val Loss: 0.234741, Val Acc: 0.515464\n",
      "Epoch 2179 - Train Loss: 0.225471, Train Acc: 0.569231 | Val Loss: 0.234720, Val Acc: 0.515464\n",
      "Epoch 2180 - Train Loss: 0.225450, Train Acc: 0.569231 | Val Loss: 0.234699, Val Acc: 0.515464\n",
      "Epoch 2181 - Train Loss: 0.225428, Train Acc: 0.569231 | Val Loss: 0.234678, Val Acc: 0.515464\n",
      "Epoch 2182 - Train Loss: 0.225407, Train Acc: 0.569231 | Val Loss: 0.234657, Val Acc: 0.515464\n",
      "Epoch 2183 - Train Loss: 0.225386, Train Acc: 0.569231 | Val Loss: 0.234636, Val Acc: 0.515464\n",
      "Epoch 2184 - Train Loss: 0.225364, Train Acc: 0.569231 | Val Loss: 0.234615, Val Acc: 0.515464\n",
      "Epoch 2185 - Train Loss: 0.225343, Train Acc: 0.569231 | Val Loss: 0.234594, Val Acc: 0.515464\n",
      "Epoch 2186 - Train Loss: 0.225321, Train Acc: 0.569231 | Val Loss: 0.234573, Val Acc: 0.515464\n",
      "Epoch 2187 - Train Loss: 0.225300, Train Acc: 0.569231 | Val Loss: 0.234552, Val Acc: 0.515464\n",
      "Epoch 2188 - Train Loss: 0.225278, Train Acc: 0.569231 | Val Loss: 0.234531, Val Acc: 0.515464\n",
      "Epoch 2189 - Train Loss: 0.225257, Train Acc: 0.569231 | Val Loss: 0.234510, Val Acc: 0.515464\n",
      "Epoch 2190 - Train Loss: 0.225235, Train Acc: 0.569231 | Val Loss: 0.234489, Val Acc: 0.515464\n",
      "Epoch 2191 - Train Loss: 0.225214, Train Acc: 0.569231 | Val Loss: 0.234468, Val Acc: 0.515464\n",
      "Epoch 2192 - Train Loss: 0.225192, Train Acc: 0.569231 | Val Loss: 0.234447, Val Acc: 0.515464\n",
      "Epoch 2193 - Train Loss: 0.225171, Train Acc: 0.569231 | Val Loss: 0.234426, Val Acc: 0.515464\n",
      "Epoch 2194 - Train Loss: 0.225150, Train Acc: 0.569231 | Val Loss: 0.234405, Val Acc: 0.515464\n",
      "Epoch 2195 - Train Loss: 0.225128, Train Acc: 0.569231 | Val Loss: 0.234384, Val Acc: 0.515464\n",
      "Epoch 2196 - Train Loss: 0.225107, Train Acc: 0.569231 | Val Loss: 0.234363, Val Acc: 0.515464\n",
      "Epoch 2197 - Train Loss: 0.225085, Train Acc: 0.569231 | Val Loss: 0.234342, Val Acc: 0.515464\n",
      "Epoch 2198 - Train Loss: 0.225064, Train Acc: 0.569231 | Val Loss: 0.234321, Val Acc: 0.515464\n",
      "Epoch 2199 - Train Loss: 0.225042, Train Acc: 0.569231 | Val Loss: 0.234300, Val Acc: 0.515464\n",
      "Epoch 2200 - Train Loss: 0.225021, Train Acc: 0.569231 | Val Loss: 0.234280, Val Acc: 0.515464\n",
      "Epoch 2201 - Train Loss: 0.225000, Train Acc: 0.569231 | Val Loss: 0.234259, Val Acc: 0.515464\n",
      "Epoch 2202 - Train Loss: 0.224978, Train Acc: 0.569231 | Val Loss: 0.234238, Val Acc: 0.515464\n",
      "Epoch 2203 - Train Loss: 0.224957, Train Acc: 0.569231 | Val Loss: 0.234217, Val Acc: 0.515464\n",
      "Epoch 2204 - Train Loss: 0.224935, Train Acc: 0.569231 | Val Loss: 0.234196, Val Acc: 0.515464\n",
      "Epoch 2205 - Train Loss: 0.224914, Train Acc: 0.569231 | Val Loss: 0.234175, Val Acc: 0.515464\n",
      "Epoch 2206 - Train Loss: 0.224893, Train Acc: 0.569231 | Val Loss: 0.234154, Val Acc: 0.515464\n",
      "Epoch 2207 - Train Loss: 0.224871, Train Acc: 0.569231 | Val Loss: 0.234133, Val Acc: 0.515464\n",
      "Epoch 2208 - Train Loss: 0.224850, Train Acc: 0.569231 | Val Loss: 0.234112, Val Acc: 0.515464\n",
      "Epoch 2209 - Train Loss: 0.224828, Train Acc: 0.569231 | Val Loss: 0.234091, Val Acc: 0.515464\n",
      "Epoch 2210 - Train Loss: 0.224807, Train Acc: 0.569231 | Val Loss: 0.234070, Val Acc: 0.515464\n",
      "Epoch 2211 - Train Loss: 0.224785, Train Acc: 0.569231 | Val Loss: 0.234049, Val Acc: 0.515464\n",
      "Epoch 2212 - Train Loss: 0.224764, Train Acc: 0.569231 | Val Loss: 0.234028, Val Acc: 0.515464\n",
      "Epoch 2213 - Train Loss: 0.224743, Train Acc: 0.569231 | Val Loss: 0.234007, Val Acc: 0.515464\n",
      "Epoch 2214 - Train Loss: 0.224721, Train Acc: 0.569231 | Val Loss: 0.233986, Val Acc: 0.515464\n",
      "Epoch 2215 - Train Loss: 0.224700, Train Acc: 0.569231 | Val Loss: 0.233966, Val Acc: 0.515464\n",
      "Epoch 2216 - Train Loss: 0.224678, Train Acc: 0.569231 | Val Loss: 0.233945, Val Acc: 0.515464\n",
      "Epoch 2217 - Train Loss: 0.224657, Train Acc: 0.569231 | Val Loss: 0.233924, Val Acc: 0.515464\n",
      "Epoch 2218 - Train Loss: 0.224636, Train Acc: 0.569231 | Val Loss: 0.233903, Val Acc: 0.515464\n",
      "Epoch 2219 - Train Loss: 0.224614, Train Acc: 0.569231 | Val Loss: 0.233882, Val Acc: 0.515464\n",
      "Epoch 2220 - Train Loss: 0.224593, Train Acc: 0.570513 | Val Loss: 0.233861, Val Acc: 0.515464\n",
      "Epoch 2221 - Train Loss: 0.224572, Train Acc: 0.570513 | Val Loss: 0.233840, Val Acc: 0.515464\n",
      "Epoch 2222 - Train Loss: 0.224550, Train Acc: 0.570513 | Val Loss: 0.233819, Val Acc: 0.515464\n",
      "Epoch 2223 - Train Loss: 0.224529, Train Acc: 0.570513 | Val Loss: 0.233798, Val Acc: 0.515464\n",
      "Epoch 2224 - Train Loss: 0.224507, Train Acc: 0.570513 | Val Loss: 0.233777, Val Acc: 0.515464\n",
      "Epoch 2225 - Train Loss: 0.224486, Train Acc: 0.570513 | Val Loss: 0.233756, Val Acc: 0.515464\n",
      "Epoch 2226 - Train Loss: 0.224465, Train Acc: 0.570513 | Val Loss: 0.233735, Val Acc: 0.515464\n",
      "Epoch 2227 - Train Loss: 0.224443, Train Acc: 0.570513 | Val Loss: 0.233714, Val Acc: 0.515464\n",
      "Epoch 2228 - Train Loss: 0.224422, Train Acc: 0.570513 | Val Loss: 0.233694, Val Acc: 0.515464\n",
      "Epoch 2229 - Train Loss: 0.224401, Train Acc: 0.570513 | Val Loss: 0.233673, Val Acc: 0.515464\n",
      "Epoch 2230 - Train Loss: 0.224379, Train Acc: 0.570513 | Val Loss: 0.233652, Val Acc: 0.515464\n",
      "Epoch 2231 - Train Loss: 0.224358, Train Acc: 0.570513 | Val Loss: 0.233631, Val Acc: 0.515464\n",
      "Epoch 2232 - Train Loss: 0.224337, Train Acc: 0.570513 | Val Loss: 0.233610, Val Acc: 0.515464\n",
      "Epoch 2233 - Train Loss: 0.224315, Train Acc: 0.570513 | Val Loss: 0.233589, Val Acc: 0.515464\n",
      "Epoch 2234 - Train Loss: 0.224294, Train Acc: 0.570513 | Val Loss: 0.233568, Val Acc: 0.515464\n",
      "Epoch 2235 - Train Loss: 0.224272, Train Acc: 0.570513 | Val Loss: 0.233547, Val Acc: 0.515464\n",
      "Epoch 2236 - Train Loss: 0.224251, Train Acc: 0.570513 | Val Loss: 0.233526, Val Acc: 0.515464\n",
      "Epoch 2237 - Train Loss: 0.224230, Train Acc: 0.570513 | Val Loss: 0.233506, Val Acc: 0.515464\n",
      "Epoch 2238 - Train Loss: 0.224208, Train Acc: 0.570513 | Val Loss: 0.233485, Val Acc: 0.515464\n",
      "Epoch 2239 - Train Loss: 0.224187, Train Acc: 0.570513 | Val Loss: 0.233464, Val Acc: 0.515464\n",
      "Epoch 2240 - Train Loss: 0.224166, Train Acc: 0.570513 | Val Loss: 0.233443, Val Acc: 0.515464\n",
      "Epoch 2241 - Train Loss: 0.224144, Train Acc: 0.570513 | Val Loss: 0.233422, Val Acc: 0.515464\n",
      "Epoch 2242 - Train Loss: 0.224123, Train Acc: 0.570513 | Val Loss: 0.233401, Val Acc: 0.515464\n",
      "Epoch 2243 - Train Loss: 0.224102, Train Acc: 0.570513 | Val Loss: 0.233380, Val Acc: 0.515464\n",
      "Epoch 2244 - Train Loss: 0.224080, Train Acc: 0.570513 | Val Loss: 0.233359, Val Acc: 0.515464\n",
      "Epoch 2245 - Train Loss: 0.224059, Train Acc: 0.570513 | Val Loss: 0.233339, Val Acc: 0.515464\n",
      "Epoch 2246 - Train Loss: 0.224038, Train Acc: 0.570513 | Val Loss: 0.233318, Val Acc: 0.515464\n",
      "Epoch 2247 - Train Loss: 0.224016, Train Acc: 0.570513 | Val Loss: 0.233297, Val Acc: 0.515464\n",
      "Epoch 2248 - Train Loss: 0.223995, Train Acc: 0.570513 | Val Loss: 0.233276, Val Acc: 0.515464\n",
      "Epoch 2249 - Train Loss: 0.223974, Train Acc: 0.570513 | Val Loss: 0.233255, Val Acc: 0.515464\n",
      "Epoch 2250 - Train Loss: 0.223952, Train Acc: 0.570513 | Val Loss: 0.233234, Val Acc: 0.515464\n",
      "Epoch 2251 - Train Loss: 0.223931, Train Acc: 0.570513 | Val Loss: 0.233213, Val Acc: 0.515464\n",
      "Epoch 2252 - Train Loss: 0.223910, Train Acc: 0.570513 | Val Loss: 0.233193, Val Acc: 0.515464\n",
      "Epoch 2253 - Train Loss: 0.223888, Train Acc: 0.570513 | Val Loss: 0.233172, Val Acc: 0.515464\n",
      "Epoch 2254 - Train Loss: 0.223867, Train Acc: 0.570513 | Val Loss: 0.233151, Val Acc: 0.515464\n",
      "Epoch 2255 - Train Loss: 0.223846, Train Acc: 0.570513 | Val Loss: 0.233130, Val Acc: 0.515464\n",
      "Epoch 2256 - Train Loss: 0.223824, Train Acc: 0.570513 | Val Loss: 0.233109, Val Acc: 0.515464\n",
      "Epoch 2257 - Train Loss: 0.223803, Train Acc: 0.570513 | Val Loss: 0.233088, Val Acc: 0.515464\n",
      "Epoch 2258 - Train Loss: 0.223782, Train Acc: 0.570513 | Val Loss: 0.233067, Val Acc: 0.515464\n",
      "Epoch 2259 - Train Loss: 0.223760, Train Acc: 0.570513 | Val Loss: 0.233047, Val Acc: 0.515464\n",
      "Epoch 2260 - Train Loss: 0.223739, Train Acc: 0.571795 | Val Loss: 0.233026, Val Acc: 0.515464\n",
      "Epoch 2261 - Train Loss: 0.223718, Train Acc: 0.571795 | Val Loss: 0.233005, Val Acc: 0.515464\n",
      "Epoch 2262 - Train Loss: 0.223696, Train Acc: 0.571795 | Val Loss: 0.232984, Val Acc: 0.515464\n",
      "Epoch 2263 - Train Loss: 0.223675, Train Acc: 0.571795 | Val Loss: 0.232963, Val Acc: 0.515464\n",
      "Epoch 2264 - Train Loss: 0.223654, Train Acc: 0.571795 | Val Loss: 0.232942, Val Acc: 0.515464\n",
      "Epoch 2265 - Train Loss: 0.223633, Train Acc: 0.571795 | Val Loss: 0.232922, Val Acc: 0.515464\n",
      "Epoch 2266 - Train Loss: 0.223611, Train Acc: 0.571795 | Val Loss: 0.232901, Val Acc: 0.515464\n",
      "Epoch 2267 - Train Loss: 0.223590, Train Acc: 0.571795 | Val Loss: 0.232880, Val Acc: 0.515464\n",
      "Epoch 2268 - Train Loss: 0.223569, Train Acc: 0.571795 | Val Loss: 0.232859, Val Acc: 0.515464\n",
      "Epoch 2269 - Train Loss: 0.223547, Train Acc: 0.571795 | Val Loss: 0.232838, Val Acc: 0.515464\n",
      "Epoch 2270 - Train Loss: 0.223526, Train Acc: 0.571795 | Val Loss: 0.232817, Val Acc: 0.515464\n",
      "Epoch 2271 - Train Loss: 0.223505, Train Acc: 0.571795 | Val Loss: 0.232797, Val Acc: 0.515464\n",
      "Epoch 2272 - Train Loss: 0.223483, Train Acc: 0.571795 | Val Loss: 0.232776, Val Acc: 0.515464\n",
      "Epoch 2273 - Train Loss: 0.223462, Train Acc: 0.571795 | Val Loss: 0.232755, Val Acc: 0.515464\n",
      "Epoch 2274 - Train Loss: 0.223441, Train Acc: 0.571795 | Val Loss: 0.232734, Val Acc: 0.515464\n",
      "Epoch 2275 - Train Loss: 0.223420, Train Acc: 0.571795 | Val Loss: 0.232713, Val Acc: 0.515464\n",
      "Epoch 2276 - Train Loss: 0.223398, Train Acc: 0.571795 | Val Loss: 0.232693, Val Acc: 0.515464\n",
      "Epoch 2277 - Train Loss: 0.223377, Train Acc: 0.571795 | Val Loss: 0.232672, Val Acc: 0.515464\n",
      "Epoch 2278 - Train Loss: 0.223356, Train Acc: 0.571795 | Val Loss: 0.232651, Val Acc: 0.515464\n",
      "Epoch 2279 - Train Loss: 0.223334, Train Acc: 0.571795 | Val Loss: 0.232630, Val Acc: 0.515464\n",
      "Epoch 2280 - Train Loss: 0.223313, Train Acc: 0.571795 | Val Loss: 0.232609, Val Acc: 0.515464\n",
      "Epoch 2281 - Train Loss: 0.223292, Train Acc: 0.571795 | Val Loss: 0.232589, Val Acc: 0.515464\n",
      "Epoch 2282 - Train Loss: 0.223271, Train Acc: 0.571795 | Val Loss: 0.232568, Val Acc: 0.515464\n",
      "Epoch 2283 - Train Loss: 0.223249, Train Acc: 0.571795 | Val Loss: 0.232547, Val Acc: 0.515464\n",
      "Epoch 2284 - Train Loss: 0.223228, Train Acc: 0.571795 | Val Loss: 0.232526, Val Acc: 0.515464\n",
      "Epoch 2285 - Train Loss: 0.223207, Train Acc: 0.571795 | Val Loss: 0.232505, Val Acc: 0.515464\n",
      "Epoch 2286 - Train Loss: 0.223185, Train Acc: 0.571795 | Val Loss: 0.232485, Val Acc: 0.515464\n",
      "Epoch 2287 - Train Loss: 0.223164, Train Acc: 0.571795 | Val Loss: 0.232464, Val Acc: 0.515464\n",
      "Epoch 2288 - Train Loss: 0.223143, Train Acc: 0.571795 | Val Loss: 0.232443, Val Acc: 0.515464\n",
      "Epoch 2289 - Train Loss: 0.223122, Train Acc: 0.571795 | Val Loss: 0.232422, Val Acc: 0.515464\n",
      "Epoch 2290 - Train Loss: 0.223100, Train Acc: 0.571795 | Val Loss: 0.232401, Val Acc: 0.515464\n",
      "Epoch 2291 - Train Loss: 0.223079, Train Acc: 0.571795 | Val Loss: 0.232381, Val Acc: 0.515464\n",
      "Epoch 2292 - Train Loss: 0.223058, Train Acc: 0.571795 | Val Loss: 0.232360, Val Acc: 0.515464\n",
      "Epoch 2293 - Train Loss: 0.223037, Train Acc: 0.571795 | Val Loss: 0.232339, Val Acc: 0.515464\n",
      "Epoch 2294 - Train Loss: 0.223015, Train Acc: 0.571795 | Val Loss: 0.232318, Val Acc: 0.515464\n",
      "Epoch 2295 - Train Loss: 0.222994, Train Acc: 0.571795 | Val Loss: 0.232297, Val Acc: 0.515464\n",
      "Epoch 2296 - Train Loss: 0.222973, Train Acc: 0.571795 | Val Loss: 0.232277, Val Acc: 0.515464\n",
      "Epoch 2297 - Train Loss: 0.222952, Train Acc: 0.571795 | Val Loss: 0.232256, Val Acc: 0.515464\n",
      "Epoch 2298 - Train Loss: 0.222930, Train Acc: 0.571795 | Val Loss: 0.232235, Val Acc: 0.515464\n",
      "Epoch 2299 - Train Loss: 0.222909, Train Acc: 0.571795 | Val Loss: 0.232214, Val Acc: 0.515464\n",
      "Epoch 2300 - Train Loss: 0.222888, Train Acc: 0.571795 | Val Loss: 0.232194, Val Acc: 0.515464\n",
      "Epoch 2301 - Train Loss: 0.222867, Train Acc: 0.571795 | Val Loss: 0.232173, Val Acc: 0.515464\n",
      "Epoch 2302 - Train Loss: 0.222845, Train Acc: 0.571795 | Val Loss: 0.232152, Val Acc: 0.515464\n",
      "Epoch 2303 - Train Loss: 0.222824, Train Acc: 0.571795 | Val Loss: 0.232131, Val Acc: 0.515464\n",
      "Epoch 2304 - Train Loss: 0.222803, Train Acc: 0.571795 | Val Loss: 0.232110, Val Acc: 0.515464\n",
      "Epoch 2305 - Train Loss: 0.222782, Train Acc: 0.571795 | Val Loss: 0.232089, Val Acc: 0.515464\n",
      "Epoch 2306 - Train Loss: 0.222761, Train Acc: 0.571795 | Val Loss: 0.232069, Val Acc: 0.515464\n",
      "Epoch 2307 - Train Loss: 0.222739, Train Acc: 0.571795 | Val Loss: 0.232048, Val Acc: 0.515464\n",
      "Epoch 2308 - Train Loss: 0.222718, Train Acc: 0.571795 | Val Loss: 0.232027, Val Acc: 0.515464\n",
      "Epoch 2309 - Train Loss: 0.222697, Train Acc: 0.571795 | Val Loss: 0.232006, Val Acc: 0.515464\n",
      "Epoch 2310 - Train Loss: 0.222676, Train Acc: 0.571795 | Val Loss: 0.231985, Val Acc: 0.515464\n",
      "Epoch 2311 - Train Loss: 0.222654, Train Acc: 0.571795 | Val Loss: 0.231965, Val Acc: 0.515464\n",
      "Epoch 2312 - Train Loss: 0.222633, Train Acc: 0.571795 | Val Loss: 0.231944, Val Acc: 0.515464\n",
      "Epoch 2313 - Train Loss: 0.222612, Train Acc: 0.571795 | Val Loss: 0.231923, Val Acc: 0.515464\n",
      "Epoch 2314 - Train Loss: 0.222591, Train Acc: 0.571795 | Val Loss: 0.231902, Val Acc: 0.515464\n",
      "Epoch 2315 - Train Loss: 0.222570, Train Acc: 0.571795 | Val Loss: 0.231881, Val Acc: 0.515464\n",
      "Epoch 2316 - Train Loss: 0.222548, Train Acc: 0.571795 | Val Loss: 0.231861, Val Acc: 0.515464\n",
      "Epoch 2317 - Train Loss: 0.222527, Train Acc: 0.571795 | Val Loss: 0.231840, Val Acc: 0.515464\n",
      "Epoch 2318 - Train Loss: 0.222506, Train Acc: 0.571795 | Val Loss: 0.231819, Val Acc: 0.515464\n",
      "Epoch 2319 - Train Loss: 0.222485, Train Acc: 0.571795 | Val Loss: 0.231798, Val Acc: 0.515464\n",
      "Epoch 2320 - Train Loss: 0.222463, Train Acc: 0.571795 | Val Loss: 0.231777, Val Acc: 0.515464\n",
      "Epoch 2321 - Train Loss: 0.222442, Train Acc: 0.571795 | Val Loss: 0.231757, Val Acc: 0.515464\n",
      "Epoch 2322 - Train Loss: 0.222421, Train Acc: 0.571795 | Val Loss: 0.231736, Val Acc: 0.515464\n",
      "Epoch 2323 - Train Loss: 0.222400, Train Acc: 0.571795 | Val Loss: 0.231715, Val Acc: 0.515464\n",
      "Epoch 2324 - Train Loss: 0.222379, Train Acc: 0.571795 | Val Loss: 0.231694, Val Acc: 0.515464\n",
      "Epoch 2325 - Train Loss: 0.222357, Train Acc: 0.571795 | Val Loss: 0.231674, Val Acc: 0.515464\n",
      "Epoch 2326 - Train Loss: 0.222336, Train Acc: 0.571795 | Val Loss: 0.231653, Val Acc: 0.515464\n",
      "Epoch 2327 - Train Loss: 0.222315, Train Acc: 0.571795 | Val Loss: 0.231632, Val Acc: 0.515464\n",
      "Epoch 2328 - Train Loss: 0.222294, Train Acc: 0.571795 | Val Loss: 0.231611, Val Acc: 0.515464\n",
      "Epoch 2329 - Train Loss: 0.222273, Train Acc: 0.571795 | Val Loss: 0.231590, Val Acc: 0.515464\n",
      "Epoch 2330 - Train Loss: 0.222252, Train Acc: 0.571795 | Val Loss: 0.231570, Val Acc: 0.515464\n",
      "Epoch 2331 - Train Loss: 0.222230, Train Acc: 0.571795 | Val Loss: 0.231549, Val Acc: 0.515464\n",
      "Epoch 2332 - Train Loss: 0.222209, Train Acc: 0.571795 | Val Loss: 0.231528, Val Acc: 0.515464\n",
      "Epoch 2333 - Train Loss: 0.222188, Train Acc: 0.571795 | Val Loss: 0.231507, Val Acc: 0.515464\n",
      "Epoch 2334 - Train Loss: 0.222167, Train Acc: 0.571795 | Val Loss: 0.231487, Val Acc: 0.515464\n",
      "Epoch 2335 - Train Loss: 0.222146, Train Acc: 0.571795 | Val Loss: 0.231466, Val Acc: 0.515464\n",
      "Epoch 2336 - Train Loss: 0.222124, Train Acc: 0.573077 | Val Loss: 0.231445, Val Acc: 0.515464\n",
      "Epoch 2337 - Train Loss: 0.222103, Train Acc: 0.573077 | Val Loss: 0.231424, Val Acc: 0.515464\n",
      "Epoch 2338 - Train Loss: 0.222082, Train Acc: 0.573077 | Val Loss: 0.231404, Val Acc: 0.515464\n",
      "Epoch 2339 - Train Loss: 0.222061, Train Acc: 0.573077 | Val Loss: 0.231383, Val Acc: 0.515464\n",
      "Epoch 2340 - Train Loss: 0.222040, Train Acc: 0.573077 | Val Loss: 0.231362, Val Acc: 0.515464\n",
      "Epoch 2341 - Train Loss: 0.222019, Train Acc: 0.573077 | Val Loss: 0.231341, Val Acc: 0.515464\n",
      "Epoch 2342 - Train Loss: 0.221997, Train Acc: 0.573077 | Val Loss: 0.231321, Val Acc: 0.515464\n",
      "Epoch 2343 - Train Loss: 0.221976, Train Acc: 0.573077 | Val Loss: 0.231300, Val Acc: 0.515464\n",
      "Epoch 2344 - Train Loss: 0.221955, Train Acc: 0.573077 | Val Loss: 0.231279, Val Acc: 0.515464\n",
      "Epoch 2345 - Train Loss: 0.221934, Train Acc: 0.573077 | Val Loss: 0.231258, Val Acc: 0.515464\n",
      "Epoch 2346 - Train Loss: 0.221913, Train Acc: 0.573077 | Val Loss: 0.231238, Val Acc: 0.515464\n",
      "Epoch 2347 - Train Loss: 0.221892, Train Acc: 0.573077 | Val Loss: 0.231217, Val Acc: 0.515464\n",
      "Epoch 2348 - Train Loss: 0.221870, Train Acc: 0.573077 | Val Loss: 0.231196, Val Acc: 0.515464\n",
      "Epoch 2349 - Train Loss: 0.221849, Train Acc: 0.575641 | Val Loss: 0.231175, Val Acc: 0.515464\n",
      "Epoch 2350 - Train Loss: 0.221828, Train Acc: 0.575641 | Val Loss: 0.231155, Val Acc: 0.515464\n",
      "Epoch 2351 - Train Loss: 0.221807, Train Acc: 0.575641 | Val Loss: 0.231134, Val Acc: 0.515464\n",
      "Epoch 2352 - Train Loss: 0.221786, Train Acc: 0.575641 | Val Loss: 0.231113, Val Acc: 0.515464\n",
      "Epoch 2353 - Train Loss: 0.221765, Train Acc: 0.575641 | Val Loss: 0.231092, Val Acc: 0.515464\n",
      "Epoch 2354 - Train Loss: 0.221744, Train Acc: 0.575641 | Val Loss: 0.231072, Val Acc: 0.515464\n",
      "Epoch 2355 - Train Loss: 0.221722, Train Acc: 0.575641 | Val Loss: 0.231051, Val Acc: 0.515464\n",
      "Epoch 2356 - Train Loss: 0.221701, Train Acc: 0.575641 | Val Loss: 0.231030, Val Acc: 0.515464\n",
      "Epoch 2357 - Train Loss: 0.221680, Train Acc: 0.575641 | Val Loss: 0.231010, Val Acc: 0.515464\n",
      "Epoch 2358 - Train Loss: 0.221659, Train Acc: 0.575641 | Val Loss: 0.230989, Val Acc: 0.515464\n",
      "Epoch 2359 - Train Loss: 0.221638, Train Acc: 0.575641 | Val Loss: 0.230968, Val Acc: 0.515464\n",
      "Epoch 2360 - Train Loss: 0.221617, Train Acc: 0.575641 | Val Loss: 0.230947, Val Acc: 0.515464\n",
      "Epoch 2361 - Train Loss: 0.221596, Train Acc: 0.575641 | Val Loss: 0.230927, Val Acc: 0.515464\n",
      "Epoch 2362 - Train Loss: 0.221574, Train Acc: 0.575641 | Val Loss: 0.230906, Val Acc: 0.515464\n",
      "Epoch 2363 - Train Loss: 0.221553, Train Acc: 0.575641 | Val Loss: 0.230885, Val Acc: 0.515464\n",
      "Epoch 2364 - Train Loss: 0.221532, Train Acc: 0.575641 | Val Loss: 0.230865, Val Acc: 0.515464\n",
      "Epoch 2365 - Train Loss: 0.221511, Train Acc: 0.576923 | Val Loss: 0.230844, Val Acc: 0.515464\n",
      "Epoch 2366 - Train Loss: 0.221490, Train Acc: 0.576923 | Val Loss: 0.230823, Val Acc: 0.515464\n",
      "Epoch 2367 - Train Loss: 0.221469, Train Acc: 0.576923 | Val Loss: 0.230803, Val Acc: 0.515464\n",
      "Epoch 2368 - Train Loss: 0.221448, Train Acc: 0.576923 | Val Loss: 0.230782, Val Acc: 0.515464\n",
      "Epoch 2369 - Train Loss: 0.221427, Train Acc: 0.576923 | Val Loss: 0.230761, Val Acc: 0.515464\n",
      "Epoch 2370 - Train Loss: 0.221406, Train Acc: 0.576923 | Val Loss: 0.230740, Val Acc: 0.515464\n",
      "Epoch 2371 - Train Loss: 0.221384, Train Acc: 0.576923 | Val Loss: 0.230720, Val Acc: 0.515464\n",
      "Epoch 2372 - Train Loss: 0.221363, Train Acc: 0.578205 | Val Loss: 0.230699, Val Acc: 0.515464\n",
      "Epoch 2373 - Train Loss: 0.221342, Train Acc: 0.578205 | Val Loss: 0.230678, Val Acc: 0.515464\n",
      "Epoch 2374 - Train Loss: 0.221321, Train Acc: 0.578205 | Val Loss: 0.230658, Val Acc: 0.515464\n",
      "Epoch 2375 - Train Loss: 0.221300, Train Acc: 0.578205 | Val Loss: 0.230637, Val Acc: 0.515464\n",
      "Epoch 2376 - Train Loss: 0.221279, Train Acc: 0.579487 | Val Loss: 0.230616, Val Acc: 0.515464\n",
      "Epoch 2377 - Train Loss: 0.221258, Train Acc: 0.579487 | Val Loss: 0.230596, Val Acc: 0.515464\n",
      "Epoch 2378 - Train Loss: 0.221237, Train Acc: 0.579487 | Val Loss: 0.230575, Val Acc: 0.515464\n",
      "Epoch 2379 - Train Loss: 0.221216, Train Acc: 0.579487 | Val Loss: 0.230554, Val Acc: 0.515464\n",
      "Epoch 2380 - Train Loss: 0.221195, Train Acc: 0.579487 | Val Loss: 0.230534, Val Acc: 0.515464\n",
      "Epoch 2381 - Train Loss: 0.221173, Train Acc: 0.579487 | Val Loss: 0.230513, Val Acc: 0.515464\n",
      "Epoch 2382 - Train Loss: 0.221152, Train Acc: 0.579487 | Val Loss: 0.230492, Val Acc: 0.515464\n",
      "Epoch 2383 - Train Loss: 0.221131, Train Acc: 0.579487 | Val Loss: 0.230472, Val Acc: 0.515464\n",
      "Epoch 2384 - Train Loss: 0.221110, Train Acc: 0.579487 | Val Loss: 0.230451, Val Acc: 0.515464\n",
      "Epoch 2385 - Train Loss: 0.221089, Train Acc: 0.579487 | Val Loss: 0.230430, Val Acc: 0.515464\n",
      "Epoch 2386 - Train Loss: 0.221068, Train Acc: 0.579487 | Val Loss: 0.230410, Val Acc: 0.515464\n",
      "Epoch 2387 - Train Loss: 0.221047, Train Acc: 0.579487 | Val Loss: 0.230389, Val Acc: 0.515464\n",
      "Epoch 2388 - Train Loss: 0.221026, Train Acc: 0.579487 | Val Loss: 0.230369, Val Acc: 0.515464\n",
      "Epoch 2389 - Train Loss: 0.221005, Train Acc: 0.579487 | Val Loss: 0.230348, Val Acc: 0.515464\n",
      "Epoch 2390 - Train Loss: 0.220984, Train Acc: 0.579487 | Val Loss: 0.230327, Val Acc: 0.515464\n",
      "Epoch 2391 - Train Loss: 0.220963, Train Acc: 0.579487 | Val Loss: 0.230307, Val Acc: 0.515464\n",
      "Epoch 2392 - Train Loss: 0.220942, Train Acc: 0.579487 | Val Loss: 0.230286, Val Acc: 0.515464\n",
      "Epoch 2393 - Train Loss: 0.220921, Train Acc: 0.579487 | Val Loss: 0.230265, Val Acc: 0.515464\n",
      "Epoch 2394 - Train Loss: 0.220899, Train Acc: 0.579487 | Val Loss: 0.230245, Val Acc: 0.515464\n",
      "Epoch 2395 - Train Loss: 0.220878, Train Acc: 0.579487 | Val Loss: 0.230224, Val Acc: 0.515464\n",
      "Epoch 2396 - Train Loss: 0.220857, Train Acc: 0.579487 | Val Loss: 0.230203, Val Acc: 0.515464\n",
      "Epoch 2397 - Train Loss: 0.220836, Train Acc: 0.579487 | Val Loss: 0.230183, Val Acc: 0.515464\n",
      "Epoch 2398 - Train Loss: 0.220815, Train Acc: 0.579487 | Val Loss: 0.230162, Val Acc: 0.515464\n",
      "Epoch 2399 - Train Loss: 0.220794, Train Acc: 0.579487 | Val Loss: 0.230142, Val Acc: 0.515464\n",
      "Epoch 2400 - Train Loss: 0.220773, Train Acc: 0.579487 | Val Loss: 0.230121, Val Acc: 0.515464\n",
      "Epoch 2401 - Train Loss: 0.220752, Train Acc: 0.580769 | Val Loss: 0.230100, Val Acc: 0.515464\n",
      "Epoch 2402 - Train Loss: 0.220731, Train Acc: 0.580769 | Val Loss: 0.230080, Val Acc: 0.515464\n",
      "Epoch 2403 - Train Loss: 0.220710, Train Acc: 0.580769 | Val Loss: 0.230059, Val Acc: 0.515464\n",
      "Epoch 2404 - Train Loss: 0.220689, Train Acc: 0.580769 | Val Loss: 0.230038, Val Acc: 0.515464\n",
      "Epoch 2405 - Train Loss: 0.220668, Train Acc: 0.580769 | Val Loss: 0.230018, Val Acc: 0.515464\n",
      "Epoch 2406 - Train Loss: 0.220647, Train Acc: 0.580769 | Val Loss: 0.229997, Val Acc: 0.515464\n",
      "Epoch 2407 - Train Loss: 0.220626, Train Acc: 0.580769 | Val Loss: 0.229977, Val Acc: 0.515464\n",
      "Epoch 2408 - Train Loss: 0.220605, Train Acc: 0.580769 | Val Loss: 0.229956, Val Acc: 0.515464\n",
      "Epoch 2409 - Train Loss: 0.220584, Train Acc: 0.580769 | Val Loss: 0.229935, Val Acc: 0.515464\n",
      "Epoch 2410 - Train Loss: 0.220563, Train Acc: 0.580769 | Val Loss: 0.229915, Val Acc: 0.515464\n",
      "Epoch 2411 - Train Loss: 0.220542, Train Acc: 0.580769 | Val Loss: 0.229894, Val Acc: 0.515464\n",
      "Epoch 2412 - Train Loss: 0.220521, Train Acc: 0.580769 | Val Loss: 0.229874, Val Acc: 0.515464\n",
      "Epoch 2413 - Train Loss: 0.220500, Train Acc: 0.580769 | Val Loss: 0.229853, Val Acc: 0.515464\n",
      "Epoch 2414 - Train Loss: 0.220479, Train Acc: 0.580769 | Val Loss: 0.229832, Val Acc: 0.515464\n",
      "Epoch 2415 - Train Loss: 0.220458, Train Acc: 0.580769 | Val Loss: 0.229812, Val Acc: 0.515464\n",
      "Epoch 2416 - Train Loss: 0.220437, Train Acc: 0.580769 | Val Loss: 0.229791, Val Acc: 0.515464\n",
      "Epoch 2417 - Train Loss: 0.220416, Train Acc: 0.580769 | Val Loss: 0.229771, Val Acc: 0.515464\n",
      "Epoch 2418 - Train Loss: 0.220395, Train Acc: 0.580769 | Val Loss: 0.229750, Val Acc: 0.515464\n",
      "Epoch 2419 - Train Loss: 0.220374, Train Acc: 0.580769 | Val Loss: 0.229729, Val Acc: 0.515464\n",
      "Epoch 2420 - Train Loss: 0.220353, Train Acc: 0.580769 | Val Loss: 0.229709, Val Acc: 0.515464\n",
      "Epoch 2421 - Train Loss: 0.220332, Train Acc: 0.580769 | Val Loss: 0.229688, Val Acc: 0.515464\n",
      "Epoch 2422 - Train Loss: 0.220311, Train Acc: 0.580769 | Val Loss: 0.229668, Val Acc: 0.515464\n",
      "Epoch 2423 - Train Loss: 0.220290, Train Acc: 0.580769 | Val Loss: 0.229647, Val Acc: 0.515464\n",
      "Epoch 2424 - Train Loss: 0.220269, Train Acc: 0.580769 | Val Loss: 0.229626, Val Acc: 0.515464\n",
      "Epoch 2425 - Train Loss: 0.220247, Train Acc: 0.580769 | Val Loss: 0.229606, Val Acc: 0.515464\n",
      "Epoch 2426 - Train Loss: 0.220226, Train Acc: 0.580769 | Val Loss: 0.229585, Val Acc: 0.515464\n",
      "Epoch 2427 - Train Loss: 0.220205, Train Acc: 0.580769 | Val Loss: 0.229565, Val Acc: 0.515464\n",
      "Epoch 2428 - Train Loss: 0.220184, Train Acc: 0.580769 | Val Loss: 0.229544, Val Acc: 0.515464\n",
      "Epoch 2429 - Train Loss: 0.220163, Train Acc: 0.580769 | Val Loss: 0.229524, Val Acc: 0.515464\n",
      "Epoch 2430 - Train Loss: 0.220142, Train Acc: 0.580769 | Val Loss: 0.229503, Val Acc: 0.515464\n",
      "Epoch 2431 - Train Loss: 0.220121, Train Acc: 0.580769 | Val Loss: 0.229482, Val Acc: 0.515464\n",
      "Epoch 2432 - Train Loss: 0.220101, Train Acc: 0.580769 | Val Loss: 0.229462, Val Acc: 0.515464\n",
      "Epoch 2433 - Train Loss: 0.220080, Train Acc: 0.580769 | Val Loss: 0.229441, Val Acc: 0.515464\n",
      "Epoch 2434 - Train Loss: 0.220059, Train Acc: 0.580769 | Val Loss: 0.229421, Val Acc: 0.515464\n",
      "Epoch 2435 - Train Loss: 0.220038, Train Acc: 0.580769 | Val Loss: 0.229400, Val Acc: 0.515464\n",
      "Epoch 2436 - Train Loss: 0.220017, Train Acc: 0.580769 | Val Loss: 0.229380, Val Acc: 0.515464\n",
      "Epoch 2437 - Train Loss: 0.219996, Train Acc: 0.580769 | Val Loss: 0.229359, Val Acc: 0.515464\n",
      "Epoch 2438 - Train Loss: 0.219975, Train Acc: 0.580769 | Val Loss: 0.229339, Val Acc: 0.515464\n",
      "Epoch 2439 - Train Loss: 0.219954, Train Acc: 0.580769 | Val Loss: 0.229318, Val Acc: 0.515464\n",
      "Epoch 2440 - Train Loss: 0.219933, Train Acc: 0.580769 | Val Loss: 0.229297, Val Acc: 0.515464\n",
      "Epoch 2441 - Train Loss: 0.219912, Train Acc: 0.580769 | Val Loss: 0.229277, Val Acc: 0.515464\n",
      "Epoch 2442 - Train Loss: 0.219891, Train Acc: 0.580769 | Val Loss: 0.229256, Val Acc: 0.515464\n",
      "Epoch 2443 - Train Loss: 0.219870, Train Acc: 0.580769 | Val Loss: 0.229236, Val Acc: 0.515464\n",
      "Epoch 2444 - Train Loss: 0.219849, Train Acc: 0.580769 | Val Loss: 0.229215, Val Acc: 0.515464\n",
      "Epoch 2445 - Train Loss: 0.219828, Train Acc: 0.580769 | Val Loss: 0.229195, Val Acc: 0.515464\n",
      "Epoch 2446 - Train Loss: 0.219807, Train Acc: 0.580769 | Val Loss: 0.229174, Val Acc: 0.515464\n",
      "Epoch 2447 - Train Loss: 0.219786, Train Acc: 0.580769 | Val Loss: 0.229154, Val Acc: 0.515464\n",
      "Epoch 2448 - Train Loss: 0.219765, Train Acc: 0.580769 | Val Loss: 0.229133, Val Acc: 0.515464\n",
      "Epoch 2449 - Train Loss: 0.219744, Train Acc: 0.580769 | Val Loss: 0.229113, Val Acc: 0.515464\n",
      "Epoch 2450 - Train Loss: 0.219723, Train Acc: 0.580769 | Val Loss: 0.229092, Val Acc: 0.515464\n",
      "Epoch 2451 - Train Loss: 0.219702, Train Acc: 0.580769 | Val Loss: 0.229072, Val Acc: 0.515464\n",
      "Epoch 2452 - Train Loss: 0.219681, Train Acc: 0.580769 | Val Loss: 0.229051, Val Acc: 0.515464\n",
      "Epoch 2453 - Train Loss: 0.219660, Train Acc: 0.580769 | Val Loss: 0.229031, Val Acc: 0.515464\n",
      "Epoch 2454 - Train Loss: 0.219639, Train Acc: 0.580769 | Val Loss: 0.229010, Val Acc: 0.515464\n",
      "Epoch 2455 - Train Loss: 0.219618, Train Acc: 0.580769 | Val Loss: 0.228990, Val Acc: 0.515464\n",
      "Epoch 2456 - Train Loss: 0.219598, Train Acc: 0.580769 | Val Loss: 0.228969, Val Acc: 0.515464\n",
      "Epoch 2457 - Train Loss: 0.219577, Train Acc: 0.580769 | Val Loss: 0.228949, Val Acc: 0.515464\n",
      "Epoch 2458 - Train Loss: 0.219556, Train Acc: 0.580769 | Val Loss: 0.228928, Val Acc: 0.515464\n",
      "Epoch 2459 - Train Loss: 0.219535, Train Acc: 0.580769 | Val Loss: 0.228908, Val Acc: 0.515464\n",
      "Epoch 2460 - Train Loss: 0.219514, Train Acc: 0.580769 | Val Loss: 0.228887, Val Acc: 0.515464\n",
      "Epoch 2461 - Train Loss: 0.219493, Train Acc: 0.580769 | Val Loss: 0.228866, Val Acc: 0.515464\n",
      "Epoch 2462 - Train Loss: 0.219472, Train Acc: 0.580769 | Val Loss: 0.228846, Val Acc: 0.515464\n",
      "Epoch 2463 - Train Loss: 0.219451, Train Acc: 0.580769 | Val Loss: 0.228825, Val Acc: 0.515464\n",
      "Epoch 2464 - Train Loss: 0.219430, Train Acc: 0.580769 | Val Loss: 0.228805, Val Acc: 0.515464\n",
      "Epoch 2465 - Train Loss: 0.219409, Train Acc: 0.580769 | Val Loss: 0.228784, Val Acc: 0.515464\n",
      "Epoch 2466 - Train Loss: 0.219388, Train Acc: 0.580769 | Val Loss: 0.228764, Val Acc: 0.515464\n",
      "Epoch 2467 - Train Loss: 0.219367, Train Acc: 0.580769 | Val Loss: 0.228743, Val Acc: 0.515464\n",
      "Epoch 2468 - Train Loss: 0.219346, Train Acc: 0.580769 | Val Loss: 0.228723, Val Acc: 0.515464\n",
      "Epoch 2469 - Train Loss: 0.219326, Train Acc: 0.580769 | Val Loss: 0.228702, Val Acc: 0.515464\n",
      "Epoch 2470 - Train Loss: 0.219305, Train Acc: 0.580769 | Val Loss: 0.228681, Val Acc: 0.515464\n",
      "Epoch 2471 - Train Loss: 0.219284, Train Acc: 0.580769 | Val Loss: 0.228661, Val Acc: 0.515464\n",
      "Epoch 2472 - Train Loss: 0.219263, Train Acc: 0.580769 | Val Loss: 0.228640, Val Acc: 0.515464\n",
      "Epoch 2473 - Train Loss: 0.219242, Train Acc: 0.580769 | Val Loss: 0.228620, Val Acc: 0.515464\n",
      "Epoch 2474 - Train Loss: 0.219221, Train Acc: 0.580769 | Val Loss: 0.228599, Val Acc: 0.515464\n",
      "Epoch 2475 - Train Loss: 0.219200, Train Acc: 0.580769 | Val Loss: 0.228579, Val Acc: 0.515464\n",
      "Epoch 2476 - Train Loss: 0.219179, Train Acc: 0.580769 | Val Loss: 0.228558, Val Acc: 0.525773\n",
      "Epoch 2477 - Train Loss: 0.219158, Train Acc: 0.580769 | Val Loss: 0.228538, Val Acc: 0.525773\n",
      "Epoch 2478 - Train Loss: 0.219137, Train Acc: 0.580769 | Val Loss: 0.228517, Val Acc: 0.525773\n",
      "Epoch 2479 - Train Loss: 0.219116, Train Acc: 0.580769 | Val Loss: 0.228497, Val Acc: 0.525773\n",
      "Epoch 2480 - Train Loss: 0.219095, Train Acc: 0.580769 | Val Loss: 0.228476, Val Acc: 0.525773\n",
      "Epoch 2481 - Train Loss: 0.219074, Train Acc: 0.580769 | Val Loss: 0.228456, Val Acc: 0.525773\n",
      "Epoch 2482 - Train Loss: 0.219054, Train Acc: 0.580769 | Val Loss: 0.228435, Val Acc: 0.525773\n",
      "Epoch 2483 - Train Loss: 0.219033, Train Acc: 0.580769 | Val Loss: 0.228414, Val Acc: 0.525773\n",
      "Epoch 2484 - Train Loss: 0.219012, Train Acc: 0.580769 | Val Loss: 0.228394, Val Acc: 0.525773\n",
      "Epoch 2485 - Train Loss: 0.218991, Train Acc: 0.580769 | Val Loss: 0.228373, Val Acc: 0.525773\n",
      "Epoch 2486 - Train Loss: 0.218970, Train Acc: 0.582051 | Val Loss: 0.228353, Val Acc: 0.525773\n",
      "Epoch 2487 - Train Loss: 0.218949, Train Acc: 0.582051 | Val Loss: 0.228332, Val Acc: 0.525773\n",
      "Epoch 2488 - Train Loss: 0.218928, Train Acc: 0.582051 | Val Loss: 0.228312, Val Acc: 0.525773\n",
      "Epoch 2489 - Train Loss: 0.218907, Train Acc: 0.582051 | Val Loss: 0.228291, Val Acc: 0.525773\n",
      "Epoch 2490 - Train Loss: 0.218886, Train Acc: 0.582051 | Val Loss: 0.228271, Val Acc: 0.525773\n",
      "Epoch 2491 - Train Loss: 0.218866, Train Acc: 0.582051 | Val Loss: 0.228250, Val Acc: 0.525773\n",
      "Epoch 2492 - Train Loss: 0.218845, Train Acc: 0.582051 | Val Loss: 0.228230, Val Acc: 0.525773\n",
      "Epoch 2493 - Train Loss: 0.218824, Train Acc: 0.582051 | Val Loss: 0.228209, Val Acc: 0.525773\n",
      "Epoch 2494 - Train Loss: 0.218803, Train Acc: 0.583333 | Val Loss: 0.228188, Val Acc: 0.525773\n",
      "Epoch 2495 - Train Loss: 0.218782, Train Acc: 0.583333 | Val Loss: 0.228168, Val Acc: 0.525773\n",
      "Epoch 2496 - Train Loss: 0.218761, Train Acc: 0.583333 | Val Loss: 0.228147, Val Acc: 0.525773\n",
      "Epoch 2497 - Train Loss: 0.218740, Train Acc: 0.583333 | Val Loss: 0.228127, Val Acc: 0.525773\n",
      "Epoch 2498 - Train Loss: 0.218719, Train Acc: 0.583333 | Val Loss: 0.228106, Val Acc: 0.525773\n",
      "Epoch 2499 - Train Loss: 0.218698, Train Acc: 0.583333 | Val Loss: 0.228086, Val Acc: 0.525773\n",
      "Epoch 2500 - Train Loss: 0.218677, Train Acc: 0.583333 | Val Loss: 0.228065, Val Acc: 0.525773\n",
      "Epoch 2501 - Train Loss: 0.218656, Train Acc: 0.583333 | Val Loss: 0.228045, Val Acc: 0.525773\n",
      "Epoch 2502 - Train Loss: 0.218636, Train Acc: 0.583333 | Val Loss: 0.228024, Val Acc: 0.525773\n",
      "Epoch 2503 - Train Loss: 0.218615, Train Acc: 0.583333 | Val Loss: 0.228004, Val Acc: 0.525773\n",
      "Epoch 2504 - Train Loss: 0.218594, Train Acc: 0.583333 | Val Loss: 0.227983, Val Acc: 0.525773\n",
      "Epoch 2505 - Train Loss: 0.218573, Train Acc: 0.583333 | Val Loss: 0.227963, Val Acc: 0.525773\n",
      "Epoch 2506 - Train Loss: 0.218552, Train Acc: 0.583333 | Val Loss: 0.227942, Val Acc: 0.525773\n",
      "Epoch 2507 - Train Loss: 0.218531, Train Acc: 0.583333 | Val Loss: 0.227922, Val Acc: 0.525773\n",
      "Epoch 2508 - Train Loss: 0.218510, Train Acc: 0.583333 | Val Loss: 0.227901, Val Acc: 0.525773\n",
      "Epoch 2509 - Train Loss: 0.218489, Train Acc: 0.583333 | Val Loss: 0.227881, Val Acc: 0.525773\n",
      "Epoch 2510 - Train Loss: 0.218469, Train Acc: 0.583333 | Val Loss: 0.227860, Val Acc: 0.525773\n",
      "Epoch 2511 - Train Loss: 0.218448, Train Acc: 0.583333 | Val Loss: 0.227840, Val Acc: 0.525773\n",
      "Epoch 2512 - Train Loss: 0.218427, Train Acc: 0.583333 | Val Loss: 0.227819, Val Acc: 0.525773\n",
      "Epoch 2513 - Train Loss: 0.218406, Train Acc: 0.583333 | Val Loss: 0.227799, Val Acc: 0.525773\n",
      "Epoch 2514 - Train Loss: 0.218385, Train Acc: 0.583333 | Val Loss: 0.227778, Val Acc: 0.525773\n",
      "Epoch 2515 - Train Loss: 0.218364, Train Acc: 0.583333 | Val Loss: 0.227758, Val Acc: 0.525773\n",
      "Epoch 2516 - Train Loss: 0.218343, Train Acc: 0.583333 | Val Loss: 0.227737, Val Acc: 0.525773\n",
      "Epoch 2517 - Train Loss: 0.218323, Train Acc: 0.583333 | Val Loss: 0.227717, Val Acc: 0.525773\n",
      "Epoch 2518 - Train Loss: 0.218302, Train Acc: 0.583333 | Val Loss: 0.227696, Val Acc: 0.525773\n",
      "Epoch 2519 - Train Loss: 0.218281, Train Acc: 0.583333 | Val Loss: 0.227675, Val Acc: 0.525773\n",
      "Epoch 2520 - Train Loss: 0.218260, Train Acc: 0.583333 | Val Loss: 0.227655, Val Acc: 0.525773\n",
      "Epoch 2521 - Train Loss: 0.218239, Train Acc: 0.583333 | Val Loss: 0.227634, Val Acc: 0.525773\n",
      "Epoch 2522 - Train Loss: 0.218218, Train Acc: 0.583333 | Val Loss: 0.227614, Val Acc: 0.525773\n",
      "Epoch 2523 - Train Loss: 0.218198, Train Acc: 0.585897 | Val Loss: 0.227593, Val Acc: 0.525773\n",
      "Epoch 2524 - Train Loss: 0.218177, Train Acc: 0.585897 | Val Loss: 0.227573, Val Acc: 0.525773\n",
      "Epoch 2525 - Train Loss: 0.218156, Train Acc: 0.585897 | Val Loss: 0.227552, Val Acc: 0.525773\n",
      "Epoch 2526 - Train Loss: 0.218135, Train Acc: 0.585897 | Val Loss: 0.227532, Val Acc: 0.525773\n",
      "Epoch 2527 - Train Loss: 0.218114, Train Acc: 0.585897 | Val Loss: 0.227511, Val Acc: 0.525773\n",
      "Epoch 2528 - Train Loss: 0.218093, Train Acc: 0.585897 | Val Loss: 0.227491, Val Acc: 0.525773\n",
      "Epoch 2529 - Train Loss: 0.218073, Train Acc: 0.585897 | Val Loss: 0.227470, Val Acc: 0.525773\n",
      "Epoch 2530 - Train Loss: 0.218052, Train Acc: 0.585897 | Val Loss: 0.227450, Val Acc: 0.525773\n",
      "Epoch 2531 - Train Loss: 0.218031, Train Acc: 0.585897 | Val Loss: 0.227429, Val Acc: 0.525773\n",
      "Epoch 2532 - Train Loss: 0.218010, Train Acc: 0.585897 | Val Loss: 0.227409, Val Acc: 0.525773\n",
      "Epoch 2533 - Train Loss: 0.217989, Train Acc: 0.585897 | Val Loss: 0.227388, Val Acc: 0.525773\n",
      "Epoch 2534 - Train Loss: 0.217968, Train Acc: 0.585897 | Val Loss: 0.227368, Val Acc: 0.525773\n",
      "Epoch 2535 - Train Loss: 0.217948, Train Acc: 0.585897 | Val Loss: 0.227347, Val Acc: 0.525773\n",
      "Epoch 2536 - Train Loss: 0.217927, Train Acc: 0.587179 | Val Loss: 0.227327, Val Acc: 0.525773\n",
      "Epoch 2537 - Train Loss: 0.217906, Train Acc: 0.587179 | Val Loss: 0.227307, Val Acc: 0.525773\n",
      "Epoch 2538 - Train Loss: 0.217885, Train Acc: 0.587179 | Val Loss: 0.227286, Val Acc: 0.525773\n",
      "Epoch 2539 - Train Loss: 0.217864, Train Acc: 0.587179 | Val Loss: 0.227266, Val Acc: 0.525773\n",
      "Epoch 2540 - Train Loss: 0.217844, Train Acc: 0.587179 | Val Loss: 0.227245, Val Acc: 0.525773\n",
      "Epoch 2541 - Train Loss: 0.217823, Train Acc: 0.587179 | Val Loss: 0.227225, Val Acc: 0.525773\n",
      "Epoch 2542 - Train Loss: 0.217802, Train Acc: 0.587179 | Val Loss: 0.227204, Val Acc: 0.525773\n",
      "Epoch 2543 - Train Loss: 0.217781, Train Acc: 0.588462 | Val Loss: 0.227184, Val Acc: 0.525773\n",
      "Epoch 2544 - Train Loss: 0.217760, Train Acc: 0.588462 | Val Loss: 0.227163, Val Acc: 0.525773\n",
      "Epoch 2545 - Train Loss: 0.217739, Train Acc: 0.589744 | Val Loss: 0.227143, Val Acc: 0.525773\n",
      "Epoch 2546 - Train Loss: 0.217719, Train Acc: 0.589744 | Val Loss: 0.227122, Val Acc: 0.525773\n",
      "Epoch 2547 - Train Loss: 0.217698, Train Acc: 0.589744 | Val Loss: 0.227102, Val Acc: 0.525773\n",
      "Epoch 2548 - Train Loss: 0.217677, Train Acc: 0.589744 | Val Loss: 0.227082, Val Acc: 0.525773\n",
      "Epoch 2549 - Train Loss: 0.217656, Train Acc: 0.589744 | Val Loss: 0.227061, Val Acc: 0.525773\n",
      "Epoch 2550 - Train Loss: 0.217635, Train Acc: 0.589744 | Val Loss: 0.227041, Val Acc: 0.525773\n",
      "Epoch 2551 - Train Loss: 0.217615, Train Acc: 0.589744 | Val Loss: 0.227020, Val Acc: 0.525773\n",
      "Epoch 2552 - Train Loss: 0.217594, Train Acc: 0.589744 | Val Loss: 0.227000, Val Acc: 0.525773\n",
      "Epoch 2553 - Train Loss: 0.217573, Train Acc: 0.589744 | Val Loss: 0.226979, Val Acc: 0.525773\n",
      "Epoch 2554 - Train Loss: 0.217552, Train Acc: 0.589744 | Val Loss: 0.226959, Val Acc: 0.525773\n",
      "Epoch 2555 - Train Loss: 0.217531, Train Acc: 0.589744 | Val Loss: 0.226938, Val Acc: 0.525773\n",
      "Epoch 2556 - Train Loss: 0.217511, Train Acc: 0.589744 | Val Loss: 0.226918, Val Acc: 0.525773\n",
      "Epoch 2557 - Train Loss: 0.217490, Train Acc: 0.589744 | Val Loss: 0.226898, Val Acc: 0.525773\n",
      "Epoch 2558 - Train Loss: 0.217469, Train Acc: 0.589744 | Val Loss: 0.226877, Val Acc: 0.525773\n",
      "Epoch 2559 - Train Loss: 0.217448, Train Acc: 0.589744 | Val Loss: 0.226857, Val Acc: 0.525773\n",
      "Epoch 2560 - Train Loss: 0.217427, Train Acc: 0.589744 | Val Loss: 0.226836, Val Acc: 0.525773\n",
      "Epoch 2561 - Train Loss: 0.217407, Train Acc: 0.589744 | Val Loss: 0.226816, Val Acc: 0.525773\n",
      "Epoch 2562 - Train Loss: 0.217386, Train Acc: 0.589744 | Val Loss: 0.226795, Val Acc: 0.525773\n",
      "Epoch 2563 - Train Loss: 0.217365, Train Acc: 0.589744 | Val Loss: 0.226775, Val Acc: 0.525773\n",
      "Epoch 2564 - Train Loss: 0.217344, Train Acc: 0.589744 | Val Loss: 0.226755, Val Acc: 0.525773\n",
      "Epoch 2565 - Train Loss: 0.217323, Train Acc: 0.589744 | Val Loss: 0.226734, Val Acc: 0.525773\n",
      "Epoch 2566 - Train Loss: 0.217303, Train Acc: 0.589744 | Val Loss: 0.226714, Val Acc: 0.525773\n",
      "Epoch 2567 - Train Loss: 0.217282, Train Acc: 0.589744 | Val Loss: 0.226693, Val Acc: 0.525773\n",
      "Epoch 2568 - Train Loss: 0.217261, Train Acc: 0.589744 | Val Loss: 0.226673, Val Acc: 0.536082\n",
      "Epoch 2569 - Train Loss: 0.217240, Train Acc: 0.589744 | Val Loss: 0.226652, Val Acc: 0.536082\n",
      "Epoch 2570 - Train Loss: 0.217220, Train Acc: 0.591026 | Val Loss: 0.226632, Val Acc: 0.536082\n",
      "Epoch 2571 - Train Loss: 0.217199, Train Acc: 0.591026 | Val Loss: 0.226612, Val Acc: 0.536082\n",
      "Epoch 2572 - Train Loss: 0.217178, Train Acc: 0.591026 | Val Loss: 0.226591, Val Acc: 0.536082\n",
      "Epoch 2573 - Train Loss: 0.217157, Train Acc: 0.591026 | Val Loss: 0.226571, Val Acc: 0.536082\n",
      "Epoch 2574 - Train Loss: 0.217136, Train Acc: 0.591026 | Val Loss: 0.226550, Val Acc: 0.536082\n",
      "Epoch 2575 - Train Loss: 0.217115, Train Acc: 0.591026 | Val Loss: 0.226530, Val Acc: 0.536082\n",
      "Epoch 2576 - Train Loss: 0.217095, Train Acc: 0.591026 | Val Loss: 0.226510, Val Acc: 0.536082\n",
      "Epoch 2577 - Train Loss: 0.217074, Train Acc: 0.591026 | Val Loss: 0.226489, Val Acc: 0.536082\n",
      "Epoch 2578 - Train Loss: 0.217053, Train Acc: 0.591026 | Val Loss: 0.226469, Val Acc: 0.536082\n",
      "Epoch 2579 - Train Loss: 0.217032, Train Acc: 0.591026 | Val Loss: 0.226448, Val Acc: 0.536082\n",
      "Epoch 2580 - Train Loss: 0.217011, Train Acc: 0.591026 | Val Loss: 0.226428, Val Acc: 0.536082\n",
      "Epoch 2581 - Train Loss: 0.216991, Train Acc: 0.591026 | Val Loss: 0.226408, Val Acc: 0.536082\n",
      "Epoch 2582 - Train Loss: 0.216970, Train Acc: 0.591026 | Val Loss: 0.226387, Val Acc: 0.536082\n",
      "Epoch 2583 - Train Loss: 0.216949, Train Acc: 0.591026 | Val Loss: 0.226367, Val Acc: 0.536082\n",
      "Epoch 2584 - Train Loss: 0.216928, Train Acc: 0.591026 | Val Loss: 0.226346, Val Acc: 0.536082\n",
      "Epoch 2585 - Train Loss: 0.216907, Train Acc: 0.591026 | Val Loss: 0.226326, Val Acc: 0.536082\n",
      "Epoch 2586 - Train Loss: 0.216887, Train Acc: 0.591026 | Val Loss: 0.226306, Val Acc: 0.536082\n",
      "Epoch 2587 - Train Loss: 0.216866, Train Acc: 0.591026 | Val Loss: 0.226285, Val Acc: 0.536082\n",
      "Epoch 2588 - Train Loss: 0.216845, Train Acc: 0.591026 | Val Loss: 0.226265, Val Acc: 0.536082\n",
      "Epoch 2589 - Train Loss: 0.216824, Train Acc: 0.591026 | Val Loss: 0.226244, Val Acc: 0.536082\n",
      "Epoch 2590 - Train Loss: 0.216804, Train Acc: 0.592308 | Val Loss: 0.226224, Val Acc: 0.536082\n",
      "Epoch 2591 - Train Loss: 0.216783, Train Acc: 0.592308 | Val Loss: 0.226204, Val Acc: 0.536082\n",
      "Epoch 2592 - Train Loss: 0.216762, Train Acc: 0.592308 | Val Loss: 0.226183, Val Acc: 0.536082\n",
      "Epoch 2593 - Train Loss: 0.216741, Train Acc: 0.592308 | Val Loss: 0.226163, Val Acc: 0.536082\n",
      "Epoch 2594 - Train Loss: 0.216720, Train Acc: 0.592308 | Val Loss: 0.226143, Val Acc: 0.536082\n",
      "Epoch 2595 - Train Loss: 0.216700, Train Acc: 0.592308 | Val Loss: 0.226122, Val Acc: 0.536082\n",
      "Epoch 2596 - Train Loss: 0.216679, Train Acc: 0.592308 | Val Loss: 0.226102, Val Acc: 0.536082\n",
      "Epoch 2597 - Train Loss: 0.216658, Train Acc: 0.593590 | Val Loss: 0.226082, Val Acc: 0.536082\n",
      "Epoch 2598 - Train Loss: 0.216637, Train Acc: 0.593590 | Val Loss: 0.226061, Val Acc: 0.536082\n",
      "Epoch 2599 - Train Loss: 0.216617, Train Acc: 0.593590 | Val Loss: 0.226041, Val Acc: 0.536082\n",
      "Epoch 2600 - Train Loss: 0.216596, Train Acc: 0.593590 | Val Loss: 0.226021, Val Acc: 0.536082\n",
      "Epoch 2601 - Train Loss: 0.216575, Train Acc: 0.593590 | Val Loss: 0.226000, Val Acc: 0.536082\n",
      "Epoch 2602 - Train Loss: 0.216554, Train Acc: 0.593590 | Val Loss: 0.225980, Val Acc: 0.536082\n",
      "Epoch 2603 - Train Loss: 0.216534, Train Acc: 0.593590 | Val Loss: 0.225960, Val Acc: 0.536082\n",
      "Epoch 2604 - Train Loss: 0.216513, Train Acc: 0.593590 | Val Loss: 0.225939, Val Acc: 0.536082\n",
      "Epoch 2605 - Train Loss: 0.216492, Train Acc: 0.593590 | Val Loss: 0.225919, Val Acc: 0.536082\n",
      "Epoch 2606 - Train Loss: 0.216471, Train Acc: 0.593590 | Val Loss: 0.225899, Val Acc: 0.536082\n",
      "Epoch 2607 - Train Loss: 0.216451, Train Acc: 0.593590 | Val Loss: 0.225878, Val Acc: 0.536082\n",
      "Epoch 2608 - Train Loss: 0.216430, Train Acc: 0.593590 | Val Loss: 0.225858, Val Acc: 0.536082\n",
      "Epoch 2609 - Train Loss: 0.216409, Train Acc: 0.593590 | Val Loss: 0.225838, Val Acc: 0.536082\n",
      "Epoch 2610 - Train Loss: 0.216388, Train Acc: 0.593590 | Val Loss: 0.225817, Val Acc: 0.536082\n",
      "Epoch 2611 - Train Loss: 0.216368, Train Acc: 0.593590 | Val Loss: 0.225797, Val Acc: 0.536082\n",
      "Epoch 2612 - Train Loss: 0.216347, Train Acc: 0.593590 | Val Loss: 0.225777, Val Acc: 0.536082\n",
      "Epoch 2613 - Train Loss: 0.216326, Train Acc: 0.593590 | Val Loss: 0.225756, Val Acc: 0.536082\n",
      "Epoch 2614 - Train Loss: 0.216305, Train Acc: 0.593590 | Val Loss: 0.225736, Val Acc: 0.536082\n",
      "Epoch 2615 - Train Loss: 0.216285, Train Acc: 0.593590 | Val Loss: 0.225715, Val Acc: 0.536082\n",
      "Epoch 2616 - Train Loss: 0.216264, Train Acc: 0.593590 | Val Loss: 0.225695, Val Acc: 0.536082\n",
      "Epoch 2617 - Train Loss: 0.216243, Train Acc: 0.593590 | Val Loss: 0.225674, Val Acc: 0.536082\n",
      "Epoch 2618 - Train Loss: 0.216222, Train Acc: 0.593590 | Val Loss: 0.225654, Val Acc: 0.536082\n",
      "Epoch 2619 - Train Loss: 0.216202, Train Acc: 0.593590 | Val Loss: 0.225634, Val Acc: 0.536082\n",
      "Epoch 2620 - Train Loss: 0.216181, Train Acc: 0.593590 | Val Loss: 0.225613, Val Acc: 0.536082\n",
      "Epoch 2621 - Train Loss: 0.216160, Train Acc: 0.593590 | Val Loss: 0.225593, Val Acc: 0.536082\n",
      "Epoch 2622 - Train Loss: 0.216139, Train Acc: 0.593590 | Val Loss: 0.225572, Val Acc: 0.536082\n",
      "Epoch 2623 - Train Loss: 0.216119, Train Acc: 0.593590 | Val Loss: 0.225552, Val Acc: 0.536082\n",
      "Epoch 2624 - Train Loss: 0.216098, Train Acc: 0.593590 | Val Loss: 0.225532, Val Acc: 0.536082\n",
      "Epoch 2625 - Train Loss: 0.216077, Train Acc: 0.593590 | Val Loss: 0.225511, Val Acc: 0.536082\n",
      "Epoch 2626 - Train Loss: 0.216056, Train Acc: 0.594872 | Val Loss: 0.225491, Val Acc: 0.536082\n",
      "Epoch 2627 - Train Loss: 0.216036, Train Acc: 0.594872 | Val Loss: 0.225470, Val Acc: 0.536082\n",
      "Epoch 2628 - Train Loss: 0.216015, Train Acc: 0.594872 | Val Loss: 0.225450, Val Acc: 0.536082\n",
      "Epoch 2629 - Train Loss: 0.215994, Train Acc: 0.594872 | Val Loss: 0.225429, Val Acc: 0.536082\n",
      "Epoch 2630 - Train Loss: 0.215973, Train Acc: 0.594872 | Val Loss: 0.225409, Val Acc: 0.536082\n",
      "Epoch 2631 - Train Loss: 0.215953, Train Acc: 0.594872 | Val Loss: 0.225389, Val Acc: 0.536082\n",
      "Epoch 2632 - Train Loss: 0.215932, Train Acc: 0.594872 | Val Loss: 0.225368, Val Acc: 0.536082\n",
      "Epoch 2633 - Train Loss: 0.215911, Train Acc: 0.594872 | Val Loss: 0.225348, Val Acc: 0.536082\n",
      "Epoch 2634 - Train Loss: 0.215891, Train Acc: 0.594872 | Val Loss: 0.225327, Val Acc: 0.536082\n",
      "Epoch 2635 - Train Loss: 0.215870, Train Acc: 0.594872 | Val Loss: 0.225307, Val Acc: 0.536082\n",
      "Epoch 2636 - Train Loss: 0.215849, Train Acc: 0.594872 | Val Loss: 0.225287, Val Acc: 0.536082\n",
      "Epoch 2637 - Train Loss: 0.215828, Train Acc: 0.594872 | Val Loss: 0.225266, Val Acc: 0.536082\n",
      "Epoch 2638 - Train Loss: 0.215808, Train Acc: 0.594872 | Val Loss: 0.225246, Val Acc: 0.536082\n",
      "Epoch 2639 - Train Loss: 0.215787, Train Acc: 0.594872 | Val Loss: 0.225225, Val Acc: 0.536082\n",
      "Epoch 2640 - Train Loss: 0.215766, Train Acc: 0.594872 | Val Loss: 0.225205, Val Acc: 0.536082\n",
      "Epoch 2641 - Train Loss: 0.215746, Train Acc: 0.594872 | Val Loss: 0.225184, Val Acc: 0.536082\n",
      "Epoch 2642 - Train Loss: 0.215725, Train Acc: 0.594872 | Val Loss: 0.225164, Val Acc: 0.536082\n",
      "Epoch 2643 - Train Loss: 0.215704, Train Acc: 0.594872 | Val Loss: 0.225143, Val Acc: 0.536082\n",
      "Epoch 2644 - Train Loss: 0.215684, Train Acc: 0.594872 | Val Loss: 0.225123, Val Acc: 0.536082\n",
      "Epoch 2645 - Train Loss: 0.215663, Train Acc: 0.594872 | Val Loss: 0.225102, Val Acc: 0.536082\n",
      "Epoch 2646 - Train Loss: 0.215642, Train Acc: 0.594872 | Val Loss: 0.225082, Val Acc: 0.536082\n",
      "Epoch 2647 - Train Loss: 0.215622, Train Acc: 0.596154 | Val Loss: 0.225061, Val Acc: 0.536082\n",
      "Epoch 2648 - Train Loss: 0.215601, Train Acc: 0.596154 | Val Loss: 0.225041, Val Acc: 0.536082\n",
      "Epoch 2649 - Train Loss: 0.215580, Train Acc: 0.596154 | Val Loss: 0.225020, Val Acc: 0.536082\n",
      "Epoch 2650 - Train Loss: 0.215560, Train Acc: 0.596154 | Val Loss: 0.225000, Val Acc: 0.536082\n",
      "Epoch 2651 - Train Loss: 0.215539, Train Acc: 0.596154 | Val Loss: 0.224979, Val Acc: 0.536082\n",
      "Epoch 2652 - Train Loss: 0.215518, Train Acc: 0.596154 | Val Loss: 0.224959, Val Acc: 0.536082\n",
      "Epoch 2653 - Train Loss: 0.215498, Train Acc: 0.596154 | Val Loss: 0.224939, Val Acc: 0.536082\n",
      "Epoch 2654 - Train Loss: 0.215477, Train Acc: 0.596154 | Val Loss: 0.224918, Val Acc: 0.536082\n",
      "Epoch 2655 - Train Loss: 0.215457, Train Acc: 0.596154 | Val Loss: 0.224898, Val Acc: 0.536082\n",
      "Epoch 2656 - Train Loss: 0.215436, Train Acc: 0.596154 | Val Loss: 0.224878, Val Acc: 0.536082\n",
      "Epoch 2657 - Train Loss: 0.215415, Train Acc: 0.596154 | Val Loss: 0.224857, Val Acc: 0.536082\n",
      "Epoch 2658 - Train Loss: 0.215395, Train Acc: 0.596154 | Val Loss: 0.224837, Val Acc: 0.536082\n",
      "Epoch 2659 - Train Loss: 0.215374, Train Acc: 0.596154 | Val Loss: 0.224817, Val Acc: 0.536082\n",
      "Epoch 2660 - Train Loss: 0.215353, Train Acc: 0.596154 | Val Loss: 0.224796, Val Acc: 0.536082\n",
      "Epoch 2661 - Train Loss: 0.215333, Train Acc: 0.596154 | Val Loss: 0.224776, Val Acc: 0.536082\n",
      "Epoch 2662 - Train Loss: 0.215312, Train Acc: 0.596154 | Val Loss: 0.224756, Val Acc: 0.536082\n",
      "Epoch 2663 - Train Loss: 0.215292, Train Acc: 0.596154 | Val Loss: 0.224736, Val Acc: 0.536082\n",
      "Epoch 2664 - Train Loss: 0.215271, Train Acc: 0.596154 | Val Loss: 0.224715, Val Acc: 0.536082\n",
      "Epoch 2665 - Train Loss: 0.215251, Train Acc: 0.596154 | Val Loss: 0.224695, Val Acc: 0.536082\n",
      "Epoch 2666 - Train Loss: 0.215230, Train Acc: 0.596154 | Val Loss: 0.224675, Val Acc: 0.536082\n",
      "Epoch 2667 - Train Loss: 0.215209, Train Acc: 0.596154 | Val Loss: 0.224655, Val Acc: 0.536082\n",
      "Epoch 2668 - Train Loss: 0.215189, Train Acc: 0.596154 | Val Loss: 0.224634, Val Acc: 0.536082\n",
      "Epoch 2669 - Train Loss: 0.215168, Train Acc: 0.596154 | Val Loss: 0.224614, Val Acc: 0.536082\n",
      "Epoch 2670 - Train Loss: 0.215148, Train Acc: 0.596154 | Val Loss: 0.224594, Val Acc: 0.536082\n",
      "Epoch 2671 - Train Loss: 0.215127, Train Acc: 0.596154 | Val Loss: 0.224573, Val Acc: 0.536082\n",
      "Epoch 2672 - Train Loss: 0.215107, Train Acc: 0.596154 | Val Loss: 0.224553, Val Acc: 0.536082\n",
      "Epoch 2673 - Train Loss: 0.215086, Train Acc: 0.596154 | Val Loss: 0.224533, Val Acc: 0.536082\n",
      "Epoch 2674 - Train Loss: 0.215065, Train Acc: 0.596154 | Val Loss: 0.224513, Val Acc: 0.536082\n",
      "Epoch 2675 - Train Loss: 0.215045, Train Acc: 0.596154 | Val Loss: 0.224492, Val Acc: 0.536082\n",
      "Epoch 2676 - Train Loss: 0.215024, Train Acc: 0.596154 | Val Loss: 0.224472, Val Acc: 0.536082\n",
      "Epoch 2677 - Train Loss: 0.215004, Train Acc: 0.596154 | Val Loss: 0.224452, Val Acc: 0.536082\n",
      "Epoch 2678 - Train Loss: 0.214983, Train Acc: 0.596154 | Val Loss: 0.224432, Val Acc: 0.536082\n",
      "Epoch 2679 - Train Loss: 0.214962, Train Acc: 0.596154 | Val Loss: 0.224411, Val Acc: 0.536082\n",
      "Epoch 2680 - Train Loss: 0.214942, Train Acc: 0.596154 | Val Loss: 0.224391, Val Acc: 0.536082\n",
      "Epoch 2681 - Train Loss: 0.214921, Train Acc: 0.596154 | Val Loss: 0.224371, Val Acc: 0.536082\n",
      "Epoch 2682 - Train Loss: 0.214901, Train Acc: 0.596154 | Val Loss: 0.224351, Val Acc: 0.536082\n",
      "Epoch 2683 - Train Loss: 0.214880, Train Acc: 0.596154 | Val Loss: 0.224330, Val Acc: 0.536082\n",
      "Epoch 2684 - Train Loss: 0.214860, Train Acc: 0.596154 | Val Loss: 0.224310, Val Acc: 0.536082\n",
      "Epoch 2685 - Train Loss: 0.214839, Train Acc: 0.596154 | Val Loss: 0.224290, Val Acc: 0.536082\n",
      "Epoch 2686 - Train Loss: 0.214819, Train Acc: 0.596154 | Val Loss: 0.224270, Val Acc: 0.536082\n",
      "Epoch 2687 - Train Loss: 0.214798, Train Acc: 0.596154 | Val Loss: 0.224250, Val Acc: 0.536082\n",
      "Epoch 2688 - Train Loss: 0.214778, Train Acc: 0.596154 | Val Loss: 0.224229, Val Acc: 0.536082\n",
      "Epoch 2689 - Train Loss: 0.214757, Train Acc: 0.596154 | Val Loss: 0.224209, Val Acc: 0.536082\n",
      "Epoch 2690 - Train Loss: 0.214737, Train Acc: 0.596154 | Val Loss: 0.224189, Val Acc: 0.536082\n",
      "Epoch 2691 - Train Loss: 0.214716, Train Acc: 0.597436 | Val Loss: 0.224169, Val Acc: 0.536082\n",
      "Epoch 2692 - Train Loss: 0.214696, Train Acc: 0.597436 | Val Loss: 0.224148, Val Acc: 0.536082\n",
      "Epoch 2693 - Train Loss: 0.214675, Train Acc: 0.597436 | Val Loss: 0.224128, Val Acc: 0.536082\n",
      "Epoch 2694 - Train Loss: 0.214655, Train Acc: 0.597436 | Val Loss: 0.224108, Val Acc: 0.536082\n",
      "Epoch 2695 - Train Loss: 0.214634, Train Acc: 0.597436 | Val Loss: 0.224088, Val Acc: 0.536082\n",
      "Epoch 2696 - Train Loss: 0.214614, Train Acc: 0.597436 | Val Loss: 0.224068, Val Acc: 0.536082\n",
      "Epoch 2697 - Train Loss: 0.214593, Train Acc: 0.597436 | Val Loss: 0.224047, Val Acc: 0.536082\n",
      "Epoch 2698 - Train Loss: 0.214573, Train Acc: 0.597436 | Val Loss: 0.224027, Val Acc: 0.536082\n",
      "Epoch 2699 - Train Loss: 0.214552, Train Acc: 0.597436 | Val Loss: 0.224007, Val Acc: 0.536082\n",
      "Epoch 2700 - Train Loss: 0.214532, Train Acc: 0.597436 | Val Loss: 0.223987, Val Acc: 0.536082\n",
      "Epoch 2701 - Train Loss: 0.214511, Train Acc: 0.597436 | Val Loss: 0.223967, Val Acc: 0.536082\n",
      "Epoch 2702 - Train Loss: 0.214491, Train Acc: 0.597436 | Val Loss: 0.223946, Val Acc: 0.536082\n",
      "Epoch 2703 - Train Loss: 0.214470, Train Acc: 0.597436 | Val Loss: 0.223926, Val Acc: 0.536082\n",
      "Epoch 2704 - Train Loss: 0.214450, Train Acc: 0.597436 | Val Loss: 0.223906, Val Acc: 0.536082\n",
      "Epoch 2705 - Train Loss: 0.214429, Train Acc: 0.597436 | Val Loss: 0.223886, Val Acc: 0.536082\n",
      "Epoch 2706 - Train Loss: 0.214409, Train Acc: 0.597436 | Val Loss: 0.223866, Val Acc: 0.536082\n",
      "Epoch 2707 - Train Loss: 0.214388, Train Acc: 0.597436 | Val Loss: 0.223846, Val Acc: 0.536082\n",
      "Epoch 2708 - Train Loss: 0.214368, Train Acc: 0.597436 | Val Loss: 0.223825, Val Acc: 0.536082\n",
      "Epoch 2709 - Train Loss: 0.214347, Train Acc: 0.597436 | Val Loss: 0.223805, Val Acc: 0.536082\n",
      "Epoch 2710 - Train Loss: 0.214327, Train Acc: 0.597436 | Val Loss: 0.223785, Val Acc: 0.536082\n",
      "Epoch 2711 - Train Loss: 0.214306, Train Acc: 0.597436 | Val Loss: 0.223765, Val Acc: 0.536082\n",
      "Epoch 2712 - Train Loss: 0.214286, Train Acc: 0.597436 | Val Loss: 0.223745, Val Acc: 0.536082\n",
      "Epoch 2713 - Train Loss: 0.214265, Train Acc: 0.597436 | Val Loss: 0.223724, Val Acc: 0.536082\n",
      "Epoch 2714 - Train Loss: 0.214245, Train Acc: 0.597436 | Val Loss: 0.223704, Val Acc: 0.536082\n",
      "Epoch 2715 - Train Loss: 0.214224, Train Acc: 0.597436 | Val Loss: 0.223684, Val Acc: 0.536082\n",
      "Epoch 2716 - Train Loss: 0.214204, Train Acc: 0.597436 | Val Loss: 0.223664, Val Acc: 0.536082\n",
      "Epoch 2717 - Train Loss: 0.214183, Train Acc: 0.597436 | Val Loss: 0.223644, Val Acc: 0.536082\n",
      "Epoch 2718 - Train Loss: 0.214163, Train Acc: 0.597436 | Val Loss: 0.223624, Val Acc: 0.536082\n",
      "Epoch 2719 - Train Loss: 0.214142, Train Acc: 0.597436 | Val Loss: 0.223604, Val Acc: 0.536082\n",
      "Epoch 2720 - Train Loss: 0.214122, Train Acc: 0.597436 | Val Loss: 0.223583, Val Acc: 0.536082\n",
      "Epoch 2721 - Train Loss: 0.214101, Train Acc: 0.597436 | Val Loss: 0.223563, Val Acc: 0.536082\n",
      "Epoch 2722 - Train Loss: 0.214081, Train Acc: 0.597436 | Val Loss: 0.223543, Val Acc: 0.536082\n",
      "Epoch 2723 - Train Loss: 0.214060, Train Acc: 0.597436 | Val Loss: 0.223523, Val Acc: 0.536082\n",
      "Epoch 2724 - Train Loss: 0.214040, Train Acc: 0.597436 | Val Loss: 0.223503, Val Acc: 0.536082\n",
      "Epoch 2725 - Train Loss: 0.214019, Train Acc: 0.597436 | Val Loss: 0.223483, Val Acc: 0.536082\n",
      "Epoch 2726 - Train Loss: 0.213999, Train Acc: 0.597436 | Val Loss: 0.223463, Val Acc: 0.536082\n",
      "Epoch 2727 - Train Loss: 0.213978, Train Acc: 0.597436 | Val Loss: 0.223442, Val Acc: 0.536082\n",
      "Epoch 2728 - Train Loss: 0.213958, Train Acc: 0.597436 | Val Loss: 0.223422, Val Acc: 0.536082\n",
      "Epoch 2729 - Train Loss: 0.213938, Train Acc: 0.597436 | Val Loss: 0.223402, Val Acc: 0.536082\n",
      "Epoch 2730 - Train Loss: 0.213917, Train Acc: 0.597436 | Val Loss: 0.223382, Val Acc: 0.536082\n",
      "Epoch 2731 - Train Loss: 0.213897, Train Acc: 0.597436 | Val Loss: 0.223362, Val Acc: 0.536082\n",
      "Epoch 2732 - Train Loss: 0.213876, Train Acc: 0.597436 | Val Loss: 0.223342, Val Acc: 0.536082\n",
      "Epoch 2733 - Train Loss: 0.213856, Train Acc: 0.597436 | Val Loss: 0.223322, Val Acc: 0.536082\n",
      "Epoch 2734 - Train Loss: 0.213835, Train Acc: 0.597436 | Val Loss: 0.223302, Val Acc: 0.536082\n",
      "Epoch 2735 - Train Loss: 0.213815, Train Acc: 0.597436 | Val Loss: 0.223282, Val Acc: 0.536082\n",
      "Epoch 2736 - Train Loss: 0.213795, Train Acc: 0.597436 | Val Loss: 0.223261, Val Acc: 0.536082\n",
      "Epoch 2737 - Train Loss: 0.213774, Train Acc: 0.597436 | Val Loss: 0.223241, Val Acc: 0.536082\n",
      "Epoch 2738 - Train Loss: 0.213754, Train Acc: 0.598718 | Val Loss: 0.223221, Val Acc: 0.536082\n",
      "Epoch 2739 - Train Loss: 0.213733, Train Acc: 0.598718 | Val Loss: 0.223201, Val Acc: 0.536082\n",
      "Epoch 2740 - Train Loss: 0.213713, Train Acc: 0.598718 | Val Loss: 0.223181, Val Acc: 0.536082\n",
      "Epoch 2741 - Train Loss: 0.213693, Train Acc: 0.598718 | Val Loss: 0.223161, Val Acc: 0.536082\n",
      "Epoch 2742 - Train Loss: 0.213672, Train Acc: 0.598718 | Val Loss: 0.223141, Val Acc: 0.536082\n",
      "Epoch 2743 - Train Loss: 0.213652, Train Acc: 0.598718 | Val Loss: 0.223121, Val Acc: 0.536082\n",
      "Epoch 2744 - Train Loss: 0.213631, Train Acc: 0.598718 | Val Loss: 0.223101, Val Acc: 0.536082\n",
      "Epoch 2745 - Train Loss: 0.213611, Train Acc: 0.598718 | Val Loss: 0.223080, Val Acc: 0.536082\n",
      "Epoch 2746 - Train Loss: 0.213591, Train Acc: 0.598718 | Val Loss: 0.223060, Val Acc: 0.536082\n",
      "Epoch 2747 - Train Loss: 0.213570, Train Acc: 0.598718 | Val Loss: 0.223040, Val Acc: 0.536082\n",
      "Epoch 2748 - Train Loss: 0.213550, Train Acc: 0.598718 | Val Loss: 0.223020, Val Acc: 0.536082\n",
      "Epoch 2749 - Train Loss: 0.213530, Train Acc: 0.598718 | Val Loss: 0.223000, Val Acc: 0.536082\n",
      "Epoch 2750 - Train Loss: 0.213509, Train Acc: 0.598718 | Val Loss: 0.222980, Val Acc: 0.536082\n",
      "Epoch 2751 - Train Loss: 0.213489, Train Acc: 0.598718 | Val Loss: 0.222960, Val Acc: 0.536082\n",
      "Epoch 2752 - Train Loss: 0.213469, Train Acc: 0.598718 | Val Loss: 0.222940, Val Acc: 0.536082\n",
      "Epoch 2753 - Train Loss: 0.213448, Train Acc: 0.598718 | Val Loss: 0.222920, Val Acc: 0.536082\n",
      "Epoch 2754 - Train Loss: 0.213428, Train Acc: 0.598718 | Val Loss: 0.222900, Val Acc: 0.536082\n",
      "Epoch 2755 - Train Loss: 0.213407, Train Acc: 0.600000 | Val Loss: 0.222879, Val Acc: 0.536082\n",
      "Epoch 2756 - Train Loss: 0.213387, Train Acc: 0.600000 | Val Loss: 0.222859, Val Acc: 0.536082\n",
      "Epoch 2757 - Train Loss: 0.213367, Train Acc: 0.600000 | Val Loss: 0.222839, Val Acc: 0.536082\n",
      "Epoch 2758 - Train Loss: 0.213346, Train Acc: 0.600000 | Val Loss: 0.222819, Val Acc: 0.536082\n",
      "Epoch 2759 - Train Loss: 0.213326, Train Acc: 0.600000 | Val Loss: 0.222799, Val Acc: 0.536082\n",
      "Epoch 2760 - Train Loss: 0.213306, Train Acc: 0.600000 | Val Loss: 0.222779, Val Acc: 0.536082\n",
      "Epoch 2761 - Train Loss: 0.213285, Train Acc: 0.600000 | Val Loss: 0.222759, Val Acc: 0.536082\n",
      "Epoch 2762 - Train Loss: 0.213265, Train Acc: 0.600000 | Val Loss: 0.222739, Val Acc: 0.536082\n",
      "Epoch 2763 - Train Loss: 0.213245, Train Acc: 0.600000 | Val Loss: 0.222719, Val Acc: 0.536082\n",
      "Epoch 2764 - Train Loss: 0.213224, Train Acc: 0.600000 | Val Loss: 0.222699, Val Acc: 0.536082\n",
      "Epoch 2765 - Train Loss: 0.213204, Train Acc: 0.600000 | Val Loss: 0.222679, Val Acc: 0.536082\n",
      "Epoch 2766 - Train Loss: 0.213184, Train Acc: 0.600000 | Val Loss: 0.222659, Val Acc: 0.536082\n",
      "Epoch 2767 - Train Loss: 0.213163, Train Acc: 0.600000 | Val Loss: 0.222639, Val Acc: 0.536082\n",
      "Epoch 2768 - Train Loss: 0.213143, Train Acc: 0.600000 | Val Loss: 0.222618, Val Acc: 0.536082\n",
      "Epoch 2769 - Train Loss: 0.213123, Train Acc: 0.600000 | Val Loss: 0.222598, Val Acc: 0.536082\n",
      "Epoch 2770 - Train Loss: 0.213102, Train Acc: 0.600000 | Val Loss: 0.222578, Val Acc: 0.536082\n",
      "Epoch 2771 - Train Loss: 0.213082, Train Acc: 0.600000 | Val Loss: 0.222558, Val Acc: 0.536082\n",
      "Epoch 2772 - Train Loss: 0.213062, Train Acc: 0.600000 | Val Loss: 0.222538, Val Acc: 0.536082\n",
      "Epoch 2773 - Train Loss: 0.213042, Train Acc: 0.600000 | Val Loss: 0.222518, Val Acc: 0.536082\n",
      "Epoch 2774 - Train Loss: 0.213021, Train Acc: 0.600000 | Val Loss: 0.222498, Val Acc: 0.536082\n",
      "Epoch 2775 - Train Loss: 0.213001, Train Acc: 0.600000 | Val Loss: 0.222478, Val Acc: 0.536082\n",
      "Epoch 2776 - Train Loss: 0.212981, Train Acc: 0.600000 | Val Loss: 0.222458, Val Acc: 0.536082\n",
      "Epoch 2777 - Train Loss: 0.212961, Train Acc: 0.600000 | Val Loss: 0.222438, Val Acc: 0.536082\n",
      "Epoch 2778 - Train Loss: 0.212940, Train Acc: 0.600000 | Val Loss: 0.222418, Val Acc: 0.536082\n",
      "Epoch 2779 - Train Loss: 0.212920, Train Acc: 0.600000 | Val Loss: 0.222398, Val Acc: 0.536082\n",
      "Epoch 2780 - Train Loss: 0.212900, Train Acc: 0.600000 | Val Loss: 0.222378, Val Acc: 0.536082\n",
      "Epoch 2781 - Train Loss: 0.212879, Train Acc: 0.600000 | Val Loss: 0.222358, Val Acc: 0.536082\n",
      "Epoch 2782 - Train Loss: 0.212859, Train Acc: 0.600000 | Val Loss: 0.222338, Val Acc: 0.536082\n",
      "Epoch 2783 - Train Loss: 0.212839, Train Acc: 0.600000 | Val Loss: 0.222318, Val Acc: 0.536082\n",
      "Epoch 2784 - Train Loss: 0.212819, Train Acc: 0.600000 | Val Loss: 0.222298, Val Acc: 0.536082\n",
      "Epoch 2785 - Train Loss: 0.212798, Train Acc: 0.600000 | Val Loss: 0.222278, Val Acc: 0.536082\n",
      "Epoch 2786 - Train Loss: 0.212778, Train Acc: 0.600000 | Val Loss: 0.222258, Val Acc: 0.536082\n",
      "Epoch 2787 - Train Loss: 0.212758, Train Acc: 0.600000 | Val Loss: 0.222238, Val Acc: 0.536082\n",
      "Epoch 2788 - Train Loss: 0.212738, Train Acc: 0.600000 | Val Loss: 0.222218, Val Acc: 0.536082\n",
      "Epoch 2789 - Train Loss: 0.212717, Train Acc: 0.600000 | Val Loss: 0.222198, Val Acc: 0.536082\n",
      "Epoch 2790 - Train Loss: 0.212697, Train Acc: 0.600000 | Val Loss: 0.222178, Val Acc: 0.536082\n",
      "Epoch 2791 - Train Loss: 0.212677, Train Acc: 0.600000 | Val Loss: 0.222158, Val Acc: 0.536082\n",
      "Epoch 2792 - Train Loss: 0.212657, Train Acc: 0.600000 | Val Loss: 0.222138, Val Acc: 0.536082\n",
      "Epoch 2793 - Train Loss: 0.212636, Train Acc: 0.600000 | Val Loss: 0.222118, Val Acc: 0.536082\n",
      "Epoch 2794 - Train Loss: 0.212616, Train Acc: 0.600000 | Val Loss: 0.222098, Val Acc: 0.536082\n",
      "Epoch 2795 - Train Loss: 0.212596, Train Acc: 0.600000 | Val Loss: 0.222078, Val Acc: 0.536082\n",
      "Epoch 2796 - Train Loss: 0.212576, Train Acc: 0.600000 | Val Loss: 0.222058, Val Acc: 0.536082\n",
      "Epoch 2797 - Train Loss: 0.212555, Train Acc: 0.600000 | Val Loss: 0.222038, Val Acc: 0.536082\n",
      "Epoch 2798 - Train Loss: 0.212535, Train Acc: 0.598718 | Val Loss: 0.222018, Val Acc: 0.536082\n",
      "Epoch 2799 - Train Loss: 0.212515, Train Acc: 0.598718 | Val Loss: 0.221998, Val Acc: 0.536082\n",
      "Epoch 2800 - Train Loss: 0.212495, Train Acc: 0.598718 | Val Loss: 0.221978, Val Acc: 0.536082\n",
      "Epoch 2801 - Train Loss: 0.212475, Train Acc: 0.598718 | Val Loss: 0.221958, Val Acc: 0.536082\n",
      "Epoch 2802 - Train Loss: 0.212454, Train Acc: 0.598718 | Val Loss: 0.221938, Val Acc: 0.536082\n",
      "Epoch 2803 - Train Loss: 0.212434, Train Acc: 0.598718 | Val Loss: 0.221918, Val Acc: 0.536082\n",
      "Epoch 2804 - Train Loss: 0.212414, Train Acc: 0.598718 | Val Loss: 0.221898, Val Acc: 0.536082\n",
      "Epoch 2805 - Train Loss: 0.212394, Train Acc: 0.598718 | Val Loss: 0.221878, Val Acc: 0.536082\n",
      "Epoch 2806 - Train Loss: 0.212373, Train Acc: 0.598718 | Val Loss: 0.221858, Val Acc: 0.536082\n",
      "Epoch 2807 - Train Loss: 0.212353, Train Acc: 0.598718 | Val Loss: 0.221839, Val Acc: 0.536082\n",
      "Epoch 2808 - Train Loss: 0.212333, Train Acc: 0.598718 | Val Loss: 0.221819, Val Acc: 0.536082\n",
      "Epoch 2809 - Train Loss: 0.212313, Train Acc: 0.598718 | Val Loss: 0.221799, Val Acc: 0.536082\n",
      "Epoch 2810 - Train Loss: 0.212293, Train Acc: 0.598718 | Val Loss: 0.221779, Val Acc: 0.546392\n",
      "Epoch 2811 - Train Loss: 0.212272, Train Acc: 0.598718 | Val Loss: 0.221759, Val Acc: 0.546392\n",
      "Epoch 2812 - Train Loss: 0.212252, Train Acc: 0.598718 | Val Loss: 0.221739, Val Acc: 0.546392\n",
      "Epoch 2813 - Train Loss: 0.212232, Train Acc: 0.598718 | Val Loss: 0.221719, Val Acc: 0.546392\n",
      "Epoch 2814 - Train Loss: 0.212212, Train Acc: 0.600000 | Val Loss: 0.221699, Val Acc: 0.546392\n",
      "Epoch 2815 - Train Loss: 0.212192, Train Acc: 0.600000 | Val Loss: 0.221679, Val Acc: 0.546392\n",
      "Epoch 2816 - Train Loss: 0.212171, Train Acc: 0.600000 | Val Loss: 0.221659, Val Acc: 0.546392\n",
      "Epoch 2817 - Train Loss: 0.212151, Train Acc: 0.600000 | Val Loss: 0.221639, Val Acc: 0.546392\n",
      "Epoch 2818 - Train Loss: 0.212131, Train Acc: 0.600000 | Val Loss: 0.221619, Val Acc: 0.546392\n",
      "Epoch 2819 - Train Loss: 0.212111, Train Acc: 0.600000 | Val Loss: 0.221599, Val Acc: 0.546392\n",
      "Epoch 2820 - Train Loss: 0.212091, Train Acc: 0.600000 | Val Loss: 0.221579, Val Acc: 0.546392\n",
      "Epoch 2821 - Train Loss: 0.212071, Train Acc: 0.600000 | Val Loss: 0.221559, Val Acc: 0.546392\n",
      "Epoch 2822 - Train Loss: 0.212050, Train Acc: 0.600000 | Val Loss: 0.221540, Val Acc: 0.546392\n",
      "Epoch 2823 - Train Loss: 0.212030, Train Acc: 0.600000 | Val Loss: 0.221520, Val Acc: 0.546392\n",
      "Epoch 2824 - Train Loss: 0.212010, Train Acc: 0.598718 | Val Loss: 0.221500, Val Acc: 0.546392\n",
      "Epoch 2825 - Train Loss: 0.211990, Train Acc: 0.598718 | Val Loss: 0.221480, Val Acc: 0.546392\n",
      "Epoch 2826 - Train Loss: 0.211970, Train Acc: 0.598718 | Val Loss: 0.221460, Val Acc: 0.546392\n",
      "Epoch 2827 - Train Loss: 0.211949, Train Acc: 0.598718 | Val Loss: 0.221440, Val Acc: 0.546392\n",
      "Epoch 2828 - Train Loss: 0.211929, Train Acc: 0.600000 | Val Loss: 0.221420, Val Acc: 0.546392\n",
      "Epoch 2829 - Train Loss: 0.211909, Train Acc: 0.600000 | Val Loss: 0.221400, Val Acc: 0.546392\n",
      "Epoch 2830 - Train Loss: 0.211889, Train Acc: 0.600000 | Val Loss: 0.221380, Val Acc: 0.546392\n",
      "Epoch 2831 - Train Loss: 0.211869, Train Acc: 0.600000 | Val Loss: 0.221360, Val Acc: 0.546392\n",
      "Epoch 2832 - Train Loss: 0.211849, Train Acc: 0.600000 | Val Loss: 0.221341, Val Acc: 0.546392\n",
      "Epoch 2833 - Train Loss: 0.211829, Train Acc: 0.600000 | Val Loss: 0.221321, Val Acc: 0.546392\n",
      "Epoch 2834 - Train Loss: 0.211808, Train Acc: 0.600000 | Val Loss: 0.221301, Val Acc: 0.546392\n",
      "Epoch 2835 - Train Loss: 0.211788, Train Acc: 0.600000 | Val Loss: 0.221281, Val Acc: 0.546392\n",
      "Epoch 2836 - Train Loss: 0.211768, Train Acc: 0.600000 | Val Loss: 0.221261, Val Acc: 0.546392\n",
      "Epoch 2837 - Train Loss: 0.211748, Train Acc: 0.600000 | Val Loss: 0.221241, Val Acc: 0.546392\n",
      "Epoch 2838 - Train Loss: 0.211728, Train Acc: 0.600000 | Val Loss: 0.221222, Val Acc: 0.546392\n",
      "Epoch 2839 - Train Loss: 0.211708, Train Acc: 0.600000 | Val Loss: 0.221202, Val Acc: 0.546392\n",
      "Epoch 2840 - Train Loss: 0.211688, Train Acc: 0.600000 | Val Loss: 0.221182, Val Acc: 0.546392\n",
      "Epoch 2841 - Train Loss: 0.211668, Train Acc: 0.600000 | Val Loss: 0.221162, Val Acc: 0.546392\n",
      "Epoch 2842 - Train Loss: 0.211648, Train Acc: 0.600000 | Val Loss: 0.221142, Val Acc: 0.546392\n",
      "Epoch 2843 - Train Loss: 0.211628, Train Acc: 0.600000 | Val Loss: 0.221123, Val Acc: 0.546392\n",
      "Epoch 2844 - Train Loss: 0.211608, Train Acc: 0.600000 | Val Loss: 0.221103, Val Acc: 0.546392\n",
      "Epoch 2845 - Train Loss: 0.211587, Train Acc: 0.600000 | Val Loss: 0.221083, Val Acc: 0.546392\n",
      "Epoch 2846 - Train Loss: 0.211567, Train Acc: 0.600000 | Val Loss: 0.221063, Val Acc: 0.546392\n",
      "Epoch 2847 - Train Loss: 0.211547, Train Acc: 0.600000 | Val Loss: 0.221043, Val Acc: 0.546392\n",
      "Epoch 2848 - Train Loss: 0.211527, Train Acc: 0.600000 | Val Loss: 0.221024, Val Acc: 0.546392\n",
      "Epoch 2849 - Train Loss: 0.211507, Train Acc: 0.600000 | Val Loss: 0.221004, Val Acc: 0.546392\n",
      "Epoch 2850 - Train Loss: 0.211487, Train Acc: 0.600000 | Val Loss: 0.220984, Val Acc: 0.546392\n",
      "Epoch 2851 - Train Loss: 0.211467, Train Acc: 0.600000 | Val Loss: 0.220964, Val Acc: 0.546392\n",
      "Epoch 2852 - Train Loss: 0.211447, Train Acc: 0.601282 | Val Loss: 0.220945, Val Acc: 0.546392\n",
      "Epoch 2853 - Train Loss: 0.211427, Train Acc: 0.601282 | Val Loss: 0.220925, Val Acc: 0.546392\n",
      "Epoch 2854 - Train Loss: 0.211407, Train Acc: 0.601282 | Val Loss: 0.220905, Val Acc: 0.546392\n",
      "Epoch 2855 - Train Loss: 0.211387, Train Acc: 0.601282 | Val Loss: 0.220885, Val Acc: 0.546392\n",
      "Epoch 2856 - Train Loss: 0.211367, Train Acc: 0.601282 | Val Loss: 0.220865, Val Acc: 0.556701\n",
      "Epoch 2857 - Train Loss: 0.211347, Train Acc: 0.601282 | Val Loss: 0.220846, Val Acc: 0.556701\n",
      "Epoch 2858 - Train Loss: 0.211327, Train Acc: 0.601282 | Val Loss: 0.220826, Val Acc: 0.556701\n",
      "Epoch 2859 - Train Loss: 0.211307, Train Acc: 0.602564 | Val Loss: 0.220806, Val Acc: 0.556701\n",
      "Epoch 2860 - Train Loss: 0.211287, Train Acc: 0.602564 | Val Loss: 0.220787, Val Acc: 0.556701\n",
      "Epoch 2861 - Train Loss: 0.211267, Train Acc: 0.602564 | Val Loss: 0.220767, Val Acc: 0.556701\n",
      "Epoch 2862 - Train Loss: 0.211247, Train Acc: 0.602564 | Val Loss: 0.220747, Val Acc: 0.556701\n",
      "Epoch 2863 - Train Loss: 0.211227, Train Acc: 0.602564 | Val Loss: 0.220727, Val Acc: 0.556701\n",
      "Epoch 2864 - Train Loss: 0.211207, Train Acc: 0.602564 | Val Loss: 0.220708, Val Acc: 0.556701\n",
      "Epoch 2865 - Train Loss: 0.211187, Train Acc: 0.602564 | Val Loss: 0.220688, Val Acc: 0.556701\n",
      "Epoch 2866 - Train Loss: 0.211167, Train Acc: 0.602564 | Val Loss: 0.220668, Val Acc: 0.556701\n",
      "Epoch 2867 - Train Loss: 0.211147, Train Acc: 0.602564 | Val Loss: 0.220649, Val Acc: 0.556701\n",
      "Epoch 2868 - Train Loss: 0.211127, Train Acc: 0.602564 | Val Loss: 0.220629, Val Acc: 0.556701\n",
      "Epoch 2869 - Train Loss: 0.211107, Train Acc: 0.602564 | Val Loss: 0.220609, Val Acc: 0.556701\n",
      "Epoch 2870 - Train Loss: 0.211087, Train Acc: 0.602564 | Val Loss: 0.220589, Val Acc: 0.556701\n",
      "Epoch 2871 - Train Loss: 0.211067, Train Acc: 0.603846 | Val Loss: 0.220570, Val Acc: 0.556701\n",
      "Epoch 2872 - Train Loss: 0.211047, Train Acc: 0.603846 | Val Loss: 0.220550, Val Acc: 0.556701\n",
      "Epoch 2873 - Train Loss: 0.211027, Train Acc: 0.603846 | Val Loss: 0.220530, Val Acc: 0.556701\n",
      "Epoch 2874 - Train Loss: 0.211007, Train Acc: 0.603846 | Val Loss: 0.220511, Val Acc: 0.556701\n",
      "Epoch 2875 - Train Loss: 0.210987, Train Acc: 0.603846 | Val Loss: 0.220491, Val Acc: 0.556701\n",
      "Epoch 2876 - Train Loss: 0.210967, Train Acc: 0.603846 | Val Loss: 0.220472, Val Acc: 0.556701\n",
      "Epoch 2877 - Train Loss: 0.210947, Train Acc: 0.603846 | Val Loss: 0.220452, Val Acc: 0.556701\n",
      "Epoch 2878 - Train Loss: 0.210927, Train Acc: 0.603846 | Val Loss: 0.220433, Val Acc: 0.556701\n",
      "Epoch 2879 - Train Loss: 0.210907, Train Acc: 0.603846 | Val Loss: 0.220413, Val Acc: 0.556701\n",
      "Epoch 2880 - Train Loss: 0.210887, Train Acc: 0.603846 | Val Loss: 0.220393, Val Acc: 0.556701\n",
      "Epoch 2881 - Train Loss: 0.210867, Train Acc: 0.603846 | Val Loss: 0.220374, Val Acc: 0.556701\n",
      "Epoch 2882 - Train Loss: 0.210847, Train Acc: 0.605128 | Val Loss: 0.220354, Val Acc: 0.556701\n",
      "Epoch 2883 - Train Loss: 0.210827, Train Acc: 0.605128 | Val Loss: 0.220334, Val Acc: 0.556701\n",
      "Epoch 2884 - Train Loss: 0.210808, Train Acc: 0.605128 | Val Loss: 0.220315, Val Acc: 0.556701\n",
      "Epoch 2885 - Train Loss: 0.210788, Train Acc: 0.605128 | Val Loss: 0.220295, Val Acc: 0.556701\n",
      "Epoch 2886 - Train Loss: 0.210768, Train Acc: 0.605128 | Val Loss: 0.220275, Val Acc: 0.556701\n",
      "Epoch 2887 - Train Loss: 0.210748, Train Acc: 0.605128 | Val Loss: 0.220256, Val Acc: 0.556701\n",
      "Epoch 2888 - Train Loss: 0.210728, Train Acc: 0.605128 | Val Loss: 0.220236, Val Acc: 0.556701\n",
      "Epoch 2889 - Train Loss: 0.210708, Train Acc: 0.605128 | Val Loss: 0.220217, Val Acc: 0.556701\n",
      "Epoch 2890 - Train Loss: 0.210688, Train Acc: 0.605128 | Val Loss: 0.220197, Val Acc: 0.556701\n",
      "Epoch 2891 - Train Loss: 0.210668, Train Acc: 0.605128 | Val Loss: 0.220177, Val Acc: 0.556701\n",
      "Epoch 2892 - Train Loss: 0.210649, Train Acc: 0.605128 | Val Loss: 0.220158, Val Acc: 0.556701\n",
      "Epoch 2893 - Train Loss: 0.210629, Train Acc: 0.605128 | Val Loss: 0.220138, Val Acc: 0.556701\n",
      "Epoch 2894 - Train Loss: 0.210609, Train Acc: 0.605128 | Val Loss: 0.220119, Val Acc: 0.556701\n",
      "Epoch 2895 - Train Loss: 0.210589, Train Acc: 0.605128 | Val Loss: 0.220099, Val Acc: 0.556701\n",
      "Epoch 2896 - Train Loss: 0.210569, Train Acc: 0.605128 | Val Loss: 0.220079, Val Acc: 0.556701\n",
      "Epoch 2897 - Train Loss: 0.210549, Train Acc: 0.605128 | Val Loss: 0.220060, Val Acc: 0.556701\n",
      "Epoch 2898 - Train Loss: 0.210529, Train Acc: 0.605128 | Val Loss: 0.220040, Val Acc: 0.556701\n",
      "Epoch 2899 - Train Loss: 0.210510, Train Acc: 0.605128 | Val Loss: 0.220021, Val Acc: 0.556701\n",
      "Epoch 2900 - Train Loss: 0.210490, Train Acc: 0.605128 | Val Loss: 0.220001, Val Acc: 0.556701\n",
      "Epoch 2901 - Train Loss: 0.210470, Train Acc: 0.605128 | Val Loss: 0.219982, Val Acc: 0.556701\n",
      "Epoch 2902 - Train Loss: 0.210450, Train Acc: 0.605128 | Val Loss: 0.219962, Val Acc: 0.556701\n",
      "Epoch 2903 - Train Loss: 0.210430, Train Acc: 0.605128 | Val Loss: 0.219943, Val Acc: 0.556701\n",
      "Epoch 2904 - Train Loss: 0.210410, Train Acc: 0.605128 | Val Loss: 0.219923, Val Acc: 0.556701\n",
      "Epoch 2905 - Train Loss: 0.210391, Train Acc: 0.605128 | Val Loss: 0.219904, Val Acc: 0.556701\n",
      "Epoch 2906 - Train Loss: 0.210371, Train Acc: 0.605128 | Val Loss: 0.219884, Val Acc: 0.556701\n",
      "Epoch 2907 - Train Loss: 0.210351, Train Acc: 0.605128 | Val Loss: 0.219865, Val Acc: 0.556701\n",
      "Epoch 2908 - Train Loss: 0.210331, Train Acc: 0.605128 | Val Loss: 0.219845, Val Acc: 0.556701\n",
      "Epoch 2909 - Train Loss: 0.210311, Train Acc: 0.606410 | Val Loss: 0.219826, Val Acc: 0.556701\n",
      "Epoch 2910 - Train Loss: 0.210292, Train Acc: 0.606410 | Val Loss: 0.219806, Val Acc: 0.556701\n",
      "Epoch 2911 - Train Loss: 0.210272, Train Acc: 0.606410 | Val Loss: 0.219787, Val Acc: 0.556701\n",
      "Epoch 2912 - Train Loss: 0.210252, Train Acc: 0.606410 | Val Loss: 0.219767, Val Acc: 0.556701\n",
      "Epoch 2913 - Train Loss: 0.210232, Train Acc: 0.606410 | Val Loss: 0.219748, Val Acc: 0.556701\n",
      "Epoch 2914 - Train Loss: 0.210212, Train Acc: 0.606410 | Val Loss: 0.219728, Val Acc: 0.556701\n",
      "Epoch 2915 - Train Loss: 0.210193, Train Acc: 0.606410 | Val Loss: 0.219709, Val Acc: 0.556701\n",
      "Epoch 2916 - Train Loss: 0.210173, Train Acc: 0.606410 | Val Loss: 0.219689, Val Acc: 0.556701\n",
      "Epoch 2917 - Train Loss: 0.210153, Train Acc: 0.606410 | Val Loss: 0.219670, Val Acc: 0.556701\n",
      "Epoch 2918 - Train Loss: 0.210133, Train Acc: 0.606410 | Val Loss: 0.219650, Val Acc: 0.556701\n",
      "Epoch 2919 - Train Loss: 0.210113, Train Acc: 0.606410 | Val Loss: 0.219631, Val Acc: 0.556701\n",
      "Epoch 2920 - Train Loss: 0.210094, Train Acc: 0.606410 | Val Loss: 0.219612, Val Acc: 0.556701\n",
      "Epoch 2921 - Train Loss: 0.210074, Train Acc: 0.606410 | Val Loss: 0.219592, Val Acc: 0.556701\n",
      "Epoch 2922 - Train Loss: 0.210054, Train Acc: 0.606410 | Val Loss: 0.219573, Val Acc: 0.556701\n",
      "Epoch 2923 - Train Loss: 0.210034, Train Acc: 0.606410 | Val Loss: 0.219553, Val Acc: 0.556701\n",
      "Epoch 2924 - Train Loss: 0.210014, Train Acc: 0.606410 | Val Loss: 0.219534, Val Acc: 0.556701\n",
      "Epoch 2925 - Train Loss: 0.209995, Train Acc: 0.606410 | Val Loss: 0.219515, Val Acc: 0.556701\n",
      "Epoch 2926 - Train Loss: 0.209975, Train Acc: 0.606410 | Val Loss: 0.219495, Val Acc: 0.556701\n",
      "Epoch 2927 - Train Loss: 0.209955, Train Acc: 0.606410 | Val Loss: 0.219476, Val Acc: 0.556701\n",
      "Epoch 2928 - Train Loss: 0.209935, Train Acc: 0.606410 | Val Loss: 0.219456, Val Acc: 0.556701\n",
      "Epoch 2929 - Train Loss: 0.209916, Train Acc: 0.606410 | Val Loss: 0.219437, Val Acc: 0.556701\n",
      "Epoch 2930 - Train Loss: 0.209896, Train Acc: 0.606410 | Val Loss: 0.219417, Val Acc: 0.556701\n",
      "Epoch 2931 - Train Loss: 0.209876, Train Acc: 0.606410 | Val Loss: 0.219398, Val Acc: 0.556701\n",
      "Epoch 2932 - Train Loss: 0.209856, Train Acc: 0.606410 | Val Loss: 0.219379, Val Acc: 0.556701\n",
      "Epoch 2933 - Train Loss: 0.209837, Train Acc: 0.606410 | Val Loss: 0.219359, Val Acc: 0.556701\n",
      "Epoch 2934 - Train Loss: 0.209817, Train Acc: 0.606410 | Val Loss: 0.219340, Val Acc: 0.556701\n",
      "Epoch 2935 - Train Loss: 0.209797, Train Acc: 0.607692 | Val Loss: 0.219320, Val Acc: 0.556701\n",
      "Epoch 2936 - Train Loss: 0.209778, Train Acc: 0.607692 | Val Loss: 0.219301, Val Acc: 0.556701\n",
      "Epoch 2937 - Train Loss: 0.209758, Train Acc: 0.607692 | Val Loss: 0.219282, Val Acc: 0.556701\n",
      "Epoch 2938 - Train Loss: 0.209738, Train Acc: 0.607692 | Val Loss: 0.219262, Val Acc: 0.556701\n",
      "Epoch 2939 - Train Loss: 0.209718, Train Acc: 0.607692 | Val Loss: 0.219243, Val Acc: 0.556701\n",
      "Epoch 2940 - Train Loss: 0.209699, Train Acc: 0.607692 | Val Loss: 0.219224, Val Acc: 0.556701\n",
      "Epoch 2941 - Train Loss: 0.209679, Train Acc: 0.607692 | Val Loss: 0.219204, Val Acc: 0.556701\n",
      "Epoch 2942 - Train Loss: 0.209659, Train Acc: 0.607692 | Val Loss: 0.219185, Val Acc: 0.556701\n",
      "Epoch 2943 - Train Loss: 0.209639, Train Acc: 0.607692 | Val Loss: 0.219165, Val Acc: 0.556701\n",
      "Epoch 2944 - Train Loss: 0.209620, Train Acc: 0.607692 | Val Loss: 0.219146, Val Acc: 0.556701\n",
      "Epoch 2945 - Train Loss: 0.209600, Train Acc: 0.607692 | Val Loss: 0.219127, Val Acc: 0.556701\n",
      "Epoch 2946 - Train Loss: 0.209580, Train Acc: 0.607692 | Val Loss: 0.219107, Val Acc: 0.556701\n",
      "Epoch 2947 - Train Loss: 0.209561, Train Acc: 0.607692 | Val Loss: 0.219088, Val Acc: 0.556701\n",
      "Epoch 2948 - Train Loss: 0.209541, Train Acc: 0.607692 | Val Loss: 0.219069, Val Acc: 0.556701\n",
      "Epoch 2949 - Train Loss: 0.209521, Train Acc: 0.607692 | Val Loss: 0.219049, Val Acc: 0.556701\n",
      "Epoch 2950 - Train Loss: 0.209502, Train Acc: 0.607692 | Val Loss: 0.219030, Val Acc: 0.556701\n",
      "Epoch 2951 - Train Loss: 0.209482, Train Acc: 0.607692 | Val Loss: 0.219011, Val Acc: 0.556701\n",
      "Epoch 2952 - Train Loss: 0.209462, Train Acc: 0.607692 | Val Loss: 0.218991, Val Acc: 0.556701\n",
      "Epoch 2953 - Train Loss: 0.209443, Train Acc: 0.607692 | Val Loss: 0.218972, Val Acc: 0.556701\n",
      "Epoch 2954 - Train Loss: 0.209423, Train Acc: 0.607692 | Val Loss: 0.218953, Val Acc: 0.556701\n",
      "Epoch 2955 - Train Loss: 0.209403, Train Acc: 0.607692 | Val Loss: 0.218933, Val Acc: 0.556701\n",
      "Epoch 2956 - Train Loss: 0.209384, Train Acc: 0.607692 | Val Loss: 0.218914, Val Acc: 0.556701\n",
      "Epoch 2957 - Train Loss: 0.209364, Train Acc: 0.607692 | Val Loss: 0.218895, Val Acc: 0.556701\n",
      "Epoch 2958 - Train Loss: 0.209344, Train Acc: 0.607692 | Val Loss: 0.218876, Val Acc: 0.556701\n",
      "Epoch 2959 - Train Loss: 0.209325, Train Acc: 0.607692 | Val Loss: 0.218856, Val Acc: 0.556701\n",
      "Epoch 2960 - Train Loss: 0.209305, Train Acc: 0.607692 | Val Loss: 0.218837, Val Acc: 0.556701\n",
      "Epoch 2961 - Train Loss: 0.209285, Train Acc: 0.607692 | Val Loss: 0.218818, Val Acc: 0.556701\n",
      "Epoch 2962 - Train Loss: 0.209266, Train Acc: 0.607692 | Val Loss: 0.218799, Val Acc: 0.556701\n",
      "Epoch 2963 - Train Loss: 0.209246, Train Acc: 0.607692 | Val Loss: 0.218779, Val Acc: 0.556701\n",
      "Epoch 2964 - Train Loss: 0.209226, Train Acc: 0.607692 | Val Loss: 0.218760, Val Acc: 0.556701\n",
      "Epoch 2965 - Train Loss: 0.209207, Train Acc: 0.607692 | Val Loss: 0.218741, Val Acc: 0.556701\n",
      "Epoch 2966 - Train Loss: 0.209187, Train Acc: 0.607692 | Val Loss: 0.218722, Val Acc: 0.556701\n",
      "Epoch 2967 - Train Loss: 0.209168, Train Acc: 0.607692 | Val Loss: 0.218702, Val Acc: 0.556701\n",
      "Epoch 2968 - Train Loss: 0.209148, Train Acc: 0.607692 | Val Loss: 0.218683, Val Acc: 0.556701\n",
      "Epoch 2969 - Train Loss: 0.209128, Train Acc: 0.607692 | Val Loss: 0.218664, Val Acc: 0.556701\n",
      "Epoch 2970 - Train Loss: 0.209109, Train Acc: 0.607692 | Val Loss: 0.218645, Val Acc: 0.556701\n",
      "Epoch 2971 - Train Loss: 0.209089, Train Acc: 0.607692 | Val Loss: 0.218625, Val Acc: 0.556701\n",
      "Epoch 2972 - Train Loss: 0.209070, Train Acc: 0.608974 | Val Loss: 0.218606, Val Acc: 0.556701\n",
      "Epoch 2973 - Train Loss: 0.209050, Train Acc: 0.608974 | Val Loss: 0.218587, Val Acc: 0.556701\n",
      "Epoch 2974 - Train Loss: 0.209030, Train Acc: 0.608974 | Val Loss: 0.218568, Val Acc: 0.556701\n",
      "Epoch 2975 - Train Loss: 0.209011, Train Acc: 0.608974 | Val Loss: 0.218549, Val Acc: 0.556701\n",
      "Epoch 2976 - Train Loss: 0.208991, Train Acc: 0.608974 | Val Loss: 0.218529, Val Acc: 0.556701\n",
      "Epoch 2977 - Train Loss: 0.208972, Train Acc: 0.608974 | Val Loss: 0.218510, Val Acc: 0.556701\n",
      "Epoch 2978 - Train Loss: 0.208952, Train Acc: 0.608974 | Val Loss: 0.218491, Val Acc: 0.556701\n",
      "Epoch 2979 - Train Loss: 0.208933, Train Acc: 0.608974 | Val Loss: 0.218472, Val Acc: 0.556701\n",
      "Epoch 2980 - Train Loss: 0.208913, Train Acc: 0.608974 | Val Loss: 0.218452, Val Acc: 0.556701\n",
      "Epoch 2981 - Train Loss: 0.208893, Train Acc: 0.608974 | Val Loss: 0.218433, Val Acc: 0.556701\n",
      "Epoch 2982 - Train Loss: 0.208874, Train Acc: 0.608974 | Val Loss: 0.218414, Val Acc: 0.556701\n",
      "Epoch 2983 - Train Loss: 0.208854, Train Acc: 0.608974 | Val Loss: 0.218395, Val Acc: 0.556701\n",
      "Epoch 2984 - Train Loss: 0.208835, Train Acc: 0.608974 | Val Loss: 0.218376, Val Acc: 0.556701\n",
      "Epoch 2985 - Train Loss: 0.208815, Train Acc: 0.608974 | Val Loss: 0.218356, Val Acc: 0.556701\n",
      "Epoch 2986 - Train Loss: 0.208796, Train Acc: 0.608974 | Val Loss: 0.218337, Val Acc: 0.556701\n",
      "Epoch 2987 - Train Loss: 0.208776, Train Acc: 0.608974 | Val Loss: 0.218318, Val Acc: 0.556701\n",
      "Epoch 2988 - Train Loss: 0.208757, Train Acc: 0.608974 | Val Loss: 0.218299, Val Acc: 0.556701\n",
      "Epoch 2989 - Train Loss: 0.208737, Train Acc: 0.608974 | Val Loss: 0.218279, Val Acc: 0.556701\n",
      "Epoch 2990 - Train Loss: 0.208718, Train Acc: 0.608974 | Val Loss: 0.218260, Val Acc: 0.556701\n",
      "Epoch 2991 - Train Loss: 0.208698, Train Acc: 0.608974 | Val Loss: 0.218241, Val Acc: 0.556701\n",
      "Epoch 2992 - Train Loss: 0.208679, Train Acc: 0.608974 | Val Loss: 0.218222, Val Acc: 0.556701\n",
      "Epoch 2993 - Train Loss: 0.208659, Train Acc: 0.608974 | Val Loss: 0.218203, Val Acc: 0.556701\n",
      "Epoch 2994 - Train Loss: 0.208640, Train Acc: 0.608974 | Val Loss: 0.218183, Val Acc: 0.556701\n",
      "Epoch 2995 - Train Loss: 0.208620, Train Acc: 0.608974 | Val Loss: 0.218164, Val Acc: 0.556701\n",
      "Epoch 2996 - Train Loss: 0.208601, Train Acc: 0.608974 | Val Loss: 0.218145, Val Acc: 0.556701\n",
      "Epoch 2997 - Train Loss: 0.208581, Train Acc: 0.608974 | Val Loss: 0.218126, Val Acc: 0.556701\n",
      "Epoch 2998 - Train Loss: 0.208561, Train Acc: 0.608974 | Val Loss: 0.218107, Val Acc: 0.556701\n",
      "Epoch 2999 - Train Loss: 0.208542, Train Acc: 0.608974 | Val Loss: 0.218087, Val Acc: 0.556701\n",
      "Epoch 3000 - Train Loss: 0.208522, Train Acc: 0.608974 | Val Loss: 0.218068, Val Acc: 0.556701\n",
      "Epoch 3001 - Train Loss: 0.208503, Train Acc: 0.608974 | Val Loss: 0.218049, Val Acc: 0.556701\n",
      "Epoch 3002 - Train Loss: 0.208483, Train Acc: 0.608974 | Val Loss: 0.218030, Val Acc: 0.556701\n",
      "Epoch 3003 - Train Loss: 0.208464, Train Acc: 0.608974 | Val Loss: 0.218011, Val Acc: 0.556701\n",
      "Epoch 3004 - Train Loss: 0.208445, Train Acc: 0.608974 | Val Loss: 0.217991, Val Acc: 0.556701\n",
      "Epoch 3005 - Train Loss: 0.208425, Train Acc: 0.608974 | Val Loss: 0.217972, Val Acc: 0.556701\n",
      "Epoch 3006 - Train Loss: 0.208406, Train Acc: 0.608974 | Val Loss: 0.217953, Val Acc: 0.556701\n",
      "Epoch 3007 - Train Loss: 0.208386, Train Acc: 0.608974 | Val Loss: 0.217934, Val Acc: 0.556701\n",
      "Epoch 3008 - Train Loss: 0.208367, Train Acc: 0.608974 | Val Loss: 0.217915, Val Acc: 0.556701\n",
      "Epoch 3009 - Train Loss: 0.208347, Train Acc: 0.608974 | Val Loss: 0.217896, Val Acc: 0.556701\n",
      "Epoch 3010 - Train Loss: 0.208328, Train Acc: 0.608974 | Val Loss: 0.217876, Val Acc: 0.556701\n",
      "Epoch 3011 - Train Loss: 0.208308, Train Acc: 0.608974 | Val Loss: 0.217857, Val Acc: 0.556701\n",
      "Epoch 3012 - Train Loss: 0.208289, Train Acc: 0.608974 | Val Loss: 0.217838, Val Acc: 0.556701\n",
      "Epoch 3013 - Train Loss: 0.208269, Train Acc: 0.608974 | Val Loss: 0.217819, Val Acc: 0.556701\n",
      "Epoch 3014 - Train Loss: 0.208250, Train Acc: 0.608974 | Val Loss: 0.217800, Val Acc: 0.556701\n",
      "Epoch 3015 - Train Loss: 0.208230, Train Acc: 0.608974 | Val Loss: 0.217781, Val Acc: 0.556701\n",
      "Epoch 3016 - Train Loss: 0.208211, Train Acc: 0.608974 | Val Loss: 0.217761, Val Acc: 0.556701\n",
      "Epoch 3017 - Train Loss: 0.208191, Train Acc: 0.608974 | Val Loss: 0.217742, Val Acc: 0.556701\n",
      "Epoch 3018 - Train Loss: 0.208172, Train Acc: 0.608974 | Val Loss: 0.217723, Val Acc: 0.556701\n",
      "Epoch 3019 - Train Loss: 0.208152, Train Acc: 0.608974 | Val Loss: 0.217704, Val Acc: 0.556701\n",
      "Epoch 3020 - Train Loss: 0.208133, Train Acc: 0.608974 | Val Loss: 0.217685, Val Acc: 0.556701\n",
      "Epoch 3021 - Train Loss: 0.208114, Train Acc: 0.608974 | Val Loss: 0.217666, Val Acc: 0.556701\n",
      "Epoch 3022 - Train Loss: 0.208094, Train Acc: 0.608974 | Val Loss: 0.217647, Val Acc: 0.556701\n",
      "Epoch 3023 - Train Loss: 0.208075, Train Acc: 0.608974 | Val Loss: 0.217628, Val Acc: 0.556701\n",
      "Epoch 3024 - Train Loss: 0.208055, Train Acc: 0.608974 | Val Loss: 0.217608, Val Acc: 0.556701\n",
      "Epoch 3025 - Train Loss: 0.208036, Train Acc: 0.608974 | Val Loss: 0.217589, Val Acc: 0.556701\n",
      "Epoch 3026 - Train Loss: 0.208016, Train Acc: 0.608974 | Val Loss: 0.217570, Val Acc: 0.556701\n",
      "Epoch 3027 - Train Loss: 0.207997, Train Acc: 0.608974 | Val Loss: 0.217551, Val Acc: 0.556701\n",
      "Epoch 3028 - Train Loss: 0.207978, Train Acc: 0.608974 | Val Loss: 0.217532, Val Acc: 0.556701\n",
      "Epoch 3029 - Train Loss: 0.207958, Train Acc: 0.608974 | Val Loss: 0.217513, Val Acc: 0.556701\n",
      "Epoch 3030 - Train Loss: 0.207939, Train Acc: 0.608974 | Val Loss: 0.217494, Val Acc: 0.567010\n",
      "Epoch 3031 - Train Loss: 0.207919, Train Acc: 0.608974 | Val Loss: 0.217475, Val Acc: 0.567010\n",
      "Epoch 3032 - Train Loss: 0.207900, Train Acc: 0.608974 | Val Loss: 0.217456, Val Acc: 0.567010\n",
      "Epoch 3033 - Train Loss: 0.207881, Train Acc: 0.608974 | Val Loss: 0.217437, Val Acc: 0.567010\n",
      "Epoch 3034 - Train Loss: 0.207861, Train Acc: 0.608974 | Val Loss: 0.217418, Val Acc: 0.567010\n",
      "Epoch 3035 - Train Loss: 0.207842, Train Acc: 0.608974 | Val Loss: 0.217398, Val Acc: 0.567010\n",
      "Epoch 3036 - Train Loss: 0.207822, Train Acc: 0.608974 | Val Loss: 0.217379, Val Acc: 0.567010\n",
      "Epoch 3037 - Train Loss: 0.207803, Train Acc: 0.608974 | Val Loss: 0.217360, Val Acc: 0.567010\n",
      "Epoch 3038 - Train Loss: 0.207784, Train Acc: 0.608974 | Val Loss: 0.217341, Val Acc: 0.567010\n",
      "Epoch 3039 - Train Loss: 0.207764, Train Acc: 0.608974 | Val Loss: 0.217322, Val Acc: 0.567010\n",
      "Epoch 3040 - Train Loss: 0.207745, Train Acc: 0.608974 | Val Loss: 0.217303, Val Acc: 0.567010\n",
      "Epoch 3041 - Train Loss: 0.207725, Train Acc: 0.608974 | Val Loss: 0.217284, Val Acc: 0.567010\n",
      "Epoch 3042 - Train Loss: 0.207706, Train Acc: 0.608974 | Val Loss: 0.217265, Val Acc: 0.567010\n",
      "Epoch 3043 - Train Loss: 0.207687, Train Acc: 0.608974 | Val Loss: 0.217246, Val Acc: 0.567010\n",
      "Epoch 3044 - Train Loss: 0.207667, Train Acc: 0.608974 | Val Loss: 0.217227, Val Acc: 0.567010\n",
      "Epoch 3045 - Train Loss: 0.207648, Train Acc: 0.608974 | Val Loss: 0.217208, Val Acc: 0.567010\n",
      "Epoch 3046 - Train Loss: 0.207629, Train Acc: 0.608974 | Val Loss: 0.217189, Val Acc: 0.567010\n",
      "Epoch 3047 - Train Loss: 0.207609, Train Acc: 0.608974 | Val Loss: 0.217170, Val Acc: 0.567010\n",
      "Epoch 3048 - Train Loss: 0.207590, Train Acc: 0.608974 | Val Loss: 0.217151, Val Acc: 0.567010\n",
      "Epoch 3049 - Train Loss: 0.207571, Train Acc: 0.608974 | Val Loss: 0.217132, Val Acc: 0.567010\n",
      "Epoch 3050 - Train Loss: 0.207551, Train Acc: 0.608974 | Val Loss: 0.217113, Val Acc: 0.567010\n",
      "Epoch 3051 - Train Loss: 0.207532, Train Acc: 0.608974 | Val Loss: 0.217094, Val Acc: 0.567010\n",
      "Epoch 3052 - Train Loss: 0.207513, Train Acc: 0.608974 | Val Loss: 0.217075, Val Acc: 0.567010\n",
      "Epoch 3053 - Train Loss: 0.207493, Train Acc: 0.608974 | Val Loss: 0.217056, Val Acc: 0.567010\n",
      "Epoch 3054 - Train Loss: 0.207474, Train Acc: 0.608974 | Val Loss: 0.217037, Val Acc: 0.567010\n",
      "Epoch 3055 - Train Loss: 0.207455, Train Acc: 0.608974 | Val Loss: 0.217018, Val Acc: 0.567010\n",
      "Epoch 3056 - Train Loss: 0.207435, Train Acc: 0.608974 | Val Loss: 0.216999, Val Acc: 0.567010\n",
      "Epoch 3057 - Train Loss: 0.207416, Train Acc: 0.608974 | Val Loss: 0.216980, Val Acc: 0.567010\n",
      "Epoch 3058 - Train Loss: 0.207397, Train Acc: 0.608974 | Val Loss: 0.216961, Val Acc: 0.567010\n",
      "Epoch 3059 - Train Loss: 0.207377, Train Acc: 0.608974 | Val Loss: 0.216942, Val Acc: 0.567010\n",
      "Epoch 3060 - Train Loss: 0.207358, Train Acc: 0.608974 | Val Loss: 0.216923, Val Acc: 0.567010\n",
      "Epoch 3061 - Train Loss: 0.207339, Train Acc: 0.608974 | Val Loss: 0.216904, Val Acc: 0.567010\n",
      "Epoch 3062 - Train Loss: 0.207319, Train Acc: 0.608974 | Val Loss: 0.216885, Val Acc: 0.567010\n",
      "Epoch 3063 - Train Loss: 0.207300, Train Acc: 0.608974 | Val Loss: 0.216866, Val Acc: 0.567010\n",
      "Epoch 3064 - Train Loss: 0.207281, Train Acc: 0.608974 | Val Loss: 0.216847, Val Acc: 0.567010\n",
      "Epoch 3065 - Train Loss: 0.207261, Train Acc: 0.608974 | Val Loss: 0.216828, Val Acc: 0.567010\n",
      "Epoch 3066 - Train Loss: 0.207242, Train Acc: 0.608974 | Val Loss: 0.216809, Val Acc: 0.567010\n",
      "Epoch 3067 - Train Loss: 0.207223, Train Acc: 0.608974 | Val Loss: 0.216790, Val Acc: 0.567010\n",
      "Epoch 3068 - Train Loss: 0.207203, Train Acc: 0.608974 | Val Loss: 0.216771, Val Acc: 0.567010\n",
      "Epoch 3069 - Train Loss: 0.207184, Train Acc: 0.608974 | Val Loss: 0.216752, Val Acc: 0.567010\n",
      "Epoch 3070 - Train Loss: 0.207165, Train Acc: 0.608974 | Val Loss: 0.216733, Val Acc: 0.567010\n",
      "Epoch 3071 - Train Loss: 0.207146, Train Acc: 0.608974 | Val Loss: 0.216714, Val Acc: 0.567010\n",
      "Epoch 3072 - Train Loss: 0.207126, Train Acc: 0.608974 | Val Loss: 0.216695, Val Acc: 0.567010\n",
      "Epoch 3073 - Train Loss: 0.207107, Train Acc: 0.608974 | Val Loss: 0.216676, Val Acc: 0.567010\n",
      "Epoch 3074 - Train Loss: 0.207088, Train Acc: 0.608974 | Val Loss: 0.216657, Val Acc: 0.567010\n",
      "Epoch 3075 - Train Loss: 0.207069, Train Acc: 0.608974 | Val Loss: 0.216638, Val Acc: 0.567010\n",
      "Epoch 3076 - Train Loss: 0.207049, Train Acc: 0.608974 | Val Loss: 0.216619, Val Acc: 0.567010\n",
      "Epoch 3077 - Train Loss: 0.207030, Train Acc: 0.608974 | Val Loss: 0.216601, Val Acc: 0.567010\n",
      "Epoch 3078 - Train Loss: 0.207011, Train Acc: 0.608974 | Val Loss: 0.216582, Val Acc: 0.567010\n",
      "Epoch 3079 - Train Loss: 0.206992, Train Acc: 0.608974 | Val Loss: 0.216563, Val Acc: 0.567010\n",
      "Epoch 3080 - Train Loss: 0.206972, Train Acc: 0.608974 | Val Loss: 0.216544, Val Acc: 0.567010\n",
      "Epoch 3081 - Train Loss: 0.206953, Train Acc: 0.608974 | Val Loss: 0.216525, Val Acc: 0.567010\n",
      "Epoch 3082 - Train Loss: 0.206934, Train Acc: 0.608974 | Val Loss: 0.216506, Val Acc: 0.567010\n",
      "Epoch 3083 - Train Loss: 0.206915, Train Acc: 0.608974 | Val Loss: 0.216487, Val Acc: 0.567010\n",
      "Epoch 3084 - Train Loss: 0.206895, Train Acc: 0.608974 | Val Loss: 0.216468, Val Acc: 0.567010\n",
      "Epoch 3085 - Train Loss: 0.206876, Train Acc: 0.608974 | Val Loss: 0.216449, Val Acc: 0.567010\n",
      "Epoch 3086 - Train Loss: 0.206857, Train Acc: 0.608974 | Val Loss: 0.216430, Val Acc: 0.567010\n",
      "Epoch 3087 - Train Loss: 0.206838, Train Acc: 0.608974 | Val Loss: 0.216412, Val Acc: 0.567010\n",
      "Epoch 3088 - Train Loss: 0.206819, Train Acc: 0.608974 | Val Loss: 0.216393, Val Acc: 0.567010\n",
      "Epoch 3089 - Train Loss: 0.206799, Train Acc: 0.608974 | Val Loss: 0.216374, Val Acc: 0.567010\n",
      "Epoch 3090 - Train Loss: 0.206780, Train Acc: 0.608974 | Val Loss: 0.216355, Val Acc: 0.567010\n",
      "Epoch 3091 - Train Loss: 0.206761, Train Acc: 0.608974 | Val Loss: 0.216336, Val Acc: 0.567010\n",
      "Epoch 3092 - Train Loss: 0.206742, Train Acc: 0.608974 | Val Loss: 0.216317, Val Acc: 0.567010\n",
      "Epoch 3093 - Train Loss: 0.206723, Train Acc: 0.608974 | Val Loss: 0.216298, Val Acc: 0.567010\n",
      "Epoch 3094 - Train Loss: 0.206703, Train Acc: 0.610256 | Val Loss: 0.216280, Val Acc: 0.567010\n",
      "Epoch 3095 - Train Loss: 0.206684, Train Acc: 0.610256 | Val Loss: 0.216261, Val Acc: 0.567010\n",
      "Epoch 3096 - Train Loss: 0.206665, Train Acc: 0.610256 | Val Loss: 0.216242, Val Acc: 0.567010\n",
      "Epoch 3097 - Train Loss: 0.206646, Train Acc: 0.610256 | Val Loss: 0.216223, Val Acc: 0.567010\n",
      "Epoch 3098 - Train Loss: 0.206627, Train Acc: 0.610256 | Val Loss: 0.216205, Val Acc: 0.567010\n",
      "Epoch 3099 - Train Loss: 0.206608, Train Acc: 0.610256 | Val Loss: 0.216186, Val Acc: 0.567010\n",
      "Epoch 3100 - Train Loss: 0.206589, Train Acc: 0.610256 | Val Loss: 0.216167, Val Acc: 0.567010\n",
      "Epoch 3101 - Train Loss: 0.206569, Train Acc: 0.610256 | Val Loss: 0.216148, Val Acc: 0.567010\n",
      "Epoch 3102 - Train Loss: 0.206550, Train Acc: 0.610256 | Val Loss: 0.216130, Val Acc: 0.567010\n",
      "Epoch 3103 - Train Loss: 0.206531, Train Acc: 0.610256 | Val Loss: 0.216111, Val Acc: 0.567010\n",
      "Epoch 3104 - Train Loss: 0.206512, Train Acc: 0.610256 | Val Loss: 0.216092, Val Acc: 0.567010\n",
      "Epoch 3105 - Train Loss: 0.206493, Train Acc: 0.610256 | Val Loss: 0.216073, Val Acc: 0.567010\n",
      "Epoch 3106 - Train Loss: 0.206474, Train Acc: 0.610256 | Val Loss: 0.216055, Val Acc: 0.567010\n",
      "Epoch 3107 - Train Loss: 0.206455, Train Acc: 0.610256 | Val Loss: 0.216036, Val Acc: 0.567010\n",
      "Epoch 3108 - Train Loss: 0.206436, Train Acc: 0.610256 | Val Loss: 0.216017, Val Acc: 0.567010\n",
      "Epoch 3109 - Train Loss: 0.206416, Train Acc: 0.610256 | Val Loss: 0.215998, Val Acc: 0.567010\n",
      "Epoch 3110 - Train Loss: 0.206397, Train Acc: 0.610256 | Val Loss: 0.215980, Val Acc: 0.567010\n",
      "Epoch 3111 - Train Loss: 0.206378, Train Acc: 0.610256 | Val Loss: 0.215961, Val Acc: 0.567010\n",
      "Epoch 3112 - Train Loss: 0.206359, Train Acc: 0.610256 | Val Loss: 0.215942, Val Acc: 0.567010\n",
      "Epoch 3113 - Train Loss: 0.206340, Train Acc: 0.610256 | Val Loss: 0.215923, Val Acc: 0.567010\n",
      "Epoch 3114 - Train Loss: 0.206321, Train Acc: 0.610256 | Val Loss: 0.215905, Val Acc: 0.567010\n",
      "Epoch 3115 - Train Loss: 0.206302, Train Acc: 0.610256 | Val Loss: 0.215886, Val Acc: 0.567010\n",
      "Epoch 3116 - Train Loss: 0.206283, Train Acc: 0.610256 | Val Loss: 0.215867, Val Acc: 0.567010\n",
      "Epoch 3117 - Train Loss: 0.206264, Train Acc: 0.610256 | Val Loss: 0.215849, Val Acc: 0.567010\n",
      "Epoch 3118 - Train Loss: 0.206245, Train Acc: 0.610256 | Val Loss: 0.215830, Val Acc: 0.567010\n",
      "Epoch 3119 - Train Loss: 0.206226, Train Acc: 0.608974 | Val Loss: 0.215811, Val Acc: 0.567010\n",
      "Epoch 3120 - Train Loss: 0.206206, Train Acc: 0.608974 | Val Loss: 0.215792, Val Acc: 0.567010\n",
      "Epoch 3121 - Train Loss: 0.206187, Train Acc: 0.608974 | Val Loss: 0.215774, Val Acc: 0.567010\n",
      "Epoch 3122 - Train Loss: 0.206168, Train Acc: 0.608974 | Val Loss: 0.215755, Val Acc: 0.567010\n",
      "Epoch 3123 - Train Loss: 0.206149, Train Acc: 0.608974 | Val Loss: 0.215736, Val Acc: 0.567010\n",
      "Epoch 3124 - Train Loss: 0.206130, Train Acc: 0.608974 | Val Loss: 0.215718, Val Acc: 0.567010\n",
      "Epoch 3125 - Train Loss: 0.206111, Train Acc: 0.608974 | Val Loss: 0.215699, Val Acc: 0.567010\n",
      "Epoch 3126 - Train Loss: 0.206092, Train Acc: 0.608974 | Val Loss: 0.215680, Val Acc: 0.567010\n",
      "Epoch 3127 - Train Loss: 0.206073, Train Acc: 0.608974 | Val Loss: 0.215661, Val Acc: 0.567010\n",
      "Epoch 3128 - Train Loss: 0.206054, Train Acc: 0.608974 | Val Loss: 0.215643, Val Acc: 0.567010\n",
      "Epoch 3129 - Train Loss: 0.206035, Train Acc: 0.608974 | Val Loss: 0.215624, Val Acc: 0.567010\n",
      "Epoch 3130 - Train Loss: 0.206016, Train Acc: 0.608974 | Val Loss: 0.215605, Val Acc: 0.567010\n",
      "Epoch 3131 - Train Loss: 0.205997, Train Acc: 0.608974 | Val Loss: 0.215587, Val Acc: 0.567010\n",
      "Epoch 3132 - Train Loss: 0.205978, Train Acc: 0.608974 | Val Loss: 0.215568, Val Acc: 0.567010\n",
      "Epoch 3133 - Train Loss: 0.205959, Train Acc: 0.608974 | Val Loss: 0.215549, Val Acc: 0.567010\n",
      "Epoch 3134 - Train Loss: 0.205940, Train Acc: 0.608974 | Val Loss: 0.215531, Val Acc: 0.567010\n",
      "Epoch 3135 - Train Loss: 0.205921, Train Acc: 0.608974 | Val Loss: 0.215512, Val Acc: 0.567010\n",
      "Epoch 3136 - Train Loss: 0.205902, Train Acc: 0.608974 | Val Loss: 0.215493, Val Acc: 0.567010\n",
      "Epoch 3137 - Train Loss: 0.205883, Train Acc: 0.608974 | Val Loss: 0.215475, Val Acc: 0.567010\n",
      "Epoch 3138 - Train Loss: 0.205864, Train Acc: 0.608974 | Val Loss: 0.215456, Val Acc: 0.567010\n",
      "Epoch 3139 - Train Loss: 0.205845, Train Acc: 0.608974 | Val Loss: 0.215437, Val Acc: 0.567010\n",
      "Epoch 3140 - Train Loss: 0.205826, Train Acc: 0.608974 | Val Loss: 0.215419, Val Acc: 0.567010\n",
      "Epoch 3141 - Train Loss: 0.205807, Train Acc: 0.608974 | Val Loss: 0.215400, Val Acc: 0.567010\n",
      "Epoch 3142 - Train Loss: 0.205788, Train Acc: 0.608974 | Val Loss: 0.215382, Val Acc: 0.567010\n",
      "Epoch 3143 - Train Loss: 0.205769, Train Acc: 0.608974 | Val Loss: 0.215363, Val Acc: 0.567010\n",
      "Epoch 3144 - Train Loss: 0.205750, Train Acc: 0.608974 | Val Loss: 0.215344, Val Acc: 0.567010\n",
      "Epoch 3145 - Train Loss: 0.205731, Train Acc: 0.608974 | Val Loss: 0.215326, Val Acc: 0.567010\n",
      "Epoch 3146 - Train Loss: 0.205712, Train Acc: 0.608974 | Val Loss: 0.215307, Val Acc: 0.567010\n",
      "Epoch 3147 - Train Loss: 0.205693, Train Acc: 0.608974 | Val Loss: 0.215288, Val Acc: 0.567010\n",
      "Epoch 3148 - Train Loss: 0.205674, Train Acc: 0.608974 | Val Loss: 0.215270, Val Acc: 0.567010\n",
      "Epoch 3149 - Train Loss: 0.205655, Train Acc: 0.608974 | Val Loss: 0.215251, Val Acc: 0.567010\n",
      "Epoch 3150 - Train Loss: 0.205636, Train Acc: 0.608974 | Val Loss: 0.215233, Val Acc: 0.567010\n",
      "Epoch 3151 - Train Loss: 0.205617, Train Acc: 0.608974 | Val Loss: 0.215214, Val Acc: 0.567010\n",
      "Epoch 3152 - Train Loss: 0.205598, Train Acc: 0.608974 | Val Loss: 0.215195, Val Acc: 0.567010\n",
      "Epoch 3153 - Train Loss: 0.205579, Train Acc: 0.608974 | Val Loss: 0.215177, Val Acc: 0.567010\n",
      "Epoch 3154 - Train Loss: 0.205560, Train Acc: 0.608974 | Val Loss: 0.215158, Val Acc: 0.567010\n",
      "Epoch 3155 - Train Loss: 0.205541, Train Acc: 0.608974 | Val Loss: 0.215139, Val Acc: 0.567010\n",
      "Epoch 3156 - Train Loss: 0.205522, Train Acc: 0.608974 | Val Loss: 0.215121, Val Acc: 0.567010\n",
      "Epoch 3157 - Train Loss: 0.205503, Train Acc: 0.608974 | Val Loss: 0.215102, Val Acc: 0.567010\n",
      "Epoch 3158 - Train Loss: 0.205484, Train Acc: 0.608974 | Val Loss: 0.215084, Val Acc: 0.567010\n",
      "Epoch 3159 - Train Loss: 0.205465, Train Acc: 0.608974 | Val Loss: 0.215065, Val Acc: 0.567010\n",
      "Epoch 3160 - Train Loss: 0.205446, Train Acc: 0.608974 | Val Loss: 0.215046, Val Acc: 0.567010\n",
      "Epoch 3161 - Train Loss: 0.205427, Train Acc: 0.608974 | Val Loss: 0.215028, Val Acc: 0.567010\n",
      "Epoch 3162 - Train Loss: 0.205408, Train Acc: 0.608974 | Val Loss: 0.215009, Val Acc: 0.567010\n",
      "Epoch 3163 - Train Loss: 0.205389, Train Acc: 0.608974 | Val Loss: 0.214991, Val Acc: 0.567010\n",
      "Epoch 3164 - Train Loss: 0.205370, Train Acc: 0.608974 | Val Loss: 0.214972, Val Acc: 0.567010\n",
      "Epoch 3165 - Train Loss: 0.205351, Train Acc: 0.608974 | Val Loss: 0.214954, Val Acc: 0.567010\n",
      "Epoch 3166 - Train Loss: 0.205333, Train Acc: 0.608974 | Val Loss: 0.214935, Val Acc: 0.567010\n",
      "Epoch 3167 - Train Loss: 0.205314, Train Acc: 0.608974 | Val Loss: 0.214916, Val Acc: 0.567010\n",
      "Epoch 3168 - Train Loss: 0.205295, Train Acc: 0.608974 | Val Loss: 0.214898, Val Acc: 0.567010\n",
      "Epoch 3169 - Train Loss: 0.205276, Train Acc: 0.608974 | Val Loss: 0.214879, Val Acc: 0.567010\n",
      "Epoch 3170 - Train Loss: 0.205257, Train Acc: 0.608974 | Val Loss: 0.214861, Val Acc: 0.567010\n",
      "Epoch 3171 - Train Loss: 0.205238, Train Acc: 0.608974 | Val Loss: 0.214842, Val Acc: 0.567010\n",
      "Epoch 3172 - Train Loss: 0.205219, Train Acc: 0.608974 | Val Loss: 0.214824, Val Acc: 0.567010\n",
      "Epoch 3173 - Train Loss: 0.205200, Train Acc: 0.608974 | Val Loss: 0.214805, Val Acc: 0.567010\n",
      "Epoch 3174 - Train Loss: 0.205181, Train Acc: 0.608974 | Val Loss: 0.214786, Val Acc: 0.567010\n",
      "Epoch 3175 - Train Loss: 0.205162, Train Acc: 0.608974 | Val Loss: 0.214768, Val Acc: 0.567010\n",
      "Epoch 3176 - Train Loss: 0.205143, Train Acc: 0.608974 | Val Loss: 0.214749, Val Acc: 0.567010\n",
      "Epoch 3177 - Train Loss: 0.205125, Train Acc: 0.608974 | Val Loss: 0.214731, Val Acc: 0.567010\n",
      "Epoch 3178 - Train Loss: 0.205106, Train Acc: 0.608974 | Val Loss: 0.214712, Val Acc: 0.567010\n",
      "Epoch 3179 - Train Loss: 0.205087, Train Acc: 0.608974 | Val Loss: 0.214694, Val Acc: 0.567010\n",
      "Epoch 3180 - Train Loss: 0.205068, Train Acc: 0.610256 | Val Loss: 0.214675, Val Acc: 0.567010\n",
      "Epoch 3181 - Train Loss: 0.205049, Train Acc: 0.610256 | Val Loss: 0.214657, Val Acc: 0.567010\n",
      "Epoch 3182 - Train Loss: 0.205030, Train Acc: 0.610256 | Val Loss: 0.214638, Val Acc: 0.567010\n",
      "Epoch 3183 - Train Loss: 0.205011, Train Acc: 0.610256 | Val Loss: 0.214620, Val Acc: 0.567010\n",
      "Epoch 3184 - Train Loss: 0.204992, Train Acc: 0.610256 | Val Loss: 0.214601, Val Acc: 0.567010\n",
      "Epoch 3185 - Train Loss: 0.204974, Train Acc: 0.610256 | Val Loss: 0.214583, Val Acc: 0.567010\n",
      "Epoch 3186 - Train Loss: 0.204955, Train Acc: 0.610256 | Val Loss: 0.214564, Val Acc: 0.567010\n",
      "Epoch 3187 - Train Loss: 0.204936, Train Acc: 0.610256 | Val Loss: 0.214546, Val Acc: 0.567010\n",
      "Epoch 3188 - Train Loss: 0.204917, Train Acc: 0.610256 | Val Loss: 0.214527, Val Acc: 0.567010\n",
      "Epoch 3189 - Train Loss: 0.204898, Train Acc: 0.610256 | Val Loss: 0.214508, Val Acc: 0.567010\n",
      "Epoch 3190 - Train Loss: 0.204879, Train Acc: 0.610256 | Val Loss: 0.214490, Val Acc: 0.567010\n",
      "Epoch 3191 - Train Loss: 0.204860, Train Acc: 0.610256 | Val Loss: 0.214471, Val Acc: 0.567010\n",
      "Epoch 3192 - Train Loss: 0.204842, Train Acc: 0.610256 | Val Loss: 0.214453, Val Acc: 0.567010\n",
      "Epoch 3193 - Train Loss: 0.204823, Train Acc: 0.610256 | Val Loss: 0.214434, Val Acc: 0.567010\n",
      "Epoch 3194 - Train Loss: 0.204804, Train Acc: 0.610256 | Val Loss: 0.214416, Val Acc: 0.567010\n",
      "Epoch 3195 - Train Loss: 0.204785, Train Acc: 0.610256 | Val Loss: 0.214397, Val Acc: 0.567010\n",
      "Epoch 3196 - Train Loss: 0.204766, Train Acc: 0.610256 | Val Loss: 0.214379, Val Acc: 0.567010\n",
      "Epoch 3197 - Train Loss: 0.204747, Train Acc: 0.610256 | Val Loss: 0.214360, Val Acc: 0.567010\n",
      "Epoch 3198 - Train Loss: 0.204729, Train Acc: 0.610256 | Val Loss: 0.214342, Val Acc: 0.567010\n",
      "Epoch 3199 - Train Loss: 0.204710, Train Acc: 0.610256 | Val Loss: 0.214323, Val Acc: 0.567010\n",
      "Epoch 3200 - Train Loss: 0.204691, Train Acc: 0.610256 | Val Loss: 0.214305, Val Acc: 0.567010\n",
      "Epoch 3201 - Train Loss: 0.204672, Train Acc: 0.611538 | Val Loss: 0.214286, Val Acc: 0.567010\n",
      "Epoch 3202 - Train Loss: 0.204653, Train Acc: 0.611538 | Val Loss: 0.214268, Val Acc: 0.567010\n",
      "Epoch 3203 - Train Loss: 0.204634, Train Acc: 0.611538 | Val Loss: 0.214249, Val Acc: 0.567010\n",
      "Epoch 3204 - Train Loss: 0.204616, Train Acc: 0.611538 | Val Loss: 0.214231, Val Acc: 0.567010\n",
      "Epoch 3205 - Train Loss: 0.204597, Train Acc: 0.611538 | Val Loss: 0.214212, Val Acc: 0.567010\n",
      "Epoch 3206 - Train Loss: 0.204578, Train Acc: 0.611538 | Val Loss: 0.214194, Val Acc: 0.567010\n",
      "Epoch 3207 - Train Loss: 0.204559, Train Acc: 0.611538 | Val Loss: 0.214175, Val Acc: 0.567010\n",
      "Epoch 3208 - Train Loss: 0.204540, Train Acc: 0.611538 | Val Loss: 0.214157, Val Acc: 0.567010\n",
      "Epoch 3209 - Train Loss: 0.204522, Train Acc: 0.611538 | Val Loss: 0.214138, Val Acc: 0.567010\n",
      "Epoch 3210 - Train Loss: 0.204503, Train Acc: 0.611538 | Val Loss: 0.214120, Val Acc: 0.567010\n",
      "Epoch 3211 - Train Loss: 0.204484, Train Acc: 0.611538 | Val Loss: 0.214102, Val Acc: 0.567010\n",
      "Epoch 3212 - Train Loss: 0.204465, Train Acc: 0.611538 | Val Loss: 0.214083, Val Acc: 0.567010\n",
      "Epoch 3213 - Train Loss: 0.204446, Train Acc: 0.611538 | Val Loss: 0.214065, Val Acc: 0.567010\n",
      "Epoch 3214 - Train Loss: 0.204428, Train Acc: 0.611538 | Val Loss: 0.214046, Val Acc: 0.567010\n",
      "Epoch 3215 - Train Loss: 0.204409, Train Acc: 0.611538 | Val Loss: 0.214028, Val Acc: 0.567010\n",
      "Epoch 3216 - Train Loss: 0.204390, Train Acc: 0.611538 | Val Loss: 0.214009, Val Acc: 0.567010\n",
      "Epoch 3217 - Train Loss: 0.204371, Train Acc: 0.611538 | Val Loss: 0.213991, Val Acc: 0.567010\n",
      "Epoch 3218 - Train Loss: 0.204352, Train Acc: 0.611538 | Val Loss: 0.213972, Val Acc: 0.567010\n",
      "Epoch 3219 - Train Loss: 0.204334, Train Acc: 0.611538 | Val Loss: 0.213954, Val Acc: 0.567010\n",
      "Epoch 3220 - Train Loss: 0.204315, Train Acc: 0.611538 | Val Loss: 0.213936, Val Acc: 0.567010\n",
      "Epoch 3221 - Train Loss: 0.204296, Train Acc: 0.611538 | Val Loss: 0.213917, Val Acc: 0.567010\n",
      "Epoch 3222 - Train Loss: 0.204277, Train Acc: 0.611538 | Val Loss: 0.213899, Val Acc: 0.567010\n",
      "Epoch 3223 - Train Loss: 0.204259, Train Acc: 0.611538 | Val Loss: 0.213880, Val Acc: 0.567010\n",
      "Epoch 3224 - Train Loss: 0.204240, Train Acc: 0.611538 | Val Loss: 0.213862, Val Acc: 0.567010\n",
      "Epoch 3225 - Train Loss: 0.204221, Train Acc: 0.612821 | Val Loss: 0.213843, Val Acc: 0.567010\n",
      "Epoch 3226 - Train Loss: 0.204202, Train Acc: 0.612821 | Val Loss: 0.213825, Val Acc: 0.567010\n",
      "Epoch 3227 - Train Loss: 0.204184, Train Acc: 0.612821 | Val Loss: 0.213807, Val Acc: 0.567010\n",
      "Epoch 3228 - Train Loss: 0.204165, Train Acc: 0.612821 | Val Loss: 0.213788, Val Acc: 0.567010\n",
      "Epoch 3229 - Train Loss: 0.204146, Train Acc: 0.612821 | Val Loss: 0.213770, Val Acc: 0.567010\n",
      "Epoch 3230 - Train Loss: 0.204127, Train Acc: 0.612821 | Val Loss: 0.213751, Val Acc: 0.567010\n",
      "Epoch 3231 - Train Loss: 0.204109, Train Acc: 0.612821 | Val Loss: 0.213733, Val Acc: 0.567010\n",
      "Epoch 3232 - Train Loss: 0.204090, Train Acc: 0.612821 | Val Loss: 0.213715, Val Acc: 0.567010\n",
      "Epoch 3233 - Train Loss: 0.204071, Train Acc: 0.612821 | Val Loss: 0.213696, Val Acc: 0.567010\n",
      "Epoch 3234 - Train Loss: 0.204052, Train Acc: 0.612821 | Val Loss: 0.213678, Val Acc: 0.567010\n",
      "Epoch 3235 - Train Loss: 0.204034, Train Acc: 0.612821 | Val Loss: 0.213660, Val Acc: 0.567010\n",
      "Epoch 3236 - Train Loss: 0.204015, Train Acc: 0.612821 | Val Loss: 0.213641, Val Acc: 0.567010\n",
      "Epoch 3237 - Train Loss: 0.203996, Train Acc: 0.612821 | Val Loss: 0.213623, Val Acc: 0.567010\n",
      "Epoch 3238 - Train Loss: 0.203978, Train Acc: 0.612821 | Val Loss: 0.213604, Val Acc: 0.567010\n",
      "Epoch 3239 - Train Loss: 0.203959, Train Acc: 0.612821 | Val Loss: 0.213586, Val Acc: 0.567010\n",
      "Epoch 3240 - Train Loss: 0.203940, Train Acc: 0.612821 | Val Loss: 0.213568, Val Acc: 0.567010\n",
      "Epoch 3241 - Train Loss: 0.203921, Train Acc: 0.612821 | Val Loss: 0.213549, Val Acc: 0.567010\n",
      "Epoch 3242 - Train Loss: 0.203903, Train Acc: 0.612821 | Val Loss: 0.213531, Val Acc: 0.567010\n",
      "Epoch 3243 - Train Loss: 0.203884, Train Acc: 0.612821 | Val Loss: 0.213513, Val Acc: 0.567010\n",
      "Epoch 3244 - Train Loss: 0.203865, Train Acc: 0.612821 | Val Loss: 0.213494, Val Acc: 0.567010\n",
      "Epoch 3245 - Train Loss: 0.203847, Train Acc: 0.612821 | Val Loss: 0.213476, Val Acc: 0.567010\n",
      "Epoch 3246 - Train Loss: 0.203828, Train Acc: 0.612821 | Val Loss: 0.213458, Val Acc: 0.567010\n",
      "Epoch 3247 - Train Loss: 0.203809, Train Acc: 0.612821 | Val Loss: 0.213439, Val Acc: 0.567010\n",
      "Epoch 3248 - Train Loss: 0.203791, Train Acc: 0.612821 | Val Loss: 0.213421, Val Acc: 0.567010\n",
      "Epoch 3249 - Train Loss: 0.203772, Train Acc: 0.612821 | Val Loss: 0.213403, Val Acc: 0.567010\n",
      "Epoch 3250 - Train Loss: 0.203753, Train Acc: 0.612821 | Val Loss: 0.213384, Val Acc: 0.567010\n",
      "Epoch 3251 - Train Loss: 0.203735, Train Acc: 0.612821 | Val Loss: 0.213366, Val Acc: 0.567010\n",
      "Epoch 3252 - Train Loss: 0.203716, Train Acc: 0.612821 | Val Loss: 0.213348, Val Acc: 0.567010\n",
      "Epoch 3253 - Train Loss: 0.203697, Train Acc: 0.612821 | Val Loss: 0.213329, Val Acc: 0.567010\n",
      "Epoch 3254 - Train Loss: 0.203679, Train Acc: 0.612821 | Val Loss: 0.213311, Val Acc: 0.567010\n",
      "Epoch 3255 - Train Loss: 0.203660, Train Acc: 0.612821 | Val Loss: 0.213293, Val Acc: 0.567010\n",
      "Epoch 3256 - Train Loss: 0.203641, Train Acc: 0.612821 | Val Loss: 0.213275, Val Acc: 0.567010\n",
      "Epoch 3257 - Train Loss: 0.203623, Train Acc: 0.612821 | Val Loss: 0.213256, Val Acc: 0.567010\n",
      "Epoch 3258 - Train Loss: 0.203604, Train Acc: 0.612821 | Val Loss: 0.213238, Val Acc: 0.567010\n",
      "Epoch 3259 - Train Loss: 0.203585, Train Acc: 0.612821 | Val Loss: 0.213220, Val Acc: 0.567010\n",
      "Epoch 3260 - Train Loss: 0.203567, Train Acc: 0.612821 | Val Loss: 0.213201, Val Acc: 0.567010\n",
      "Epoch 3261 - Train Loss: 0.203548, Train Acc: 0.612821 | Val Loss: 0.213183, Val Acc: 0.567010\n",
      "Epoch 3262 - Train Loss: 0.203529, Train Acc: 0.612821 | Val Loss: 0.213165, Val Acc: 0.567010\n",
      "Epoch 3263 - Train Loss: 0.203511, Train Acc: 0.612821 | Val Loss: 0.213147, Val Acc: 0.567010\n",
      "Epoch 3264 - Train Loss: 0.203492, Train Acc: 0.612821 | Val Loss: 0.213128, Val Acc: 0.567010\n",
      "Epoch 3265 - Train Loss: 0.203473, Train Acc: 0.612821 | Val Loss: 0.213110, Val Acc: 0.567010\n",
      "Epoch 3266 - Train Loss: 0.203455, Train Acc: 0.612821 | Val Loss: 0.213092, Val Acc: 0.567010\n",
      "Epoch 3267 - Train Loss: 0.203436, Train Acc: 0.612821 | Val Loss: 0.213074, Val Acc: 0.567010\n",
      "Epoch 3268 - Train Loss: 0.203418, Train Acc: 0.612821 | Val Loss: 0.213055, Val Acc: 0.567010\n",
      "Epoch 3269 - Train Loss: 0.203399, Train Acc: 0.612821 | Val Loss: 0.213037, Val Acc: 0.567010\n",
      "Epoch 3270 - Train Loss: 0.203380, Train Acc: 0.612821 | Val Loss: 0.213019, Val Acc: 0.567010\n",
      "Epoch 3271 - Train Loss: 0.203362, Train Acc: 0.612821 | Val Loss: 0.213001, Val Acc: 0.567010\n",
      "Epoch 3272 - Train Loss: 0.203343, Train Acc: 0.612821 | Val Loss: 0.212982, Val Acc: 0.567010\n",
      "Epoch 3273 - Train Loss: 0.203325, Train Acc: 0.612821 | Val Loss: 0.212964, Val Acc: 0.567010\n",
      "Epoch 3274 - Train Loss: 0.203306, Train Acc: 0.612821 | Val Loss: 0.212946, Val Acc: 0.567010\n",
      "Epoch 3275 - Train Loss: 0.203287, Train Acc: 0.612821 | Val Loss: 0.212928, Val Acc: 0.567010\n",
      "Epoch 3276 - Train Loss: 0.203269, Train Acc: 0.612821 | Val Loss: 0.212909, Val Acc: 0.567010\n",
      "Epoch 3277 - Train Loss: 0.203250, Train Acc: 0.612821 | Val Loss: 0.212891, Val Acc: 0.567010\n",
      "Epoch 3278 - Train Loss: 0.203232, Train Acc: 0.612821 | Val Loss: 0.212873, Val Acc: 0.567010\n",
      "Epoch 3279 - Train Loss: 0.203213, Train Acc: 0.612821 | Val Loss: 0.212855, Val Acc: 0.567010\n",
      "Epoch 3280 - Train Loss: 0.203194, Train Acc: 0.612821 | Val Loss: 0.212837, Val Acc: 0.567010\n",
      "Epoch 3281 - Train Loss: 0.203176, Train Acc: 0.612821 | Val Loss: 0.212819, Val Acc: 0.567010\n",
      "Epoch 3282 - Train Loss: 0.203157, Train Acc: 0.614103 | Val Loss: 0.212800, Val Acc: 0.567010\n",
      "Epoch 3283 - Train Loss: 0.203139, Train Acc: 0.614103 | Val Loss: 0.212782, Val Acc: 0.567010\n",
      "Epoch 3284 - Train Loss: 0.203120, Train Acc: 0.614103 | Val Loss: 0.212764, Val Acc: 0.567010\n",
      "Epoch 3285 - Train Loss: 0.203101, Train Acc: 0.614103 | Val Loss: 0.212746, Val Acc: 0.567010\n",
      "Epoch 3286 - Train Loss: 0.203083, Train Acc: 0.614103 | Val Loss: 0.212728, Val Acc: 0.567010\n",
      "Epoch 3287 - Train Loss: 0.203064, Train Acc: 0.614103 | Val Loss: 0.212709, Val Acc: 0.567010\n",
      "Epoch 3288 - Train Loss: 0.203046, Train Acc: 0.615385 | Val Loss: 0.212691, Val Acc: 0.567010\n",
      "Epoch 3289 - Train Loss: 0.203027, Train Acc: 0.615385 | Val Loss: 0.212673, Val Acc: 0.567010\n",
      "Epoch 3290 - Train Loss: 0.203009, Train Acc: 0.615385 | Val Loss: 0.212655, Val Acc: 0.567010\n",
      "Epoch 3291 - Train Loss: 0.202990, Train Acc: 0.615385 | Val Loss: 0.212637, Val Acc: 0.567010\n",
      "Epoch 3292 - Train Loss: 0.202972, Train Acc: 0.615385 | Val Loss: 0.212619, Val Acc: 0.567010\n",
      "Epoch 3293 - Train Loss: 0.202953, Train Acc: 0.615385 | Val Loss: 0.212601, Val Acc: 0.567010\n",
      "Epoch 3294 - Train Loss: 0.202934, Train Acc: 0.615385 | Val Loss: 0.212582, Val Acc: 0.567010\n",
      "Epoch 3295 - Train Loss: 0.202916, Train Acc: 0.615385 | Val Loss: 0.212564, Val Acc: 0.567010\n",
      "Epoch 3296 - Train Loss: 0.202897, Train Acc: 0.615385 | Val Loss: 0.212546, Val Acc: 0.567010\n",
      "Epoch 3297 - Train Loss: 0.202879, Train Acc: 0.615385 | Val Loss: 0.212528, Val Acc: 0.567010\n",
      "Epoch 3298 - Train Loss: 0.202860, Train Acc: 0.615385 | Val Loss: 0.212510, Val Acc: 0.567010\n",
      "Epoch 3299 - Train Loss: 0.202842, Train Acc: 0.615385 | Val Loss: 0.212492, Val Acc: 0.567010\n",
      "Epoch 3300 - Train Loss: 0.202823, Train Acc: 0.615385 | Val Loss: 0.212474, Val Acc: 0.567010\n",
      "Epoch 3301 - Train Loss: 0.202805, Train Acc: 0.615385 | Val Loss: 0.212456, Val Acc: 0.567010\n",
      "Epoch 3302 - Train Loss: 0.202786, Train Acc: 0.615385 | Val Loss: 0.212437, Val Acc: 0.567010\n",
      "Epoch 3303 - Train Loss: 0.202768, Train Acc: 0.615385 | Val Loss: 0.212419, Val Acc: 0.567010\n",
      "Epoch 3304 - Train Loss: 0.202749, Train Acc: 0.615385 | Val Loss: 0.212401, Val Acc: 0.567010\n",
      "Epoch 3305 - Train Loss: 0.202731, Train Acc: 0.615385 | Val Loss: 0.212383, Val Acc: 0.567010\n",
      "Epoch 3306 - Train Loss: 0.202712, Train Acc: 0.615385 | Val Loss: 0.212365, Val Acc: 0.567010\n",
      "Epoch 3307 - Train Loss: 0.202694, Train Acc: 0.615385 | Val Loss: 0.212347, Val Acc: 0.567010\n",
      "Epoch 3308 - Train Loss: 0.202675, Train Acc: 0.615385 | Val Loss: 0.212329, Val Acc: 0.567010\n",
      "Epoch 3309 - Train Loss: 0.202657, Train Acc: 0.615385 | Val Loss: 0.212311, Val Acc: 0.567010\n",
      "Epoch 3310 - Train Loss: 0.202638, Train Acc: 0.615385 | Val Loss: 0.212293, Val Acc: 0.567010\n",
      "Epoch 3311 - Train Loss: 0.202620, Train Acc: 0.615385 | Val Loss: 0.212274, Val Acc: 0.567010\n",
      "Epoch 3312 - Train Loss: 0.202601, Train Acc: 0.615385 | Val Loss: 0.212256, Val Acc: 0.567010\n",
      "Epoch 3313 - Train Loss: 0.202583, Train Acc: 0.615385 | Val Loss: 0.212238, Val Acc: 0.567010\n",
      "Epoch 3314 - Train Loss: 0.202564, Train Acc: 0.615385 | Val Loss: 0.212220, Val Acc: 0.567010\n",
      "Epoch 3315 - Train Loss: 0.202546, Train Acc: 0.615385 | Val Loss: 0.212202, Val Acc: 0.567010\n",
      "Epoch 3316 - Train Loss: 0.202527, Train Acc: 0.615385 | Val Loss: 0.212184, Val Acc: 0.567010\n",
      "Epoch 3317 - Train Loss: 0.202509, Train Acc: 0.615385 | Val Loss: 0.212166, Val Acc: 0.567010\n",
      "Epoch 3318 - Train Loss: 0.202490, Train Acc: 0.615385 | Val Loss: 0.212148, Val Acc: 0.567010\n",
      "Epoch 3319 - Train Loss: 0.202472, Train Acc: 0.615385 | Val Loss: 0.212130, Val Acc: 0.567010\n",
      "Epoch 3320 - Train Loss: 0.202453, Train Acc: 0.615385 | Val Loss: 0.212112, Val Acc: 0.567010\n",
      "Epoch 3321 - Train Loss: 0.202435, Train Acc: 0.615385 | Val Loss: 0.212094, Val Acc: 0.567010\n",
      "Epoch 3322 - Train Loss: 0.202417, Train Acc: 0.615385 | Val Loss: 0.212076, Val Acc: 0.567010\n",
      "Epoch 3323 - Train Loss: 0.202398, Train Acc: 0.615385 | Val Loss: 0.212058, Val Acc: 0.567010\n",
      "Epoch 3324 - Train Loss: 0.202380, Train Acc: 0.615385 | Val Loss: 0.212040, Val Acc: 0.567010\n",
      "Epoch 3325 - Train Loss: 0.202361, Train Acc: 0.615385 | Val Loss: 0.212022, Val Acc: 0.567010\n",
      "Epoch 3326 - Train Loss: 0.202343, Train Acc: 0.615385 | Val Loss: 0.212004, Val Acc: 0.567010\n",
      "Epoch 3327 - Train Loss: 0.202324, Train Acc: 0.615385 | Val Loss: 0.211986, Val Acc: 0.567010\n",
      "Epoch 3328 - Train Loss: 0.202306, Train Acc: 0.615385 | Val Loss: 0.211968, Val Acc: 0.567010\n",
      "Epoch 3329 - Train Loss: 0.202287, Train Acc: 0.615385 | Val Loss: 0.211950, Val Acc: 0.567010\n",
      "Epoch 3330 - Train Loss: 0.202269, Train Acc: 0.615385 | Val Loss: 0.211932, Val Acc: 0.567010\n",
      "Epoch 3331 - Train Loss: 0.202251, Train Acc: 0.615385 | Val Loss: 0.211914, Val Acc: 0.567010\n",
      "Epoch 3332 - Train Loss: 0.202232, Train Acc: 0.615385 | Val Loss: 0.211896, Val Acc: 0.567010\n",
      "Epoch 3333 - Train Loss: 0.202214, Train Acc: 0.615385 | Val Loss: 0.211878, Val Acc: 0.567010\n",
      "Epoch 3334 - Train Loss: 0.202195, Train Acc: 0.615385 | Val Loss: 0.211860, Val Acc: 0.567010\n",
      "Epoch 3335 - Train Loss: 0.202177, Train Acc: 0.615385 | Val Loss: 0.211842, Val Acc: 0.567010\n",
      "Epoch 3336 - Train Loss: 0.202159, Train Acc: 0.615385 | Val Loss: 0.211824, Val Acc: 0.567010\n",
      "Epoch 3337 - Train Loss: 0.202140, Train Acc: 0.615385 | Val Loss: 0.211806, Val Acc: 0.567010\n",
      "Epoch 3338 - Train Loss: 0.202122, Train Acc: 0.615385 | Val Loss: 0.211788, Val Acc: 0.567010\n",
      "Epoch 3339 - Train Loss: 0.202103, Train Acc: 0.615385 | Val Loss: 0.211770, Val Acc: 0.567010\n",
      "Epoch 3340 - Train Loss: 0.202085, Train Acc: 0.615385 | Val Loss: 0.211752, Val Acc: 0.567010\n",
      "Epoch 3341 - Train Loss: 0.202066, Train Acc: 0.615385 | Val Loss: 0.211734, Val Acc: 0.567010\n",
      "Epoch 3342 - Train Loss: 0.202048, Train Acc: 0.615385 | Val Loss: 0.211716, Val Acc: 0.567010\n",
      "Epoch 3343 - Train Loss: 0.202030, Train Acc: 0.615385 | Val Loss: 0.211698, Val Acc: 0.567010\n",
      "Epoch 3344 - Train Loss: 0.202011, Train Acc: 0.615385 | Val Loss: 0.211680, Val Acc: 0.567010\n",
      "Epoch 3345 - Train Loss: 0.201993, Train Acc: 0.615385 | Val Loss: 0.211662, Val Acc: 0.567010\n",
      "Epoch 3346 - Train Loss: 0.201975, Train Acc: 0.615385 | Val Loss: 0.211644, Val Acc: 0.567010\n",
      "Epoch 3347 - Train Loss: 0.201956, Train Acc: 0.615385 | Val Loss: 0.211626, Val Acc: 0.567010\n",
      "Epoch 3348 - Train Loss: 0.201938, Train Acc: 0.615385 | Val Loss: 0.211608, Val Acc: 0.567010\n",
      "Epoch 3349 - Train Loss: 0.201919, Train Acc: 0.615385 | Val Loss: 0.211590, Val Acc: 0.567010\n",
      "Epoch 3350 - Train Loss: 0.201901, Train Acc: 0.615385 | Val Loss: 0.211572, Val Acc: 0.567010\n",
      "Epoch 3351 - Train Loss: 0.201883, Train Acc: 0.615385 | Val Loss: 0.211554, Val Acc: 0.567010\n",
      "Epoch 3352 - Train Loss: 0.201864, Train Acc: 0.615385 | Val Loss: 0.211536, Val Acc: 0.567010\n",
      "Epoch 3353 - Train Loss: 0.201846, Train Acc: 0.615385 | Val Loss: 0.211518, Val Acc: 0.567010\n",
      "Epoch 3354 - Train Loss: 0.201828, Train Acc: 0.615385 | Val Loss: 0.211500, Val Acc: 0.567010\n",
      "Epoch 3355 - Train Loss: 0.201809, Train Acc: 0.615385 | Val Loss: 0.211482, Val Acc: 0.567010\n",
      "Epoch 3356 - Train Loss: 0.201791, Train Acc: 0.615385 | Val Loss: 0.211464, Val Acc: 0.567010\n",
      "Epoch 3357 - Train Loss: 0.201772, Train Acc: 0.615385 | Val Loss: 0.211446, Val Acc: 0.567010\n",
      "Epoch 3358 - Train Loss: 0.201754, Train Acc: 0.615385 | Val Loss: 0.211429, Val Acc: 0.567010\n",
      "Epoch 3359 - Train Loss: 0.201736, Train Acc: 0.615385 | Val Loss: 0.211411, Val Acc: 0.567010\n",
      "Epoch 3360 - Train Loss: 0.201717, Train Acc: 0.615385 | Val Loss: 0.211393, Val Acc: 0.567010\n",
      "Epoch 3361 - Train Loss: 0.201699, Train Acc: 0.615385 | Val Loss: 0.211375, Val Acc: 0.567010\n",
      "Epoch 3362 - Train Loss: 0.201681, Train Acc: 0.615385 | Val Loss: 0.211357, Val Acc: 0.567010\n",
      "Epoch 3363 - Train Loss: 0.201662, Train Acc: 0.615385 | Val Loss: 0.211339, Val Acc: 0.567010\n",
      "Epoch 3364 - Train Loss: 0.201644, Train Acc: 0.615385 | Val Loss: 0.211321, Val Acc: 0.567010\n",
      "Epoch 3365 - Train Loss: 0.201626, Train Acc: 0.615385 | Val Loss: 0.211303, Val Acc: 0.567010\n",
      "Epoch 3366 - Train Loss: 0.201607, Train Acc: 0.615385 | Val Loss: 0.211285, Val Acc: 0.567010\n",
      "Epoch 3367 - Train Loss: 0.201589, Train Acc: 0.615385 | Val Loss: 0.211267, Val Acc: 0.567010\n",
      "Epoch 3368 - Train Loss: 0.201571, Train Acc: 0.615385 | Val Loss: 0.211249, Val Acc: 0.567010\n",
      "Epoch 3369 - Train Loss: 0.201552, Train Acc: 0.615385 | Val Loss: 0.211232, Val Acc: 0.567010\n",
      "Epoch 3370 - Train Loss: 0.201534, Train Acc: 0.615385 | Val Loss: 0.211214, Val Acc: 0.567010\n",
      "Epoch 3371 - Train Loss: 0.201516, Train Acc: 0.615385 | Val Loss: 0.211196, Val Acc: 0.567010\n",
      "Epoch 3372 - Train Loss: 0.201497, Train Acc: 0.615385 | Val Loss: 0.211178, Val Acc: 0.567010\n",
      "Epoch 3373 - Train Loss: 0.201479, Train Acc: 0.615385 | Val Loss: 0.211160, Val Acc: 0.567010\n",
      "Epoch 3374 - Train Loss: 0.201461, Train Acc: 0.615385 | Val Loss: 0.211142, Val Acc: 0.567010\n",
      "Epoch 3375 - Train Loss: 0.201443, Train Acc: 0.615385 | Val Loss: 0.211124, Val Acc: 0.567010\n",
      "Epoch 3376 - Train Loss: 0.201424, Train Acc: 0.615385 | Val Loss: 0.211106, Val Acc: 0.567010\n",
      "Epoch 3377 - Train Loss: 0.201406, Train Acc: 0.615385 | Val Loss: 0.211089, Val Acc: 0.567010\n",
      "Epoch 3378 - Train Loss: 0.201388, Train Acc: 0.615385 | Val Loss: 0.211071, Val Acc: 0.567010\n",
      "Epoch 3379 - Train Loss: 0.201369, Train Acc: 0.615385 | Val Loss: 0.211053, Val Acc: 0.567010\n",
      "Epoch 3380 - Train Loss: 0.201351, Train Acc: 0.616667 | Val Loss: 0.211035, Val Acc: 0.567010\n",
      "Epoch 3381 - Train Loss: 0.201333, Train Acc: 0.616667 | Val Loss: 0.211017, Val Acc: 0.567010\n",
      "Epoch 3382 - Train Loss: 0.201314, Train Acc: 0.616667 | Val Loss: 0.210999, Val Acc: 0.567010\n",
      "Epoch 3383 - Train Loss: 0.201296, Train Acc: 0.616667 | Val Loss: 0.210981, Val Acc: 0.567010\n",
      "Epoch 3384 - Train Loss: 0.201278, Train Acc: 0.616667 | Val Loss: 0.210964, Val Acc: 0.567010\n",
      "Epoch 3385 - Train Loss: 0.201260, Train Acc: 0.616667 | Val Loss: 0.210946, Val Acc: 0.567010\n",
      "Epoch 3386 - Train Loss: 0.201241, Train Acc: 0.616667 | Val Loss: 0.210928, Val Acc: 0.567010\n",
      "Epoch 3387 - Train Loss: 0.201223, Train Acc: 0.616667 | Val Loss: 0.210910, Val Acc: 0.567010\n",
      "Epoch 3388 - Train Loss: 0.201205, Train Acc: 0.616667 | Val Loss: 0.210892, Val Acc: 0.567010\n",
      "Epoch 3389 - Train Loss: 0.201187, Train Acc: 0.616667 | Val Loss: 0.210875, Val Acc: 0.567010\n",
      "Epoch 3390 - Train Loss: 0.201168, Train Acc: 0.616667 | Val Loss: 0.210857, Val Acc: 0.567010\n",
      "Epoch 3391 - Train Loss: 0.201150, Train Acc: 0.616667 | Val Loss: 0.210839, Val Acc: 0.567010\n",
      "Epoch 3392 - Train Loss: 0.201132, Train Acc: 0.616667 | Val Loss: 0.210821, Val Acc: 0.567010\n",
      "Epoch 3393 - Train Loss: 0.201114, Train Acc: 0.616667 | Val Loss: 0.210803, Val Acc: 0.567010\n",
      "Epoch 3394 - Train Loss: 0.201095, Train Acc: 0.616667 | Val Loss: 0.210786, Val Acc: 0.567010\n",
      "Epoch 3395 - Train Loss: 0.201077, Train Acc: 0.616667 | Val Loss: 0.210768, Val Acc: 0.567010\n",
      "Epoch 3396 - Train Loss: 0.201059, Train Acc: 0.616667 | Val Loss: 0.210750, Val Acc: 0.567010\n",
      "Epoch 3397 - Train Loss: 0.201041, Train Acc: 0.616667 | Val Loss: 0.210732, Val Acc: 0.567010\n",
      "Epoch 3398 - Train Loss: 0.201022, Train Acc: 0.616667 | Val Loss: 0.210715, Val Acc: 0.567010\n",
      "Epoch 3399 - Train Loss: 0.201004, Train Acc: 0.616667 | Val Loss: 0.210697, Val Acc: 0.567010\n",
      "Epoch 3400 - Train Loss: 0.200986, Train Acc: 0.616667 | Val Loss: 0.210679, Val Acc: 0.567010\n",
      "Epoch 3401 - Train Loss: 0.200968, Train Acc: 0.616667 | Val Loss: 0.210661, Val Acc: 0.567010\n",
      "Epoch 3402 - Train Loss: 0.200949, Train Acc: 0.616667 | Val Loss: 0.210644, Val Acc: 0.567010\n",
      "Epoch 3403 - Train Loss: 0.200931, Train Acc: 0.616667 | Val Loss: 0.210626, Val Acc: 0.567010\n",
      "Epoch 3404 - Train Loss: 0.200913, Train Acc: 0.616667 | Val Loss: 0.210608, Val Acc: 0.567010\n",
      "Epoch 3405 - Train Loss: 0.200895, Train Acc: 0.616667 | Val Loss: 0.210590, Val Acc: 0.567010\n",
      "Epoch 3406 - Train Loss: 0.200877, Train Acc: 0.616667 | Val Loss: 0.210573, Val Acc: 0.567010\n",
      "Epoch 3407 - Train Loss: 0.200858, Train Acc: 0.616667 | Val Loss: 0.210555, Val Acc: 0.567010\n",
      "Epoch 3408 - Train Loss: 0.200840, Train Acc: 0.616667 | Val Loss: 0.210537, Val Acc: 0.567010\n",
      "Epoch 3409 - Train Loss: 0.200822, Train Acc: 0.616667 | Val Loss: 0.210519, Val Acc: 0.567010\n",
      "Epoch 3410 - Train Loss: 0.200804, Train Acc: 0.616667 | Val Loss: 0.210502, Val Acc: 0.567010\n",
      "Epoch 3411 - Train Loss: 0.200786, Train Acc: 0.616667 | Val Loss: 0.210484, Val Acc: 0.567010\n",
      "Epoch 3412 - Train Loss: 0.200767, Train Acc: 0.616667 | Val Loss: 0.210466, Val Acc: 0.567010\n",
      "Epoch 3413 - Train Loss: 0.200749, Train Acc: 0.616667 | Val Loss: 0.210448, Val Acc: 0.567010\n",
      "Epoch 3414 - Train Loss: 0.200731, Train Acc: 0.616667 | Val Loss: 0.210431, Val Acc: 0.567010\n",
      "Epoch 3415 - Train Loss: 0.200713, Train Acc: 0.617949 | Val Loss: 0.210413, Val Acc: 0.567010\n",
      "Epoch 3416 - Train Loss: 0.200695, Train Acc: 0.617949 | Val Loss: 0.210395, Val Acc: 0.567010\n",
      "Epoch 3417 - Train Loss: 0.200676, Train Acc: 0.617949 | Val Loss: 0.210378, Val Acc: 0.567010\n",
      "Epoch 3418 - Train Loss: 0.200658, Train Acc: 0.617949 | Val Loss: 0.210360, Val Acc: 0.567010\n",
      "Epoch 3419 - Train Loss: 0.200640, Train Acc: 0.617949 | Val Loss: 0.210342, Val Acc: 0.567010\n",
      "Epoch 3420 - Train Loss: 0.200622, Train Acc: 0.617949 | Val Loss: 0.210325, Val Acc: 0.567010\n",
      "Epoch 3421 - Train Loss: 0.200604, Train Acc: 0.617949 | Val Loss: 0.210307, Val Acc: 0.567010\n",
      "Epoch 3422 - Train Loss: 0.200585, Train Acc: 0.617949 | Val Loss: 0.210289, Val Acc: 0.567010\n",
      "Epoch 3423 - Train Loss: 0.200567, Train Acc: 0.617949 | Val Loss: 0.210271, Val Acc: 0.567010\n",
      "Epoch 3424 - Train Loss: 0.200549, Train Acc: 0.617949 | Val Loss: 0.210254, Val Acc: 0.567010\n",
      "Epoch 3425 - Train Loss: 0.200531, Train Acc: 0.617949 | Val Loss: 0.210236, Val Acc: 0.567010\n",
      "Epoch 3426 - Train Loss: 0.200513, Train Acc: 0.617949 | Val Loss: 0.210218, Val Acc: 0.567010\n",
      "Epoch 3427 - Train Loss: 0.200495, Train Acc: 0.617949 | Val Loss: 0.210201, Val Acc: 0.567010\n",
      "Epoch 3428 - Train Loss: 0.200476, Train Acc: 0.617949 | Val Loss: 0.210183, Val Acc: 0.567010\n",
      "Epoch 3429 - Train Loss: 0.200458, Train Acc: 0.617949 | Val Loss: 0.210165, Val Acc: 0.577320\n",
      "Epoch 3430 - Train Loss: 0.200440, Train Acc: 0.617949 | Val Loss: 0.210148, Val Acc: 0.577320\n",
      "Epoch 3431 - Train Loss: 0.200422, Train Acc: 0.617949 | Val Loss: 0.210130, Val Acc: 0.577320\n",
      "Epoch 3432 - Train Loss: 0.200404, Train Acc: 0.617949 | Val Loss: 0.210113, Val Acc: 0.577320\n",
      "Epoch 3433 - Train Loss: 0.200386, Train Acc: 0.617949 | Val Loss: 0.210095, Val Acc: 0.577320\n",
      "Epoch 3434 - Train Loss: 0.200368, Train Acc: 0.617949 | Val Loss: 0.210077, Val Acc: 0.577320\n",
      "Epoch 3435 - Train Loss: 0.200349, Train Acc: 0.617949 | Val Loss: 0.210060, Val Acc: 0.577320\n",
      "Epoch 3436 - Train Loss: 0.200331, Train Acc: 0.617949 | Val Loss: 0.210042, Val Acc: 0.577320\n",
      "Epoch 3437 - Train Loss: 0.200313, Train Acc: 0.617949 | Val Loss: 0.210024, Val Acc: 0.577320\n",
      "Epoch 3438 - Train Loss: 0.200295, Train Acc: 0.619231 | Val Loss: 0.210007, Val Acc: 0.577320\n",
      "Epoch 3439 - Train Loss: 0.200277, Train Acc: 0.619231 | Val Loss: 0.209989, Val Acc: 0.577320\n",
      "Epoch 3440 - Train Loss: 0.200259, Train Acc: 0.619231 | Val Loss: 0.209972, Val Acc: 0.577320\n",
      "Epoch 3441 - Train Loss: 0.200241, Train Acc: 0.619231 | Val Loss: 0.209954, Val Acc: 0.577320\n",
      "Epoch 3442 - Train Loss: 0.200223, Train Acc: 0.619231 | Val Loss: 0.209936, Val Acc: 0.577320\n",
      "Epoch 3443 - Train Loss: 0.200204, Train Acc: 0.619231 | Val Loss: 0.209919, Val Acc: 0.577320\n",
      "Epoch 3444 - Train Loss: 0.200186, Train Acc: 0.619231 | Val Loss: 0.209901, Val Acc: 0.577320\n",
      "Epoch 3445 - Train Loss: 0.200168, Train Acc: 0.619231 | Val Loss: 0.209884, Val Acc: 0.577320\n",
      "Epoch 3446 - Train Loss: 0.200150, Train Acc: 0.619231 | Val Loss: 0.209866, Val Acc: 0.577320\n",
      "Epoch 3447 - Train Loss: 0.200132, Train Acc: 0.619231 | Val Loss: 0.209848, Val Acc: 0.577320\n",
      "Epoch 3448 - Train Loss: 0.200114, Train Acc: 0.619231 | Val Loss: 0.209831, Val Acc: 0.577320\n",
      "Epoch 3449 - Train Loss: 0.200096, Train Acc: 0.619231 | Val Loss: 0.209813, Val Acc: 0.577320\n",
      "Epoch 3450 - Train Loss: 0.200078, Train Acc: 0.619231 | Val Loss: 0.209796, Val Acc: 0.577320\n",
      "Epoch 3451 - Train Loss: 0.200060, Train Acc: 0.619231 | Val Loss: 0.209778, Val Acc: 0.577320\n",
      "Epoch 3452 - Train Loss: 0.200041, Train Acc: 0.619231 | Val Loss: 0.209760, Val Acc: 0.577320\n",
      "Epoch 3453 - Train Loss: 0.200023, Train Acc: 0.619231 | Val Loss: 0.209743, Val Acc: 0.577320\n",
      "Epoch 3454 - Train Loss: 0.200005, Train Acc: 0.619231 | Val Loss: 0.209725, Val Acc: 0.577320\n",
      "Epoch 3455 - Train Loss: 0.199987, Train Acc: 0.619231 | Val Loss: 0.209708, Val Acc: 0.577320\n",
      "Epoch 3456 - Train Loss: 0.199969, Train Acc: 0.619231 | Val Loss: 0.209690, Val Acc: 0.577320\n",
      "Epoch 3457 - Train Loss: 0.199951, Train Acc: 0.619231 | Val Loss: 0.209673, Val Acc: 0.577320\n",
      "Epoch 3458 - Train Loss: 0.199933, Train Acc: 0.619231 | Val Loss: 0.209655, Val Acc: 0.577320\n",
      "Epoch 3459 - Train Loss: 0.199915, Train Acc: 0.619231 | Val Loss: 0.209638, Val Acc: 0.577320\n",
      "Epoch 3460 - Train Loss: 0.199897, Train Acc: 0.619231 | Val Loss: 0.209620, Val Acc: 0.577320\n",
      "Epoch 3461 - Train Loss: 0.199879, Train Acc: 0.619231 | Val Loss: 0.209603, Val Acc: 0.577320\n",
      "Epoch 3462 - Train Loss: 0.199861, Train Acc: 0.619231 | Val Loss: 0.209585, Val Acc: 0.577320\n",
      "Epoch 3463 - Train Loss: 0.199843, Train Acc: 0.619231 | Val Loss: 0.209568, Val Acc: 0.577320\n",
      "Epoch 3464 - Train Loss: 0.199825, Train Acc: 0.619231 | Val Loss: 0.209550, Val Acc: 0.577320\n",
      "Epoch 3465 - Train Loss: 0.199807, Train Acc: 0.619231 | Val Loss: 0.209532, Val Acc: 0.577320\n",
      "Epoch 3466 - Train Loss: 0.199788, Train Acc: 0.619231 | Val Loss: 0.209515, Val Acc: 0.577320\n",
      "Epoch 3467 - Train Loss: 0.199770, Train Acc: 0.619231 | Val Loss: 0.209497, Val Acc: 0.577320\n",
      "Epoch 3468 - Train Loss: 0.199752, Train Acc: 0.619231 | Val Loss: 0.209480, Val Acc: 0.577320\n",
      "Epoch 3469 - Train Loss: 0.199734, Train Acc: 0.619231 | Val Loss: 0.209462, Val Acc: 0.577320\n",
      "Epoch 3470 - Train Loss: 0.199716, Train Acc: 0.619231 | Val Loss: 0.209445, Val Acc: 0.577320\n",
      "Epoch 3471 - Train Loss: 0.199698, Train Acc: 0.619231 | Val Loss: 0.209427, Val Acc: 0.577320\n",
      "Epoch 3472 - Train Loss: 0.199680, Train Acc: 0.620513 | Val Loss: 0.209410, Val Acc: 0.577320\n",
      "Epoch 3473 - Train Loss: 0.199662, Train Acc: 0.620513 | Val Loss: 0.209392, Val Acc: 0.577320\n",
      "Epoch 3474 - Train Loss: 0.199644, Train Acc: 0.620513 | Val Loss: 0.209375, Val Acc: 0.577320\n",
      "Epoch 3475 - Train Loss: 0.199626, Train Acc: 0.620513 | Val Loss: 0.209357, Val Acc: 0.577320\n",
      "Epoch 3476 - Train Loss: 0.199608, Train Acc: 0.620513 | Val Loss: 0.209340, Val Acc: 0.577320\n",
      "Epoch 3477 - Train Loss: 0.199590, Train Acc: 0.621795 | Val Loss: 0.209323, Val Acc: 0.577320\n",
      "Epoch 3478 - Train Loss: 0.199572, Train Acc: 0.621795 | Val Loss: 0.209305, Val Acc: 0.587629\n",
      "Epoch 3479 - Train Loss: 0.199554, Train Acc: 0.621795 | Val Loss: 0.209288, Val Acc: 0.587629\n",
      "Epoch 3480 - Train Loss: 0.199536, Train Acc: 0.621795 | Val Loss: 0.209270, Val Acc: 0.587629\n",
      "Epoch 3481 - Train Loss: 0.199518, Train Acc: 0.621795 | Val Loss: 0.209253, Val Acc: 0.587629\n",
      "Epoch 3482 - Train Loss: 0.199500, Train Acc: 0.623077 | Val Loss: 0.209235, Val Acc: 0.587629\n",
      "Epoch 3483 - Train Loss: 0.199482, Train Acc: 0.623077 | Val Loss: 0.209218, Val Acc: 0.587629\n",
      "Epoch 3484 - Train Loss: 0.199464, Train Acc: 0.623077 | Val Loss: 0.209200, Val Acc: 0.587629\n",
      "Epoch 3485 - Train Loss: 0.199446, Train Acc: 0.623077 | Val Loss: 0.209183, Val Acc: 0.587629\n",
      "Epoch 3486 - Train Loss: 0.199428, Train Acc: 0.623077 | Val Loss: 0.209165, Val Acc: 0.587629\n",
      "Epoch 3487 - Train Loss: 0.199410, Train Acc: 0.623077 | Val Loss: 0.209148, Val Acc: 0.587629\n",
      "Epoch 3488 - Train Loss: 0.199392, Train Acc: 0.623077 | Val Loss: 0.209131, Val Acc: 0.587629\n",
      "Epoch 3489 - Train Loss: 0.199374, Train Acc: 0.623077 | Val Loss: 0.209113, Val Acc: 0.587629\n",
      "Epoch 3490 - Train Loss: 0.199356, Train Acc: 0.623077 | Val Loss: 0.209096, Val Acc: 0.587629\n",
      "Epoch 3491 - Train Loss: 0.199338, Train Acc: 0.623077 | Val Loss: 0.209078, Val Acc: 0.587629\n",
      "Epoch 3492 - Train Loss: 0.199320, Train Acc: 0.623077 | Val Loss: 0.209061, Val Acc: 0.587629\n",
      "Epoch 3493 - Train Loss: 0.199302, Train Acc: 0.623077 | Val Loss: 0.209044, Val Acc: 0.587629\n",
      "Epoch 3494 - Train Loss: 0.199284, Train Acc: 0.623077 | Val Loss: 0.209026, Val Acc: 0.587629\n",
      "Epoch 3495 - Train Loss: 0.199266, Train Acc: 0.623077 | Val Loss: 0.209009, Val Acc: 0.587629\n",
      "Epoch 3496 - Train Loss: 0.199248, Train Acc: 0.623077 | Val Loss: 0.208991, Val Acc: 0.587629\n",
      "Epoch 3497 - Train Loss: 0.199230, Train Acc: 0.623077 | Val Loss: 0.208974, Val Acc: 0.587629\n",
      "Epoch 3498 - Train Loss: 0.199212, Train Acc: 0.623077 | Val Loss: 0.208956, Val Acc: 0.587629\n",
      "Epoch 3499 - Train Loss: 0.199194, Train Acc: 0.623077 | Val Loss: 0.208939, Val Acc: 0.587629\n",
      "Epoch 3500 - Train Loss: 0.199176, Train Acc: 0.623077 | Val Loss: 0.208922, Val Acc: 0.587629\n",
      "Epoch 3501 - Train Loss: 0.199158, Train Acc: 0.623077 | Val Loss: 0.208904, Val Acc: 0.587629\n",
      "Epoch 3502 - Train Loss: 0.199140, Train Acc: 0.623077 | Val Loss: 0.208887, Val Acc: 0.587629\n",
      "Epoch 3503 - Train Loss: 0.199122, Train Acc: 0.623077 | Val Loss: 0.208870, Val Acc: 0.587629\n",
      "Epoch 3504 - Train Loss: 0.199104, Train Acc: 0.623077 | Val Loss: 0.208852, Val Acc: 0.587629\n",
      "Epoch 3505 - Train Loss: 0.199086, Train Acc: 0.623077 | Val Loss: 0.208835, Val Acc: 0.587629\n",
      "Epoch 3506 - Train Loss: 0.199068, Train Acc: 0.623077 | Val Loss: 0.208817, Val Acc: 0.587629\n",
      "Epoch 3507 - Train Loss: 0.199050, Train Acc: 0.623077 | Val Loss: 0.208800, Val Acc: 0.587629\n",
      "Epoch 3508 - Train Loss: 0.199032, Train Acc: 0.623077 | Val Loss: 0.208783, Val Acc: 0.597938\n",
      "Epoch 3509 - Train Loss: 0.199014, Train Acc: 0.623077 | Val Loss: 0.208765, Val Acc: 0.597938\n",
      "Epoch 3510 - Train Loss: 0.198997, Train Acc: 0.623077 | Val Loss: 0.208748, Val Acc: 0.597938\n",
      "Epoch 3511 - Train Loss: 0.198979, Train Acc: 0.623077 | Val Loss: 0.208731, Val Acc: 0.597938\n",
      "Epoch 3512 - Train Loss: 0.198961, Train Acc: 0.623077 | Val Loss: 0.208713, Val Acc: 0.597938\n",
      "Epoch 3513 - Train Loss: 0.198943, Train Acc: 0.623077 | Val Loss: 0.208696, Val Acc: 0.597938\n",
      "Epoch 3514 - Train Loss: 0.198925, Train Acc: 0.623077 | Val Loss: 0.208679, Val Acc: 0.597938\n",
      "Epoch 3515 - Train Loss: 0.198907, Train Acc: 0.623077 | Val Loss: 0.208661, Val Acc: 0.597938\n",
      "Epoch 3516 - Train Loss: 0.198889, Train Acc: 0.623077 | Val Loss: 0.208644, Val Acc: 0.597938\n",
      "Epoch 3517 - Train Loss: 0.198871, Train Acc: 0.623077 | Val Loss: 0.208627, Val Acc: 0.597938\n",
      "Epoch 3518 - Train Loss: 0.198853, Train Acc: 0.623077 | Val Loss: 0.208609, Val Acc: 0.597938\n",
      "Epoch 3519 - Train Loss: 0.198835, Train Acc: 0.623077 | Val Loss: 0.208592, Val Acc: 0.597938\n",
      "Epoch 3520 - Train Loss: 0.198817, Train Acc: 0.623077 | Val Loss: 0.208575, Val Acc: 0.597938\n",
      "Epoch 3521 - Train Loss: 0.198799, Train Acc: 0.623077 | Val Loss: 0.208557, Val Acc: 0.597938\n",
      "Epoch 3522 - Train Loss: 0.198782, Train Acc: 0.623077 | Val Loss: 0.208540, Val Acc: 0.597938\n",
      "Epoch 3523 - Train Loss: 0.198764, Train Acc: 0.623077 | Val Loss: 0.208523, Val Acc: 0.597938\n",
      "Epoch 3524 - Train Loss: 0.198746, Train Acc: 0.623077 | Val Loss: 0.208505, Val Acc: 0.597938\n",
      "Epoch 3525 - Train Loss: 0.198728, Train Acc: 0.623077 | Val Loss: 0.208488, Val Acc: 0.597938\n",
      "Epoch 3526 - Train Loss: 0.198710, Train Acc: 0.623077 | Val Loss: 0.208471, Val Acc: 0.597938\n",
      "Epoch 3527 - Train Loss: 0.198692, Train Acc: 0.623077 | Val Loss: 0.208453, Val Acc: 0.597938\n",
      "Epoch 3528 - Train Loss: 0.198674, Train Acc: 0.623077 | Val Loss: 0.208436, Val Acc: 0.597938\n",
      "Epoch 3529 - Train Loss: 0.198656, Train Acc: 0.623077 | Val Loss: 0.208419, Val Acc: 0.597938\n",
      "Epoch 3530 - Train Loss: 0.198638, Train Acc: 0.623077 | Val Loss: 0.208402, Val Acc: 0.597938\n",
      "Epoch 3531 - Train Loss: 0.198620, Train Acc: 0.624359 | Val Loss: 0.208384, Val Acc: 0.597938\n",
      "Epoch 3532 - Train Loss: 0.198603, Train Acc: 0.624359 | Val Loss: 0.208367, Val Acc: 0.597938\n",
      "Epoch 3533 - Train Loss: 0.198585, Train Acc: 0.624359 | Val Loss: 0.208350, Val Acc: 0.597938\n",
      "Epoch 3534 - Train Loss: 0.198567, Train Acc: 0.624359 | Val Loss: 0.208332, Val Acc: 0.597938\n",
      "Epoch 3535 - Train Loss: 0.198549, Train Acc: 0.624359 | Val Loss: 0.208315, Val Acc: 0.597938\n",
      "Epoch 3536 - Train Loss: 0.198531, Train Acc: 0.624359 | Val Loss: 0.208298, Val Acc: 0.597938\n",
      "Epoch 3537 - Train Loss: 0.198513, Train Acc: 0.624359 | Val Loss: 0.208281, Val Acc: 0.597938\n",
      "Epoch 3538 - Train Loss: 0.198495, Train Acc: 0.624359 | Val Loss: 0.208263, Val Acc: 0.597938\n",
      "Epoch 3539 - Train Loss: 0.198478, Train Acc: 0.624359 | Val Loss: 0.208246, Val Acc: 0.597938\n",
      "Epoch 3540 - Train Loss: 0.198460, Train Acc: 0.624359 | Val Loss: 0.208229, Val Acc: 0.597938\n",
      "Epoch 3541 - Train Loss: 0.198442, Train Acc: 0.624359 | Val Loss: 0.208212, Val Acc: 0.597938\n",
      "Epoch 3542 - Train Loss: 0.198424, Train Acc: 0.624359 | Val Loss: 0.208194, Val Acc: 0.597938\n",
      "Epoch 3543 - Train Loss: 0.198406, Train Acc: 0.624359 | Val Loss: 0.208177, Val Acc: 0.597938\n",
      "Epoch 3544 - Train Loss: 0.198388, Train Acc: 0.624359 | Val Loss: 0.208160, Val Acc: 0.597938\n",
      "Epoch 3545 - Train Loss: 0.198370, Train Acc: 0.624359 | Val Loss: 0.208143, Val Acc: 0.597938\n",
      "Epoch 3546 - Train Loss: 0.198353, Train Acc: 0.624359 | Val Loss: 0.208125, Val Acc: 0.597938\n",
      "Epoch 3547 - Train Loss: 0.198335, Train Acc: 0.624359 | Val Loss: 0.208108, Val Acc: 0.597938\n",
      "Epoch 3548 - Train Loss: 0.198317, Train Acc: 0.624359 | Val Loss: 0.208091, Val Acc: 0.597938\n",
      "Epoch 3549 - Train Loss: 0.198299, Train Acc: 0.624359 | Val Loss: 0.208074, Val Acc: 0.597938\n",
      "Epoch 3550 - Train Loss: 0.198281, Train Acc: 0.624359 | Val Loss: 0.208057, Val Acc: 0.597938\n",
      "Epoch 3551 - Train Loss: 0.198263, Train Acc: 0.624359 | Val Loss: 0.208039, Val Acc: 0.597938\n",
      "Epoch 3552 - Train Loss: 0.198246, Train Acc: 0.624359 | Val Loss: 0.208022, Val Acc: 0.597938\n",
      "Epoch 3553 - Train Loss: 0.198228, Train Acc: 0.624359 | Val Loss: 0.208005, Val Acc: 0.597938\n",
      "Epoch 3554 - Train Loss: 0.198210, Train Acc: 0.624359 | Val Loss: 0.207988, Val Acc: 0.597938\n",
      "Epoch 3555 - Train Loss: 0.198192, Train Acc: 0.624359 | Val Loss: 0.207971, Val Acc: 0.597938\n",
      "Epoch 3556 - Train Loss: 0.198174, Train Acc: 0.624359 | Val Loss: 0.207953, Val Acc: 0.597938\n",
      "Epoch 3557 - Train Loss: 0.198157, Train Acc: 0.624359 | Val Loss: 0.207936, Val Acc: 0.597938\n",
      "Epoch 3558 - Train Loss: 0.198139, Train Acc: 0.624359 | Val Loss: 0.207919, Val Acc: 0.597938\n",
      "Epoch 3559 - Train Loss: 0.198121, Train Acc: 0.624359 | Val Loss: 0.207902, Val Acc: 0.597938\n",
      "Epoch 3560 - Train Loss: 0.198103, Train Acc: 0.624359 | Val Loss: 0.207885, Val Acc: 0.608247\n",
      "Epoch 3561 - Train Loss: 0.198085, Train Acc: 0.624359 | Val Loss: 0.207868, Val Acc: 0.608247\n",
      "Epoch 3562 - Train Loss: 0.198068, Train Acc: 0.624359 | Val Loss: 0.207850, Val Acc: 0.608247\n",
      "Epoch 3563 - Train Loss: 0.198050, Train Acc: 0.624359 | Val Loss: 0.207833, Val Acc: 0.608247\n",
      "Epoch 3564 - Train Loss: 0.198032, Train Acc: 0.624359 | Val Loss: 0.207816, Val Acc: 0.608247\n",
      "Epoch 3565 - Train Loss: 0.198014, Train Acc: 0.624359 | Val Loss: 0.207799, Val Acc: 0.608247\n",
      "Epoch 3566 - Train Loss: 0.197996, Train Acc: 0.624359 | Val Loss: 0.207782, Val Acc: 0.608247\n",
      "Epoch 3567 - Train Loss: 0.197979, Train Acc: 0.624359 | Val Loss: 0.207764, Val Acc: 0.608247\n",
      "Epoch 3568 - Train Loss: 0.197961, Train Acc: 0.624359 | Val Loss: 0.207747, Val Acc: 0.608247\n",
      "Epoch 3569 - Train Loss: 0.197943, Train Acc: 0.624359 | Val Loss: 0.207730, Val Acc: 0.608247\n",
      "Epoch 3570 - Train Loss: 0.197925, Train Acc: 0.624359 | Val Loss: 0.207713, Val Acc: 0.608247\n",
      "Epoch 3571 - Train Loss: 0.197907, Train Acc: 0.624359 | Val Loss: 0.207696, Val Acc: 0.608247\n",
      "Epoch 3572 - Train Loss: 0.197890, Train Acc: 0.624359 | Val Loss: 0.207679, Val Acc: 0.608247\n",
      "Epoch 3573 - Train Loss: 0.197872, Train Acc: 0.624359 | Val Loss: 0.207662, Val Acc: 0.608247\n",
      "Epoch 3574 - Train Loss: 0.197854, Train Acc: 0.624359 | Val Loss: 0.207644, Val Acc: 0.608247\n",
      "Epoch 3575 - Train Loss: 0.197836, Train Acc: 0.624359 | Val Loss: 0.207627, Val Acc: 0.608247\n",
      "Epoch 3576 - Train Loss: 0.197819, Train Acc: 0.624359 | Val Loss: 0.207610, Val Acc: 0.608247\n",
      "Epoch 3577 - Train Loss: 0.197801, Train Acc: 0.624359 | Val Loss: 0.207593, Val Acc: 0.608247\n",
      "Epoch 3578 - Train Loss: 0.197783, Train Acc: 0.624359 | Val Loss: 0.207576, Val Acc: 0.608247\n",
      "Epoch 3579 - Train Loss: 0.197765, Train Acc: 0.624359 | Val Loss: 0.207559, Val Acc: 0.608247\n",
      "Epoch 3580 - Train Loss: 0.197748, Train Acc: 0.624359 | Val Loss: 0.207542, Val Acc: 0.608247\n",
      "Epoch 3581 - Train Loss: 0.197730, Train Acc: 0.624359 | Val Loss: 0.207525, Val Acc: 0.608247\n",
      "Epoch 3582 - Train Loss: 0.197712, Train Acc: 0.624359 | Val Loss: 0.207507, Val Acc: 0.608247\n",
      "Epoch 3583 - Train Loss: 0.197694, Train Acc: 0.624359 | Val Loss: 0.207490, Val Acc: 0.608247\n",
      "Epoch 3584 - Train Loss: 0.197677, Train Acc: 0.624359 | Val Loss: 0.207473, Val Acc: 0.608247\n",
      "Epoch 3585 - Train Loss: 0.197659, Train Acc: 0.624359 | Val Loss: 0.207456, Val Acc: 0.608247\n",
      "Epoch 3586 - Train Loss: 0.197641, Train Acc: 0.624359 | Val Loss: 0.207439, Val Acc: 0.608247\n",
      "Epoch 3587 - Train Loss: 0.197623, Train Acc: 0.624359 | Val Loss: 0.207422, Val Acc: 0.608247\n",
      "Epoch 3588 - Train Loss: 0.197606, Train Acc: 0.624359 | Val Loss: 0.207405, Val Acc: 0.608247\n",
      "Epoch 3589 - Train Loss: 0.197588, Train Acc: 0.624359 | Val Loss: 0.207388, Val Acc: 0.608247\n",
      "Epoch 3590 - Train Loss: 0.197570, Train Acc: 0.624359 | Val Loss: 0.207371, Val Acc: 0.608247\n",
      "Epoch 3591 - Train Loss: 0.197553, Train Acc: 0.624359 | Val Loss: 0.207353, Val Acc: 0.608247\n",
      "Epoch 3592 - Train Loss: 0.197535, Train Acc: 0.624359 | Val Loss: 0.207336, Val Acc: 0.608247\n",
      "Epoch 3593 - Train Loss: 0.197517, Train Acc: 0.624359 | Val Loss: 0.207319, Val Acc: 0.608247\n",
      "Epoch 3594 - Train Loss: 0.197499, Train Acc: 0.624359 | Val Loss: 0.207302, Val Acc: 0.608247\n",
      "Epoch 3595 - Train Loss: 0.197482, Train Acc: 0.624359 | Val Loss: 0.207285, Val Acc: 0.608247\n",
      "Epoch 3596 - Train Loss: 0.197464, Train Acc: 0.624359 | Val Loss: 0.207268, Val Acc: 0.608247\n",
      "Epoch 3597 - Train Loss: 0.197446, Train Acc: 0.624359 | Val Loss: 0.207251, Val Acc: 0.608247\n",
      "Epoch 3598 - Train Loss: 0.197429, Train Acc: 0.624359 | Val Loss: 0.207234, Val Acc: 0.608247\n",
      "Epoch 3599 - Train Loss: 0.197411, Train Acc: 0.624359 | Val Loss: 0.207217, Val Acc: 0.608247\n",
      "Epoch 3600 - Train Loss: 0.197393, Train Acc: 0.624359 | Val Loss: 0.207200, Val Acc: 0.608247\n",
      "Epoch 3601 - Train Loss: 0.197376, Train Acc: 0.624359 | Val Loss: 0.207183, Val Acc: 0.608247\n",
      "Epoch 3602 - Train Loss: 0.197358, Train Acc: 0.624359 | Val Loss: 0.207166, Val Acc: 0.608247\n",
      "Epoch 3603 - Train Loss: 0.197340, Train Acc: 0.625641 | Val Loss: 0.207148, Val Acc: 0.608247\n",
      "Epoch 3604 - Train Loss: 0.197322, Train Acc: 0.625641 | Val Loss: 0.207131, Val Acc: 0.608247\n",
      "Epoch 3605 - Train Loss: 0.197305, Train Acc: 0.625641 | Val Loss: 0.207114, Val Acc: 0.608247\n",
      "Epoch 3606 - Train Loss: 0.197287, Train Acc: 0.625641 | Val Loss: 0.207097, Val Acc: 0.608247\n",
      "Epoch 3607 - Train Loss: 0.197269, Train Acc: 0.625641 | Val Loss: 0.207080, Val Acc: 0.608247\n",
      "Epoch 3608 - Train Loss: 0.197252, Train Acc: 0.625641 | Val Loss: 0.207063, Val Acc: 0.608247\n",
      "Epoch 3609 - Train Loss: 0.197234, Train Acc: 0.625641 | Val Loss: 0.207046, Val Acc: 0.608247\n",
      "Epoch 3610 - Train Loss: 0.197216, Train Acc: 0.625641 | Val Loss: 0.207029, Val Acc: 0.608247\n",
      "Epoch 3611 - Train Loss: 0.197199, Train Acc: 0.625641 | Val Loss: 0.207012, Val Acc: 0.608247\n",
      "Epoch 3612 - Train Loss: 0.197181, Train Acc: 0.625641 | Val Loss: 0.206995, Val Acc: 0.608247\n",
      "Epoch 3613 - Train Loss: 0.197163, Train Acc: 0.625641 | Val Loss: 0.206978, Val Acc: 0.608247\n",
      "Epoch 3614 - Train Loss: 0.197146, Train Acc: 0.625641 | Val Loss: 0.206961, Val Acc: 0.608247\n",
      "Epoch 3615 - Train Loss: 0.197128, Train Acc: 0.625641 | Val Loss: 0.206944, Val Acc: 0.608247\n",
      "Epoch 3616 - Train Loss: 0.197111, Train Acc: 0.625641 | Val Loss: 0.206927, Val Acc: 0.608247\n",
      "Epoch 3617 - Train Loss: 0.197093, Train Acc: 0.625641 | Val Loss: 0.206910, Val Acc: 0.608247\n",
      "Epoch 3618 - Train Loss: 0.197075, Train Acc: 0.625641 | Val Loss: 0.206893, Val Acc: 0.608247\n",
      "Epoch 3619 - Train Loss: 0.197058, Train Acc: 0.625641 | Val Loss: 0.206876, Val Acc: 0.608247\n",
      "Epoch 3620 - Train Loss: 0.197040, Train Acc: 0.625641 | Val Loss: 0.206859, Val Acc: 0.608247\n",
      "Epoch 3621 - Train Loss: 0.197022, Train Acc: 0.625641 | Val Loss: 0.206841, Val Acc: 0.608247\n",
      "Epoch 3622 - Train Loss: 0.197005, Train Acc: 0.625641 | Val Loss: 0.206824, Val Acc: 0.608247\n",
      "Epoch 3623 - Train Loss: 0.196987, Train Acc: 0.625641 | Val Loss: 0.206807, Val Acc: 0.608247\n",
      "Epoch 3624 - Train Loss: 0.196969, Train Acc: 0.625641 | Val Loss: 0.206790, Val Acc: 0.608247\n",
      "Epoch 3625 - Train Loss: 0.196952, Train Acc: 0.625641 | Val Loss: 0.206773, Val Acc: 0.608247\n",
      "Epoch 3626 - Train Loss: 0.196934, Train Acc: 0.625641 | Val Loss: 0.206756, Val Acc: 0.608247\n",
      "Epoch 3627 - Train Loss: 0.196917, Train Acc: 0.625641 | Val Loss: 0.206739, Val Acc: 0.608247\n",
      "Epoch 3628 - Train Loss: 0.196899, Train Acc: 0.625641 | Val Loss: 0.206722, Val Acc: 0.608247\n",
      "Epoch 3629 - Train Loss: 0.196881, Train Acc: 0.625641 | Val Loss: 0.206705, Val Acc: 0.608247\n",
      "Epoch 3630 - Train Loss: 0.196864, Train Acc: 0.625641 | Val Loss: 0.206688, Val Acc: 0.608247\n",
      "Epoch 3631 - Train Loss: 0.196846, Train Acc: 0.625641 | Val Loss: 0.206671, Val Acc: 0.608247\n",
      "Epoch 3632 - Train Loss: 0.196829, Train Acc: 0.625641 | Val Loss: 0.206654, Val Acc: 0.608247\n",
      "Epoch 3633 - Train Loss: 0.196811, Train Acc: 0.625641 | Val Loss: 0.206637, Val Acc: 0.608247\n",
      "Epoch 3634 - Train Loss: 0.196793, Train Acc: 0.625641 | Val Loss: 0.206620, Val Acc: 0.608247\n",
      "Epoch 3635 - Train Loss: 0.196776, Train Acc: 0.625641 | Val Loss: 0.206603, Val Acc: 0.608247\n",
      "Epoch 3636 - Train Loss: 0.196758, Train Acc: 0.625641 | Val Loss: 0.206586, Val Acc: 0.608247\n",
      "Epoch 3637 - Train Loss: 0.196741, Train Acc: 0.625641 | Val Loss: 0.206569, Val Acc: 0.608247\n",
      "Epoch 3638 - Train Loss: 0.196723, Train Acc: 0.625641 | Val Loss: 0.206552, Val Acc: 0.608247\n",
      "Epoch 3639 - Train Loss: 0.196705, Train Acc: 0.625641 | Val Loss: 0.206535, Val Acc: 0.608247\n",
      "Epoch 3640 - Train Loss: 0.196688, Train Acc: 0.626923 | Val Loss: 0.206518, Val Acc: 0.608247\n",
      "Epoch 3641 - Train Loss: 0.196670, Train Acc: 0.626923 | Val Loss: 0.206501, Val Acc: 0.608247\n",
      "Epoch 3642 - Train Loss: 0.196653, Train Acc: 0.626923 | Val Loss: 0.206484, Val Acc: 0.608247\n",
      "Epoch 3643 - Train Loss: 0.196635, Train Acc: 0.626923 | Val Loss: 0.206467, Val Acc: 0.608247\n",
      "Epoch 3644 - Train Loss: 0.196618, Train Acc: 0.626923 | Val Loss: 0.206450, Val Acc: 0.608247\n",
      "Epoch 3645 - Train Loss: 0.196600, Train Acc: 0.626923 | Val Loss: 0.206433, Val Acc: 0.608247\n",
      "Epoch 3646 - Train Loss: 0.196582, Train Acc: 0.626923 | Val Loss: 0.206416, Val Acc: 0.608247\n",
      "Epoch 3647 - Train Loss: 0.196565, Train Acc: 0.626923 | Val Loss: 0.206399, Val Acc: 0.608247\n",
      "Epoch 3648 - Train Loss: 0.196547, Train Acc: 0.626923 | Val Loss: 0.206382, Val Acc: 0.608247\n",
      "Epoch 3649 - Train Loss: 0.196530, Train Acc: 0.626923 | Val Loss: 0.206365, Val Acc: 0.608247\n",
      "Epoch 3650 - Train Loss: 0.196512, Train Acc: 0.626923 | Val Loss: 0.206348, Val Acc: 0.608247\n",
      "Epoch 3651 - Train Loss: 0.196495, Train Acc: 0.626923 | Val Loss: 0.206331, Val Acc: 0.608247\n",
      "Epoch 3652 - Train Loss: 0.196477, Train Acc: 0.626923 | Val Loss: 0.206314, Val Acc: 0.608247\n",
      "Epoch 3653 - Train Loss: 0.196459, Train Acc: 0.626923 | Val Loss: 0.206298, Val Acc: 0.608247\n",
      "Epoch 3654 - Train Loss: 0.196442, Train Acc: 0.626923 | Val Loss: 0.206281, Val Acc: 0.608247\n",
      "Epoch 3655 - Train Loss: 0.196424, Train Acc: 0.626923 | Val Loss: 0.206264, Val Acc: 0.608247\n",
      "Epoch 3656 - Train Loss: 0.196407, Train Acc: 0.626923 | Val Loss: 0.206247, Val Acc: 0.608247\n",
      "Epoch 3657 - Train Loss: 0.196389, Train Acc: 0.626923 | Val Loss: 0.206230, Val Acc: 0.608247\n",
      "Epoch 3658 - Train Loss: 0.196372, Train Acc: 0.626923 | Val Loss: 0.206213, Val Acc: 0.608247\n",
      "Epoch 3659 - Train Loss: 0.196354, Train Acc: 0.626923 | Val Loss: 0.206196, Val Acc: 0.608247\n",
      "Epoch 3660 - Train Loss: 0.196337, Train Acc: 0.626923 | Val Loss: 0.206179, Val Acc: 0.608247\n",
      "Epoch 3661 - Train Loss: 0.196319, Train Acc: 0.626923 | Val Loss: 0.206162, Val Acc: 0.608247\n",
      "Epoch 3662 - Train Loss: 0.196302, Train Acc: 0.626923 | Val Loss: 0.206145, Val Acc: 0.608247\n",
      "Epoch 3663 - Train Loss: 0.196284, Train Acc: 0.626923 | Val Loss: 0.206128, Val Acc: 0.608247\n",
      "Epoch 3664 - Train Loss: 0.196267, Train Acc: 0.626923 | Val Loss: 0.206111, Val Acc: 0.608247\n",
      "Epoch 3665 - Train Loss: 0.196249, Train Acc: 0.626923 | Val Loss: 0.206094, Val Acc: 0.608247\n",
      "Epoch 3666 - Train Loss: 0.196232, Train Acc: 0.626923 | Val Loss: 0.206077, Val Acc: 0.608247\n",
      "Epoch 3667 - Train Loss: 0.196214, Train Acc: 0.626923 | Val Loss: 0.206060, Val Acc: 0.608247\n",
      "Epoch 3668 - Train Loss: 0.196197, Train Acc: 0.626923 | Val Loss: 0.206044, Val Acc: 0.608247\n",
      "Epoch 3669 - Train Loss: 0.196179, Train Acc: 0.626923 | Val Loss: 0.206027, Val Acc: 0.608247\n",
      "Epoch 3670 - Train Loss: 0.196161, Train Acc: 0.626923 | Val Loss: 0.206010, Val Acc: 0.608247\n",
      "Epoch 3671 - Train Loss: 0.196144, Train Acc: 0.626923 | Val Loss: 0.205993, Val Acc: 0.608247\n",
      "Epoch 3672 - Train Loss: 0.196126, Train Acc: 0.626923 | Val Loss: 0.205976, Val Acc: 0.608247\n",
      "Epoch 3673 - Train Loss: 0.196109, Train Acc: 0.626923 | Val Loss: 0.205959, Val Acc: 0.608247\n",
      "Epoch 3674 - Train Loss: 0.196091, Train Acc: 0.626923 | Val Loss: 0.205942, Val Acc: 0.608247\n",
      "Epoch 3675 - Train Loss: 0.196074, Train Acc: 0.626923 | Val Loss: 0.205925, Val Acc: 0.608247\n",
      "Epoch 3676 - Train Loss: 0.196057, Train Acc: 0.626923 | Val Loss: 0.205908, Val Acc: 0.608247\n",
      "Epoch 3677 - Train Loss: 0.196039, Train Acc: 0.626923 | Val Loss: 0.205891, Val Acc: 0.608247\n",
      "Epoch 3678 - Train Loss: 0.196022, Train Acc: 0.626923 | Val Loss: 0.205875, Val Acc: 0.608247\n",
      "Epoch 3679 - Train Loss: 0.196004, Train Acc: 0.626923 | Val Loss: 0.205858, Val Acc: 0.608247\n",
      "Epoch 3680 - Train Loss: 0.195987, Train Acc: 0.626923 | Val Loss: 0.205841, Val Acc: 0.608247\n",
      "Epoch 3681 - Train Loss: 0.195969, Train Acc: 0.626923 | Val Loss: 0.205824, Val Acc: 0.608247\n",
      "Epoch 3682 - Train Loss: 0.195952, Train Acc: 0.626923 | Val Loss: 0.205807, Val Acc: 0.608247\n",
      "Epoch 3683 - Train Loss: 0.195934, Train Acc: 0.626923 | Val Loss: 0.205790, Val Acc: 0.608247\n",
      "Epoch 3684 - Train Loss: 0.195917, Train Acc: 0.626923 | Val Loss: 0.205773, Val Acc: 0.608247\n",
      "Epoch 3685 - Train Loss: 0.195899, Train Acc: 0.626923 | Val Loss: 0.205757, Val Acc: 0.608247\n",
      "Epoch 3686 - Train Loss: 0.195882, Train Acc: 0.626923 | Val Loss: 0.205740, Val Acc: 0.608247\n",
      "Epoch 3687 - Train Loss: 0.195864, Train Acc: 0.626923 | Val Loss: 0.205723, Val Acc: 0.608247\n",
      "Epoch 3688 - Train Loss: 0.195847, Train Acc: 0.626923 | Val Loss: 0.205706, Val Acc: 0.608247\n",
      "Epoch 3689 - Train Loss: 0.195829, Train Acc: 0.626923 | Val Loss: 0.205689, Val Acc: 0.608247\n",
      "Epoch 3690 - Train Loss: 0.195812, Train Acc: 0.626923 | Val Loss: 0.205672, Val Acc: 0.608247\n",
      "Epoch 3691 - Train Loss: 0.195795, Train Acc: 0.626923 | Val Loss: 0.205655, Val Acc: 0.608247\n",
      "Epoch 3692 - Train Loss: 0.195777, Train Acc: 0.626923 | Val Loss: 0.205639, Val Acc: 0.608247\n",
      "Epoch 3693 - Train Loss: 0.195760, Train Acc: 0.626923 | Val Loss: 0.205622, Val Acc: 0.608247\n",
      "Epoch 3694 - Train Loss: 0.195742, Train Acc: 0.626923 | Val Loss: 0.205605, Val Acc: 0.608247\n",
      "Epoch 3695 - Train Loss: 0.195725, Train Acc: 0.626923 | Val Loss: 0.205588, Val Acc: 0.608247\n",
      "Epoch 3696 - Train Loss: 0.195707, Train Acc: 0.626923 | Val Loss: 0.205571, Val Acc: 0.608247\n",
      "Epoch 3697 - Train Loss: 0.195690, Train Acc: 0.626923 | Val Loss: 0.205554, Val Acc: 0.608247\n",
      "Epoch 3698 - Train Loss: 0.195672, Train Acc: 0.626923 | Val Loss: 0.205538, Val Acc: 0.608247\n",
      "Epoch 3699 - Train Loss: 0.195655, Train Acc: 0.626923 | Val Loss: 0.205521, Val Acc: 0.608247\n",
      "Epoch 3700 - Train Loss: 0.195638, Train Acc: 0.626923 | Val Loss: 0.205504, Val Acc: 0.608247\n",
      "Epoch 3701 - Train Loss: 0.195620, Train Acc: 0.626923 | Val Loss: 0.205487, Val Acc: 0.608247\n",
      "Epoch 3702 - Train Loss: 0.195603, Train Acc: 0.626923 | Val Loss: 0.205470, Val Acc: 0.608247\n",
      "Epoch 3703 - Train Loss: 0.195585, Train Acc: 0.626923 | Val Loss: 0.205453, Val Acc: 0.608247\n",
      "Epoch 3704 - Train Loss: 0.195568, Train Acc: 0.626923 | Val Loss: 0.205437, Val Acc: 0.608247\n",
      "Epoch 3705 - Train Loss: 0.195551, Train Acc: 0.628205 | Val Loss: 0.205420, Val Acc: 0.608247\n",
      "Epoch 3706 - Train Loss: 0.195533, Train Acc: 0.628205 | Val Loss: 0.205403, Val Acc: 0.608247\n",
      "Epoch 3707 - Train Loss: 0.195516, Train Acc: 0.628205 | Val Loss: 0.205386, Val Acc: 0.608247\n",
      "Epoch 3708 - Train Loss: 0.195498, Train Acc: 0.628205 | Val Loss: 0.205369, Val Acc: 0.608247\n",
      "Epoch 3709 - Train Loss: 0.195481, Train Acc: 0.628205 | Val Loss: 0.205353, Val Acc: 0.608247\n",
      "Epoch 3710 - Train Loss: 0.195464, Train Acc: 0.628205 | Val Loss: 0.205336, Val Acc: 0.608247\n",
      "Epoch 3711 - Train Loss: 0.195446, Train Acc: 0.628205 | Val Loss: 0.205319, Val Acc: 0.608247\n",
      "Epoch 3712 - Train Loss: 0.195429, Train Acc: 0.628205 | Val Loss: 0.205302, Val Acc: 0.608247\n",
      "Epoch 3713 - Train Loss: 0.195411, Train Acc: 0.628205 | Val Loss: 0.205285, Val Acc: 0.608247\n",
      "Epoch 3714 - Train Loss: 0.195394, Train Acc: 0.628205 | Val Loss: 0.205269, Val Acc: 0.608247\n",
      "Epoch 3715 - Train Loss: 0.195377, Train Acc: 0.628205 | Val Loss: 0.205252, Val Acc: 0.608247\n",
      "Epoch 3716 - Train Loss: 0.195359, Train Acc: 0.628205 | Val Loss: 0.205235, Val Acc: 0.608247\n",
      "Epoch 3717 - Train Loss: 0.195342, Train Acc: 0.628205 | Val Loss: 0.205218, Val Acc: 0.608247\n",
      "Epoch 3718 - Train Loss: 0.195324, Train Acc: 0.628205 | Val Loss: 0.205201, Val Acc: 0.608247\n",
      "Epoch 3719 - Train Loss: 0.195307, Train Acc: 0.628205 | Val Loss: 0.205185, Val Acc: 0.608247\n",
      "Epoch 3720 - Train Loss: 0.195290, Train Acc: 0.628205 | Val Loss: 0.205168, Val Acc: 0.608247\n",
      "Epoch 3721 - Train Loss: 0.195272, Train Acc: 0.628205 | Val Loss: 0.205151, Val Acc: 0.608247\n",
      "Epoch 3722 - Train Loss: 0.195255, Train Acc: 0.628205 | Val Loss: 0.205134, Val Acc: 0.608247\n",
      "Epoch 3723 - Train Loss: 0.195238, Train Acc: 0.628205 | Val Loss: 0.205117, Val Acc: 0.597938\n",
      "Epoch 3724 - Train Loss: 0.195220, Train Acc: 0.628205 | Val Loss: 0.205101, Val Acc: 0.597938\n",
      "Epoch 3725 - Train Loss: 0.195203, Train Acc: 0.626923 | Val Loss: 0.205084, Val Acc: 0.597938\n",
      "Epoch 3726 - Train Loss: 0.195186, Train Acc: 0.626923 | Val Loss: 0.205067, Val Acc: 0.597938\n",
      "Epoch 3727 - Train Loss: 0.195168, Train Acc: 0.626923 | Val Loss: 0.205050, Val Acc: 0.597938\n",
      "Epoch 3728 - Train Loss: 0.195151, Train Acc: 0.626923 | Val Loss: 0.205034, Val Acc: 0.597938\n",
      "Epoch 3729 - Train Loss: 0.195133, Train Acc: 0.626923 | Val Loss: 0.205017, Val Acc: 0.597938\n",
      "Epoch 3730 - Train Loss: 0.195116, Train Acc: 0.626923 | Val Loss: 0.205000, Val Acc: 0.597938\n",
      "Epoch 3731 - Train Loss: 0.195099, Train Acc: 0.626923 | Val Loss: 0.204983, Val Acc: 0.597938\n",
      "Epoch 3732 - Train Loss: 0.195081, Train Acc: 0.628205 | Val Loss: 0.204967, Val Acc: 0.597938\n",
      "Epoch 3733 - Train Loss: 0.195064, Train Acc: 0.628205 | Val Loss: 0.204950, Val Acc: 0.597938\n",
      "Epoch 3734 - Train Loss: 0.195047, Train Acc: 0.628205 | Val Loss: 0.204933, Val Acc: 0.597938\n",
      "Epoch 3735 - Train Loss: 0.195029, Train Acc: 0.628205 | Val Loss: 0.204916, Val Acc: 0.597938\n",
      "Epoch 3736 - Train Loss: 0.195012, Train Acc: 0.628205 | Val Loss: 0.204900, Val Acc: 0.597938\n",
      "Epoch 3737 - Train Loss: 0.194995, Train Acc: 0.628205 | Val Loss: 0.204883, Val Acc: 0.597938\n",
      "Epoch 3738 - Train Loss: 0.194977, Train Acc: 0.628205 | Val Loss: 0.204866, Val Acc: 0.597938\n",
      "Epoch 3739 - Train Loss: 0.194960, Train Acc: 0.628205 | Val Loss: 0.204849, Val Acc: 0.608247\n",
      "Epoch 3740 - Train Loss: 0.194943, Train Acc: 0.628205 | Val Loss: 0.204833, Val Acc: 0.608247\n",
      "Epoch 3741 - Train Loss: 0.194925, Train Acc: 0.628205 | Val Loss: 0.204816, Val Acc: 0.608247\n",
      "Epoch 3742 - Train Loss: 0.194908, Train Acc: 0.628205 | Val Loss: 0.204799, Val Acc: 0.608247\n",
      "Epoch 3743 - Train Loss: 0.194891, Train Acc: 0.628205 | Val Loss: 0.204783, Val Acc: 0.608247\n",
      "Epoch 3744 - Train Loss: 0.194873, Train Acc: 0.628205 | Val Loss: 0.204766, Val Acc: 0.608247\n",
      "Epoch 3745 - Train Loss: 0.194856, Train Acc: 0.628205 | Val Loss: 0.204749, Val Acc: 0.608247\n",
      "Epoch 3746 - Train Loss: 0.194839, Train Acc: 0.628205 | Val Loss: 0.204732, Val Acc: 0.608247\n",
      "Epoch 3747 - Train Loss: 0.194821, Train Acc: 0.628205 | Val Loss: 0.204716, Val Acc: 0.608247\n",
      "Epoch 3748 - Train Loss: 0.194804, Train Acc: 0.628205 | Val Loss: 0.204699, Val Acc: 0.608247\n",
      "Epoch 3749 - Train Loss: 0.194787, Train Acc: 0.628205 | Val Loss: 0.204682, Val Acc: 0.608247\n",
      "Epoch 3750 - Train Loss: 0.194770, Train Acc: 0.628205 | Val Loss: 0.204666, Val Acc: 0.608247\n",
      "Epoch 3751 - Train Loss: 0.194752, Train Acc: 0.628205 | Val Loss: 0.204649, Val Acc: 0.608247\n",
      "Epoch 3752 - Train Loss: 0.194735, Train Acc: 0.628205 | Val Loss: 0.204632, Val Acc: 0.608247\n",
      "Epoch 3753 - Train Loss: 0.194718, Train Acc: 0.628205 | Val Loss: 0.204615, Val Acc: 0.608247\n",
      "Epoch 3754 - Train Loss: 0.194700, Train Acc: 0.628205 | Val Loss: 0.204599, Val Acc: 0.608247\n",
      "Epoch 3755 - Train Loss: 0.194683, Train Acc: 0.628205 | Val Loss: 0.204582, Val Acc: 0.608247\n",
      "Epoch 3756 - Train Loss: 0.194666, Train Acc: 0.628205 | Val Loss: 0.204565, Val Acc: 0.608247\n",
      "Epoch 3757 - Train Loss: 0.194648, Train Acc: 0.628205 | Val Loss: 0.204549, Val Acc: 0.608247\n",
      "Epoch 3758 - Train Loss: 0.194631, Train Acc: 0.628205 | Val Loss: 0.204532, Val Acc: 0.608247\n",
      "Epoch 3759 - Train Loss: 0.194614, Train Acc: 0.628205 | Val Loss: 0.204515, Val Acc: 0.608247\n",
      "Epoch 3760 - Train Loss: 0.194597, Train Acc: 0.628205 | Val Loss: 0.204499, Val Acc: 0.608247\n",
      "Epoch 3761 - Train Loss: 0.194579, Train Acc: 0.628205 | Val Loss: 0.204482, Val Acc: 0.608247\n",
      "Epoch 3762 - Train Loss: 0.194562, Train Acc: 0.628205 | Val Loss: 0.204466, Val Acc: 0.608247\n",
      "Epoch 3763 - Train Loss: 0.194545, Train Acc: 0.628205 | Val Loss: 0.204449, Val Acc: 0.608247\n",
      "Epoch 3764 - Train Loss: 0.194527, Train Acc: 0.628205 | Val Loss: 0.204432, Val Acc: 0.608247\n",
      "Epoch 3765 - Train Loss: 0.194510, Train Acc: 0.628205 | Val Loss: 0.204416, Val Acc: 0.608247\n",
      "Epoch 3766 - Train Loss: 0.194493, Train Acc: 0.628205 | Val Loss: 0.204399, Val Acc: 0.608247\n",
      "Epoch 3767 - Train Loss: 0.194476, Train Acc: 0.628205 | Val Loss: 0.204382, Val Acc: 0.608247\n",
      "Epoch 3768 - Train Loss: 0.194458, Train Acc: 0.628205 | Val Loss: 0.204366, Val Acc: 0.608247\n",
      "Epoch 3769 - Train Loss: 0.194441, Train Acc: 0.628205 | Val Loss: 0.204349, Val Acc: 0.608247\n",
      "Epoch 3770 - Train Loss: 0.194424, Train Acc: 0.628205 | Val Loss: 0.204332, Val Acc: 0.608247\n",
      "Epoch 3771 - Train Loss: 0.194407, Train Acc: 0.628205 | Val Loss: 0.204316, Val Acc: 0.608247\n",
      "Epoch 3772 - Train Loss: 0.194389, Train Acc: 0.628205 | Val Loss: 0.204299, Val Acc: 0.608247\n",
      "Epoch 3773 - Train Loss: 0.194372, Train Acc: 0.628205 | Val Loss: 0.204282, Val Acc: 0.608247\n",
      "Epoch 3774 - Train Loss: 0.194355, Train Acc: 0.628205 | Val Loss: 0.204266, Val Acc: 0.608247\n",
      "Epoch 3775 - Train Loss: 0.194338, Train Acc: 0.628205 | Val Loss: 0.204249, Val Acc: 0.608247\n",
      "Epoch 3776 - Train Loss: 0.194320, Train Acc: 0.628205 | Val Loss: 0.204233, Val Acc: 0.608247\n",
      "Epoch 3777 - Train Loss: 0.194303, Train Acc: 0.628205 | Val Loss: 0.204216, Val Acc: 0.608247\n",
      "Epoch 3778 - Train Loss: 0.194286, Train Acc: 0.628205 | Val Loss: 0.204199, Val Acc: 0.608247\n",
      "Epoch 3779 - Train Loss: 0.194269, Train Acc: 0.628205 | Val Loss: 0.204183, Val Acc: 0.608247\n",
      "Epoch 3780 - Train Loss: 0.194251, Train Acc: 0.628205 | Val Loss: 0.204166, Val Acc: 0.608247\n",
      "Epoch 3781 - Train Loss: 0.194234, Train Acc: 0.628205 | Val Loss: 0.204150, Val Acc: 0.608247\n",
      "Epoch 3782 - Train Loss: 0.194217, Train Acc: 0.628205 | Val Loss: 0.204133, Val Acc: 0.608247\n",
      "Epoch 3783 - Train Loss: 0.194200, Train Acc: 0.628205 | Val Loss: 0.204116, Val Acc: 0.608247\n",
      "Epoch 3784 - Train Loss: 0.194182, Train Acc: 0.628205 | Val Loss: 0.204100, Val Acc: 0.608247\n",
      "Epoch 3785 - Train Loss: 0.194165, Train Acc: 0.628205 | Val Loss: 0.204083, Val Acc: 0.618557\n",
      "Epoch 3786 - Train Loss: 0.194148, Train Acc: 0.628205 | Val Loss: 0.204067, Val Acc: 0.618557\n",
      "Epoch 3787 - Train Loss: 0.194131, Train Acc: 0.628205 | Val Loss: 0.204050, Val Acc: 0.618557\n",
      "Epoch 3788 - Train Loss: 0.194114, Train Acc: 0.628205 | Val Loss: 0.204033, Val Acc: 0.618557\n",
      "Epoch 3789 - Train Loss: 0.194096, Train Acc: 0.628205 | Val Loss: 0.204017, Val Acc: 0.618557\n",
      "Epoch 3790 - Train Loss: 0.194079, Train Acc: 0.628205 | Val Loss: 0.204000, Val Acc: 0.618557\n",
      "Epoch 3791 - Train Loss: 0.194062, Train Acc: 0.628205 | Val Loss: 0.203984, Val Acc: 0.618557\n",
      "Epoch 3792 - Train Loss: 0.194045, Train Acc: 0.628205 | Val Loss: 0.203967, Val Acc: 0.618557\n",
      "Epoch 3793 - Train Loss: 0.194027, Train Acc: 0.628205 | Val Loss: 0.203951, Val Acc: 0.618557\n",
      "Epoch 3794 - Train Loss: 0.194010, Train Acc: 0.628205 | Val Loss: 0.203934, Val Acc: 0.618557\n",
      "Epoch 3795 - Train Loss: 0.193993, Train Acc: 0.628205 | Val Loss: 0.203917, Val Acc: 0.618557\n",
      "Epoch 3796 - Train Loss: 0.193976, Train Acc: 0.628205 | Val Loss: 0.203901, Val Acc: 0.618557\n",
      "Epoch 3797 - Train Loss: 0.193959, Train Acc: 0.628205 | Val Loss: 0.203884, Val Acc: 0.618557\n",
      "Epoch 3798 - Train Loss: 0.193941, Train Acc: 0.628205 | Val Loss: 0.203868, Val Acc: 0.618557\n",
      "Epoch 3799 - Train Loss: 0.193924, Train Acc: 0.628205 | Val Loss: 0.203851, Val Acc: 0.618557\n",
      "Epoch 3800 - Train Loss: 0.193907, Train Acc: 0.628205 | Val Loss: 0.203835, Val Acc: 0.618557\n",
      "Epoch 3801 - Train Loss: 0.193890, Train Acc: 0.628205 | Val Loss: 0.203818, Val Acc: 0.618557\n",
      "Epoch 3802 - Train Loss: 0.193873, Train Acc: 0.628205 | Val Loss: 0.203802, Val Acc: 0.618557\n",
      "Epoch 3803 - Train Loss: 0.193855, Train Acc: 0.628205 | Val Loss: 0.203785, Val Acc: 0.618557\n",
      "Epoch 3804 - Train Loss: 0.193838, Train Acc: 0.628205 | Val Loss: 0.203768, Val Acc: 0.618557\n",
      "Epoch 3805 - Train Loss: 0.193821, Train Acc: 0.628205 | Val Loss: 0.203752, Val Acc: 0.618557\n",
      "Epoch 3806 - Train Loss: 0.193804, Train Acc: 0.629487 | Val Loss: 0.203735, Val Acc: 0.618557\n",
      "Epoch 3807 - Train Loss: 0.193787, Train Acc: 0.629487 | Val Loss: 0.203719, Val Acc: 0.618557\n",
      "Epoch 3808 - Train Loss: 0.193770, Train Acc: 0.629487 | Val Loss: 0.203702, Val Acc: 0.618557\n",
      "Epoch 3809 - Train Loss: 0.193752, Train Acc: 0.629487 | Val Loss: 0.203686, Val Acc: 0.618557\n",
      "Epoch 3810 - Train Loss: 0.193735, Train Acc: 0.629487 | Val Loss: 0.203669, Val Acc: 0.618557\n",
      "Epoch 3811 - Train Loss: 0.193718, Train Acc: 0.629487 | Val Loss: 0.203653, Val Acc: 0.618557\n",
      "Epoch 3812 - Train Loss: 0.193701, Train Acc: 0.629487 | Val Loss: 0.203636, Val Acc: 0.618557\n",
      "Epoch 3813 - Train Loss: 0.193684, Train Acc: 0.629487 | Val Loss: 0.203620, Val Acc: 0.618557\n",
      "Epoch 3814 - Train Loss: 0.193667, Train Acc: 0.629487 | Val Loss: 0.203603, Val Acc: 0.618557\n",
      "Epoch 3815 - Train Loss: 0.193649, Train Acc: 0.629487 | Val Loss: 0.203587, Val Acc: 0.618557\n",
      "Epoch 3816 - Train Loss: 0.193632, Train Acc: 0.629487 | Val Loss: 0.203570, Val Acc: 0.618557\n",
      "Epoch 3817 - Train Loss: 0.193615, Train Acc: 0.629487 | Val Loss: 0.203554, Val Acc: 0.618557\n",
      "Epoch 3818 - Train Loss: 0.193598, Train Acc: 0.629487 | Val Loss: 0.203537, Val Acc: 0.618557\n",
      "Epoch 3819 - Train Loss: 0.193581, Train Acc: 0.629487 | Val Loss: 0.203521, Val Acc: 0.618557\n",
      "Epoch 3820 - Train Loss: 0.193564, Train Acc: 0.629487 | Val Loss: 0.203504, Val Acc: 0.618557\n",
      "Epoch 3821 - Train Loss: 0.193547, Train Acc: 0.629487 | Val Loss: 0.203488, Val Acc: 0.618557\n",
      "Epoch 3822 - Train Loss: 0.193529, Train Acc: 0.629487 | Val Loss: 0.203471, Val Acc: 0.618557\n",
      "Epoch 3823 - Train Loss: 0.193512, Train Acc: 0.629487 | Val Loss: 0.203455, Val Acc: 0.618557\n",
      "Epoch 3824 - Train Loss: 0.193495, Train Acc: 0.629487 | Val Loss: 0.203438, Val Acc: 0.618557\n",
      "Epoch 3825 - Train Loss: 0.193478, Train Acc: 0.629487 | Val Loss: 0.203422, Val Acc: 0.618557\n",
      "Epoch 3826 - Train Loss: 0.193461, Train Acc: 0.629487 | Val Loss: 0.203405, Val Acc: 0.618557\n",
      "Epoch 3827 - Train Loss: 0.193444, Train Acc: 0.629487 | Val Loss: 0.203389, Val Acc: 0.618557\n",
      "Epoch 3828 - Train Loss: 0.193427, Train Acc: 0.629487 | Val Loss: 0.203372, Val Acc: 0.618557\n",
      "Epoch 3829 - Train Loss: 0.193410, Train Acc: 0.629487 | Val Loss: 0.203356, Val Acc: 0.618557\n",
      "Epoch 3830 - Train Loss: 0.193392, Train Acc: 0.629487 | Val Loss: 0.203339, Val Acc: 0.618557\n",
      "Epoch 3831 - Train Loss: 0.193375, Train Acc: 0.629487 | Val Loss: 0.203323, Val Acc: 0.618557\n",
      "Epoch 3832 - Train Loss: 0.193358, Train Acc: 0.629487 | Val Loss: 0.203306, Val Acc: 0.618557\n",
      "Epoch 3833 - Train Loss: 0.193341, Train Acc: 0.629487 | Val Loss: 0.203290, Val Acc: 0.618557\n",
      "Epoch 3834 - Train Loss: 0.193324, Train Acc: 0.629487 | Val Loss: 0.203274, Val Acc: 0.618557\n",
      "Epoch 3835 - Train Loss: 0.193307, Train Acc: 0.629487 | Val Loss: 0.203257, Val Acc: 0.618557\n",
      "Epoch 3836 - Train Loss: 0.193290, Train Acc: 0.629487 | Val Loss: 0.203241, Val Acc: 0.618557\n",
      "Epoch 3837 - Train Loss: 0.193273, Train Acc: 0.629487 | Val Loss: 0.203224, Val Acc: 0.618557\n",
      "Epoch 3838 - Train Loss: 0.193256, Train Acc: 0.629487 | Val Loss: 0.203208, Val Acc: 0.618557\n",
      "Epoch 3839 - Train Loss: 0.193239, Train Acc: 0.629487 | Val Loss: 0.203191, Val Acc: 0.618557\n",
      "Epoch 3840 - Train Loss: 0.193221, Train Acc: 0.629487 | Val Loss: 0.203175, Val Acc: 0.618557\n",
      "Epoch 3841 - Train Loss: 0.193204, Train Acc: 0.629487 | Val Loss: 0.203158, Val Acc: 0.628866\n",
      "Epoch 3842 - Train Loss: 0.193187, Train Acc: 0.629487 | Val Loss: 0.203142, Val Acc: 0.628866\n",
      "Epoch 3843 - Train Loss: 0.193170, Train Acc: 0.629487 | Val Loss: 0.203125, Val Acc: 0.628866\n",
      "Epoch 3844 - Train Loss: 0.193153, Train Acc: 0.629487 | Val Loss: 0.203109, Val Acc: 0.628866\n",
      "Epoch 3845 - Train Loss: 0.193136, Train Acc: 0.629487 | Val Loss: 0.203093, Val Acc: 0.628866\n",
      "Epoch 3846 - Train Loss: 0.193119, Train Acc: 0.630769 | Val Loss: 0.203076, Val Acc: 0.628866\n",
      "Epoch 3847 - Train Loss: 0.193102, Train Acc: 0.630769 | Val Loss: 0.203060, Val Acc: 0.628866\n",
      "Epoch 3848 - Train Loss: 0.193085, Train Acc: 0.630769 | Val Loss: 0.203043, Val Acc: 0.628866\n",
      "Epoch 3849 - Train Loss: 0.193068, Train Acc: 0.630769 | Val Loss: 0.203027, Val Acc: 0.628866\n",
      "Epoch 3850 - Train Loss: 0.193051, Train Acc: 0.630769 | Val Loss: 0.203011, Val Acc: 0.628866\n",
      "Epoch 3851 - Train Loss: 0.193034, Train Acc: 0.630769 | Val Loss: 0.202994, Val Acc: 0.628866\n",
      "Epoch 3852 - Train Loss: 0.193017, Train Acc: 0.630769 | Val Loss: 0.202978, Val Acc: 0.628866\n",
      "Epoch 3853 - Train Loss: 0.193000, Train Acc: 0.630769 | Val Loss: 0.202961, Val Acc: 0.628866\n",
      "Epoch 3854 - Train Loss: 0.192983, Train Acc: 0.630769 | Val Loss: 0.202945, Val Acc: 0.628866\n",
      "Epoch 3855 - Train Loss: 0.192965, Train Acc: 0.630769 | Val Loss: 0.202928, Val Acc: 0.628866\n",
      "Epoch 3856 - Train Loss: 0.192948, Train Acc: 0.630769 | Val Loss: 0.202912, Val Acc: 0.628866\n",
      "Epoch 3857 - Train Loss: 0.192931, Train Acc: 0.630769 | Val Loss: 0.202896, Val Acc: 0.628866\n",
      "Epoch 3858 - Train Loss: 0.192914, Train Acc: 0.630769 | Val Loss: 0.202879, Val Acc: 0.628866\n",
      "Epoch 3859 - Train Loss: 0.192897, Train Acc: 0.630769 | Val Loss: 0.202863, Val Acc: 0.628866\n",
      "Epoch 3860 - Train Loss: 0.192880, Train Acc: 0.630769 | Val Loss: 0.202846, Val Acc: 0.628866\n",
      "Epoch 3861 - Train Loss: 0.192863, Train Acc: 0.630769 | Val Loss: 0.202830, Val Acc: 0.628866\n",
      "Epoch 3862 - Train Loss: 0.192846, Train Acc: 0.630769 | Val Loss: 0.202814, Val Acc: 0.628866\n",
      "Epoch 3863 - Train Loss: 0.192829, Train Acc: 0.630769 | Val Loss: 0.202797, Val Acc: 0.628866\n",
      "Epoch 3864 - Train Loss: 0.192812, Train Acc: 0.630769 | Val Loss: 0.202781, Val Acc: 0.628866\n",
      "Epoch 3865 - Train Loss: 0.192795, Train Acc: 0.630769 | Val Loss: 0.202765, Val Acc: 0.628866\n",
      "Epoch 3866 - Train Loss: 0.192778, Train Acc: 0.630769 | Val Loss: 0.202748, Val Acc: 0.628866\n",
      "Epoch 3867 - Train Loss: 0.192761, Train Acc: 0.630769 | Val Loss: 0.202732, Val Acc: 0.628866\n",
      "Epoch 3868 - Train Loss: 0.192744, Train Acc: 0.630769 | Val Loss: 0.202715, Val Acc: 0.628866\n",
      "Epoch 3869 - Train Loss: 0.192727, Train Acc: 0.630769 | Val Loss: 0.202699, Val Acc: 0.628866\n",
      "Epoch 3870 - Train Loss: 0.192710, Train Acc: 0.630769 | Val Loss: 0.202683, Val Acc: 0.628866\n",
      "Epoch 3871 - Train Loss: 0.192693, Train Acc: 0.630769 | Val Loss: 0.202666, Val Acc: 0.628866\n",
      "Epoch 3872 - Train Loss: 0.192676, Train Acc: 0.630769 | Val Loss: 0.202650, Val Acc: 0.628866\n",
      "Epoch 3873 - Train Loss: 0.192659, Train Acc: 0.630769 | Val Loss: 0.202634, Val Acc: 0.628866\n",
      "Epoch 3874 - Train Loss: 0.192642, Train Acc: 0.630769 | Val Loss: 0.202617, Val Acc: 0.628866\n",
      "Epoch 3875 - Train Loss: 0.192625, Train Acc: 0.630769 | Val Loss: 0.202601, Val Acc: 0.628866\n",
      "Epoch 3876 - Train Loss: 0.192608, Train Acc: 0.630769 | Val Loss: 0.202585, Val Acc: 0.628866\n",
      "Epoch 3877 - Train Loss: 0.192591, Train Acc: 0.630769 | Val Loss: 0.202568, Val Acc: 0.628866\n",
      "Epoch 3878 - Train Loss: 0.192574, Train Acc: 0.630769 | Val Loss: 0.202552, Val Acc: 0.628866\n",
      "Epoch 3879 - Train Loss: 0.192557, Train Acc: 0.630769 | Val Loss: 0.202535, Val Acc: 0.628866\n",
      "Epoch 3880 - Train Loss: 0.192540, Train Acc: 0.630769 | Val Loss: 0.202519, Val Acc: 0.628866\n",
      "Epoch 3881 - Train Loss: 0.192523, Train Acc: 0.630769 | Val Loss: 0.202503, Val Acc: 0.628866\n",
      "Epoch 3882 - Train Loss: 0.192506, Train Acc: 0.630769 | Val Loss: 0.202486, Val Acc: 0.628866\n",
      "Epoch 3883 - Train Loss: 0.192489, Train Acc: 0.630769 | Val Loss: 0.202470, Val Acc: 0.628866\n",
      "Epoch 3884 - Train Loss: 0.192472, Train Acc: 0.630769 | Val Loss: 0.202454, Val Acc: 0.628866\n",
      "Epoch 3885 - Train Loss: 0.192455, Train Acc: 0.630769 | Val Loss: 0.202437, Val Acc: 0.628866\n",
      "Epoch 3886 - Train Loss: 0.192438, Train Acc: 0.630769 | Val Loss: 0.202421, Val Acc: 0.628866\n",
      "Epoch 3887 - Train Loss: 0.192421, Train Acc: 0.630769 | Val Loss: 0.202405, Val Acc: 0.628866\n",
      "Epoch 3888 - Train Loss: 0.192404, Train Acc: 0.630769 | Val Loss: 0.202388, Val Acc: 0.628866\n",
      "Epoch 3889 - Train Loss: 0.192387, Train Acc: 0.630769 | Val Loss: 0.202372, Val Acc: 0.628866\n",
      "Epoch 3890 - Train Loss: 0.192370, Train Acc: 0.630769 | Val Loss: 0.202356, Val Acc: 0.628866\n",
      "Epoch 3891 - Train Loss: 0.192353, Train Acc: 0.630769 | Val Loss: 0.202339, Val Acc: 0.628866\n",
      "Epoch 3892 - Train Loss: 0.192336, Train Acc: 0.630769 | Val Loss: 0.202323, Val Acc: 0.628866\n",
      "Epoch 3893 - Train Loss: 0.192319, Train Acc: 0.632051 | Val Loss: 0.202307, Val Acc: 0.628866\n",
      "Epoch 3894 - Train Loss: 0.192302, Train Acc: 0.632051 | Val Loss: 0.202291, Val Acc: 0.628866\n",
      "Epoch 3895 - Train Loss: 0.192285, Train Acc: 0.632051 | Val Loss: 0.202274, Val Acc: 0.628866\n",
      "Epoch 3896 - Train Loss: 0.192268, Train Acc: 0.632051 | Val Loss: 0.202258, Val Acc: 0.628866\n",
      "Epoch 3897 - Train Loss: 0.192251, Train Acc: 0.632051 | Val Loss: 0.202242, Val Acc: 0.628866\n",
      "Epoch 3898 - Train Loss: 0.192235, Train Acc: 0.632051 | Val Loss: 0.202225, Val Acc: 0.628866\n",
      "Epoch 3899 - Train Loss: 0.192218, Train Acc: 0.632051 | Val Loss: 0.202209, Val Acc: 0.628866\n",
      "Epoch 3900 - Train Loss: 0.192201, Train Acc: 0.632051 | Val Loss: 0.202193, Val Acc: 0.628866\n",
      "Epoch 3901 - Train Loss: 0.192184, Train Acc: 0.632051 | Val Loss: 0.202177, Val Acc: 0.639175\n",
      "Epoch 3902 - Train Loss: 0.192167, Train Acc: 0.632051 | Val Loss: 0.202160, Val Acc: 0.639175\n",
      "Epoch 3903 - Train Loss: 0.192150, Train Acc: 0.632051 | Val Loss: 0.202144, Val Acc: 0.639175\n",
      "Epoch 3904 - Train Loss: 0.192133, Train Acc: 0.632051 | Val Loss: 0.202128, Val Acc: 0.639175\n",
      "Epoch 3905 - Train Loss: 0.192116, Train Acc: 0.632051 | Val Loss: 0.202112, Val Acc: 0.639175\n",
      "Epoch 3906 - Train Loss: 0.192099, Train Acc: 0.632051 | Val Loss: 0.202095, Val Acc: 0.639175\n",
      "Epoch 3907 - Train Loss: 0.192082, Train Acc: 0.632051 | Val Loss: 0.202079, Val Acc: 0.639175\n",
      "Epoch 3908 - Train Loss: 0.192065, Train Acc: 0.632051 | Val Loss: 0.202063, Val Acc: 0.639175\n",
      "Epoch 3909 - Train Loss: 0.192048, Train Acc: 0.632051 | Val Loss: 0.202047, Val Acc: 0.639175\n",
      "Epoch 3910 - Train Loss: 0.192031, Train Acc: 0.632051 | Val Loss: 0.202030, Val Acc: 0.639175\n",
      "Epoch 3911 - Train Loss: 0.192014, Train Acc: 0.632051 | Val Loss: 0.202014, Val Acc: 0.639175\n",
      "Epoch 3912 - Train Loss: 0.191997, Train Acc: 0.632051 | Val Loss: 0.201998, Val Acc: 0.639175\n",
      "Epoch 3913 - Train Loss: 0.191981, Train Acc: 0.632051 | Val Loss: 0.201982, Val Acc: 0.639175\n",
      "Epoch 3914 - Train Loss: 0.191964, Train Acc: 0.632051 | Val Loss: 0.201966, Val Acc: 0.639175\n",
      "Epoch 3915 - Train Loss: 0.191947, Train Acc: 0.632051 | Val Loss: 0.201949, Val Acc: 0.639175\n",
      "Epoch 3916 - Train Loss: 0.191930, Train Acc: 0.632051 | Val Loss: 0.201933, Val Acc: 0.639175\n",
      "Epoch 3917 - Train Loss: 0.191913, Train Acc: 0.632051 | Val Loss: 0.201917, Val Acc: 0.639175\n",
      "Epoch 3918 - Train Loss: 0.191896, Train Acc: 0.632051 | Val Loss: 0.201901, Val Acc: 0.639175\n",
      "Epoch 3919 - Train Loss: 0.191879, Train Acc: 0.632051 | Val Loss: 0.201885, Val Acc: 0.639175\n",
      "Epoch 3920 - Train Loss: 0.191862, Train Acc: 0.632051 | Val Loss: 0.201868, Val Acc: 0.639175\n",
      "Epoch 3921 - Train Loss: 0.191845, Train Acc: 0.632051 | Val Loss: 0.201852, Val Acc: 0.639175\n",
      "Epoch 3922 - Train Loss: 0.191828, Train Acc: 0.632051 | Val Loss: 0.201836, Val Acc: 0.639175\n",
      "Epoch 3923 - Train Loss: 0.191811, Train Acc: 0.632051 | Val Loss: 0.201820, Val Acc: 0.639175\n",
      "Epoch 3924 - Train Loss: 0.191795, Train Acc: 0.632051 | Val Loss: 0.201804, Val Acc: 0.639175\n",
      "Epoch 3925 - Train Loss: 0.191778, Train Acc: 0.632051 | Val Loss: 0.201788, Val Acc: 0.639175\n",
      "Epoch 3926 - Train Loss: 0.191761, Train Acc: 0.632051 | Val Loss: 0.201771, Val Acc: 0.639175\n",
      "Epoch 3927 - Train Loss: 0.191744, Train Acc: 0.632051 | Val Loss: 0.201755, Val Acc: 0.639175\n",
      "Epoch 3928 - Train Loss: 0.191727, Train Acc: 0.632051 | Val Loss: 0.201739, Val Acc: 0.639175\n",
      "Epoch 3929 - Train Loss: 0.191710, Train Acc: 0.632051 | Val Loss: 0.201723, Val Acc: 0.639175\n",
      "Epoch 3930 - Train Loss: 0.191693, Train Acc: 0.632051 | Val Loss: 0.201707, Val Acc: 0.639175\n",
      "Epoch 3931 - Train Loss: 0.191676, Train Acc: 0.632051 | Val Loss: 0.201691, Val Acc: 0.639175\n",
      "Epoch 3932 - Train Loss: 0.191659, Train Acc: 0.632051 | Val Loss: 0.201674, Val Acc: 0.639175\n",
      "Epoch 3933 - Train Loss: 0.191643, Train Acc: 0.632051 | Val Loss: 0.201658, Val Acc: 0.639175\n",
      "Epoch 3934 - Train Loss: 0.191626, Train Acc: 0.632051 | Val Loss: 0.201642, Val Acc: 0.639175\n",
      "Epoch 3935 - Train Loss: 0.191609, Train Acc: 0.632051 | Val Loss: 0.201626, Val Acc: 0.639175\n",
      "Epoch 3936 - Train Loss: 0.191592, Train Acc: 0.632051 | Val Loss: 0.201610, Val Acc: 0.639175\n",
      "Epoch 3937 - Train Loss: 0.191575, Train Acc: 0.632051 | Val Loss: 0.201594, Val Acc: 0.639175\n",
      "Epoch 3938 - Train Loss: 0.191558, Train Acc: 0.632051 | Val Loss: 0.201577, Val Acc: 0.639175\n",
      "Epoch 3939 - Train Loss: 0.191541, Train Acc: 0.632051 | Val Loss: 0.201561, Val Acc: 0.639175\n",
      "Epoch 3940 - Train Loss: 0.191524, Train Acc: 0.632051 | Val Loss: 0.201545, Val Acc: 0.639175\n",
      "Epoch 3941 - Train Loss: 0.191507, Train Acc: 0.632051 | Val Loss: 0.201529, Val Acc: 0.639175\n",
      "Epoch 3942 - Train Loss: 0.191491, Train Acc: 0.632051 | Val Loss: 0.201513, Val Acc: 0.639175\n",
      "Epoch 3943 - Train Loss: 0.191474, Train Acc: 0.632051 | Val Loss: 0.201497, Val Acc: 0.639175\n",
      "Epoch 3944 - Train Loss: 0.191457, Train Acc: 0.632051 | Val Loss: 0.201481, Val Acc: 0.639175\n",
      "Epoch 3945 - Train Loss: 0.191440, Train Acc: 0.632051 | Val Loss: 0.201464, Val Acc: 0.639175\n",
      "Epoch 3946 - Train Loss: 0.191423, Train Acc: 0.632051 | Val Loss: 0.201448, Val Acc: 0.639175\n",
      "Epoch 3947 - Train Loss: 0.191406, Train Acc: 0.632051 | Val Loss: 0.201432, Val Acc: 0.639175\n",
      "Epoch 3948 - Train Loss: 0.191389, Train Acc: 0.632051 | Val Loss: 0.201416, Val Acc: 0.639175\n",
      "Epoch 3949 - Train Loss: 0.191373, Train Acc: 0.632051 | Val Loss: 0.201400, Val Acc: 0.639175\n",
      "Epoch 3950 - Train Loss: 0.191356, Train Acc: 0.632051 | Val Loss: 0.201384, Val Acc: 0.639175\n",
      "Epoch 3951 - Train Loss: 0.191339, Train Acc: 0.632051 | Val Loss: 0.201368, Val Acc: 0.639175\n",
      "Epoch 3952 - Train Loss: 0.191322, Train Acc: 0.632051 | Val Loss: 0.201351, Val Acc: 0.639175\n",
      "Epoch 3953 - Train Loss: 0.191305, Train Acc: 0.632051 | Val Loss: 0.201335, Val Acc: 0.639175\n",
      "Epoch 3954 - Train Loss: 0.191288, Train Acc: 0.632051 | Val Loss: 0.201319, Val Acc: 0.639175\n",
      "Epoch 3955 - Train Loss: 0.191272, Train Acc: 0.632051 | Val Loss: 0.201303, Val Acc: 0.639175\n",
      "Epoch 3956 - Train Loss: 0.191255, Train Acc: 0.632051 | Val Loss: 0.201287, Val Acc: 0.639175\n",
      "Epoch 3957 - Train Loss: 0.191238, Train Acc: 0.632051 | Val Loss: 0.201271, Val Acc: 0.639175\n",
      "Epoch 3958 - Train Loss: 0.191221, Train Acc: 0.632051 | Val Loss: 0.201255, Val Acc: 0.639175\n",
      "Epoch 3959 - Train Loss: 0.191204, Train Acc: 0.632051 | Val Loss: 0.201239, Val Acc: 0.639175\n",
      "Epoch 3960 - Train Loss: 0.191187, Train Acc: 0.632051 | Val Loss: 0.201223, Val Acc: 0.639175\n",
      "Epoch 3961 - Train Loss: 0.191171, Train Acc: 0.632051 | Val Loss: 0.201206, Val Acc: 0.639175\n",
      "Epoch 3962 - Train Loss: 0.191154, Train Acc: 0.632051 | Val Loss: 0.201190, Val Acc: 0.639175\n",
      "Epoch 3963 - Train Loss: 0.191137, Train Acc: 0.632051 | Val Loss: 0.201174, Val Acc: 0.639175\n",
      "Epoch 3964 - Train Loss: 0.191120, Train Acc: 0.632051 | Val Loss: 0.201158, Val Acc: 0.639175\n",
      "Epoch 3965 - Train Loss: 0.191103, Train Acc: 0.632051 | Val Loss: 0.201142, Val Acc: 0.639175\n",
      "Epoch 3966 - Train Loss: 0.191087, Train Acc: 0.632051 | Val Loss: 0.201126, Val Acc: 0.639175\n",
      "Epoch 3967 - Train Loss: 0.191070, Train Acc: 0.632051 | Val Loss: 0.201110, Val Acc: 0.639175\n",
      "Epoch 3968 - Train Loss: 0.191053, Train Acc: 0.632051 | Val Loss: 0.201094, Val Acc: 0.639175\n",
      "Epoch 3969 - Train Loss: 0.191036, Train Acc: 0.632051 | Val Loss: 0.201078, Val Acc: 0.639175\n",
      "Epoch 3970 - Train Loss: 0.191019, Train Acc: 0.632051 | Val Loss: 0.201062, Val Acc: 0.639175\n",
      "Epoch 3971 - Train Loss: 0.191002, Train Acc: 0.632051 | Val Loss: 0.201045, Val Acc: 0.639175\n",
      "Epoch 3972 - Train Loss: 0.190986, Train Acc: 0.632051 | Val Loss: 0.201029, Val Acc: 0.639175\n",
      "Epoch 3973 - Train Loss: 0.190969, Train Acc: 0.632051 | Val Loss: 0.201013, Val Acc: 0.639175\n",
      "Epoch 3974 - Train Loss: 0.190952, Train Acc: 0.632051 | Val Loss: 0.200997, Val Acc: 0.639175\n",
      "Epoch 3975 - Train Loss: 0.190935, Train Acc: 0.632051 | Val Loss: 0.200981, Val Acc: 0.639175\n",
      "Epoch 3976 - Train Loss: 0.190918, Train Acc: 0.632051 | Val Loss: 0.200965, Val Acc: 0.639175\n",
      "Epoch 3977 - Train Loss: 0.190902, Train Acc: 0.632051 | Val Loss: 0.200949, Val Acc: 0.639175\n",
      "Epoch 3978 - Train Loss: 0.190885, Train Acc: 0.632051 | Val Loss: 0.200933, Val Acc: 0.639175\n",
      "Epoch 3979 - Train Loss: 0.190868, Train Acc: 0.632051 | Val Loss: 0.200917, Val Acc: 0.639175\n",
      "Epoch 3980 - Train Loss: 0.190851, Train Acc: 0.632051 | Val Loss: 0.200901, Val Acc: 0.639175\n",
      "Epoch 3981 - Train Loss: 0.190835, Train Acc: 0.632051 | Val Loss: 0.200885, Val Acc: 0.639175\n",
      "Epoch 3982 - Train Loss: 0.190818, Train Acc: 0.632051 | Val Loss: 0.200869, Val Acc: 0.639175\n",
      "Epoch 3983 - Train Loss: 0.190801, Train Acc: 0.632051 | Val Loss: 0.200853, Val Acc: 0.639175\n",
      "Epoch 3984 - Train Loss: 0.190784, Train Acc: 0.632051 | Val Loss: 0.200837, Val Acc: 0.639175\n",
      "Epoch 3985 - Train Loss: 0.190767, Train Acc: 0.632051 | Val Loss: 0.200820, Val Acc: 0.639175\n",
      "Epoch 3986 - Train Loss: 0.190751, Train Acc: 0.632051 | Val Loss: 0.200804, Val Acc: 0.639175\n",
      "Epoch 3987 - Train Loss: 0.190734, Train Acc: 0.632051 | Val Loss: 0.200788, Val Acc: 0.639175\n",
      "Epoch 3988 - Train Loss: 0.190717, Train Acc: 0.632051 | Val Loss: 0.200772, Val Acc: 0.639175\n",
      "Epoch 3989 - Train Loss: 0.190700, Train Acc: 0.632051 | Val Loss: 0.200756, Val Acc: 0.639175\n",
      "Epoch 3990 - Train Loss: 0.190684, Train Acc: 0.632051 | Val Loss: 0.200740, Val Acc: 0.639175\n",
      "Epoch 3991 - Train Loss: 0.190667, Train Acc: 0.632051 | Val Loss: 0.200724, Val Acc: 0.639175\n",
      "Epoch 3992 - Train Loss: 0.190650, Train Acc: 0.632051 | Val Loss: 0.200708, Val Acc: 0.639175\n",
      "Epoch 3993 - Train Loss: 0.190633, Train Acc: 0.632051 | Val Loss: 0.200692, Val Acc: 0.639175\n",
      "Epoch 3994 - Train Loss: 0.190617, Train Acc: 0.632051 | Val Loss: 0.200676, Val Acc: 0.639175\n",
      "Epoch 3995 - Train Loss: 0.190600, Train Acc: 0.632051 | Val Loss: 0.200660, Val Acc: 0.639175\n",
      "Epoch 3996 - Train Loss: 0.190583, Train Acc: 0.632051 | Val Loss: 0.200644, Val Acc: 0.639175\n",
      "Epoch 3997 - Train Loss: 0.190566, Train Acc: 0.632051 | Val Loss: 0.200628, Val Acc: 0.639175\n",
      "Epoch 3998 - Train Loss: 0.190550, Train Acc: 0.633333 | Val Loss: 0.200612, Val Acc: 0.639175\n",
      "Epoch 3999 - Train Loss: 0.190533, Train Acc: 0.633333 | Val Loss: 0.200596, Val Acc: 0.639175\n",
      "Epoch 4000 - Train Loss: 0.190516, Train Acc: 0.633333 | Val Loss: 0.200580, Val Acc: 0.639175\n",
      "Epoch 4001 - Train Loss: 0.190499, Train Acc: 0.633333 | Val Loss: 0.200564, Val Acc: 0.639175\n",
      "Epoch 4002 - Train Loss: 0.190483, Train Acc: 0.633333 | Val Loss: 0.200548, Val Acc: 0.639175\n",
      "Epoch 4003 - Train Loss: 0.190466, Train Acc: 0.633333 | Val Loss: 0.200532, Val Acc: 0.639175\n",
      "Epoch 4004 - Train Loss: 0.190449, Train Acc: 0.633333 | Val Loss: 0.200516, Val Acc: 0.639175\n",
      "Epoch 4005 - Train Loss: 0.190433, Train Acc: 0.633333 | Val Loss: 0.200500, Val Acc: 0.639175\n",
      "Epoch 4006 - Train Loss: 0.190416, Train Acc: 0.633333 | Val Loss: 0.200484, Val Acc: 0.639175\n",
      "Epoch 4007 - Train Loss: 0.190399, Train Acc: 0.633333 | Val Loss: 0.200468, Val Acc: 0.639175\n",
      "Epoch 4008 - Train Loss: 0.190382, Train Acc: 0.634615 | Val Loss: 0.200452, Val Acc: 0.639175\n",
      "Epoch 4009 - Train Loss: 0.190366, Train Acc: 0.634615 | Val Loss: 0.200436, Val Acc: 0.639175\n",
      "Epoch 4010 - Train Loss: 0.190349, Train Acc: 0.634615 | Val Loss: 0.200420, Val Acc: 0.639175\n",
      "Epoch 4011 - Train Loss: 0.190332, Train Acc: 0.634615 | Val Loss: 0.200404, Val Acc: 0.639175\n",
      "Epoch 4012 - Train Loss: 0.190315, Train Acc: 0.634615 | Val Loss: 0.200388, Val Acc: 0.639175\n",
      "Epoch 4013 - Train Loss: 0.190299, Train Acc: 0.634615 | Val Loss: 0.200372, Val Acc: 0.639175\n",
      "Epoch 4014 - Train Loss: 0.190282, Train Acc: 0.634615 | Val Loss: 0.200356, Val Acc: 0.639175\n",
      "Epoch 4015 - Train Loss: 0.190265, Train Acc: 0.634615 | Val Loss: 0.200340, Val Acc: 0.639175\n",
      "Epoch 4016 - Train Loss: 0.190249, Train Acc: 0.634615 | Val Loss: 0.200324, Val Acc: 0.639175\n",
      "Epoch 4017 - Train Loss: 0.190232, Train Acc: 0.634615 | Val Loss: 0.200308, Val Acc: 0.639175\n",
      "Epoch 4018 - Train Loss: 0.190215, Train Acc: 0.634615 | Val Loss: 0.200292, Val Acc: 0.639175\n",
      "Epoch 4019 - Train Loss: 0.190199, Train Acc: 0.634615 | Val Loss: 0.200276, Val Acc: 0.639175\n",
      "Epoch 4020 - Train Loss: 0.190182, Train Acc: 0.634615 | Val Loss: 0.200260, Val Acc: 0.639175\n",
      "Epoch 4021 - Train Loss: 0.190165, Train Acc: 0.634615 | Val Loss: 0.200244, Val Acc: 0.639175\n",
      "Epoch 4022 - Train Loss: 0.190149, Train Acc: 0.634615 | Val Loss: 0.200228, Val Acc: 0.639175\n",
      "Epoch 4023 - Train Loss: 0.190132, Train Acc: 0.634615 | Val Loss: 0.200212, Val Acc: 0.639175\n",
      "Epoch 4024 - Train Loss: 0.190115, Train Acc: 0.634615 | Val Loss: 0.200196, Val Acc: 0.639175\n",
      "Epoch 4025 - Train Loss: 0.190098, Train Acc: 0.634615 | Val Loss: 0.200180, Val Acc: 0.639175\n",
      "Epoch 4026 - Train Loss: 0.190082, Train Acc: 0.634615 | Val Loss: 0.200164, Val Acc: 0.639175\n",
      "Epoch 4027 - Train Loss: 0.190065, Train Acc: 0.634615 | Val Loss: 0.200148, Val Acc: 0.639175\n",
      "Epoch 4028 - Train Loss: 0.190048, Train Acc: 0.634615 | Val Loss: 0.200132, Val Acc: 0.639175\n",
      "Epoch 4029 - Train Loss: 0.190032, Train Acc: 0.634615 | Val Loss: 0.200117, Val Acc: 0.639175\n",
      "Epoch 4030 - Train Loss: 0.190015, Train Acc: 0.634615 | Val Loss: 0.200101, Val Acc: 0.639175\n",
      "Epoch 4031 - Train Loss: 0.189998, Train Acc: 0.634615 | Val Loss: 0.200085, Val Acc: 0.639175\n",
      "Epoch 4032 - Train Loss: 0.189982, Train Acc: 0.634615 | Val Loss: 0.200069, Val Acc: 0.639175\n",
      "Epoch 4033 - Train Loss: 0.189965, Train Acc: 0.634615 | Val Loss: 0.200053, Val Acc: 0.639175\n",
      "Epoch 4034 - Train Loss: 0.189948, Train Acc: 0.634615 | Val Loss: 0.200037, Val Acc: 0.639175\n",
      "Epoch 4035 - Train Loss: 0.189932, Train Acc: 0.634615 | Val Loss: 0.200021, Val Acc: 0.639175\n",
      "Epoch 4036 - Train Loss: 0.189915, Train Acc: 0.634615 | Val Loss: 0.200005, Val Acc: 0.639175\n",
      "Epoch 4037 - Train Loss: 0.189898, Train Acc: 0.634615 | Val Loss: 0.199989, Val Acc: 0.639175\n",
      "Epoch 4038 - Train Loss: 0.189882, Train Acc: 0.634615 | Val Loss: 0.199973, Val Acc: 0.639175\n",
      "Epoch 4039 - Train Loss: 0.189865, Train Acc: 0.634615 | Val Loss: 0.199957, Val Acc: 0.639175\n",
      "Epoch 4040 - Train Loss: 0.189849, Train Acc: 0.634615 | Val Loss: 0.199941, Val Acc: 0.639175\n",
      "Epoch 4041 - Train Loss: 0.189832, Train Acc: 0.634615 | Val Loss: 0.199925, Val Acc: 0.639175\n",
      "Epoch 4042 - Train Loss: 0.189815, Train Acc: 0.634615 | Val Loss: 0.199910, Val Acc: 0.639175\n",
      "Epoch 4043 - Train Loss: 0.189799, Train Acc: 0.634615 | Val Loss: 0.199894, Val Acc: 0.639175\n",
      "Epoch 4044 - Train Loss: 0.189782, Train Acc: 0.634615 | Val Loss: 0.199878, Val Acc: 0.639175\n",
      "Epoch 4045 - Train Loss: 0.189765, Train Acc: 0.634615 | Val Loss: 0.199862, Val Acc: 0.639175\n",
      "Epoch 4046 - Train Loss: 0.189749, Train Acc: 0.634615 | Val Loss: 0.199846, Val Acc: 0.639175\n",
      "Epoch 4047 - Train Loss: 0.189732, Train Acc: 0.634615 | Val Loss: 0.199830, Val Acc: 0.639175\n",
      "Epoch 4048 - Train Loss: 0.189716, Train Acc: 0.634615 | Val Loss: 0.199814, Val Acc: 0.639175\n",
      "Epoch 4049 - Train Loss: 0.189699, Train Acc: 0.634615 | Val Loss: 0.199798, Val Acc: 0.639175\n",
      "Epoch 4050 - Train Loss: 0.189682, Train Acc: 0.634615 | Val Loss: 0.199782, Val Acc: 0.639175\n",
      "Epoch 4051 - Train Loss: 0.189666, Train Acc: 0.634615 | Val Loss: 0.199766, Val Acc: 0.639175\n",
      "Epoch 4052 - Train Loss: 0.189649, Train Acc: 0.634615 | Val Loss: 0.199751, Val Acc: 0.639175\n",
      "Epoch 4053 - Train Loss: 0.189633, Train Acc: 0.634615 | Val Loss: 0.199735, Val Acc: 0.639175\n",
      "Epoch 4054 - Train Loss: 0.189616, Train Acc: 0.634615 | Val Loss: 0.199719, Val Acc: 0.639175\n",
      "Epoch 4055 - Train Loss: 0.189599, Train Acc: 0.634615 | Val Loss: 0.199703, Val Acc: 0.639175\n",
      "Epoch 4056 - Train Loss: 0.189583, Train Acc: 0.634615 | Val Loss: 0.199687, Val Acc: 0.639175\n",
      "Epoch 4057 - Train Loss: 0.189566, Train Acc: 0.634615 | Val Loss: 0.199671, Val Acc: 0.639175\n",
      "Epoch 4058 - Train Loss: 0.189550, Train Acc: 0.634615 | Val Loss: 0.199655, Val Acc: 0.639175\n",
      "Epoch 4059 - Train Loss: 0.189533, Train Acc: 0.634615 | Val Loss: 0.199639, Val Acc: 0.639175\n",
      "Epoch 4060 - Train Loss: 0.189516, Train Acc: 0.634615 | Val Loss: 0.199623, Val Acc: 0.639175\n",
      "Epoch 4061 - Train Loss: 0.189500, Train Acc: 0.634615 | Val Loss: 0.199607, Val Acc: 0.639175\n",
      "Epoch 4062 - Train Loss: 0.189483, Train Acc: 0.634615 | Val Loss: 0.199591, Val Acc: 0.639175\n",
      "Epoch 4063 - Train Loss: 0.189467, Train Acc: 0.634615 | Val Loss: 0.199576, Val Acc: 0.639175\n",
      "Epoch 4064 - Train Loss: 0.189450, Train Acc: 0.634615 | Val Loss: 0.199560, Val Acc: 0.639175\n",
      "Epoch 4065 - Train Loss: 0.189433, Train Acc: 0.634615 | Val Loss: 0.199544, Val Acc: 0.639175\n",
      "Epoch 4066 - Train Loss: 0.189417, Train Acc: 0.634615 | Val Loss: 0.199528, Val Acc: 0.639175\n",
      "Epoch 4067 - Train Loss: 0.189400, Train Acc: 0.634615 | Val Loss: 0.199512, Val Acc: 0.639175\n",
      "Epoch 4068 - Train Loss: 0.189384, Train Acc: 0.634615 | Val Loss: 0.199496, Val Acc: 0.639175\n",
      "Epoch 4069 - Train Loss: 0.189367, Train Acc: 0.634615 | Val Loss: 0.199480, Val Acc: 0.639175\n",
      "Epoch 4070 - Train Loss: 0.189351, Train Acc: 0.634615 | Val Loss: 0.199464, Val Acc: 0.639175\n",
      "Epoch 4071 - Train Loss: 0.189334, Train Acc: 0.634615 | Val Loss: 0.199448, Val Acc: 0.639175\n",
      "Epoch 4072 - Train Loss: 0.189317, Train Acc: 0.634615 | Val Loss: 0.199433, Val Acc: 0.639175\n",
      "Epoch 4073 - Train Loss: 0.189301, Train Acc: 0.634615 | Val Loss: 0.199417, Val Acc: 0.639175\n",
      "Epoch 4074 - Train Loss: 0.189284, Train Acc: 0.634615 | Val Loss: 0.199401, Val Acc: 0.639175\n",
      "Epoch 4075 - Train Loss: 0.189268, Train Acc: 0.634615 | Val Loss: 0.199385, Val Acc: 0.639175\n",
      "Epoch 4076 - Train Loss: 0.189251, Train Acc: 0.634615 | Val Loss: 0.199369, Val Acc: 0.639175\n",
      "Epoch 4077 - Train Loss: 0.189235, Train Acc: 0.634615 | Val Loss: 0.199353, Val Acc: 0.639175\n",
      "Epoch 4078 - Train Loss: 0.189218, Train Acc: 0.634615 | Val Loss: 0.199337, Val Acc: 0.639175\n",
      "Epoch 4079 - Train Loss: 0.189201, Train Acc: 0.634615 | Val Loss: 0.199322, Val Acc: 0.639175\n",
      "Epoch 4080 - Train Loss: 0.189185, Train Acc: 0.635897 | Val Loss: 0.199306, Val Acc: 0.639175\n",
      "Epoch 4081 - Train Loss: 0.189168, Train Acc: 0.635897 | Val Loss: 0.199290, Val Acc: 0.639175\n",
      "Epoch 4082 - Train Loss: 0.189152, Train Acc: 0.635897 | Val Loss: 0.199274, Val Acc: 0.639175\n",
      "Epoch 4083 - Train Loss: 0.189135, Train Acc: 0.635897 | Val Loss: 0.199258, Val Acc: 0.639175\n",
      "Epoch 4084 - Train Loss: 0.189119, Train Acc: 0.635897 | Val Loss: 0.199242, Val Acc: 0.639175\n",
      "Epoch 4085 - Train Loss: 0.189102, Train Acc: 0.635897 | Val Loss: 0.199227, Val Acc: 0.639175\n",
      "Epoch 4086 - Train Loss: 0.189086, Train Acc: 0.635897 | Val Loss: 0.199211, Val Acc: 0.639175\n",
      "Epoch 4087 - Train Loss: 0.189069, Train Acc: 0.635897 | Val Loss: 0.199195, Val Acc: 0.639175\n",
      "Epoch 4088 - Train Loss: 0.189053, Train Acc: 0.635897 | Val Loss: 0.199179, Val Acc: 0.639175\n",
      "Epoch 4089 - Train Loss: 0.189036, Train Acc: 0.635897 | Val Loss: 0.199163, Val Acc: 0.639175\n",
      "Epoch 4090 - Train Loss: 0.189020, Train Acc: 0.635897 | Val Loss: 0.199148, Val Acc: 0.639175\n",
      "Epoch 4091 - Train Loss: 0.189003, Train Acc: 0.635897 | Val Loss: 0.199132, Val Acc: 0.639175\n",
      "Epoch 4092 - Train Loss: 0.188987, Train Acc: 0.635897 | Val Loss: 0.199116, Val Acc: 0.639175\n",
      "Epoch 4093 - Train Loss: 0.188970, Train Acc: 0.635897 | Val Loss: 0.199100, Val Acc: 0.639175\n",
      "Epoch 4094 - Train Loss: 0.188953, Train Acc: 0.635897 | Val Loss: 0.199084, Val Acc: 0.639175\n",
      "Epoch 4095 - Train Loss: 0.188937, Train Acc: 0.635897 | Val Loss: 0.199068, Val Acc: 0.639175\n",
      "Epoch 4096 - Train Loss: 0.188920, Train Acc: 0.635897 | Val Loss: 0.199053, Val Acc: 0.639175\n",
      "Epoch 4097 - Train Loss: 0.188904, Train Acc: 0.635897 | Val Loss: 0.199037, Val Acc: 0.639175\n",
      "Epoch 4098 - Train Loss: 0.188887, Train Acc: 0.635897 | Val Loss: 0.199021, Val Acc: 0.639175\n",
      "Epoch 4099 - Train Loss: 0.188871, Train Acc: 0.635897 | Val Loss: 0.199005, Val Acc: 0.639175\n",
      "Epoch 4100 - Train Loss: 0.188854, Train Acc: 0.635897 | Val Loss: 0.198990, Val Acc: 0.639175\n",
      "Epoch 4101 - Train Loss: 0.188838, Train Acc: 0.635897 | Val Loss: 0.198974, Val Acc: 0.639175\n",
      "Epoch 4102 - Train Loss: 0.188821, Train Acc: 0.635897 | Val Loss: 0.198958, Val Acc: 0.639175\n",
      "Epoch 4103 - Train Loss: 0.188805, Train Acc: 0.635897 | Val Loss: 0.198942, Val Acc: 0.639175\n",
      "Epoch 4104 - Train Loss: 0.188788, Train Acc: 0.635897 | Val Loss: 0.198926, Val Acc: 0.639175\n",
      "Epoch 4105 - Train Loss: 0.188772, Train Acc: 0.635897 | Val Loss: 0.198911, Val Acc: 0.639175\n",
      "Epoch 4106 - Train Loss: 0.188755, Train Acc: 0.635897 | Val Loss: 0.198895, Val Acc: 0.639175\n",
      "Epoch 4107 - Train Loss: 0.188739, Train Acc: 0.635897 | Val Loss: 0.198879, Val Acc: 0.639175\n",
      "Epoch 4108 - Train Loss: 0.188722, Train Acc: 0.635897 | Val Loss: 0.198863, Val Acc: 0.639175\n",
      "Epoch 4109 - Train Loss: 0.188706, Train Acc: 0.635897 | Val Loss: 0.198848, Val Acc: 0.639175\n",
      "Epoch 4110 - Train Loss: 0.188689, Train Acc: 0.635897 | Val Loss: 0.198832, Val Acc: 0.639175\n",
      "Epoch 4111 - Train Loss: 0.188673, Train Acc: 0.635897 | Val Loss: 0.198816, Val Acc: 0.639175\n",
      "Epoch 4112 - Train Loss: 0.188656, Train Acc: 0.635897 | Val Loss: 0.198800, Val Acc: 0.639175\n",
      "Epoch 4113 - Train Loss: 0.188640, Train Acc: 0.635897 | Val Loss: 0.198785, Val Acc: 0.639175\n",
      "Epoch 4114 - Train Loss: 0.188624, Train Acc: 0.635897 | Val Loss: 0.198769, Val Acc: 0.639175\n",
      "Epoch 4115 - Train Loss: 0.188607, Train Acc: 0.635897 | Val Loss: 0.198753, Val Acc: 0.639175\n",
      "Epoch 4116 - Train Loss: 0.188591, Train Acc: 0.635897 | Val Loss: 0.198737, Val Acc: 0.639175\n",
      "Epoch 4117 - Train Loss: 0.188574, Train Acc: 0.635897 | Val Loss: 0.198722, Val Acc: 0.639175\n",
      "Epoch 4118 - Train Loss: 0.188558, Train Acc: 0.635897 | Val Loss: 0.198706, Val Acc: 0.639175\n",
      "Epoch 4119 - Train Loss: 0.188541, Train Acc: 0.635897 | Val Loss: 0.198690, Val Acc: 0.639175\n",
      "Epoch 4120 - Train Loss: 0.188525, Train Acc: 0.635897 | Val Loss: 0.198674, Val Acc: 0.639175\n",
      "Epoch 4121 - Train Loss: 0.188508, Train Acc: 0.635897 | Val Loss: 0.198659, Val Acc: 0.639175\n",
      "Epoch 4122 - Train Loss: 0.188492, Train Acc: 0.635897 | Val Loss: 0.198643, Val Acc: 0.639175\n",
      "Epoch 4123 - Train Loss: 0.188475, Train Acc: 0.635897 | Val Loss: 0.198627, Val Acc: 0.639175\n",
      "Epoch 4124 - Train Loss: 0.188459, Train Acc: 0.635897 | Val Loss: 0.198611, Val Acc: 0.639175\n",
      "Epoch 4125 - Train Loss: 0.188442, Train Acc: 0.635897 | Val Loss: 0.198596, Val Acc: 0.639175\n",
      "Epoch 4126 - Train Loss: 0.188426, Train Acc: 0.635897 | Val Loss: 0.198580, Val Acc: 0.639175\n",
      "Epoch 4127 - Train Loss: 0.188409, Train Acc: 0.635897 | Val Loss: 0.198564, Val Acc: 0.639175\n",
      "Epoch 4128 - Train Loss: 0.188393, Train Acc: 0.635897 | Val Loss: 0.198548, Val Acc: 0.639175\n",
      "Epoch 4129 - Train Loss: 0.188377, Train Acc: 0.635897 | Val Loss: 0.198533, Val Acc: 0.639175\n",
      "Epoch 4130 - Train Loss: 0.188360, Train Acc: 0.635897 | Val Loss: 0.198517, Val Acc: 0.639175\n",
      "Epoch 4131 - Train Loss: 0.188344, Train Acc: 0.635897 | Val Loss: 0.198501, Val Acc: 0.639175\n",
      "Epoch 4132 - Train Loss: 0.188327, Train Acc: 0.635897 | Val Loss: 0.198486, Val Acc: 0.639175\n",
      "Epoch 4133 - Train Loss: 0.188311, Train Acc: 0.635897 | Val Loss: 0.198470, Val Acc: 0.639175\n",
      "Epoch 4134 - Train Loss: 0.188294, Train Acc: 0.635897 | Val Loss: 0.198454, Val Acc: 0.639175\n",
      "Epoch 4135 - Train Loss: 0.188278, Train Acc: 0.635897 | Val Loss: 0.198438, Val Acc: 0.639175\n",
      "Epoch 4136 - Train Loss: 0.188261, Train Acc: 0.635897 | Val Loss: 0.198423, Val Acc: 0.639175\n",
      "Epoch 4137 - Train Loss: 0.188245, Train Acc: 0.635897 | Val Loss: 0.198407, Val Acc: 0.639175\n",
      "Epoch 4138 - Train Loss: 0.188229, Train Acc: 0.635897 | Val Loss: 0.198391, Val Acc: 0.639175\n",
      "Epoch 4139 - Train Loss: 0.188212, Train Acc: 0.635897 | Val Loss: 0.198376, Val Acc: 0.639175\n",
      "Epoch 4140 - Train Loss: 0.188196, Train Acc: 0.635897 | Val Loss: 0.198360, Val Acc: 0.639175\n",
      "Epoch 4141 - Train Loss: 0.188179, Train Acc: 0.635897 | Val Loss: 0.198344, Val Acc: 0.639175\n",
      "Epoch 4142 - Train Loss: 0.188163, Train Acc: 0.635897 | Val Loss: 0.198329, Val Acc: 0.639175\n",
      "Epoch 4143 - Train Loss: 0.188146, Train Acc: 0.635897 | Val Loss: 0.198313, Val Acc: 0.639175\n",
      "Epoch 4144 - Train Loss: 0.188130, Train Acc: 0.635897 | Val Loss: 0.198297, Val Acc: 0.639175\n",
      "Epoch 4145 - Train Loss: 0.188114, Train Acc: 0.635897 | Val Loss: 0.198282, Val Acc: 0.639175\n",
      "Epoch 4146 - Train Loss: 0.188097, Train Acc: 0.635897 | Val Loss: 0.198266, Val Acc: 0.639175\n",
      "Epoch 4147 - Train Loss: 0.188081, Train Acc: 0.635897 | Val Loss: 0.198250, Val Acc: 0.639175\n",
      "Epoch 4148 - Train Loss: 0.188064, Train Acc: 0.635897 | Val Loss: 0.198235, Val Acc: 0.639175\n",
      "Epoch 4149 - Train Loss: 0.188048, Train Acc: 0.635897 | Val Loss: 0.198219, Val Acc: 0.639175\n",
      "Epoch 4150 - Train Loss: 0.188032, Train Acc: 0.635897 | Val Loss: 0.198203, Val Acc: 0.639175\n",
      "Epoch 4151 - Train Loss: 0.188015, Train Acc: 0.635897 | Val Loss: 0.198188, Val Acc: 0.639175\n",
      "Epoch 4152 - Train Loss: 0.187999, Train Acc: 0.635897 | Val Loss: 0.198172, Val Acc: 0.639175\n",
      "Epoch 4153 - Train Loss: 0.187982, Train Acc: 0.635897 | Val Loss: 0.198156, Val Acc: 0.639175\n",
      "Epoch 4154 - Train Loss: 0.187966, Train Acc: 0.635897 | Val Loss: 0.198141, Val Acc: 0.639175\n",
      "Epoch 4155 - Train Loss: 0.187950, Train Acc: 0.635897 | Val Loss: 0.198125, Val Acc: 0.639175\n",
      "Epoch 4156 - Train Loss: 0.187933, Train Acc: 0.635897 | Val Loss: 0.198110, Val Acc: 0.639175\n",
      "Epoch 4157 - Train Loss: 0.187917, Train Acc: 0.637179 | Val Loss: 0.198094, Val Acc: 0.639175\n",
      "Epoch 4158 - Train Loss: 0.187900, Train Acc: 0.637179 | Val Loss: 0.198078, Val Acc: 0.639175\n",
      "Epoch 4159 - Train Loss: 0.187884, Train Acc: 0.637179 | Val Loss: 0.198063, Val Acc: 0.639175\n",
      "Epoch 4160 - Train Loss: 0.187868, Train Acc: 0.637179 | Val Loss: 0.198047, Val Acc: 0.639175\n",
      "Epoch 4161 - Train Loss: 0.187851, Train Acc: 0.637179 | Val Loss: 0.198032, Val Acc: 0.639175\n",
      "Epoch 4162 - Train Loss: 0.187835, Train Acc: 0.637179 | Val Loss: 0.198016, Val Acc: 0.639175\n",
      "Epoch 4163 - Train Loss: 0.187819, Train Acc: 0.637179 | Val Loss: 0.198000, Val Acc: 0.639175\n",
      "Epoch 4164 - Train Loss: 0.187802, Train Acc: 0.637179 | Val Loss: 0.197985, Val Acc: 0.649485\n",
      "Epoch 4165 - Train Loss: 0.187786, Train Acc: 0.637179 | Val Loss: 0.197969, Val Acc: 0.649485\n",
      "Epoch 4166 - Train Loss: 0.187770, Train Acc: 0.637179 | Val Loss: 0.197954, Val Acc: 0.649485\n",
      "Epoch 4167 - Train Loss: 0.187753, Train Acc: 0.637179 | Val Loss: 0.197938, Val Acc: 0.649485\n",
      "Epoch 4168 - Train Loss: 0.187737, Train Acc: 0.637179 | Val Loss: 0.197922, Val Acc: 0.649485\n",
      "Epoch 4169 - Train Loss: 0.187720, Train Acc: 0.637179 | Val Loss: 0.197907, Val Acc: 0.649485\n",
      "Epoch 4170 - Train Loss: 0.187704, Train Acc: 0.637179 | Val Loss: 0.197891, Val Acc: 0.649485\n",
      "Epoch 4171 - Train Loss: 0.187688, Train Acc: 0.637179 | Val Loss: 0.197876, Val Acc: 0.649485\n",
      "Epoch 4172 - Train Loss: 0.187671, Train Acc: 0.637179 | Val Loss: 0.197860, Val Acc: 0.649485\n",
      "Epoch 4173 - Train Loss: 0.187655, Train Acc: 0.637179 | Val Loss: 0.197844, Val Acc: 0.649485\n",
      "Epoch 4174 - Train Loss: 0.187639, Train Acc: 0.637179 | Val Loss: 0.197829, Val Acc: 0.649485\n",
      "Epoch 4175 - Train Loss: 0.187622, Train Acc: 0.637179 | Val Loss: 0.197813, Val Acc: 0.649485\n",
      "Epoch 4176 - Train Loss: 0.187606, Train Acc: 0.637179 | Val Loss: 0.197798, Val Acc: 0.649485\n",
      "Epoch 4177 - Train Loss: 0.187590, Train Acc: 0.637179 | Val Loss: 0.197782, Val Acc: 0.649485\n",
      "Epoch 4178 - Train Loss: 0.187573, Train Acc: 0.637179 | Val Loss: 0.197766, Val Acc: 0.649485\n",
      "Epoch 4179 - Train Loss: 0.187557, Train Acc: 0.637179 | Val Loss: 0.197751, Val Acc: 0.649485\n",
      "Epoch 4180 - Train Loss: 0.187541, Train Acc: 0.637179 | Val Loss: 0.197735, Val Acc: 0.649485\n",
      "Epoch 4181 - Train Loss: 0.187524, Train Acc: 0.637179 | Val Loss: 0.197720, Val Acc: 0.649485\n",
      "Epoch 4182 - Train Loss: 0.187508, Train Acc: 0.637179 | Val Loss: 0.197704, Val Acc: 0.649485\n",
      "Epoch 4183 - Train Loss: 0.187492, Train Acc: 0.637179 | Val Loss: 0.197688, Val Acc: 0.649485\n",
      "Epoch 4184 - Train Loss: 0.187475, Train Acc: 0.637179 | Val Loss: 0.197673, Val Acc: 0.649485\n",
      "Epoch 4185 - Train Loss: 0.187459, Train Acc: 0.637179 | Val Loss: 0.197657, Val Acc: 0.649485\n",
      "Epoch 4186 - Train Loss: 0.187443, Train Acc: 0.637179 | Val Loss: 0.197642, Val Acc: 0.649485\n",
      "Epoch 4187 - Train Loss: 0.187426, Train Acc: 0.637179 | Val Loss: 0.197626, Val Acc: 0.649485\n",
      "Epoch 4188 - Train Loss: 0.187410, Train Acc: 0.637179 | Val Loss: 0.197611, Val Acc: 0.649485\n",
      "Epoch 4189 - Train Loss: 0.187394, Train Acc: 0.637179 | Val Loss: 0.197595, Val Acc: 0.649485\n",
      "Epoch 4190 - Train Loss: 0.187377, Train Acc: 0.637179 | Val Loss: 0.197579, Val Acc: 0.649485\n",
      "Epoch 4191 - Train Loss: 0.187361, Train Acc: 0.637179 | Val Loss: 0.197564, Val Acc: 0.649485\n",
      "Epoch 4192 - Train Loss: 0.187345, Train Acc: 0.637179 | Val Loss: 0.197548, Val Acc: 0.649485\n",
      "Epoch 4193 - Train Loss: 0.187329, Train Acc: 0.637179 | Val Loss: 0.197533, Val Acc: 0.649485\n",
      "Epoch 4194 - Train Loss: 0.187312, Train Acc: 0.637179 | Val Loss: 0.197517, Val Acc: 0.649485\n",
      "Epoch 4195 - Train Loss: 0.187296, Train Acc: 0.637179 | Val Loss: 0.197502, Val Acc: 0.649485\n",
      "Epoch 4196 - Train Loss: 0.187280, Train Acc: 0.637179 | Val Loss: 0.197486, Val Acc: 0.649485\n",
      "Epoch 4197 - Train Loss: 0.187263, Train Acc: 0.637179 | Val Loss: 0.197471, Val Acc: 0.649485\n",
      "Epoch 4198 - Train Loss: 0.187247, Train Acc: 0.637179 | Val Loss: 0.197455, Val Acc: 0.649485\n",
      "Epoch 4199 - Train Loss: 0.187231, Train Acc: 0.637179 | Val Loss: 0.197440, Val Acc: 0.649485\n",
      "Epoch 4200 - Train Loss: 0.187215, Train Acc: 0.638462 | Val Loss: 0.197424, Val Acc: 0.649485\n",
      "Epoch 4201 - Train Loss: 0.187198, Train Acc: 0.638462 | Val Loss: 0.197408, Val Acc: 0.649485\n",
      "Epoch 4202 - Train Loss: 0.187182, Train Acc: 0.638462 | Val Loss: 0.197393, Val Acc: 0.649485\n",
      "Epoch 4203 - Train Loss: 0.187166, Train Acc: 0.638462 | Val Loss: 0.197377, Val Acc: 0.649485\n",
      "Epoch 4204 - Train Loss: 0.187149, Train Acc: 0.639744 | Val Loss: 0.197362, Val Acc: 0.649485\n",
      "Epoch 4205 - Train Loss: 0.187133, Train Acc: 0.639744 | Val Loss: 0.197346, Val Acc: 0.649485\n",
      "Epoch 4206 - Train Loss: 0.187117, Train Acc: 0.641026 | Val Loss: 0.197331, Val Acc: 0.649485\n",
      "Epoch 4207 - Train Loss: 0.187101, Train Acc: 0.641026 | Val Loss: 0.197315, Val Acc: 0.649485\n",
      "Epoch 4208 - Train Loss: 0.187084, Train Acc: 0.641026 | Val Loss: 0.197300, Val Acc: 0.649485\n",
      "Epoch 4209 - Train Loss: 0.187068, Train Acc: 0.641026 | Val Loss: 0.197284, Val Acc: 0.649485\n",
      "Epoch 4210 - Train Loss: 0.187052, Train Acc: 0.641026 | Val Loss: 0.197269, Val Acc: 0.649485\n",
      "Epoch 4211 - Train Loss: 0.187036, Train Acc: 0.641026 | Val Loss: 0.197253, Val Acc: 0.649485\n",
      "Epoch 4212 - Train Loss: 0.187019, Train Acc: 0.641026 | Val Loss: 0.197238, Val Acc: 0.649485\n",
      "Epoch 4213 - Train Loss: 0.187003, Train Acc: 0.641026 | Val Loss: 0.197222, Val Acc: 0.649485\n",
      "Epoch 4214 - Train Loss: 0.186987, Train Acc: 0.641026 | Val Loss: 0.197207, Val Acc: 0.649485\n",
      "Epoch 4215 - Train Loss: 0.186971, Train Acc: 0.641026 | Val Loss: 0.197191, Val Acc: 0.649485\n",
      "Epoch 4216 - Train Loss: 0.186954, Train Acc: 0.641026 | Val Loss: 0.197176, Val Acc: 0.649485\n",
      "Epoch 4217 - Train Loss: 0.186938, Train Acc: 0.641026 | Val Loss: 0.197160, Val Acc: 0.649485\n",
      "Epoch 4218 - Train Loss: 0.186922, Train Acc: 0.642308 | Val Loss: 0.197145, Val Acc: 0.649485\n",
      "Epoch 4219 - Train Loss: 0.186906, Train Acc: 0.642308 | Val Loss: 0.197129, Val Acc: 0.649485\n",
      "Epoch 4220 - Train Loss: 0.186889, Train Acc: 0.642308 | Val Loss: 0.197114, Val Acc: 0.649485\n",
      "Epoch 4221 - Train Loss: 0.186873, Train Acc: 0.642308 | Val Loss: 0.197098, Val Acc: 0.649485\n",
      "Epoch 4222 - Train Loss: 0.186857, Train Acc: 0.642308 | Val Loss: 0.197083, Val Acc: 0.649485\n",
      "Epoch 4223 - Train Loss: 0.186841, Train Acc: 0.643590 | Val Loss: 0.197067, Val Acc: 0.649485\n",
      "Epoch 4224 - Train Loss: 0.186824, Train Acc: 0.643590 | Val Loss: 0.197052, Val Acc: 0.649485\n",
      "Epoch 4225 - Train Loss: 0.186808, Train Acc: 0.643590 | Val Loss: 0.197036, Val Acc: 0.649485\n",
      "Epoch 4226 - Train Loss: 0.186792, Train Acc: 0.643590 | Val Loss: 0.197021, Val Acc: 0.649485\n",
      "Epoch 4227 - Train Loss: 0.186776, Train Acc: 0.643590 | Val Loss: 0.197005, Val Acc: 0.649485\n",
      "Epoch 4228 - Train Loss: 0.186759, Train Acc: 0.643590 | Val Loss: 0.196990, Val Acc: 0.649485\n",
      "Epoch 4229 - Train Loss: 0.186743, Train Acc: 0.643590 | Val Loss: 0.196974, Val Acc: 0.649485\n",
      "Epoch 4230 - Train Loss: 0.186727, Train Acc: 0.643590 | Val Loss: 0.196959, Val Acc: 0.649485\n",
      "Epoch 4231 - Train Loss: 0.186711, Train Acc: 0.643590 | Val Loss: 0.196943, Val Acc: 0.649485\n",
      "Epoch 4232 - Train Loss: 0.186695, Train Acc: 0.643590 | Val Loss: 0.196928, Val Acc: 0.649485\n",
      "Epoch 4233 - Train Loss: 0.186678, Train Acc: 0.643590 | Val Loss: 0.196912, Val Acc: 0.649485\n",
      "Epoch 4234 - Train Loss: 0.186662, Train Acc: 0.643590 | Val Loss: 0.196897, Val Acc: 0.649485\n",
      "Epoch 4235 - Train Loss: 0.186646, Train Acc: 0.644872 | Val Loss: 0.196882, Val Acc: 0.649485\n",
      "Epoch 4236 - Train Loss: 0.186630, Train Acc: 0.644872 | Val Loss: 0.196866, Val Acc: 0.649485\n",
      "Epoch 4237 - Train Loss: 0.186613, Train Acc: 0.644872 | Val Loss: 0.196851, Val Acc: 0.649485\n",
      "Epoch 4238 - Train Loss: 0.186597, Train Acc: 0.644872 | Val Loss: 0.196835, Val Acc: 0.649485\n",
      "Epoch 4239 - Train Loss: 0.186581, Train Acc: 0.644872 | Val Loss: 0.196820, Val Acc: 0.649485\n",
      "Epoch 4240 - Train Loss: 0.186565, Train Acc: 0.644872 | Val Loss: 0.196804, Val Acc: 0.649485\n",
      "Epoch 4241 - Train Loss: 0.186549, Train Acc: 0.644872 | Val Loss: 0.196789, Val Acc: 0.649485\n",
      "Epoch 4242 - Train Loss: 0.186532, Train Acc: 0.644872 | Val Loss: 0.196773, Val Acc: 0.649485\n",
      "Epoch 4243 - Train Loss: 0.186516, Train Acc: 0.644872 | Val Loss: 0.196758, Val Acc: 0.649485\n",
      "Epoch 4244 - Train Loss: 0.186500, Train Acc: 0.644872 | Val Loss: 0.196742, Val Acc: 0.649485\n",
      "Epoch 4245 - Train Loss: 0.186484, Train Acc: 0.644872 | Val Loss: 0.196727, Val Acc: 0.649485\n",
      "Epoch 4246 - Train Loss: 0.186468, Train Acc: 0.644872 | Val Loss: 0.196711, Val Acc: 0.649485\n",
      "Epoch 4247 - Train Loss: 0.186451, Train Acc: 0.644872 | Val Loss: 0.196696, Val Acc: 0.649485\n",
      "Epoch 4248 - Train Loss: 0.186435, Train Acc: 0.644872 | Val Loss: 0.196680, Val Acc: 0.649485\n",
      "Epoch 4249 - Train Loss: 0.186419, Train Acc: 0.644872 | Val Loss: 0.196665, Val Acc: 0.649485\n",
      "Epoch 4250 - Train Loss: 0.186403, Train Acc: 0.644872 | Val Loss: 0.196650, Val Acc: 0.649485\n",
      "Epoch 4251 - Train Loss: 0.186387, Train Acc: 0.644872 | Val Loss: 0.196634, Val Acc: 0.649485\n",
      "Epoch 4252 - Train Loss: 0.186371, Train Acc: 0.644872 | Val Loss: 0.196619, Val Acc: 0.649485\n",
      "Epoch 4253 - Train Loss: 0.186354, Train Acc: 0.644872 | Val Loss: 0.196603, Val Acc: 0.649485\n",
      "Epoch 4254 - Train Loss: 0.186338, Train Acc: 0.644872 | Val Loss: 0.196588, Val Acc: 0.649485\n",
      "Epoch 4255 - Train Loss: 0.186322, Train Acc: 0.644872 | Val Loss: 0.196572, Val Acc: 0.649485\n",
      "Epoch 4256 - Train Loss: 0.186306, Train Acc: 0.644872 | Val Loss: 0.196557, Val Acc: 0.649485\n",
      "Epoch 4257 - Train Loss: 0.186290, Train Acc: 0.644872 | Val Loss: 0.196541, Val Acc: 0.649485\n",
      "Epoch 4258 - Train Loss: 0.186274, Train Acc: 0.644872 | Val Loss: 0.196526, Val Acc: 0.649485\n",
      "Epoch 4259 - Train Loss: 0.186257, Train Acc: 0.644872 | Val Loss: 0.196511, Val Acc: 0.649485\n",
      "Epoch 4260 - Train Loss: 0.186241, Train Acc: 0.644872 | Val Loss: 0.196495, Val Acc: 0.649485\n",
      "Epoch 4261 - Train Loss: 0.186225, Train Acc: 0.644872 | Val Loss: 0.196480, Val Acc: 0.649485\n",
      "Epoch 4262 - Train Loss: 0.186209, Train Acc: 0.644872 | Val Loss: 0.196464, Val Acc: 0.649485\n",
      "Epoch 4263 - Train Loss: 0.186193, Train Acc: 0.644872 | Val Loss: 0.196449, Val Acc: 0.649485\n",
      "Epoch 4264 - Train Loss: 0.186177, Train Acc: 0.644872 | Val Loss: 0.196433, Val Acc: 0.649485\n",
      "Epoch 4265 - Train Loss: 0.186160, Train Acc: 0.644872 | Val Loss: 0.196418, Val Acc: 0.649485\n",
      "Epoch 4266 - Train Loss: 0.186144, Train Acc: 0.644872 | Val Loss: 0.196403, Val Acc: 0.649485\n",
      "Epoch 4267 - Train Loss: 0.186128, Train Acc: 0.644872 | Val Loss: 0.196387, Val Acc: 0.649485\n",
      "Epoch 4268 - Train Loss: 0.186112, Train Acc: 0.644872 | Val Loss: 0.196372, Val Acc: 0.649485\n",
      "Epoch 4269 - Train Loss: 0.186096, Train Acc: 0.644872 | Val Loss: 0.196356, Val Acc: 0.649485\n",
      "Epoch 4270 - Train Loss: 0.186080, Train Acc: 0.644872 | Val Loss: 0.196341, Val Acc: 0.649485\n",
      "Epoch 4271 - Train Loss: 0.186064, Train Acc: 0.644872 | Val Loss: 0.196325, Val Acc: 0.649485\n",
      "Epoch 4272 - Train Loss: 0.186048, Train Acc: 0.644872 | Val Loss: 0.196310, Val Acc: 0.649485\n",
      "Epoch 4273 - Train Loss: 0.186031, Train Acc: 0.644872 | Val Loss: 0.196295, Val Acc: 0.649485\n",
      "Epoch 4274 - Train Loss: 0.186015, Train Acc: 0.644872 | Val Loss: 0.196279, Val Acc: 0.649485\n",
      "Epoch 4275 - Train Loss: 0.185999, Train Acc: 0.644872 | Val Loss: 0.196264, Val Acc: 0.649485\n",
      "Epoch 4276 - Train Loss: 0.185983, Train Acc: 0.644872 | Val Loss: 0.196248, Val Acc: 0.649485\n",
      "Epoch 4277 - Train Loss: 0.185967, Train Acc: 0.644872 | Val Loss: 0.196233, Val Acc: 0.649485\n",
      "Epoch 4278 - Train Loss: 0.185951, Train Acc: 0.644872 | Val Loss: 0.196218, Val Acc: 0.649485\n",
      "Epoch 4279 - Train Loss: 0.185935, Train Acc: 0.644872 | Val Loss: 0.196202, Val Acc: 0.649485\n",
      "Epoch 4280 - Train Loss: 0.185919, Train Acc: 0.644872 | Val Loss: 0.196187, Val Acc: 0.649485\n",
      "Epoch 4281 - Train Loss: 0.185903, Train Acc: 0.644872 | Val Loss: 0.196171, Val Acc: 0.649485\n",
      "Epoch 4282 - Train Loss: 0.185886, Train Acc: 0.644872 | Val Loss: 0.196156, Val Acc: 0.649485\n",
      "Epoch 4283 - Train Loss: 0.185870, Train Acc: 0.644872 | Val Loss: 0.196141, Val Acc: 0.649485\n",
      "Epoch 4284 - Train Loss: 0.185854, Train Acc: 0.644872 | Val Loss: 0.196125, Val Acc: 0.649485\n",
      "Epoch 4285 - Train Loss: 0.185838, Train Acc: 0.644872 | Val Loss: 0.196110, Val Acc: 0.649485\n",
      "Epoch 4286 - Train Loss: 0.185822, Train Acc: 0.644872 | Val Loss: 0.196095, Val Acc: 0.649485\n",
      "Epoch 4287 - Train Loss: 0.185806, Train Acc: 0.646154 | Val Loss: 0.196079, Val Acc: 0.649485\n",
      "Epoch 4288 - Train Loss: 0.185790, Train Acc: 0.646154 | Val Loss: 0.196064, Val Acc: 0.649485\n",
      "Epoch 4289 - Train Loss: 0.185774, Train Acc: 0.646154 | Val Loss: 0.196048, Val Acc: 0.649485\n",
      "Epoch 4290 - Train Loss: 0.185758, Train Acc: 0.646154 | Val Loss: 0.196033, Val Acc: 0.649485\n",
      "Epoch 4291 - Train Loss: 0.185742, Train Acc: 0.646154 | Val Loss: 0.196018, Val Acc: 0.649485\n",
      "Epoch 4292 - Train Loss: 0.185725, Train Acc: 0.646154 | Val Loss: 0.196002, Val Acc: 0.649485\n",
      "Epoch 4293 - Train Loss: 0.185709, Train Acc: 0.646154 | Val Loss: 0.195987, Val Acc: 0.649485\n",
      "Epoch 4294 - Train Loss: 0.185693, Train Acc: 0.646154 | Val Loss: 0.195972, Val Acc: 0.649485\n",
      "Epoch 4295 - Train Loss: 0.185677, Train Acc: 0.646154 | Val Loss: 0.195956, Val Acc: 0.649485\n",
      "Epoch 4296 - Train Loss: 0.185661, Train Acc: 0.646154 | Val Loss: 0.195941, Val Acc: 0.649485\n",
      "Epoch 4297 - Train Loss: 0.185645, Train Acc: 0.646154 | Val Loss: 0.195926, Val Acc: 0.649485\n",
      "Epoch 4298 - Train Loss: 0.185629, Train Acc: 0.646154 | Val Loss: 0.195910, Val Acc: 0.649485\n",
      "Epoch 4299 - Train Loss: 0.185613, Train Acc: 0.646154 | Val Loss: 0.195895, Val Acc: 0.649485\n",
      "Epoch 4300 - Train Loss: 0.185597, Train Acc: 0.646154 | Val Loss: 0.195879, Val Acc: 0.649485\n",
      "Epoch 4301 - Train Loss: 0.185581, Train Acc: 0.646154 | Val Loss: 0.195864, Val Acc: 0.649485\n",
      "Epoch 4302 - Train Loss: 0.185565, Train Acc: 0.646154 | Val Loss: 0.195849, Val Acc: 0.649485\n",
      "Epoch 4303 - Train Loss: 0.185549, Train Acc: 0.646154 | Val Loss: 0.195833, Val Acc: 0.649485\n",
      "Epoch 4304 - Train Loss: 0.185533, Train Acc: 0.646154 | Val Loss: 0.195818, Val Acc: 0.649485\n",
      "Epoch 4305 - Train Loss: 0.185517, Train Acc: 0.646154 | Val Loss: 0.195803, Val Acc: 0.649485\n",
      "Epoch 4306 - Train Loss: 0.185501, Train Acc: 0.646154 | Val Loss: 0.195787, Val Acc: 0.649485\n",
      "Epoch 4307 - Train Loss: 0.185484, Train Acc: 0.646154 | Val Loss: 0.195772, Val Acc: 0.649485\n",
      "Epoch 4308 - Train Loss: 0.185468, Train Acc: 0.646154 | Val Loss: 0.195757, Val Acc: 0.649485\n",
      "Epoch 4309 - Train Loss: 0.185452, Train Acc: 0.646154 | Val Loss: 0.195741, Val Acc: 0.649485\n",
      "Epoch 4310 - Train Loss: 0.185436, Train Acc: 0.646154 | Val Loss: 0.195726, Val Acc: 0.649485\n",
      "Epoch 4311 - Train Loss: 0.185420, Train Acc: 0.646154 | Val Loss: 0.195711, Val Acc: 0.649485\n",
      "Epoch 4312 - Train Loss: 0.185404, Train Acc: 0.646154 | Val Loss: 0.195696, Val Acc: 0.649485\n",
      "Epoch 4313 - Train Loss: 0.185388, Train Acc: 0.646154 | Val Loss: 0.195680, Val Acc: 0.649485\n",
      "Epoch 4314 - Train Loss: 0.185372, Train Acc: 0.646154 | Val Loss: 0.195665, Val Acc: 0.649485\n",
      "Epoch 4315 - Train Loss: 0.185356, Train Acc: 0.646154 | Val Loss: 0.195650, Val Acc: 0.649485\n",
      "Epoch 4316 - Train Loss: 0.185340, Train Acc: 0.646154 | Val Loss: 0.195634, Val Acc: 0.649485\n",
      "Epoch 4317 - Train Loss: 0.185324, Train Acc: 0.646154 | Val Loss: 0.195619, Val Acc: 0.649485\n",
      "Epoch 4318 - Train Loss: 0.185308, Train Acc: 0.646154 | Val Loss: 0.195604, Val Acc: 0.649485\n",
      "Epoch 4319 - Train Loss: 0.185292, Train Acc: 0.646154 | Val Loss: 0.195588, Val Acc: 0.649485\n",
      "Epoch 4320 - Train Loss: 0.185276, Train Acc: 0.646154 | Val Loss: 0.195573, Val Acc: 0.649485\n",
      "Epoch 4321 - Train Loss: 0.185260, Train Acc: 0.646154 | Val Loss: 0.195558, Val Acc: 0.649485\n",
      "Epoch 4322 - Train Loss: 0.185244, Train Acc: 0.646154 | Val Loss: 0.195542, Val Acc: 0.649485\n",
      "Epoch 4323 - Train Loss: 0.185228, Train Acc: 0.646154 | Val Loss: 0.195527, Val Acc: 0.649485\n",
      "Epoch 4324 - Train Loss: 0.185212, Train Acc: 0.646154 | Val Loss: 0.195512, Val Acc: 0.649485\n",
      "Epoch 4325 - Train Loss: 0.185196, Train Acc: 0.646154 | Val Loss: 0.195497, Val Acc: 0.649485\n",
      "Epoch 4326 - Train Loss: 0.185180, Train Acc: 0.646154 | Val Loss: 0.195481, Val Acc: 0.649485\n",
      "Epoch 4327 - Train Loss: 0.185164, Train Acc: 0.646154 | Val Loss: 0.195466, Val Acc: 0.649485\n",
      "Epoch 4328 - Train Loss: 0.185148, Train Acc: 0.646154 | Val Loss: 0.195451, Val Acc: 0.649485\n",
      "Epoch 4329 - Train Loss: 0.185132, Train Acc: 0.646154 | Val Loss: 0.195435, Val Acc: 0.639175\n",
      "Epoch 4330 - Train Loss: 0.185116, Train Acc: 0.646154 | Val Loss: 0.195420, Val Acc: 0.639175\n",
      "Epoch 4331 - Train Loss: 0.185100, Train Acc: 0.646154 | Val Loss: 0.195405, Val Acc: 0.639175\n",
      "Epoch 4332 - Train Loss: 0.185084, Train Acc: 0.646154 | Val Loss: 0.195390, Val Acc: 0.639175\n",
      "Epoch 4333 - Train Loss: 0.185068, Train Acc: 0.646154 | Val Loss: 0.195374, Val Acc: 0.639175\n",
      "Epoch 4334 - Train Loss: 0.185052, Train Acc: 0.646154 | Val Loss: 0.195359, Val Acc: 0.639175\n",
      "Epoch 4335 - Train Loss: 0.185036, Train Acc: 0.646154 | Val Loss: 0.195344, Val Acc: 0.639175\n",
      "Epoch 4336 - Train Loss: 0.185020, Train Acc: 0.646154 | Val Loss: 0.195328, Val Acc: 0.639175\n",
      "Epoch 4337 - Train Loss: 0.185004, Train Acc: 0.646154 | Val Loss: 0.195313, Val Acc: 0.639175\n",
      "Epoch 4338 - Train Loss: 0.184988, Train Acc: 0.646154 | Val Loss: 0.195298, Val Acc: 0.639175\n",
      "Epoch 4339 - Train Loss: 0.184972, Train Acc: 0.646154 | Val Loss: 0.195283, Val Acc: 0.639175\n",
      "Epoch 4340 - Train Loss: 0.184956, Train Acc: 0.646154 | Val Loss: 0.195267, Val Acc: 0.639175\n",
      "Epoch 4341 - Train Loss: 0.184940, Train Acc: 0.646154 | Val Loss: 0.195252, Val Acc: 0.639175\n",
      "Epoch 4342 - Train Loss: 0.184924, Train Acc: 0.646154 | Val Loss: 0.195237, Val Acc: 0.639175\n",
      "Epoch 4343 - Train Loss: 0.184908, Train Acc: 0.646154 | Val Loss: 0.195222, Val Acc: 0.639175\n",
      "Epoch 4344 - Train Loss: 0.184892, Train Acc: 0.646154 | Val Loss: 0.195207, Val Acc: 0.639175\n",
      "Epoch 4345 - Train Loss: 0.184876, Train Acc: 0.646154 | Val Loss: 0.195191, Val Acc: 0.639175\n",
      "Epoch 4346 - Train Loss: 0.184860, Train Acc: 0.646154 | Val Loss: 0.195176, Val Acc: 0.639175\n",
      "Epoch 4347 - Train Loss: 0.184844, Train Acc: 0.646154 | Val Loss: 0.195161, Val Acc: 0.639175\n",
      "Epoch 4348 - Train Loss: 0.184828, Train Acc: 0.646154 | Val Loss: 0.195146, Val Acc: 0.639175\n",
      "Epoch 4349 - Train Loss: 0.184812, Train Acc: 0.646154 | Val Loss: 0.195130, Val Acc: 0.639175\n",
      "Epoch 4350 - Train Loss: 0.184796, Train Acc: 0.646154 | Val Loss: 0.195115, Val Acc: 0.639175\n",
      "Epoch 4351 - Train Loss: 0.184780, Train Acc: 0.646154 | Val Loss: 0.195100, Val Acc: 0.639175\n",
      "Epoch 4352 - Train Loss: 0.184764, Train Acc: 0.646154 | Val Loss: 0.195085, Val Acc: 0.639175\n",
      "Epoch 4353 - Train Loss: 0.184748, Train Acc: 0.646154 | Val Loss: 0.195069, Val Acc: 0.639175\n",
      "Epoch 4354 - Train Loss: 0.184732, Train Acc: 0.646154 | Val Loss: 0.195054, Val Acc: 0.639175\n",
      "Epoch 4355 - Train Loss: 0.184716, Train Acc: 0.646154 | Val Loss: 0.195039, Val Acc: 0.639175\n",
      "Epoch 4356 - Train Loss: 0.184700, Train Acc: 0.646154 | Val Loss: 0.195024, Val Acc: 0.639175\n",
      "Epoch 4357 - Train Loss: 0.184684, Train Acc: 0.646154 | Val Loss: 0.195008, Val Acc: 0.639175\n",
      "Epoch 4358 - Train Loss: 0.184668, Train Acc: 0.646154 | Val Loss: 0.194993, Val Acc: 0.639175\n",
      "Epoch 4359 - Train Loss: 0.184652, Train Acc: 0.646154 | Val Loss: 0.194978, Val Acc: 0.639175\n",
      "Epoch 4360 - Train Loss: 0.184636, Train Acc: 0.646154 | Val Loss: 0.194963, Val Acc: 0.639175\n",
      "Epoch 4361 - Train Loss: 0.184620, Train Acc: 0.646154 | Val Loss: 0.194948, Val Acc: 0.649485\n",
      "Epoch 4362 - Train Loss: 0.184604, Train Acc: 0.646154 | Val Loss: 0.194932, Val Acc: 0.649485\n",
      "Epoch 4363 - Train Loss: 0.184589, Train Acc: 0.646154 | Val Loss: 0.194917, Val Acc: 0.649485\n",
      "Epoch 4364 - Train Loss: 0.184573, Train Acc: 0.646154 | Val Loss: 0.194902, Val Acc: 0.649485\n",
      "Epoch 4365 - Train Loss: 0.184557, Train Acc: 0.646154 | Val Loss: 0.194887, Val Acc: 0.649485\n",
      "Epoch 4366 - Train Loss: 0.184541, Train Acc: 0.646154 | Val Loss: 0.194872, Val Acc: 0.649485\n",
      "Epoch 4367 - Train Loss: 0.184525, Train Acc: 0.646154 | Val Loss: 0.194856, Val Acc: 0.649485\n",
      "Epoch 4368 - Train Loss: 0.184509, Train Acc: 0.646154 | Val Loss: 0.194841, Val Acc: 0.649485\n",
      "Epoch 4369 - Train Loss: 0.184493, Train Acc: 0.646154 | Val Loss: 0.194826, Val Acc: 0.649485\n",
      "Epoch 4370 - Train Loss: 0.184477, Train Acc: 0.646154 | Val Loss: 0.194811, Val Acc: 0.649485\n",
      "Epoch 4371 - Train Loss: 0.184461, Train Acc: 0.646154 | Val Loss: 0.194796, Val Acc: 0.649485\n",
      "Epoch 4372 - Train Loss: 0.184445, Train Acc: 0.646154 | Val Loss: 0.194780, Val Acc: 0.649485\n",
      "Epoch 4373 - Train Loss: 0.184429, Train Acc: 0.646154 | Val Loss: 0.194765, Val Acc: 0.649485\n",
      "Epoch 4374 - Train Loss: 0.184413, Train Acc: 0.646154 | Val Loss: 0.194750, Val Acc: 0.649485\n",
      "Epoch 4375 - Train Loss: 0.184397, Train Acc: 0.646154 | Val Loss: 0.194735, Val Acc: 0.649485\n",
      "Epoch 4376 - Train Loss: 0.184381, Train Acc: 0.646154 | Val Loss: 0.194720, Val Acc: 0.649485\n",
      "Epoch 4377 - Train Loss: 0.184366, Train Acc: 0.646154 | Val Loss: 0.194704, Val Acc: 0.649485\n",
      "Epoch 4378 - Train Loss: 0.184350, Train Acc: 0.646154 | Val Loss: 0.194689, Val Acc: 0.649485\n",
      "Epoch 4379 - Train Loss: 0.184334, Train Acc: 0.646154 | Val Loss: 0.194674, Val Acc: 0.649485\n",
      "Epoch 4380 - Train Loss: 0.184318, Train Acc: 0.646154 | Val Loss: 0.194659, Val Acc: 0.649485\n",
      "Epoch 4381 - Train Loss: 0.184302, Train Acc: 0.646154 | Val Loss: 0.194644, Val Acc: 0.649485\n",
      "Epoch 4382 - Train Loss: 0.184286, Train Acc: 0.646154 | Val Loss: 0.194629, Val Acc: 0.649485\n",
      "Epoch 4383 - Train Loss: 0.184270, Train Acc: 0.646154 | Val Loss: 0.194613, Val Acc: 0.649485\n",
      "Epoch 4384 - Train Loss: 0.184254, Train Acc: 0.646154 | Val Loss: 0.194598, Val Acc: 0.649485\n",
      "Epoch 4385 - Train Loss: 0.184238, Train Acc: 0.646154 | Val Loss: 0.194583, Val Acc: 0.649485\n",
      "Epoch 4386 - Train Loss: 0.184222, Train Acc: 0.646154 | Val Loss: 0.194568, Val Acc: 0.649485\n",
      "Epoch 4387 - Train Loss: 0.184206, Train Acc: 0.646154 | Val Loss: 0.194553, Val Acc: 0.649485\n",
      "Epoch 4388 - Train Loss: 0.184191, Train Acc: 0.646154 | Val Loss: 0.194538, Val Acc: 0.649485\n",
      "Epoch 4389 - Train Loss: 0.184175, Train Acc: 0.646154 | Val Loss: 0.194522, Val Acc: 0.649485\n",
      "Epoch 4390 - Train Loss: 0.184159, Train Acc: 0.646154 | Val Loss: 0.194507, Val Acc: 0.649485\n",
      "Epoch 4391 - Train Loss: 0.184143, Train Acc: 0.646154 | Val Loss: 0.194492, Val Acc: 0.649485\n",
      "Epoch 4392 - Train Loss: 0.184127, Train Acc: 0.646154 | Val Loss: 0.194477, Val Acc: 0.649485\n",
      "Epoch 4393 - Train Loss: 0.184111, Train Acc: 0.646154 | Val Loss: 0.194462, Val Acc: 0.649485\n",
      "Epoch 4394 - Train Loss: 0.184095, Train Acc: 0.646154 | Val Loss: 0.194447, Val Acc: 0.649485\n",
      "Epoch 4395 - Train Loss: 0.184079, Train Acc: 0.646154 | Val Loss: 0.194432, Val Acc: 0.649485\n",
      "Epoch 4396 - Train Loss: 0.184063, Train Acc: 0.646154 | Val Loss: 0.194416, Val Acc: 0.649485\n",
      "Epoch 4397 - Train Loss: 0.184048, Train Acc: 0.646154 | Val Loss: 0.194401, Val Acc: 0.649485\n",
      "Epoch 4398 - Train Loss: 0.184032, Train Acc: 0.646154 | Val Loss: 0.194386, Val Acc: 0.649485\n",
      "Epoch 4399 - Train Loss: 0.184016, Train Acc: 0.646154 | Val Loss: 0.194371, Val Acc: 0.649485\n",
      "Epoch 4400 - Train Loss: 0.184000, Train Acc: 0.646154 | Val Loss: 0.194356, Val Acc: 0.649485\n",
      "Epoch 4401 - Train Loss: 0.183984, Train Acc: 0.646154 | Val Loss: 0.194341, Val Acc: 0.649485\n",
      "Epoch 4402 - Train Loss: 0.183968, Train Acc: 0.646154 | Val Loss: 0.194326, Val Acc: 0.649485\n",
      "Epoch 4403 - Train Loss: 0.183952, Train Acc: 0.646154 | Val Loss: 0.194310, Val Acc: 0.649485\n",
      "Epoch 4404 - Train Loss: 0.183937, Train Acc: 0.646154 | Val Loss: 0.194295, Val Acc: 0.649485\n",
      "Epoch 4405 - Train Loss: 0.183921, Train Acc: 0.646154 | Val Loss: 0.194280, Val Acc: 0.649485\n",
      "Epoch 4406 - Train Loss: 0.183905, Train Acc: 0.646154 | Val Loss: 0.194265, Val Acc: 0.649485\n",
      "Epoch 4407 - Train Loss: 0.183889, Train Acc: 0.646154 | Val Loss: 0.194250, Val Acc: 0.649485\n",
      "Epoch 4408 - Train Loss: 0.183873, Train Acc: 0.646154 | Val Loss: 0.194235, Val Acc: 0.649485\n",
      "Epoch 4409 - Train Loss: 0.183857, Train Acc: 0.646154 | Val Loss: 0.194220, Val Acc: 0.649485\n",
      "Epoch 4410 - Train Loss: 0.183841, Train Acc: 0.646154 | Val Loss: 0.194205, Val Acc: 0.649485\n",
      "Epoch 4411 - Train Loss: 0.183826, Train Acc: 0.646154 | Val Loss: 0.194190, Val Acc: 0.649485\n",
      "Epoch 4412 - Train Loss: 0.183810, Train Acc: 0.646154 | Val Loss: 0.194174, Val Acc: 0.649485\n",
      "Epoch 4413 - Train Loss: 0.183794, Train Acc: 0.646154 | Val Loss: 0.194159, Val Acc: 0.649485\n",
      "Epoch 4414 - Train Loss: 0.183778, Train Acc: 0.646154 | Val Loss: 0.194144, Val Acc: 0.649485\n",
      "Epoch 4415 - Train Loss: 0.183762, Train Acc: 0.646154 | Val Loss: 0.194129, Val Acc: 0.649485\n",
      "Epoch 4416 - Train Loss: 0.183746, Train Acc: 0.646154 | Val Loss: 0.194114, Val Acc: 0.649485\n",
      "Epoch 4417 - Train Loss: 0.183730, Train Acc: 0.646154 | Val Loss: 0.194099, Val Acc: 0.649485\n",
      "Epoch 4418 - Train Loss: 0.183715, Train Acc: 0.646154 | Val Loss: 0.194084, Val Acc: 0.649485\n",
      "Epoch 4419 - Train Loss: 0.183699, Train Acc: 0.646154 | Val Loss: 0.194069, Val Acc: 0.649485\n",
      "Epoch 4420 - Train Loss: 0.183683, Train Acc: 0.646154 | Val Loss: 0.194054, Val Acc: 0.649485\n",
      "Epoch 4421 - Train Loss: 0.183667, Train Acc: 0.647436 | Val Loss: 0.194039, Val Acc: 0.649485\n",
      "Epoch 4422 - Train Loss: 0.183651, Train Acc: 0.647436 | Val Loss: 0.194023, Val Acc: 0.649485\n",
      "Epoch 4423 - Train Loss: 0.183635, Train Acc: 0.647436 | Val Loss: 0.194008, Val Acc: 0.649485\n",
      "Epoch 4424 - Train Loss: 0.183620, Train Acc: 0.648718 | Val Loss: 0.193993, Val Acc: 0.649485\n",
      "Epoch 4425 - Train Loss: 0.183604, Train Acc: 0.648718 | Val Loss: 0.193978, Val Acc: 0.649485\n",
      "Epoch 4426 - Train Loss: 0.183588, Train Acc: 0.648718 | Val Loss: 0.193963, Val Acc: 0.649485\n",
      "Epoch 4427 - Train Loss: 0.183572, Train Acc: 0.648718 | Val Loss: 0.193948, Val Acc: 0.649485\n",
      "Epoch 4428 - Train Loss: 0.183556, Train Acc: 0.648718 | Val Loss: 0.193933, Val Acc: 0.649485\n",
      "Epoch 4429 - Train Loss: 0.183541, Train Acc: 0.648718 | Val Loss: 0.193918, Val Acc: 0.649485\n",
      "Epoch 4430 - Train Loss: 0.183525, Train Acc: 0.648718 | Val Loss: 0.193903, Val Acc: 0.649485\n",
      "Epoch 4431 - Train Loss: 0.183509, Train Acc: 0.648718 | Val Loss: 0.193888, Val Acc: 0.649485\n",
      "Epoch 4432 - Train Loss: 0.183493, Train Acc: 0.648718 | Val Loss: 0.193873, Val Acc: 0.649485\n",
      "Epoch 4433 - Train Loss: 0.183477, Train Acc: 0.648718 | Val Loss: 0.193858, Val Acc: 0.649485\n",
      "Epoch 4434 - Train Loss: 0.183461, Train Acc: 0.648718 | Val Loss: 0.193843, Val Acc: 0.649485\n",
      "Epoch 4435 - Train Loss: 0.183446, Train Acc: 0.648718 | Val Loss: 0.193828, Val Acc: 0.649485\n",
      "Epoch 4436 - Train Loss: 0.183430, Train Acc: 0.648718 | Val Loss: 0.193813, Val Acc: 0.649485\n",
      "Epoch 4437 - Train Loss: 0.183414, Train Acc: 0.648718 | Val Loss: 0.193797, Val Acc: 0.649485\n",
      "Epoch 4438 - Train Loss: 0.183398, Train Acc: 0.648718 | Val Loss: 0.193782, Val Acc: 0.649485\n",
      "Epoch 4439 - Train Loss: 0.183382, Train Acc: 0.648718 | Val Loss: 0.193767, Val Acc: 0.649485\n",
      "Epoch 4440 - Train Loss: 0.183367, Train Acc: 0.648718 | Val Loss: 0.193752, Val Acc: 0.649485\n",
      "Epoch 4441 - Train Loss: 0.183351, Train Acc: 0.648718 | Val Loss: 0.193737, Val Acc: 0.649485\n",
      "Epoch 4442 - Train Loss: 0.183335, Train Acc: 0.648718 | Val Loss: 0.193722, Val Acc: 0.649485\n",
      "Epoch 4443 - Train Loss: 0.183319, Train Acc: 0.648718 | Val Loss: 0.193707, Val Acc: 0.649485\n",
      "Epoch 4444 - Train Loss: 0.183303, Train Acc: 0.648718 | Val Loss: 0.193692, Val Acc: 0.649485\n",
      "Epoch 4445 - Train Loss: 0.183288, Train Acc: 0.648718 | Val Loss: 0.193677, Val Acc: 0.649485\n",
      "Epoch 4446 - Train Loss: 0.183272, Train Acc: 0.648718 | Val Loss: 0.193662, Val Acc: 0.649485\n",
      "Epoch 4447 - Train Loss: 0.183256, Train Acc: 0.648718 | Val Loss: 0.193647, Val Acc: 0.649485\n",
      "Epoch 4448 - Train Loss: 0.183240, Train Acc: 0.648718 | Val Loss: 0.193632, Val Acc: 0.649485\n",
      "Epoch 4449 - Train Loss: 0.183225, Train Acc: 0.648718 | Val Loss: 0.193617, Val Acc: 0.649485\n",
      "Epoch 4450 - Train Loss: 0.183209, Train Acc: 0.648718 | Val Loss: 0.193603, Val Acc: 0.649485\n",
      "Epoch 4451 - Train Loss: 0.183193, Train Acc: 0.648718 | Val Loss: 0.193588, Val Acc: 0.649485\n",
      "Epoch 4452 - Train Loss: 0.183177, Train Acc: 0.648718 | Val Loss: 0.193573, Val Acc: 0.649485\n",
      "Epoch 4453 - Train Loss: 0.183161, Train Acc: 0.648718 | Val Loss: 0.193558, Val Acc: 0.649485\n",
      "Epoch 4454 - Train Loss: 0.183146, Train Acc: 0.648718 | Val Loss: 0.193543, Val Acc: 0.649485\n",
      "Epoch 4455 - Train Loss: 0.183130, Train Acc: 0.648718 | Val Loss: 0.193528, Val Acc: 0.649485\n",
      "Epoch 4456 - Train Loss: 0.183114, Train Acc: 0.648718 | Val Loss: 0.193513, Val Acc: 0.649485\n",
      "Epoch 4457 - Train Loss: 0.183098, Train Acc: 0.648718 | Val Loss: 0.193498, Val Acc: 0.649485\n",
      "Epoch 4458 - Train Loss: 0.183083, Train Acc: 0.648718 | Val Loss: 0.193483, Val Acc: 0.649485\n",
      "Epoch 4459 - Train Loss: 0.183067, Train Acc: 0.648718 | Val Loss: 0.193468, Val Acc: 0.649485\n",
      "Epoch 4460 - Train Loss: 0.183051, Train Acc: 0.648718 | Val Loss: 0.193453, Val Acc: 0.649485\n",
      "Epoch 4461 - Train Loss: 0.183035, Train Acc: 0.648718 | Val Loss: 0.193438, Val Acc: 0.649485\n",
      "Epoch 4462 - Train Loss: 0.183020, Train Acc: 0.648718 | Val Loss: 0.193423, Val Acc: 0.649485\n",
      "Epoch 4463 - Train Loss: 0.183004, Train Acc: 0.648718 | Val Loss: 0.193408, Val Acc: 0.649485\n",
      "Epoch 4464 - Train Loss: 0.182988, Train Acc: 0.648718 | Val Loss: 0.193393, Val Acc: 0.649485\n",
      "Epoch 4465 - Train Loss: 0.182972, Train Acc: 0.648718 | Val Loss: 0.193378, Val Acc: 0.649485\n",
      "Epoch 4466 - Train Loss: 0.182957, Train Acc: 0.650000 | Val Loss: 0.193363, Val Acc: 0.649485\n",
      "Epoch 4467 - Train Loss: 0.182941, Train Acc: 0.650000 | Val Loss: 0.193348, Val Acc: 0.649485\n",
      "Epoch 4468 - Train Loss: 0.182925, Train Acc: 0.650000 | Val Loss: 0.193333, Val Acc: 0.649485\n",
      "Epoch 4469 - Train Loss: 0.182909, Train Acc: 0.650000 | Val Loss: 0.193318, Val Acc: 0.649485\n",
      "Epoch 4470 - Train Loss: 0.182894, Train Acc: 0.650000 | Val Loss: 0.193303, Val Acc: 0.649485\n",
      "Epoch 4471 - Train Loss: 0.182878, Train Acc: 0.650000 | Val Loss: 0.193288, Val Acc: 0.649485\n",
      "Epoch 4472 - Train Loss: 0.182862, Train Acc: 0.650000 | Val Loss: 0.193273, Val Acc: 0.649485\n",
      "Epoch 4473 - Train Loss: 0.182846, Train Acc: 0.650000 | Val Loss: 0.193258, Val Acc: 0.649485\n",
      "Epoch 4474 - Train Loss: 0.182831, Train Acc: 0.650000 | Val Loss: 0.193244, Val Acc: 0.649485\n",
      "Epoch 4475 - Train Loss: 0.182815, Train Acc: 0.650000 | Val Loss: 0.193229, Val Acc: 0.649485\n",
      "Epoch 4476 - Train Loss: 0.182799, Train Acc: 0.650000 | Val Loss: 0.193214, Val Acc: 0.649485\n",
      "Epoch 4477 - Train Loss: 0.182783, Train Acc: 0.650000 | Val Loss: 0.193199, Val Acc: 0.649485\n",
      "Epoch 4478 - Train Loss: 0.182768, Train Acc: 0.650000 | Val Loss: 0.193184, Val Acc: 0.649485\n",
      "Epoch 4479 - Train Loss: 0.182752, Train Acc: 0.650000 | Val Loss: 0.193169, Val Acc: 0.649485\n",
      "Epoch 4480 - Train Loss: 0.182736, Train Acc: 0.650000 | Val Loss: 0.193154, Val Acc: 0.649485\n",
      "Epoch 4481 - Train Loss: 0.182721, Train Acc: 0.650000 | Val Loss: 0.193139, Val Acc: 0.649485\n",
      "Epoch 4482 - Train Loss: 0.182705, Train Acc: 0.650000 | Val Loss: 0.193124, Val Acc: 0.649485\n",
      "Epoch 4483 - Train Loss: 0.182689, Train Acc: 0.650000 | Val Loss: 0.193109, Val Acc: 0.649485\n",
      "Epoch 4484 - Train Loss: 0.182673, Train Acc: 0.650000 | Val Loss: 0.193094, Val Acc: 0.649485\n",
      "Epoch 4485 - Train Loss: 0.182658, Train Acc: 0.651282 | Val Loss: 0.193079, Val Acc: 0.649485\n",
      "Epoch 4486 - Train Loss: 0.182642, Train Acc: 0.651282 | Val Loss: 0.193064, Val Acc: 0.649485\n",
      "Epoch 4487 - Train Loss: 0.182626, Train Acc: 0.651282 | Val Loss: 0.193049, Val Acc: 0.649485\n",
      "Epoch 4488 - Train Loss: 0.182611, Train Acc: 0.651282 | Val Loss: 0.193034, Val Acc: 0.649485\n",
      "Epoch 4489 - Train Loss: 0.182595, Train Acc: 0.651282 | Val Loss: 0.193019, Val Acc: 0.649485\n",
      "Epoch 4490 - Train Loss: 0.182579, Train Acc: 0.651282 | Val Loss: 0.193004, Val Acc: 0.649485\n",
      "Epoch 4491 - Train Loss: 0.182563, Train Acc: 0.651282 | Val Loss: 0.192990, Val Acc: 0.649485\n",
      "Epoch 4492 - Train Loss: 0.182548, Train Acc: 0.651282 | Val Loss: 0.192975, Val Acc: 0.649485\n",
      "Epoch 4493 - Train Loss: 0.182532, Train Acc: 0.651282 | Val Loss: 0.192960, Val Acc: 0.649485\n",
      "Epoch 4494 - Train Loss: 0.182516, Train Acc: 0.652564 | Val Loss: 0.192945, Val Acc: 0.649485\n",
      "Epoch 4495 - Train Loss: 0.182501, Train Acc: 0.652564 | Val Loss: 0.192930, Val Acc: 0.649485\n",
      "Epoch 4496 - Train Loss: 0.182485, Train Acc: 0.652564 | Val Loss: 0.192915, Val Acc: 0.649485\n",
      "Epoch 4497 - Train Loss: 0.182469, Train Acc: 0.652564 | Val Loss: 0.192900, Val Acc: 0.649485\n",
      "Epoch 4498 - Train Loss: 0.182454, Train Acc: 0.652564 | Val Loss: 0.192885, Val Acc: 0.649485\n",
      "Epoch 4499 - Train Loss: 0.182438, Train Acc: 0.652564 | Val Loss: 0.192870, Val Acc: 0.649485\n",
      "Epoch 4500 - Train Loss: 0.182422, Train Acc: 0.652564 | Val Loss: 0.192855, Val Acc: 0.649485\n",
      "Epoch 4501 - Train Loss: 0.182407, Train Acc: 0.652564 | Val Loss: 0.192840, Val Acc: 0.649485\n",
      "Epoch 4502 - Train Loss: 0.182391, Train Acc: 0.652564 | Val Loss: 0.192825, Val Acc: 0.649485\n",
      "Epoch 4503 - Train Loss: 0.182375, Train Acc: 0.652564 | Val Loss: 0.192811, Val Acc: 0.649485\n",
      "Epoch 4504 - Train Loss: 0.182359, Train Acc: 0.652564 | Val Loss: 0.192796, Val Acc: 0.649485\n",
      "Epoch 4505 - Train Loss: 0.182344, Train Acc: 0.652564 | Val Loss: 0.192781, Val Acc: 0.649485\n",
      "Epoch 4506 - Train Loss: 0.182328, Train Acc: 0.652564 | Val Loss: 0.192766, Val Acc: 0.649485\n",
      "Epoch 4507 - Train Loss: 0.182312, Train Acc: 0.652564 | Val Loss: 0.192751, Val Acc: 0.649485\n",
      "Epoch 4508 - Train Loss: 0.182297, Train Acc: 0.652564 | Val Loss: 0.192736, Val Acc: 0.649485\n",
      "Epoch 4509 - Train Loss: 0.182281, Train Acc: 0.652564 | Val Loss: 0.192721, Val Acc: 0.649485\n",
      "Epoch 4510 - Train Loss: 0.182265, Train Acc: 0.652564 | Val Loss: 0.192706, Val Acc: 0.649485\n",
      "Epoch 4511 - Train Loss: 0.182250, Train Acc: 0.652564 | Val Loss: 0.192691, Val Acc: 0.649485\n",
      "Epoch 4512 - Train Loss: 0.182234, Train Acc: 0.652564 | Val Loss: 0.192677, Val Acc: 0.649485\n",
      "Epoch 4513 - Train Loss: 0.182218, Train Acc: 0.652564 | Val Loss: 0.192662, Val Acc: 0.649485\n",
      "Epoch 4514 - Train Loss: 0.182203, Train Acc: 0.652564 | Val Loss: 0.192647, Val Acc: 0.649485\n",
      "Epoch 4515 - Train Loss: 0.182187, Train Acc: 0.652564 | Val Loss: 0.192632, Val Acc: 0.649485\n",
      "Epoch 4516 - Train Loss: 0.182171, Train Acc: 0.652564 | Val Loss: 0.192617, Val Acc: 0.649485\n",
      "Epoch 4517 - Train Loss: 0.182156, Train Acc: 0.652564 | Val Loss: 0.192602, Val Acc: 0.649485\n",
      "Epoch 4518 - Train Loss: 0.182140, Train Acc: 0.652564 | Val Loss: 0.192587, Val Acc: 0.649485\n",
      "Epoch 4519 - Train Loss: 0.182124, Train Acc: 0.652564 | Val Loss: 0.192572, Val Acc: 0.649485\n",
      "Epoch 4520 - Train Loss: 0.182109, Train Acc: 0.652564 | Val Loss: 0.192558, Val Acc: 0.649485\n",
      "Epoch 4521 - Train Loss: 0.182093, Train Acc: 0.652564 | Val Loss: 0.192543, Val Acc: 0.649485\n",
      "Epoch 4522 - Train Loss: 0.182077, Train Acc: 0.652564 | Val Loss: 0.192528, Val Acc: 0.649485\n",
      "Epoch 4523 - Train Loss: 0.182062, Train Acc: 0.652564 | Val Loss: 0.192513, Val Acc: 0.649485\n",
      "Epoch 4524 - Train Loss: 0.182046, Train Acc: 0.652564 | Val Loss: 0.192498, Val Acc: 0.649485\n",
      "Epoch 4525 - Train Loss: 0.182031, Train Acc: 0.652564 | Val Loss: 0.192483, Val Acc: 0.649485\n",
      "Epoch 4526 - Train Loss: 0.182015, Train Acc: 0.652564 | Val Loss: 0.192469, Val Acc: 0.649485\n",
      "Epoch 4527 - Train Loss: 0.181999, Train Acc: 0.652564 | Val Loss: 0.192454, Val Acc: 0.649485\n",
      "Epoch 4528 - Train Loss: 0.181984, Train Acc: 0.652564 | Val Loss: 0.192439, Val Acc: 0.649485\n",
      "Epoch 4529 - Train Loss: 0.181968, Train Acc: 0.652564 | Val Loss: 0.192424, Val Acc: 0.649485\n",
      "Epoch 4530 - Train Loss: 0.181952, Train Acc: 0.652564 | Val Loss: 0.192409, Val Acc: 0.649485\n",
      "Epoch 4531 - Train Loss: 0.181937, Train Acc: 0.652564 | Val Loss: 0.192394, Val Acc: 0.649485\n",
      "Epoch 4532 - Train Loss: 0.181921, Train Acc: 0.652564 | Val Loss: 0.192379, Val Acc: 0.649485\n",
      "Epoch 4533 - Train Loss: 0.181905, Train Acc: 0.652564 | Val Loss: 0.192365, Val Acc: 0.649485\n",
      "Epoch 4534 - Train Loss: 0.181890, Train Acc: 0.652564 | Val Loss: 0.192350, Val Acc: 0.649485\n",
      "Epoch 4535 - Train Loss: 0.181874, Train Acc: 0.652564 | Val Loss: 0.192335, Val Acc: 0.649485\n",
      "Epoch 4536 - Train Loss: 0.181859, Train Acc: 0.652564 | Val Loss: 0.192320, Val Acc: 0.649485\n",
      "Epoch 4537 - Train Loss: 0.181843, Train Acc: 0.652564 | Val Loss: 0.192305, Val Acc: 0.649485\n",
      "Epoch 4538 - Train Loss: 0.181827, Train Acc: 0.652564 | Val Loss: 0.192291, Val Acc: 0.649485\n",
      "Epoch 4539 - Train Loss: 0.181812, Train Acc: 0.652564 | Val Loss: 0.192276, Val Acc: 0.649485\n",
      "Epoch 4540 - Train Loss: 0.181796, Train Acc: 0.652564 | Val Loss: 0.192261, Val Acc: 0.649485\n",
      "Epoch 4541 - Train Loss: 0.181781, Train Acc: 0.652564 | Val Loss: 0.192246, Val Acc: 0.649485\n",
      "Epoch 4542 - Train Loss: 0.181765, Train Acc: 0.652564 | Val Loss: 0.192231, Val Acc: 0.649485\n",
      "Epoch 4543 - Train Loss: 0.181749, Train Acc: 0.652564 | Val Loss: 0.192217, Val Acc: 0.649485\n",
      "Epoch 4544 - Train Loss: 0.181734, Train Acc: 0.652564 | Val Loss: 0.192202, Val Acc: 0.649485\n",
      "Epoch 4545 - Train Loss: 0.181718, Train Acc: 0.652564 | Val Loss: 0.192187, Val Acc: 0.649485\n",
      "Epoch 4546 - Train Loss: 0.181703, Train Acc: 0.652564 | Val Loss: 0.192172, Val Acc: 0.649485\n",
      "Epoch 4547 - Train Loss: 0.181687, Train Acc: 0.652564 | Val Loss: 0.192157, Val Acc: 0.649485\n",
      "Epoch 4548 - Train Loss: 0.181671, Train Acc: 0.652564 | Val Loss: 0.192143, Val Acc: 0.649485\n",
      "Epoch 4549 - Train Loss: 0.181656, Train Acc: 0.652564 | Val Loss: 0.192128, Val Acc: 0.649485\n",
      "Epoch 4550 - Train Loss: 0.181640, Train Acc: 0.652564 | Val Loss: 0.192113, Val Acc: 0.649485\n",
      "Epoch 4551 - Train Loss: 0.181625, Train Acc: 0.652564 | Val Loss: 0.192098, Val Acc: 0.649485\n",
      "Epoch 4552 - Train Loss: 0.181609, Train Acc: 0.652564 | Val Loss: 0.192083, Val Acc: 0.649485\n",
      "Epoch 4553 - Train Loss: 0.181593, Train Acc: 0.652564 | Val Loss: 0.192069, Val Acc: 0.649485\n",
      "Epoch 4554 - Train Loss: 0.181578, Train Acc: 0.652564 | Val Loss: 0.192054, Val Acc: 0.649485\n",
      "Epoch 4555 - Train Loss: 0.181562, Train Acc: 0.652564 | Val Loss: 0.192039, Val Acc: 0.649485\n",
      "Epoch 4556 - Train Loss: 0.181547, Train Acc: 0.652564 | Val Loss: 0.192024, Val Acc: 0.649485\n",
      "Epoch 4557 - Train Loss: 0.181531, Train Acc: 0.652564 | Val Loss: 0.192010, Val Acc: 0.649485\n",
      "Epoch 4558 - Train Loss: 0.181515, Train Acc: 0.652564 | Val Loss: 0.191995, Val Acc: 0.649485\n",
      "Epoch 4559 - Train Loss: 0.181500, Train Acc: 0.652564 | Val Loss: 0.191980, Val Acc: 0.649485\n",
      "Epoch 4560 - Train Loss: 0.181484, Train Acc: 0.652564 | Val Loss: 0.191965, Val Acc: 0.649485\n",
      "Epoch 4561 - Train Loss: 0.181469, Train Acc: 0.652564 | Val Loss: 0.191951, Val Acc: 0.649485\n",
      "Epoch 4562 - Train Loss: 0.181453, Train Acc: 0.652564 | Val Loss: 0.191936, Val Acc: 0.649485\n",
      "Epoch 4563 - Train Loss: 0.181438, Train Acc: 0.652564 | Val Loss: 0.191921, Val Acc: 0.649485\n",
      "Epoch 4564 - Train Loss: 0.181422, Train Acc: 0.652564 | Val Loss: 0.191906, Val Acc: 0.649485\n",
      "Epoch 4565 - Train Loss: 0.181406, Train Acc: 0.652564 | Val Loss: 0.191892, Val Acc: 0.649485\n",
      "Epoch 4566 - Train Loss: 0.181391, Train Acc: 0.652564 | Val Loss: 0.191877, Val Acc: 0.649485\n",
      "Epoch 4567 - Train Loss: 0.181375, Train Acc: 0.652564 | Val Loss: 0.191862, Val Acc: 0.649485\n",
      "Epoch 4568 - Train Loss: 0.181360, Train Acc: 0.652564 | Val Loss: 0.191847, Val Acc: 0.649485\n",
      "Epoch 4569 - Train Loss: 0.181344, Train Acc: 0.652564 | Val Loss: 0.191833, Val Acc: 0.649485\n",
      "Epoch 4570 - Train Loss: 0.181329, Train Acc: 0.652564 | Val Loss: 0.191818, Val Acc: 0.649485\n",
      "Epoch 4571 - Train Loss: 0.181313, Train Acc: 0.652564 | Val Loss: 0.191803, Val Acc: 0.649485\n",
      "Epoch 4572 - Train Loss: 0.181298, Train Acc: 0.652564 | Val Loss: 0.191789, Val Acc: 0.649485\n",
      "Epoch 4573 - Train Loss: 0.181282, Train Acc: 0.652564 | Val Loss: 0.191774, Val Acc: 0.649485\n",
      "Epoch 4574 - Train Loss: 0.181266, Train Acc: 0.652564 | Val Loss: 0.191759, Val Acc: 0.649485\n",
      "Epoch 4575 - Train Loss: 0.181251, Train Acc: 0.652564 | Val Loss: 0.191744, Val Acc: 0.649485\n",
      "Epoch 4576 - Train Loss: 0.181235, Train Acc: 0.652564 | Val Loss: 0.191730, Val Acc: 0.649485\n",
      "Epoch 4577 - Train Loss: 0.181220, Train Acc: 0.652564 | Val Loss: 0.191715, Val Acc: 0.649485\n",
      "Epoch 4578 - Train Loss: 0.181204, Train Acc: 0.652564 | Val Loss: 0.191700, Val Acc: 0.649485\n",
      "Epoch 4579 - Train Loss: 0.181189, Train Acc: 0.652564 | Val Loss: 0.191685, Val Acc: 0.649485\n",
      "Epoch 4580 - Train Loss: 0.181173, Train Acc: 0.652564 | Val Loss: 0.191671, Val Acc: 0.649485\n",
      "Epoch 4581 - Train Loss: 0.181158, Train Acc: 0.652564 | Val Loss: 0.191656, Val Acc: 0.649485\n",
      "Epoch 4582 - Train Loss: 0.181142, Train Acc: 0.652564 | Val Loss: 0.191641, Val Acc: 0.649485\n",
      "Epoch 4583 - Train Loss: 0.181127, Train Acc: 0.652564 | Val Loss: 0.191627, Val Acc: 0.649485\n",
      "Epoch 4584 - Train Loss: 0.181111, Train Acc: 0.652564 | Val Loss: 0.191612, Val Acc: 0.649485\n",
      "Epoch 4585 - Train Loss: 0.181096, Train Acc: 0.652564 | Val Loss: 0.191597, Val Acc: 0.649485\n",
      "Epoch 4586 - Train Loss: 0.181080, Train Acc: 0.652564 | Val Loss: 0.191583, Val Acc: 0.649485\n",
      "Epoch 4587 - Train Loss: 0.181064, Train Acc: 0.652564 | Val Loss: 0.191568, Val Acc: 0.649485\n",
      "Epoch 4588 - Train Loss: 0.181049, Train Acc: 0.651282 | Val Loss: 0.191553, Val Acc: 0.649485\n",
      "Epoch 4589 - Train Loss: 0.181033, Train Acc: 0.651282 | Val Loss: 0.191538, Val Acc: 0.649485\n",
      "Epoch 4590 - Train Loss: 0.181018, Train Acc: 0.651282 | Val Loss: 0.191524, Val Acc: 0.649485\n",
      "Epoch 4591 - Train Loss: 0.181002, Train Acc: 0.651282 | Val Loss: 0.191509, Val Acc: 0.649485\n",
      "Epoch 4592 - Train Loss: 0.180987, Train Acc: 0.651282 | Val Loss: 0.191494, Val Acc: 0.649485\n",
      "Epoch 4593 - Train Loss: 0.180971, Train Acc: 0.651282 | Val Loss: 0.191480, Val Acc: 0.649485\n",
      "Epoch 4594 - Train Loss: 0.180956, Train Acc: 0.651282 | Val Loss: 0.191465, Val Acc: 0.649485\n",
      "Epoch 4595 - Train Loss: 0.180940, Train Acc: 0.651282 | Val Loss: 0.191450, Val Acc: 0.649485\n",
      "Epoch 4596 - Train Loss: 0.180925, Train Acc: 0.651282 | Val Loss: 0.191436, Val Acc: 0.649485\n",
      "Epoch 4597 - Train Loss: 0.180909, Train Acc: 0.651282 | Val Loss: 0.191421, Val Acc: 0.649485\n",
      "Epoch 4598 - Train Loss: 0.180894, Train Acc: 0.652564 | Val Loss: 0.191406, Val Acc: 0.649485\n",
      "Epoch 4599 - Train Loss: 0.180878, Train Acc: 0.652564 | Val Loss: 0.191392, Val Acc: 0.649485\n",
      "Epoch 4600 - Train Loss: 0.180863, Train Acc: 0.652564 | Val Loss: 0.191377, Val Acc: 0.649485\n",
      "Epoch 4601 - Train Loss: 0.180847, Train Acc: 0.652564 | Val Loss: 0.191362, Val Acc: 0.649485\n",
      "Epoch 4602 - Train Loss: 0.180832, Train Acc: 0.652564 | Val Loss: 0.191348, Val Acc: 0.649485\n",
      "Epoch 4603 - Train Loss: 0.180816, Train Acc: 0.652564 | Val Loss: 0.191333, Val Acc: 0.649485\n",
      "Epoch 4604 - Train Loss: 0.180801, Train Acc: 0.652564 | Val Loss: 0.191318, Val Acc: 0.649485\n",
      "Epoch 4605 - Train Loss: 0.180785, Train Acc: 0.652564 | Val Loss: 0.191304, Val Acc: 0.649485\n",
      "Epoch 4606 - Train Loss: 0.180770, Train Acc: 0.652564 | Val Loss: 0.191289, Val Acc: 0.649485\n",
      "Epoch 4607 - Train Loss: 0.180754, Train Acc: 0.652564 | Val Loss: 0.191274, Val Acc: 0.649485\n",
      "Epoch 4608 - Train Loss: 0.180739, Train Acc: 0.652564 | Val Loss: 0.191260, Val Acc: 0.649485\n",
      "Epoch 4609 - Train Loss: 0.180723, Train Acc: 0.652564 | Val Loss: 0.191245, Val Acc: 0.649485\n",
      "Epoch 4610 - Train Loss: 0.180708, Train Acc: 0.652564 | Val Loss: 0.191230, Val Acc: 0.649485\n",
      "Epoch 4611 - Train Loss: 0.180692, Train Acc: 0.652564 | Val Loss: 0.191216, Val Acc: 0.649485\n",
      "Epoch 4612 - Train Loss: 0.180677, Train Acc: 0.652564 | Val Loss: 0.191201, Val Acc: 0.649485\n",
      "Epoch 4613 - Train Loss: 0.180661, Train Acc: 0.652564 | Val Loss: 0.191186, Val Acc: 0.649485\n",
      "Epoch 4614 - Train Loss: 0.180646, Train Acc: 0.652564 | Val Loss: 0.191172, Val Acc: 0.649485\n",
      "Epoch 4615 - Train Loss: 0.180630, Train Acc: 0.652564 | Val Loss: 0.191157, Val Acc: 0.649485\n",
      "Epoch 4616 - Train Loss: 0.180615, Train Acc: 0.652564 | Val Loss: 0.191142, Val Acc: 0.649485\n",
      "Epoch 4617 - Train Loss: 0.180600, Train Acc: 0.652564 | Val Loss: 0.191128, Val Acc: 0.649485\n",
      "Epoch 4618 - Train Loss: 0.180584, Train Acc: 0.652564 | Val Loss: 0.191113, Val Acc: 0.649485\n",
      "Epoch 4619 - Train Loss: 0.180569, Train Acc: 0.652564 | Val Loss: 0.191098, Val Acc: 0.649485\n",
      "Epoch 4620 - Train Loss: 0.180553, Train Acc: 0.652564 | Val Loss: 0.191084, Val Acc: 0.649485\n",
      "Epoch 4621 - Train Loss: 0.180538, Train Acc: 0.652564 | Val Loss: 0.191069, Val Acc: 0.649485\n",
      "Epoch 4622 - Train Loss: 0.180522, Train Acc: 0.652564 | Val Loss: 0.191054, Val Acc: 0.649485\n",
      "Epoch 4623 - Train Loss: 0.180507, Train Acc: 0.652564 | Val Loss: 0.191040, Val Acc: 0.649485\n",
      "Epoch 4624 - Train Loss: 0.180491, Train Acc: 0.652564 | Val Loss: 0.191025, Val Acc: 0.649485\n",
      "Epoch 4625 - Train Loss: 0.180476, Train Acc: 0.652564 | Val Loss: 0.191010, Val Acc: 0.649485\n",
      "Epoch 4626 - Train Loss: 0.180460, Train Acc: 0.652564 | Val Loss: 0.190996, Val Acc: 0.649485\n",
      "Epoch 4627 - Train Loss: 0.180445, Train Acc: 0.652564 | Val Loss: 0.190981, Val Acc: 0.649485\n",
      "Epoch 4628 - Train Loss: 0.180429, Train Acc: 0.652564 | Val Loss: 0.190966, Val Acc: 0.649485\n",
      "Epoch 4629 - Train Loss: 0.180414, Train Acc: 0.652564 | Val Loss: 0.190952, Val Acc: 0.649485\n",
      "Epoch 4630 - Train Loss: 0.180399, Train Acc: 0.652564 | Val Loss: 0.190937, Val Acc: 0.649485\n",
      "Epoch 4631 - Train Loss: 0.180383, Train Acc: 0.652564 | Val Loss: 0.190923, Val Acc: 0.649485\n",
      "Epoch 4632 - Train Loss: 0.180368, Train Acc: 0.652564 | Val Loss: 0.190908, Val Acc: 0.649485\n",
      "Epoch 4633 - Train Loss: 0.180352, Train Acc: 0.652564 | Val Loss: 0.190893, Val Acc: 0.649485\n",
      "Epoch 4634 - Train Loss: 0.180337, Train Acc: 0.652564 | Val Loss: 0.190879, Val Acc: 0.649485\n",
      "Epoch 4635 - Train Loss: 0.180321, Train Acc: 0.652564 | Val Loss: 0.190864, Val Acc: 0.649485\n",
      "Epoch 4636 - Train Loss: 0.180306, Train Acc: 0.652564 | Val Loss: 0.190849, Val Acc: 0.649485\n",
      "Epoch 4637 - Train Loss: 0.180290, Train Acc: 0.652564 | Val Loss: 0.190835, Val Acc: 0.649485\n",
      "Epoch 4638 - Train Loss: 0.180275, Train Acc: 0.652564 | Val Loss: 0.190820, Val Acc: 0.649485\n",
      "Epoch 4639 - Train Loss: 0.180260, Train Acc: 0.652564 | Val Loss: 0.190805, Val Acc: 0.649485\n",
      "Epoch 4640 - Train Loss: 0.180244, Train Acc: 0.652564 | Val Loss: 0.190791, Val Acc: 0.649485\n",
      "Epoch 4641 - Train Loss: 0.180229, Train Acc: 0.652564 | Val Loss: 0.190776, Val Acc: 0.649485\n",
      "Epoch 4642 - Train Loss: 0.180213, Train Acc: 0.652564 | Val Loss: 0.190762, Val Acc: 0.649485\n",
      "Epoch 4643 - Train Loss: 0.180198, Train Acc: 0.652564 | Val Loss: 0.190747, Val Acc: 0.649485\n",
      "Epoch 4644 - Train Loss: 0.180182, Train Acc: 0.652564 | Val Loss: 0.190732, Val Acc: 0.649485\n",
      "Epoch 4645 - Train Loss: 0.180167, Train Acc: 0.652564 | Val Loss: 0.190718, Val Acc: 0.649485\n",
      "Epoch 4646 - Train Loss: 0.180152, Train Acc: 0.652564 | Val Loss: 0.190703, Val Acc: 0.649485\n",
      "Epoch 4647 - Train Loss: 0.180136, Train Acc: 0.652564 | Val Loss: 0.190688, Val Acc: 0.649485\n",
      "Epoch 4648 - Train Loss: 0.180121, Train Acc: 0.652564 | Val Loss: 0.190674, Val Acc: 0.649485\n",
      "Epoch 4649 - Train Loss: 0.180105, Train Acc: 0.652564 | Val Loss: 0.190659, Val Acc: 0.649485\n",
      "Epoch 4650 - Train Loss: 0.180090, Train Acc: 0.652564 | Val Loss: 0.190645, Val Acc: 0.649485\n",
      "Epoch 4651 - Train Loss: 0.180074, Train Acc: 0.652564 | Val Loss: 0.190630, Val Acc: 0.649485\n",
      "Epoch 4652 - Train Loss: 0.180059, Train Acc: 0.652564 | Val Loss: 0.190615, Val Acc: 0.649485\n",
      "Epoch 4653 - Train Loss: 0.180044, Train Acc: 0.652564 | Val Loss: 0.190601, Val Acc: 0.649485\n",
      "Epoch 4654 - Train Loss: 0.180028, Train Acc: 0.652564 | Val Loss: 0.190586, Val Acc: 0.649485\n",
      "Epoch 4655 - Train Loss: 0.180013, Train Acc: 0.652564 | Val Loss: 0.190572, Val Acc: 0.649485\n",
      "Epoch 4656 - Train Loss: 0.179997, Train Acc: 0.652564 | Val Loss: 0.190557, Val Acc: 0.649485\n",
      "Epoch 4657 - Train Loss: 0.179982, Train Acc: 0.652564 | Val Loss: 0.190542, Val Acc: 0.649485\n",
      "Epoch 4658 - Train Loss: 0.179967, Train Acc: 0.652564 | Val Loss: 0.190528, Val Acc: 0.649485\n",
      "Epoch 4659 - Train Loss: 0.179951, Train Acc: 0.652564 | Val Loss: 0.190513, Val Acc: 0.649485\n",
      "Epoch 4660 - Train Loss: 0.179936, Train Acc: 0.652564 | Val Loss: 0.190499, Val Acc: 0.649485\n",
      "Epoch 4661 - Train Loss: 0.179920, Train Acc: 0.652564 | Val Loss: 0.190484, Val Acc: 0.649485\n",
      "Epoch 4662 - Train Loss: 0.179905, Train Acc: 0.652564 | Val Loss: 0.190470, Val Acc: 0.649485\n",
      "Epoch 4663 - Train Loss: 0.179890, Train Acc: 0.652564 | Val Loss: 0.190455, Val Acc: 0.649485\n",
      "Epoch 4664 - Train Loss: 0.179874, Train Acc: 0.652564 | Val Loss: 0.190440, Val Acc: 0.649485\n",
      "Epoch 4665 - Train Loss: 0.179859, Train Acc: 0.652564 | Val Loss: 0.190426, Val Acc: 0.649485\n",
      "Epoch 4666 - Train Loss: 0.179843, Train Acc: 0.652564 | Val Loss: 0.190411, Val Acc: 0.649485\n",
      "Epoch 4667 - Train Loss: 0.179828, Train Acc: 0.652564 | Val Loss: 0.190397, Val Acc: 0.649485\n",
      "Epoch 4668 - Train Loss: 0.179813, Train Acc: 0.652564 | Val Loss: 0.190382, Val Acc: 0.649485\n",
      "Epoch 4669 - Train Loss: 0.179797, Train Acc: 0.652564 | Val Loss: 0.190367, Val Acc: 0.649485\n",
      "Epoch 4670 - Train Loss: 0.179782, Train Acc: 0.652564 | Val Loss: 0.190353, Val Acc: 0.649485\n",
      "Epoch 4671 - Train Loss: 0.179766, Train Acc: 0.652564 | Val Loss: 0.190338, Val Acc: 0.649485\n",
      "Epoch 4672 - Train Loss: 0.179751, Train Acc: 0.652564 | Val Loss: 0.190324, Val Acc: 0.649485\n",
      "Epoch 4673 - Train Loss: 0.179736, Train Acc: 0.652564 | Val Loss: 0.190309, Val Acc: 0.649485\n",
      "Epoch 4674 - Train Loss: 0.179720, Train Acc: 0.652564 | Val Loss: 0.190295, Val Acc: 0.649485\n",
      "Epoch 4675 - Train Loss: 0.179705, Train Acc: 0.652564 | Val Loss: 0.190280, Val Acc: 0.649485\n",
      "Epoch 4676 - Train Loss: 0.179689, Train Acc: 0.652564 | Val Loss: 0.190265, Val Acc: 0.649485\n",
      "Epoch 4677 - Train Loss: 0.179674, Train Acc: 0.652564 | Val Loss: 0.190251, Val Acc: 0.649485\n",
      "Epoch 4678 - Train Loss: 0.179659, Train Acc: 0.652564 | Val Loss: 0.190236, Val Acc: 0.649485\n",
      "Epoch 4679 - Train Loss: 0.179643, Train Acc: 0.652564 | Val Loss: 0.190222, Val Acc: 0.649485\n",
      "Epoch 4680 - Train Loss: 0.179628, Train Acc: 0.652564 | Val Loss: 0.190207, Val Acc: 0.649485\n",
      "Epoch 4681 - Train Loss: 0.179613, Train Acc: 0.652564 | Val Loss: 0.190193, Val Acc: 0.649485\n",
      "Epoch 4682 - Train Loss: 0.179597, Train Acc: 0.652564 | Val Loss: 0.190178, Val Acc: 0.649485\n",
      "Epoch 4683 - Train Loss: 0.179582, Train Acc: 0.652564 | Val Loss: 0.190164, Val Acc: 0.649485\n",
      "Epoch 4684 - Train Loss: 0.179566, Train Acc: 0.652564 | Val Loss: 0.190149, Val Acc: 0.649485\n",
      "Epoch 4685 - Train Loss: 0.179551, Train Acc: 0.652564 | Val Loss: 0.190135, Val Acc: 0.649485\n",
      "Epoch 4686 - Train Loss: 0.179536, Train Acc: 0.652564 | Val Loss: 0.190120, Val Acc: 0.649485\n",
      "Epoch 4687 - Train Loss: 0.179520, Train Acc: 0.652564 | Val Loss: 0.190106, Val Acc: 0.649485\n",
      "Epoch 4688 - Train Loss: 0.179505, Train Acc: 0.652564 | Val Loss: 0.190091, Val Acc: 0.649485\n",
      "Epoch 4689 - Train Loss: 0.179489, Train Acc: 0.652564 | Val Loss: 0.190077, Val Acc: 0.649485\n",
      "Epoch 4690 - Train Loss: 0.179474, Train Acc: 0.652564 | Val Loss: 0.190062, Val Acc: 0.649485\n",
      "Epoch 4691 - Train Loss: 0.179459, Train Acc: 0.652564 | Val Loss: 0.190047, Val Acc: 0.649485\n",
      "Epoch 4692 - Train Loss: 0.179443, Train Acc: 0.652564 | Val Loss: 0.190033, Val Acc: 0.649485\n",
      "Epoch 4693 - Train Loss: 0.179428, Train Acc: 0.652564 | Val Loss: 0.190018, Val Acc: 0.649485\n",
      "Epoch 4694 - Train Loss: 0.179413, Train Acc: 0.652564 | Val Loss: 0.190004, Val Acc: 0.649485\n",
      "Epoch 4695 - Train Loss: 0.179397, Train Acc: 0.652564 | Val Loss: 0.189989, Val Acc: 0.649485\n",
      "Epoch 4696 - Train Loss: 0.179382, Train Acc: 0.652564 | Val Loss: 0.189975, Val Acc: 0.649485\n",
      "Epoch 4697 - Train Loss: 0.179367, Train Acc: 0.652564 | Val Loss: 0.189960, Val Acc: 0.649485\n",
      "Epoch 4698 - Train Loss: 0.179351, Train Acc: 0.652564 | Val Loss: 0.189946, Val Acc: 0.649485\n",
      "Epoch 4699 - Train Loss: 0.179336, Train Acc: 0.652564 | Val Loss: 0.189931, Val Acc: 0.649485\n",
      "Epoch 4700 - Train Loss: 0.179321, Train Acc: 0.652564 | Val Loss: 0.189917, Val Acc: 0.649485\n",
      "Epoch 4701 - Train Loss: 0.179305, Train Acc: 0.652564 | Val Loss: 0.189902, Val Acc: 0.649485\n",
      "Epoch 4702 - Train Loss: 0.179290, Train Acc: 0.652564 | Val Loss: 0.189888, Val Acc: 0.649485\n",
      "Epoch 4703 - Train Loss: 0.179275, Train Acc: 0.652564 | Val Loss: 0.189873, Val Acc: 0.649485\n",
      "Epoch 4704 - Train Loss: 0.179259, Train Acc: 0.652564 | Val Loss: 0.189859, Val Acc: 0.649485\n",
      "Epoch 4705 - Train Loss: 0.179244, Train Acc: 0.652564 | Val Loss: 0.189844, Val Acc: 0.649485\n",
      "Epoch 4706 - Train Loss: 0.179228, Train Acc: 0.652564 | Val Loss: 0.189830, Val Acc: 0.649485\n",
      "Epoch 4707 - Train Loss: 0.179213, Train Acc: 0.652564 | Val Loss: 0.189815, Val Acc: 0.649485\n",
      "Epoch 4708 - Train Loss: 0.179198, Train Acc: 0.652564 | Val Loss: 0.189800, Val Acc: 0.649485\n",
      "Epoch 4709 - Train Loss: 0.179182, Train Acc: 0.652564 | Val Loss: 0.189786, Val Acc: 0.649485\n",
      "Epoch 4710 - Train Loss: 0.179167, Train Acc: 0.652564 | Val Loss: 0.189771, Val Acc: 0.649485\n",
      "Epoch 4711 - Train Loss: 0.179152, Train Acc: 0.652564 | Val Loss: 0.189757, Val Acc: 0.649485\n",
      "Epoch 4712 - Train Loss: 0.179136, Train Acc: 0.652564 | Val Loss: 0.189742, Val Acc: 0.649485\n",
      "Epoch 4713 - Train Loss: 0.179121, Train Acc: 0.652564 | Val Loss: 0.189728, Val Acc: 0.649485\n",
      "Epoch 4714 - Train Loss: 0.179106, Train Acc: 0.652564 | Val Loss: 0.189713, Val Acc: 0.649485\n",
      "Epoch 4715 - Train Loss: 0.179090, Train Acc: 0.652564 | Val Loss: 0.189699, Val Acc: 0.649485\n",
      "Epoch 4716 - Train Loss: 0.179075, Train Acc: 0.652564 | Val Loss: 0.189684, Val Acc: 0.649485\n",
      "Epoch 4717 - Train Loss: 0.179060, Train Acc: 0.653846 | Val Loss: 0.189670, Val Acc: 0.649485\n",
      "Epoch 4718 - Train Loss: 0.179044, Train Acc: 0.653846 | Val Loss: 0.189655, Val Acc: 0.649485\n",
      "Epoch 4719 - Train Loss: 0.179029, Train Acc: 0.653846 | Val Loss: 0.189641, Val Acc: 0.649485\n",
      "Epoch 4720 - Train Loss: 0.179014, Train Acc: 0.653846 | Val Loss: 0.189626, Val Acc: 0.649485\n",
      "Epoch 4721 - Train Loss: 0.178999, Train Acc: 0.653846 | Val Loss: 0.189612, Val Acc: 0.649485\n",
      "Epoch 4722 - Train Loss: 0.178983, Train Acc: 0.653846 | Val Loss: 0.189597, Val Acc: 0.649485\n",
      "Epoch 4723 - Train Loss: 0.178968, Train Acc: 0.653846 | Val Loss: 0.189583, Val Acc: 0.649485\n",
      "Epoch 4724 - Train Loss: 0.178953, Train Acc: 0.653846 | Val Loss: 0.189568, Val Acc: 0.649485\n",
      "Epoch 4725 - Train Loss: 0.178937, Train Acc: 0.653846 | Val Loss: 0.189554, Val Acc: 0.649485\n",
      "Epoch 4726 - Train Loss: 0.178922, Train Acc: 0.653846 | Val Loss: 0.189540, Val Acc: 0.649485\n",
      "Epoch 4727 - Train Loss: 0.178907, Train Acc: 0.653846 | Val Loss: 0.189525, Val Acc: 0.649485\n",
      "Epoch 4728 - Train Loss: 0.178891, Train Acc: 0.653846 | Val Loss: 0.189511, Val Acc: 0.649485\n",
      "Epoch 4729 - Train Loss: 0.178876, Train Acc: 0.653846 | Val Loss: 0.189496, Val Acc: 0.649485\n",
      "Epoch 4730 - Train Loss: 0.178861, Train Acc: 0.653846 | Val Loss: 0.189482, Val Acc: 0.649485\n",
      "Epoch 4731 - Train Loss: 0.178845, Train Acc: 0.653846 | Val Loss: 0.189467, Val Acc: 0.649485\n",
      "Epoch 4732 - Train Loss: 0.178830, Train Acc: 0.653846 | Val Loss: 0.189453, Val Acc: 0.649485\n",
      "Epoch 4733 - Train Loss: 0.178815, Train Acc: 0.653846 | Val Loss: 0.189438, Val Acc: 0.649485\n",
      "Epoch 4734 - Train Loss: 0.178799, Train Acc: 0.653846 | Val Loss: 0.189424, Val Acc: 0.649485\n",
      "Epoch 4735 - Train Loss: 0.178784, Train Acc: 0.653846 | Val Loss: 0.189409, Val Acc: 0.649485\n",
      "Epoch 4736 - Train Loss: 0.178769, Train Acc: 0.653846 | Val Loss: 0.189395, Val Acc: 0.649485\n",
      "Epoch 4737 - Train Loss: 0.178754, Train Acc: 0.653846 | Val Loss: 0.189380, Val Acc: 0.649485\n",
      "Epoch 4738 - Train Loss: 0.178738, Train Acc: 0.653846 | Val Loss: 0.189366, Val Acc: 0.649485\n",
      "Epoch 4739 - Train Loss: 0.178723, Train Acc: 0.653846 | Val Loss: 0.189351, Val Acc: 0.649485\n",
      "Epoch 4740 - Train Loss: 0.178708, Train Acc: 0.653846 | Val Loss: 0.189337, Val Acc: 0.649485\n",
      "Epoch 4741 - Train Loss: 0.178692, Train Acc: 0.653846 | Val Loss: 0.189323, Val Acc: 0.649485\n",
      "Epoch 4742 - Train Loss: 0.178677, Train Acc: 0.653846 | Val Loss: 0.189308, Val Acc: 0.649485\n",
      "Epoch 4743 - Train Loss: 0.178662, Train Acc: 0.653846 | Val Loss: 0.189294, Val Acc: 0.649485\n",
      "Epoch 4744 - Train Loss: 0.178647, Train Acc: 0.653846 | Val Loss: 0.189279, Val Acc: 0.649485\n",
      "Epoch 4745 - Train Loss: 0.178631, Train Acc: 0.653846 | Val Loss: 0.189265, Val Acc: 0.649485\n",
      "Epoch 4746 - Train Loss: 0.178616, Train Acc: 0.653846 | Val Loss: 0.189250, Val Acc: 0.649485\n",
      "Epoch 4747 - Train Loss: 0.178601, Train Acc: 0.653846 | Val Loss: 0.189236, Val Acc: 0.649485\n",
      "Epoch 4748 - Train Loss: 0.178586, Train Acc: 0.653846 | Val Loss: 0.189221, Val Acc: 0.649485\n",
      "Epoch 4749 - Train Loss: 0.178570, Train Acc: 0.653846 | Val Loss: 0.189207, Val Acc: 0.649485\n",
      "Epoch 4750 - Train Loss: 0.178555, Train Acc: 0.653846 | Val Loss: 0.189193, Val Acc: 0.649485\n",
      "Epoch 4751 - Train Loss: 0.178540, Train Acc: 0.653846 | Val Loss: 0.189178, Val Acc: 0.649485\n",
      "Epoch 4752 - Train Loss: 0.178524, Train Acc: 0.653846 | Val Loss: 0.189164, Val Acc: 0.649485\n",
      "Epoch 4753 - Train Loss: 0.178509, Train Acc: 0.653846 | Val Loss: 0.189149, Val Acc: 0.649485\n",
      "Epoch 4754 - Train Loss: 0.178494, Train Acc: 0.653846 | Val Loss: 0.189135, Val Acc: 0.649485\n",
      "Epoch 4755 - Train Loss: 0.178479, Train Acc: 0.653846 | Val Loss: 0.189120, Val Acc: 0.649485\n",
      "Epoch 4756 - Train Loss: 0.178463, Train Acc: 0.653846 | Val Loss: 0.189106, Val Acc: 0.649485\n",
      "Epoch 4757 - Train Loss: 0.178448, Train Acc: 0.653846 | Val Loss: 0.189092, Val Acc: 0.649485\n",
      "Epoch 4758 - Train Loss: 0.178433, Train Acc: 0.653846 | Val Loss: 0.189077, Val Acc: 0.649485\n",
      "Epoch 4759 - Train Loss: 0.178418, Train Acc: 0.653846 | Val Loss: 0.189063, Val Acc: 0.649485\n",
      "Epoch 4760 - Train Loss: 0.178402, Train Acc: 0.653846 | Val Loss: 0.189048, Val Acc: 0.649485\n",
      "Epoch 4761 - Train Loss: 0.178387, Train Acc: 0.653846 | Val Loss: 0.189034, Val Acc: 0.649485\n",
      "Epoch 4762 - Train Loss: 0.178372, Train Acc: 0.653846 | Val Loss: 0.189020, Val Acc: 0.649485\n",
      "Epoch 4763 - Train Loss: 0.178357, Train Acc: 0.653846 | Val Loss: 0.189005, Val Acc: 0.649485\n",
      "Epoch 4764 - Train Loss: 0.178341, Train Acc: 0.653846 | Val Loss: 0.188991, Val Acc: 0.649485\n",
      "Epoch 4765 - Train Loss: 0.178326, Train Acc: 0.653846 | Val Loss: 0.188976, Val Acc: 0.649485\n",
      "Epoch 4766 - Train Loss: 0.178311, Train Acc: 0.653846 | Val Loss: 0.188962, Val Acc: 0.649485\n",
      "Epoch 4767 - Train Loss: 0.178296, Train Acc: 0.653846 | Val Loss: 0.188948, Val Acc: 0.649485\n",
      "Epoch 4768 - Train Loss: 0.178280, Train Acc: 0.653846 | Val Loss: 0.188933, Val Acc: 0.649485\n",
      "Epoch 4769 - Train Loss: 0.178265, Train Acc: 0.653846 | Val Loss: 0.188919, Val Acc: 0.649485\n",
      "Epoch 4770 - Train Loss: 0.178250, Train Acc: 0.653846 | Val Loss: 0.188905, Val Acc: 0.649485\n",
      "Epoch 4771 - Train Loss: 0.178235, Train Acc: 0.655128 | Val Loss: 0.188890, Val Acc: 0.649485\n",
      "Epoch 4772 - Train Loss: 0.178219, Train Acc: 0.655128 | Val Loss: 0.188876, Val Acc: 0.649485\n",
      "Epoch 4773 - Train Loss: 0.178204, Train Acc: 0.655128 | Val Loss: 0.188862, Val Acc: 0.649485\n",
      "Epoch 4774 - Train Loss: 0.178189, Train Acc: 0.655128 | Val Loss: 0.188847, Val Acc: 0.649485\n",
      "Epoch 4775 - Train Loss: 0.178174, Train Acc: 0.655128 | Val Loss: 0.188833, Val Acc: 0.649485\n",
      "Epoch 4776 - Train Loss: 0.178159, Train Acc: 0.655128 | Val Loss: 0.188818, Val Acc: 0.649485\n",
      "Epoch 4777 - Train Loss: 0.178143, Train Acc: 0.655128 | Val Loss: 0.188804, Val Acc: 0.649485\n",
      "Epoch 4778 - Train Loss: 0.178128, Train Acc: 0.655128 | Val Loss: 0.188790, Val Acc: 0.649485\n",
      "Epoch 4779 - Train Loss: 0.178113, Train Acc: 0.655128 | Val Loss: 0.188775, Val Acc: 0.649485\n",
      "Epoch 4780 - Train Loss: 0.178098, Train Acc: 0.655128 | Val Loss: 0.188761, Val Acc: 0.649485\n",
      "Epoch 4781 - Train Loss: 0.178083, Train Acc: 0.655128 | Val Loss: 0.188747, Val Acc: 0.649485\n",
      "Epoch 4782 - Train Loss: 0.178067, Train Acc: 0.655128 | Val Loss: 0.188732, Val Acc: 0.649485\n",
      "Epoch 4783 - Train Loss: 0.178052, Train Acc: 0.655128 | Val Loss: 0.188718, Val Acc: 0.649485\n",
      "Epoch 4784 - Train Loss: 0.178037, Train Acc: 0.655128 | Val Loss: 0.188704, Val Acc: 0.649485\n",
      "Epoch 4785 - Train Loss: 0.178022, Train Acc: 0.655128 | Val Loss: 0.188689, Val Acc: 0.649485\n",
      "Epoch 4786 - Train Loss: 0.178007, Train Acc: 0.655128 | Val Loss: 0.188675, Val Acc: 0.649485\n",
      "Epoch 4787 - Train Loss: 0.177991, Train Acc: 0.655128 | Val Loss: 0.188661, Val Acc: 0.649485\n",
      "Epoch 4788 - Train Loss: 0.177976, Train Acc: 0.655128 | Val Loss: 0.188647, Val Acc: 0.649485\n",
      "Epoch 4789 - Train Loss: 0.177961, Train Acc: 0.655128 | Val Loss: 0.188632, Val Acc: 0.649485\n",
      "Epoch 4790 - Train Loss: 0.177946, Train Acc: 0.655128 | Val Loss: 0.188618, Val Acc: 0.649485\n",
      "Epoch 4791 - Train Loss: 0.177931, Train Acc: 0.655128 | Val Loss: 0.188604, Val Acc: 0.649485\n",
      "Epoch 4792 - Train Loss: 0.177915, Train Acc: 0.655128 | Val Loss: 0.188589, Val Acc: 0.649485\n",
      "Epoch 4793 - Train Loss: 0.177900, Train Acc: 0.655128 | Val Loss: 0.188575, Val Acc: 0.649485\n",
      "Epoch 4794 - Train Loss: 0.177885, Train Acc: 0.655128 | Val Loss: 0.188561, Val Acc: 0.649485\n",
      "Epoch 4795 - Train Loss: 0.177870, Train Acc: 0.655128 | Val Loss: 0.188546, Val Acc: 0.649485\n",
      "Epoch 4796 - Train Loss: 0.177855, Train Acc: 0.655128 | Val Loss: 0.188532, Val Acc: 0.649485\n",
      "Epoch 4797 - Train Loss: 0.177840, Train Acc: 0.655128 | Val Loss: 0.188518, Val Acc: 0.649485\n",
      "Epoch 4798 - Train Loss: 0.177824, Train Acc: 0.655128 | Val Loss: 0.188503, Val Acc: 0.649485\n",
      "Epoch 4799 - Train Loss: 0.177809, Train Acc: 0.655128 | Val Loss: 0.188489, Val Acc: 0.649485\n",
      "Epoch 4800 - Train Loss: 0.177794, Train Acc: 0.655128 | Val Loss: 0.188475, Val Acc: 0.649485\n",
      "Epoch 4801 - Train Loss: 0.177779, Train Acc: 0.655128 | Val Loss: 0.188461, Val Acc: 0.649485\n",
      "Epoch 4802 - Train Loss: 0.177764, Train Acc: 0.656410 | Val Loss: 0.188446, Val Acc: 0.649485\n",
      "Epoch 4803 - Train Loss: 0.177749, Train Acc: 0.656410 | Val Loss: 0.188432, Val Acc: 0.649485\n",
      "Epoch 4804 - Train Loss: 0.177733, Train Acc: 0.656410 | Val Loss: 0.188418, Val Acc: 0.649485\n",
      "Epoch 4805 - Train Loss: 0.177718, Train Acc: 0.656410 | Val Loss: 0.188404, Val Acc: 0.649485\n",
      "Epoch 4806 - Train Loss: 0.177703, Train Acc: 0.656410 | Val Loss: 0.188389, Val Acc: 0.649485\n",
      "Epoch 4807 - Train Loss: 0.177688, Train Acc: 0.656410 | Val Loss: 0.188375, Val Acc: 0.649485\n",
      "Epoch 4808 - Train Loss: 0.177673, Train Acc: 0.657692 | Val Loss: 0.188361, Val Acc: 0.649485\n",
      "Epoch 4809 - Train Loss: 0.177658, Train Acc: 0.657692 | Val Loss: 0.188347, Val Acc: 0.649485\n",
      "Epoch 4810 - Train Loss: 0.177642, Train Acc: 0.657692 | Val Loss: 0.188332, Val Acc: 0.649485\n",
      "Epoch 4811 - Train Loss: 0.177627, Train Acc: 0.657692 | Val Loss: 0.188318, Val Acc: 0.649485\n",
      "Epoch 4812 - Train Loss: 0.177612, Train Acc: 0.657692 | Val Loss: 0.188304, Val Acc: 0.649485\n",
      "Epoch 4813 - Train Loss: 0.177597, Train Acc: 0.657692 | Val Loss: 0.188290, Val Acc: 0.649485\n",
      "Epoch 4814 - Train Loss: 0.177582, Train Acc: 0.657692 | Val Loss: 0.188275, Val Acc: 0.649485\n",
      "Epoch 4815 - Train Loss: 0.177567, Train Acc: 0.657692 | Val Loss: 0.188261, Val Acc: 0.649485\n",
      "Epoch 4816 - Train Loss: 0.177552, Train Acc: 0.657692 | Val Loss: 0.188247, Val Acc: 0.649485\n",
      "Epoch 4817 - Train Loss: 0.177536, Train Acc: 0.657692 | Val Loss: 0.188233, Val Acc: 0.649485\n",
      "Epoch 4818 - Train Loss: 0.177521, Train Acc: 0.657692 | Val Loss: 0.188218, Val Acc: 0.649485\n",
      "Epoch 4819 - Train Loss: 0.177506, Train Acc: 0.657692 | Val Loss: 0.188204, Val Acc: 0.649485\n",
      "Epoch 4820 - Train Loss: 0.177491, Train Acc: 0.657692 | Val Loss: 0.188190, Val Acc: 0.649485\n",
      "Epoch 4821 - Train Loss: 0.177476, Train Acc: 0.657692 | Val Loss: 0.188176, Val Acc: 0.649485\n",
      "Epoch 4822 - Train Loss: 0.177461, Train Acc: 0.657692 | Val Loss: 0.188161, Val Acc: 0.649485\n",
      "Epoch 4823 - Train Loss: 0.177446, Train Acc: 0.657692 | Val Loss: 0.188147, Val Acc: 0.649485\n",
      "Epoch 4824 - Train Loss: 0.177431, Train Acc: 0.657692 | Val Loss: 0.188133, Val Acc: 0.649485\n",
      "Epoch 4825 - Train Loss: 0.177415, Train Acc: 0.657692 | Val Loss: 0.188119, Val Acc: 0.649485\n",
      "Epoch 4826 - Train Loss: 0.177400, Train Acc: 0.657692 | Val Loss: 0.188104, Val Acc: 0.649485\n",
      "Epoch 4827 - Train Loss: 0.177385, Train Acc: 0.657692 | Val Loss: 0.188090, Val Acc: 0.649485\n",
      "Epoch 4828 - Train Loss: 0.177370, Train Acc: 0.657692 | Val Loss: 0.188076, Val Acc: 0.649485\n",
      "Epoch 4829 - Train Loss: 0.177355, Train Acc: 0.657692 | Val Loss: 0.188062, Val Acc: 0.649485\n",
      "Epoch 4830 - Train Loss: 0.177340, Train Acc: 0.657692 | Val Loss: 0.188048, Val Acc: 0.649485\n",
      "Epoch 4831 - Train Loss: 0.177325, Train Acc: 0.657692 | Val Loss: 0.188033, Val Acc: 0.649485\n",
      "Epoch 4832 - Train Loss: 0.177310, Train Acc: 0.657692 | Val Loss: 0.188019, Val Acc: 0.649485\n",
      "Epoch 4833 - Train Loss: 0.177295, Train Acc: 0.657692 | Val Loss: 0.188005, Val Acc: 0.649485\n",
      "Epoch 4834 - Train Loss: 0.177279, Train Acc: 0.657692 | Val Loss: 0.187991, Val Acc: 0.649485\n",
      "Epoch 4835 - Train Loss: 0.177264, Train Acc: 0.657692 | Val Loss: 0.187977, Val Acc: 0.649485\n",
      "Epoch 4836 - Train Loss: 0.177249, Train Acc: 0.657692 | Val Loss: 0.187963, Val Acc: 0.649485\n",
      "Epoch 4837 - Train Loss: 0.177234, Train Acc: 0.657692 | Val Loss: 0.187948, Val Acc: 0.649485\n",
      "Epoch 4838 - Train Loss: 0.177219, Train Acc: 0.657692 | Val Loss: 0.187934, Val Acc: 0.649485\n",
      "Epoch 4839 - Train Loss: 0.177204, Train Acc: 0.657692 | Val Loss: 0.187920, Val Acc: 0.649485\n",
      "Epoch 4840 - Train Loss: 0.177189, Train Acc: 0.657692 | Val Loss: 0.187906, Val Acc: 0.649485\n",
      "Epoch 4841 - Train Loss: 0.177174, Train Acc: 0.657692 | Val Loss: 0.187892, Val Acc: 0.649485\n",
      "Epoch 4842 - Train Loss: 0.177159, Train Acc: 0.657692 | Val Loss: 0.187877, Val Acc: 0.649485\n",
      "Epoch 4843 - Train Loss: 0.177144, Train Acc: 0.657692 | Val Loss: 0.187863, Val Acc: 0.649485\n",
      "Epoch 4844 - Train Loss: 0.177129, Train Acc: 0.657692 | Val Loss: 0.187849, Val Acc: 0.649485\n",
      "Epoch 4845 - Train Loss: 0.177113, Train Acc: 0.657692 | Val Loss: 0.187835, Val Acc: 0.649485\n",
      "Epoch 4846 - Train Loss: 0.177098, Train Acc: 0.657692 | Val Loss: 0.187821, Val Acc: 0.649485\n",
      "Epoch 4847 - Train Loss: 0.177083, Train Acc: 0.657692 | Val Loss: 0.187807, Val Acc: 0.649485\n",
      "Epoch 4848 - Train Loss: 0.177068, Train Acc: 0.657692 | Val Loss: 0.187792, Val Acc: 0.649485\n",
      "Epoch 4849 - Train Loss: 0.177053, Train Acc: 0.657692 | Val Loss: 0.187778, Val Acc: 0.649485\n",
      "Epoch 4850 - Train Loss: 0.177038, Train Acc: 0.657692 | Val Loss: 0.187764, Val Acc: 0.649485\n",
      "Epoch 4851 - Train Loss: 0.177023, Train Acc: 0.657692 | Val Loss: 0.187750, Val Acc: 0.649485\n",
      "Epoch 4852 - Train Loss: 0.177008, Train Acc: 0.657692 | Val Loss: 0.187736, Val Acc: 0.649485\n",
      "Epoch 4853 - Train Loss: 0.176993, Train Acc: 0.657692 | Val Loss: 0.187722, Val Acc: 0.649485\n",
      "Epoch 4854 - Train Loss: 0.176978, Train Acc: 0.657692 | Val Loss: 0.187707, Val Acc: 0.649485\n",
      "Epoch 4855 - Train Loss: 0.176963, Train Acc: 0.657692 | Val Loss: 0.187693, Val Acc: 0.649485\n",
      "Epoch 4856 - Train Loss: 0.176948, Train Acc: 0.657692 | Val Loss: 0.187679, Val Acc: 0.649485\n",
      "Epoch 4857 - Train Loss: 0.176933, Train Acc: 0.657692 | Val Loss: 0.187665, Val Acc: 0.649485\n",
      "Epoch 4858 - Train Loss: 0.176918, Train Acc: 0.657692 | Val Loss: 0.187651, Val Acc: 0.649485\n",
      "Epoch 4859 - Train Loss: 0.176903, Train Acc: 0.657692 | Val Loss: 0.187637, Val Acc: 0.649485\n",
      "Epoch 4860 - Train Loss: 0.176888, Train Acc: 0.657692 | Val Loss: 0.187623, Val Acc: 0.649485\n",
      "Epoch 4861 - Train Loss: 0.176872, Train Acc: 0.657692 | Val Loss: 0.187608, Val Acc: 0.649485\n",
      "Epoch 4862 - Train Loss: 0.176857, Train Acc: 0.657692 | Val Loss: 0.187594, Val Acc: 0.649485\n",
      "Epoch 4863 - Train Loss: 0.176842, Train Acc: 0.657692 | Val Loss: 0.187580, Val Acc: 0.649485\n",
      "Epoch 4864 - Train Loss: 0.176827, Train Acc: 0.657692 | Val Loss: 0.187566, Val Acc: 0.649485\n",
      "Epoch 4865 - Train Loss: 0.176812, Train Acc: 0.657692 | Val Loss: 0.187552, Val Acc: 0.649485\n",
      "Epoch 4866 - Train Loss: 0.176797, Train Acc: 0.657692 | Val Loss: 0.187538, Val Acc: 0.649485\n",
      "Epoch 4867 - Train Loss: 0.176782, Train Acc: 0.657692 | Val Loss: 0.187524, Val Acc: 0.649485\n",
      "Epoch 4868 - Train Loss: 0.176767, Train Acc: 0.657692 | Val Loss: 0.187510, Val Acc: 0.649485\n",
      "Epoch 4869 - Train Loss: 0.176752, Train Acc: 0.657692 | Val Loss: 0.187495, Val Acc: 0.649485\n",
      "Epoch 4870 - Train Loss: 0.176737, Train Acc: 0.657692 | Val Loss: 0.187481, Val Acc: 0.649485\n",
      "Epoch 4871 - Train Loss: 0.176722, Train Acc: 0.657692 | Val Loss: 0.187467, Val Acc: 0.649485\n",
      "Epoch 4872 - Train Loss: 0.176707, Train Acc: 0.657692 | Val Loss: 0.187453, Val Acc: 0.649485\n",
      "Epoch 4873 - Train Loss: 0.176692, Train Acc: 0.657692 | Val Loss: 0.187439, Val Acc: 0.649485\n",
      "Epoch 4874 - Train Loss: 0.176677, Train Acc: 0.657692 | Val Loss: 0.187425, Val Acc: 0.649485\n",
      "Epoch 4875 - Train Loss: 0.176662, Train Acc: 0.657692 | Val Loss: 0.187411, Val Acc: 0.649485\n",
      "Epoch 4876 - Train Loss: 0.176647, Train Acc: 0.657692 | Val Loss: 0.187397, Val Acc: 0.649485\n",
      "Epoch 4877 - Train Loss: 0.176632, Train Acc: 0.657692 | Val Loss: 0.187382, Val Acc: 0.649485\n",
      "Epoch 4878 - Train Loss: 0.176617, Train Acc: 0.657692 | Val Loss: 0.187368, Val Acc: 0.649485\n",
      "Epoch 4879 - Train Loss: 0.176602, Train Acc: 0.657692 | Val Loss: 0.187354, Val Acc: 0.649485\n",
      "Epoch 4880 - Train Loss: 0.176587, Train Acc: 0.657692 | Val Loss: 0.187340, Val Acc: 0.649485\n",
      "Epoch 4881 - Train Loss: 0.176572, Train Acc: 0.657692 | Val Loss: 0.187326, Val Acc: 0.649485\n",
      "Epoch 4882 - Train Loss: 0.176557, Train Acc: 0.657692 | Val Loss: 0.187312, Val Acc: 0.649485\n",
      "Epoch 4883 - Train Loss: 0.176542, Train Acc: 0.657692 | Val Loss: 0.187298, Val Acc: 0.649485\n",
      "Epoch 4884 - Train Loss: 0.176527, Train Acc: 0.657692 | Val Loss: 0.187284, Val Acc: 0.649485\n",
      "Epoch 4885 - Train Loss: 0.176512, Train Acc: 0.657692 | Val Loss: 0.187270, Val Acc: 0.649485\n",
      "Epoch 4886 - Train Loss: 0.176497, Train Acc: 0.657692 | Val Loss: 0.187256, Val Acc: 0.649485\n",
      "Epoch 4887 - Train Loss: 0.176482, Train Acc: 0.657692 | Val Loss: 0.187241, Val Acc: 0.649485\n",
      "Epoch 4888 - Train Loss: 0.176467, Train Acc: 0.657692 | Val Loss: 0.187227, Val Acc: 0.649485\n",
      "Epoch 4889 - Train Loss: 0.176452, Train Acc: 0.658974 | Val Loss: 0.187213, Val Acc: 0.649485\n",
      "Epoch 4890 - Train Loss: 0.176437, Train Acc: 0.658974 | Val Loss: 0.187199, Val Acc: 0.649485\n",
      "Epoch 4891 - Train Loss: 0.176422, Train Acc: 0.658974 | Val Loss: 0.187185, Val Acc: 0.649485\n",
      "Epoch 4892 - Train Loss: 0.176407, Train Acc: 0.658974 | Val Loss: 0.187171, Val Acc: 0.649485\n",
      "Epoch 4893 - Train Loss: 0.176392, Train Acc: 0.658974 | Val Loss: 0.187157, Val Acc: 0.649485\n",
      "Epoch 4894 - Train Loss: 0.176377, Train Acc: 0.658974 | Val Loss: 0.187143, Val Acc: 0.649485\n",
      "Epoch 4895 - Train Loss: 0.176362, Train Acc: 0.658974 | Val Loss: 0.187129, Val Acc: 0.649485\n",
      "Epoch 4896 - Train Loss: 0.176347, Train Acc: 0.658974 | Val Loss: 0.187115, Val Acc: 0.649485\n",
      "Epoch 4897 - Train Loss: 0.176332, Train Acc: 0.658974 | Val Loss: 0.187100, Val Acc: 0.649485\n",
      "Epoch 4898 - Train Loss: 0.176317, Train Acc: 0.658974 | Val Loss: 0.187086, Val Acc: 0.649485\n",
      "Epoch 4899 - Train Loss: 0.176302, Train Acc: 0.658974 | Val Loss: 0.187072, Val Acc: 0.649485\n",
      "Epoch 4900 - Train Loss: 0.176287, Train Acc: 0.658974 | Val Loss: 0.187058, Val Acc: 0.649485\n",
      "Epoch 4901 - Train Loss: 0.176272, Train Acc: 0.658974 | Val Loss: 0.187044, Val Acc: 0.649485\n",
      "Epoch 4902 - Train Loss: 0.176257, Train Acc: 0.660256 | Val Loss: 0.187030, Val Acc: 0.649485\n",
      "Epoch 4903 - Train Loss: 0.176242, Train Acc: 0.660256 | Val Loss: 0.187016, Val Acc: 0.649485\n",
      "Epoch 4904 - Train Loss: 0.176227, Train Acc: 0.660256 | Val Loss: 0.187002, Val Acc: 0.649485\n",
      "Epoch 4905 - Train Loss: 0.176212, Train Acc: 0.660256 | Val Loss: 0.186988, Val Acc: 0.649485\n",
      "Epoch 4906 - Train Loss: 0.176197, Train Acc: 0.660256 | Val Loss: 0.186974, Val Acc: 0.649485\n",
      "Epoch 4907 - Train Loss: 0.176182, Train Acc: 0.660256 | Val Loss: 0.186960, Val Acc: 0.649485\n",
      "Epoch 4908 - Train Loss: 0.176167, Train Acc: 0.660256 | Val Loss: 0.186946, Val Acc: 0.649485\n",
      "Epoch 4909 - Train Loss: 0.176152, Train Acc: 0.660256 | Val Loss: 0.186932, Val Acc: 0.649485\n",
      "Epoch 4910 - Train Loss: 0.176137, Train Acc: 0.660256 | Val Loss: 0.186918, Val Acc: 0.649485\n",
      "Epoch 4911 - Train Loss: 0.176122, Train Acc: 0.660256 | Val Loss: 0.186904, Val Acc: 0.649485\n",
      "Epoch 4912 - Train Loss: 0.176107, Train Acc: 0.660256 | Val Loss: 0.186890, Val Acc: 0.649485\n",
      "Epoch 4913 - Train Loss: 0.176092, Train Acc: 0.660256 | Val Loss: 0.186876, Val Acc: 0.649485\n",
      "Epoch 4914 - Train Loss: 0.176077, Train Acc: 0.660256 | Val Loss: 0.186862, Val Acc: 0.649485\n",
      "Epoch 4915 - Train Loss: 0.176062, Train Acc: 0.660256 | Val Loss: 0.186848, Val Acc: 0.649485\n",
      "Epoch 4916 - Train Loss: 0.176048, Train Acc: 0.660256 | Val Loss: 0.186834, Val Acc: 0.649485\n",
      "Epoch 4917 - Train Loss: 0.176033, Train Acc: 0.660256 | Val Loss: 0.186820, Val Acc: 0.649485\n",
      "Epoch 4918 - Train Loss: 0.176018, Train Acc: 0.660256 | Val Loss: 0.186806, Val Acc: 0.649485\n",
      "Epoch 4919 - Train Loss: 0.176003, Train Acc: 0.660256 | Val Loss: 0.186792, Val Acc: 0.649485\n",
      "Epoch 4920 - Train Loss: 0.175988, Train Acc: 0.660256 | Val Loss: 0.186778, Val Acc: 0.649485\n",
      "Epoch 4921 - Train Loss: 0.175973, Train Acc: 0.660256 | Val Loss: 0.186764, Val Acc: 0.659794\n",
      "Epoch 4922 - Train Loss: 0.175958, Train Acc: 0.660256 | Val Loss: 0.186750, Val Acc: 0.659794\n",
      "Epoch 4923 - Train Loss: 0.175943, Train Acc: 0.660256 | Val Loss: 0.186736, Val Acc: 0.659794\n",
      "Epoch 4924 - Train Loss: 0.175928, Train Acc: 0.660256 | Val Loss: 0.186722, Val Acc: 0.659794\n",
      "Epoch 4925 - Train Loss: 0.175913, Train Acc: 0.660256 | Val Loss: 0.186708, Val Acc: 0.659794\n",
      "Epoch 4926 - Train Loss: 0.175898, Train Acc: 0.660256 | Val Loss: 0.186694, Val Acc: 0.659794\n",
      "Epoch 4927 - Train Loss: 0.175883, Train Acc: 0.660256 | Val Loss: 0.186680, Val Acc: 0.659794\n",
      "Epoch 4928 - Train Loss: 0.175868, Train Acc: 0.660256 | Val Loss: 0.186666, Val Acc: 0.659794\n",
      "Epoch 4929 - Train Loss: 0.175853, Train Acc: 0.660256 | Val Loss: 0.186652, Val Acc: 0.659794\n",
      "Epoch 4930 - Train Loss: 0.175838, Train Acc: 0.660256 | Val Loss: 0.186638, Val Acc: 0.659794\n",
      "Epoch 4931 - Train Loss: 0.175823, Train Acc: 0.660256 | Val Loss: 0.186624, Val Acc: 0.659794\n",
      "Epoch 4932 - Train Loss: 0.175809, Train Acc: 0.660256 | Val Loss: 0.186610, Val Acc: 0.659794\n",
      "Epoch 4933 - Train Loss: 0.175794, Train Acc: 0.660256 | Val Loss: 0.186596, Val Acc: 0.659794\n",
      "Epoch 4934 - Train Loss: 0.175779, Train Acc: 0.660256 | Val Loss: 0.186582, Val Acc: 0.659794\n",
      "Epoch 4935 - Train Loss: 0.175764, Train Acc: 0.660256 | Val Loss: 0.186568, Val Acc: 0.659794\n",
      "Epoch 4936 - Train Loss: 0.175749, Train Acc: 0.660256 | Val Loss: 0.186554, Val Acc: 0.659794\n",
      "Epoch 4937 - Train Loss: 0.175734, Train Acc: 0.660256 | Val Loss: 0.186540, Val Acc: 0.659794\n",
      "Epoch 4938 - Train Loss: 0.175719, Train Acc: 0.660256 | Val Loss: 0.186526, Val Acc: 0.659794\n",
      "Epoch 4939 - Train Loss: 0.175704, Train Acc: 0.660256 | Val Loss: 0.186512, Val Acc: 0.659794\n",
      "Epoch 4940 - Train Loss: 0.175689, Train Acc: 0.660256 | Val Loss: 0.186498, Val Acc: 0.659794\n",
      "Epoch 4941 - Train Loss: 0.175674, Train Acc: 0.660256 | Val Loss: 0.186484, Val Acc: 0.659794\n",
      "Epoch 4942 - Train Loss: 0.175659, Train Acc: 0.661538 | Val Loss: 0.186470, Val Acc: 0.659794\n",
      "Epoch 4943 - Train Loss: 0.175644, Train Acc: 0.661538 | Val Loss: 0.186456, Val Acc: 0.659794\n",
      "Epoch 4944 - Train Loss: 0.175630, Train Acc: 0.661538 | Val Loss: 0.186442, Val Acc: 0.659794\n",
      "Epoch 4945 - Train Loss: 0.175615, Train Acc: 0.661538 | Val Loss: 0.186428, Val Acc: 0.659794\n",
      "Epoch 4946 - Train Loss: 0.175600, Train Acc: 0.661538 | Val Loss: 0.186414, Val Acc: 0.659794\n",
      "Epoch 4947 - Train Loss: 0.175585, Train Acc: 0.661538 | Val Loss: 0.186400, Val Acc: 0.659794\n",
      "Epoch 4948 - Train Loss: 0.175570, Train Acc: 0.661538 | Val Loss: 0.186386, Val Acc: 0.659794\n",
      "Epoch 4949 - Train Loss: 0.175555, Train Acc: 0.661538 | Val Loss: 0.186372, Val Acc: 0.659794\n",
      "Epoch 4950 - Train Loss: 0.175540, Train Acc: 0.662821 | Val Loss: 0.186359, Val Acc: 0.659794\n",
      "Epoch 4951 - Train Loss: 0.175525, Train Acc: 0.662821 | Val Loss: 0.186345, Val Acc: 0.659794\n",
      "Epoch 4952 - Train Loss: 0.175510, Train Acc: 0.662821 | Val Loss: 0.186331, Val Acc: 0.659794\n",
      "Epoch 4953 - Train Loss: 0.175495, Train Acc: 0.662821 | Val Loss: 0.186317, Val Acc: 0.659794\n",
      "Epoch 4954 - Train Loss: 0.175481, Train Acc: 0.662821 | Val Loss: 0.186303, Val Acc: 0.659794\n",
      "Epoch 4955 - Train Loss: 0.175466, Train Acc: 0.662821 | Val Loss: 0.186289, Val Acc: 0.659794\n",
      "Epoch 4956 - Train Loss: 0.175451, Train Acc: 0.662821 | Val Loss: 0.186275, Val Acc: 0.659794\n",
      "Epoch 4957 - Train Loss: 0.175436, Train Acc: 0.662821 | Val Loss: 0.186261, Val Acc: 0.659794\n",
      "Epoch 4958 - Train Loss: 0.175421, Train Acc: 0.662821 | Val Loss: 0.186247, Val Acc: 0.659794\n",
      "Epoch 4959 - Train Loss: 0.175406, Train Acc: 0.662821 | Val Loss: 0.186233, Val Acc: 0.659794\n",
      "Epoch 4960 - Train Loss: 0.175391, Train Acc: 0.662821 | Val Loss: 0.186219, Val Acc: 0.659794\n",
      "Epoch 4961 - Train Loss: 0.175376, Train Acc: 0.662821 | Val Loss: 0.186205, Val Acc: 0.659794\n",
      "Epoch 4962 - Train Loss: 0.175362, Train Acc: 0.662821 | Val Loss: 0.186191, Val Acc: 0.659794\n",
      "Epoch 4963 - Train Loss: 0.175347, Train Acc: 0.662821 | Val Loss: 0.186177, Val Acc: 0.659794\n",
      "Epoch 4964 - Train Loss: 0.175332, Train Acc: 0.662821 | Val Loss: 0.186164, Val Acc: 0.659794\n",
      "Epoch 4965 - Train Loss: 0.175317, Train Acc: 0.662821 | Val Loss: 0.186150, Val Acc: 0.659794\n",
      "Epoch 4966 - Train Loss: 0.175302, Train Acc: 0.662821 | Val Loss: 0.186136, Val Acc: 0.659794\n",
      "Epoch 4967 - Train Loss: 0.175287, Train Acc: 0.662821 | Val Loss: 0.186122, Val Acc: 0.659794\n",
      "Epoch 4968 - Train Loss: 0.175272, Train Acc: 0.664103 | Val Loss: 0.186108, Val Acc: 0.659794\n",
      "Epoch 4969 - Train Loss: 0.175257, Train Acc: 0.664103 | Val Loss: 0.186094, Val Acc: 0.659794\n",
      "Epoch 4970 - Train Loss: 0.175243, Train Acc: 0.664103 | Val Loss: 0.186080, Val Acc: 0.649485\n",
      "Epoch 4971 - Train Loss: 0.175228, Train Acc: 0.664103 | Val Loss: 0.186066, Val Acc: 0.649485\n",
      "Epoch 4972 - Train Loss: 0.175213, Train Acc: 0.664103 | Val Loss: 0.186052, Val Acc: 0.649485\n",
      "Epoch 4973 - Train Loss: 0.175198, Train Acc: 0.664103 | Val Loss: 0.186038, Val Acc: 0.649485\n",
      "Epoch 4974 - Train Loss: 0.175183, Train Acc: 0.664103 | Val Loss: 0.186024, Val Acc: 0.649485\n",
      "Epoch 4975 - Train Loss: 0.175168, Train Acc: 0.664103 | Val Loss: 0.186010, Val Acc: 0.649485\n",
      "Epoch 4976 - Train Loss: 0.175154, Train Acc: 0.664103 | Val Loss: 0.185997, Val Acc: 0.649485\n",
      "Epoch 4977 - Train Loss: 0.175139, Train Acc: 0.664103 | Val Loss: 0.185983, Val Acc: 0.649485\n",
      "Epoch 4978 - Train Loss: 0.175124, Train Acc: 0.664103 | Val Loss: 0.185969, Val Acc: 0.649485\n",
      "Epoch 4979 - Train Loss: 0.175109, Train Acc: 0.664103 | Val Loss: 0.185955, Val Acc: 0.649485\n",
      "Epoch 4980 - Train Loss: 0.175094, Train Acc: 0.664103 | Val Loss: 0.185941, Val Acc: 0.649485\n",
      "Epoch 4981 - Train Loss: 0.175079, Train Acc: 0.664103 | Val Loss: 0.185927, Val Acc: 0.649485\n",
      "Epoch 4982 - Train Loss: 0.175064, Train Acc: 0.664103 | Val Loss: 0.185913, Val Acc: 0.649485\n",
      "Epoch 4983 - Train Loss: 0.175050, Train Acc: 0.664103 | Val Loss: 0.185899, Val Acc: 0.649485\n",
      "Epoch 4984 - Train Loss: 0.175035, Train Acc: 0.664103 | Val Loss: 0.185885, Val Acc: 0.649485\n",
      "Epoch 4985 - Train Loss: 0.175020, Train Acc: 0.664103 | Val Loss: 0.185871, Val Acc: 0.649485\n",
      "Epoch 4986 - Train Loss: 0.175005, Train Acc: 0.664103 | Val Loss: 0.185858, Val Acc: 0.649485\n",
      "Epoch 4987 - Train Loss: 0.174990, Train Acc: 0.664103 | Val Loss: 0.185844, Val Acc: 0.649485\n",
      "Epoch 4988 - Train Loss: 0.174975, Train Acc: 0.664103 | Val Loss: 0.185830, Val Acc: 0.649485\n",
      "Epoch 4989 - Train Loss: 0.174961, Train Acc: 0.664103 | Val Loss: 0.185816, Val Acc: 0.649485\n",
      "Epoch 4990 - Train Loss: 0.174946, Train Acc: 0.664103 | Val Loss: 0.185802, Val Acc: 0.649485\n",
      "Epoch 4991 - Train Loss: 0.174931, Train Acc: 0.664103 | Val Loss: 0.185788, Val Acc: 0.649485\n",
      "Epoch 4992 - Train Loss: 0.174916, Train Acc: 0.664103 | Val Loss: 0.185774, Val Acc: 0.649485\n",
      "Epoch 4993 - Train Loss: 0.174901, Train Acc: 0.664103 | Val Loss: 0.185760, Val Acc: 0.649485\n",
      "Epoch 4994 - Train Loss: 0.174887, Train Acc: 0.664103 | Val Loss: 0.185746, Val Acc: 0.649485\n",
      "Epoch 4995 - Train Loss: 0.174872, Train Acc: 0.664103 | Val Loss: 0.185733, Val Acc: 0.649485\n",
      "Epoch 4996 - Train Loss: 0.174857, Train Acc: 0.664103 | Val Loss: 0.185719, Val Acc: 0.649485\n",
      "Epoch 4997 - Train Loss: 0.174842, Train Acc: 0.664103 | Val Loss: 0.185705, Val Acc: 0.649485\n",
      "Epoch 4998 - Train Loss: 0.174827, Train Acc: 0.664103 | Val Loss: 0.185691, Val Acc: 0.649485\n",
      "Epoch 4999 - Train Loss: 0.174812, Train Acc: 0.664103 | Val Loss: 0.185677, Val Acc: 0.649485\n",
      "Epoch 5000 - Train Loss: 0.174798, Train Acc: 0.664103 | Val Loss: 0.185663, Val Acc: 0.649485\n",
      "Epoch 5001 - Train Loss: 0.174783, Train Acc: 0.664103 | Val Loss: 0.185649, Val Acc: 0.649485\n",
      "Epoch 5002 - Train Loss: 0.174768, Train Acc: 0.664103 | Val Loss: 0.185635, Val Acc: 0.649485\n",
      "Epoch 5003 - Train Loss: 0.174753, Train Acc: 0.664103 | Val Loss: 0.185622, Val Acc: 0.649485\n",
      "Epoch 5004 - Train Loss: 0.174738, Train Acc: 0.664103 | Val Loss: 0.185608, Val Acc: 0.649485\n",
      "Epoch 5005 - Train Loss: 0.174724, Train Acc: 0.664103 | Val Loss: 0.185594, Val Acc: 0.649485\n",
      "Epoch 5006 - Train Loss: 0.174709, Train Acc: 0.664103 | Val Loss: 0.185580, Val Acc: 0.649485\n",
      "Epoch 5007 - Train Loss: 0.174694, Train Acc: 0.664103 | Val Loss: 0.185566, Val Acc: 0.649485\n",
      "Epoch 5008 - Train Loss: 0.174679, Train Acc: 0.664103 | Val Loss: 0.185552, Val Acc: 0.649485\n",
      "Epoch 5009 - Train Loss: 0.174664, Train Acc: 0.664103 | Val Loss: 0.185538, Val Acc: 0.649485\n",
      "Epoch 5010 - Train Loss: 0.174650, Train Acc: 0.664103 | Val Loss: 0.185525, Val Acc: 0.649485\n",
      "Epoch 5011 - Train Loss: 0.174635, Train Acc: 0.664103 | Val Loss: 0.185511, Val Acc: 0.649485\n",
      "Epoch 5012 - Train Loss: 0.174620, Train Acc: 0.664103 | Val Loss: 0.185497, Val Acc: 0.649485\n",
      "Epoch 5013 - Train Loss: 0.174605, Train Acc: 0.664103 | Val Loss: 0.185483, Val Acc: 0.649485\n",
      "Epoch 5014 - Train Loss: 0.174590, Train Acc: 0.664103 | Val Loss: 0.185469, Val Acc: 0.649485\n",
      "Epoch 5015 - Train Loss: 0.174576, Train Acc: 0.664103 | Val Loss: 0.185455, Val Acc: 0.649485\n",
      "Epoch 5016 - Train Loss: 0.174561, Train Acc: 0.664103 | Val Loss: 0.185442, Val Acc: 0.649485\n",
      "Epoch 5017 - Train Loss: 0.174546, Train Acc: 0.664103 | Val Loss: 0.185428, Val Acc: 0.649485\n",
      "Epoch 5018 - Train Loss: 0.174531, Train Acc: 0.664103 | Val Loss: 0.185414, Val Acc: 0.649485\n",
      "Epoch 5019 - Train Loss: 0.174517, Train Acc: 0.664103 | Val Loss: 0.185400, Val Acc: 0.649485\n",
      "Epoch 5020 - Train Loss: 0.174502, Train Acc: 0.664103 | Val Loss: 0.185386, Val Acc: 0.649485\n",
      "Epoch 5021 - Train Loss: 0.174487, Train Acc: 0.664103 | Val Loss: 0.185372, Val Acc: 0.649485\n",
      "Epoch 5022 - Train Loss: 0.174472, Train Acc: 0.664103 | Val Loss: 0.185359, Val Acc: 0.649485\n",
      "Epoch 5023 - Train Loss: 0.174457, Train Acc: 0.664103 | Val Loss: 0.185345, Val Acc: 0.649485\n",
      "Epoch 5024 - Train Loss: 0.174443, Train Acc: 0.664103 | Val Loss: 0.185331, Val Acc: 0.649485\n",
      "Epoch 5025 - Train Loss: 0.174428, Train Acc: 0.664103 | Val Loss: 0.185317, Val Acc: 0.649485\n",
      "Epoch 5026 - Train Loss: 0.174413, Train Acc: 0.664103 | Val Loss: 0.185303, Val Acc: 0.649485\n",
      "Epoch 5027 - Train Loss: 0.174398, Train Acc: 0.664103 | Val Loss: 0.185289, Val Acc: 0.649485\n",
      "Epoch 5028 - Train Loss: 0.174384, Train Acc: 0.664103 | Val Loss: 0.185276, Val Acc: 0.649485\n",
      "Epoch 5029 - Train Loss: 0.174369, Train Acc: 0.664103 | Val Loss: 0.185262, Val Acc: 0.649485\n",
      "Epoch 5030 - Train Loss: 0.174354, Train Acc: 0.664103 | Val Loss: 0.185248, Val Acc: 0.649485\n",
      "Epoch 5031 - Train Loss: 0.174339, Train Acc: 0.664103 | Val Loss: 0.185234, Val Acc: 0.649485\n",
      "Epoch 5032 - Train Loss: 0.174324, Train Acc: 0.664103 | Val Loss: 0.185220, Val Acc: 0.649485\n",
      "Epoch 5033 - Train Loss: 0.174310, Train Acc: 0.664103 | Val Loss: 0.185207, Val Acc: 0.649485\n",
      "Epoch 5034 - Train Loss: 0.174295, Train Acc: 0.664103 | Val Loss: 0.185193, Val Acc: 0.649485\n",
      "Epoch 5035 - Train Loss: 0.174280, Train Acc: 0.664103 | Val Loss: 0.185179, Val Acc: 0.649485\n",
      "Epoch 5036 - Train Loss: 0.174265, Train Acc: 0.665385 | Val Loss: 0.185165, Val Acc: 0.649485\n",
      "Epoch 5037 - Train Loss: 0.174251, Train Acc: 0.665385 | Val Loss: 0.185151, Val Acc: 0.649485\n",
      "Epoch 5038 - Train Loss: 0.174236, Train Acc: 0.665385 | Val Loss: 0.185138, Val Acc: 0.649485\n",
      "Epoch 5039 - Train Loss: 0.174221, Train Acc: 0.665385 | Val Loss: 0.185124, Val Acc: 0.649485\n",
      "Epoch 5040 - Train Loss: 0.174206, Train Acc: 0.665385 | Val Loss: 0.185110, Val Acc: 0.649485\n",
      "Epoch 5041 - Train Loss: 0.174192, Train Acc: 0.665385 | Val Loss: 0.185096, Val Acc: 0.649485\n",
      "Epoch 5042 - Train Loss: 0.174177, Train Acc: 0.665385 | Val Loss: 0.185082, Val Acc: 0.649485\n",
      "Epoch 5043 - Train Loss: 0.174162, Train Acc: 0.665385 | Val Loss: 0.185069, Val Acc: 0.649485\n",
      "Epoch 5044 - Train Loss: 0.174147, Train Acc: 0.665385 | Val Loss: 0.185055, Val Acc: 0.649485\n",
      "Epoch 5045 - Train Loss: 0.174133, Train Acc: 0.665385 | Val Loss: 0.185041, Val Acc: 0.649485\n",
      "Epoch 5046 - Train Loss: 0.174118, Train Acc: 0.666667 | Val Loss: 0.185027, Val Acc: 0.649485\n",
      "Epoch 5047 - Train Loss: 0.174103, Train Acc: 0.666667 | Val Loss: 0.185013, Val Acc: 0.649485\n",
      "Epoch 5048 - Train Loss: 0.174088, Train Acc: 0.666667 | Val Loss: 0.185000, Val Acc: 0.649485\n",
      "Epoch 5049 - Train Loss: 0.174074, Train Acc: 0.666667 | Val Loss: 0.184986, Val Acc: 0.649485\n",
      "Epoch 5050 - Train Loss: 0.174059, Train Acc: 0.666667 | Val Loss: 0.184972, Val Acc: 0.649485\n",
      "Epoch 5051 - Train Loss: 0.174044, Train Acc: 0.666667 | Val Loss: 0.184958, Val Acc: 0.649485\n",
      "Epoch 5052 - Train Loss: 0.174029, Train Acc: 0.666667 | Val Loss: 0.184945, Val Acc: 0.649485\n",
      "Epoch 5053 - Train Loss: 0.174015, Train Acc: 0.666667 | Val Loss: 0.184931, Val Acc: 0.649485\n",
      "Epoch 5054 - Train Loss: 0.174000, Train Acc: 0.666667 | Val Loss: 0.184917, Val Acc: 0.649485\n",
      "Epoch 5055 - Train Loss: 0.173985, Train Acc: 0.666667 | Val Loss: 0.184903, Val Acc: 0.649485\n",
      "Epoch 5056 - Train Loss: 0.173971, Train Acc: 0.666667 | Val Loss: 0.184889, Val Acc: 0.649485\n",
      "Epoch 5057 - Train Loss: 0.173956, Train Acc: 0.666667 | Val Loss: 0.184876, Val Acc: 0.649485\n",
      "Epoch 5058 - Train Loss: 0.173941, Train Acc: 0.666667 | Val Loss: 0.184862, Val Acc: 0.649485\n",
      "Epoch 5059 - Train Loss: 0.173926, Train Acc: 0.666667 | Val Loss: 0.184848, Val Acc: 0.649485\n",
      "Epoch 5060 - Train Loss: 0.173912, Train Acc: 0.666667 | Val Loss: 0.184834, Val Acc: 0.649485\n",
      "Epoch 5061 - Train Loss: 0.173897, Train Acc: 0.666667 | Val Loss: 0.184821, Val Acc: 0.649485\n",
      "Epoch 5062 - Train Loss: 0.173882, Train Acc: 0.666667 | Val Loss: 0.184807, Val Acc: 0.649485\n",
      "Epoch 5063 - Train Loss: 0.173868, Train Acc: 0.666667 | Val Loss: 0.184793, Val Acc: 0.649485\n",
      "Epoch 5064 - Train Loss: 0.173853, Train Acc: 0.666667 | Val Loss: 0.184779, Val Acc: 0.649485\n",
      "Epoch 5065 - Train Loss: 0.173838, Train Acc: 0.666667 | Val Loss: 0.184766, Val Acc: 0.649485\n",
      "Epoch 5066 - Train Loss: 0.173823, Train Acc: 0.666667 | Val Loss: 0.184752, Val Acc: 0.649485\n",
      "Epoch 5067 - Train Loss: 0.173809, Train Acc: 0.666667 | Val Loss: 0.184738, Val Acc: 0.649485\n",
      "Epoch 5068 - Train Loss: 0.173794, Train Acc: 0.666667 | Val Loss: 0.184724, Val Acc: 0.649485\n",
      "Epoch 5069 - Train Loss: 0.173779, Train Acc: 0.666667 | Val Loss: 0.184711, Val Acc: 0.649485\n",
      "Epoch 5070 - Train Loss: 0.173765, Train Acc: 0.666667 | Val Loss: 0.184697, Val Acc: 0.649485\n",
      "Epoch 5071 - Train Loss: 0.173750, Train Acc: 0.666667 | Val Loss: 0.184683, Val Acc: 0.649485\n",
      "Epoch 5072 - Train Loss: 0.173735, Train Acc: 0.666667 | Val Loss: 0.184669, Val Acc: 0.649485\n",
      "Epoch 5073 - Train Loss: 0.173720, Train Acc: 0.666667 | Val Loss: 0.184656, Val Acc: 0.649485\n",
      "Epoch 5074 - Train Loss: 0.173706, Train Acc: 0.666667 | Val Loss: 0.184642, Val Acc: 0.649485\n",
      "Epoch 5075 - Train Loss: 0.173691, Train Acc: 0.666667 | Val Loss: 0.184628, Val Acc: 0.649485\n",
      "Epoch 5076 - Train Loss: 0.173676, Train Acc: 0.666667 | Val Loss: 0.184615, Val Acc: 0.649485\n",
      "Epoch 5077 - Train Loss: 0.173662, Train Acc: 0.666667 | Val Loss: 0.184601, Val Acc: 0.649485\n",
      "Epoch 5078 - Train Loss: 0.173647, Train Acc: 0.666667 | Val Loss: 0.184587, Val Acc: 0.649485\n",
      "Epoch 5079 - Train Loss: 0.173632, Train Acc: 0.666667 | Val Loss: 0.184573, Val Acc: 0.649485\n",
      "Epoch 5080 - Train Loss: 0.173618, Train Acc: 0.666667 | Val Loss: 0.184560, Val Acc: 0.649485\n",
      "Epoch 5081 - Train Loss: 0.173603, Train Acc: 0.666667 | Val Loss: 0.184546, Val Acc: 0.649485\n",
      "Epoch 5082 - Train Loss: 0.173588, Train Acc: 0.666667 | Val Loss: 0.184532, Val Acc: 0.649485\n",
      "Epoch 5083 - Train Loss: 0.173574, Train Acc: 0.666667 | Val Loss: 0.184518, Val Acc: 0.649485\n",
      "Epoch 5084 - Train Loss: 0.173559, Train Acc: 0.666667 | Val Loss: 0.184505, Val Acc: 0.649485\n",
      "Epoch 5085 - Train Loss: 0.173544, Train Acc: 0.666667 | Val Loss: 0.184491, Val Acc: 0.649485\n",
      "Epoch 5086 - Train Loss: 0.173529, Train Acc: 0.666667 | Val Loss: 0.184477, Val Acc: 0.649485\n",
      "Epoch 5087 - Train Loss: 0.173515, Train Acc: 0.666667 | Val Loss: 0.184464, Val Acc: 0.649485\n",
      "Epoch 5088 - Train Loss: 0.173500, Train Acc: 0.666667 | Val Loss: 0.184450, Val Acc: 0.649485\n",
      "Epoch 5089 - Train Loss: 0.173485, Train Acc: 0.667949 | Val Loss: 0.184436, Val Acc: 0.649485\n",
      "Epoch 5090 - Train Loss: 0.173471, Train Acc: 0.667949 | Val Loss: 0.184423, Val Acc: 0.649485\n",
      "Epoch 5091 - Train Loss: 0.173456, Train Acc: 0.667949 | Val Loss: 0.184409, Val Acc: 0.649485\n",
      "Epoch 5092 - Train Loss: 0.173441, Train Acc: 0.667949 | Val Loss: 0.184395, Val Acc: 0.649485\n",
      "Epoch 5093 - Train Loss: 0.173427, Train Acc: 0.667949 | Val Loss: 0.184381, Val Acc: 0.649485\n",
      "Epoch 5094 - Train Loss: 0.173412, Train Acc: 0.667949 | Val Loss: 0.184368, Val Acc: 0.649485\n",
      "Epoch 5095 - Train Loss: 0.173397, Train Acc: 0.667949 | Val Loss: 0.184354, Val Acc: 0.649485\n",
      "Epoch 5096 - Train Loss: 0.173383, Train Acc: 0.667949 | Val Loss: 0.184340, Val Acc: 0.649485\n",
      "Epoch 5097 - Train Loss: 0.173368, Train Acc: 0.667949 | Val Loss: 0.184327, Val Acc: 0.649485\n",
      "Epoch 5098 - Train Loss: 0.173353, Train Acc: 0.667949 | Val Loss: 0.184313, Val Acc: 0.649485\n",
      "Epoch 5099 - Train Loss: 0.173339, Train Acc: 0.667949 | Val Loss: 0.184299, Val Acc: 0.649485\n",
      "Epoch 5100 - Train Loss: 0.173324, Train Acc: 0.667949 | Val Loss: 0.184286, Val Acc: 0.649485\n",
      "Epoch 5101 - Train Loss: 0.173309, Train Acc: 0.667949 | Val Loss: 0.184272, Val Acc: 0.649485\n",
      "Epoch 5102 - Train Loss: 0.173295, Train Acc: 0.667949 | Val Loss: 0.184258, Val Acc: 0.649485\n",
      "Epoch 5103 - Train Loss: 0.173280, Train Acc: 0.667949 | Val Loss: 0.184245, Val Acc: 0.649485\n",
      "Epoch 5104 - Train Loss: 0.173265, Train Acc: 0.667949 | Val Loss: 0.184231, Val Acc: 0.649485\n",
      "Epoch 5105 - Train Loss: 0.173251, Train Acc: 0.667949 | Val Loss: 0.184217, Val Acc: 0.649485\n",
      "Epoch 5106 - Train Loss: 0.173236, Train Acc: 0.667949 | Val Loss: 0.184204, Val Acc: 0.649485\n",
      "Epoch 5107 - Train Loss: 0.173221, Train Acc: 0.667949 | Val Loss: 0.184190, Val Acc: 0.649485\n",
      "Epoch 5108 - Train Loss: 0.173207, Train Acc: 0.667949 | Val Loss: 0.184176, Val Acc: 0.649485\n",
      "Epoch 5109 - Train Loss: 0.173192, Train Acc: 0.667949 | Val Loss: 0.184163, Val Acc: 0.649485\n",
      "Epoch 5110 - Train Loss: 0.173177, Train Acc: 0.667949 | Val Loss: 0.184149, Val Acc: 0.649485\n",
      "Epoch 5111 - Train Loss: 0.173163, Train Acc: 0.667949 | Val Loss: 0.184135, Val Acc: 0.649485\n",
      "Epoch 5112 - Train Loss: 0.173148, Train Acc: 0.667949 | Val Loss: 0.184122, Val Acc: 0.649485\n",
      "Epoch 5113 - Train Loss: 0.173134, Train Acc: 0.667949 | Val Loss: 0.184108, Val Acc: 0.649485\n",
      "Epoch 5114 - Train Loss: 0.173119, Train Acc: 0.667949 | Val Loss: 0.184094, Val Acc: 0.649485\n",
      "Epoch 5115 - Train Loss: 0.173104, Train Acc: 0.667949 | Val Loss: 0.184081, Val Acc: 0.649485\n",
      "Epoch 5116 - Train Loss: 0.173090, Train Acc: 0.667949 | Val Loss: 0.184067, Val Acc: 0.649485\n",
      "Epoch 5117 - Train Loss: 0.173075, Train Acc: 0.667949 | Val Loss: 0.184054, Val Acc: 0.649485\n",
      "Epoch 5118 - Train Loss: 0.173060, Train Acc: 0.667949 | Val Loss: 0.184040, Val Acc: 0.649485\n",
      "Epoch 5119 - Train Loss: 0.173046, Train Acc: 0.667949 | Val Loss: 0.184026, Val Acc: 0.649485\n",
      "Epoch 5120 - Train Loss: 0.173031, Train Acc: 0.667949 | Val Loss: 0.184013, Val Acc: 0.649485\n",
      "Epoch 5121 - Train Loss: 0.173016, Train Acc: 0.667949 | Val Loss: 0.183999, Val Acc: 0.649485\n",
      "Epoch 5122 - Train Loss: 0.173002, Train Acc: 0.667949 | Val Loss: 0.183985, Val Acc: 0.649485\n",
      "Epoch 5123 - Train Loss: 0.172987, Train Acc: 0.667949 | Val Loss: 0.183972, Val Acc: 0.649485\n",
      "Epoch 5124 - Train Loss: 0.172973, Train Acc: 0.667949 | Val Loss: 0.183958, Val Acc: 0.649485\n",
      "Epoch 5125 - Train Loss: 0.172958, Train Acc: 0.667949 | Val Loss: 0.183945, Val Acc: 0.649485\n",
      "Epoch 5126 - Train Loss: 0.172943, Train Acc: 0.667949 | Val Loss: 0.183931, Val Acc: 0.649485\n",
      "Epoch 5127 - Train Loss: 0.172929, Train Acc: 0.667949 | Val Loss: 0.183917, Val Acc: 0.649485\n",
      "Epoch 5128 - Train Loss: 0.172914, Train Acc: 0.667949 | Val Loss: 0.183904, Val Acc: 0.649485\n",
      "Epoch 5129 - Train Loss: 0.172900, Train Acc: 0.667949 | Val Loss: 0.183890, Val Acc: 0.649485\n",
      "Epoch 5130 - Train Loss: 0.172885, Train Acc: 0.667949 | Val Loss: 0.183877, Val Acc: 0.649485\n",
      "Epoch 5131 - Train Loss: 0.172870, Train Acc: 0.667949 | Val Loss: 0.183863, Val Acc: 0.649485\n",
      "Epoch 5132 - Train Loss: 0.172856, Train Acc: 0.667949 | Val Loss: 0.183849, Val Acc: 0.649485\n",
      "Epoch 5133 - Train Loss: 0.172841, Train Acc: 0.667949 | Val Loss: 0.183836, Val Acc: 0.649485\n",
      "Epoch 5134 - Train Loss: 0.172827, Train Acc: 0.667949 | Val Loss: 0.183822, Val Acc: 0.649485\n",
      "Epoch 5135 - Train Loss: 0.172812, Train Acc: 0.667949 | Val Loss: 0.183809, Val Acc: 0.649485\n",
      "Epoch 5136 - Train Loss: 0.172797, Train Acc: 0.667949 | Val Loss: 0.183795, Val Acc: 0.649485\n",
      "Epoch 5137 - Train Loss: 0.172783, Train Acc: 0.667949 | Val Loss: 0.183782, Val Acc: 0.649485\n",
      "Epoch 5138 - Train Loss: 0.172768, Train Acc: 0.667949 | Val Loss: 0.183768, Val Acc: 0.649485\n",
      "Epoch 5139 - Train Loss: 0.172754, Train Acc: 0.667949 | Val Loss: 0.183754, Val Acc: 0.649485\n",
      "Epoch 5140 - Train Loss: 0.172739, Train Acc: 0.667949 | Val Loss: 0.183741, Val Acc: 0.649485\n",
      "Epoch 5141 - Train Loss: 0.172725, Train Acc: 0.667949 | Val Loss: 0.183727, Val Acc: 0.649485\n",
      "Epoch 5142 - Train Loss: 0.172710, Train Acc: 0.667949 | Val Loss: 0.183714, Val Acc: 0.649485\n",
      "Epoch 5143 - Train Loss: 0.172695, Train Acc: 0.667949 | Val Loss: 0.183700, Val Acc: 0.649485\n",
      "Epoch 5144 - Train Loss: 0.172681, Train Acc: 0.667949 | Val Loss: 0.183687, Val Acc: 0.649485\n",
      "Epoch 5145 - Train Loss: 0.172666, Train Acc: 0.667949 | Val Loss: 0.183673, Val Acc: 0.649485\n",
      "Epoch 5146 - Train Loss: 0.172652, Train Acc: 0.667949 | Val Loss: 0.183660, Val Acc: 0.649485\n",
      "Epoch 5147 - Train Loss: 0.172637, Train Acc: 0.667949 | Val Loss: 0.183646, Val Acc: 0.649485\n",
      "Epoch 5148 - Train Loss: 0.172623, Train Acc: 0.667949 | Val Loss: 0.183633, Val Acc: 0.649485\n",
      "Epoch 5149 - Train Loss: 0.172608, Train Acc: 0.667949 | Val Loss: 0.183619, Val Acc: 0.649485\n",
      "Epoch 5150 - Train Loss: 0.172593, Train Acc: 0.667949 | Val Loss: 0.183605, Val Acc: 0.649485\n",
      "Epoch 5151 - Train Loss: 0.172579, Train Acc: 0.667949 | Val Loss: 0.183592, Val Acc: 0.649485\n",
      "Epoch 5152 - Train Loss: 0.172564, Train Acc: 0.667949 | Val Loss: 0.183578, Val Acc: 0.649485\n",
      "Epoch 5153 - Train Loss: 0.172550, Train Acc: 0.667949 | Val Loss: 0.183565, Val Acc: 0.649485\n",
      "Epoch 5154 - Train Loss: 0.172535, Train Acc: 0.667949 | Val Loss: 0.183551, Val Acc: 0.649485\n",
      "Epoch 5155 - Train Loss: 0.172521, Train Acc: 0.667949 | Val Loss: 0.183538, Val Acc: 0.649485\n",
      "Epoch 5156 - Train Loss: 0.172506, Train Acc: 0.667949 | Val Loss: 0.183524, Val Acc: 0.649485\n",
      "Epoch 5157 - Train Loss: 0.172492, Train Acc: 0.667949 | Val Loss: 0.183511, Val Acc: 0.649485\n",
      "Epoch 5158 - Train Loss: 0.172477, Train Acc: 0.667949 | Val Loss: 0.183497, Val Acc: 0.649485\n",
      "Epoch 5159 - Train Loss: 0.172462, Train Acc: 0.667949 | Val Loss: 0.183484, Val Acc: 0.649485\n",
      "Epoch 5160 - Train Loss: 0.172448, Train Acc: 0.667949 | Val Loss: 0.183470, Val Acc: 0.649485\n",
      "Epoch 5161 - Train Loss: 0.172433, Train Acc: 0.667949 | Val Loss: 0.183457, Val Acc: 0.649485\n",
      "Epoch 5162 - Train Loss: 0.172419, Train Acc: 0.667949 | Val Loss: 0.183443, Val Acc: 0.649485\n",
      "Epoch 5163 - Train Loss: 0.172404, Train Acc: 0.667949 | Val Loss: 0.183430, Val Acc: 0.649485\n",
      "Epoch 5164 - Train Loss: 0.172390, Train Acc: 0.667949 | Val Loss: 0.183416, Val Acc: 0.649485\n",
      "Epoch 5165 - Train Loss: 0.172375, Train Acc: 0.667949 | Val Loss: 0.183402, Val Acc: 0.649485\n",
      "Epoch 5166 - Train Loss: 0.172361, Train Acc: 0.667949 | Val Loss: 0.183389, Val Acc: 0.649485\n",
      "Epoch 5167 - Train Loss: 0.172346, Train Acc: 0.667949 | Val Loss: 0.183375, Val Acc: 0.649485\n",
      "Epoch 5168 - Train Loss: 0.172332, Train Acc: 0.667949 | Val Loss: 0.183362, Val Acc: 0.649485\n",
      "Epoch 5169 - Train Loss: 0.172317, Train Acc: 0.667949 | Val Loss: 0.183348, Val Acc: 0.649485\n",
      "Epoch 5170 - Train Loss: 0.172302, Train Acc: 0.667949 | Val Loss: 0.183335, Val Acc: 0.649485\n",
      "Epoch 5171 - Train Loss: 0.172288, Train Acc: 0.667949 | Val Loss: 0.183321, Val Acc: 0.649485\n",
      "Epoch 5172 - Train Loss: 0.172273, Train Acc: 0.667949 | Val Loss: 0.183308, Val Acc: 0.649485\n",
      "Epoch 5173 - Train Loss: 0.172259, Train Acc: 0.667949 | Val Loss: 0.183294, Val Acc: 0.649485\n",
      "Epoch 5174 - Train Loss: 0.172244, Train Acc: 0.667949 | Val Loss: 0.183281, Val Acc: 0.649485\n",
      "Epoch 5175 - Train Loss: 0.172230, Train Acc: 0.667949 | Val Loss: 0.183267, Val Acc: 0.649485\n",
      "Epoch 5176 - Train Loss: 0.172215, Train Acc: 0.667949 | Val Loss: 0.183254, Val Acc: 0.649485\n",
      "Epoch 5177 - Train Loss: 0.172201, Train Acc: 0.667949 | Val Loss: 0.183240, Val Acc: 0.649485\n",
      "Epoch 5178 - Train Loss: 0.172186, Train Acc: 0.667949 | Val Loss: 0.183227, Val Acc: 0.649485\n",
      "Epoch 5179 - Train Loss: 0.172172, Train Acc: 0.667949 | Val Loss: 0.183213, Val Acc: 0.649485\n",
      "Epoch 5180 - Train Loss: 0.172157, Train Acc: 0.667949 | Val Loss: 0.183200, Val Acc: 0.649485\n",
      "Epoch 5181 - Train Loss: 0.172143, Train Acc: 0.667949 | Val Loss: 0.183186, Val Acc: 0.649485\n",
      "Epoch 5182 - Train Loss: 0.172128, Train Acc: 0.667949 | Val Loss: 0.183173, Val Acc: 0.649485\n",
      "Epoch 5183 - Train Loss: 0.172114, Train Acc: 0.667949 | Val Loss: 0.183159, Val Acc: 0.649485\n",
      "Epoch 5184 - Train Loss: 0.172099, Train Acc: 0.669231 | Val Loss: 0.183146, Val Acc: 0.649485\n",
      "Epoch 5185 - Train Loss: 0.172085, Train Acc: 0.669231 | Val Loss: 0.183133, Val Acc: 0.649485\n",
      "Epoch 5186 - Train Loss: 0.172070, Train Acc: 0.669231 | Val Loss: 0.183119, Val Acc: 0.649485\n",
      "Epoch 5187 - Train Loss: 0.172056, Train Acc: 0.669231 | Val Loss: 0.183106, Val Acc: 0.649485\n",
      "Epoch 5188 - Train Loss: 0.172041, Train Acc: 0.669231 | Val Loss: 0.183092, Val Acc: 0.649485\n",
      "Epoch 5189 - Train Loss: 0.172027, Train Acc: 0.669231 | Val Loss: 0.183079, Val Acc: 0.649485\n",
      "Epoch 5190 - Train Loss: 0.172012, Train Acc: 0.669231 | Val Loss: 0.183065, Val Acc: 0.649485\n",
      "Epoch 5191 - Train Loss: 0.171998, Train Acc: 0.669231 | Val Loss: 0.183052, Val Acc: 0.649485\n",
      "Epoch 5192 - Train Loss: 0.171983, Train Acc: 0.669231 | Val Loss: 0.183038, Val Acc: 0.649485\n",
      "Epoch 5193 - Train Loss: 0.171969, Train Acc: 0.669231 | Val Loss: 0.183025, Val Acc: 0.649485\n",
      "Epoch 5194 - Train Loss: 0.171954, Train Acc: 0.669231 | Val Loss: 0.183011, Val Acc: 0.649485\n",
      "Epoch 5195 - Train Loss: 0.171940, Train Acc: 0.669231 | Val Loss: 0.182998, Val Acc: 0.649485\n",
      "Epoch 5196 - Train Loss: 0.171925, Train Acc: 0.669231 | Val Loss: 0.182984, Val Acc: 0.649485\n",
      "Epoch 5197 - Train Loss: 0.171911, Train Acc: 0.669231 | Val Loss: 0.182971, Val Acc: 0.649485\n",
      "Epoch 5198 - Train Loss: 0.171896, Train Acc: 0.669231 | Val Loss: 0.182957, Val Acc: 0.649485\n",
      "Epoch 5199 - Train Loss: 0.171882, Train Acc: 0.669231 | Val Loss: 0.182944, Val Acc: 0.649485\n",
      "Epoch 5200 - Train Loss: 0.171867, Train Acc: 0.669231 | Val Loss: 0.182930, Val Acc: 0.649485\n",
      "Epoch 5201 - Train Loss: 0.171853, Train Acc: 0.669231 | Val Loss: 0.182917, Val Acc: 0.649485\n",
      "Epoch 5202 - Train Loss: 0.171838, Train Acc: 0.670513 | Val Loss: 0.182904, Val Acc: 0.649485\n",
      "Epoch 5203 - Train Loss: 0.171824, Train Acc: 0.670513 | Val Loss: 0.182890, Val Acc: 0.649485\n",
      "Epoch 5204 - Train Loss: 0.171809, Train Acc: 0.670513 | Val Loss: 0.182877, Val Acc: 0.649485\n",
      "Epoch 5205 - Train Loss: 0.171795, Train Acc: 0.670513 | Val Loss: 0.182863, Val Acc: 0.649485\n",
      "Epoch 5206 - Train Loss: 0.171780, Train Acc: 0.670513 | Val Loss: 0.182850, Val Acc: 0.649485\n",
      "Epoch 5207 - Train Loss: 0.171766, Train Acc: 0.670513 | Val Loss: 0.182836, Val Acc: 0.649485\n",
      "Epoch 5208 - Train Loss: 0.171752, Train Acc: 0.670513 | Val Loss: 0.182823, Val Acc: 0.649485\n",
      "Epoch 5209 - Train Loss: 0.171737, Train Acc: 0.670513 | Val Loss: 0.182809, Val Acc: 0.649485\n",
      "Epoch 5210 - Train Loss: 0.171723, Train Acc: 0.670513 | Val Loss: 0.182796, Val Acc: 0.649485\n",
      "Epoch 5211 - Train Loss: 0.171708, Train Acc: 0.670513 | Val Loss: 0.182783, Val Acc: 0.649485\n",
      "Epoch 5212 - Train Loss: 0.171694, Train Acc: 0.670513 | Val Loss: 0.182769, Val Acc: 0.649485\n",
      "Epoch 5213 - Train Loss: 0.171679, Train Acc: 0.670513 | Val Loss: 0.182756, Val Acc: 0.649485\n",
      "Epoch 5214 - Train Loss: 0.171665, Train Acc: 0.670513 | Val Loss: 0.182742, Val Acc: 0.649485\n",
      "Epoch 5215 - Train Loss: 0.171650, Train Acc: 0.670513 | Val Loss: 0.182729, Val Acc: 0.649485\n",
      "Epoch 5216 - Train Loss: 0.171636, Train Acc: 0.670513 | Val Loss: 0.182715, Val Acc: 0.649485\n",
      "Epoch 5217 - Train Loss: 0.171621, Train Acc: 0.670513 | Val Loss: 0.182702, Val Acc: 0.649485\n",
      "Epoch 5218 - Train Loss: 0.171607, Train Acc: 0.670513 | Val Loss: 0.182689, Val Acc: 0.649485\n",
      "Epoch 5219 - Train Loss: 0.171593, Train Acc: 0.670513 | Val Loss: 0.182675, Val Acc: 0.649485\n",
      "Epoch 5220 - Train Loss: 0.171578, Train Acc: 0.670513 | Val Loss: 0.182662, Val Acc: 0.649485\n",
      "Epoch 5221 - Train Loss: 0.171564, Train Acc: 0.670513 | Val Loss: 0.182648, Val Acc: 0.649485\n",
      "Epoch 5222 - Train Loss: 0.171549, Train Acc: 0.670513 | Val Loss: 0.182635, Val Acc: 0.649485\n",
      "Epoch 5223 - Train Loss: 0.171535, Train Acc: 0.670513 | Val Loss: 0.182621, Val Acc: 0.649485\n",
      "Epoch 5224 - Train Loss: 0.171520, Train Acc: 0.670513 | Val Loss: 0.182608, Val Acc: 0.649485\n",
      "Epoch 5225 - Train Loss: 0.171506, Train Acc: 0.670513 | Val Loss: 0.182595, Val Acc: 0.649485\n",
      "Epoch 5226 - Train Loss: 0.171491, Train Acc: 0.670513 | Val Loss: 0.182581, Val Acc: 0.649485\n",
      "Epoch 5227 - Train Loss: 0.171477, Train Acc: 0.670513 | Val Loss: 0.182568, Val Acc: 0.649485\n",
      "Epoch 5228 - Train Loss: 0.171463, Train Acc: 0.670513 | Val Loss: 0.182554, Val Acc: 0.649485\n",
      "Epoch 5229 - Train Loss: 0.171448, Train Acc: 0.670513 | Val Loss: 0.182541, Val Acc: 0.649485\n",
      "Epoch 5230 - Train Loss: 0.171434, Train Acc: 0.671795 | Val Loss: 0.182528, Val Acc: 0.649485\n",
      "Epoch 5231 - Train Loss: 0.171419, Train Acc: 0.671795 | Val Loss: 0.182514, Val Acc: 0.649485\n",
      "Epoch 5232 - Train Loss: 0.171405, Train Acc: 0.671795 | Val Loss: 0.182501, Val Acc: 0.649485\n",
      "Epoch 5233 - Train Loss: 0.171390, Train Acc: 0.671795 | Val Loss: 0.182487, Val Acc: 0.649485\n",
      "Epoch 5234 - Train Loss: 0.171376, Train Acc: 0.671795 | Val Loss: 0.182474, Val Acc: 0.649485\n",
      "Epoch 5235 - Train Loss: 0.171362, Train Acc: 0.671795 | Val Loss: 0.182461, Val Acc: 0.649485\n",
      "Epoch 5236 - Train Loss: 0.171347, Train Acc: 0.671795 | Val Loss: 0.182447, Val Acc: 0.649485\n",
      "Epoch 5237 - Train Loss: 0.171333, Train Acc: 0.671795 | Val Loss: 0.182434, Val Acc: 0.649485\n",
      "Epoch 5238 - Train Loss: 0.171318, Train Acc: 0.671795 | Val Loss: 0.182420, Val Acc: 0.649485\n",
      "Epoch 5239 - Train Loss: 0.171304, Train Acc: 0.671795 | Val Loss: 0.182407, Val Acc: 0.649485\n",
      "Epoch 5240 - Train Loss: 0.171289, Train Acc: 0.671795 | Val Loss: 0.182394, Val Acc: 0.649485\n",
      "Epoch 5241 - Train Loss: 0.171275, Train Acc: 0.671795 | Val Loss: 0.182380, Val Acc: 0.649485\n",
      "Epoch 5242 - Train Loss: 0.171261, Train Acc: 0.671795 | Val Loss: 0.182367, Val Acc: 0.649485\n",
      "Epoch 5243 - Train Loss: 0.171246, Train Acc: 0.671795 | Val Loss: 0.182353, Val Acc: 0.649485\n",
      "Epoch 5244 - Train Loss: 0.171232, Train Acc: 0.671795 | Val Loss: 0.182340, Val Acc: 0.649485\n",
      "Epoch 5245 - Train Loss: 0.171217, Train Acc: 0.671795 | Val Loss: 0.182327, Val Acc: 0.649485\n",
      "Epoch 5246 - Train Loss: 0.171203, Train Acc: 0.671795 | Val Loss: 0.182313, Val Acc: 0.649485\n",
      "Epoch 5247 - Train Loss: 0.171189, Train Acc: 0.671795 | Val Loss: 0.182300, Val Acc: 0.649485\n",
      "Epoch 5248 - Train Loss: 0.171174, Train Acc: 0.671795 | Val Loss: 0.182287, Val Acc: 0.649485\n",
      "Epoch 5249 - Train Loss: 0.171160, Train Acc: 0.671795 | Val Loss: 0.182273, Val Acc: 0.649485\n",
      "Epoch 5250 - Train Loss: 0.171145, Train Acc: 0.671795 | Val Loss: 0.182260, Val Acc: 0.649485\n",
      "Epoch 5251 - Train Loss: 0.171131, Train Acc: 0.671795 | Val Loss: 0.182246, Val Acc: 0.649485\n",
      "Epoch 5252 - Train Loss: 0.171116, Train Acc: 0.671795 | Val Loss: 0.182233, Val Acc: 0.649485\n",
      "Epoch 5253 - Train Loss: 0.171102, Train Acc: 0.671795 | Val Loss: 0.182220, Val Acc: 0.649485\n",
      "Epoch 5254 - Train Loss: 0.171088, Train Acc: 0.671795 | Val Loss: 0.182206, Val Acc: 0.649485\n",
      "Epoch 5255 - Train Loss: 0.171073, Train Acc: 0.671795 | Val Loss: 0.182193, Val Acc: 0.649485\n",
      "Epoch 5256 - Train Loss: 0.171059, Train Acc: 0.671795 | Val Loss: 0.182180, Val Acc: 0.649485\n",
      "Epoch 5257 - Train Loss: 0.171044, Train Acc: 0.671795 | Val Loss: 0.182166, Val Acc: 0.649485\n",
      "Epoch 5258 - Train Loss: 0.171030, Train Acc: 0.671795 | Val Loss: 0.182153, Val Acc: 0.649485\n",
      "Epoch 5259 - Train Loss: 0.171016, Train Acc: 0.671795 | Val Loss: 0.182140, Val Acc: 0.649485\n",
      "Epoch 5260 - Train Loss: 0.171001, Train Acc: 0.671795 | Val Loss: 0.182126, Val Acc: 0.649485\n",
      "Epoch 5261 - Train Loss: 0.170987, Train Acc: 0.671795 | Val Loss: 0.182113, Val Acc: 0.649485\n",
      "Epoch 5262 - Train Loss: 0.170973, Train Acc: 0.671795 | Val Loss: 0.182100, Val Acc: 0.649485\n",
      "Epoch 5263 - Train Loss: 0.170958, Train Acc: 0.671795 | Val Loss: 0.182086, Val Acc: 0.649485\n",
      "Epoch 5264 - Train Loss: 0.170944, Train Acc: 0.673077 | Val Loss: 0.182073, Val Acc: 0.649485\n",
      "Epoch 5265 - Train Loss: 0.170929, Train Acc: 0.673077 | Val Loss: 0.182060, Val Acc: 0.649485\n",
      "Epoch 5266 - Train Loss: 0.170915, Train Acc: 0.673077 | Val Loss: 0.182046, Val Acc: 0.649485\n",
      "Epoch 5267 - Train Loss: 0.170901, Train Acc: 0.673077 | Val Loss: 0.182033, Val Acc: 0.649485\n",
      "Epoch 5268 - Train Loss: 0.170886, Train Acc: 0.673077 | Val Loss: 0.182020, Val Acc: 0.649485\n",
      "Epoch 5269 - Train Loss: 0.170872, Train Acc: 0.673077 | Val Loss: 0.182006, Val Acc: 0.649485\n",
      "Epoch 5270 - Train Loss: 0.170858, Train Acc: 0.673077 | Val Loss: 0.181993, Val Acc: 0.649485\n",
      "Epoch 5271 - Train Loss: 0.170843, Train Acc: 0.673077 | Val Loss: 0.181980, Val Acc: 0.649485\n",
      "Epoch 5272 - Train Loss: 0.170829, Train Acc: 0.673077 | Val Loss: 0.181966, Val Acc: 0.649485\n",
      "Epoch 5273 - Train Loss: 0.170814, Train Acc: 0.673077 | Val Loss: 0.181953, Val Acc: 0.649485\n",
      "Epoch 5274 - Train Loss: 0.170800, Train Acc: 0.673077 | Val Loss: 0.181940, Val Acc: 0.649485\n",
      "Epoch 5275 - Train Loss: 0.170786, Train Acc: 0.673077 | Val Loss: 0.181926, Val Acc: 0.649485\n",
      "Epoch 5276 - Train Loss: 0.170771, Train Acc: 0.673077 | Val Loss: 0.181913, Val Acc: 0.649485\n",
      "Epoch 5277 - Train Loss: 0.170757, Train Acc: 0.673077 | Val Loss: 0.181900, Val Acc: 0.649485\n",
      "Epoch 5278 - Train Loss: 0.170743, Train Acc: 0.673077 | Val Loss: 0.181886, Val Acc: 0.649485\n",
      "Epoch 5279 - Train Loss: 0.170728, Train Acc: 0.673077 | Val Loss: 0.181873, Val Acc: 0.649485\n",
      "Epoch 5280 - Train Loss: 0.170714, Train Acc: 0.673077 | Val Loss: 0.181860, Val Acc: 0.649485\n",
      "Epoch 5281 - Train Loss: 0.170699, Train Acc: 0.673077 | Val Loss: 0.181847, Val Acc: 0.649485\n",
      "Epoch 5282 - Train Loss: 0.170685, Train Acc: 0.673077 | Val Loss: 0.181833, Val Acc: 0.649485\n",
      "Epoch 5283 - Train Loss: 0.170671, Train Acc: 0.673077 | Val Loss: 0.181820, Val Acc: 0.649485\n",
      "Epoch 5284 - Train Loss: 0.170656, Train Acc: 0.673077 | Val Loss: 0.181807, Val Acc: 0.649485\n",
      "Epoch 5285 - Train Loss: 0.170642, Train Acc: 0.673077 | Val Loss: 0.181793, Val Acc: 0.649485\n",
      "Epoch 5286 - Train Loss: 0.170628, Train Acc: 0.673077 | Val Loss: 0.181780, Val Acc: 0.649485\n",
      "Epoch 5287 - Train Loss: 0.170613, Train Acc: 0.673077 | Val Loss: 0.181767, Val Acc: 0.649485\n",
      "Epoch 5288 - Train Loss: 0.170599, Train Acc: 0.673077 | Val Loss: 0.181753, Val Acc: 0.649485\n",
      "Epoch 5289 - Train Loss: 0.170585, Train Acc: 0.673077 | Val Loss: 0.181740, Val Acc: 0.649485\n",
      "Epoch 5290 - Train Loss: 0.170570, Train Acc: 0.673077 | Val Loss: 0.181727, Val Acc: 0.649485\n",
      "Epoch 5291 - Train Loss: 0.170556, Train Acc: 0.673077 | Val Loss: 0.181714, Val Acc: 0.649485\n",
      "Epoch 5292 - Train Loss: 0.170542, Train Acc: 0.673077 | Val Loss: 0.181700, Val Acc: 0.649485\n",
      "Epoch 5293 - Train Loss: 0.170527, Train Acc: 0.673077 | Val Loss: 0.181687, Val Acc: 0.649485\n",
      "Epoch 5294 - Train Loss: 0.170513, Train Acc: 0.673077 | Val Loss: 0.181674, Val Acc: 0.649485\n",
      "Epoch 5295 - Train Loss: 0.170499, Train Acc: 0.673077 | Val Loss: 0.181660, Val Acc: 0.649485\n",
      "Epoch 5296 - Train Loss: 0.170484, Train Acc: 0.673077 | Val Loss: 0.181647, Val Acc: 0.649485\n",
      "Epoch 5297 - Train Loss: 0.170470, Train Acc: 0.673077 | Val Loss: 0.181634, Val Acc: 0.649485\n",
      "Epoch 5298 - Train Loss: 0.170456, Train Acc: 0.673077 | Val Loss: 0.181621, Val Acc: 0.649485\n",
      "Epoch 5299 - Train Loss: 0.170441, Train Acc: 0.673077 | Val Loss: 0.181607, Val Acc: 0.649485\n",
      "Epoch 5300 - Train Loss: 0.170427, Train Acc: 0.673077 | Val Loss: 0.181594, Val Acc: 0.649485\n",
      "Epoch 5301 - Train Loss: 0.170413, Train Acc: 0.673077 | Val Loss: 0.181581, Val Acc: 0.649485\n",
      "Epoch 5302 - Train Loss: 0.170398, Train Acc: 0.673077 | Val Loss: 0.181567, Val Acc: 0.649485\n",
      "Epoch 5303 - Train Loss: 0.170384, Train Acc: 0.673077 | Val Loss: 0.181554, Val Acc: 0.649485\n",
      "Epoch 5304 - Train Loss: 0.170370, Train Acc: 0.673077 | Val Loss: 0.181541, Val Acc: 0.649485\n",
      "Epoch 5305 - Train Loss: 0.170355, Train Acc: 0.673077 | Val Loss: 0.181528, Val Acc: 0.649485\n",
      "Epoch 5306 - Train Loss: 0.170341, Train Acc: 0.673077 | Val Loss: 0.181514, Val Acc: 0.649485\n",
      "Epoch 5307 - Train Loss: 0.170327, Train Acc: 0.673077 | Val Loss: 0.181501, Val Acc: 0.649485\n",
      "Epoch 5308 - Train Loss: 0.170312, Train Acc: 0.673077 | Val Loss: 0.181488, Val Acc: 0.649485\n",
      "Epoch 5309 - Train Loss: 0.170298, Train Acc: 0.673077 | Val Loss: 0.181474, Val Acc: 0.649485\n",
      "Epoch 5310 - Train Loss: 0.170284, Train Acc: 0.673077 | Val Loss: 0.181461, Val Acc: 0.649485\n",
      "Epoch 5311 - Train Loss: 0.170269, Train Acc: 0.673077 | Val Loss: 0.181448, Val Acc: 0.649485\n",
      "Epoch 5312 - Train Loss: 0.170255, Train Acc: 0.673077 | Val Loss: 0.181435, Val Acc: 0.649485\n",
      "Epoch 5313 - Train Loss: 0.170241, Train Acc: 0.673077 | Val Loss: 0.181421, Val Acc: 0.649485\n",
      "Epoch 5314 - Train Loss: 0.170227, Train Acc: 0.673077 | Val Loss: 0.181408, Val Acc: 0.649485\n",
      "Epoch 5315 - Train Loss: 0.170212, Train Acc: 0.673077 | Val Loss: 0.181395, Val Acc: 0.649485\n",
      "Epoch 5316 - Train Loss: 0.170198, Train Acc: 0.673077 | Val Loss: 0.181381, Val Acc: 0.649485\n",
      "Epoch 5317 - Train Loss: 0.170184, Train Acc: 0.673077 | Val Loss: 0.181368, Val Acc: 0.649485\n",
      "Epoch 5318 - Train Loss: 0.170169, Train Acc: 0.673077 | Val Loss: 0.181355, Val Acc: 0.649485\n",
      "Epoch 5319 - Train Loss: 0.170155, Train Acc: 0.673077 | Val Loss: 0.181342, Val Acc: 0.649485\n",
      "Epoch 5320 - Train Loss: 0.170141, Train Acc: 0.673077 | Val Loss: 0.181328, Val Acc: 0.649485\n",
      "Epoch 5321 - Train Loss: 0.170127, Train Acc: 0.673077 | Val Loss: 0.181315, Val Acc: 0.649485\n",
      "Epoch 5322 - Train Loss: 0.170112, Train Acc: 0.673077 | Val Loss: 0.181302, Val Acc: 0.649485\n",
      "Epoch 5323 - Train Loss: 0.170098, Train Acc: 0.673077 | Val Loss: 0.181289, Val Acc: 0.649485\n",
      "Epoch 5324 - Train Loss: 0.170084, Train Acc: 0.673077 | Val Loss: 0.181275, Val Acc: 0.649485\n",
      "Epoch 5325 - Train Loss: 0.170069, Train Acc: 0.673077 | Val Loss: 0.181262, Val Acc: 0.649485\n",
      "Epoch 5326 - Train Loss: 0.170055, Train Acc: 0.673077 | Val Loss: 0.181249, Val Acc: 0.649485\n",
      "Epoch 5327 - Train Loss: 0.170041, Train Acc: 0.673077 | Val Loss: 0.181236, Val Acc: 0.649485\n",
      "Epoch 5328 - Train Loss: 0.170026, Train Acc: 0.673077 | Val Loss: 0.181222, Val Acc: 0.649485\n",
      "Epoch 5329 - Train Loss: 0.170012, Train Acc: 0.673077 | Val Loss: 0.181209, Val Acc: 0.649485\n",
      "Epoch 5330 - Train Loss: 0.169998, Train Acc: 0.673077 | Val Loss: 0.181196, Val Acc: 0.659794\n",
      "Epoch 5331 - Train Loss: 0.169984, Train Acc: 0.673077 | Val Loss: 0.181182, Val Acc: 0.659794\n",
      "Epoch 5332 - Train Loss: 0.169969, Train Acc: 0.673077 | Val Loss: 0.181169, Val Acc: 0.659794\n",
      "Epoch 5333 - Train Loss: 0.169955, Train Acc: 0.673077 | Val Loss: 0.181156, Val Acc: 0.659794\n",
      "Epoch 5334 - Train Loss: 0.169941, Train Acc: 0.673077 | Val Loss: 0.181143, Val Acc: 0.659794\n",
      "Epoch 5335 - Train Loss: 0.169926, Train Acc: 0.673077 | Val Loss: 0.181129, Val Acc: 0.659794\n",
      "Epoch 5336 - Train Loss: 0.169912, Train Acc: 0.673077 | Val Loss: 0.181116, Val Acc: 0.659794\n",
      "Epoch 5337 - Train Loss: 0.169898, Train Acc: 0.673077 | Val Loss: 0.181103, Val Acc: 0.659794\n",
      "Epoch 5338 - Train Loss: 0.169884, Train Acc: 0.673077 | Val Loss: 0.181090, Val Acc: 0.659794\n",
      "Epoch 5339 - Train Loss: 0.169869, Train Acc: 0.673077 | Val Loss: 0.181077, Val Acc: 0.659794\n",
      "Epoch 5340 - Train Loss: 0.169855, Train Acc: 0.673077 | Val Loss: 0.181063, Val Acc: 0.659794\n",
      "Epoch 5341 - Train Loss: 0.169841, Train Acc: 0.673077 | Val Loss: 0.181050, Val Acc: 0.659794\n",
      "Epoch 5342 - Train Loss: 0.169827, Train Acc: 0.673077 | Val Loss: 0.181037, Val Acc: 0.659794\n",
      "Epoch 5343 - Train Loss: 0.169812, Train Acc: 0.673077 | Val Loss: 0.181024, Val Acc: 0.659794\n",
      "Epoch 5344 - Train Loss: 0.169798, Train Acc: 0.673077 | Val Loss: 0.181010, Val Acc: 0.659794\n",
      "Epoch 5345 - Train Loss: 0.169784, Train Acc: 0.673077 | Val Loss: 0.180997, Val Acc: 0.659794\n",
      "Epoch 5346 - Train Loss: 0.169770, Train Acc: 0.673077 | Val Loss: 0.180984, Val Acc: 0.659794\n",
      "Epoch 5347 - Train Loss: 0.169755, Train Acc: 0.673077 | Val Loss: 0.180971, Val Acc: 0.659794\n",
      "Epoch 5348 - Train Loss: 0.169741, Train Acc: 0.673077 | Val Loss: 0.180957, Val Acc: 0.659794\n",
      "Epoch 5349 - Train Loss: 0.169727, Train Acc: 0.673077 | Val Loss: 0.180944, Val Acc: 0.659794\n",
      "Epoch 5350 - Train Loss: 0.169713, Train Acc: 0.673077 | Val Loss: 0.180931, Val Acc: 0.659794\n",
      "Epoch 5351 - Train Loss: 0.169698, Train Acc: 0.674359 | Val Loss: 0.180918, Val Acc: 0.659794\n",
      "Epoch 5352 - Train Loss: 0.169684, Train Acc: 0.674359 | Val Loss: 0.180905, Val Acc: 0.659794\n",
      "Epoch 5353 - Train Loss: 0.169670, Train Acc: 0.674359 | Val Loss: 0.180891, Val Acc: 0.659794\n",
      "Epoch 5354 - Train Loss: 0.169656, Train Acc: 0.674359 | Val Loss: 0.180878, Val Acc: 0.659794\n",
      "Epoch 5355 - Train Loss: 0.169641, Train Acc: 0.674359 | Val Loss: 0.180865, Val Acc: 0.659794\n",
      "Epoch 5356 - Train Loss: 0.169627, Train Acc: 0.674359 | Val Loss: 0.180852, Val Acc: 0.659794\n",
      "Epoch 5357 - Train Loss: 0.169613, Train Acc: 0.674359 | Val Loss: 0.180839, Val Acc: 0.659794\n",
      "Epoch 5358 - Train Loss: 0.169599, Train Acc: 0.674359 | Val Loss: 0.180825, Val Acc: 0.659794\n",
      "Epoch 5359 - Train Loss: 0.169584, Train Acc: 0.674359 | Val Loss: 0.180812, Val Acc: 0.659794\n",
      "Epoch 5360 - Train Loss: 0.169570, Train Acc: 0.674359 | Val Loss: 0.180799, Val Acc: 0.659794\n",
      "Epoch 5361 - Train Loss: 0.169556, Train Acc: 0.674359 | Val Loss: 0.180786, Val Acc: 0.659794\n",
      "Epoch 5362 - Train Loss: 0.169542, Train Acc: 0.674359 | Val Loss: 0.180773, Val Acc: 0.659794\n",
      "Epoch 5363 - Train Loss: 0.169527, Train Acc: 0.674359 | Val Loss: 0.180760, Val Acc: 0.659794\n",
      "Epoch 5364 - Train Loss: 0.169513, Train Acc: 0.674359 | Val Loss: 0.180746, Val Acc: 0.659794\n",
      "Epoch 5365 - Train Loss: 0.169499, Train Acc: 0.674359 | Val Loss: 0.180733, Val Acc: 0.659794\n",
      "Epoch 5366 - Train Loss: 0.169485, Train Acc: 0.674359 | Val Loss: 0.180720, Val Acc: 0.659794\n",
      "Epoch 5367 - Train Loss: 0.169471, Train Acc: 0.674359 | Val Loss: 0.180707, Val Acc: 0.659794\n",
      "Epoch 5368 - Train Loss: 0.169456, Train Acc: 0.674359 | Val Loss: 0.180694, Val Acc: 0.659794\n",
      "Epoch 5369 - Train Loss: 0.169442, Train Acc: 0.674359 | Val Loss: 0.180681, Val Acc: 0.659794\n",
      "Epoch 5370 - Train Loss: 0.169428, Train Acc: 0.674359 | Val Loss: 0.180667, Val Acc: 0.659794\n",
      "Epoch 5371 - Train Loss: 0.169414, Train Acc: 0.674359 | Val Loss: 0.180654, Val Acc: 0.659794\n",
      "Epoch 5372 - Train Loss: 0.169399, Train Acc: 0.674359 | Val Loss: 0.180641, Val Acc: 0.659794\n",
      "Epoch 5373 - Train Loss: 0.169385, Train Acc: 0.676923 | Val Loss: 0.180628, Val Acc: 0.659794\n",
      "Epoch 5374 - Train Loss: 0.169371, Train Acc: 0.676923 | Val Loss: 0.180615, Val Acc: 0.659794\n",
      "Epoch 5375 - Train Loss: 0.169357, Train Acc: 0.676923 | Val Loss: 0.180602, Val Acc: 0.659794\n",
      "Epoch 5376 - Train Loss: 0.169343, Train Acc: 0.676923 | Val Loss: 0.180588, Val Acc: 0.659794\n",
      "Epoch 5377 - Train Loss: 0.169328, Train Acc: 0.676923 | Val Loss: 0.180575, Val Acc: 0.659794\n",
      "Epoch 5378 - Train Loss: 0.169314, Train Acc: 0.676923 | Val Loss: 0.180562, Val Acc: 0.659794\n",
      "Epoch 5379 - Train Loss: 0.169300, Train Acc: 0.676923 | Val Loss: 0.180549, Val Acc: 0.659794\n",
      "Epoch 5380 - Train Loss: 0.169286, Train Acc: 0.676923 | Val Loss: 0.180536, Val Acc: 0.659794\n",
      "Epoch 5381 - Train Loss: 0.169272, Train Acc: 0.676923 | Val Loss: 0.180523, Val Acc: 0.659794\n",
      "Epoch 5382 - Train Loss: 0.169257, Train Acc: 0.676923 | Val Loss: 0.180510, Val Acc: 0.659794\n",
      "Epoch 5383 - Train Loss: 0.169243, Train Acc: 0.676923 | Val Loss: 0.180496, Val Acc: 0.659794\n",
      "Epoch 5384 - Train Loss: 0.169229, Train Acc: 0.676923 | Val Loss: 0.180483, Val Acc: 0.659794\n",
      "Epoch 5385 - Train Loss: 0.169215, Train Acc: 0.676923 | Val Loss: 0.180470, Val Acc: 0.659794\n",
      "Epoch 5386 - Train Loss: 0.169201, Train Acc: 0.676923 | Val Loss: 0.180457, Val Acc: 0.659794\n",
      "Epoch 5387 - Train Loss: 0.169186, Train Acc: 0.676923 | Val Loss: 0.180444, Val Acc: 0.659794\n",
      "Epoch 5388 - Train Loss: 0.169172, Train Acc: 0.676923 | Val Loss: 0.180431, Val Acc: 0.659794\n",
      "Epoch 5389 - Train Loss: 0.169158, Train Acc: 0.676923 | Val Loss: 0.180418, Val Acc: 0.659794\n",
      "Epoch 5390 - Train Loss: 0.169144, Train Acc: 0.676923 | Val Loss: 0.180405, Val Acc: 0.659794\n",
      "Epoch 5391 - Train Loss: 0.169130, Train Acc: 0.676923 | Val Loss: 0.180391, Val Acc: 0.659794\n",
      "Epoch 5392 - Train Loss: 0.169115, Train Acc: 0.676923 | Val Loss: 0.180378, Val Acc: 0.659794\n",
      "Epoch 5393 - Train Loss: 0.169101, Train Acc: 0.676923 | Val Loss: 0.180365, Val Acc: 0.659794\n",
      "Epoch 5394 - Train Loss: 0.169087, Train Acc: 0.676923 | Val Loss: 0.180352, Val Acc: 0.659794\n",
      "Epoch 5395 - Train Loss: 0.169073, Train Acc: 0.676923 | Val Loss: 0.180339, Val Acc: 0.659794\n",
      "Epoch 5396 - Train Loss: 0.169059, Train Acc: 0.676923 | Val Loss: 0.180326, Val Acc: 0.659794\n",
      "Epoch 5397 - Train Loss: 0.169045, Train Acc: 0.676923 | Val Loss: 0.180313, Val Acc: 0.659794\n",
      "Epoch 5398 - Train Loss: 0.169030, Train Acc: 0.676923 | Val Loss: 0.180300, Val Acc: 0.659794\n",
      "Epoch 5399 - Train Loss: 0.169016, Train Acc: 0.676923 | Val Loss: 0.180286, Val Acc: 0.659794\n",
      "Epoch 5400 - Train Loss: 0.169002, Train Acc: 0.676923 | Val Loss: 0.180273, Val Acc: 0.659794\n",
      "Epoch 5401 - Train Loss: 0.168988, Train Acc: 0.676923 | Val Loss: 0.180260, Val Acc: 0.659794\n",
      "Epoch 5402 - Train Loss: 0.168974, Train Acc: 0.678205 | Val Loss: 0.180247, Val Acc: 0.659794\n",
      "Epoch 5403 - Train Loss: 0.168959, Train Acc: 0.678205 | Val Loss: 0.180234, Val Acc: 0.659794\n",
      "Epoch 5404 - Train Loss: 0.168945, Train Acc: 0.678205 | Val Loss: 0.180221, Val Acc: 0.659794\n",
      "Epoch 5405 - Train Loss: 0.168931, Train Acc: 0.678205 | Val Loss: 0.180208, Val Acc: 0.659794\n",
      "Epoch 5406 - Train Loss: 0.168917, Train Acc: 0.678205 | Val Loss: 0.180195, Val Acc: 0.659794\n",
      "Epoch 5407 - Train Loss: 0.168903, Train Acc: 0.678205 | Val Loss: 0.180182, Val Acc: 0.659794\n",
      "Epoch 5408 - Train Loss: 0.168889, Train Acc: 0.678205 | Val Loss: 0.180169, Val Acc: 0.659794\n",
      "Epoch 5409 - Train Loss: 0.168875, Train Acc: 0.678205 | Val Loss: 0.180155, Val Acc: 0.659794\n",
      "Epoch 5410 - Train Loss: 0.168860, Train Acc: 0.678205 | Val Loss: 0.180142, Val Acc: 0.659794\n",
      "Epoch 5411 - Train Loss: 0.168846, Train Acc: 0.678205 | Val Loss: 0.180129, Val Acc: 0.659794\n",
      "Epoch 5412 - Train Loss: 0.168832, Train Acc: 0.678205 | Val Loss: 0.180116, Val Acc: 0.659794\n",
      "Epoch 5413 - Train Loss: 0.168818, Train Acc: 0.678205 | Val Loss: 0.180103, Val Acc: 0.659794\n",
      "Epoch 5414 - Train Loss: 0.168804, Train Acc: 0.678205 | Val Loss: 0.180090, Val Acc: 0.659794\n",
      "Epoch 5415 - Train Loss: 0.168790, Train Acc: 0.678205 | Val Loss: 0.180077, Val Acc: 0.659794\n",
      "Epoch 5416 - Train Loss: 0.168775, Train Acc: 0.678205 | Val Loss: 0.180064, Val Acc: 0.659794\n",
      "Epoch 5417 - Train Loss: 0.168761, Train Acc: 0.678205 | Val Loss: 0.180051, Val Acc: 0.659794\n",
      "Epoch 5418 - Train Loss: 0.168747, Train Acc: 0.678205 | Val Loss: 0.180038, Val Acc: 0.659794\n",
      "Epoch 5419 - Train Loss: 0.168733, Train Acc: 0.678205 | Val Loss: 0.180025, Val Acc: 0.659794\n",
      "Epoch 5420 - Train Loss: 0.168719, Train Acc: 0.678205 | Val Loss: 0.180011, Val Acc: 0.659794\n",
      "Epoch 5421 - Train Loss: 0.168705, Train Acc: 0.678205 | Val Loss: 0.179998, Val Acc: 0.659794\n",
      "Epoch 5422 - Train Loss: 0.168690, Train Acc: 0.678205 | Val Loss: 0.179985, Val Acc: 0.659794\n",
      "Epoch 5423 - Train Loss: 0.168676, Train Acc: 0.678205 | Val Loss: 0.179972, Val Acc: 0.659794\n",
      "Epoch 5424 - Train Loss: 0.168662, Train Acc: 0.678205 | Val Loss: 0.179959, Val Acc: 0.659794\n",
      "Epoch 5425 - Train Loss: 0.168648, Train Acc: 0.678205 | Val Loss: 0.179946, Val Acc: 0.659794\n",
      "Epoch 5426 - Train Loss: 0.168634, Train Acc: 0.678205 | Val Loss: 0.179933, Val Acc: 0.659794\n",
      "Epoch 5427 - Train Loss: 0.168620, Train Acc: 0.678205 | Val Loss: 0.179920, Val Acc: 0.659794\n",
      "Epoch 5428 - Train Loss: 0.168606, Train Acc: 0.678205 | Val Loss: 0.179907, Val Acc: 0.659794\n",
      "Epoch 5429 - Train Loss: 0.168591, Train Acc: 0.678205 | Val Loss: 0.179894, Val Acc: 0.659794\n",
      "Epoch 5430 - Train Loss: 0.168577, Train Acc: 0.678205 | Val Loss: 0.179881, Val Acc: 0.659794\n",
      "Epoch 5431 - Train Loss: 0.168563, Train Acc: 0.678205 | Val Loss: 0.179868, Val Acc: 0.659794\n",
      "Epoch 5432 - Train Loss: 0.168549, Train Acc: 0.678205 | Val Loss: 0.179854, Val Acc: 0.659794\n",
      "Epoch 5433 - Train Loss: 0.168535, Train Acc: 0.678205 | Val Loss: 0.179841, Val Acc: 0.659794\n",
      "Epoch 5434 - Train Loss: 0.168521, Train Acc: 0.678205 | Val Loss: 0.179828, Val Acc: 0.659794\n",
      "Epoch 5435 - Train Loss: 0.168507, Train Acc: 0.678205 | Val Loss: 0.179815, Val Acc: 0.659794\n",
      "Epoch 5436 - Train Loss: 0.168493, Train Acc: 0.678205 | Val Loss: 0.179802, Val Acc: 0.659794\n",
      "Epoch 5437 - Train Loss: 0.168478, Train Acc: 0.678205 | Val Loss: 0.179789, Val Acc: 0.659794\n",
      "Epoch 5438 - Train Loss: 0.168464, Train Acc: 0.678205 | Val Loss: 0.179776, Val Acc: 0.659794\n",
      "Epoch 5439 - Train Loss: 0.168450, Train Acc: 0.678205 | Val Loss: 0.179763, Val Acc: 0.659794\n",
      "Epoch 5440 - Train Loss: 0.168436, Train Acc: 0.678205 | Val Loss: 0.179750, Val Acc: 0.659794\n",
      "Epoch 5441 - Train Loss: 0.168422, Train Acc: 0.678205 | Val Loss: 0.179737, Val Acc: 0.659794\n",
      "Epoch 5442 - Train Loss: 0.168408, Train Acc: 0.678205 | Val Loss: 0.179724, Val Acc: 0.659794\n",
      "Epoch 5443 - Train Loss: 0.168394, Train Acc: 0.678205 | Val Loss: 0.179711, Val Acc: 0.659794\n",
      "Epoch 5444 - Train Loss: 0.168380, Train Acc: 0.679487 | Val Loss: 0.179698, Val Acc: 0.659794\n",
      "Epoch 5445 - Train Loss: 0.168366, Train Acc: 0.679487 | Val Loss: 0.179685, Val Acc: 0.659794\n",
      "Epoch 5446 - Train Loss: 0.168351, Train Acc: 0.679487 | Val Loss: 0.179672, Val Acc: 0.659794\n",
      "Epoch 5447 - Train Loss: 0.168337, Train Acc: 0.679487 | Val Loss: 0.179659, Val Acc: 0.659794\n",
      "Epoch 5448 - Train Loss: 0.168323, Train Acc: 0.678205 | Val Loss: 0.179646, Val Acc: 0.659794\n",
      "Epoch 5449 - Train Loss: 0.168309, Train Acc: 0.678205 | Val Loss: 0.179633, Val Acc: 0.659794\n",
      "Epoch 5450 - Train Loss: 0.168295, Train Acc: 0.678205 | Val Loss: 0.179620, Val Acc: 0.659794\n",
      "Epoch 5451 - Train Loss: 0.168281, Train Acc: 0.678205 | Val Loss: 0.179606, Val Acc: 0.659794\n",
      "Epoch 5452 - Train Loss: 0.168267, Train Acc: 0.678205 | Val Loss: 0.179593, Val Acc: 0.659794\n",
      "Epoch 5453 - Train Loss: 0.168253, Train Acc: 0.678205 | Val Loss: 0.179580, Val Acc: 0.659794\n",
      "Epoch 5454 - Train Loss: 0.168239, Train Acc: 0.678205 | Val Loss: 0.179567, Val Acc: 0.659794\n",
      "Epoch 5455 - Train Loss: 0.168225, Train Acc: 0.678205 | Val Loss: 0.179554, Val Acc: 0.659794\n",
      "Epoch 5456 - Train Loss: 0.168210, Train Acc: 0.678205 | Val Loss: 0.179541, Val Acc: 0.659794\n",
      "Epoch 5457 - Train Loss: 0.168196, Train Acc: 0.678205 | Val Loss: 0.179528, Val Acc: 0.659794\n",
      "Epoch 5458 - Train Loss: 0.168182, Train Acc: 0.679487 | Val Loss: 0.179515, Val Acc: 0.659794\n",
      "Epoch 5459 - Train Loss: 0.168168, Train Acc: 0.679487 | Val Loss: 0.179502, Val Acc: 0.659794\n",
      "Epoch 5460 - Train Loss: 0.168154, Train Acc: 0.679487 | Val Loss: 0.179489, Val Acc: 0.659794\n",
      "Epoch 5461 - Train Loss: 0.168140, Train Acc: 0.679487 | Val Loss: 0.179476, Val Acc: 0.659794\n",
      "Epoch 5462 - Train Loss: 0.168126, Train Acc: 0.679487 | Val Loss: 0.179463, Val Acc: 0.659794\n",
      "Epoch 5463 - Train Loss: 0.168112, Train Acc: 0.679487 | Val Loss: 0.179450, Val Acc: 0.659794\n",
      "Epoch 5464 - Train Loss: 0.168098, Train Acc: 0.679487 | Val Loss: 0.179437, Val Acc: 0.659794\n",
      "Epoch 5465 - Train Loss: 0.168084, Train Acc: 0.679487 | Val Loss: 0.179424, Val Acc: 0.659794\n",
      "Epoch 5466 - Train Loss: 0.168070, Train Acc: 0.679487 | Val Loss: 0.179411, Val Acc: 0.659794\n",
      "Epoch 5467 - Train Loss: 0.168056, Train Acc: 0.679487 | Val Loss: 0.179398, Val Acc: 0.659794\n",
      "Epoch 5468 - Train Loss: 0.168041, Train Acc: 0.679487 | Val Loss: 0.179385, Val Acc: 0.659794\n",
      "Epoch 5469 - Train Loss: 0.168027, Train Acc: 0.679487 | Val Loss: 0.179372, Val Acc: 0.659794\n",
      "Epoch 5470 - Train Loss: 0.168013, Train Acc: 0.679487 | Val Loss: 0.179359, Val Acc: 0.659794\n",
      "Epoch 5471 - Train Loss: 0.167999, Train Acc: 0.679487 | Val Loss: 0.179346, Val Acc: 0.659794\n",
      "Epoch 5472 - Train Loss: 0.167985, Train Acc: 0.679487 | Val Loss: 0.179333, Val Acc: 0.659794\n",
      "Epoch 5473 - Train Loss: 0.167971, Train Acc: 0.679487 | Val Loss: 0.179320, Val Acc: 0.659794\n",
      "Epoch 5474 - Train Loss: 0.167957, Train Acc: 0.679487 | Val Loss: 0.179307, Val Acc: 0.659794\n",
      "Epoch 5475 - Train Loss: 0.167943, Train Acc: 0.679487 | Val Loss: 0.179294, Val Acc: 0.659794\n",
      "Epoch 5476 - Train Loss: 0.167929, Train Acc: 0.679487 | Val Loss: 0.179281, Val Acc: 0.659794\n",
      "Epoch 5477 - Train Loss: 0.167915, Train Acc: 0.679487 | Val Loss: 0.179268, Val Acc: 0.659794\n",
      "Epoch 5478 - Train Loss: 0.167901, Train Acc: 0.679487 | Val Loss: 0.179255, Val Acc: 0.659794\n",
      "Epoch 5479 - Train Loss: 0.167887, Train Acc: 0.679487 | Val Loss: 0.179242, Val Acc: 0.659794\n",
      "Epoch 5480 - Train Loss: 0.167873, Train Acc: 0.679487 | Val Loss: 0.179229, Val Acc: 0.659794\n",
      "Epoch 5481 - Train Loss: 0.167859, Train Acc: 0.679487 | Val Loss: 0.179216, Val Acc: 0.659794\n",
      "Epoch 5482 - Train Loss: 0.167845, Train Acc: 0.679487 | Val Loss: 0.179203, Val Acc: 0.659794\n",
      "Epoch 5483 - Train Loss: 0.167831, Train Acc: 0.679487 | Val Loss: 0.179190, Val Acc: 0.659794\n",
      "Epoch 5484 - Train Loss: 0.167817, Train Acc: 0.679487 | Val Loss: 0.179177, Val Acc: 0.659794\n",
      "Epoch 5485 - Train Loss: 0.167802, Train Acc: 0.679487 | Val Loss: 0.179164, Val Acc: 0.659794\n",
      "Epoch 5486 - Train Loss: 0.167788, Train Acc: 0.679487 | Val Loss: 0.179151, Val Acc: 0.659794\n",
      "Epoch 5487 - Train Loss: 0.167774, Train Acc: 0.679487 | Val Loss: 0.179138, Val Acc: 0.659794\n",
      "Epoch 5488 - Train Loss: 0.167760, Train Acc: 0.679487 | Val Loss: 0.179125, Val Acc: 0.659794\n",
      "Epoch 5489 - Train Loss: 0.167746, Train Acc: 0.680769 | Val Loss: 0.179112, Val Acc: 0.659794\n",
      "Epoch 5490 - Train Loss: 0.167732, Train Acc: 0.680769 | Val Loss: 0.179100, Val Acc: 0.659794\n",
      "Epoch 5491 - Train Loss: 0.167718, Train Acc: 0.680769 | Val Loss: 0.179087, Val Acc: 0.659794\n",
      "Epoch 5492 - Train Loss: 0.167704, Train Acc: 0.680769 | Val Loss: 0.179074, Val Acc: 0.659794\n",
      "Epoch 5493 - Train Loss: 0.167690, Train Acc: 0.680769 | Val Loss: 0.179061, Val Acc: 0.659794\n",
      "Epoch 5494 - Train Loss: 0.167676, Train Acc: 0.680769 | Val Loss: 0.179048, Val Acc: 0.659794\n",
      "Epoch 5495 - Train Loss: 0.167662, Train Acc: 0.680769 | Val Loss: 0.179035, Val Acc: 0.659794\n",
      "Epoch 5496 - Train Loss: 0.167648, Train Acc: 0.680769 | Val Loss: 0.179022, Val Acc: 0.659794\n",
      "Epoch 5497 - Train Loss: 0.167634, Train Acc: 0.680769 | Val Loss: 0.179009, Val Acc: 0.659794\n",
      "Epoch 5498 - Train Loss: 0.167620, Train Acc: 0.680769 | Val Loss: 0.178996, Val Acc: 0.659794\n",
      "Epoch 5499 - Train Loss: 0.167606, Train Acc: 0.680769 | Val Loss: 0.178983, Val Acc: 0.659794\n",
      "Epoch 5500 - Train Loss: 0.167592, Train Acc: 0.680769 | Val Loss: 0.178970, Val Acc: 0.659794\n",
      "Epoch 5501 - Train Loss: 0.167578, Train Acc: 0.680769 | Val Loss: 0.178957, Val Acc: 0.659794\n",
      "Epoch 5502 - Train Loss: 0.167564, Train Acc: 0.680769 | Val Loss: 0.178944, Val Acc: 0.659794\n",
      "Epoch 5503 - Train Loss: 0.167550, Train Acc: 0.680769 | Val Loss: 0.178931, Val Acc: 0.659794\n",
      "Epoch 5504 - Train Loss: 0.167536, Train Acc: 0.680769 | Val Loss: 0.178918, Val Acc: 0.659794\n",
      "Epoch 5505 - Train Loss: 0.167522, Train Acc: 0.680769 | Val Loss: 0.178905, Val Acc: 0.659794\n",
      "Epoch 5506 - Train Loss: 0.167508, Train Acc: 0.680769 | Val Loss: 0.178892, Val Acc: 0.659794\n",
      "Epoch 5507 - Train Loss: 0.167494, Train Acc: 0.680769 | Val Loss: 0.178879, Val Acc: 0.659794\n",
      "Epoch 5508 - Train Loss: 0.167480, Train Acc: 0.680769 | Val Loss: 0.178866, Val Acc: 0.659794\n",
      "Epoch 5509 - Train Loss: 0.167466, Train Acc: 0.680769 | Val Loss: 0.178854, Val Acc: 0.659794\n",
      "Epoch 5510 - Train Loss: 0.167452, Train Acc: 0.680769 | Val Loss: 0.178841, Val Acc: 0.659794\n",
      "Epoch 5511 - Train Loss: 0.167438, Train Acc: 0.680769 | Val Loss: 0.178828, Val Acc: 0.659794\n",
      "Epoch 5512 - Train Loss: 0.167424, Train Acc: 0.680769 | Val Loss: 0.178815, Val Acc: 0.659794\n",
      "Epoch 5513 - Train Loss: 0.167410, Train Acc: 0.680769 | Val Loss: 0.178802, Val Acc: 0.659794\n",
      "Epoch 5514 - Train Loss: 0.167396, Train Acc: 0.680769 | Val Loss: 0.178789, Val Acc: 0.659794\n",
      "Epoch 5515 - Train Loss: 0.167382, Train Acc: 0.680769 | Val Loss: 0.178776, Val Acc: 0.659794\n",
      "Epoch 5516 - Train Loss: 0.167368, Train Acc: 0.680769 | Val Loss: 0.178763, Val Acc: 0.659794\n",
      "Epoch 5517 - Train Loss: 0.167354, Train Acc: 0.680769 | Val Loss: 0.178750, Val Acc: 0.659794\n",
      "Epoch 5518 - Train Loss: 0.167340, Train Acc: 0.680769 | Val Loss: 0.178737, Val Acc: 0.659794\n",
      "Epoch 5519 - Train Loss: 0.167326, Train Acc: 0.680769 | Val Loss: 0.178724, Val Acc: 0.659794\n",
      "Epoch 5520 - Train Loss: 0.167312, Train Acc: 0.680769 | Val Loss: 0.178711, Val Acc: 0.659794\n",
      "Epoch 5521 - Train Loss: 0.167298, Train Acc: 0.680769 | Val Loss: 0.178699, Val Acc: 0.659794\n",
      "Epoch 5522 - Train Loss: 0.167284, Train Acc: 0.680769 | Val Loss: 0.178686, Val Acc: 0.659794\n",
      "Epoch 5523 - Train Loss: 0.167270, Train Acc: 0.680769 | Val Loss: 0.178673, Val Acc: 0.659794\n",
      "Epoch 5524 - Train Loss: 0.167256, Train Acc: 0.680769 | Val Loss: 0.178660, Val Acc: 0.659794\n",
      "Epoch 5525 - Train Loss: 0.167242, Train Acc: 0.680769 | Val Loss: 0.178647, Val Acc: 0.659794\n",
      "Epoch 5526 - Train Loss: 0.167228, Train Acc: 0.680769 | Val Loss: 0.178634, Val Acc: 0.659794\n",
      "Epoch 5527 - Train Loss: 0.167214, Train Acc: 0.680769 | Val Loss: 0.178621, Val Acc: 0.659794\n",
      "Epoch 5528 - Train Loss: 0.167200, Train Acc: 0.680769 | Val Loss: 0.178608, Val Acc: 0.659794\n",
      "Epoch 5529 - Train Loss: 0.167186, Train Acc: 0.680769 | Val Loss: 0.178595, Val Acc: 0.659794\n",
      "Epoch 5530 - Train Loss: 0.167172, Train Acc: 0.680769 | Val Loss: 0.178583, Val Acc: 0.659794\n",
      "Epoch 5531 - Train Loss: 0.167158, Train Acc: 0.682051 | Val Loss: 0.178570, Val Acc: 0.659794\n",
      "Epoch 5532 - Train Loss: 0.167144, Train Acc: 0.682051 | Val Loss: 0.178557, Val Acc: 0.659794\n",
      "Epoch 5533 - Train Loss: 0.167130, Train Acc: 0.682051 | Val Loss: 0.178544, Val Acc: 0.659794\n",
      "Epoch 5534 - Train Loss: 0.167116, Train Acc: 0.682051 | Val Loss: 0.178531, Val Acc: 0.659794\n",
      "Epoch 5535 - Train Loss: 0.167102, Train Acc: 0.683333 | Val Loss: 0.178518, Val Acc: 0.659794\n",
      "Epoch 5536 - Train Loss: 0.167088, Train Acc: 0.683333 | Val Loss: 0.178505, Val Acc: 0.659794\n",
      "Epoch 5537 - Train Loss: 0.167075, Train Acc: 0.684615 | Val Loss: 0.178492, Val Acc: 0.659794\n",
      "Epoch 5538 - Train Loss: 0.167061, Train Acc: 0.684615 | Val Loss: 0.178479, Val Acc: 0.659794\n",
      "Epoch 5539 - Train Loss: 0.167047, Train Acc: 0.684615 | Val Loss: 0.178467, Val Acc: 0.659794\n",
      "Epoch 5540 - Train Loss: 0.167033, Train Acc: 0.684615 | Val Loss: 0.178454, Val Acc: 0.659794\n",
      "Epoch 5541 - Train Loss: 0.167019, Train Acc: 0.684615 | Val Loss: 0.178441, Val Acc: 0.659794\n",
      "Epoch 5542 - Train Loss: 0.167005, Train Acc: 0.684615 | Val Loss: 0.178428, Val Acc: 0.659794\n",
      "Epoch 5543 - Train Loss: 0.166991, Train Acc: 0.684615 | Val Loss: 0.178415, Val Acc: 0.659794\n",
      "Epoch 5544 - Train Loss: 0.166977, Train Acc: 0.684615 | Val Loss: 0.178402, Val Acc: 0.659794\n",
      "Epoch 5545 - Train Loss: 0.166963, Train Acc: 0.684615 | Val Loss: 0.178389, Val Acc: 0.659794\n",
      "Epoch 5546 - Train Loss: 0.166949, Train Acc: 0.684615 | Val Loss: 0.178377, Val Acc: 0.659794\n",
      "Epoch 5547 - Train Loss: 0.166935, Train Acc: 0.684615 | Val Loss: 0.178364, Val Acc: 0.659794\n",
      "Epoch 5548 - Train Loss: 0.166921, Train Acc: 0.684615 | Val Loss: 0.178351, Val Acc: 0.659794\n",
      "Epoch 5549 - Train Loss: 0.166907, Train Acc: 0.684615 | Val Loss: 0.178338, Val Acc: 0.659794\n",
      "Epoch 5550 - Train Loss: 0.166893, Train Acc: 0.684615 | Val Loss: 0.178325, Val Acc: 0.659794\n",
      "Epoch 5551 - Train Loss: 0.166879, Train Acc: 0.684615 | Val Loss: 0.178312, Val Acc: 0.659794\n",
      "Epoch 5552 - Train Loss: 0.166865, Train Acc: 0.684615 | Val Loss: 0.178299, Val Acc: 0.659794\n",
      "Epoch 5553 - Train Loss: 0.166851, Train Acc: 0.684615 | Val Loss: 0.178287, Val Acc: 0.659794\n",
      "Epoch 5554 - Train Loss: 0.166837, Train Acc: 0.684615 | Val Loss: 0.178274, Val Acc: 0.659794\n",
      "Epoch 5555 - Train Loss: 0.166823, Train Acc: 0.684615 | Val Loss: 0.178261, Val Acc: 0.659794\n",
      "Epoch 5556 - Train Loss: 0.166810, Train Acc: 0.684615 | Val Loss: 0.178248, Val Acc: 0.659794\n",
      "Epoch 5557 - Train Loss: 0.166796, Train Acc: 0.684615 | Val Loss: 0.178235, Val Acc: 0.659794\n",
      "Epoch 5558 - Train Loss: 0.166782, Train Acc: 0.684615 | Val Loss: 0.178222, Val Acc: 0.659794\n",
      "Epoch 5559 - Train Loss: 0.166768, Train Acc: 0.684615 | Val Loss: 0.178210, Val Acc: 0.659794\n",
      "Epoch 5560 - Train Loss: 0.166754, Train Acc: 0.684615 | Val Loss: 0.178197, Val Acc: 0.659794\n",
      "Epoch 5561 - Train Loss: 0.166740, Train Acc: 0.684615 | Val Loss: 0.178184, Val Acc: 0.659794\n",
      "Epoch 5562 - Train Loss: 0.166726, Train Acc: 0.684615 | Val Loss: 0.178171, Val Acc: 0.659794\n",
      "Epoch 5563 - Train Loss: 0.166712, Train Acc: 0.684615 | Val Loss: 0.178158, Val Acc: 0.659794\n",
      "Epoch 5564 - Train Loss: 0.166698, Train Acc: 0.684615 | Val Loss: 0.178145, Val Acc: 0.659794\n",
      "Epoch 5565 - Train Loss: 0.166684, Train Acc: 0.684615 | Val Loss: 0.178133, Val Acc: 0.659794\n",
      "Epoch 5566 - Train Loss: 0.166670, Train Acc: 0.684615 | Val Loss: 0.178120, Val Acc: 0.659794\n",
      "Epoch 5567 - Train Loss: 0.166656, Train Acc: 0.684615 | Val Loss: 0.178107, Val Acc: 0.659794\n",
      "Epoch 5568 - Train Loss: 0.166643, Train Acc: 0.685897 | Val Loss: 0.178094, Val Acc: 0.659794\n",
      "Epoch 5569 - Train Loss: 0.166629, Train Acc: 0.685897 | Val Loss: 0.178081, Val Acc: 0.659794\n",
      "Epoch 5570 - Train Loss: 0.166615, Train Acc: 0.685897 | Val Loss: 0.178069, Val Acc: 0.659794\n",
      "Epoch 5571 - Train Loss: 0.166601, Train Acc: 0.685897 | Val Loss: 0.178056, Val Acc: 0.659794\n",
      "Epoch 5572 - Train Loss: 0.166587, Train Acc: 0.685897 | Val Loss: 0.178043, Val Acc: 0.659794\n",
      "Epoch 5573 - Train Loss: 0.166573, Train Acc: 0.685897 | Val Loss: 0.178030, Val Acc: 0.659794\n",
      "Epoch 5574 - Train Loss: 0.166559, Train Acc: 0.685897 | Val Loss: 0.178017, Val Acc: 0.659794\n",
      "Epoch 5575 - Train Loss: 0.166545, Train Acc: 0.685897 | Val Loss: 0.178005, Val Acc: 0.659794\n",
      "Epoch 5576 - Train Loss: 0.166531, Train Acc: 0.685897 | Val Loss: 0.177992, Val Acc: 0.659794\n",
      "Epoch 5577 - Train Loss: 0.166517, Train Acc: 0.685897 | Val Loss: 0.177979, Val Acc: 0.659794\n",
      "Epoch 5578 - Train Loss: 0.166504, Train Acc: 0.685897 | Val Loss: 0.177966, Val Acc: 0.659794\n",
      "Epoch 5579 - Train Loss: 0.166490, Train Acc: 0.685897 | Val Loss: 0.177953, Val Acc: 0.659794\n",
      "Epoch 5580 - Train Loss: 0.166476, Train Acc: 0.685897 | Val Loss: 0.177940, Val Acc: 0.659794\n",
      "Epoch 5581 - Train Loss: 0.166462, Train Acc: 0.685897 | Val Loss: 0.177928, Val Acc: 0.659794\n",
      "Epoch 5582 - Train Loss: 0.166448, Train Acc: 0.685897 | Val Loss: 0.177915, Val Acc: 0.659794\n",
      "Epoch 5583 - Train Loss: 0.166434, Train Acc: 0.685897 | Val Loss: 0.177902, Val Acc: 0.659794\n",
      "Epoch 5584 - Train Loss: 0.166420, Train Acc: 0.685897 | Val Loss: 0.177889, Val Acc: 0.659794\n",
      "Epoch 5585 - Train Loss: 0.166406, Train Acc: 0.687179 | Val Loss: 0.177877, Val Acc: 0.659794\n",
      "Epoch 5586 - Train Loss: 0.166392, Train Acc: 0.687179 | Val Loss: 0.177864, Val Acc: 0.659794\n",
      "Epoch 5587 - Train Loss: 0.166379, Train Acc: 0.687179 | Val Loss: 0.177851, Val Acc: 0.659794\n",
      "Epoch 5588 - Train Loss: 0.166365, Train Acc: 0.687179 | Val Loss: 0.177838, Val Acc: 0.659794\n",
      "Epoch 5589 - Train Loss: 0.166351, Train Acc: 0.687179 | Val Loss: 0.177825, Val Acc: 0.659794\n",
      "Epoch 5590 - Train Loss: 0.166337, Train Acc: 0.687179 | Val Loss: 0.177813, Val Acc: 0.659794\n",
      "Epoch 5591 - Train Loss: 0.166323, Train Acc: 0.687179 | Val Loss: 0.177800, Val Acc: 0.659794\n",
      "Epoch 5592 - Train Loss: 0.166309, Train Acc: 0.687179 | Val Loss: 0.177787, Val Acc: 0.659794\n",
      "Epoch 5593 - Train Loss: 0.166295, Train Acc: 0.687179 | Val Loss: 0.177774, Val Acc: 0.659794\n",
      "Epoch 5594 - Train Loss: 0.166282, Train Acc: 0.687179 | Val Loss: 0.177762, Val Acc: 0.659794\n",
      "Epoch 5595 - Train Loss: 0.166268, Train Acc: 0.687179 | Val Loss: 0.177749, Val Acc: 0.659794\n",
      "Epoch 5596 - Train Loss: 0.166254, Train Acc: 0.687179 | Val Loss: 0.177736, Val Acc: 0.659794\n",
      "Epoch 5597 - Train Loss: 0.166240, Train Acc: 0.687179 | Val Loss: 0.177723, Val Acc: 0.659794\n",
      "Epoch 5598 - Train Loss: 0.166226, Train Acc: 0.688462 | Val Loss: 0.177710, Val Acc: 0.659794\n",
      "Epoch 5599 - Train Loss: 0.166212, Train Acc: 0.688462 | Val Loss: 0.177698, Val Acc: 0.659794\n",
      "Epoch 5600 - Train Loss: 0.166198, Train Acc: 0.688462 | Val Loss: 0.177685, Val Acc: 0.659794\n",
      "Epoch 5601 - Train Loss: 0.166185, Train Acc: 0.688462 | Val Loss: 0.177672, Val Acc: 0.659794\n",
      "Epoch 5602 - Train Loss: 0.166171, Train Acc: 0.688462 | Val Loss: 0.177659, Val Acc: 0.659794\n",
      "Epoch 5603 - Train Loss: 0.166157, Train Acc: 0.688462 | Val Loss: 0.177647, Val Acc: 0.659794\n",
      "Epoch 5604 - Train Loss: 0.166143, Train Acc: 0.688462 | Val Loss: 0.177634, Val Acc: 0.659794\n",
      "Epoch 5605 - Train Loss: 0.166129, Train Acc: 0.688462 | Val Loss: 0.177621, Val Acc: 0.659794\n",
      "Epoch 5606 - Train Loss: 0.166115, Train Acc: 0.688462 | Val Loss: 0.177608, Val Acc: 0.659794\n",
      "Epoch 5607 - Train Loss: 0.166101, Train Acc: 0.688462 | Val Loss: 0.177596, Val Acc: 0.659794\n",
      "Epoch 5608 - Train Loss: 0.166088, Train Acc: 0.688462 | Val Loss: 0.177583, Val Acc: 0.659794\n",
      "Epoch 5609 - Train Loss: 0.166074, Train Acc: 0.688462 | Val Loss: 0.177570, Val Acc: 0.659794\n",
      "Epoch 5610 - Train Loss: 0.166060, Train Acc: 0.688462 | Val Loss: 0.177557, Val Acc: 0.659794\n",
      "Epoch 5611 - Train Loss: 0.166046, Train Acc: 0.688462 | Val Loss: 0.177545, Val Acc: 0.659794\n",
      "Epoch 5612 - Train Loss: 0.166032, Train Acc: 0.688462 | Val Loss: 0.177532, Val Acc: 0.659794\n",
      "Epoch 5613 - Train Loss: 0.166018, Train Acc: 0.688462 | Val Loss: 0.177519, Val Acc: 0.659794\n",
      "Epoch 5614 - Train Loss: 0.166005, Train Acc: 0.688462 | Val Loss: 0.177506, Val Acc: 0.659794\n",
      "Epoch 5615 - Train Loss: 0.165991, Train Acc: 0.688462 | Val Loss: 0.177494, Val Acc: 0.659794\n",
      "Epoch 5616 - Train Loss: 0.165977, Train Acc: 0.688462 | Val Loss: 0.177481, Val Acc: 0.659794\n",
      "Epoch 5617 - Train Loss: 0.165963, Train Acc: 0.688462 | Val Loss: 0.177468, Val Acc: 0.659794\n",
      "Epoch 5618 - Train Loss: 0.165949, Train Acc: 0.688462 | Val Loss: 0.177455, Val Acc: 0.659794\n",
      "Epoch 5619 - Train Loss: 0.165935, Train Acc: 0.688462 | Val Loss: 0.177443, Val Acc: 0.659794\n",
      "Epoch 5620 - Train Loss: 0.165922, Train Acc: 0.688462 | Val Loss: 0.177430, Val Acc: 0.659794\n",
      "Epoch 5621 - Train Loss: 0.165908, Train Acc: 0.688462 | Val Loss: 0.177417, Val Acc: 0.659794\n",
      "Epoch 5622 - Train Loss: 0.165894, Train Acc: 0.688462 | Val Loss: 0.177405, Val Acc: 0.659794\n",
      "Epoch 5623 - Train Loss: 0.165880, Train Acc: 0.688462 | Val Loss: 0.177392, Val Acc: 0.659794\n",
      "Epoch 5624 - Train Loss: 0.165866, Train Acc: 0.688462 | Val Loss: 0.177379, Val Acc: 0.659794\n",
      "Epoch 5625 - Train Loss: 0.165853, Train Acc: 0.688462 | Val Loss: 0.177366, Val Acc: 0.659794\n",
      "Epoch 5626 - Train Loss: 0.165839, Train Acc: 0.688462 | Val Loss: 0.177354, Val Acc: 0.659794\n",
      "Epoch 5627 - Train Loss: 0.165825, Train Acc: 0.688462 | Val Loss: 0.177341, Val Acc: 0.659794\n",
      "Epoch 5628 - Train Loss: 0.165811, Train Acc: 0.688462 | Val Loss: 0.177328, Val Acc: 0.659794\n",
      "Epoch 5629 - Train Loss: 0.165797, Train Acc: 0.688462 | Val Loss: 0.177315, Val Acc: 0.659794\n",
      "Epoch 5630 - Train Loss: 0.165783, Train Acc: 0.688462 | Val Loss: 0.177303, Val Acc: 0.659794\n",
      "Epoch 5631 - Train Loss: 0.165770, Train Acc: 0.688462 | Val Loss: 0.177290, Val Acc: 0.659794\n",
      "Epoch 5632 - Train Loss: 0.165756, Train Acc: 0.688462 | Val Loss: 0.177277, Val Acc: 0.659794\n",
      "Epoch 5633 - Train Loss: 0.165742, Train Acc: 0.688462 | Val Loss: 0.177265, Val Acc: 0.659794\n",
      "Epoch 5634 - Train Loss: 0.165728, Train Acc: 0.688462 | Val Loss: 0.177252, Val Acc: 0.659794\n",
      "Epoch 5635 - Train Loss: 0.165714, Train Acc: 0.688462 | Val Loss: 0.177239, Val Acc: 0.659794\n",
      "Epoch 5636 - Train Loss: 0.165701, Train Acc: 0.688462 | Val Loss: 0.177226, Val Acc: 0.659794\n",
      "Epoch 5637 - Train Loss: 0.165687, Train Acc: 0.688462 | Val Loss: 0.177214, Val Acc: 0.659794\n",
      "Epoch 5638 - Train Loss: 0.165673, Train Acc: 0.688462 | Val Loss: 0.177201, Val Acc: 0.659794\n",
      "Epoch 5639 - Train Loss: 0.165659, Train Acc: 0.688462 | Val Loss: 0.177188, Val Acc: 0.659794\n",
      "Epoch 5640 - Train Loss: 0.165645, Train Acc: 0.688462 | Val Loss: 0.177176, Val Acc: 0.659794\n",
      "Epoch 5641 - Train Loss: 0.165632, Train Acc: 0.688462 | Val Loss: 0.177163, Val Acc: 0.659794\n",
      "Epoch 5642 - Train Loss: 0.165618, Train Acc: 0.688462 | Val Loss: 0.177150, Val Acc: 0.659794\n",
      "Epoch 5643 - Train Loss: 0.165604, Train Acc: 0.688462 | Val Loss: 0.177138, Val Acc: 0.659794\n",
      "Epoch 5644 - Train Loss: 0.165590, Train Acc: 0.688462 | Val Loss: 0.177125, Val Acc: 0.659794\n",
      "Epoch 5645 - Train Loss: 0.165577, Train Acc: 0.688462 | Val Loss: 0.177112, Val Acc: 0.659794\n",
      "Epoch 5646 - Train Loss: 0.165563, Train Acc: 0.688462 | Val Loss: 0.177100, Val Acc: 0.659794\n",
      "Epoch 5647 - Train Loss: 0.165549, Train Acc: 0.688462 | Val Loss: 0.177087, Val Acc: 0.659794\n",
      "Epoch 5648 - Train Loss: 0.165535, Train Acc: 0.688462 | Val Loss: 0.177074, Val Acc: 0.659794\n",
      "Epoch 5649 - Train Loss: 0.165521, Train Acc: 0.688462 | Val Loss: 0.177061, Val Acc: 0.659794\n",
      "Epoch 5650 - Train Loss: 0.165508, Train Acc: 0.688462 | Val Loss: 0.177049, Val Acc: 0.659794\n",
      "Epoch 5651 - Train Loss: 0.165494, Train Acc: 0.688462 | Val Loss: 0.177036, Val Acc: 0.659794\n",
      "Epoch 5652 - Train Loss: 0.165480, Train Acc: 0.688462 | Val Loss: 0.177023, Val Acc: 0.659794\n",
      "Epoch 5653 - Train Loss: 0.165466, Train Acc: 0.688462 | Val Loss: 0.177011, Val Acc: 0.659794\n",
      "Epoch 5654 - Train Loss: 0.165453, Train Acc: 0.688462 | Val Loss: 0.176998, Val Acc: 0.659794\n",
      "Epoch 5655 - Train Loss: 0.165439, Train Acc: 0.688462 | Val Loss: 0.176985, Val Acc: 0.659794\n",
      "Epoch 5656 - Train Loss: 0.165425, Train Acc: 0.689744 | Val Loss: 0.176973, Val Acc: 0.659794\n",
      "Epoch 5657 - Train Loss: 0.165411, Train Acc: 0.689744 | Val Loss: 0.176960, Val Acc: 0.659794\n",
      "Epoch 5658 - Train Loss: 0.165397, Train Acc: 0.689744 | Val Loss: 0.176947, Val Acc: 0.659794\n",
      "Epoch 5659 - Train Loss: 0.165384, Train Acc: 0.689744 | Val Loss: 0.176935, Val Acc: 0.659794\n",
      "Epoch 5660 - Train Loss: 0.165370, Train Acc: 0.689744 | Val Loss: 0.176922, Val Acc: 0.659794\n",
      "Epoch 5661 - Train Loss: 0.165356, Train Acc: 0.689744 | Val Loss: 0.176909, Val Acc: 0.659794\n",
      "Epoch 5662 - Train Loss: 0.165342, Train Acc: 0.689744 | Val Loss: 0.176897, Val Acc: 0.659794\n",
      "Epoch 5663 - Train Loss: 0.165329, Train Acc: 0.689744 | Val Loss: 0.176884, Val Acc: 0.659794\n",
      "Epoch 5664 - Train Loss: 0.165315, Train Acc: 0.689744 | Val Loss: 0.176871, Val Acc: 0.659794\n",
      "Epoch 5665 - Train Loss: 0.165301, Train Acc: 0.689744 | Val Loss: 0.176859, Val Acc: 0.659794\n",
      "Epoch 5666 - Train Loss: 0.165287, Train Acc: 0.689744 | Val Loss: 0.176846, Val Acc: 0.659794\n",
      "Epoch 5667 - Train Loss: 0.165274, Train Acc: 0.689744 | Val Loss: 0.176833, Val Acc: 0.659794\n",
      "Epoch 5668 - Train Loss: 0.165260, Train Acc: 0.689744 | Val Loss: 0.176821, Val Acc: 0.659794\n",
      "Epoch 5669 - Train Loss: 0.165246, Train Acc: 0.689744 | Val Loss: 0.176808, Val Acc: 0.659794\n",
      "Epoch 5670 - Train Loss: 0.165232, Train Acc: 0.689744 | Val Loss: 0.176795, Val Acc: 0.659794\n",
      "Epoch 5671 - Train Loss: 0.165219, Train Acc: 0.689744 | Val Loss: 0.176783, Val Acc: 0.659794\n",
      "Epoch 5672 - Train Loss: 0.165205, Train Acc: 0.689744 | Val Loss: 0.176770, Val Acc: 0.659794\n",
      "Epoch 5673 - Train Loss: 0.165191, Train Acc: 0.689744 | Val Loss: 0.176758, Val Acc: 0.659794\n",
      "Epoch 5674 - Train Loss: 0.165177, Train Acc: 0.689744 | Val Loss: 0.176745, Val Acc: 0.659794\n",
      "Epoch 5675 - Train Loss: 0.165164, Train Acc: 0.689744 | Val Loss: 0.176732, Val Acc: 0.659794\n",
      "Epoch 5676 - Train Loss: 0.165150, Train Acc: 0.689744 | Val Loss: 0.176720, Val Acc: 0.659794\n",
      "Epoch 5677 - Train Loss: 0.165136, Train Acc: 0.689744 | Val Loss: 0.176707, Val Acc: 0.659794\n",
      "Epoch 5678 - Train Loss: 0.165122, Train Acc: 0.689744 | Val Loss: 0.176694, Val Acc: 0.659794\n",
      "Epoch 5679 - Train Loss: 0.165109, Train Acc: 0.689744 | Val Loss: 0.176682, Val Acc: 0.659794\n",
      "Epoch 5680 - Train Loss: 0.165095, Train Acc: 0.689744 | Val Loss: 0.176669, Val Acc: 0.659794\n",
      "Epoch 5681 - Train Loss: 0.165081, Train Acc: 0.689744 | Val Loss: 0.176656, Val Acc: 0.659794\n",
      "Epoch 5682 - Train Loss: 0.165067, Train Acc: 0.689744 | Val Loss: 0.176644, Val Acc: 0.659794\n",
      "Epoch 5683 - Train Loss: 0.165054, Train Acc: 0.689744 | Val Loss: 0.176631, Val Acc: 0.659794\n",
      "Epoch 5684 - Train Loss: 0.165040, Train Acc: 0.689744 | Val Loss: 0.176619, Val Acc: 0.659794\n",
      "Epoch 5685 - Train Loss: 0.165026, Train Acc: 0.689744 | Val Loss: 0.176606, Val Acc: 0.659794\n",
      "Epoch 5686 - Train Loss: 0.165013, Train Acc: 0.689744 | Val Loss: 0.176593, Val Acc: 0.659794\n",
      "Epoch 5687 - Train Loss: 0.164999, Train Acc: 0.689744 | Val Loss: 0.176581, Val Acc: 0.659794\n",
      "Epoch 5688 - Train Loss: 0.164985, Train Acc: 0.689744 | Val Loss: 0.176568, Val Acc: 0.659794\n",
      "Epoch 5689 - Train Loss: 0.164971, Train Acc: 0.689744 | Val Loss: 0.176556, Val Acc: 0.659794\n",
      "Epoch 5690 - Train Loss: 0.164958, Train Acc: 0.689744 | Val Loss: 0.176543, Val Acc: 0.659794\n",
      "Epoch 5691 - Train Loss: 0.164944, Train Acc: 0.689744 | Val Loss: 0.176530, Val Acc: 0.659794\n",
      "Epoch 5692 - Train Loss: 0.164930, Train Acc: 0.689744 | Val Loss: 0.176518, Val Acc: 0.659794\n",
      "Epoch 5693 - Train Loss: 0.164917, Train Acc: 0.689744 | Val Loss: 0.176505, Val Acc: 0.659794\n",
      "Epoch 5694 - Train Loss: 0.164903, Train Acc: 0.689744 | Val Loss: 0.176492, Val Acc: 0.659794\n",
      "Epoch 5695 - Train Loss: 0.164889, Train Acc: 0.689744 | Val Loss: 0.176480, Val Acc: 0.659794\n",
      "Epoch 5696 - Train Loss: 0.164875, Train Acc: 0.689744 | Val Loss: 0.176467, Val Acc: 0.659794\n",
      "Epoch 5697 - Train Loss: 0.164862, Train Acc: 0.689744 | Val Loss: 0.176455, Val Acc: 0.659794\n",
      "Epoch 5698 - Train Loss: 0.164848, Train Acc: 0.689744 | Val Loss: 0.176442, Val Acc: 0.659794\n",
      "Epoch 5699 - Train Loss: 0.164834, Train Acc: 0.689744 | Val Loss: 0.176429, Val Acc: 0.659794\n",
      "Epoch 5700 - Train Loss: 0.164821, Train Acc: 0.689744 | Val Loss: 0.176417, Val Acc: 0.659794\n",
      "Epoch 5701 - Train Loss: 0.164807, Train Acc: 0.689744 | Val Loss: 0.176404, Val Acc: 0.659794\n",
      "Epoch 5702 - Train Loss: 0.164793, Train Acc: 0.689744 | Val Loss: 0.176392, Val Acc: 0.670103\n",
      "Epoch 5703 - Train Loss: 0.164780, Train Acc: 0.689744 | Val Loss: 0.176379, Val Acc: 0.670103\n",
      "Epoch 5704 - Train Loss: 0.164766, Train Acc: 0.689744 | Val Loss: 0.176367, Val Acc: 0.670103\n",
      "Epoch 5705 - Train Loss: 0.164752, Train Acc: 0.689744 | Val Loss: 0.176354, Val Acc: 0.670103\n",
      "Epoch 5706 - Train Loss: 0.164738, Train Acc: 0.689744 | Val Loss: 0.176341, Val Acc: 0.670103\n",
      "Epoch 5707 - Train Loss: 0.164725, Train Acc: 0.689744 | Val Loss: 0.176329, Val Acc: 0.670103\n",
      "Epoch 5708 - Train Loss: 0.164711, Train Acc: 0.689744 | Val Loss: 0.176316, Val Acc: 0.670103\n",
      "Epoch 5709 - Train Loss: 0.164697, Train Acc: 0.689744 | Val Loss: 0.176304, Val Acc: 0.670103\n",
      "Epoch 5710 - Train Loss: 0.164684, Train Acc: 0.689744 | Val Loss: 0.176291, Val Acc: 0.670103\n",
      "Epoch 5711 - Train Loss: 0.164670, Train Acc: 0.689744 | Val Loss: 0.176279, Val Acc: 0.670103\n",
      "Epoch 5712 - Train Loss: 0.164656, Train Acc: 0.689744 | Val Loss: 0.176266, Val Acc: 0.670103\n",
      "Epoch 5713 - Train Loss: 0.164643, Train Acc: 0.689744 | Val Loss: 0.176254, Val Acc: 0.670103\n",
      "Epoch 5714 - Train Loss: 0.164629, Train Acc: 0.689744 | Val Loss: 0.176241, Val Acc: 0.670103\n",
      "Epoch 5715 - Train Loss: 0.164615, Train Acc: 0.689744 | Val Loss: 0.176228, Val Acc: 0.670103\n",
      "Epoch 5716 - Train Loss: 0.164602, Train Acc: 0.689744 | Val Loss: 0.176216, Val Acc: 0.670103\n",
      "Epoch 5717 - Train Loss: 0.164588, Train Acc: 0.689744 | Val Loss: 0.176203, Val Acc: 0.670103\n",
      "Epoch 5718 - Train Loss: 0.164574, Train Acc: 0.689744 | Val Loss: 0.176191, Val Acc: 0.670103\n",
      "Epoch 5719 - Train Loss: 0.164561, Train Acc: 0.689744 | Val Loss: 0.176178, Val Acc: 0.670103\n",
      "Epoch 5720 - Train Loss: 0.164547, Train Acc: 0.689744 | Val Loss: 0.176166, Val Acc: 0.670103\n",
      "Epoch 5721 - Train Loss: 0.164533, Train Acc: 0.689744 | Val Loss: 0.176153, Val Acc: 0.670103\n",
      "Epoch 5722 - Train Loss: 0.164520, Train Acc: 0.689744 | Val Loss: 0.176141, Val Acc: 0.670103\n",
      "Epoch 5723 - Train Loss: 0.164506, Train Acc: 0.689744 | Val Loss: 0.176128, Val Acc: 0.670103\n",
      "Epoch 5724 - Train Loss: 0.164492, Train Acc: 0.689744 | Val Loss: 0.176116, Val Acc: 0.670103\n",
      "Epoch 5725 - Train Loss: 0.164479, Train Acc: 0.689744 | Val Loss: 0.176103, Val Acc: 0.670103\n",
      "Epoch 5726 - Train Loss: 0.164465, Train Acc: 0.689744 | Val Loss: 0.176091, Val Acc: 0.670103\n",
      "Epoch 5727 - Train Loss: 0.164451, Train Acc: 0.689744 | Val Loss: 0.176078, Val Acc: 0.670103\n",
      "Epoch 5728 - Train Loss: 0.164438, Train Acc: 0.689744 | Val Loss: 0.176065, Val Acc: 0.670103\n",
      "Epoch 5729 - Train Loss: 0.164424, Train Acc: 0.689744 | Val Loss: 0.176053, Val Acc: 0.670103\n",
      "Epoch 5730 - Train Loss: 0.164410, Train Acc: 0.689744 | Val Loss: 0.176040, Val Acc: 0.670103\n",
      "Epoch 5731 - Train Loss: 0.164397, Train Acc: 0.689744 | Val Loss: 0.176028, Val Acc: 0.670103\n",
      "Epoch 5732 - Train Loss: 0.164383, Train Acc: 0.689744 | Val Loss: 0.176015, Val Acc: 0.670103\n",
      "Epoch 5733 - Train Loss: 0.164369, Train Acc: 0.689744 | Val Loss: 0.176003, Val Acc: 0.670103\n",
      "Epoch 5734 - Train Loss: 0.164356, Train Acc: 0.689744 | Val Loss: 0.175990, Val Acc: 0.670103\n",
      "Epoch 5735 - Train Loss: 0.164342, Train Acc: 0.689744 | Val Loss: 0.175978, Val Acc: 0.670103\n",
      "Epoch 5736 - Train Loss: 0.164329, Train Acc: 0.689744 | Val Loss: 0.175965, Val Acc: 0.670103\n",
      "Epoch 5737 - Train Loss: 0.164315, Train Acc: 0.689744 | Val Loss: 0.175953, Val Acc: 0.670103\n",
      "Epoch 5738 - Train Loss: 0.164301, Train Acc: 0.689744 | Val Loss: 0.175940, Val Acc: 0.670103\n",
      "Epoch 5739 - Train Loss: 0.164288, Train Acc: 0.689744 | Val Loss: 0.175928, Val Acc: 0.670103\n",
      "Epoch 5740 - Train Loss: 0.164274, Train Acc: 0.689744 | Val Loss: 0.175915, Val Acc: 0.670103\n",
      "Epoch 5741 - Train Loss: 0.164260, Train Acc: 0.689744 | Val Loss: 0.175903, Val Acc: 0.670103\n",
      "Epoch 5742 - Train Loss: 0.164247, Train Acc: 0.689744 | Val Loss: 0.175890, Val Acc: 0.670103\n",
      "Epoch 5743 - Train Loss: 0.164233, Train Acc: 0.689744 | Val Loss: 0.175878, Val Acc: 0.670103\n",
      "Epoch 5744 - Train Loss: 0.164219, Train Acc: 0.689744 | Val Loss: 0.175865, Val Acc: 0.670103\n",
      "Epoch 5745 - Train Loss: 0.164206, Train Acc: 0.689744 | Val Loss: 0.175853, Val Acc: 0.670103\n",
      "Epoch 5746 - Train Loss: 0.164192, Train Acc: 0.689744 | Val Loss: 0.175840, Val Acc: 0.670103\n",
      "Epoch 5747 - Train Loss: 0.164179, Train Acc: 0.689744 | Val Loss: 0.175828, Val Acc: 0.670103\n",
      "Epoch 5748 - Train Loss: 0.164165, Train Acc: 0.689744 | Val Loss: 0.175815, Val Acc: 0.670103\n",
      "Epoch 5749 - Train Loss: 0.164151, Train Acc: 0.689744 | Val Loss: 0.175803, Val Acc: 0.670103\n",
      "Epoch 5750 - Train Loss: 0.164138, Train Acc: 0.689744 | Val Loss: 0.175790, Val Acc: 0.670103\n",
      "Epoch 5751 - Train Loss: 0.164124, Train Acc: 0.689744 | Val Loss: 0.175778, Val Acc: 0.670103\n",
      "Epoch 5752 - Train Loss: 0.164110, Train Acc: 0.689744 | Val Loss: 0.175765, Val Acc: 0.670103\n",
      "Epoch 5753 - Train Loss: 0.164097, Train Acc: 0.689744 | Val Loss: 0.175753, Val Acc: 0.670103\n",
      "Epoch 5754 - Train Loss: 0.164083, Train Acc: 0.689744 | Val Loss: 0.175740, Val Acc: 0.670103\n",
      "Epoch 5755 - Train Loss: 0.164070, Train Acc: 0.689744 | Val Loss: 0.175728, Val Acc: 0.670103\n",
      "Epoch 5756 - Train Loss: 0.164056, Train Acc: 0.689744 | Val Loss: 0.175715, Val Acc: 0.670103\n",
      "Epoch 5757 - Train Loss: 0.164042, Train Acc: 0.689744 | Val Loss: 0.175703, Val Acc: 0.670103\n",
      "Epoch 5758 - Train Loss: 0.164029, Train Acc: 0.689744 | Val Loss: 0.175690, Val Acc: 0.670103\n",
      "Epoch 5759 - Train Loss: 0.164015, Train Acc: 0.689744 | Val Loss: 0.175678, Val Acc: 0.670103\n",
      "Epoch 5760 - Train Loss: 0.164002, Train Acc: 0.689744 | Val Loss: 0.175665, Val Acc: 0.670103\n",
      "Epoch 5761 - Train Loss: 0.163988, Train Acc: 0.689744 | Val Loss: 0.175653, Val Acc: 0.670103\n",
      "Epoch 5762 - Train Loss: 0.163974, Train Acc: 0.689744 | Val Loss: 0.175641, Val Acc: 0.670103\n",
      "Epoch 5763 - Train Loss: 0.163961, Train Acc: 0.689744 | Val Loss: 0.175628, Val Acc: 0.670103\n",
      "Epoch 5764 - Train Loss: 0.163947, Train Acc: 0.689744 | Val Loss: 0.175616, Val Acc: 0.670103\n",
      "Epoch 5765 - Train Loss: 0.163934, Train Acc: 0.689744 | Val Loss: 0.175603, Val Acc: 0.670103\n",
      "Epoch 5766 - Train Loss: 0.163920, Train Acc: 0.689744 | Val Loss: 0.175591, Val Acc: 0.670103\n",
      "Epoch 5767 - Train Loss: 0.163906, Train Acc: 0.689744 | Val Loss: 0.175578, Val Acc: 0.670103\n",
      "Epoch 5768 - Train Loss: 0.163893, Train Acc: 0.689744 | Val Loss: 0.175566, Val Acc: 0.670103\n",
      "Epoch 5769 - Train Loss: 0.163879, Train Acc: 0.689744 | Val Loss: 0.175553, Val Acc: 0.670103\n",
      "Epoch 5770 - Train Loss: 0.163866, Train Acc: 0.689744 | Val Loss: 0.175541, Val Acc: 0.670103\n",
      "Epoch 5771 - Train Loss: 0.163852, Train Acc: 0.689744 | Val Loss: 0.175528, Val Acc: 0.670103\n",
      "Epoch 5772 - Train Loss: 0.163838, Train Acc: 0.689744 | Val Loss: 0.175516, Val Acc: 0.670103\n",
      "Epoch 5773 - Train Loss: 0.163825, Train Acc: 0.689744 | Val Loss: 0.175503, Val Acc: 0.670103\n",
      "Epoch 5774 - Train Loss: 0.163811, Train Acc: 0.689744 | Val Loss: 0.175491, Val Acc: 0.670103\n",
      "Epoch 5775 - Train Loss: 0.163798, Train Acc: 0.689744 | Val Loss: 0.175479, Val Acc: 0.670103\n",
      "Epoch 5776 - Train Loss: 0.163784, Train Acc: 0.689744 | Val Loss: 0.175466, Val Acc: 0.670103\n",
      "Epoch 5777 - Train Loss: 0.163771, Train Acc: 0.689744 | Val Loss: 0.175454, Val Acc: 0.670103\n",
      "Epoch 5778 - Train Loss: 0.163757, Train Acc: 0.689744 | Val Loss: 0.175441, Val Acc: 0.670103\n",
      "Epoch 5779 - Train Loss: 0.163743, Train Acc: 0.689744 | Val Loss: 0.175429, Val Acc: 0.670103\n",
      "Epoch 5780 - Train Loss: 0.163730, Train Acc: 0.689744 | Val Loss: 0.175416, Val Acc: 0.670103\n",
      "Epoch 5781 - Train Loss: 0.163716, Train Acc: 0.689744 | Val Loss: 0.175404, Val Acc: 0.670103\n",
      "Epoch 5782 - Train Loss: 0.163703, Train Acc: 0.689744 | Val Loss: 0.175391, Val Acc: 0.670103\n",
      "Epoch 5783 - Train Loss: 0.163689, Train Acc: 0.689744 | Val Loss: 0.175379, Val Acc: 0.670103\n",
      "Epoch 5784 - Train Loss: 0.163675, Train Acc: 0.689744 | Val Loss: 0.175367, Val Acc: 0.670103\n",
      "Epoch 5785 - Train Loss: 0.163662, Train Acc: 0.689744 | Val Loss: 0.175354, Val Acc: 0.670103\n",
      "Epoch 5786 - Train Loss: 0.163648, Train Acc: 0.689744 | Val Loss: 0.175342, Val Acc: 0.670103\n",
      "Epoch 5787 - Train Loss: 0.163635, Train Acc: 0.689744 | Val Loss: 0.175329, Val Acc: 0.670103\n",
      "Epoch 5788 - Train Loss: 0.163621, Train Acc: 0.689744 | Val Loss: 0.175317, Val Acc: 0.670103\n",
      "Epoch 5789 - Train Loss: 0.163608, Train Acc: 0.689744 | Val Loss: 0.175304, Val Acc: 0.670103\n",
      "Epoch 5790 - Train Loss: 0.163594, Train Acc: 0.689744 | Val Loss: 0.175292, Val Acc: 0.670103\n",
      "Epoch 5791 - Train Loss: 0.163581, Train Acc: 0.689744 | Val Loss: 0.175280, Val Acc: 0.670103\n",
      "Epoch 5792 - Train Loss: 0.163567, Train Acc: 0.689744 | Val Loss: 0.175267, Val Acc: 0.670103\n",
      "Epoch 5793 - Train Loss: 0.163553, Train Acc: 0.689744 | Val Loss: 0.175255, Val Acc: 0.670103\n",
      "Epoch 5794 - Train Loss: 0.163540, Train Acc: 0.689744 | Val Loss: 0.175242, Val Acc: 0.670103\n",
      "Epoch 5795 - Train Loss: 0.163526, Train Acc: 0.689744 | Val Loss: 0.175230, Val Acc: 0.670103\n",
      "Epoch 5796 - Train Loss: 0.163513, Train Acc: 0.689744 | Val Loss: 0.175218, Val Acc: 0.670103\n",
      "Epoch 5797 - Train Loss: 0.163499, Train Acc: 0.689744 | Val Loss: 0.175205, Val Acc: 0.670103\n",
      "Epoch 5798 - Train Loss: 0.163486, Train Acc: 0.689744 | Val Loss: 0.175193, Val Acc: 0.670103\n",
      "Epoch 5799 - Train Loss: 0.163472, Train Acc: 0.689744 | Val Loss: 0.175180, Val Acc: 0.670103\n",
      "Epoch 5800 - Train Loss: 0.163459, Train Acc: 0.689744 | Val Loss: 0.175168, Val Acc: 0.670103\n",
      "Epoch 5801 - Train Loss: 0.163445, Train Acc: 0.689744 | Val Loss: 0.175155, Val Acc: 0.670103\n",
      "Epoch 5802 - Train Loss: 0.163432, Train Acc: 0.689744 | Val Loss: 0.175143, Val Acc: 0.670103\n",
      "Epoch 5803 - Train Loss: 0.163418, Train Acc: 0.689744 | Val Loss: 0.175131, Val Acc: 0.670103\n",
      "Epoch 5804 - Train Loss: 0.163405, Train Acc: 0.689744 | Val Loss: 0.175118, Val Acc: 0.670103\n",
      "Epoch 5805 - Train Loss: 0.163391, Train Acc: 0.689744 | Val Loss: 0.175106, Val Acc: 0.670103\n",
      "Epoch 5806 - Train Loss: 0.163378, Train Acc: 0.689744 | Val Loss: 0.175093, Val Acc: 0.670103\n",
      "Epoch 5807 - Train Loss: 0.163364, Train Acc: 0.689744 | Val Loss: 0.175081, Val Acc: 0.670103\n",
      "Epoch 5808 - Train Loss: 0.163350, Train Acc: 0.689744 | Val Loss: 0.175069, Val Acc: 0.670103\n",
      "Epoch 5809 - Train Loss: 0.163337, Train Acc: 0.689744 | Val Loss: 0.175056, Val Acc: 0.670103\n",
      "Epoch 5810 - Train Loss: 0.163323, Train Acc: 0.689744 | Val Loss: 0.175044, Val Acc: 0.670103\n",
      "Epoch 5811 - Train Loss: 0.163310, Train Acc: 0.689744 | Val Loss: 0.175031, Val Acc: 0.670103\n",
      "Epoch 5812 - Train Loss: 0.163296, Train Acc: 0.689744 | Val Loss: 0.175019, Val Acc: 0.670103\n",
      "Epoch 5813 - Train Loss: 0.163283, Train Acc: 0.689744 | Val Loss: 0.175007, Val Acc: 0.670103\n",
      "Epoch 5814 - Train Loss: 0.163269, Train Acc: 0.689744 | Val Loss: 0.174994, Val Acc: 0.670103\n",
      "Epoch 5815 - Train Loss: 0.163256, Train Acc: 0.689744 | Val Loss: 0.174982, Val Acc: 0.670103\n",
      "Epoch 5816 - Train Loss: 0.163242, Train Acc: 0.688462 | Val Loss: 0.174970, Val Acc: 0.670103\n",
      "Epoch 5817 - Train Loss: 0.163229, Train Acc: 0.688462 | Val Loss: 0.174957, Val Acc: 0.670103\n",
      "Epoch 5818 - Train Loss: 0.163215, Train Acc: 0.688462 | Val Loss: 0.174945, Val Acc: 0.670103\n",
      "Epoch 5819 - Train Loss: 0.163202, Train Acc: 0.688462 | Val Loss: 0.174932, Val Acc: 0.670103\n",
      "Epoch 5820 - Train Loss: 0.163188, Train Acc: 0.688462 | Val Loss: 0.174920, Val Acc: 0.670103\n",
      "Epoch 5821 - Train Loss: 0.163175, Train Acc: 0.688462 | Val Loss: 0.174908, Val Acc: 0.670103\n",
      "Epoch 5822 - Train Loss: 0.163161, Train Acc: 0.688462 | Val Loss: 0.174895, Val Acc: 0.670103\n",
      "Epoch 5823 - Train Loss: 0.163148, Train Acc: 0.688462 | Val Loss: 0.174883, Val Acc: 0.670103\n",
      "Epoch 5824 - Train Loss: 0.163134, Train Acc: 0.688462 | Val Loss: 0.174871, Val Acc: 0.670103\n",
      "Epoch 5825 - Train Loss: 0.163121, Train Acc: 0.688462 | Val Loss: 0.174858, Val Acc: 0.670103\n",
      "Epoch 5826 - Train Loss: 0.163107, Train Acc: 0.688462 | Val Loss: 0.174846, Val Acc: 0.670103\n",
      "Epoch 5827 - Train Loss: 0.163094, Train Acc: 0.688462 | Val Loss: 0.174833, Val Acc: 0.670103\n",
      "Epoch 5828 - Train Loss: 0.163080, Train Acc: 0.688462 | Val Loss: 0.174821, Val Acc: 0.670103\n",
      "Epoch 5829 - Train Loss: 0.163067, Train Acc: 0.688462 | Val Loss: 0.174809, Val Acc: 0.670103\n",
      "Epoch 5830 - Train Loss: 0.163053, Train Acc: 0.689744 | Val Loss: 0.174796, Val Acc: 0.670103\n",
      "Epoch 5831 - Train Loss: 0.163040, Train Acc: 0.689744 | Val Loss: 0.174784, Val Acc: 0.670103\n",
      "Epoch 5832 - Train Loss: 0.163026, Train Acc: 0.689744 | Val Loss: 0.174772, Val Acc: 0.670103\n",
      "Epoch 5833 - Train Loss: 0.163013, Train Acc: 0.689744 | Val Loss: 0.174759, Val Acc: 0.670103\n",
      "Epoch 5834 - Train Loss: 0.162999, Train Acc: 0.689744 | Val Loss: 0.174747, Val Acc: 0.670103\n",
      "Epoch 5835 - Train Loss: 0.162986, Train Acc: 0.689744 | Val Loss: 0.174735, Val Acc: 0.670103\n",
      "Epoch 5836 - Train Loss: 0.162972, Train Acc: 0.689744 | Val Loss: 0.174722, Val Acc: 0.670103\n",
      "Epoch 5837 - Train Loss: 0.162959, Train Acc: 0.689744 | Val Loss: 0.174710, Val Acc: 0.670103\n",
      "Epoch 5838 - Train Loss: 0.162945, Train Acc: 0.689744 | Val Loss: 0.174698, Val Acc: 0.670103\n",
      "Epoch 5839 - Train Loss: 0.162932, Train Acc: 0.689744 | Val Loss: 0.174685, Val Acc: 0.670103\n",
      "Epoch 5840 - Train Loss: 0.162918, Train Acc: 0.689744 | Val Loss: 0.174673, Val Acc: 0.670103\n",
      "Epoch 5841 - Train Loss: 0.162905, Train Acc: 0.689744 | Val Loss: 0.174661, Val Acc: 0.670103\n",
      "Epoch 5842 - Train Loss: 0.162891, Train Acc: 0.691026 | Val Loss: 0.174648, Val Acc: 0.670103\n",
      "Epoch 5843 - Train Loss: 0.162878, Train Acc: 0.691026 | Val Loss: 0.174636, Val Acc: 0.670103\n",
      "Epoch 5844 - Train Loss: 0.162864, Train Acc: 0.691026 | Val Loss: 0.174624, Val Acc: 0.670103\n",
      "Epoch 5845 - Train Loss: 0.162851, Train Acc: 0.691026 | Val Loss: 0.174611, Val Acc: 0.670103\n",
      "Epoch 5846 - Train Loss: 0.162838, Train Acc: 0.691026 | Val Loss: 0.174599, Val Acc: 0.670103\n",
      "Epoch 5847 - Train Loss: 0.162824, Train Acc: 0.691026 | Val Loss: 0.174587, Val Acc: 0.670103\n",
      "Epoch 5848 - Train Loss: 0.162811, Train Acc: 0.691026 | Val Loss: 0.174575, Val Acc: 0.670103\n",
      "Epoch 5849 - Train Loss: 0.162797, Train Acc: 0.691026 | Val Loss: 0.174562, Val Acc: 0.670103\n",
      "Epoch 5850 - Train Loss: 0.162784, Train Acc: 0.691026 | Val Loss: 0.174550, Val Acc: 0.670103\n",
      "Epoch 5851 - Train Loss: 0.162770, Train Acc: 0.692308 | Val Loss: 0.174538, Val Acc: 0.670103\n",
      "Epoch 5852 - Train Loss: 0.162757, Train Acc: 0.692308 | Val Loss: 0.174525, Val Acc: 0.670103\n",
      "Epoch 5853 - Train Loss: 0.162743, Train Acc: 0.693590 | Val Loss: 0.174513, Val Acc: 0.670103\n",
      "Epoch 5854 - Train Loss: 0.162730, Train Acc: 0.693590 | Val Loss: 0.174501, Val Acc: 0.670103\n",
      "Epoch 5855 - Train Loss: 0.162716, Train Acc: 0.693590 | Val Loss: 0.174488, Val Acc: 0.670103\n",
      "Epoch 5856 - Train Loss: 0.162703, Train Acc: 0.693590 | Val Loss: 0.174476, Val Acc: 0.670103\n",
      "Epoch 5857 - Train Loss: 0.162689, Train Acc: 0.693590 | Val Loss: 0.174464, Val Acc: 0.670103\n",
      "Epoch 5858 - Train Loss: 0.162676, Train Acc: 0.693590 | Val Loss: 0.174452, Val Acc: 0.670103\n",
      "Epoch 5859 - Train Loss: 0.162663, Train Acc: 0.693590 | Val Loss: 0.174439, Val Acc: 0.670103\n",
      "Epoch 5860 - Train Loss: 0.162649, Train Acc: 0.693590 | Val Loss: 0.174427, Val Acc: 0.670103\n",
      "Epoch 5861 - Train Loss: 0.162636, Train Acc: 0.693590 | Val Loss: 0.174415, Val Acc: 0.670103\n",
      "Epoch 5862 - Train Loss: 0.162622, Train Acc: 0.693590 | Val Loss: 0.174402, Val Acc: 0.670103\n",
      "Epoch 5863 - Train Loss: 0.162609, Train Acc: 0.693590 | Val Loss: 0.174390, Val Acc: 0.670103\n",
      "Epoch 5864 - Train Loss: 0.162595, Train Acc: 0.693590 | Val Loss: 0.174378, Val Acc: 0.670103\n",
      "Epoch 5865 - Train Loss: 0.162582, Train Acc: 0.693590 | Val Loss: 0.174365, Val Acc: 0.670103\n",
      "Epoch 5866 - Train Loss: 0.162569, Train Acc: 0.693590 | Val Loss: 0.174353, Val Acc: 0.670103\n",
      "Epoch 5867 - Train Loss: 0.162555, Train Acc: 0.693590 | Val Loss: 0.174341, Val Acc: 0.670103\n",
      "Epoch 5868 - Train Loss: 0.162542, Train Acc: 0.693590 | Val Loss: 0.174329, Val Acc: 0.670103\n",
      "Epoch 5869 - Train Loss: 0.162528, Train Acc: 0.693590 | Val Loss: 0.174316, Val Acc: 0.670103\n",
      "Epoch 5870 - Train Loss: 0.162515, Train Acc: 0.693590 | Val Loss: 0.174304, Val Acc: 0.670103\n",
      "Epoch 5871 - Train Loss: 0.162501, Train Acc: 0.693590 | Val Loss: 0.174292, Val Acc: 0.670103\n",
      "Epoch 5872 - Train Loss: 0.162488, Train Acc: 0.693590 | Val Loss: 0.174280, Val Acc: 0.670103\n",
      "Epoch 5873 - Train Loss: 0.162475, Train Acc: 0.693590 | Val Loss: 0.174267, Val Acc: 0.670103\n",
      "Epoch 5874 - Train Loss: 0.162461, Train Acc: 0.693590 | Val Loss: 0.174255, Val Acc: 0.670103\n",
      "Epoch 5875 - Train Loss: 0.162448, Train Acc: 0.693590 | Val Loss: 0.174243, Val Acc: 0.670103\n",
      "Epoch 5876 - Train Loss: 0.162434, Train Acc: 0.693590 | Val Loss: 0.174230, Val Acc: 0.670103\n",
      "Epoch 5877 - Train Loss: 0.162421, Train Acc: 0.693590 | Val Loss: 0.174218, Val Acc: 0.670103\n",
      "Epoch 5878 - Train Loss: 0.162407, Train Acc: 0.693590 | Val Loss: 0.174206, Val Acc: 0.670103\n",
      "Epoch 5879 - Train Loss: 0.162394, Train Acc: 0.694872 | Val Loss: 0.174194, Val Acc: 0.670103\n",
      "Epoch 5880 - Train Loss: 0.162381, Train Acc: 0.694872 | Val Loss: 0.174181, Val Acc: 0.670103\n",
      "Epoch 5881 - Train Loss: 0.162367, Train Acc: 0.694872 | Val Loss: 0.174169, Val Acc: 0.670103\n",
      "Epoch 5882 - Train Loss: 0.162354, Train Acc: 0.694872 | Val Loss: 0.174157, Val Acc: 0.670103\n",
      "Epoch 5883 - Train Loss: 0.162340, Train Acc: 0.694872 | Val Loss: 0.174145, Val Acc: 0.670103\n",
      "Epoch 5884 - Train Loss: 0.162327, Train Acc: 0.694872 | Val Loss: 0.174132, Val Acc: 0.670103\n",
      "Epoch 5885 - Train Loss: 0.162314, Train Acc: 0.694872 | Val Loss: 0.174120, Val Acc: 0.670103\n",
      "Epoch 5886 - Train Loss: 0.162300, Train Acc: 0.694872 | Val Loss: 0.174108, Val Acc: 0.670103\n",
      "Epoch 5887 - Train Loss: 0.162287, Train Acc: 0.694872 | Val Loss: 0.174096, Val Acc: 0.670103\n",
      "Epoch 5888 - Train Loss: 0.162273, Train Acc: 0.694872 | Val Loss: 0.174083, Val Acc: 0.670103\n",
      "Epoch 5889 - Train Loss: 0.162260, Train Acc: 0.694872 | Val Loss: 0.174071, Val Acc: 0.670103\n",
      "Epoch 5890 - Train Loss: 0.162247, Train Acc: 0.694872 | Val Loss: 0.174059, Val Acc: 0.670103\n",
      "Epoch 5891 - Train Loss: 0.162233, Train Acc: 0.694872 | Val Loss: 0.174047, Val Acc: 0.670103\n",
      "Epoch 5892 - Train Loss: 0.162220, Train Acc: 0.697436 | Val Loss: 0.174034, Val Acc: 0.670103\n",
      "Epoch 5893 - Train Loss: 0.162206, Train Acc: 0.697436 | Val Loss: 0.174022, Val Acc: 0.670103\n",
      "Epoch 5894 - Train Loss: 0.162193, Train Acc: 0.697436 | Val Loss: 0.174010, Val Acc: 0.670103\n",
      "Epoch 5895 - Train Loss: 0.162180, Train Acc: 0.697436 | Val Loss: 0.173998, Val Acc: 0.670103\n",
      "Epoch 5896 - Train Loss: 0.162166, Train Acc: 0.697436 | Val Loss: 0.173985, Val Acc: 0.670103\n",
      "Epoch 5897 - Train Loss: 0.162153, Train Acc: 0.697436 | Val Loss: 0.173973, Val Acc: 0.670103\n",
      "Epoch 5898 - Train Loss: 0.162139, Train Acc: 0.697436 | Val Loss: 0.173961, Val Acc: 0.670103\n",
      "Epoch 5899 - Train Loss: 0.162126, Train Acc: 0.697436 | Val Loss: 0.173949, Val Acc: 0.670103\n",
      "Epoch 5900 - Train Loss: 0.162113, Train Acc: 0.697436 | Val Loss: 0.173937, Val Acc: 0.670103\n",
      "Epoch 5901 - Train Loss: 0.162099, Train Acc: 0.697436 | Val Loss: 0.173924, Val Acc: 0.670103\n",
      "Epoch 5902 - Train Loss: 0.162086, Train Acc: 0.697436 | Val Loss: 0.173912, Val Acc: 0.670103\n",
      "Epoch 5903 - Train Loss: 0.162073, Train Acc: 0.697436 | Val Loss: 0.173900, Val Acc: 0.670103\n",
      "Epoch 5904 - Train Loss: 0.162059, Train Acc: 0.697436 | Val Loss: 0.173888, Val Acc: 0.670103\n",
      "Epoch 5905 - Train Loss: 0.162046, Train Acc: 0.697436 | Val Loss: 0.173875, Val Acc: 0.670103\n",
      "Epoch 5906 - Train Loss: 0.162032, Train Acc: 0.697436 | Val Loss: 0.173863, Val Acc: 0.670103\n",
      "Epoch 5907 - Train Loss: 0.162019, Train Acc: 0.697436 | Val Loss: 0.173851, Val Acc: 0.670103\n",
      "Epoch 5908 - Train Loss: 0.162006, Train Acc: 0.697436 | Val Loss: 0.173839, Val Acc: 0.670103\n",
      "Epoch 5909 - Train Loss: 0.161992, Train Acc: 0.697436 | Val Loss: 0.173827, Val Acc: 0.670103\n",
      "Epoch 5910 - Train Loss: 0.161979, Train Acc: 0.697436 | Val Loss: 0.173814, Val Acc: 0.670103\n",
      "Epoch 5911 - Train Loss: 0.161966, Train Acc: 0.697436 | Val Loss: 0.173802, Val Acc: 0.670103\n",
      "Epoch 5912 - Train Loss: 0.161952, Train Acc: 0.697436 | Val Loss: 0.173790, Val Acc: 0.670103\n",
      "Epoch 5913 - Train Loss: 0.161939, Train Acc: 0.697436 | Val Loss: 0.173778, Val Acc: 0.670103\n",
      "Epoch 5914 - Train Loss: 0.161926, Train Acc: 0.697436 | Val Loss: 0.173766, Val Acc: 0.670103\n",
      "Epoch 5915 - Train Loss: 0.161912, Train Acc: 0.697436 | Val Loss: 0.173753, Val Acc: 0.670103\n",
      "Epoch 5916 - Train Loss: 0.161899, Train Acc: 0.697436 | Val Loss: 0.173741, Val Acc: 0.670103\n",
      "Epoch 5917 - Train Loss: 0.161886, Train Acc: 0.697436 | Val Loss: 0.173729, Val Acc: 0.670103\n",
      "Epoch 5918 - Train Loss: 0.161872, Train Acc: 0.697436 | Val Loss: 0.173717, Val Acc: 0.670103\n",
      "Epoch 5919 - Train Loss: 0.161859, Train Acc: 0.697436 | Val Loss: 0.173705, Val Acc: 0.670103\n",
      "Epoch 5920 - Train Loss: 0.161845, Train Acc: 0.697436 | Val Loss: 0.173692, Val Acc: 0.670103\n",
      "Epoch 5921 - Train Loss: 0.161832, Train Acc: 0.697436 | Val Loss: 0.173680, Val Acc: 0.670103\n",
      "Epoch 5922 - Train Loss: 0.161819, Train Acc: 0.697436 | Val Loss: 0.173668, Val Acc: 0.670103\n",
      "Epoch 5923 - Train Loss: 0.161805, Train Acc: 0.697436 | Val Loss: 0.173656, Val Acc: 0.670103\n",
      "Epoch 5924 - Train Loss: 0.161792, Train Acc: 0.698718 | Val Loss: 0.173644, Val Acc: 0.670103\n",
      "Epoch 5925 - Train Loss: 0.161779, Train Acc: 0.698718 | Val Loss: 0.173631, Val Acc: 0.670103\n",
      "Epoch 5926 - Train Loss: 0.161765, Train Acc: 0.698718 | Val Loss: 0.173619, Val Acc: 0.670103\n",
      "Epoch 5927 - Train Loss: 0.161752, Train Acc: 0.698718 | Val Loss: 0.173607, Val Acc: 0.670103\n",
      "Epoch 5928 - Train Loss: 0.161739, Train Acc: 0.698718 | Val Loss: 0.173595, Val Acc: 0.670103\n",
      "Epoch 5929 - Train Loss: 0.161725, Train Acc: 0.698718 | Val Loss: 0.173583, Val Acc: 0.670103\n",
      "Epoch 5930 - Train Loss: 0.161712, Train Acc: 0.698718 | Val Loss: 0.173570, Val Acc: 0.670103\n",
      "Epoch 5931 - Train Loss: 0.161699, Train Acc: 0.698718 | Val Loss: 0.173558, Val Acc: 0.670103\n",
      "Epoch 5932 - Train Loss: 0.161685, Train Acc: 0.698718 | Val Loss: 0.173546, Val Acc: 0.670103\n",
      "Epoch 5933 - Train Loss: 0.161672, Train Acc: 0.698718 | Val Loss: 0.173534, Val Acc: 0.670103\n",
      "Epoch 5934 - Train Loss: 0.161659, Train Acc: 0.698718 | Val Loss: 0.173522, Val Acc: 0.670103\n",
      "Epoch 5935 - Train Loss: 0.161645, Train Acc: 0.698718 | Val Loss: 0.173510, Val Acc: 0.670103\n",
      "Epoch 5936 - Train Loss: 0.161632, Train Acc: 0.701282 | Val Loss: 0.173497, Val Acc: 0.670103\n",
      "Epoch 5937 - Train Loss: 0.161619, Train Acc: 0.701282 | Val Loss: 0.173485, Val Acc: 0.670103\n",
      "Epoch 5938 - Train Loss: 0.161605, Train Acc: 0.701282 | Val Loss: 0.173473, Val Acc: 0.670103\n",
      "Epoch 5939 - Train Loss: 0.161592, Train Acc: 0.701282 | Val Loss: 0.173461, Val Acc: 0.670103\n",
      "Epoch 5940 - Train Loss: 0.161579, Train Acc: 0.701282 | Val Loss: 0.173449, Val Acc: 0.670103\n",
      "Epoch 5941 - Train Loss: 0.161566, Train Acc: 0.701282 | Val Loss: 0.173437, Val Acc: 0.670103\n",
      "Epoch 5942 - Train Loss: 0.161552, Train Acc: 0.701282 | Val Loss: 0.173424, Val Acc: 0.670103\n",
      "Epoch 5943 - Train Loss: 0.161539, Train Acc: 0.701282 | Val Loss: 0.173412, Val Acc: 0.670103\n",
      "Epoch 5944 - Train Loss: 0.161526, Train Acc: 0.701282 | Val Loss: 0.173400, Val Acc: 0.670103\n",
      "Epoch 5945 - Train Loss: 0.161512, Train Acc: 0.701282 | Val Loss: 0.173388, Val Acc: 0.670103\n",
      "Epoch 5946 - Train Loss: 0.161499, Train Acc: 0.701282 | Val Loss: 0.173376, Val Acc: 0.670103\n",
      "Epoch 5947 - Train Loss: 0.161486, Train Acc: 0.701282 | Val Loss: 0.173364, Val Acc: 0.670103\n",
      "Epoch 5948 - Train Loss: 0.161472, Train Acc: 0.701282 | Val Loss: 0.173351, Val Acc: 0.670103\n",
      "Epoch 5949 - Train Loss: 0.161459, Train Acc: 0.701282 | Val Loss: 0.173339, Val Acc: 0.670103\n",
      "Epoch 5950 - Train Loss: 0.161446, Train Acc: 0.701282 | Val Loss: 0.173327, Val Acc: 0.670103\n",
      "Epoch 5951 - Train Loss: 0.161432, Train Acc: 0.701282 | Val Loss: 0.173315, Val Acc: 0.670103\n",
      "Epoch 5952 - Train Loss: 0.161419, Train Acc: 0.701282 | Val Loss: 0.173303, Val Acc: 0.670103\n",
      "Epoch 5953 - Train Loss: 0.161406, Train Acc: 0.701282 | Val Loss: 0.173291, Val Acc: 0.670103\n",
      "Epoch 5954 - Train Loss: 0.161393, Train Acc: 0.701282 | Val Loss: 0.173279, Val Acc: 0.670103\n",
      "Epoch 5955 - Train Loss: 0.161379, Train Acc: 0.701282 | Val Loss: 0.173266, Val Acc: 0.670103\n",
      "Epoch 5956 - Train Loss: 0.161366, Train Acc: 0.701282 | Val Loss: 0.173254, Val Acc: 0.670103\n",
      "Epoch 5957 - Train Loss: 0.161353, Train Acc: 0.701282 | Val Loss: 0.173242, Val Acc: 0.670103\n",
      "Epoch 5958 - Train Loss: 0.161339, Train Acc: 0.701282 | Val Loss: 0.173230, Val Acc: 0.670103\n",
      "Epoch 5959 - Train Loss: 0.161326, Train Acc: 0.701282 | Val Loss: 0.173218, Val Acc: 0.670103\n",
      "Epoch 5960 - Train Loss: 0.161313, Train Acc: 0.701282 | Val Loss: 0.173206, Val Acc: 0.670103\n",
      "Epoch 5961 - Train Loss: 0.161299, Train Acc: 0.701282 | Val Loss: 0.173194, Val Acc: 0.670103\n",
      "Epoch 5962 - Train Loss: 0.161286, Train Acc: 0.701282 | Val Loss: 0.173181, Val Acc: 0.670103\n",
      "Epoch 5963 - Train Loss: 0.161273, Train Acc: 0.701282 | Val Loss: 0.173169, Val Acc: 0.670103\n",
      "Epoch 5964 - Train Loss: 0.161260, Train Acc: 0.701282 | Val Loss: 0.173157, Val Acc: 0.670103\n",
      "Epoch 5965 - Train Loss: 0.161246, Train Acc: 0.701282 | Val Loss: 0.173145, Val Acc: 0.670103\n",
      "Epoch 5966 - Train Loss: 0.161233, Train Acc: 0.701282 | Val Loss: 0.173133, Val Acc: 0.670103\n",
      "Epoch 5967 - Train Loss: 0.161220, Train Acc: 0.701282 | Val Loss: 0.173121, Val Acc: 0.670103\n",
      "Epoch 5968 - Train Loss: 0.161207, Train Acc: 0.701282 | Val Loss: 0.173109, Val Acc: 0.670103\n",
      "Epoch 5969 - Train Loss: 0.161193, Train Acc: 0.701282 | Val Loss: 0.173097, Val Acc: 0.670103\n",
      "Epoch 5970 - Train Loss: 0.161180, Train Acc: 0.701282 | Val Loss: 0.173084, Val Acc: 0.670103\n",
      "Epoch 5971 - Train Loss: 0.161167, Train Acc: 0.701282 | Val Loss: 0.173072, Val Acc: 0.670103\n",
      "Epoch 5972 - Train Loss: 0.161153, Train Acc: 0.701282 | Val Loss: 0.173060, Val Acc: 0.670103\n",
      "Epoch 5973 - Train Loss: 0.161140, Train Acc: 0.701282 | Val Loss: 0.173048, Val Acc: 0.670103\n",
      "Epoch 5974 - Train Loss: 0.161127, Train Acc: 0.701282 | Val Loss: 0.173036, Val Acc: 0.670103\n",
      "Epoch 5975 - Train Loss: 0.161114, Train Acc: 0.701282 | Val Loss: 0.173024, Val Acc: 0.670103\n",
      "Epoch 5976 - Train Loss: 0.161100, Train Acc: 0.701282 | Val Loss: 0.173012, Val Acc: 0.670103\n",
      "Epoch 5977 - Train Loss: 0.161087, Train Acc: 0.701282 | Val Loss: 0.173000, Val Acc: 0.670103\n",
      "Epoch 5978 - Train Loss: 0.161074, Train Acc: 0.701282 | Val Loss: 0.172988, Val Acc: 0.670103\n",
      "Epoch 5979 - Train Loss: 0.161061, Train Acc: 0.701282 | Val Loss: 0.172975, Val Acc: 0.670103\n",
      "Epoch 5980 - Train Loss: 0.161047, Train Acc: 0.701282 | Val Loss: 0.172963, Val Acc: 0.670103\n",
      "Epoch 5981 - Train Loss: 0.161034, Train Acc: 0.701282 | Val Loss: 0.172951, Val Acc: 0.670103\n",
      "Epoch 5982 - Train Loss: 0.161021, Train Acc: 0.701282 | Val Loss: 0.172939, Val Acc: 0.670103\n",
      "Epoch 5983 - Train Loss: 0.161008, Train Acc: 0.701282 | Val Loss: 0.172927, Val Acc: 0.670103\n",
      "Epoch 5984 - Train Loss: 0.160994, Train Acc: 0.701282 | Val Loss: 0.172915, Val Acc: 0.670103\n",
      "Epoch 5985 - Train Loss: 0.160981, Train Acc: 0.701282 | Val Loss: 0.172903, Val Acc: 0.670103\n",
      "Epoch 5986 - Train Loss: 0.160968, Train Acc: 0.702564 | Val Loss: 0.172891, Val Acc: 0.670103\n",
      "Epoch 5987 - Train Loss: 0.160955, Train Acc: 0.702564 | Val Loss: 0.172879, Val Acc: 0.670103\n",
      "Epoch 5988 - Train Loss: 0.160941, Train Acc: 0.702564 | Val Loss: 0.172867, Val Acc: 0.670103\n",
      "Epoch 5989 - Train Loss: 0.160928, Train Acc: 0.702564 | Val Loss: 0.172854, Val Acc: 0.670103\n",
      "Epoch 5990 - Train Loss: 0.160915, Train Acc: 0.702564 | Val Loss: 0.172842, Val Acc: 0.670103\n",
      "Epoch 5991 - Train Loss: 0.160902, Train Acc: 0.702564 | Val Loss: 0.172830, Val Acc: 0.670103\n",
      "Epoch 5992 - Train Loss: 0.160889, Train Acc: 0.701282 | Val Loss: 0.172818, Val Acc: 0.670103\n",
      "Epoch 5993 - Train Loss: 0.160875, Train Acc: 0.701282 | Val Loss: 0.172806, Val Acc: 0.670103\n",
      "Epoch 5994 - Train Loss: 0.160862, Train Acc: 0.701282 | Val Loss: 0.172794, Val Acc: 0.670103\n",
      "Epoch 5995 - Train Loss: 0.160849, Train Acc: 0.701282 | Val Loss: 0.172782, Val Acc: 0.670103\n",
      "Epoch 5996 - Train Loss: 0.160836, Train Acc: 0.701282 | Val Loss: 0.172770, Val Acc: 0.670103\n",
      "Epoch 5997 - Train Loss: 0.160822, Train Acc: 0.701282 | Val Loss: 0.172758, Val Acc: 0.670103\n",
      "Epoch 5998 - Train Loss: 0.160809, Train Acc: 0.701282 | Val Loss: 0.172746, Val Acc: 0.670103\n",
      "Epoch 5999 - Train Loss: 0.160796, Train Acc: 0.701282 | Val Loss: 0.172734, Val Acc: 0.670103\n",
      "Epoch 6000 - Train Loss: 0.160783, Train Acc: 0.701282 | Val Loss: 0.172721, Val Acc: 0.670103\n",
      "Epoch 6001 - Train Loss: 0.160770, Train Acc: 0.701282 | Val Loss: 0.172709, Val Acc: 0.670103\n",
      "Epoch 6002 - Train Loss: 0.160756, Train Acc: 0.701282 | Val Loss: 0.172697, Val Acc: 0.670103\n",
      "Epoch 6003 - Train Loss: 0.160743, Train Acc: 0.701282 | Val Loss: 0.172685, Val Acc: 0.670103\n",
      "Epoch 6004 - Train Loss: 0.160730, Train Acc: 0.701282 | Val Loss: 0.172673, Val Acc: 0.680412\n",
      "Epoch 6005 - Train Loss: 0.160717, Train Acc: 0.701282 | Val Loss: 0.172661, Val Acc: 0.680412\n",
      "Epoch 6006 - Train Loss: 0.160703, Train Acc: 0.701282 | Val Loss: 0.172649, Val Acc: 0.680412\n",
      "Epoch 6007 - Train Loss: 0.160690, Train Acc: 0.701282 | Val Loss: 0.172637, Val Acc: 0.680412\n",
      "Epoch 6008 - Train Loss: 0.160677, Train Acc: 0.701282 | Val Loss: 0.172625, Val Acc: 0.680412\n",
      "Epoch 6009 - Train Loss: 0.160664, Train Acc: 0.701282 | Val Loss: 0.172613, Val Acc: 0.680412\n",
      "Epoch 6010 - Train Loss: 0.160651, Train Acc: 0.701282 | Val Loss: 0.172601, Val Acc: 0.680412\n",
      "Epoch 6011 - Train Loss: 0.160637, Train Acc: 0.701282 | Val Loss: 0.172589, Val Acc: 0.680412\n",
      "Epoch 6012 - Train Loss: 0.160624, Train Acc: 0.701282 | Val Loss: 0.172577, Val Acc: 0.680412\n",
      "Epoch 6013 - Train Loss: 0.160611, Train Acc: 0.701282 | Val Loss: 0.172565, Val Acc: 0.680412\n",
      "Epoch 6014 - Train Loss: 0.160598, Train Acc: 0.701282 | Val Loss: 0.172553, Val Acc: 0.680412\n",
      "Epoch 6015 - Train Loss: 0.160585, Train Acc: 0.701282 | Val Loss: 0.172541, Val Acc: 0.680412\n",
      "Epoch 6016 - Train Loss: 0.160571, Train Acc: 0.701282 | Val Loss: 0.172528, Val Acc: 0.680412\n",
      "Epoch 6017 - Train Loss: 0.160558, Train Acc: 0.701282 | Val Loss: 0.172516, Val Acc: 0.680412\n",
      "Epoch 6018 - Train Loss: 0.160545, Train Acc: 0.701282 | Val Loss: 0.172504, Val Acc: 0.680412\n",
      "Epoch 6019 - Train Loss: 0.160532, Train Acc: 0.701282 | Val Loss: 0.172492, Val Acc: 0.680412\n",
      "Epoch 6020 - Train Loss: 0.160519, Train Acc: 0.701282 | Val Loss: 0.172480, Val Acc: 0.680412\n",
      "Epoch 6021 - Train Loss: 0.160506, Train Acc: 0.701282 | Val Loss: 0.172468, Val Acc: 0.680412\n",
      "Epoch 6022 - Train Loss: 0.160492, Train Acc: 0.701282 | Val Loss: 0.172456, Val Acc: 0.680412\n",
      "Epoch 6023 - Train Loss: 0.160479, Train Acc: 0.701282 | Val Loss: 0.172444, Val Acc: 0.680412\n",
      "Epoch 6024 - Train Loss: 0.160466, Train Acc: 0.701282 | Val Loss: 0.172432, Val Acc: 0.680412\n",
      "Epoch 6025 - Train Loss: 0.160453, Train Acc: 0.701282 | Val Loss: 0.172420, Val Acc: 0.680412\n",
      "Epoch 6026 - Train Loss: 0.160440, Train Acc: 0.701282 | Val Loss: 0.172408, Val Acc: 0.680412\n",
      "Epoch 6027 - Train Loss: 0.160426, Train Acc: 0.701282 | Val Loss: 0.172396, Val Acc: 0.680412\n",
      "Epoch 6028 - Train Loss: 0.160413, Train Acc: 0.701282 | Val Loss: 0.172384, Val Acc: 0.680412\n",
      "Epoch 6029 - Train Loss: 0.160400, Train Acc: 0.701282 | Val Loss: 0.172372, Val Acc: 0.680412\n",
      "Epoch 6030 - Train Loss: 0.160387, Train Acc: 0.702564 | Val Loss: 0.172360, Val Acc: 0.680412\n",
      "Epoch 6031 - Train Loss: 0.160374, Train Acc: 0.702564 | Val Loss: 0.172348, Val Acc: 0.680412\n",
      "Epoch 6032 - Train Loss: 0.160361, Train Acc: 0.702564 | Val Loss: 0.172336, Val Acc: 0.680412\n",
      "Epoch 6033 - Train Loss: 0.160347, Train Acc: 0.702564 | Val Loss: 0.172324, Val Acc: 0.680412\n",
      "Epoch 6034 - Train Loss: 0.160334, Train Acc: 0.702564 | Val Loss: 0.172312, Val Acc: 0.680412\n",
      "Epoch 6035 - Train Loss: 0.160321, Train Acc: 0.702564 | Val Loss: 0.172300, Val Acc: 0.680412\n",
      "Epoch 6036 - Train Loss: 0.160308, Train Acc: 0.702564 | Val Loss: 0.172288, Val Acc: 0.680412\n",
      "Epoch 6037 - Train Loss: 0.160295, Train Acc: 0.702564 | Val Loss: 0.172276, Val Acc: 0.690722\n",
      "Epoch 6038 - Train Loss: 0.160282, Train Acc: 0.702564 | Val Loss: 0.172264, Val Acc: 0.690722\n",
      "Epoch 6039 - Train Loss: 0.160268, Train Acc: 0.702564 | Val Loss: 0.172252, Val Acc: 0.690722\n",
      "Epoch 6040 - Train Loss: 0.160255, Train Acc: 0.702564 | Val Loss: 0.172240, Val Acc: 0.690722\n",
      "Epoch 6041 - Train Loss: 0.160242, Train Acc: 0.702564 | Val Loss: 0.172227, Val Acc: 0.690722\n",
      "Epoch 6042 - Train Loss: 0.160229, Train Acc: 0.702564 | Val Loss: 0.172215, Val Acc: 0.690722\n",
      "Epoch 6043 - Train Loss: 0.160216, Train Acc: 0.702564 | Val Loss: 0.172203, Val Acc: 0.690722\n",
      "Epoch 6044 - Train Loss: 0.160203, Train Acc: 0.705128 | Val Loss: 0.172191, Val Acc: 0.690722\n",
      "Epoch 6045 - Train Loss: 0.160190, Train Acc: 0.705128 | Val Loss: 0.172179, Val Acc: 0.690722\n",
      "Epoch 6046 - Train Loss: 0.160176, Train Acc: 0.705128 | Val Loss: 0.172167, Val Acc: 0.690722\n",
      "Epoch 6047 - Train Loss: 0.160163, Train Acc: 0.705128 | Val Loss: 0.172155, Val Acc: 0.690722\n",
      "Epoch 6048 - Train Loss: 0.160150, Train Acc: 0.705128 | Val Loss: 0.172143, Val Acc: 0.690722\n",
      "Epoch 6049 - Train Loss: 0.160137, Train Acc: 0.705128 | Val Loss: 0.172131, Val Acc: 0.690722\n",
      "Epoch 6050 - Train Loss: 0.160124, Train Acc: 0.705128 | Val Loss: 0.172119, Val Acc: 0.690722\n",
      "Epoch 6051 - Train Loss: 0.160111, Train Acc: 0.705128 | Val Loss: 0.172107, Val Acc: 0.690722\n",
      "Epoch 6052 - Train Loss: 0.160098, Train Acc: 0.705128 | Val Loss: 0.172095, Val Acc: 0.690722\n",
      "Epoch 6053 - Train Loss: 0.160084, Train Acc: 0.706410 | Val Loss: 0.172083, Val Acc: 0.690722\n",
      "Epoch 6054 - Train Loss: 0.160071, Train Acc: 0.706410 | Val Loss: 0.172071, Val Acc: 0.690722\n",
      "Epoch 6055 - Train Loss: 0.160058, Train Acc: 0.706410 | Val Loss: 0.172059, Val Acc: 0.690722\n",
      "Epoch 6056 - Train Loss: 0.160045, Train Acc: 0.706410 | Val Loss: 0.172047, Val Acc: 0.690722\n",
      "Epoch 6057 - Train Loss: 0.160032, Train Acc: 0.706410 | Val Loss: 0.172035, Val Acc: 0.690722\n",
      "Epoch 6058 - Train Loss: 0.160019, Train Acc: 0.706410 | Val Loss: 0.172023, Val Acc: 0.690722\n",
      "Epoch 6059 - Train Loss: 0.160006, Train Acc: 0.706410 | Val Loss: 0.172011, Val Acc: 0.690722\n",
      "Epoch 6060 - Train Loss: 0.159993, Train Acc: 0.706410 | Val Loss: 0.172000, Val Acc: 0.690722\n",
      "Epoch 6061 - Train Loss: 0.159979, Train Acc: 0.706410 | Val Loss: 0.171988, Val Acc: 0.690722\n",
      "Epoch 6062 - Train Loss: 0.159966, Train Acc: 0.706410 | Val Loss: 0.171976, Val Acc: 0.690722\n",
      "Epoch 6063 - Train Loss: 0.159953, Train Acc: 0.706410 | Val Loss: 0.171964, Val Acc: 0.690722\n",
      "Epoch 6064 - Train Loss: 0.159940, Train Acc: 0.706410 | Val Loss: 0.171952, Val Acc: 0.690722\n",
      "Epoch 6065 - Train Loss: 0.159927, Train Acc: 0.706410 | Val Loss: 0.171940, Val Acc: 0.690722\n",
      "Epoch 6066 - Train Loss: 0.159914, Train Acc: 0.706410 | Val Loss: 0.171928, Val Acc: 0.690722\n",
      "Epoch 6067 - Train Loss: 0.159901, Train Acc: 0.706410 | Val Loss: 0.171916, Val Acc: 0.690722\n",
      "Epoch 6068 - Train Loss: 0.159888, Train Acc: 0.706410 | Val Loss: 0.171904, Val Acc: 0.690722\n",
      "Epoch 6069 - Train Loss: 0.159875, Train Acc: 0.706410 | Val Loss: 0.171892, Val Acc: 0.690722\n",
      "Epoch 6070 - Train Loss: 0.159861, Train Acc: 0.706410 | Val Loss: 0.171880, Val Acc: 0.690722\n",
      "Epoch 6071 - Train Loss: 0.159848, Train Acc: 0.706410 | Val Loss: 0.171868, Val Acc: 0.690722\n",
      "Epoch 6072 - Train Loss: 0.159835, Train Acc: 0.706410 | Val Loss: 0.171856, Val Acc: 0.690722\n",
      "Epoch 6073 - Train Loss: 0.159822, Train Acc: 0.706410 | Val Loss: 0.171844, Val Acc: 0.690722\n",
      "Epoch 6074 - Train Loss: 0.159809, Train Acc: 0.706410 | Val Loss: 0.171832, Val Acc: 0.690722\n",
      "Epoch 6075 - Train Loss: 0.159796, Train Acc: 0.706410 | Val Loss: 0.171820, Val Acc: 0.690722\n",
      "Epoch 6076 - Train Loss: 0.159783, Train Acc: 0.706410 | Val Loss: 0.171808, Val Acc: 0.690722\n",
      "Epoch 6077 - Train Loss: 0.159770, Train Acc: 0.706410 | Val Loss: 0.171796, Val Acc: 0.690722\n",
      "Epoch 6078 - Train Loss: 0.159757, Train Acc: 0.706410 | Val Loss: 0.171784, Val Acc: 0.690722\n",
      "Epoch 6079 - Train Loss: 0.159744, Train Acc: 0.706410 | Val Loss: 0.171772, Val Acc: 0.690722\n",
      "Epoch 6080 - Train Loss: 0.159730, Train Acc: 0.706410 | Val Loss: 0.171760, Val Acc: 0.690722\n",
      "Epoch 6081 - Train Loss: 0.159717, Train Acc: 0.706410 | Val Loss: 0.171748, Val Acc: 0.690722\n",
      "Epoch 6082 - Train Loss: 0.159704, Train Acc: 0.706410 | Val Loss: 0.171736, Val Acc: 0.690722\n",
      "Epoch 6083 - Train Loss: 0.159691, Train Acc: 0.706410 | Val Loss: 0.171724, Val Acc: 0.690722\n",
      "Epoch 6084 - Train Loss: 0.159678, Train Acc: 0.706410 | Val Loss: 0.171712, Val Acc: 0.690722\n",
      "Epoch 6085 - Train Loss: 0.159665, Train Acc: 0.706410 | Val Loss: 0.171700, Val Acc: 0.690722\n",
      "Epoch 6086 - Train Loss: 0.159652, Train Acc: 0.706410 | Val Loss: 0.171688, Val Acc: 0.690722\n",
      "Epoch 6087 - Train Loss: 0.159639, Train Acc: 0.706410 | Val Loss: 0.171677, Val Acc: 0.690722\n",
      "Epoch 6088 - Train Loss: 0.159626, Train Acc: 0.706410 | Val Loss: 0.171665, Val Acc: 0.690722\n",
      "Epoch 6089 - Train Loss: 0.159613, Train Acc: 0.706410 | Val Loss: 0.171653, Val Acc: 0.690722\n",
      "Epoch 6090 - Train Loss: 0.159600, Train Acc: 0.706410 | Val Loss: 0.171641, Val Acc: 0.690722\n",
      "Epoch 6091 - Train Loss: 0.159586, Train Acc: 0.706410 | Val Loss: 0.171629, Val Acc: 0.690722\n",
      "Epoch 6092 - Train Loss: 0.159573, Train Acc: 0.706410 | Val Loss: 0.171617, Val Acc: 0.690722\n",
      "Epoch 6093 - Train Loss: 0.159560, Train Acc: 0.706410 | Val Loss: 0.171605, Val Acc: 0.690722\n",
      "Epoch 6094 - Train Loss: 0.159547, Train Acc: 0.706410 | Val Loss: 0.171593, Val Acc: 0.690722\n",
      "Epoch 6095 - Train Loss: 0.159534, Train Acc: 0.706410 | Val Loss: 0.171581, Val Acc: 0.690722\n",
      "Epoch 6096 - Train Loss: 0.159521, Train Acc: 0.706410 | Val Loss: 0.171569, Val Acc: 0.690722\n",
      "Epoch 6097 - Train Loss: 0.159508, Train Acc: 0.706410 | Val Loss: 0.171557, Val Acc: 0.690722\n",
      "Epoch 6098 - Train Loss: 0.159495, Train Acc: 0.706410 | Val Loss: 0.171545, Val Acc: 0.690722\n",
      "Epoch 6099 - Train Loss: 0.159482, Train Acc: 0.706410 | Val Loss: 0.171533, Val Acc: 0.690722\n",
      "Epoch 6100 - Train Loss: 0.159469, Train Acc: 0.706410 | Val Loss: 0.171521, Val Acc: 0.690722\n",
      "Epoch 6101 - Train Loss: 0.159456, Train Acc: 0.706410 | Val Loss: 0.171509, Val Acc: 0.690722\n",
      "Epoch 6102 - Train Loss: 0.159443, Train Acc: 0.706410 | Val Loss: 0.171497, Val Acc: 0.690722\n",
      "Epoch 6103 - Train Loss: 0.159430, Train Acc: 0.706410 | Val Loss: 0.171485, Val Acc: 0.690722\n",
      "Epoch 6104 - Train Loss: 0.159416, Train Acc: 0.706410 | Val Loss: 0.171473, Val Acc: 0.690722\n",
      "Epoch 6105 - Train Loss: 0.159403, Train Acc: 0.706410 | Val Loss: 0.171461, Val Acc: 0.690722\n",
      "Epoch 6106 - Train Loss: 0.159390, Train Acc: 0.706410 | Val Loss: 0.171450, Val Acc: 0.690722\n",
      "Epoch 6107 - Train Loss: 0.159377, Train Acc: 0.706410 | Val Loss: 0.171438, Val Acc: 0.690722\n",
      "Epoch 6108 - Train Loss: 0.159364, Train Acc: 0.706410 | Val Loss: 0.171426, Val Acc: 0.690722\n",
      "Epoch 6109 - Train Loss: 0.159351, Train Acc: 0.706410 | Val Loss: 0.171414, Val Acc: 0.690722\n",
      "Epoch 6110 - Train Loss: 0.159338, Train Acc: 0.706410 | Val Loss: 0.171402, Val Acc: 0.690722\n",
      "Epoch 6111 - Train Loss: 0.159325, Train Acc: 0.706410 | Val Loss: 0.171390, Val Acc: 0.690722\n",
      "Epoch 6112 - Train Loss: 0.159312, Train Acc: 0.706410 | Val Loss: 0.171378, Val Acc: 0.690722\n",
      "Epoch 6113 - Train Loss: 0.159299, Train Acc: 0.706410 | Val Loss: 0.171366, Val Acc: 0.690722\n",
      "Epoch 6114 - Train Loss: 0.159286, Train Acc: 0.706410 | Val Loss: 0.171354, Val Acc: 0.690722\n",
      "Epoch 6115 - Train Loss: 0.159273, Train Acc: 0.706410 | Val Loss: 0.171342, Val Acc: 0.690722\n",
      "Epoch 6116 - Train Loss: 0.159260, Train Acc: 0.706410 | Val Loss: 0.171330, Val Acc: 0.690722\n",
      "Epoch 6117 - Train Loss: 0.159247, Train Acc: 0.706410 | Val Loss: 0.171318, Val Acc: 0.690722\n",
      "Epoch 6118 - Train Loss: 0.159234, Train Acc: 0.706410 | Val Loss: 0.171307, Val Acc: 0.690722\n",
      "Epoch 6119 - Train Loss: 0.159221, Train Acc: 0.706410 | Val Loss: 0.171295, Val Acc: 0.690722\n",
      "Epoch 6120 - Train Loss: 0.159208, Train Acc: 0.706410 | Val Loss: 0.171283, Val Acc: 0.690722\n",
      "Epoch 6121 - Train Loss: 0.159195, Train Acc: 0.706410 | Val Loss: 0.171271, Val Acc: 0.690722\n",
      "Epoch 6122 - Train Loss: 0.159182, Train Acc: 0.707692 | Val Loss: 0.171259, Val Acc: 0.690722\n",
      "Epoch 6123 - Train Loss: 0.159168, Train Acc: 0.707692 | Val Loss: 0.171247, Val Acc: 0.690722\n",
      "Epoch 6124 - Train Loss: 0.159155, Train Acc: 0.707692 | Val Loss: 0.171235, Val Acc: 0.690722\n",
      "Epoch 6125 - Train Loss: 0.159142, Train Acc: 0.707692 | Val Loss: 0.171223, Val Acc: 0.690722\n",
      "Epoch 6126 - Train Loss: 0.159129, Train Acc: 0.707692 | Val Loss: 0.171211, Val Acc: 0.690722\n",
      "Epoch 6127 - Train Loss: 0.159116, Train Acc: 0.707692 | Val Loss: 0.171200, Val Acc: 0.690722\n",
      "Epoch 6128 - Train Loss: 0.159103, Train Acc: 0.707692 | Val Loss: 0.171188, Val Acc: 0.690722\n",
      "Epoch 6129 - Train Loss: 0.159090, Train Acc: 0.707692 | Val Loss: 0.171176, Val Acc: 0.690722\n",
      "Epoch 6130 - Train Loss: 0.159077, Train Acc: 0.707692 | Val Loss: 0.171164, Val Acc: 0.690722\n",
      "Epoch 6131 - Train Loss: 0.159064, Train Acc: 0.707692 | Val Loss: 0.171152, Val Acc: 0.690722\n",
      "Epoch 6132 - Train Loss: 0.159051, Train Acc: 0.707692 | Val Loss: 0.171140, Val Acc: 0.690722\n",
      "Epoch 6133 - Train Loss: 0.159038, Train Acc: 0.707692 | Val Loss: 0.171128, Val Acc: 0.690722\n",
      "Epoch 6134 - Train Loss: 0.159025, Train Acc: 0.707692 | Val Loss: 0.171116, Val Acc: 0.690722\n",
      "Epoch 6135 - Train Loss: 0.159012, Train Acc: 0.707692 | Val Loss: 0.171105, Val Acc: 0.690722\n",
      "Epoch 6136 - Train Loss: 0.158999, Train Acc: 0.707692 | Val Loss: 0.171093, Val Acc: 0.690722\n",
      "Epoch 6137 - Train Loss: 0.158986, Train Acc: 0.707692 | Val Loss: 0.171081, Val Acc: 0.690722\n",
      "Epoch 6138 - Train Loss: 0.158973, Train Acc: 0.708974 | Val Loss: 0.171069, Val Acc: 0.690722\n",
      "Epoch 6139 - Train Loss: 0.158960, Train Acc: 0.708974 | Val Loss: 0.171057, Val Acc: 0.690722\n",
      "Epoch 6140 - Train Loss: 0.158947, Train Acc: 0.708974 | Val Loss: 0.171045, Val Acc: 0.690722\n",
      "Epoch 6141 - Train Loss: 0.158934, Train Acc: 0.708974 | Val Loss: 0.171033, Val Acc: 0.690722\n",
      "Epoch 6142 - Train Loss: 0.158921, Train Acc: 0.708974 | Val Loss: 0.171021, Val Acc: 0.690722\n",
      "Epoch 6143 - Train Loss: 0.158908, Train Acc: 0.708974 | Val Loss: 0.171010, Val Acc: 0.690722\n",
      "Epoch 6144 - Train Loss: 0.158895, Train Acc: 0.708974 | Val Loss: 0.170998, Val Acc: 0.690722\n",
      "Epoch 6145 - Train Loss: 0.158882, Train Acc: 0.708974 | Val Loss: 0.170986, Val Acc: 0.690722\n",
      "Epoch 6146 - Train Loss: 0.158869, Train Acc: 0.708974 | Val Loss: 0.170974, Val Acc: 0.690722\n",
      "Epoch 6147 - Train Loss: 0.158856, Train Acc: 0.708974 | Val Loss: 0.170962, Val Acc: 0.690722\n",
      "Epoch 6148 - Train Loss: 0.158843, Train Acc: 0.708974 | Val Loss: 0.170950, Val Acc: 0.690722\n",
      "Epoch 6149 - Train Loss: 0.158830, Train Acc: 0.708974 | Val Loss: 0.170938, Val Acc: 0.690722\n",
      "Epoch 6150 - Train Loss: 0.158817, Train Acc: 0.708974 | Val Loss: 0.170926, Val Acc: 0.690722\n",
      "Epoch 6151 - Train Loss: 0.158804, Train Acc: 0.708974 | Val Loss: 0.170915, Val Acc: 0.690722\n",
      "Epoch 6152 - Train Loss: 0.158791, Train Acc: 0.708974 | Val Loss: 0.170903, Val Acc: 0.690722\n",
      "Epoch 6153 - Train Loss: 0.158778, Train Acc: 0.707692 | Val Loss: 0.170891, Val Acc: 0.690722\n",
      "Epoch 6154 - Train Loss: 0.158765, Train Acc: 0.707692 | Val Loss: 0.170879, Val Acc: 0.690722\n",
      "Epoch 6155 - Train Loss: 0.158752, Train Acc: 0.707692 | Val Loss: 0.170867, Val Acc: 0.690722\n",
      "Epoch 6156 - Train Loss: 0.158739, Train Acc: 0.707692 | Val Loss: 0.170855, Val Acc: 0.690722\n",
      "Epoch 6157 - Train Loss: 0.158726, Train Acc: 0.707692 | Val Loss: 0.170843, Val Acc: 0.690722\n",
      "Epoch 6158 - Train Loss: 0.158713, Train Acc: 0.708974 | Val Loss: 0.170832, Val Acc: 0.690722\n",
      "Epoch 6159 - Train Loss: 0.158700, Train Acc: 0.708974 | Val Loss: 0.170820, Val Acc: 0.690722\n",
      "Epoch 6160 - Train Loss: 0.158687, Train Acc: 0.708974 | Val Loss: 0.170808, Val Acc: 0.690722\n",
      "Epoch 6161 - Train Loss: 0.158674, Train Acc: 0.708974 | Val Loss: 0.170796, Val Acc: 0.690722\n",
      "Epoch 6162 - Train Loss: 0.158662, Train Acc: 0.710256 | Val Loss: 0.170784, Val Acc: 0.690722\n",
      "Epoch 6163 - Train Loss: 0.158649, Train Acc: 0.710256 | Val Loss: 0.170772, Val Acc: 0.690722\n",
      "Epoch 6164 - Train Loss: 0.158636, Train Acc: 0.710256 | Val Loss: 0.170760, Val Acc: 0.690722\n",
      "Epoch 6165 - Train Loss: 0.158623, Train Acc: 0.711538 | Val Loss: 0.170749, Val Acc: 0.690722\n",
      "Epoch 6166 - Train Loss: 0.158610, Train Acc: 0.711538 | Val Loss: 0.170737, Val Acc: 0.690722\n",
      "Epoch 6167 - Train Loss: 0.158597, Train Acc: 0.711538 | Val Loss: 0.170725, Val Acc: 0.690722\n",
      "Epoch 6168 - Train Loss: 0.158584, Train Acc: 0.711538 | Val Loss: 0.170713, Val Acc: 0.690722\n",
      "Epoch 6169 - Train Loss: 0.158571, Train Acc: 0.711538 | Val Loss: 0.170701, Val Acc: 0.690722\n",
      "Epoch 6170 - Train Loss: 0.158558, Train Acc: 0.711538 | Val Loss: 0.170689, Val Acc: 0.690722\n",
      "Epoch 6171 - Train Loss: 0.158545, Train Acc: 0.711538 | Val Loss: 0.170678, Val Acc: 0.690722\n",
      "Epoch 6172 - Train Loss: 0.158532, Train Acc: 0.711538 | Val Loss: 0.170666, Val Acc: 0.690722\n",
      "Epoch 6173 - Train Loss: 0.158519, Train Acc: 0.711538 | Val Loss: 0.170654, Val Acc: 0.690722\n",
      "Epoch 6174 - Train Loss: 0.158506, Train Acc: 0.711538 | Val Loss: 0.170642, Val Acc: 0.690722\n",
      "Epoch 6175 - Train Loss: 0.158493, Train Acc: 0.711538 | Val Loss: 0.170630, Val Acc: 0.690722\n",
      "Epoch 6176 - Train Loss: 0.158480, Train Acc: 0.711538 | Val Loss: 0.170618, Val Acc: 0.690722\n",
      "Epoch 6177 - Train Loss: 0.158467, Train Acc: 0.711538 | Val Loss: 0.170607, Val Acc: 0.690722\n",
      "Epoch 6178 - Train Loss: 0.158454, Train Acc: 0.711538 | Val Loss: 0.170595, Val Acc: 0.690722\n",
      "Epoch 6179 - Train Loss: 0.158441, Train Acc: 0.711538 | Val Loss: 0.170583, Val Acc: 0.690722\n",
      "Epoch 6180 - Train Loss: 0.158428, Train Acc: 0.711538 | Val Loss: 0.170571, Val Acc: 0.690722\n",
      "Epoch 6181 - Train Loss: 0.158416, Train Acc: 0.711538 | Val Loss: 0.170559, Val Acc: 0.690722\n",
      "Epoch 6182 - Train Loss: 0.158403, Train Acc: 0.711538 | Val Loss: 0.170547, Val Acc: 0.690722\n",
      "Epoch 6183 - Train Loss: 0.158390, Train Acc: 0.711538 | Val Loss: 0.170536, Val Acc: 0.690722\n",
      "Epoch 6184 - Train Loss: 0.158377, Train Acc: 0.711538 | Val Loss: 0.170524, Val Acc: 0.690722\n",
      "Epoch 6185 - Train Loss: 0.158364, Train Acc: 0.711538 | Val Loss: 0.170512, Val Acc: 0.690722\n",
      "Epoch 6186 - Train Loss: 0.158351, Train Acc: 0.712821 | Val Loss: 0.170500, Val Acc: 0.690722\n",
      "Epoch 6187 - Train Loss: 0.158338, Train Acc: 0.712821 | Val Loss: 0.170488, Val Acc: 0.690722\n",
      "Epoch 6188 - Train Loss: 0.158325, Train Acc: 0.712821 | Val Loss: 0.170477, Val Acc: 0.690722\n",
      "Epoch 6189 - Train Loss: 0.158312, Train Acc: 0.714103 | Val Loss: 0.170465, Val Acc: 0.690722\n",
      "Epoch 6190 - Train Loss: 0.158299, Train Acc: 0.714103 | Val Loss: 0.170453, Val Acc: 0.690722\n",
      "Epoch 6191 - Train Loss: 0.158286, Train Acc: 0.714103 | Val Loss: 0.170441, Val Acc: 0.690722\n",
      "Epoch 6192 - Train Loss: 0.158273, Train Acc: 0.714103 | Val Loss: 0.170429, Val Acc: 0.690722\n",
      "Epoch 6193 - Train Loss: 0.158260, Train Acc: 0.714103 | Val Loss: 0.170418, Val Acc: 0.690722\n",
      "Epoch 6194 - Train Loss: 0.158248, Train Acc: 0.714103 | Val Loss: 0.170406, Val Acc: 0.690722\n",
      "Epoch 6195 - Train Loss: 0.158235, Train Acc: 0.714103 | Val Loss: 0.170394, Val Acc: 0.690722\n",
      "Epoch 6196 - Train Loss: 0.158222, Train Acc: 0.714103 | Val Loss: 0.170382, Val Acc: 0.690722\n",
      "Epoch 6197 - Train Loss: 0.158209, Train Acc: 0.714103 | Val Loss: 0.170371, Val Acc: 0.690722\n",
      "Epoch 6198 - Train Loss: 0.158196, Train Acc: 0.714103 | Val Loss: 0.170359, Val Acc: 0.690722\n",
      "Epoch 6199 - Train Loss: 0.158183, Train Acc: 0.714103 | Val Loss: 0.170347, Val Acc: 0.690722\n",
      "Epoch 6200 - Train Loss: 0.158170, Train Acc: 0.714103 | Val Loss: 0.170335, Val Acc: 0.690722\n",
      "Epoch 6201 - Train Loss: 0.158157, Train Acc: 0.714103 | Val Loss: 0.170323, Val Acc: 0.690722\n",
      "Epoch 6202 - Train Loss: 0.158144, Train Acc: 0.714103 | Val Loss: 0.170312, Val Acc: 0.690722\n",
      "Epoch 6203 - Train Loss: 0.158131, Train Acc: 0.714103 | Val Loss: 0.170300, Val Acc: 0.690722\n",
      "Epoch 6204 - Train Loss: 0.158119, Train Acc: 0.714103 | Val Loss: 0.170288, Val Acc: 0.690722\n",
      "Epoch 6205 - Train Loss: 0.158106, Train Acc: 0.714103 | Val Loss: 0.170276, Val Acc: 0.690722\n",
      "Epoch 6206 - Train Loss: 0.158093, Train Acc: 0.714103 | Val Loss: 0.170265, Val Acc: 0.690722\n",
      "Epoch 6207 - Train Loss: 0.158080, Train Acc: 0.714103 | Val Loss: 0.170253, Val Acc: 0.690722\n",
      "Epoch 6208 - Train Loss: 0.158067, Train Acc: 0.714103 | Val Loss: 0.170241, Val Acc: 0.690722\n",
      "Epoch 6209 - Train Loss: 0.158054, Train Acc: 0.714103 | Val Loss: 0.170229, Val Acc: 0.690722\n",
      "Epoch 6210 - Train Loss: 0.158041, Train Acc: 0.714103 | Val Loss: 0.170218, Val Acc: 0.690722\n",
      "Epoch 6211 - Train Loss: 0.158028, Train Acc: 0.714103 | Val Loss: 0.170206, Val Acc: 0.690722\n",
      "Epoch 6212 - Train Loss: 0.158015, Train Acc: 0.714103 | Val Loss: 0.170194, Val Acc: 0.690722\n",
      "Epoch 6213 - Train Loss: 0.158003, Train Acc: 0.714103 | Val Loss: 0.170182, Val Acc: 0.690722\n",
      "Epoch 6214 - Train Loss: 0.157990, Train Acc: 0.714103 | Val Loss: 0.170171, Val Acc: 0.690722\n",
      "Epoch 6215 - Train Loss: 0.157977, Train Acc: 0.714103 | Val Loss: 0.170159, Val Acc: 0.690722\n",
      "Epoch 6216 - Train Loss: 0.157964, Train Acc: 0.714103 | Val Loss: 0.170147, Val Acc: 0.690722\n",
      "Epoch 6217 - Train Loss: 0.157951, Train Acc: 0.714103 | Val Loss: 0.170135, Val Acc: 0.690722\n",
      "Epoch 6218 - Train Loss: 0.157938, Train Acc: 0.714103 | Val Loss: 0.170124, Val Acc: 0.690722\n",
      "Epoch 6219 - Train Loss: 0.157925, Train Acc: 0.714103 | Val Loss: 0.170112, Val Acc: 0.690722\n",
      "Epoch 6220 - Train Loss: 0.157912, Train Acc: 0.714103 | Val Loss: 0.170100, Val Acc: 0.690722\n",
      "Epoch 6221 - Train Loss: 0.157900, Train Acc: 0.714103 | Val Loss: 0.170088, Val Acc: 0.690722\n",
      "Epoch 6222 - Train Loss: 0.157887, Train Acc: 0.714103 | Val Loss: 0.170077, Val Acc: 0.690722\n",
      "Epoch 6223 - Train Loss: 0.157874, Train Acc: 0.714103 | Val Loss: 0.170065, Val Acc: 0.690722\n",
      "Epoch 6224 - Train Loss: 0.157861, Train Acc: 0.714103 | Val Loss: 0.170053, Val Acc: 0.690722\n",
      "Epoch 6225 - Train Loss: 0.157848, Train Acc: 0.714103 | Val Loss: 0.170041, Val Acc: 0.690722\n",
      "Epoch 6226 - Train Loss: 0.157835, Train Acc: 0.714103 | Val Loss: 0.170030, Val Acc: 0.690722\n",
      "Epoch 6227 - Train Loss: 0.157822, Train Acc: 0.714103 | Val Loss: 0.170018, Val Acc: 0.690722\n",
      "Epoch 6228 - Train Loss: 0.157810, Train Acc: 0.714103 | Val Loss: 0.170006, Val Acc: 0.690722\n",
      "Epoch 6229 - Train Loss: 0.157797, Train Acc: 0.714103 | Val Loss: 0.169995, Val Acc: 0.690722\n",
      "Epoch 6230 - Train Loss: 0.157784, Train Acc: 0.714103 | Val Loss: 0.169983, Val Acc: 0.690722\n",
      "Epoch 6231 - Train Loss: 0.157771, Train Acc: 0.714103 | Val Loss: 0.169971, Val Acc: 0.690722\n",
      "Epoch 6232 - Train Loss: 0.157758, Train Acc: 0.714103 | Val Loss: 0.169959, Val Acc: 0.690722\n",
      "Epoch 6233 - Train Loss: 0.157745, Train Acc: 0.714103 | Val Loss: 0.169948, Val Acc: 0.690722\n",
      "Epoch 6234 - Train Loss: 0.157732, Train Acc: 0.714103 | Val Loss: 0.169936, Val Acc: 0.690722\n",
      "Epoch 6235 - Train Loss: 0.157720, Train Acc: 0.714103 | Val Loss: 0.169924, Val Acc: 0.690722\n",
      "Epoch 6236 - Train Loss: 0.157707, Train Acc: 0.714103 | Val Loss: 0.169913, Val Acc: 0.690722\n",
      "Epoch 6237 - Train Loss: 0.157694, Train Acc: 0.714103 | Val Loss: 0.169901, Val Acc: 0.690722\n",
      "Epoch 6238 - Train Loss: 0.157681, Train Acc: 0.714103 | Val Loss: 0.169889, Val Acc: 0.690722\n",
      "Epoch 6239 - Train Loss: 0.157668, Train Acc: 0.714103 | Val Loss: 0.169878, Val Acc: 0.690722\n",
      "Epoch 6240 - Train Loss: 0.157655, Train Acc: 0.715385 | Val Loss: 0.169866, Val Acc: 0.690722\n",
      "Epoch 6241 - Train Loss: 0.157643, Train Acc: 0.715385 | Val Loss: 0.169854, Val Acc: 0.690722\n",
      "Epoch 6242 - Train Loss: 0.157630, Train Acc: 0.715385 | Val Loss: 0.169843, Val Acc: 0.690722\n",
      "Epoch 6243 - Train Loss: 0.157617, Train Acc: 0.715385 | Val Loss: 0.169831, Val Acc: 0.690722\n",
      "Epoch 6244 - Train Loss: 0.157604, Train Acc: 0.715385 | Val Loss: 0.169819, Val Acc: 0.690722\n",
      "Epoch 6245 - Train Loss: 0.157591, Train Acc: 0.715385 | Val Loss: 0.169807, Val Acc: 0.690722\n",
      "Epoch 6246 - Train Loss: 0.157578, Train Acc: 0.715385 | Val Loss: 0.169796, Val Acc: 0.690722\n",
      "Epoch 6247 - Train Loss: 0.157566, Train Acc: 0.715385 | Val Loss: 0.169784, Val Acc: 0.690722\n",
      "Epoch 6248 - Train Loss: 0.157553, Train Acc: 0.715385 | Val Loss: 0.169772, Val Acc: 0.690722\n",
      "Epoch 6249 - Train Loss: 0.157540, Train Acc: 0.715385 | Val Loss: 0.169761, Val Acc: 0.690722\n",
      "Epoch 6250 - Train Loss: 0.157527, Train Acc: 0.715385 | Val Loss: 0.169749, Val Acc: 0.690722\n",
      "Epoch 6251 - Train Loss: 0.157514, Train Acc: 0.715385 | Val Loss: 0.169737, Val Acc: 0.690722\n",
      "Epoch 6252 - Train Loss: 0.157501, Train Acc: 0.715385 | Val Loss: 0.169726, Val Acc: 0.690722\n",
      "Epoch 6253 - Train Loss: 0.157489, Train Acc: 0.716667 | Val Loss: 0.169714, Val Acc: 0.690722\n",
      "Epoch 6254 - Train Loss: 0.157476, Train Acc: 0.716667 | Val Loss: 0.169702, Val Acc: 0.690722\n",
      "Epoch 6255 - Train Loss: 0.157463, Train Acc: 0.716667 | Val Loss: 0.169691, Val Acc: 0.690722\n",
      "Epoch 6256 - Train Loss: 0.157450, Train Acc: 0.716667 | Val Loss: 0.169679, Val Acc: 0.690722\n",
      "Epoch 6257 - Train Loss: 0.157437, Train Acc: 0.716667 | Val Loss: 0.169667, Val Acc: 0.690722\n",
      "Epoch 6258 - Train Loss: 0.157425, Train Acc: 0.716667 | Val Loss: 0.169656, Val Acc: 0.690722\n",
      "Epoch 6259 - Train Loss: 0.157412, Train Acc: 0.716667 | Val Loss: 0.169644, Val Acc: 0.690722\n",
      "Epoch 6260 - Train Loss: 0.157399, Train Acc: 0.716667 | Val Loss: 0.169632, Val Acc: 0.690722\n",
      "Epoch 6261 - Train Loss: 0.157386, Train Acc: 0.716667 | Val Loss: 0.169621, Val Acc: 0.690722\n",
      "Epoch 6262 - Train Loss: 0.157373, Train Acc: 0.716667 | Val Loss: 0.169609, Val Acc: 0.690722\n",
      "Epoch 6263 - Train Loss: 0.157361, Train Acc: 0.716667 | Val Loss: 0.169597, Val Acc: 0.690722\n",
      "Epoch 6264 - Train Loss: 0.157348, Train Acc: 0.716667 | Val Loss: 0.169586, Val Acc: 0.690722\n",
      "Epoch 6265 - Train Loss: 0.157335, Train Acc: 0.717949 | Val Loss: 0.169574, Val Acc: 0.690722\n",
      "Epoch 6266 - Train Loss: 0.157322, Train Acc: 0.717949 | Val Loss: 0.169562, Val Acc: 0.690722\n",
      "Epoch 6267 - Train Loss: 0.157309, Train Acc: 0.717949 | Val Loss: 0.169551, Val Acc: 0.690722\n",
      "Epoch 6268 - Train Loss: 0.157297, Train Acc: 0.717949 | Val Loss: 0.169539, Val Acc: 0.690722\n",
      "Epoch 6269 - Train Loss: 0.157284, Train Acc: 0.717949 | Val Loss: 0.169528, Val Acc: 0.690722\n",
      "Epoch 6270 - Train Loss: 0.157271, Train Acc: 0.717949 | Val Loss: 0.169516, Val Acc: 0.690722\n",
      "Epoch 6271 - Train Loss: 0.157258, Train Acc: 0.717949 | Val Loss: 0.169504, Val Acc: 0.690722\n",
      "Epoch 6272 - Train Loss: 0.157245, Train Acc: 0.717949 | Val Loss: 0.169493, Val Acc: 0.690722\n",
      "Epoch 6273 - Train Loss: 0.157233, Train Acc: 0.717949 | Val Loss: 0.169481, Val Acc: 0.690722\n",
      "Epoch 6274 - Train Loss: 0.157220, Train Acc: 0.717949 | Val Loss: 0.169469, Val Acc: 0.690722\n",
      "Epoch 6275 - Train Loss: 0.157207, Train Acc: 0.717949 | Val Loss: 0.169458, Val Acc: 0.690722\n",
      "Epoch 6276 - Train Loss: 0.157194, Train Acc: 0.717949 | Val Loss: 0.169446, Val Acc: 0.690722\n",
      "Epoch 6277 - Train Loss: 0.157181, Train Acc: 0.717949 | Val Loss: 0.169434, Val Acc: 0.690722\n",
      "Epoch 6278 - Train Loss: 0.157169, Train Acc: 0.717949 | Val Loss: 0.169423, Val Acc: 0.690722\n",
      "Epoch 6279 - Train Loss: 0.157156, Train Acc: 0.717949 | Val Loss: 0.169411, Val Acc: 0.690722\n",
      "Epoch 6280 - Train Loss: 0.157143, Train Acc: 0.717949 | Val Loss: 0.169400, Val Acc: 0.690722\n",
      "Epoch 6281 - Train Loss: 0.157130, Train Acc: 0.717949 | Val Loss: 0.169388, Val Acc: 0.690722\n",
      "Epoch 6282 - Train Loss: 0.157118, Train Acc: 0.717949 | Val Loss: 0.169376, Val Acc: 0.690722\n",
      "Epoch 6283 - Train Loss: 0.157105, Train Acc: 0.717949 | Val Loss: 0.169365, Val Acc: 0.690722\n",
      "Epoch 6284 - Train Loss: 0.157092, Train Acc: 0.717949 | Val Loss: 0.169353, Val Acc: 0.690722\n",
      "Epoch 6285 - Train Loss: 0.157079, Train Acc: 0.717949 | Val Loss: 0.169341, Val Acc: 0.690722\n",
      "Epoch 6286 - Train Loss: 0.157067, Train Acc: 0.719231 | Val Loss: 0.169330, Val Acc: 0.690722\n",
      "Epoch 6287 - Train Loss: 0.157054, Train Acc: 0.719231 | Val Loss: 0.169318, Val Acc: 0.690722\n",
      "Epoch 6288 - Train Loss: 0.157041, Train Acc: 0.719231 | Val Loss: 0.169307, Val Acc: 0.690722\n",
      "Epoch 6289 - Train Loss: 0.157028, Train Acc: 0.719231 | Val Loss: 0.169295, Val Acc: 0.690722\n",
      "Epoch 6290 - Train Loss: 0.157015, Train Acc: 0.719231 | Val Loss: 0.169283, Val Acc: 0.690722\n",
      "Epoch 6291 - Train Loss: 0.157003, Train Acc: 0.719231 | Val Loss: 0.169272, Val Acc: 0.690722\n",
      "Epoch 6292 - Train Loss: 0.156990, Train Acc: 0.720513 | Val Loss: 0.169260, Val Acc: 0.690722\n",
      "Epoch 6293 - Train Loss: 0.156977, Train Acc: 0.720513 | Val Loss: 0.169249, Val Acc: 0.690722\n",
      "Epoch 6294 - Train Loss: 0.156964, Train Acc: 0.720513 | Val Loss: 0.169237, Val Acc: 0.690722\n",
      "Epoch 6295 - Train Loss: 0.156952, Train Acc: 0.720513 | Val Loss: 0.169225, Val Acc: 0.690722\n",
      "Epoch 6296 - Train Loss: 0.156939, Train Acc: 0.720513 | Val Loss: 0.169214, Val Acc: 0.690722\n",
      "Epoch 6297 - Train Loss: 0.156926, Train Acc: 0.720513 | Val Loss: 0.169202, Val Acc: 0.690722\n",
      "Epoch 6298 - Train Loss: 0.156913, Train Acc: 0.720513 | Val Loss: 0.169190, Val Acc: 0.690722\n",
      "Epoch 6299 - Train Loss: 0.156901, Train Acc: 0.720513 | Val Loss: 0.169179, Val Acc: 0.690722\n",
      "Epoch 6300 - Train Loss: 0.156888, Train Acc: 0.721795 | Val Loss: 0.169167, Val Acc: 0.690722\n",
      "Epoch 6301 - Train Loss: 0.156875, Train Acc: 0.723077 | Val Loss: 0.169156, Val Acc: 0.690722\n",
      "Epoch 6302 - Train Loss: 0.156863, Train Acc: 0.723077 | Val Loss: 0.169144, Val Acc: 0.690722\n",
      "Epoch 6303 - Train Loss: 0.156850, Train Acc: 0.723077 | Val Loss: 0.169132, Val Acc: 0.690722\n",
      "Epoch 6304 - Train Loss: 0.156837, Train Acc: 0.723077 | Val Loss: 0.169121, Val Acc: 0.690722\n",
      "Epoch 6305 - Train Loss: 0.156824, Train Acc: 0.723077 | Val Loss: 0.169109, Val Acc: 0.690722\n",
      "Epoch 6306 - Train Loss: 0.156812, Train Acc: 0.723077 | Val Loss: 0.169098, Val Acc: 0.690722\n",
      "Epoch 6307 - Train Loss: 0.156799, Train Acc: 0.723077 | Val Loss: 0.169086, Val Acc: 0.690722\n",
      "Epoch 6308 - Train Loss: 0.156786, Train Acc: 0.723077 | Val Loss: 0.169074, Val Acc: 0.690722\n",
      "Epoch 6309 - Train Loss: 0.156773, Train Acc: 0.723077 | Val Loss: 0.169063, Val Acc: 0.690722\n",
      "Epoch 6310 - Train Loss: 0.156761, Train Acc: 0.723077 | Val Loss: 0.169051, Val Acc: 0.690722\n",
      "Epoch 6311 - Train Loss: 0.156748, Train Acc: 0.723077 | Val Loss: 0.169040, Val Acc: 0.690722\n",
      "Epoch 6312 - Train Loss: 0.156735, Train Acc: 0.724359 | Val Loss: 0.169028, Val Acc: 0.690722\n",
      "Epoch 6313 - Train Loss: 0.156722, Train Acc: 0.724359 | Val Loss: 0.169016, Val Acc: 0.690722\n",
      "Epoch 6314 - Train Loss: 0.156710, Train Acc: 0.724359 | Val Loss: 0.169005, Val Acc: 0.690722\n",
      "Epoch 6315 - Train Loss: 0.156697, Train Acc: 0.724359 | Val Loss: 0.168993, Val Acc: 0.690722\n",
      "Epoch 6316 - Train Loss: 0.156684, Train Acc: 0.725641 | Val Loss: 0.168982, Val Acc: 0.690722\n",
      "Epoch 6317 - Train Loss: 0.156672, Train Acc: 0.725641 | Val Loss: 0.168970, Val Acc: 0.690722\n",
      "Epoch 6318 - Train Loss: 0.156659, Train Acc: 0.725641 | Val Loss: 0.168958, Val Acc: 0.690722\n",
      "Epoch 6319 - Train Loss: 0.156646, Train Acc: 0.725641 | Val Loss: 0.168947, Val Acc: 0.690722\n",
      "Epoch 6320 - Train Loss: 0.156633, Train Acc: 0.725641 | Val Loss: 0.168935, Val Acc: 0.690722\n",
      "Epoch 6321 - Train Loss: 0.156621, Train Acc: 0.725641 | Val Loss: 0.168924, Val Acc: 0.690722\n",
      "Epoch 6322 - Train Loss: 0.156608, Train Acc: 0.725641 | Val Loss: 0.168912, Val Acc: 0.690722\n",
      "Epoch 6323 - Train Loss: 0.156595, Train Acc: 0.725641 | Val Loss: 0.168900, Val Acc: 0.690722\n",
      "Epoch 6324 - Train Loss: 0.156583, Train Acc: 0.725641 | Val Loss: 0.168889, Val Acc: 0.690722\n",
      "Epoch 6325 - Train Loss: 0.156570, Train Acc: 0.725641 | Val Loss: 0.168877, Val Acc: 0.690722\n",
      "Epoch 6326 - Train Loss: 0.156557, Train Acc: 0.725641 | Val Loss: 0.168866, Val Acc: 0.690722\n",
      "Epoch 6327 - Train Loss: 0.156544, Train Acc: 0.725641 | Val Loss: 0.168854, Val Acc: 0.690722\n",
      "Epoch 6328 - Train Loss: 0.156532, Train Acc: 0.725641 | Val Loss: 0.168843, Val Acc: 0.690722\n",
      "Epoch 6329 - Train Loss: 0.156519, Train Acc: 0.725641 | Val Loss: 0.168831, Val Acc: 0.690722\n",
      "Epoch 6330 - Train Loss: 0.156506, Train Acc: 0.725641 | Val Loss: 0.168819, Val Acc: 0.690722\n",
      "Epoch 6331 - Train Loss: 0.156494, Train Acc: 0.725641 | Val Loss: 0.168808, Val Acc: 0.690722\n",
      "Epoch 6332 - Train Loss: 0.156481, Train Acc: 0.725641 | Val Loss: 0.168796, Val Acc: 0.690722\n",
      "Epoch 6333 - Train Loss: 0.156468, Train Acc: 0.725641 | Val Loss: 0.168785, Val Acc: 0.690722\n",
      "Epoch 6334 - Train Loss: 0.156456, Train Acc: 0.725641 | Val Loss: 0.168773, Val Acc: 0.690722\n",
      "Epoch 6335 - Train Loss: 0.156443, Train Acc: 0.725641 | Val Loss: 0.168762, Val Acc: 0.690722\n",
      "Epoch 6336 - Train Loss: 0.156430, Train Acc: 0.725641 | Val Loss: 0.168750, Val Acc: 0.690722\n",
      "Epoch 6337 - Train Loss: 0.156418, Train Acc: 0.725641 | Val Loss: 0.168739, Val Acc: 0.690722\n",
      "Epoch 6338 - Train Loss: 0.156405, Train Acc: 0.725641 | Val Loss: 0.168727, Val Acc: 0.690722\n",
      "Epoch 6339 - Train Loss: 0.156392, Train Acc: 0.725641 | Val Loss: 0.168715, Val Acc: 0.690722\n",
      "Epoch 6340 - Train Loss: 0.156379, Train Acc: 0.725641 | Val Loss: 0.168704, Val Acc: 0.690722\n",
      "Epoch 6341 - Train Loss: 0.156367, Train Acc: 0.725641 | Val Loss: 0.168692, Val Acc: 0.690722\n",
      "Epoch 6342 - Train Loss: 0.156354, Train Acc: 0.725641 | Val Loss: 0.168681, Val Acc: 0.690722\n",
      "Epoch 6343 - Train Loss: 0.156341, Train Acc: 0.725641 | Val Loss: 0.168669, Val Acc: 0.690722\n",
      "Epoch 6344 - Train Loss: 0.156329, Train Acc: 0.725641 | Val Loss: 0.168658, Val Acc: 0.690722\n",
      "Epoch 6345 - Train Loss: 0.156316, Train Acc: 0.725641 | Val Loss: 0.168646, Val Acc: 0.690722\n",
      "Epoch 6346 - Train Loss: 0.156303, Train Acc: 0.725641 | Val Loss: 0.168635, Val Acc: 0.690722\n",
      "Epoch 6347 - Train Loss: 0.156291, Train Acc: 0.725641 | Val Loss: 0.168623, Val Acc: 0.690722\n",
      "Epoch 6348 - Train Loss: 0.156278, Train Acc: 0.725641 | Val Loss: 0.168611, Val Acc: 0.690722\n",
      "Epoch 6349 - Train Loss: 0.156265, Train Acc: 0.725641 | Val Loss: 0.168600, Val Acc: 0.690722\n",
      "Epoch 6350 - Train Loss: 0.156253, Train Acc: 0.725641 | Val Loss: 0.168588, Val Acc: 0.690722\n",
      "Epoch 6351 - Train Loss: 0.156240, Train Acc: 0.725641 | Val Loss: 0.168577, Val Acc: 0.690722\n",
      "Epoch 6352 - Train Loss: 0.156227, Train Acc: 0.725641 | Val Loss: 0.168565, Val Acc: 0.690722\n",
      "Epoch 6353 - Train Loss: 0.156215, Train Acc: 0.725641 | Val Loss: 0.168554, Val Acc: 0.690722\n",
      "Epoch 6354 - Train Loss: 0.156202, Train Acc: 0.725641 | Val Loss: 0.168542, Val Acc: 0.690722\n",
      "Epoch 6355 - Train Loss: 0.156189, Train Acc: 0.725641 | Val Loss: 0.168531, Val Acc: 0.690722\n",
      "Epoch 6356 - Train Loss: 0.156177, Train Acc: 0.725641 | Val Loss: 0.168519, Val Acc: 0.690722\n",
      "Epoch 6357 - Train Loss: 0.156164, Train Acc: 0.725641 | Val Loss: 0.168508, Val Acc: 0.690722\n",
      "Epoch 6358 - Train Loss: 0.156152, Train Acc: 0.725641 | Val Loss: 0.168496, Val Acc: 0.690722\n",
      "Epoch 6359 - Train Loss: 0.156139, Train Acc: 0.725641 | Val Loss: 0.168485, Val Acc: 0.690722\n",
      "Epoch 6360 - Train Loss: 0.156126, Train Acc: 0.725641 | Val Loss: 0.168473, Val Acc: 0.690722\n",
      "Epoch 6361 - Train Loss: 0.156114, Train Acc: 0.725641 | Val Loss: 0.168462, Val Acc: 0.690722\n",
      "Epoch 6362 - Train Loss: 0.156101, Train Acc: 0.725641 | Val Loss: 0.168450, Val Acc: 0.690722\n",
      "Epoch 6363 - Train Loss: 0.156088, Train Acc: 0.725641 | Val Loss: 0.168439, Val Acc: 0.690722\n",
      "Epoch 6364 - Train Loss: 0.156076, Train Acc: 0.725641 | Val Loss: 0.168427, Val Acc: 0.690722\n",
      "Epoch 6365 - Train Loss: 0.156063, Train Acc: 0.725641 | Val Loss: 0.168416, Val Acc: 0.690722\n",
      "Epoch 6366 - Train Loss: 0.156050, Train Acc: 0.725641 | Val Loss: 0.168404, Val Acc: 0.690722\n",
      "Epoch 6367 - Train Loss: 0.156038, Train Acc: 0.725641 | Val Loss: 0.168393, Val Acc: 0.690722\n",
      "Epoch 6368 - Train Loss: 0.156025, Train Acc: 0.725641 | Val Loss: 0.168381, Val Acc: 0.690722\n",
      "Epoch 6369 - Train Loss: 0.156012, Train Acc: 0.725641 | Val Loss: 0.168370, Val Acc: 0.690722\n",
      "Epoch 6370 - Train Loss: 0.156000, Train Acc: 0.725641 | Val Loss: 0.168358, Val Acc: 0.690722\n",
      "Epoch 6371 - Train Loss: 0.155987, Train Acc: 0.725641 | Val Loss: 0.168347, Val Acc: 0.690722\n",
      "Epoch 6372 - Train Loss: 0.155975, Train Acc: 0.725641 | Val Loss: 0.168335, Val Acc: 0.690722\n",
      "Epoch 6373 - Train Loss: 0.155962, Train Acc: 0.725641 | Val Loss: 0.168324, Val Acc: 0.690722\n",
      "Epoch 6374 - Train Loss: 0.155949, Train Acc: 0.725641 | Val Loss: 0.168312, Val Acc: 0.690722\n",
      "Epoch 6375 - Train Loss: 0.155937, Train Acc: 0.725641 | Val Loss: 0.168301, Val Acc: 0.690722\n",
      "Epoch 6376 - Train Loss: 0.155924, Train Acc: 0.725641 | Val Loss: 0.168289, Val Acc: 0.690722\n",
      "Epoch 6377 - Train Loss: 0.155912, Train Acc: 0.725641 | Val Loss: 0.168278, Val Acc: 0.690722\n",
      "Epoch 6378 - Train Loss: 0.155899, Train Acc: 0.725641 | Val Loss: 0.168266, Val Acc: 0.690722\n",
      "Epoch 6379 - Train Loss: 0.155886, Train Acc: 0.725641 | Val Loss: 0.168255, Val Acc: 0.690722\n",
      "Epoch 6380 - Train Loss: 0.155874, Train Acc: 0.725641 | Val Loss: 0.168243, Val Acc: 0.690722\n",
      "Epoch 6381 - Train Loss: 0.155861, Train Acc: 0.725641 | Val Loss: 0.168232, Val Acc: 0.690722\n",
      "Epoch 6382 - Train Loss: 0.155848, Train Acc: 0.725641 | Val Loss: 0.168220, Val Acc: 0.690722\n",
      "Epoch 6383 - Train Loss: 0.155836, Train Acc: 0.725641 | Val Loss: 0.168209, Val Acc: 0.690722\n",
      "Epoch 6384 - Train Loss: 0.155823, Train Acc: 0.725641 | Val Loss: 0.168198, Val Acc: 0.690722\n",
      "Epoch 6385 - Train Loss: 0.155811, Train Acc: 0.725641 | Val Loss: 0.168186, Val Acc: 0.690722\n",
      "Epoch 6386 - Train Loss: 0.155798, Train Acc: 0.725641 | Val Loss: 0.168175, Val Acc: 0.690722\n",
      "Epoch 6387 - Train Loss: 0.155785, Train Acc: 0.725641 | Val Loss: 0.168163, Val Acc: 0.690722\n",
      "Epoch 6388 - Train Loss: 0.155773, Train Acc: 0.725641 | Val Loss: 0.168152, Val Acc: 0.690722\n",
      "Epoch 6389 - Train Loss: 0.155760, Train Acc: 0.725641 | Val Loss: 0.168140, Val Acc: 0.690722\n",
      "Epoch 6390 - Train Loss: 0.155748, Train Acc: 0.725641 | Val Loss: 0.168129, Val Acc: 0.690722\n",
      "Epoch 6391 - Train Loss: 0.155735, Train Acc: 0.725641 | Val Loss: 0.168117, Val Acc: 0.690722\n",
      "Epoch 6392 - Train Loss: 0.155723, Train Acc: 0.725641 | Val Loss: 0.168106, Val Acc: 0.690722\n",
      "Epoch 6393 - Train Loss: 0.155710, Train Acc: 0.725641 | Val Loss: 0.168094, Val Acc: 0.690722\n",
      "Epoch 6394 - Train Loss: 0.155697, Train Acc: 0.725641 | Val Loss: 0.168083, Val Acc: 0.690722\n",
      "Epoch 6395 - Train Loss: 0.155685, Train Acc: 0.725641 | Val Loss: 0.168072, Val Acc: 0.690722\n",
      "Epoch 6396 - Train Loss: 0.155672, Train Acc: 0.725641 | Val Loss: 0.168060, Val Acc: 0.690722\n",
      "Epoch 6397 - Train Loss: 0.155660, Train Acc: 0.725641 | Val Loss: 0.168049, Val Acc: 0.690722\n",
      "Epoch 6398 - Train Loss: 0.155647, Train Acc: 0.725641 | Val Loss: 0.168037, Val Acc: 0.690722\n",
      "Epoch 6399 - Train Loss: 0.155634, Train Acc: 0.725641 | Val Loss: 0.168026, Val Acc: 0.690722\n",
      "Epoch 6400 - Train Loss: 0.155622, Train Acc: 0.725641 | Val Loss: 0.168014, Val Acc: 0.690722\n",
      "Epoch 6401 - Train Loss: 0.155609, Train Acc: 0.725641 | Val Loss: 0.168003, Val Acc: 0.690722\n",
      "Epoch 6402 - Train Loss: 0.155597, Train Acc: 0.725641 | Val Loss: 0.167991, Val Acc: 0.690722\n",
      "Epoch 6403 - Train Loss: 0.155584, Train Acc: 0.725641 | Val Loss: 0.167980, Val Acc: 0.690722\n",
      "Epoch 6404 - Train Loss: 0.155572, Train Acc: 0.725641 | Val Loss: 0.167969, Val Acc: 0.690722\n",
      "Epoch 6405 - Train Loss: 0.155559, Train Acc: 0.725641 | Val Loss: 0.167957, Val Acc: 0.690722\n",
      "Epoch 6406 - Train Loss: 0.155546, Train Acc: 0.725641 | Val Loss: 0.167946, Val Acc: 0.690722\n",
      "Epoch 6407 - Train Loss: 0.155534, Train Acc: 0.725641 | Val Loss: 0.167934, Val Acc: 0.690722\n",
      "Epoch 6408 - Train Loss: 0.155521, Train Acc: 0.725641 | Val Loss: 0.167923, Val Acc: 0.690722\n",
      "Epoch 6409 - Train Loss: 0.155509, Train Acc: 0.724359 | Val Loss: 0.167911, Val Acc: 0.690722\n",
      "Epoch 6410 - Train Loss: 0.155496, Train Acc: 0.724359 | Val Loss: 0.167900, Val Acc: 0.690722\n",
      "Epoch 6411 - Train Loss: 0.155484, Train Acc: 0.724359 | Val Loss: 0.167889, Val Acc: 0.690722\n",
      "Epoch 6412 - Train Loss: 0.155471, Train Acc: 0.724359 | Val Loss: 0.167877, Val Acc: 0.690722\n",
      "Epoch 6413 - Train Loss: 0.155459, Train Acc: 0.724359 | Val Loss: 0.167866, Val Acc: 0.690722\n",
      "Epoch 6414 - Train Loss: 0.155446, Train Acc: 0.724359 | Val Loss: 0.167854, Val Acc: 0.690722\n",
      "Epoch 6415 - Train Loss: 0.155433, Train Acc: 0.724359 | Val Loss: 0.167843, Val Acc: 0.690722\n",
      "Epoch 6416 - Train Loss: 0.155421, Train Acc: 0.724359 | Val Loss: 0.167831, Val Acc: 0.690722\n",
      "Epoch 6417 - Train Loss: 0.155408, Train Acc: 0.724359 | Val Loss: 0.167820, Val Acc: 0.690722\n",
      "Epoch 6418 - Train Loss: 0.155396, Train Acc: 0.724359 | Val Loss: 0.167809, Val Acc: 0.690722\n",
      "Epoch 6419 - Train Loss: 0.155383, Train Acc: 0.724359 | Val Loss: 0.167797, Val Acc: 0.690722\n",
      "Epoch 6420 - Train Loss: 0.155371, Train Acc: 0.724359 | Val Loss: 0.167786, Val Acc: 0.690722\n",
      "Epoch 6421 - Train Loss: 0.155358, Train Acc: 0.724359 | Val Loss: 0.167774, Val Acc: 0.690722\n",
      "Epoch 6422 - Train Loss: 0.155346, Train Acc: 0.724359 | Val Loss: 0.167763, Val Acc: 0.690722\n",
      "Epoch 6423 - Train Loss: 0.155333, Train Acc: 0.725641 | Val Loss: 0.167752, Val Acc: 0.690722\n",
      "Epoch 6424 - Train Loss: 0.155321, Train Acc: 0.725641 | Val Loss: 0.167740, Val Acc: 0.690722\n",
      "Epoch 6425 - Train Loss: 0.155308, Train Acc: 0.725641 | Val Loss: 0.167729, Val Acc: 0.690722\n",
      "Epoch 6426 - Train Loss: 0.155295, Train Acc: 0.725641 | Val Loss: 0.167717, Val Acc: 0.690722\n",
      "Epoch 6427 - Train Loss: 0.155283, Train Acc: 0.725641 | Val Loss: 0.167706, Val Acc: 0.690722\n",
      "Epoch 6428 - Train Loss: 0.155270, Train Acc: 0.725641 | Val Loss: 0.167695, Val Acc: 0.690722\n",
      "Epoch 6429 - Train Loss: 0.155258, Train Acc: 0.725641 | Val Loss: 0.167683, Val Acc: 0.690722\n",
      "Epoch 6430 - Train Loss: 0.155245, Train Acc: 0.725641 | Val Loss: 0.167672, Val Acc: 0.690722\n",
      "Epoch 6431 - Train Loss: 0.155233, Train Acc: 0.725641 | Val Loss: 0.167660, Val Acc: 0.690722\n",
      "Epoch 6432 - Train Loss: 0.155220, Train Acc: 0.725641 | Val Loss: 0.167649, Val Acc: 0.690722\n",
      "Epoch 6433 - Train Loss: 0.155208, Train Acc: 0.725641 | Val Loss: 0.167638, Val Acc: 0.690722\n",
      "Epoch 6434 - Train Loss: 0.155195, Train Acc: 0.725641 | Val Loss: 0.167626, Val Acc: 0.690722\n",
      "Epoch 6435 - Train Loss: 0.155183, Train Acc: 0.726923 | Val Loss: 0.167615, Val Acc: 0.690722\n",
      "Epoch 6436 - Train Loss: 0.155170, Train Acc: 0.726923 | Val Loss: 0.167603, Val Acc: 0.690722\n",
      "Epoch 6437 - Train Loss: 0.155158, Train Acc: 0.726923 | Val Loss: 0.167592, Val Acc: 0.690722\n",
      "Epoch 6438 - Train Loss: 0.155145, Train Acc: 0.726923 | Val Loss: 0.167581, Val Acc: 0.690722\n",
      "Epoch 6439 - Train Loss: 0.155133, Train Acc: 0.726923 | Val Loss: 0.167569, Val Acc: 0.690722\n",
      "Epoch 6440 - Train Loss: 0.155120, Train Acc: 0.726923 | Val Loss: 0.167558, Val Acc: 0.690722\n",
      "Epoch 6441 - Train Loss: 0.155108, Train Acc: 0.726923 | Val Loss: 0.167547, Val Acc: 0.690722\n",
      "Epoch 6442 - Train Loss: 0.155095, Train Acc: 0.726923 | Val Loss: 0.167535, Val Acc: 0.690722\n",
      "Epoch 6443 - Train Loss: 0.155083, Train Acc: 0.726923 | Val Loss: 0.167524, Val Acc: 0.690722\n",
      "Epoch 6444 - Train Loss: 0.155070, Train Acc: 0.726923 | Val Loss: 0.167512, Val Acc: 0.690722\n",
      "Epoch 6445 - Train Loss: 0.155058, Train Acc: 0.726923 | Val Loss: 0.167501, Val Acc: 0.690722\n",
      "Epoch 6446 - Train Loss: 0.155045, Train Acc: 0.726923 | Val Loss: 0.167490, Val Acc: 0.690722\n",
      "Epoch 6447 - Train Loss: 0.155033, Train Acc: 0.726923 | Val Loss: 0.167478, Val Acc: 0.690722\n",
      "Epoch 6448 - Train Loss: 0.155020, Train Acc: 0.726923 | Val Loss: 0.167467, Val Acc: 0.690722\n",
      "Epoch 6449 - Train Loss: 0.155008, Train Acc: 0.726923 | Val Loss: 0.167456, Val Acc: 0.690722\n",
      "Epoch 6450 - Train Loss: 0.154995, Train Acc: 0.726923 | Val Loss: 0.167444, Val Acc: 0.690722\n",
      "Epoch 6451 - Train Loss: 0.154983, Train Acc: 0.726923 | Val Loss: 0.167433, Val Acc: 0.690722\n",
      "Epoch 6452 - Train Loss: 0.154970, Train Acc: 0.726923 | Val Loss: 0.167422, Val Acc: 0.690722\n",
      "Epoch 6453 - Train Loss: 0.154958, Train Acc: 0.726923 | Val Loss: 0.167410, Val Acc: 0.690722\n",
      "Epoch 6454 - Train Loss: 0.154945, Train Acc: 0.726923 | Val Loss: 0.167399, Val Acc: 0.690722\n",
      "Epoch 6455 - Train Loss: 0.154933, Train Acc: 0.726923 | Val Loss: 0.167387, Val Acc: 0.690722\n",
      "Epoch 6456 - Train Loss: 0.154920, Train Acc: 0.726923 | Val Loss: 0.167376, Val Acc: 0.690722\n",
      "Epoch 6457 - Train Loss: 0.154908, Train Acc: 0.726923 | Val Loss: 0.167365, Val Acc: 0.690722\n",
      "Epoch 6458 - Train Loss: 0.154895, Train Acc: 0.726923 | Val Loss: 0.167353, Val Acc: 0.690722\n",
      "Epoch 6459 - Train Loss: 0.154883, Train Acc: 0.726923 | Val Loss: 0.167342, Val Acc: 0.690722\n",
      "Epoch 6460 - Train Loss: 0.154870, Train Acc: 0.726923 | Val Loss: 0.167331, Val Acc: 0.690722\n",
      "Epoch 6461 - Train Loss: 0.154858, Train Acc: 0.726923 | Val Loss: 0.167319, Val Acc: 0.690722\n",
      "Epoch 6462 - Train Loss: 0.154845, Train Acc: 0.726923 | Val Loss: 0.167308, Val Acc: 0.690722\n",
      "Epoch 6463 - Train Loss: 0.154833, Train Acc: 0.726923 | Val Loss: 0.167297, Val Acc: 0.690722\n",
      "Epoch 6464 - Train Loss: 0.154820, Train Acc: 0.726923 | Val Loss: 0.167285, Val Acc: 0.690722\n",
      "Epoch 6465 - Train Loss: 0.154808, Train Acc: 0.726923 | Val Loss: 0.167274, Val Acc: 0.690722\n",
      "Epoch 6466 - Train Loss: 0.154795, Train Acc: 0.726923 | Val Loss: 0.167263, Val Acc: 0.690722\n",
      "Epoch 6467 - Train Loss: 0.154783, Train Acc: 0.726923 | Val Loss: 0.167251, Val Acc: 0.690722\n",
      "Epoch 6468 - Train Loss: 0.154771, Train Acc: 0.726923 | Val Loss: 0.167240, Val Acc: 0.690722\n",
      "Epoch 6469 - Train Loss: 0.154758, Train Acc: 0.726923 | Val Loss: 0.167229, Val Acc: 0.690722\n",
      "Epoch 6470 - Train Loss: 0.154746, Train Acc: 0.726923 | Val Loss: 0.167217, Val Acc: 0.690722\n",
      "Epoch 6471 - Train Loss: 0.154733, Train Acc: 0.726923 | Val Loss: 0.167206, Val Acc: 0.690722\n",
      "Epoch 6472 - Train Loss: 0.154721, Train Acc: 0.726923 | Val Loss: 0.167195, Val Acc: 0.690722\n",
      "Epoch 6473 - Train Loss: 0.154708, Train Acc: 0.726923 | Val Loss: 0.167183, Val Acc: 0.690722\n",
      "Epoch 6474 - Train Loss: 0.154696, Train Acc: 0.726923 | Val Loss: 0.167172, Val Acc: 0.690722\n",
      "Epoch 6475 - Train Loss: 0.154683, Train Acc: 0.726923 | Val Loss: 0.167161, Val Acc: 0.690722\n",
      "Epoch 6476 - Train Loss: 0.154671, Train Acc: 0.726923 | Val Loss: 0.167150, Val Acc: 0.690722\n",
      "Epoch 6477 - Train Loss: 0.154658, Train Acc: 0.726923 | Val Loss: 0.167138, Val Acc: 0.690722\n",
      "Epoch 6478 - Train Loss: 0.154646, Train Acc: 0.726923 | Val Loss: 0.167127, Val Acc: 0.690722\n",
      "Epoch 6479 - Train Loss: 0.154633, Train Acc: 0.726923 | Val Loss: 0.167116, Val Acc: 0.690722\n",
      "Epoch 6480 - Train Loss: 0.154621, Train Acc: 0.726923 | Val Loss: 0.167104, Val Acc: 0.690722\n",
      "Epoch 6481 - Train Loss: 0.154609, Train Acc: 0.726923 | Val Loss: 0.167093, Val Acc: 0.690722\n",
      "Epoch 6482 - Train Loss: 0.154596, Train Acc: 0.726923 | Val Loss: 0.167082, Val Acc: 0.690722\n",
      "Epoch 6483 - Train Loss: 0.154584, Train Acc: 0.726923 | Val Loss: 0.167070, Val Acc: 0.690722\n",
      "Epoch 6484 - Train Loss: 0.154571, Train Acc: 0.726923 | Val Loss: 0.167059, Val Acc: 0.690722\n",
      "Epoch 6485 - Train Loss: 0.154559, Train Acc: 0.726923 | Val Loss: 0.167048, Val Acc: 0.690722\n",
      "Epoch 6486 - Train Loss: 0.154546, Train Acc: 0.726923 | Val Loss: 0.167037, Val Acc: 0.690722\n",
      "Epoch 6487 - Train Loss: 0.154534, Train Acc: 0.726923 | Val Loss: 0.167025, Val Acc: 0.690722\n",
      "Epoch 6488 - Train Loss: 0.154522, Train Acc: 0.726923 | Val Loss: 0.167014, Val Acc: 0.690722\n",
      "Epoch 6489 - Train Loss: 0.154509, Train Acc: 0.726923 | Val Loss: 0.167003, Val Acc: 0.690722\n",
      "Epoch 6490 - Train Loss: 0.154497, Train Acc: 0.726923 | Val Loss: 0.166991, Val Acc: 0.690722\n",
      "Epoch 6491 - Train Loss: 0.154484, Train Acc: 0.726923 | Val Loss: 0.166980, Val Acc: 0.690722\n",
      "Epoch 6492 - Train Loss: 0.154472, Train Acc: 0.726923 | Val Loss: 0.166969, Val Acc: 0.690722\n",
      "Epoch 6493 - Train Loss: 0.154459, Train Acc: 0.726923 | Val Loss: 0.166957, Val Acc: 0.690722\n",
      "Epoch 6494 - Train Loss: 0.154447, Train Acc: 0.726923 | Val Loss: 0.166946, Val Acc: 0.690722\n",
      "Epoch 6495 - Train Loss: 0.154435, Train Acc: 0.726923 | Val Loss: 0.166935, Val Acc: 0.690722\n",
      "Epoch 6496 - Train Loss: 0.154422, Train Acc: 0.726923 | Val Loss: 0.166924, Val Acc: 0.690722\n",
      "Epoch 6497 - Train Loss: 0.154410, Train Acc: 0.726923 | Val Loss: 0.166912, Val Acc: 0.690722\n",
      "Epoch 6498 - Train Loss: 0.154397, Train Acc: 0.726923 | Val Loss: 0.166901, Val Acc: 0.690722\n",
      "Epoch 6499 - Train Loss: 0.154385, Train Acc: 0.726923 | Val Loss: 0.166890, Val Acc: 0.690722\n",
      "Epoch 6500 - Train Loss: 0.154372, Train Acc: 0.726923 | Val Loss: 0.166879, Val Acc: 0.690722\n",
      "Epoch 6501 - Train Loss: 0.154360, Train Acc: 0.726923 | Val Loss: 0.166867, Val Acc: 0.690722\n",
      "Epoch 6502 - Train Loss: 0.154348, Train Acc: 0.726923 | Val Loss: 0.166856, Val Acc: 0.690722\n",
      "Epoch 6503 - Train Loss: 0.154335, Train Acc: 0.728205 | Val Loss: 0.166845, Val Acc: 0.690722\n",
      "Epoch 6504 - Train Loss: 0.154323, Train Acc: 0.728205 | Val Loss: 0.166834, Val Acc: 0.690722\n",
      "Epoch 6505 - Train Loss: 0.154310, Train Acc: 0.728205 | Val Loss: 0.166822, Val Acc: 0.690722\n",
      "Epoch 6506 - Train Loss: 0.154298, Train Acc: 0.728205 | Val Loss: 0.166811, Val Acc: 0.690722\n",
      "Epoch 6507 - Train Loss: 0.154286, Train Acc: 0.728205 | Val Loss: 0.166800, Val Acc: 0.690722\n",
      "Epoch 6508 - Train Loss: 0.154273, Train Acc: 0.728205 | Val Loss: 0.166788, Val Acc: 0.690722\n",
      "Epoch 6509 - Train Loss: 0.154261, Train Acc: 0.728205 | Val Loss: 0.166777, Val Acc: 0.690722\n",
      "Epoch 6510 - Train Loss: 0.154248, Train Acc: 0.728205 | Val Loss: 0.166766, Val Acc: 0.690722\n",
      "Epoch 6511 - Train Loss: 0.154236, Train Acc: 0.728205 | Val Loss: 0.166755, Val Acc: 0.690722\n",
      "Epoch 6512 - Train Loss: 0.154224, Train Acc: 0.728205 | Val Loss: 0.166743, Val Acc: 0.690722\n",
      "Epoch 6513 - Train Loss: 0.154211, Train Acc: 0.728205 | Val Loss: 0.166732, Val Acc: 0.690722\n",
      "Epoch 6514 - Train Loss: 0.154199, Train Acc: 0.728205 | Val Loss: 0.166721, Val Acc: 0.690722\n",
      "Epoch 6515 - Train Loss: 0.154186, Train Acc: 0.728205 | Val Loss: 0.166710, Val Acc: 0.690722\n",
      "Epoch 6516 - Train Loss: 0.154174, Train Acc: 0.728205 | Val Loss: 0.166698, Val Acc: 0.690722\n",
      "Epoch 6517 - Train Loss: 0.154162, Train Acc: 0.728205 | Val Loss: 0.166687, Val Acc: 0.690722\n",
      "Epoch 6518 - Train Loss: 0.154149, Train Acc: 0.728205 | Val Loss: 0.166676, Val Acc: 0.690722\n",
      "Epoch 6519 - Train Loss: 0.154137, Train Acc: 0.728205 | Val Loss: 0.166665, Val Acc: 0.690722\n",
      "Epoch 6520 - Train Loss: 0.154124, Train Acc: 0.728205 | Val Loss: 0.166654, Val Acc: 0.690722\n",
      "Epoch 6521 - Train Loss: 0.154112, Train Acc: 0.728205 | Val Loss: 0.166642, Val Acc: 0.690722\n",
      "Epoch 6522 - Train Loss: 0.154100, Train Acc: 0.728205 | Val Loss: 0.166631, Val Acc: 0.690722\n",
      "Epoch 6523 - Train Loss: 0.154087, Train Acc: 0.728205 | Val Loss: 0.166620, Val Acc: 0.690722\n",
      "Epoch 6524 - Train Loss: 0.154075, Train Acc: 0.728205 | Val Loss: 0.166609, Val Acc: 0.690722\n",
      "Epoch 6525 - Train Loss: 0.154063, Train Acc: 0.728205 | Val Loss: 0.166597, Val Acc: 0.690722\n",
      "Epoch 6526 - Train Loss: 0.154050, Train Acc: 0.728205 | Val Loss: 0.166586, Val Acc: 0.701031\n",
      "Epoch 6527 - Train Loss: 0.154038, Train Acc: 0.726923 | Val Loss: 0.166575, Val Acc: 0.701031\n",
      "Epoch 6528 - Train Loss: 0.154025, Train Acc: 0.726923 | Val Loss: 0.166564, Val Acc: 0.701031\n",
      "Epoch 6529 - Train Loss: 0.154013, Train Acc: 0.726923 | Val Loss: 0.166552, Val Acc: 0.701031\n",
      "Epoch 6530 - Train Loss: 0.154001, Train Acc: 0.726923 | Val Loss: 0.166541, Val Acc: 0.701031\n",
      "Epoch 6531 - Train Loss: 0.153988, Train Acc: 0.728205 | Val Loss: 0.166530, Val Acc: 0.701031\n",
      "Epoch 6532 - Train Loss: 0.153976, Train Acc: 0.728205 | Val Loss: 0.166519, Val Acc: 0.701031\n",
      "Epoch 6533 - Train Loss: 0.153964, Train Acc: 0.728205 | Val Loss: 0.166508, Val Acc: 0.701031\n",
      "Epoch 6534 - Train Loss: 0.153951, Train Acc: 0.728205 | Val Loss: 0.166496, Val Acc: 0.701031\n",
      "Epoch 6535 - Train Loss: 0.153939, Train Acc: 0.729487 | Val Loss: 0.166485, Val Acc: 0.701031\n",
      "Epoch 6536 - Train Loss: 0.153927, Train Acc: 0.729487 | Val Loss: 0.166474, Val Acc: 0.701031\n",
      "Epoch 6537 - Train Loss: 0.153914, Train Acc: 0.729487 | Val Loss: 0.166463, Val Acc: 0.701031\n",
      "Epoch 6538 - Train Loss: 0.153902, Train Acc: 0.729487 | Val Loss: 0.166452, Val Acc: 0.701031\n",
      "Epoch 6539 - Train Loss: 0.153890, Train Acc: 0.729487 | Val Loss: 0.166440, Val Acc: 0.701031\n",
      "Epoch 6540 - Train Loss: 0.153877, Train Acc: 0.729487 | Val Loss: 0.166429, Val Acc: 0.701031\n",
      "Epoch 6541 - Train Loss: 0.153865, Train Acc: 0.729487 | Val Loss: 0.166418, Val Acc: 0.701031\n",
      "Epoch 6542 - Train Loss: 0.153852, Train Acc: 0.729487 | Val Loss: 0.166407, Val Acc: 0.701031\n",
      "Epoch 6543 - Train Loss: 0.153840, Train Acc: 0.729487 | Val Loss: 0.166396, Val Acc: 0.701031\n",
      "Epoch 6544 - Train Loss: 0.153828, Train Acc: 0.729487 | Val Loss: 0.166384, Val Acc: 0.701031\n",
      "Epoch 6545 - Train Loss: 0.153815, Train Acc: 0.729487 | Val Loss: 0.166373, Val Acc: 0.701031\n",
      "Epoch 6546 - Train Loss: 0.153803, Train Acc: 0.729487 | Val Loss: 0.166362, Val Acc: 0.701031\n",
      "Epoch 6547 - Train Loss: 0.153791, Train Acc: 0.729487 | Val Loss: 0.166351, Val Acc: 0.701031\n",
      "Epoch 6548 - Train Loss: 0.153778, Train Acc: 0.729487 | Val Loss: 0.166340, Val Acc: 0.701031\n",
      "Epoch 6549 - Train Loss: 0.153766, Train Acc: 0.729487 | Val Loss: 0.166328, Val Acc: 0.701031\n",
      "Epoch 6550 - Train Loss: 0.153754, Train Acc: 0.729487 | Val Loss: 0.166317, Val Acc: 0.701031\n",
      "Epoch 6551 - Train Loss: 0.153741, Train Acc: 0.729487 | Val Loss: 0.166306, Val Acc: 0.701031\n",
      "Epoch 6552 - Train Loss: 0.153729, Train Acc: 0.729487 | Val Loss: 0.166295, Val Acc: 0.701031\n",
      "Epoch 6553 - Train Loss: 0.153717, Train Acc: 0.729487 | Val Loss: 0.166284, Val Acc: 0.701031\n",
      "Epoch 6554 - Train Loss: 0.153704, Train Acc: 0.729487 | Val Loss: 0.166272, Val Acc: 0.701031\n",
      "Epoch 6555 - Train Loss: 0.153692, Train Acc: 0.729487 | Val Loss: 0.166261, Val Acc: 0.701031\n",
      "Epoch 6556 - Train Loss: 0.153680, Train Acc: 0.729487 | Val Loss: 0.166250, Val Acc: 0.701031\n",
      "Epoch 6557 - Train Loss: 0.153667, Train Acc: 0.729487 | Val Loss: 0.166239, Val Acc: 0.701031\n",
      "Epoch 6558 - Train Loss: 0.153655, Train Acc: 0.729487 | Val Loss: 0.166227, Val Acc: 0.701031\n",
      "Epoch 6559 - Train Loss: 0.153643, Train Acc: 0.729487 | Val Loss: 0.166216, Val Acc: 0.701031\n",
      "Epoch 6560 - Train Loss: 0.153630, Train Acc: 0.729487 | Val Loss: 0.166205, Val Acc: 0.701031\n",
      "Epoch 6561 - Train Loss: 0.153618, Train Acc: 0.729487 | Val Loss: 0.166194, Val Acc: 0.701031\n",
      "Epoch 6562 - Train Loss: 0.153606, Train Acc: 0.729487 | Val Loss: 0.166183, Val Acc: 0.701031\n",
      "Epoch 6563 - Train Loss: 0.153593, Train Acc: 0.729487 | Val Loss: 0.166171, Val Acc: 0.701031\n",
      "Epoch 6564 - Train Loss: 0.153581, Train Acc: 0.729487 | Val Loss: 0.166160, Val Acc: 0.701031\n",
      "Epoch 6565 - Train Loss: 0.153569, Train Acc: 0.729487 | Val Loss: 0.166149, Val Acc: 0.701031\n",
      "Epoch 6566 - Train Loss: 0.153556, Train Acc: 0.729487 | Val Loss: 0.166138, Val Acc: 0.701031\n",
      "Epoch 6567 - Train Loss: 0.153544, Train Acc: 0.729487 | Val Loss: 0.166127, Val Acc: 0.701031\n",
      "Epoch 6568 - Train Loss: 0.153532, Train Acc: 0.729487 | Val Loss: 0.166115, Val Acc: 0.701031\n",
      "Epoch 6569 - Train Loss: 0.153520, Train Acc: 0.729487 | Val Loss: 0.166104, Val Acc: 0.701031\n",
      "Epoch 6570 - Train Loss: 0.153507, Train Acc: 0.729487 | Val Loss: 0.166093, Val Acc: 0.701031\n",
      "Epoch 6571 - Train Loss: 0.153495, Train Acc: 0.729487 | Val Loss: 0.166082, Val Acc: 0.701031\n",
      "Epoch 6572 - Train Loss: 0.153483, Train Acc: 0.729487 | Val Loss: 0.166071, Val Acc: 0.701031\n",
      "Epoch 6573 - Train Loss: 0.153470, Train Acc: 0.729487 | Val Loss: 0.166060, Val Acc: 0.701031\n",
      "Epoch 6574 - Train Loss: 0.153458, Train Acc: 0.729487 | Val Loss: 0.166048, Val Acc: 0.701031\n",
      "Epoch 6575 - Train Loss: 0.153446, Train Acc: 0.729487 | Val Loss: 0.166037, Val Acc: 0.701031\n",
      "Epoch 6576 - Train Loss: 0.153433, Train Acc: 0.729487 | Val Loss: 0.166026, Val Acc: 0.701031\n",
      "Epoch 6577 - Train Loss: 0.153421, Train Acc: 0.729487 | Val Loss: 0.166015, Val Acc: 0.701031\n",
      "Epoch 6578 - Train Loss: 0.153409, Train Acc: 0.729487 | Val Loss: 0.166004, Val Acc: 0.701031\n",
      "Epoch 6579 - Train Loss: 0.153396, Train Acc: 0.729487 | Val Loss: 0.165993, Val Acc: 0.701031\n",
      "Epoch 6580 - Train Loss: 0.153384, Train Acc: 0.729487 | Val Loss: 0.165981, Val Acc: 0.701031\n",
      "Epoch 6581 - Train Loss: 0.153372, Train Acc: 0.729487 | Val Loss: 0.165970, Val Acc: 0.701031\n",
      "Epoch 6582 - Train Loss: 0.153360, Train Acc: 0.729487 | Val Loss: 0.165959, Val Acc: 0.701031\n",
      "Epoch 6583 - Train Loss: 0.153347, Train Acc: 0.729487 | Val Loss: 0.165948, Val Acc: 0.701031\n",
      "Epoch 6584 - Train Loss: 0.153335, Train Acc: 0.729487 | Val Loss: 0.165937, Val Acc: 0.701031\n",
      "Epoch 6585 - Train Loss: 0.153323, Train Acc: 0.729487 | Val Loss: 0.165926, Val Acc: 0.701031\n",
      "Epoch 6586 - Train Loss: 0.153310, Train Acc: 0.729487 | Val Loss: 0.165914, Val Acc: 0.701031\n",
      "Epoch 6587 - Train Loss: 0.153298, Train Acc: 0.729487 | Val Loss: 0.165903, Val Acc: 0.701031\n",
      "Epoch 6588 - Train Loss: 0.153286, Train Acc: 0.729487 | Val Loss: 0.165892, Val Acc: 0.701031\n",
      "Epoch 6589 - Train Loss: 0.153274, Train Acc: 0.729487 | Val Loss: 0.165881, Val Acc: 0.701031\n",
      "Epoch 6590 - Train Loss: 0.153261, Train Acc: 0.729487 | Val Loss: 0.165870, Val Acc: 0.701031\n",
      "Epoch 6591 - Train Loss: 0.153249, Train Acc: 0.729487 | Val Loss: 0.165859, Val Acc: 0.701031\n",
      "Epoch 6592 - Train Loss: 0.153237, Train Acc: 0.729487 | Val Loss: 0.165848, Val Acc: 0.701031\n",
      "Epoch 6593 - Train Loss: 0.153225, Train Acc: 0.730769 | Val Loss: 0.165836, Val Acc: 0.701031\n",
      "Epoch 6594 - Train Loss: 0.153212, Train Acc: 0.730769 | Val Loss: 0.165825, Val Acc: 0.701031\n",
      "Epoch 6595 - Train Loss: 0.153200, Train Acc: 0.730769 | Val Loss: 0.165814, Val Acc: 0.701031\n",
      "Epoch 6596 - Train Loss: 0.153188, Train Acc: 0.730769 | Val Loss: 0.165803, Val Acc: 0.701031\n",
      "Epoch 6597 - Train Loss: 0.153175, Train Acc: 0.730769 | Val Loss: 0.165792, Val Acc: 0.701031\n",
      "Epoch 6598 - Train Loss: 0.153163, Train Acc: 0.730769 | Val Loss: 0.165781, Val Acc: 0.701031\n",
      "Epoch 6599 - Train Loss: 0.153151, Train Acc: 0.730769 | Val Loss: 0.165770, Val Acc: 0.701031\n",
      "Epoch 6600 - Train Loss: 0.153139, Train Acc: 0.730769 | Val Loss: 0.165758, Val Acc: 0.701031\n",
      "Epoch 6601 - Train Loss: 0.153126, Train Acc: 0.730769 | Val Loss: 0.165747, Val Acc: 0.701031\n",
      "Epoch 6602 - Train Loss: 0.153114, Train Acc: 0.730769 | Val Loss: 0.165736, Val Acc: 0.701031\n",
      "Epoch 6603 - Train Loss: 0.153102, Train Acc: 0.730769 | Val Loss: 0.165725, Val Acc: 0.701031\n",
      "Epoch 6604 - Train Loss: 0.153090, Train Acc: 0.730769 | Val Loss: 0.165714, Val Acc: 0.701031\n",
      "Epoch 6605 - Train Loss: 0.153077, Train Acc: 0.730769 | Val Loss: 0.165703, Val Acc: 0.701031\n",
      "Epoch 6606 - Train Loss: 0.153065, Train Acc: 0.730769 | Val Loss: 0.165692, Val Acc: 0.701031\n",
      "Epoch 6607 - Train Loss: 0.153053, Train Acc: 0.730769 | Val Loss: 0.165681, Val Acc: 0.701031\n",
      "Epoch 6608 - Train Loss: 0.153041, Train Acc: 0.730769 | Val Loss: 0.165670, Val Acc: 0.701031\n",
      "Epoch 6609 - Train Loss: 0.153028, Train Acc: 0.730769 | Val Loss: 0.165658, Val Acc: 0.701031\n",
      "Epoch 6610 - Train Loss: 0.153016, Train Acc: 0.730769 | Val Loss: 0.165647, Val Acc: 0.701031\n",
      "Epoch 6611 - Train Loss: 0.153004, Train Acc: 0.730769 | Val Loss: 0.165636, Val Acc: 0.701031\n",
      "Epoch 6612 - Train Loss: 0.152992, Train Acc: 0.730769 | Val Loss: 0.165625, Val Acc: 0.701031\n",
      "Epoch 6613 - Train Loss: 0.152979, Train Acc: 0.730769 | Val Loss: 0.165614, Val Acc: 0.701031\n",
      "Epoch 6614 - Train Loss: 0.152967, Train Acc: 0.730769 | Val Loss: 0.165603, Val Acc: 0.701031\n",
      "Epoch 6615 - Train Loss: 0.152955, Train Acc: 0.730769 | Val Loss: 0.165592, Val Acc: 0.701031\n",
      "Epoch 6616 - Train Loss: 0.152943, Train Acc: 0.730769 | Val Loss: 0.165581, Val Acc: 0.701031\n",
      "Epoch 6617 - Train Loss: 0.152930, Train Acc: 0.730769 | Val Loss: 0.165570, Val Acc: 0.701031\n",
      "Epoch 6618 - Train Loss: 0.152918, Train Acc: 0.730769 | Val Loss: 0.165559, Val Acc: 0.701031\n",
      "Epoch 6619 - Train Loss: 0.152906, Train Acc: 0.730769 | Val Loss: 0.165548, Val Acc: 0.701031\n",
      "Epoch 6620 - Train Loss: 0.152894, Train Acc: 0.730769 | Val Loss: 0.165536, Val Acc: 0.701031\n",
      "Epoch 6621 - Train Loss: 0.152882, Train Acc: 0.730769 | Val Loss: 0.165525, Val Acc: 0.701031\n",
      "Epoch 6622 - Train Loss: 0.152869, Train Acc: 0.730769 | Val Loss: 0.165514, Val Acc: 0.701031\n",
      "Epoch 6623 - Train Loss: 0.152857, Train Acc: 0.730769 | Val Loss: 0.165503, Val Acc: 0.701031\n",
      "Epoch 6624 - Train Loss: 0.152845, Train Acc: 0.730769 | Val Loss: 0.165492, Val Acc: 0.701031\n",
      "Epoch 6625 - Train Loss: 0.152833, Train Acc: 0.730769 | Val Loss: 0.165481, Val Acc: 0.701031\n",
      "Epoch 6626 - Train Loss: 0.152820, Train Acc: 0.730769 | Val Loss: 0.165470, Val Acc: 0.701031\n",
      "Epoch 6627 - Train Loss: 0.152808, Train Acc: 0.730769 | Val Loss: 0.165459, Val Acc: 0.701031\n",
      "Epoch 6628 - Train Loss: 0.152796, Train Acc: 0.730769 | Val Loss: 0.165448, Val Acc: 0.701031\n",
      "Epoch 6629 - Train Loss: 0.152784, Train Acc: 0.730769 | Val Loss: 0.165437, Val Acc: 0.701031\n",
      "Epoch 6630 - Train Loss: 0.152772, Train Acc: 0.730769 | Val Loss: 0.165426, Val Acc: 0.701031\n",
      "Epoch 6631 - Train Loss: 0.152759, Train Acc: 0.730769 | Val Loss: 0.165415, Val Acc: 0.701031\n",
      "Epoch 6632 - Train Loss: 0.152747, Train Acc: 0.730769 | Val Loss: 0.165404, Val Acc: 0.701031\n",
      "Epoch 6633 - Train Loss: 0.152735, Train Acc: 0.730769 | Val Loss: 0.165392, Val Acc: 0.701031\n",
      "Epoch 6634 - Train Loss: 0.152723, Train Acc: 0.730769 | Val Loss: 0.165381, Val Acc: 0.701031\n",
      "Epoch 6635 - Train Loss: 0.152711, Train Acc: 0.730769 | Val Loss: 0.165370, Val Acc: 0.701031\n",
      "Epoch 6636 - Train Loss: 0.152698, Train Acc: 0.730769 | Val Loss: 0.165359, Val Acc: 0.701031\n",
      "Epoch 6637 - Train Loss: 0.152686, Train Acc: 0.730769 | Val Loss: 0.165348, Val Acc: 0.701031\n",
      "Epoch 6638 - Train Loss: 0.152674, Train Acc: 0.730769 | Val Loss: 0.165337, Val Acc: 0.701031\n",
      "Epoch 6639 - Train Loss: 0.152662, Train Acc: 0.730769 | Val Loss: 0.165326, Val Acc: 0.701031\n",
      "Epoch 6640 - Train Loss: 0.152650, Train Acc: 0.730769 | Val Loss: 0.165315, Val Acc: 0.701031\n",
      "Epoch 6641 - Train Loss: 0.152637, Train Acc: 0.730769 | Val Loss: 0.165304, Val Acc: 0.701031\n",
      "Epoch 6642 - Train Loss: 0.152625, Train Acc: 0.730769 | Val Loss: 0.165293, Val Acc: 0.701031\n",
      "Epoch 6643 - Train Loss: 0.152613, Train Acc: 0.730769 | Val Loss: 0.165282, Val Acc: 0.701031\n",
      "Epoch 6644 - Train Loss: 0.152601, Train Acc: 0.730769 | Val Loss: 0.165271, Val Acc: 0.701031\n",
      "Epoch 6645 - Train Loss: 0.152589, Train Acc: 0.730769 | Val Loss: 0.165260, Val Acc: 0.701031\n",
      "Epoch 6646 - Train Loss: 0.152576, Train Acc: 0.730769 | Val Loss: 0.165249, Val Acc: 0.701031\n",
      "Epoch 6647 - Train Loss: 0.152564, Train Acc: 0.730769 | Val Loss: 0.165237, Val Acc: 0.701031\n",
      "Epoch 6648 - Train Loss: 0.152552, Train Acc: 0.730769 | Val Loss: 0.165226, Val Acc: 0.701031\n",
      "Epoch 6649 - Train Loss: 0.152540, Train Acc: 0.730769 | Val Loss: 0.165215, Val Acc: 0.701031\n",
      "Epoch 6650 - Train Loss: 0.152528, Train Acc: 0.732051 | Val Loss: 0.165204, Val Acc: 0.701031\n",
      "Epoch 6651 - Train Loss: 0.152515, Train Acc: 0.732051 | Val Loss: 0.165193, Val Acc: 0.701031\n",
      "Epoch 6652 - Train Loss: 0.152503, Train Acc: 0.732051 | Val Loss: 0.165182, Val Acc: 0.701031\n",
      "Epoch 6653 - Train Loss: 0.152491, Train Acc: 0.732051 | Val Loss: 0.165171, Val Acc: 0.701031\n",
      "Epoch 6654 - Train Loss: 0.152479, Train Acc: 0.732051 | Val Loss: 0.165160, Val Acc: 0.701031\n",
      "Epoch 6655 - Train Loss: 0.152467, Train Acc: 0.732051 | Val Loss: 0.165149, Val Acc: 0.701031\n",
      "Epoch 6656 - Train Loss: 0.152455, Train Acc: 0.732051 | Val Loss: 0.165138, Val Acc: 0.701031\n",
      "Epoch 6657 - Train Loss: 0.152442, Train Acc: 0.732051 | Val Loss: 0.165127, Val Acc: 0.701031\n",
      "Epoch 6658 - Train Loss: 0.152430, Train Acc: 0.732051 | Val Loss: 0.165116, Val Acc: 0.701031\n",
      "Epoch 6659 - Train Loss: 0.152418, Train Acc: 0.732051 | Val Loss: 0.165105, Val Acc: 0.701031\n",
      "Epoch 6660 - Train Loss: 0.152406, Train Acc: 0.732051 | Val Loss: 0.165094, Val Acc: 0.701031\n",
      "Epoch 6661 - Train Loss: 0.152394, Train Acc: 0.732051 | Val Loss: 0.165083, Val Acc: 0.701031\n",
      "Epoch 6662 - Train Loss: 0.152382, Train Acc: 0.732051 | Val Loss: 0.165072, Val Acc: 0.701031\n",
      "Epoch 6663 - Train Loss: 0.152369, Train Acc: 0.732051 | Val Loss: 0.165061, Val Acc: 0.701031\n",
      "Epoch 6664 - Train Loss: 0.152357, Train Acc: 0.732051 | Val Loss: 0.165050, Val Acc: 0.701031\n",
      "Epoch 6665 - Train Loss: 0.152345, Train Acc: 0.732051 | Val Loss: 0.165039, Val Acc: 0.701031\n",
      "Epoch 6666 - Train Loss: 0.152333, Train Acc: 0.732051 | Val Loss: 0.165027, Val Acc: 0.701031\n",
      "Epoch 6667 - Train Loss: 0.152321, Train Acc: 0.732051 | Val Loss: 0.165016, Val Acc: 0.701031\n",
      "Epoch 6668 - Train Loss: 0.152309, Train Acc: 0.732051 | Val Loss: 0.165005, Val Acc: 0.701031\n",
      "Epoch 6669 - Train Loss: 0.152296, Train Acc: 0.732051 | Val Loss: 0.164994, Val Acc: 0.701031\n",
      "Epoch 6670 - Train Loss: 0.152284, Train Acc: 0.732051 | Val Loss: 0.164983, Val Acc: 0.701031\n",
      "Epoch 6671 - Train Loss: 0.152272, Train Acc: 0.732051 | Val Loss: 0.164972, Val Acc: 0.701031\n",
      "Epoch 6672 - Train Loss: 0.152260, Train Acc: 0.732051 | Val Loss: 0.164961, Val Acc: 0.701031\n",
      "Epoch 6673 - Train Loss: 0.152248, Train Acc: 0.732051 | Val Loss: 0.164950, Val Acc: 0.701031\n",
      "Epoch 6674 - Train Loss: 0.152236, Train Acc: 0.732051 | Val Loss: 0.164939, Val Acc: 0.701031\n",
      "Epoch 6675 - Train Loss: 0.152224, Train Acc: 0.732051 | Val Loss: 0.164928, Val Acc: 0.701031\n",
      "Epoch 6676 - Train Loss: 0.152211, Train Acc: 0.732051 | Val Loss: 0.164917, Val Acc: 0.701031\n",
      "Epoch 6677 - Train Loss: 0.152199, Train Acc: 0.732051 | Val Loss: 0.164906, Val Acc: 0.701031\n",
      "Epoch 6678 - Train Loss: 0.152187, Train Acc: 0.732051 | Val Loss: 0.164895, Val Acc: 0.701031\n",
      "Epoch 6679 - Train Loss: 0.152175, Train Acc: 0.732051 | Val Loss: 0.164884, Val Acc: 0.701031\n",
      "Epoch 6680 - Train Loss: 0.152163, Train Acc: 0.732051 | Val Loss: 0.164873, Val Acc: 0.701031\n",
      "Epoch 6681 - Train Loss: 0.152151, Train Acc: 0.732051 | Val Loss: 0.164862, Val Acc: 0.701031\n",
      "Epoch 6682 - Train Loss: 0.152139, Train Acc: 0.732051 | Val Loss: 0.164851, Val Acc: 0.701031\n",
      "Epoch 6683 - Train Loss: 0.152126, Train Acc: 0.732051 | Val Loss: 0.164840, Val Acc: 0.701031\n",
      "Epoch 6684 - Train Loss: 0.152114, Train Acc: 0.732051 | Val Loss: 0.164829, Val Acc: 0.701031\n",
      "Epoch 6685 - Train Loss: 0.152102, Train Acc: 0.732051 | Val Loss: 0.164818, Val Acc: 0.701031\n",
      "Epoch 6686 - Train Loss: 0.152090, Train Acc: 0.732051 | Val Loss: 0.164807, Val Acc: 0.701031\n",
      "Epoch 6687 - Train Loss: 0.152078, Train Acc: 0.732051 | Val Loss: 0.164796, Val Acc: 0.701031\n",
      "Epoch 6688 - Train Loss: 0.152066, Train Acc: 0.732051 | Val Loss: 0.164785, Val Acc: 0.701031\n",
      "Epoch 6689 - Train Loss: 0.152054, Train Acc: 0.732051 | Val Loss: 0.164774, Val Acc: 0.701031\n",
      "Epoch 6690 - Train Loss: 0.152042, Train Acc: 0.732051 | Val Loss: 0.164763, Val Acc: 0.701031\n",
      "Epoch 6691 - Train Loss: 0.152029, Train Acc: 0.733333 | Val Loss: 0.164752, Val Acc: 0.701031\n",
      "Epoch 6692 - Train Loss: 0.152017, Train Acc: 0.733333 | Val Loss: 0.164741, Val Acc: 0.701031\n",
      "Epoch 6693 - Train Loss: 0.152005, Train Acc: 0.733333 | Val Loss: 0.164730, Val Acc: 0.701031\n",
      "Epoch 6694 - Train Loss: 0.151993, Train Acc: 0.733333 | Val Loss: 0.164719, Val Acc: 0.701031\n",
      "Epoch 6695 - Train Loss: 0.151981, Train Acc: 0.733333 | Val Loss: 0.164708, Val Acc: 0.701031\n",
      "Epoch 6696 - Train Loss: 0.151969, Train Acc: 0.733333 | Val Loss: 0.164697, Val Acc: 0.701031\n",
      "Epoch 6697 - Train Loss: 0.151957, Train Acc: 0.733333 | Val Loss: 0.164686, Val Acc: 0.701031\n",
      "Epoch 6698 - Train Loss: 0.151945, Train Acc: 0.733333 | Val Loss: 0.164675, Val Acc: 0.701031\n",
      "Epoch 6699 - Train Loss: 0.151933, Train Acc: 0.733333 | Val Loss: 0.164664, Val Acc: 0.701031\n",
      "Epoch 6700 - Train Loss: 0.151920, Train Acc: 0.733333 | Val Loss: 0.164653, Val Acc: 0.701031\n",
      "Epoch 6701 - Train Loss: 0.151908, Train Acc: 0.733333 | Val Loss: 0.164642, Val Acc: 0.701031\n",
      "Epoch 6702 - Train Loss: 0.151896, Train Acc: 0.733333 | Val Loss: 0.164632, Val Acc: 0.701031\n",
      "Epoch 6703 - Train Loss: 0.151884, Train Acc: 0.733333 | Val Loss: 0.164621, Val Acc: 0.701031\n",
      "Epoch 6704 - Train Loss: 0.151872, Train Acc: 0.733333 | Val Loss: 0.164610, Val Acc: 0.701031\n",
      "Epoch 6705 - Train Loss: 0.151860, Train Acc: 0.733333 | Val Loss: 0.164599, Val Acc: 0.701031\n",
      "Epoch 6706 - Train Loss: 0.151848, Train Acc: 0.733333 | Val Loss: 0.164588, Val Acc: 0.701031\n",
      "Epoch 6707 - Train Loss: 0.151836, Train Acc: 0.733333 | Val Loss: 0.164577, Val Acc: 0.701031\n",
      "Epoch 6708 - Train Loss: 0.151824, Train Acc: 0.733333 | Val Loss: 0.164566, Val Acc: 0.701031\n",
      "Epoch 6709 - Train Loss: 0.151812, Train Acc: 0.733333 | Val Loss: 0.164555, Val Acc: 0.701031\n",
      "Epoch 6710 - Train Loss: 0.151799, Train Acc: 0.733333 | Val Loss: 0.164544, Val Acc: 0.701031\n",
      "Epoch 6711 - Train Loss: 0.151787, Train Acc: 0.733333 | Val Loss: 0.164533, Val Acc: 0.701031\n",
      "Epoch 6712 - Train Loss: 0.151775, Train Acc: 0.733333 | Val Loss: 0.164522, Val Acc: 0.701031\n",
      "Epoch 6713 - Train Loss: 0.151763, Train Acc: 0.733333 | Val Loss: 0.164511, Val Acc: 0.701031\n",
      "Epoch 6714 - Train Loss: 0.151751, Train Acc: 0.733333 | Val Loss: 0.164500, Val Acc: 0.701031\n",
      "Epoch 6715 - Train Loss: 0.151739, Train Acc: 0.733333 | Val Loss: 0.164489, Val Acc: 0.701031\n",
      "Epoch 6716 - Train Loss: 0.151727, Train Acc: 0.733333 | Val Loss: 0.164478, Val Acc: 0.701031\n",
      "Epoch 6717 - Train Loss: 0.151715, Train Acc: 0.733333 | Val Loss: 0.164467, Val Acc: 0.701031\n",
      "Epoch 6718 - Train Loss: 0.151703, Train Acc: 0.733333 | Val Loss: 0.164456, Val Acc: 0.701031\n",
      "Epoch 6719 - Train Loss: 0.151691, Train Acc: 0.733333 | Val Loss: 0.164445, Val Acc: 0.701031\n",
      "Epoch 6720 - Train Loss: 0.151679, Train Acc: 0.733333 | Val Loss: 0.164435, Val Acc: 0.701031\n",
      "Epoch 6721 - Train Loss: 0.151667, Train Acc: 0.733333 | Val Loss: 0.164424, Val Acc: 0.701031\n",
      "Epoch 6722 - Train Loss: 0.151655, Train Acc: 0.733333 | Val Loss: 0.164413, Val Acc: 0.701031\n",
      "Epoch 6723 - Train Loss: 0.151642, Train Acc: 0.733333 | Val Loss: 0.164402, Val Acc: 0.701031\n",
      "Epoch 6724 - Train Loss: 0.151630, Train Acc: 0.733333 | Val Loss: 0.164391, Val Acc: 0.701031\n",
      "Epoch 6725 - Train Loss: 0.151618, Train Acc: 0.733333 | Val Loss: 0.164380, Val Acc: 0.701031\n",
      "Epoch 6726 - Train Loss: 0.151606, Train Acc: 0.733333 | Val Loss: 0.164369, Val Acc: 0.701031\n",
      "Epoch 6727 - Train Loss: 0.151594, Train Acc: 0.733333 | Val Loss: 0.164358, Val Acc: 0.701031\n",
      "Epoch 6728 - Train Loss: 0.151582, Train Acc: 0.733333 | Val Loss: 0.164347, Val Acc: 0.701031\n",
      "Epoch 6729 - Train Loss: 0.151570, Train Acc: 0.733333 | Val Loss: 0.164336, Val Acc: 0.701031\n",
      "Epoch 6730 - Train Loss: 0.151558, Train Acc: 0.733333 | Val Loss: 0.164325, Val Acc: 0.701031\n",
      "Epoch 6731 - Train Loss: 0.151546, Train Acc: 0.733333 | Val Loss: 0.164315, Val Acc: 0.701031\n",
      "Epoch 6732 - Train Loss: 0.151534, Train Acc: 0.733333 | Val Loss: 0.164304, Val Acc: 0.701031\n",
      "Epoch 6733 - Train Loss: 0.151522, Train Acc: 0.732051 | Val Loss: 0.164293, Val Acc: 0.701031\n",
      "Epoch 6734 - Train Loss: 0.151510, Train Acc: 0.732051 | Val Loss: 0.164282, Val Acc: 0.701031\n",
      "Epoch 6735 - Train Loss: 0.151498, Train Acc: 0.732051 | Val Loss: 0.164271, Val Acc: 0.701031\n",
      "Epoch 6736 - Train Loss: 0.151486, Train Acc: 0.733333 | Val Loss: 0.164260, Val Acc: 0.701031\n",
      "Epoch 6737 - Train Loss: 0.151474, Train Acc: 0.733333 | Val Loss: 0.164249, Val Acc: 0.701031\n",
      "Epoch 6738 - Train Loss: 0.151462, Train Acc: 0.733333 | Val Loss: 0.164238, Val Acc: 0.701031\n",
      "Epoch 6739 - Train Loss: 0.151450, Train Acc: 0.733333 | Val Loss: 0.164227, Val Acc: 0.701031\n",
      "Epoch 6740 - Train Loss: 0.151438, Train Acc: 0.733333 | Val Loss: 0.164217, Val Acc: 0.701031\n",
      "Epoch 6741 - Train Loss: 0.151426, Train Acc: 0.733333 | Val Loss: 0.164206, Val Acc: 0.701031\n",
      "Epoch 6742 - Train Loss: 0.151413, Train Acc: 0.733333 | Val Loss: 0.164195, Val Acc: 0.701031\n",
      "Epoch 6743 - Train Loss: 0.151401, Train Acc: 0.733333 | Val Loss: 0.164184, Val Acc: 0.701031\n",
      "Epoch 6744 - Train Loss: 0.151389, Train Acc: 0.733333 | Val Loss: 0.164173, Val Acc: 0.701031\n",
      "Epoch 6745 - Train Loss: 0.151377, Train Acc: 0.733333 | Val Loss: 0.164162, Val Acc: 0.701031\n",
      "Epoch 6746 - Train Loss: 0.151365, Train Acc: 0.733333 | Val Loss: 0.164151, Val Acc: 0.701031\n",
      "Epoch 6747 - Train Loss: 0.151353, Train Acc: 0.733333 | Val Loss: 0.164140, Val Acc: 0.701031\n",
      "Epoch 6748 - Train Loss: 0.151341, Train Acc: 0.733333 | Val Loss: 0.164129, Val Acc: 0.701031\n",
      "Epoch 6749 - Train Loss: 0.151329, Train Acc: 0.733333 | Val Loss: 0.164119, Val Acc: 0.701031\n",
      "Epoch 6750 - Train Loss: 0.151317, Train Acc: 0.733333 | Val Loss: 0.164108, Val Acc: 0.701031\n",
      "Epoch 6751 - Train Loss: 0.151305, Train Acc: 0.733333 | Val Loss: 0.164097, Val Acc: 0.701031\n",
      "Epoch 6752 - Train Loss: 0.151293, Train Acc: 0.733333 | Val Loss: 0.164086, Val Acc: 0.701031\n",
      "Epoch 6753 - Train Loss: 0.151281, Train Acc: 0.733333 | Val Loss: 0.164075, Val Acc: 0.701031\n",
      "Epoch 6754 - Train Loss: 0.151269, Train Acc: 0.733333 | Val Loss: 0.164064, Val Acc: 0.701031\n",
      "Epoch 6755 - Train Loss: 0.151257, Train Acc: 0.733333 | Val Loss: 0.164053, Val Acc: 0.701031\n",
      "Epoch 6756 - Train Loss: 0.151245, Train Acc: 0.733333 | Val Loss: 0.164043, Val Acc: 0.701031\n",
      "Epoch 6757 - Train Loss: 0.151233, Train Acc: 0.733333 | Val Loss: 0.164032, Val Acc: 0.701031\n",
      "Epoch 6758 - Train Loss: 0.151221, Train Acc: 0.733333 | Val Loss: 0.164021, Val Acc: 0.701031\n",
      "Epoch 6759 - Train Loss: 0.151209, Train Acc: 0.733333 | Val Loss: 0.164010, Val Acc: 0.701031\n",
      "Epoch 6760 - Train Loss: 0.151197, Train Acc: 0.733333 | Val Loss: 0.163999, Val Acc: 0.701031\n",
      "Epoch 6761 - Train Loss: 0.151185, Train Acc: 0.733333 | Val Loss: 0.163988, Val Acc: 0.701031\n",
      "Epoch 6762 - Train Loss: 0.151173, Train Acc: 0.733333 | Val Loss: 0.163977, Val Acc: 0.701031\n",
      "Epoch 6763 - Train Loss: 0.151161, Train Acc: 0.733333 | Val Loss: 0.163967, Val Acc: 0.701031\n",
      "Epoch 6764 - Train Loss: 0.151149, Train Acc: 0.733333 | Val Loss: 0.163956, Val Acc: 0.701031\n",
      "Epoch 6765 - Train Loss: 0.151137, Train Acc: 0.733333 | Val Loss: 0.163945, Val Acc: 0.701031\n",
      "Epoch 6766 - Train Loss: 0.151125, Train Acc: 0.733333 | Val Loss: 0.163934, Val Acc: 0.701031\n",
      "Epoch 6767 - Train Loss: 0.151113, Train Acc: 0.733333 | Val Loss: 0.163923, Val Acc: 0.701031\n",
      "Epoch 6768 - Train Loss: 0.151101, Train Acc: 0.733333 | Val Loss: 0.163912, Val Acc: 0.701031\n",
      "Epoch 6769 - Train Loss: 0.151089, Train Acc: 0.733333 | Val Loss: 0.163902, Val Acc: 0.701031\n",
      "Epoch 6770 - Train Loss: 0.151077, Train Acc: 0.733333 | Val Loss: 0.163891, Val Acc: 0.701031\n",
      "Epoch 6771 - Train Loss: 0.151065, Train Acc: 0.733333 | Val Loss: 0.163880, Val Acc: 0.701031\n",
      "Epoch 6772 - Train Loss: 0.151053, Train Acc: 0.733333 | Val Loss: 0.163869, Val Acc: 0.701031\n",
      "Epoch 6773 - Train Loss: 0.151041, Train Acc: 0.733333 | Val Loss: 0.163858, Val Acc: 0.701031\n",
      "Epoch 6774 - Train Loss: 0.151029, Train Acc: 0.733333 | Val Loss: 0.163847, Val Acc: 0.701031\n",
      "Epoch 6775 - Train Loss: 0.151017, Train Acc: 0.733333 | Val Loss: 0.163837, Val Acc: 0.701031\n",
      "Epoch 6776 - Train Loss: 0.151005, Train Acc: 0.733333 | Val Loss: 0.163826, Val Acc: 0.701031\n",
      "Epoch 6777 - Train Loss: 0.150993, Train Acc: 0.733333 | Val Loss: 0.163815, Val Acc: 0.701031\n",
      "Epoch 6778 - Train Loss: 0.150981, Train Acc: 0.733333 | Val Loss: 0.163804, Val Acc: 0.701031\n",
      "Epoch 6779 - Train Loss: 0.150969, Train Acc: 0.733333 | Val Loss: 0.163793, Val Acc: 0.701031\n",
      "Epoch 6780 - Train Loss: 0.150957, Train Acc: 0.733333 | Val Loss: 0.163782, Val Acc: 0.701031\n",
      "Epoch 6781 - Train Loss: 0.150945, Train Acc: 0.734615 | Val Loss: 0.163772, Val Acc: 0.701031\n",
      "Epoch 6782 - Train Loss: 0.150933, Train Acc: 0.734615 | Val Loss: 0.163761, Val Acc: 0.701031\n",
      "Epoch 6783 - Train Loss: 0.150921, Train Acc: 0.734615 | Val Loss: 0.163750, Val Acc: 0.701031\n",
      "Epoch 6784 - Train Loss: 0.150909, Train Acc: 0.734615 | Val Loss: 0.163739, Val Acc: 0.701031\n",
      "Epoch 6785 - Train Loss: 0.150897, Train Acc: 0.734615 | Val Loss: 0.163728, Val Acc: 0.701031\n",
      "Epoch 6786 - Train Loss: 0.150885, Train Acc: 0.734615 | Val Loss: 0.163718, Val Acc: 0.701031\n",
      "Epoch 6787 - Train Loss: 0.150873, Train Acc: 0.734615 | Val Loss: 0.163707, Val Acc: 0.701031\n",
      "Epoch 6788 - Train Loss: 0.150861, Train Acc: 0.734615 | Val Loss: 0.163696, Val Acc: 0.701031\n",
      "Epoch 6789 - Train Loss: 0.150850, Train Acc: 0.735897 | Val Loss: 0.163685, Val Acc: 0.701031\n",
      "Epoch 6790 - Train Loss: 0.150838, Train Acc: 0.735897 | Val Loss: 0.163675, Val Acc: 0.701031\n",
      "Epoch 6791 - Train Loss: 0.150826, Train Acc: 0.735897 | Val Loss: 0.163664, Val Acc: 0.701031\n",
      "Epoch 6792 - Train Loss: 0.150814, Train Acc: 0.735897 | Val Loss: 0.163653, Val Acc: 0.701031\n",
      "Epoch 6793 - Train Loss: 0.150802, Train Acc: 0.735897 | Val Loss: 0.163642, Val Acc: 0.701031\n",
      "Epoch 6794 - Train Loss: 0.150790, Train Acc: 0.735897 | Val Loss: 0.163631, Val Acc: 0.701031\n",
      "Epoch 6795 - Train Loss: 0.150778, Train Acc: 0.735897 | Val Loss: 0.163621, Val Acc: 0.701031\n",
      "Epoch 6796 - Train Loss: 0.150766, Train Acc: 0.735897 | Val Loss: 0.163610, Val Acc: 0.701031\n",
      "Epoch 6797 - Train Loss: 0.150754, Train Acc: 0.735897 | Val Loss: 0.163599, Val Acc: 0.701031\n",
      "Epoch 6798 - Train Loss: 0.150742, Train Acc: 0.735897 | Val Loss: 0.163588, Val Acc: 0.701031\n",
      "Epoch 6799 - Train Loss: 0.150730, Train Acc: 0.735897 | Val Loss: 0.163578, Val Acc: 0.701031\n",
      "Epoch 6800 - Train Loss: 0.150718, Train Acc: 0.735897 | Val Loss: 0.163567, Val Acc: 0.701031\n",
      "Epoch 6801 - Train Loss: 0.150706, Train Acc: 0.735897 | Val Loss: 0.163556, Val Acc: 0.701031\n",
      "Epoch 6802 - Train Loss: 0.150694, Train Acc: 0.735897 | Val Loss: 0.163545, Val Acc: 0.701031\n",
      "Epoch 6803 - Train Loss: 0.150682, Train Acc: 0.735897 | Val Loss: 0.163535, Val Acc: 0.701031\n",
      "Epoch 6804 - Train Loss: 0.150670, Train Acc: 0.735897 | Val Loss: 0.163524, Val Acc: 0.701031\n",
      "Epoch 6805 - Train Loss: 0.150658, Train Acc: 0.735897 | Val Loss: 0.163513, Val Acc: 0.701031\n",
      "Epoch 6806 - Train Loss: 0.150646, Train Acc: 0.735897 | Val Loss: 0.163502, Val Acc: 0.701031\n",
      "Epoch 6807 - Train Loss: 0.150635, Train Acc: 0.735897 | Val Loss: 0.163492, Val Acc: 0.701031\n",
      "Epoch 6808 - Train Loss: 0.150623, Train Acc: 0.735897 | Val Loss: 0.163481, Val Acc: 0.701031\n",
      "Epoch 6809 - Train Loss: 0.150611, Train Acc: 0.735897 | Val Loss: 0.163470, Val Acc: 0.701031\n",
      "Epoch 6810 - Train Loss: 0.150599, Train Acc: 0.735897 | Val Loss: 0.163459, Val Acc: 0.701031\n",
      "Epoch 6811 - Train Loss: 0.150587, Train Acc: 0.735897 | Val Loss: 0.163449, Val Acc: 0.701031\n",
      "Epoch 6812 - Train Loss: 0.150575, Train Acc: 0.735897 | Val Loss: 0.163438, Val Acc: 0.701031\n",
      "Epoch 6813 - Train Loss: 0.150563, Train Acc: 0.735897 | Val Loss: 0.163427, Val Acc: 0.701031\n",
      "Epoch 6814 - Train Loss: 0.150551, Train Acc: 0.735897 | Val Loss: 0.163416, Val Acc: 0.701031\n",
      "Epoch 6815 - Train Loss: 0.150539, Train Acc: 0.735897 | Val Loss: 0.163406, Val Acc: 0.701031\n",
      "Epoch 6816 - Train Loss: 0.150527, Train Acc: 0.735897 | Val Loss: 0.163395, Val Acc: 0.701031\n",
      "Epoch 6817 - Train Loss: 0.150515, Train Acc: 0.735897 | Val Loss: 0.163384, Val Acc: 0.701031\n",
      "Epoch 6818 - Train Loss: 0.150503, Train Acc: 0.735897 | Val Loss: 0.163373, Val Acc: 0.701031\n",
      "Epoch 6819 - Train Loss: 0.150492, Train Acc: 0.735897 | Val Loss: 0.163363, Val Acc: 0.701031\n",
      "Epoch 6820 - Train Loss: 0.150480, Train Acc: 0.735897 | Val Loss: 0.163352, Val Acc: 0.701031\n",
      "Epoch 6821 - Train Loss: 0.150468, Train Acc: 0.735897 | Val Loss: 0.163341, Val Acc: 0.701031\n",
      "Epoch 6822 - Train Loss: 0.150456, Train Acc: 0.735897 | Val Loss: 0.163330, Val Acc: 0.701031\n",
      "Epoch 6823 - Train Loss: 0.150444, Train Acc: 0.735897 | Val Loss: 0.163320, Val Acc: 0.701031\n",
      "Epoch 6824 - Train Loss: 0.150432, Train Acc: 0.735897 | Val Loss: 0.163309, Val Acc: 0.701031\n",
      "Epoch 6825 - Train Loss: 0.150420, Train Acc: 0.735897 | Val Loss: 0.163298, Val Acc: 0.701031\n",
      "Epoch 6826 - Train Loss: 0.150408, Train Acc: 0.735897 | Val Loss: 0.163287, Val Acc: 0.701031\n",
      "Epoch 6827 - Train Loss: 0.150396, Train Acc: 0.735897 | Val Loss: 0.163277, Val Acc: 0.701031\n",
      "Epoch 6828 - Train Loss: 0.150384, Train Acc: 0.735897 | Val Loss: 0.163266, Val Acc: 0.701031\n",
      "Epoch 6829 - Train Loss: 0.150372, Train Acc: 0.735897 | Val Loss: 0.163255, Val Acc: 0.701031\n",
      "Epoch 6830 - Train Loss: 0.150361, Train Acc: 0.735897 | Val Loss: 0.163245, Val Acc: 0.701031\n",
      "Epoch 6831 - Train Loss: 0.150349, Train Acc: 0.735897 | Val Loss: 0.163234, Val Acc: 0.701031\n",
      "Epoch 6832 - Train Loss: 0.150337, Train Acc: 0.735897 | Val Loss: 0.163223, Val Acc: 0.701031\n",
      "Epoch 6833 - Train Loss: 0.150325, Train Acc: 0.735897 | Val Loss: 0.163212, Val Acc: 0.701031\n",
      "Epoch 6834 - Train Loss: 0.150313, Train Acc: 0.735897 | Val Loss: 0.163202, Val Acc: 0.701031\n",
      "Epoch 6835 - Train Loss: 0.150301, Train Acc: 0.735897 | Val Loss: 0.163191, Val Acc: 0.701031\n",
      "Epoch 6836 - Train Loss: 0.150289, Train Acc: 0.735897 | Val Loss: 0.163180, Val Acc: 0.701031\n",
      "Epoch 6837 - Train Loss: 0.150277, Train Acc: 0.735897 | Val Loss: 0.163170, Val Acc: 0.701031\n",
      "Epoch 6838 - Train Loss: 0.150266, Train Acc: 0.735897 | Val Loss: 0.163159, Val Acc: 0.701031\n",
      "Epoch 6839 - Train Loss: 0.150254, Train Acc: 0.735897 | Val Loss: 0.163148, Val Acc: 0.701031\n",
      "Epoch 6840 - Train Loss: 0.150242, Train Acc: 0.735897 | Val Loss: 0.163137, Val Acc: 0.701031\n",
      "Epoch 6841 - Train Loss: 0.150230, Train Acc: 0.735897 | Val Loss: 0.163127, Val Acc: 0.701031\n",
      "Epoch 6842 - Train Loss: 0.150218, Train Acc: 0.735897 | Val Loss: 0.163116, Val Acc: 0.701031\n",
      "Epoch 6843 - Train Loss: 0.150206, Train Acc: 0.735897 | Val Loss: 0.163105, Val Acc: 0.701031\n",
      "Epoch 6844 - Train Loss: 0.150194, Train Acc: 0.735897 | Val Loss: 0.163095, Val Acc: 0.701031\n",
      "Epoch 6845 - Train Loss: 0.150182, Train Acc: 0.735897 | Val Loss: 0.163084, Val Acc: 0.701031\n",
      "Epoch 6846 - Train Loss: 0.150171, Train Acc: 0.737179 | Val Loss: 0.163073, Val Acc: 0.701031\n",
      "Epoch 6847 - Train Loss: 0.150159, Train Acc: 0.737179 | Val Loss: 0.163063, Val Acc: 0.701031\n",
      "Epoch 6848 - Train Loss: 0.150147, Train Acc: 0.737179 | Val Loss: 0.163052, Val Acc: 0.701031\n",
      "Epoch 6849 - Train Loss: 0.150135, Train Acc: 0.737179 | Val Loss: 0.163041, Val Acc: 0.701031\n",
      "Epoch 6850 - Train Loss: 0.150123, Train Acc: 0.737179 | Val Loss: 0.163031, Val Acc: 0.701031\n",
      "Epoch 6851 - Train Loss: 0.150111, Train Acc: 0.737179 | Val Loss: 0.163020, Val Acc: 0.701031\n",
      "Epoch 6852 - Train Loss: 0.150099, Train Acc: 0.737179 | Val Loss: 0.163009, Val Acc: 0.701031\n",
      "Epoch 6853 - Train Loss: 0.150087, Train Acc: 0.737179 | Val Loss: 0.162998, Val Acc: 0.701031\n",
      "Epoch 6854 - Train Loss: 0.150076, Train Acc: 0.737179 | Val Loss: 0.162988, Val Acc: 0.701031\n",
      "Epoch 6855 - Train Loss: 0.150064, Train Acc: 0.737179 | Val Loss: 0.162977, Val Acc: 0.701031\n",
      "Epoch 6856 - Train Loss: 0.150052, Train Acc: 0.737179 | Val Loss: 0.162966, Val Acc: 0.701031\n",
      "Epoch 6857 - Train Loss: 0.150040, Train Acc: 0.737179 | Val Loss: 0.162956, Val Acc: 0.701031\n",
      "Epoch 6858 - Train Loss: 0.150028, Train Acc: 0.737179 | Val Loss: 0.162945, Val Acc: 0.701031\n",
      "Epoch 6859 - Train Loss: 0.150016, Train Acc: 0.737179 | Val Loss: 0.162934, Val Acc: 0.701031\n",
      "Epoch 6860 - Train Loss: 0.150005, Train Acc: 0.737179 | Val Loss: 0.162924, Val Acc: 0.701031\n",
      "Epoch 6861 - Train Loss: 0.149993, Train Acc: 0.737179 | Val Loss: 0.162913, Val Acc: 0.701031\n",
      "Epoch 6862 - Train Loss: 0.149981, Train Acc: 0.737179 | Val Loss: 0.162902, Val Acc: 0.701031\n",
      "Epoch 6863 - Train Loss: 0.149969, Train Acc: 0.737179 | Val Loss: 0.162892, Val Acc: 0.701031\n",
      "Epoch 6864 - Train Loss: 0.149957, Train Acc: 0.737179 | Val Loss: 0.162881, Val Acc: 0.701031\n",
      "Epoch 6865 - Train Loss: 0.149945, Train Acc: 0.737179 | Val Loss: 0.162870, Val Acc: 0.701031\n",
      "Epoch 6866 - Train Loss: 0.149933, Train Acc: 0.737179 | Val Loss: 0.162860, Val Acc: 0.701031\n",
      "Epoch 6867 - Train Loss: 0.149922, Train Acc: 0.737179 | Val Loss: 0.162849, Val Acc: 0.701031\n",
      "Epoch 6868 - Train Loss: 0.149910, Train Acc: 0.737179 | Val Loss: 0.162838, Val Acc: 0.701031\n",
      "Epoch 6869 - Train Loss: 0.149898, Train Acc: 0.737179 | Val Loss: 0.162828, Val Acc: 0.701031\n",
      "Epoch 6870 - Train Loss: 0.149886, Train Acc: 0.737179 | Val Loss: 0.162817, Val Acc: 0.701031\n",
      "Epoch 6871 - Train Loss: 0.149874, Train Acc: 0.737179 | Val Loss: 0.162806, Val Acc: 0.701031\n",
      "Epoch 6872 - Train Loss: 0.149863, Train Acc: 0.737179 | Val Loss: 0.162796, Val Acc: 0.701031\n",
      "Epoch 6873 - Train Loss: 0.149851, Train Acc: 0.737179 | Val Loss: 0.162785, Val Acc: 0.701031\n",
      "Epoch 6874 - Train Loss: 0.149839, Train Acc: 0.737179 | Val Loss: 0.162774, Val Acc: 0.701031\n",
      "Epoch 6875 - Train Loss: 0.149827, Train Acc: 0.737179 | Val Loss: 0.162764, Val Acc: 0.701031\n",
      "Epoch 6876 - Train Loss: 0.149815, Train Acc: 0.737179 | Val Loss: 0.162753, Val Acc: 0.701031\n",
      "Epoch 6877 - Train Loss: 0.149803, Train Acc: 0.737179 | Val Loss: 0.162743, Val Acc: 0.701031\n",
      "Epoch 6878 - Train Loss: 0.149792, Train Acc: 0.737179 | Val Loss: 0.162732, Val Acc: 0.701031\n",
      "Epoch 6879 - Train Loss: 0.149780, Train Acc: 0.737179 | Val Loss: 0.162721, Val Acc: 0.701031\n",
      "Epoch 6880 - Train Loss: 0.149768, Train Acc: 0.737179 | Val Loss: 0.162711, Val Acc: 0.701031\n",
      "Epoch 6881 - Train Loss: 0.149756, Train Acc: 0.737179 | Val Loss: 0.162700, Val Acc: 0.701031\n",
      "Epoch 6882 - Train Loss: 0.149744, Train Acc: 0.737179 | Val Loss: 0.162689, Val Acc: 0.701031\n",
      "Epoch 6883 - Train Loss: 0.149733, Train Acc: 0.737179 | Val Loss: 0.162679, Val Acc: 0.701031\n",
      "Epoch 6884 - Train Loss: 0.149721, Train Acc: 0.737179 | Val Loss: 0.162668, Val Acc: 0.701031\n",
      "Epoch 6885 - Train Loss: 0.149709, Train Acc: 0.737179 | Val Loss: 0.162657, Val Acc: 0.701031\n",
      "Epoch 6886 - Train Loss: 0.149697, Train Acc: 0.737179 | Val Loss: 0.162647, Val Acc: 0.701031\n",
      "Epoch 6887 - Train Loss: 0.149685, Train Acc: 0.737179 | Val Loss: 0.162636, Val Acc: 0.701031\n",
      "Epoch 6888 - Train Loss: 0.149674, Train Acc: 0.737179 | Val Loss: 0.162626, Val Acc: 0.701031\n",
      "Epoch 6889 - Train Loss: 0.149662, Train Acc: 0.737179 | Val Loss: 0.162615, Val Acc: 0.701031\n",
      "Epoch 6890 - Train Loss: 0.149650, Train Acc: 0.737179 | Val Loss: 0.162604, Val Acc: 0.701031\n",
      "Epoch 6891 - Train Loss: 0.149638, Train Acc: 0.737179 | Val Loss: 0.162594, Val Acc: 0.701031\n",
      "Epoch 6892 - Train Loss: 0.149626, Train Acc: 0.737179 | Val Loss: 0.162583, Val Acc: 0.701031\n",
      "Epoch 6893 - Train Loss: 0.149615, Train Acc: 0.737179 | Val Loss: 0.162572, Val Acc: 0.701031\n",
      "Epoch 6894 - Train Loss: 0.149603, Train Acc: 0.737179 | Val Loss: 0.162562, Val Acc: 0.701031\n",
      "Epoch 6895 - Train Loss: 0.149591, Train Acc: 0.737179 | Val Loss: 0.162551, Val Acc: 0.701031\n",
      "Epoch 6896 - Train Loss: 0.149579, Train Acc: 0.737179 | Val Loss: 0.162541, Val Acc: 0.701031\n",
      "Epoch 6897 - Train Loss: 0.149567, Train Acc: 0.737179 | Val Loss: 0.162530, Val Acc: 0.701031\n",
      "Epoch 6898 - Train Loss: 0.149556, Train Acc: 0.737179 | Val Loss: 0.162519, Val Acc: 0.701031\n",
      "Epoch 6899 - Train Loss: 0.149544, Train Acc: 0.737179 | Val Loss: 0.162509, Val Acc: 0.701031\n",
      "Epoch 6900 - Train Loss: 0.149532, Train Acc: 0.737179 | Val Loss: 0.162498, Val Acc: 0.701031\n",
      "Epoch 6901 - Train Loss: 0.149520, Train Acc: 0.737179 | Val Loss: 0.162488, Val Acc: 0.701031\n",
      "Epoch 6902 - Train Loss: 0.149508, Train Acc: 0.738462 | Val Loss: 0.162477, Val Acc: 0.701031\n",
      "Epoch 6903 - Train Loss: 0.149497, Train Acc: 0.738462 | Val Loss: 0.162466, Val Acc: 0.701031\n",
      "Epoch 6904 - Train Loss: 0.149485, Train Acc: 0.738462 | Val Loss: 0.162456, Val Acc: 0.701031\n",
      "Epoch 6905 - Train Loss: 0.149473, Train Acc: 0.738462 | Val Loss: 0.162445, Val Acc: 0.701031\n",
      "Epoch 6906 - Train Loss: 0.149461, Train Acc: 0.738462 | Val Loss: 0.162434, Val Acc: 0.701031\n",
      "Epoch 6907 - Train Loss: 0.149450, Train Acc: 0.738462 | Val Loss: 0.162424, Val Acc: 0.701031\n",
      "Epoch 6908 - Train Loss: 0.149438, Train Acc: 0.738462 | Val Loss: 0.162413, Val Acc: 0.701031\n",
      "Epoch 6909 - Train Loss: 0.149426, Train Acc: 0.738462 | Val Loss: 0.162403, Val Acc: 0.701031\n",
      "Epoch 6910 - Train Loss: 0.149414, Train Acc: 0.738462 | Val Loss: 0.162392, Val Acc: 0.701031\n",
      "Epoch 6911 - Train Loss: 0.149403, Train Acc: 0.738462 | Val Loss: 0.162381, Val Acc: 0.701031\n",
      "Epoch 6912 - Train Loss: 0.149391, Train Acc: 0.738462 | Val Loss: 0.162371, Val Acc: 0.701031\n",
      "Epoch 6913 - Train Loss: 0.149379, Train Acc: 0.738462 | Val Loss: 0.162360, Val Acc: 0.701031\n",
      "Epoch 6914 - Train Loss: 0.149367, Train Acc: 0.738462 | Val Loss: 0.162350, Val Acc: 0.701031\n",
      "Epoch 6915 - Train Loss: 0.149355, Train Acc: 0.738462 | Val Loss: 0.162339, Val Acc: 0.701031\n",
      "Epoch 6916 - Train Loss: 0.149344, Train Acc: 0.738462 | Val Loss: 0.162329, Val Acc: 0.701031\n",
      "Epoch 6917 - Train Loss: 0.149332, Train Acc: 0.738462 | Val Loss: 0.162318, Val Acc: 0.701031\n",
      "Epoch 6918 - Train Loss: 0.149320, Train Acc: 0.738462 | Val Loss: 0.162307, Val Acc: 0.701031\n",
      "Epoch 6919 - Train Loss: 0.149308, Train Acc: 0.738462 | Val Loss: 0.162297, Val Acc: 0.701031\n",
      "Epoch 6920 - Train Loss: 0.149297, Train Acc: 0.738462 | Val Loss: 0.162286, Val Acc: 0.701031\n",
      "Epoch 6921 - Train Loss: 0.149285, Train Acc: 0.738462 | Val Loss: 0.162276, Val Acc: 0.701031\n",
      "Epoch 6922 - Train Loss: 0.149273, Train Acc: 0.738462 | Val Loss: 0.162265, Val Acc: 0.701031\n",
      "Epoch 6923 - Train Loss: 0.149261, Train Acc: 0.738462 | Val Loss: 0.162255, Val Acc: 0.701031\n",
      "Epoch 6924 - Train Loss: 0.149250, Train Acc: 0.738462 | Val Loss: 0.162244, Val Acc: 0.701031\n",
      "Epoch 6925 - Train Loss: 0.149238, Train Acc: 0.739744 | Val Loss: 0.162233, Val Acc: 0.701031\n",
      "Epoch 6926 - Train Loss: 0.149226, Train Acc: 0.739744 | Val Loss: 0.162223, Val Acc: 0.701031\n",
      "Epoch 6927 - Train Loss: 0.149215, Train Acc: 0.739744 | Val Loss: 0.162212, Val Acc: 0.701031\n",
      "Epoch 6928 - Train Loss: 0.149203, Train Acc: 0.739744 | Val Loss: 0.162202, Val Acc: 0.701031\n",
      "Epoch 6929 - Train Loss: 0.149191, Train Acc: 0.739744 | Val Loss: 0.162191, Val Acc: 0.701031\n",
      "Epoch 6930 - Train Loss: 0.149179, Train Acc: 0.739744 | Val Loss: 0.162181, Val Acc: 0.701031\n",
      "Epoch 6931 - Train Loss: 0.149168, Train Acc: 0.739744 | Val Loss: 0.162170, Val Acc: 0.701031\n",
      "Epoch 6932 - Train Loss: 0.149156, Train Acc: 0.739744 | Val Loss: 0.162159, Val Acc: 0.701031\n",
      "Epoch 6933 - Train Loss: 0.149144, Train Acc: 0.739744 | Val Loss: 0.162149, Val Acc: 0.701031\n",
      "Epoch 6934 - Train Loss: 0.149132, Train Acc: 0.739744 | Val Loss: 0.162138, Val Acc: 0.701031\n",
      "Epoch 6935 - Train Loss: 0.149121, Train Acc: 0.739744 | Val Loss: 0.162128, Val Acc: 0.701031\n",
      "Epoch 6936 - Train Loss: 0.149109, Train Acc: 0.739744 | Val Loss: 0.162117, Val Acc: 0.701031\n",
      "Epoch 6937 - Train Loss: 0.149097, Train Acc: 0.739744 | Val Loss: 0.162107, Val Acc: 0.701031\n",
      "Epoch 6938 - Train Loss: 0.149085, Train Acc: 0.739744 | Val Loss: 0.162096, Val Acc: 0.701031\n",
      "Epoch 6939 - Train Loss: 0.149074, Train Acc: 0.739744 | Val Loss: 0.162086, Val Acc: 0.701031\n",
      "Epoch 6940 - Train Loss: 0.149062, Train Acc: 0.739744 | Val Loss: 0.162075, Val Acc: 0.701031\n",
      "Epoch 6941 - Train Loss: 0.149050, Train Acc: 0.739744 | Val Loss: 0.162065, Val Acc: 0.701031\n",
      "Epoch 6942 - Train Loss: 0.149039, Train Acc: 0.739744 | Val Loss: 0.162054, Val Acc: 0.701031\n",
      "Epoch 6943 - Train Loss: 0.149027, Train Acc: 0.739744 | Val Loss: 0.162043, Val Acc: 0.701031\n",
      "Epoch 6944 - Train Loss: 0.149015, Train Acc: 0.739744 | Val Loss: 0.162033, Val Acc: 0.701031\n",
      "Epoch 6945 - Train Loss: 0.149003, Train Acc: 0.739744 | Val Loss: 0.162022, Val Acc: 0.701031\n",
      "Epoch 6946 - Train Loss: 0.148992, Train Acc: 0.739744 | Val Loss: 0.162012, Val Acc: 0.701031\n",
      "Epoch 6947 - Train Loss: 0.148980, Train Acc: 0.739744 | Val Loss: 0.162001, Val Acc: 0.701031\n",
      "Epoch 6948 - Train Loss: 0.148968, Train Acc: 0.739744 | Val Loss: 0.161991, Val Acc: 0.701031\n",
      "Epoch 6949 - Train Loss: 0.148957, Train Acc: 0.739744 | Val Loss: 0.161980, Val Acc: 0.701031\n",
      "Epoch 6950 - Train Loss: 0.148945, Train Acc: 0.739744 | Val Loss: 0.161970, Val Acc: 0.701031\n",
      "Epoch 6951 - Train Loss: 0.148933, Train Acc: 0.739744 | Val Loss: 0.161959, Val Acc: 0.701031\n",
      "Epoch 6952 - Train Loss: 0.148922, Train Acc: 0.739744 | Val Loss: 0.161949, Val Acc: 0.701031\n",
      "Epoch 6953 - Train Loss: 0.148910, Train Acc: 0.739744 | Val Loss: 0.161938, Val Acc: 0.701031\n",
      "Epoch 6954 - Train Loss: 0.148898, Train Acc: 0.739744 | Val Loss: 0.161928, Val Acc: 0.701031\n",
      "Epoch 6955 - Train Loss: 0.148886, Train Acc: 0.739744 | Val Loss: 0.161917, Val Acc: 0.701031\n",
      "Epoch 6956 - Train Loss: 0.148875, Train Acc: 0.739744 | Val Loss: 0.161907, Val Acc: 0.701031\n",
      "Epoch 6957 - Train Loss: 0.148863, Train Acc: 0.739744 | Val Loss: 0.161896, Val Acc: 0.701031\n",
      "Epoch 6958 - Train Loss: 0.148851, Train Acc: 0.738462 | Val Loss: 0.161886, Val Acc: 0.701031\n",
      "Epoch 6959 - Train Loss: 0.148840, Train Acc: 0.738462 | Val Loss: 0.161875, Val Acc: 0.701031\n",
      "Epoch 6960 - Train Loss: 0.148828, Train Acc: 0.738462 | Val Loss: 0.161865, Val Acc: 0.701031\n",
      "Epoch 6961 - Train Loss: 0.148816, Train Acc: 0.739744 | Val Loss: 0.161854, Val Acc: 0.701031\n",
      "Epoch 6962 - Train Loss: 0.148805, Train Acc: 0.739744 | Val Loss: 0.161844, Val Acc: 0.701031\n",
      "Epoch 6963 - Train Loss: 0.148793, Train Acc: 0.739744 | Val Loss: 0.161833, Val Acc: 0.701031\n",
      "Epoch 6964 - Train Loss: 0.148781, Train Acc: 0.739744 | Val Loss: 0.161823, Val Acc: 0.701031\n",
      "Epoch 6965 - Train Loss: 0.148770, Train Acc: 0.739744 | Val Loss: 0.161812, Val Acc: 0.701031\n",
      "Epoch 6966 - Train Loss: 0.148758, Train Acc: 0.739744 | Val Loss: 0.161802, Val Acc: 0.701031\n",
      "Epoch 6967 - Train Loss: 0.148746, Train Acc: 0.739744 | Val Loss: 0.161791, Val Acc: 0.701031\n",
      "Epoch 6968 - Train Loss: 0.148735, Train Acc: 0.739744 | Val Loss: 0.161781, Val Acc: 0.701031\n",
      "Epoch 6969 - Train Loss: 0.148723, Train Acc: 0.739744 | Val Loss: 0.161770, Val Acc: 0.701031\n",
      "Epoch 6970 - Train Loss: 0.148711, Train Acc: 0.739744 | Val Loss: 0.161760, Val Acc: 0.701031\n",
      "Epoch 6971 - Train Loss: 0.148699, Train Acc: 0.739744 | Val Loss: 0.161749, Val Acc: 0.701031\n",
      "Epoch 6972 - Train Loss: 0.148688, Train Acc: 0.739744 | Val Loss: 0.161739, Val Acc: 0.701031\n",
      "Epoch 6973 - Train Loss: 0.148676, Train Acc: 0.739744 | Val Loss: 0.161728, Val Acc: 0.701031\n",
      "Epoch 6974 - Train Loss: 0.148664, Train Acc: 0.739744 | Val Loss: 0.161718, Val Acc: 0.701031\n",
      "Epoch 6975 - Train Loss: 0.148653, Train Acc: 0.739744 | Val Loss: 0.161707, Val Acc: 0.701031\n",
      "Epoch 6976 - Train Loss: 0.148641, Train Acc: 0.739744 | Val Loss: 0.161697, Val Acc: 0.701031\n",
      "Epoch 6977 - Train Loss: 0.148629, Train Acc: 0.739744 | Val Loss: 0.161686, Val Acc: 0.701031\n",
      "Epoch 6978 - Train Loss: 0.148618, Train Acc: 0.739744 | Val Loss: 0.161676, Val Acc: 0.701031\n",
      "Epoch 6979 - Train Loss: 0.148606, Train Acc: 0.739744 | Val Loss: 0.161665, Val Acc: 0.701031\n",
      "Epoch 6980 - Train Loss: 0.148595, Train Acc: 0.739744 | Val Loss: 0.161655, Val Acc: 0.701031\n",
      "Epoch 6981 - Train Loss: 0.148583, Train Acc: 0.739744 | Val Loss: 0.161644, Val Acc: 0.701031\n",
      "Epoch 6982 - Train Loss: 0.148571, Train Acc: 0.739744 | Val Loss: 0.161634, Val Acc: 0.701031\n",
      "Epoch 6983 - Train Loss: 0.148560, Train Acc: 0.739744 | Val Loss: 0.161623, Val Acc: 0.701031\n",
      "Epoch 6984 - Train Loss: 0.148548, Train Acc: 0.739744 | Val Loss: 0.161613, Val Acc: 0.701031\n",
      "Epoch 6985 - Train Loss: 0.148536, Train Acc: 0.739744 | Val Loss: 0.161602, Val Acc: 0.701031\n",
      "Epoch 6986 - Train Loss: 0.148525, Train Acc: 0.739744 | Val Loss: 0.161592, Val Acc: 0.701031\n",
      "Epoch 6987 - Train Loss: 0.148513, Train Acc: 0.739744 | Val Loss: 0.161581, Val Acc: 0.701031\n",
      "Epoch 6988 - Train Loss: 0.148501, Train Acc: 0.739744 | Val Loss: 0.161571, Val Acc: 0.701031\n",
      "Epoch 6989 - Train Loss: 0.148490, Train Acc: 0.739744 | Val Loss: 0.161561, Val Acc: 0.701031\n",
      "Epoch 6990 - Train Loss: 0.148478, Train Acc: 0.739744 | Val Loss: 0.161550, Val Acc: 0.701031\n",
      "Epoch 6991 - Train Loss: 0.148466, Train Acc: 0.739744 | Val Loss: 0.161540, Val Acc: 0.701031\n",
      "Epoch 6992 - Train Loss: 0.148455, Train Acc: 0.739744 | Val Loss: 0.161529, Val Acc: 0.701031\n",
      "Epoch 6993 - Train Loss: 0.148443, Train Acc: 0.739744 | Val Loss: 0.161519, Val Acc: 0.701031\n",
      "Epoch 6994 - Train Loss: 0.148431, Train Acc: 0.739744 | Val Loss: 0.161508, Val Acc: 0.701031\n",
      "Epoch 6995 - Train Loss: 0.148420, Train Acc: 0.739744 | Val Loss: 0.161498, Val Acc: 0.701031\n",
      "Epoch 6996 - Train Loss: 0.148408, Train Acc: 0.739744 | Val Loss: 0.161487, Val Acc: 0.701031\n",
      "Epoch 6997 - Train Loss: 0.148397, Train Acc: 0.739744 | Val Loss: 0.161477, Val Acc: 0.701031\n",
      "Epoch 6998 - Train Loss: 0.148385, Train Acc: 0.739744 | Val Loss: 0.161466, Val Acc: 0.701031\n",
      "Epoch 6999 - Train Loss: 0.148373, Train Acc: 0.739744 | Val Loss: 0.161456, Val Acc: 0.701031\n",
      "Epoch 7000 - Train Loss: 0.148362, Train Acc: 0.739744 | Val Loss: 0.161446, Val Acc: 0.701031\n",
      "Epoch 7001 - Train Loss: 0.148350, Train Acc: 0.739744 | Val Loss: 0.161435, Val Acc: 0.701031\n",
      "Epoch 7002 - Train Loss: 0.148338, Train Acc: 0.739744 | Val Loss: 0.161425, Val Acc: 0.701031\n",
      "Epoch 7003 - Train Loss: 0.148327, Train Acc: 0.739744 | Val Loss: 0.161414, Val Acc: 0.701031\n",
      "Epoch 7004 - Train Loss: 0.148315, Train Acc: 0.739744 | Val Loss: 0.161404, Val Acc: 0.701031\n",
      "Epoch 7005 - Train Loss: 0.148304, Train Acc: 0.739744 | Val Loss: 0.161393, Val Acc: 0.701031\n",
      "Epoch 7006 - Train Loss: 0.148292, Train Acc: 0.739744 | Val Loss: 0.161383, Val Acc: 0.701031\n",
      "Epoch 7007 - Train Loss: 0.148280, Train Acc: 0.739744 | Val Loss: 0.161372, Val Acc: 0.701031\n",
      "Epoch 7008 - Train Loss: 0.148269, Train Acc: 0.739744 | Val Loss: 0.161362, Val Acc: 0.701031\n",
      "Epoch 7009 - Train Loss: 0.148257, Train Acc: 0.739744 | Val Loss: 0.161352, Val Acc: 0.701031\n",
      "Epoch 7010 - Train Loss: 0.148246, Train Acc: 0.739744 | Val Loss: 0.161341, Val Acc: 0.701031\n",
      "Epoch 7011 - Train Loss: 0.148234, Train Acc: 0.739744 | Val Loss: 0.161331, Val Acc: 0.701031\n",
      "Epoch 7012 - Train Loss: 0.148222, Train Acc: 0.739744 | Val Loss: 0.161320, Val Acc: 0.701031\n",
      "Epoch 7013 - Train Loss: 0.148211, Train Acc: 0.739744 | Val Loss: 0.161310, Val Acc: 0.701031\n",
      "Epoch 7014 - Train Loss: 0.148199, Train Acc: 0.739744 | Val Loss: 0.161299, Val Acc: 0.701031\n",
      "Epoch 7015 - Train Loss: 0.148187, Train Acc: 0.739744 | Val Loss: 0.161289, Val Acc: 0.701031\n",
      "Epoch 7016 - Train Loss: 0.148176, Train Acc: 0.739744 | Val Loss: 0.161279, Val Acc: 0.701031\n",
      "Epoch 7017 - Train Loss: 0.148164, Train Acc: 0.739744 | Val Loss: 0.161268, Val Acc: 0.701031\n",
      "Epoch 7018 - Train Loss: 0.148153, Train Acc: 0.739744 | Val Loss: 0.161258, Val Acc: 0.701031\n",
      "Epoch 7019 - Train Loss: 0.148141, Train Acc: 0.739744 | Val Loss: 0.161247, Val Acc: 0.711340\n",
      "Epoch 7020 - Train Loss: 0.148130, Train Acc: 0.739744 | Val Loss: 0.161237, Val Acc: 0.711340\n",
      "Epoch 7021 - Train Loss: 0.148118, Train Acc: 0.739744 | Val Loss: 0.161227, Val Acc: 0.711340\n",
      "Epoch 7022 - Train Loss: 0.148106, Train Acc: 0.739744 | Val Loss: 0.161216, Val Acc: 0.711340\n",
      "Epoch 7023 - Train Loss: 0.148095, Train Acc: 0.739744 | Val Loss: 0.161206, Val Acc: 0.711340\n",
      "Epoch 7024 - Train Loss: 0.148083, Train Acc: 0.739744 | Val Loss: 0.161195, Val Acc: 0.711340\n",
      "Epoch 7025 - Train Loss: 0.148072, Train Acc: 0.739744 | Val Loss: 0.161185, Val Acc: 0.711340\n",
      "Epoch 7026 - Train Loss: 0.148060, Train Acc: 0.739744 | Val Loss: 0.161174, Val Acc: 0.711340\n",
      "Epoch 7027 - Train Loss: 0.148048, Train Acc: 0.739744 | Val Loss: 0.161164, Val Acc: 0.711340\n",
      "Epoch 7028 - Train Loss: 0.148037, Train Acc: 0.739744 | Val Loss: 0.161154, Val Acc: 0.711340\n",
      "Epoch 7029 - Train Loss: 0.148025, Train Acc: 0.739744 | Val Loss: 0.161143, Val Acc: 0.711340\n",
      "Epoch 7030 - Train Loss: 0.148014, Train Acc: 0.739744 | Val Loss: 0.161133, Val Acc: 0.711340\n",
      "Epoch 7031 - Train Loss: 0.148002, Train Acc: 0.739744 | Val Loss: 0.161122, Val Acc: 0.711340\n",
      "Epoch 7032 - Train Loss: 0.147990, Train Acc: 0.739744 | Val Loss: 0.161112, Val Acc: 0.711340\n",
      "Epoch 7033 - Train Loss: 0.147979, Train Acc: 0.739744 | Val Loss: 0.161102, Val Acc: 0.711340\n",
      "Epoch 7034 - Train Loss: 0.147967, Train Acc: 0.739744 | Val Loss: 0.161091, Val Acc: 0.711340\n",
      "Epoch 7035 - Train Loss: 0.147956, Train Acc: 0.739744 | Val Loss: 0.161081, Val Acc: 0.711340\n",
      "Epoch 7036 - Train Loss: 0.147944, Train Acc: 0.739744 | Val Loss: 0.161070, Val Acc: 0.711340\n",
      "Epoch 7037 - Train Loss: 0.147933, Train Acc: 0.739744 | Val Loss: 0.161060, Val Acc: 0.711340\n",
      "Epoch 7038 - Train Loss: 0.147921, Train Acc: 0.739744 | Val Loss: 0.161050, Val Acc: 0.711340\n",
      "Epoch 7039 - Train Loss: 0.147909, Train Acc: 0.739744 | Val Loss: 0.161039, Val Acc: 0.711340\n",
      "Epoch 7040 - Train Loss: 0.147898, Train Acc: 0.739744 | Val Loss: 0.161029, Val Acc: 0.711340\n",
      "Epoch 7041 - Train Loss: 0.147886, Train Acc: 0.739744 | Val Loss: 0.161019, Val Acc: 0.711340\n",
      "Epoch 7042 - Train Loss: 0.147875, Train Acc: 0.739744 | Val Loss: 0.161008, Val Acc: 0.711340\n",
      "Epoch 7043 - Train Loss: 0.147863, Train Acc: 0.739744 | Val Loss: 0.160998, Val Acc: 0.711340\n",
      "Epoch 7044 - Train Loss: 0.147852, Train Acc: 0.739744 | Val Loss: 0.160987, Val Acc: 0.711340\n",
      "Epoch 7045 - Train Loss: 0.147840, Train Acc: 0.739744 | Val Loss: 0.160977, Val Acc: 0.711340\n",
      "Epoch 7046 - Train Loss: 0.147829, Train Acc: 0.739744 | Val Loss: 0.160967, Val Acc: 0.711340\n",
      "Epoch 7047 - Train Loss: 0.147817, Train Acc: 0.739744 | Val Loss: 0.160956, Val Acc: 0.711340\n",
      "Epoch 7048 - Train Loss: 0.147805, Train Acc: 0.739744 | Val Loss: 0.160946, Val Acc: 0.711340\n",
      "Epoch 7049 - Train Loss: 0.147794, Train Acc: 0.739744 | Val Loss: 0.160936, Val Acc: 0.711340\n",
      "Epoch 7050 - Train Loss: 0.147782, Train Acc: 0.739744 | Val Loss: 0.160925, Val Acc: 0.711340\n",
      "Epoch 7051 - Train Loss: 0.147771, Train Acc: 0.739744 | Val Loss: 0.160915, Val Acc: 0.711340\n",
      "Epoch 7052 - Train Loss: 0.147759, Train Acc: 0.739744 | Val Loss: 0.160904, Val Acc: 0.711340\n",
      "Epoch 7053 - Train Loss: 0.147748, Train Acc: 0.739744 | Val Loss: 0.160894, Val Acc: 0.711340\n",
      "Epoch 7054 - Train Loss: 0.147736, Train Acc: 0.739744 | Val Loss: 0.160884, Val Acc: 0.711340\n",
      "Epoch 7055 - Train Loss: 0.147725, Train Acc: 0.739744 | Val Loss: 0.160873, Val Acc: 0.711340\n",
      "Epoch 7056 - Train Loss: 0.147713, Train Acc: 0.739744 | Val Loss: 0.160863, Val Acc: 0.711340\n",
      "Epoch 7057 - Train Loss: 0.147702, Train Acc: 0.739744 | Val Loss: 0.160853, Val Acc: 0.711340\n",
      "Epoch 7058 - Train Loss: 0.147690, Train Acc: 0.739744 | Val Loss: 0.160842, Val Acc: 0.711340\n",
      "Epoch 7059 - Train Loss: 0.147679, Train Acc: 0.739744 | Val Loss: 0.160832, Val Acc: 0.711340\n",
      "Epoch 7060 - Train Loss: 0.147667, Train Acc: 0.739744 | Val Loss: 0.160822, Val Acc: 0.711340\n",
      "Epoch 7061 - Train Loss: 0.147655, Train Acc: 0.741026 | Val Loss: 0.160811, Val Acc: 0.711340\n",
      "Epoch 7062 - Train Loss: 0.147644, Train Acc: 0.741026 | Val Loss: 0.160801, Val Acc: 0.711340\n",
      "Epoch 7063 - Train Loss: 0.147632, Train Acc: 0.741026 | Val Loss: 0.160790, Val Acc: 0.711340\n",
      "Epoch 7064 - Train Loss: 0.147621, Train Acc: 0.741026 | Val Loss: 0.160780, Val Acc: 0.711340\n",
      "Epoch 7065 - Train Loss: 0.147609, Train Acc: 0.741026 | Val Loss: 0.160770, Val Acc: 0.711340\n",
      "Epoch 7066 - Train Loss: 0.147598, Train Acc: 0.741026 | Val Loss: 0.160759, Val Acc: 0.711340\n",
      "Epoch 7067 - Train Loss: 0.147586, Train Acc: 0.741026 | Val Loss: 0.160749, Val Acc: 0.711340\n",
      "Epoch 7068 - Train Loss: 0.147575, Train Acc: 0.741026 | Val Loss: 0.160739, Val Acc: 0.711340\n",
      "Epoch 7069 - Train Loss: 0.147563, Train Acc: 0.741026 | Val Loss: 0.160728, Val Acc: 0.711340\n",
      "Epoch 7070 - Train Loss: 0.147552, Train Acc: 0.741026 | Val Loss: 0.160718, Val Acc: 0.711340\n",
      "Epoch 7071 - Train Loss: 0.147540, Train Acc: 0.741026 | Val Loss: 0.160708, Val Acc: 0.711340\n",
      "Epoch 7072 - Train Loss: 0.147529, Train Acc: 0.741026 | Val Loss: 0.160697, Val Acc: 0.711340\n",
      "Epoch 7073 - Train Loss: 0.147517, Train Acc: 0.741026 | Val Loss: 0.160687, Val Acc: 0.711340\n",
      "Epoch 7074 - Train Loss: 0.147506, Train Acc: 0.741026 | Val Loss: 0.160677, Val Acc: 0.711340\n",
      "Epoch 7075 - Train Loss: 0.147494, Train Acc: 0.741026 | Val Loss: 0.160666, Val Acc: 0.711340\n",
      "Epoch 7076 - Train Loss: 0.147483, Train Acc: 0.741026 | Val Loss: 0.160656, Val Acc: 0.711340\n",
      "Epoch 7077 - Train Loss: 0.147471, Train Acc: 0.741026 | Val Loss: 0.160646, Val Acc: 0.711340\n",
      "Epoch 7078 - Train Loss: 0.147460, Train Acc: 0.741026 | Val Loss: 0.160635, Val Acc: 0.711340\n",
      "Epoch 7079 - Train Loss: 0.147448, Train Acc: 0.741026 | Val Loss: 0.160625, Val Acc: 0.711340\n",
      "Epoch 7080 - Train Loss: 0.147437, Train Acc: 0.741026 | Val Loss: 0.160615, Val Acc: 0.711340\n",
      "Epoch 7081 - Train Loss: 0.147425, Train Acc: 0.741026 | Val Loss: 0.160604, Val Acc: 0.711340\n",
      "Epoch 7082 - Train Loss: 0.147414, Train Acc: 0.741026 | Val Loss: 0.160594, Val Acc: 0.711340\n",
      "Epoch 7083 - Train Loss: 0.147402, Train Acc: 0.741026 | Val Loss: 0.160584, Val Acc: 0.711340\n",
      "Epoch 7084 - Train Loss: 0.147391, Train Acc: 0.741026 | Val Loss: 0.160574, Val Acc: 0.711340\n",
      "Epoch 7085 - Train Loss: 0.147379, Train Acc: 0.741026 | Val Loss: 0.160563, Val Acc: 0.711340\n",
      "Epoch 7086 - Train Loss: 0.147368, Train Acc: 0.741026 | Val Loss: 0.160553, Val Acc: 0.711340\n",
      "Epoch 7087 - Train Loss: 0.147356, Train Acc: 0.741026 | Val Loss: 0.160543, Val Acc: 0.711340\n",
      "Epoch 7088 - Train Loss: 0.147345, Train Acc: 0.741026 | Val Loss: 0.160532, Val Acc: 0.711340\n",
      "Epoch 7089 - Train Loss: 0.147333, Train Acc: 0.741026 | Val Loss: 0.160522, Val Acc: 0.711340\n",
      "Epoch 7090 - Train Loss: 0.147322, Train Acc: 0.741026 | Val Loss: 0.160512, Val Acc: 0.711340\n",
      "Epoch 7091 - Train Loss: 0.147310, Train Acc: 0.741026 | Val Loss: 0.160501, Val Acc: 0.711340\n",
      "Epoch 7092 - Train Loss: 0.147299, Train Acc: 0.741026 | Val Loss: 0.160491, Val Acc: 0.711340\n",
      "Epoch 7093 - Train Loss: 0.147287, Train Acc: 0.741026 | Val Loss: 0.160481, Val Acc: 0.711340\n",
      "Epoch 7094 - Train Loss: 0.147276, Train Acc: 0.741026 | Val Loss: 0.160471, Val Acc: 0.711340\n",
      "Epoch 7095 - Train Loss: 0.147264, Train Acc: 0.741026 | Val Loss: 0.160460, Val Acc: 0.711340\n",
      "Epoch 7096 - Train Loss: 0.147253, Train Acc: 0.741026 | Val Loss: 0.160450, Val Acc: 0.711340\n",
      "Epoch 7097 - Train Loss: 0.147241, Train Acc: 0.741026 | Val Loss: 0.160440, Val Acc: 0.711340\n",
      "Epoch 7098 - Train Loss: 0.147230, Train Acc: 0.743590 | Val Loss: 0.160429, Val Acc: 0.711340\n",
      "Epoch 7099 - Train Loss: 0.147218, Train Acc: 0.743590 | Val Loss: 0.160419, Val Acc: 0.711340\n",
      "Epoch 7100 - Train Loss: 0.147207, Train Acc: 0.743590 | Val Loss: 0.160409, Val Acc: 0.711340\n",
      "Epoch 7101 - Train Loss: 0.147195, Train Acc: 0.743590 | Val Loss: 0.160399, Val Acc: 0.711340\n",
      "Epoch 7102 - Train Loss: 0.147184, Train Acc: 0.743590 | Val Loss: 0.160388, Val Acc: 0.711340\n",
      "Epoch 7103 - Train Loss: 0.147173, Train Acc: 0.743590 | Val Loss: 0.160378, Val Acc: 0.711340\n",
      "Epoch 7104 - Train Loss: 0.147161, Train Acc: 0.743590 | Val Loss: 0.160368, Val Acc: 0.711340\n",
      "Epoch 7105 - Train Loss: 0.147150, Train Acc: 0.743590 | Val Loss: 0.160357, Val Acc: 0.711340\n",
      "Epoch 7106 - Train Loss: 0.147138, Train Acc: 0.743590 | Val Loss: 0.160347, Val Acc: 0.711340\n",
      "Epoch 7107 - Train Loss: 0.147127, Train Acc: 0.743590 | Val Loss: 0.160337, Val Acc: 0.711340\n",
      "Epoch 7108 - Train Loss: 0.147115, Train Acc: 0.743590 | Val Loss: 0.160327, Val Acc: 0.711340\n",
      "Epoch 7109 - Train Loss: 0.147104, Train Acc: 0.743590 | Val Loss: 0.160316, Val Acc: 0.711340\n",
      "Epoch 7110 - Train Loss: 0.147092, Train Acc: 0.743590 | Val Loss: 0.160306, Val Acc: 0.711340\n",
      "Epoch 7111 - Train Loss: 0.147081, Train Acc: 0.743590 | Val Loss: 0.160296, Val Acc: 0.711340\n",
      "Epoch 7112 - Train Loss: 0.147069, Train Acc: 0.743590 | Val Loss: 0.160285, Val Acc: 0.711340\n",
      "Epoch 7113 - Train Loss: 0.147058, Train Acc: 0.743590 | Val Loss: 0.160275, Val Acc: 0.711340\n",
      "Epoch 7114 - Train Loss: 0.147047, Train Acc: 0.743590 | Val Loss: 0.160265, Val Acc: 0.711340\n",
      "Epoch 7115 - Train Loss: 0.147035, Train Acc: 0.743590 | Val Loss: 0.160255, Val Acc: 0.711340\n",
      "Epoch 7116 - Train Loss: 0.147024, Train Acc: 0.743590 | Val Loss: 0.160244, Val Acc: 0.711340\n",
      "Epoch 7117 - Train Loss: 0.147012, Train Acc: 0.743590 | Val Loss: 0.160234, Val Acc: 0.711340\n",
      "Epoch 7118 - Train Loss: 0.147001, Train Acc: 0.743590 | Val Loss: 0.160224, Val Acc: 0.711340\n",
      "Epoch 7119 - Train Loss: 0.146989, Train Acc: 0.743590 | Val Loss: 0.160214, Val Acc: 0.711340\n",
      "Epoch 7120 - Train Loss: 0.146978, Train Acc: 0.743590 | Val Loss: 0.160203, Val Acc: 0.711340\n",
      "Epoch 7121 - Train Loss: 0.146966, Train Acc: 0.743590 | Val Loss: 0.160193, Val Acc: 0.711340\n",
      "Epoch 7122 - Train Loss: 0.146955, Train Acc: 0.743590 | Val Loss: 0.160183, Val Acc: 0.711340\n",
      "Epoch 7123 - Train Loss: 0.146944, Train Acc: 0.743590 | Val Loss: 0.160173, Val Acc: 0.711340\n",
      "Epoch 7124 - Train Loss: 0.146932, Train Acc: 0.743590 | Val Loss: 0.160162, Val Acc: 0.711340\n",
      "Epoch 7125 - Train Loss: 0.146921, Train Acc: 0.743590 | Val Loss: 0.160152, Val Acc: 0.711340\n",
      "Epoch 7126 - Train Loss: 0.146909, Train Acc: 0.743590 | Val Loss: 0.160142, Val Acc: 0.711340\n",
      "Epoch 7127 - Train Loss: 0.146898, Train Acc: 0.743590 | Val Loss: 0.160132, Val Acc: 0.711340\n",
      "Epoch 7128 - Train Loss: 0.146886, Train Acc: 0.743590 | Val Loss: 0.160121, Val Acc: 0.711340\n",
      "Epoch 7129 - Train Loss: 0.146875, Train Acc: 0.743590 | Val Loss: 0.160111, Val Acc: 0.711340\n",
      "Epoch 7130 - Train Loss: 0.146864, Train Acc: 0.743590 | Val Loss: 0.160101, Val Acc: 0.711340\n",
      "Epoch 7131 - Train Loss: 0.146852, Train Acc: 0.743590 | Val Loss: 0.160090, Val Acc: 0.711340\n",
      "Epoch 7132 - Train Loss: 0.146841, Train Acc: 0.743590 | Val Loss: 0.160080, Val Acc: 0.711340\n",
      "Epoch 7133 - Train Loss: 0.146829, Train Acc: 0.743590 | Val Loss: 0.160070, Val Acc: 0.711340\n",
      "Epoch 7134 - Train Loss: 0.146818, Train Acc: 0.743590 | Val Loss: 0.160060, Val Acc: 0.711340\n",
      "Epoch 7135 - Train Loss: 0.146807, Train Acc: 0.743590 | Val Loss: 0.160050, Val Acc: 0.711340\n",
      "Epoch 7136 - Train Loss: 0.146795, Train Acc: 0.743590 | Val Loss: 0.160039, Val Acc: 0.711340\n",
      "Epoch 7137 - Train Loss: 0.146784, Train Acc: 0.743590 | Val Loss: 0.160029, Val Acc: 0.711340\n",
      "Epoch 7138 - Train Loss: 0.146772, Train Acc: 0.744872 | Val Loss: 0.160019, Val Acc: 0.711340\n",
      "Epoch 7139 - Train Loss: 0.146761, Train Acc: 0.744872 | Val Loss: 0.160009, Val Acc: 0.711340\n",
      "Epoch 7140 - Train Loss: 0.146749, Train Acc: 0.744872 | Val Loss: 0.159998, Val Acc: 0.711340\n",
      "Epoch 7141 - Train Loss: 0.146738, Train Acc: 0.744872 | Val Loss: 0.159988, Val Acc: 0.711340\n",
      "Epoch 7142 - Train Loss: 0.146727, Train Acc: 0.744872 | Val Loss: 0.159978, Val Acc: 0.711340\n",
      "Epoch 7143 - Train Loss: 0.146715, Train Acc: 0.744872 | Val Loss: 0.159968, Val Acc: 0.711340\n",
      "Epoch 7144 - Train Loss: 0.146704, Train Acc: 0.744872 | Val Loss: 0.159957, Val Acc: 0.711340\n",
      "Epoch 7145 - Train Loss: 0.146692, Train Acc: 0.744872 | Val Loss: 0.159947, Val Acc: 0.711340\n",
      "Epoch 7146 - Train Loss: 0.146681, Train Acc: 0.744872 | Val Loss: 0.159937, Val Acc: 0.711340\n",
      "Epoch 7147 - Train Loss: 0.146670, Train Acc: 0.744872 | Val Loss: 0.159927, Val Acc: 0.711340\n",
      "Epoch 7148 - Train Loss: 0.146658, Train Acc: 0.744872 | Val Loss: 0.159916, Val Acc: 0.711340\n",
      "Epoch 7149 - Train Loss: 0.146647, Train Acc: 0.744872 | Val Loss: 0.159906, Val Acc: 0.711340\n",
      "Epoch 7150 - Train Loss: 0.146635, Train Acc: 0.744872 | Val Loss: 0.159896, Val Acc: 0.711340\n",
      "Epoch 7151 - Train Loss: 0.146624, Train Acc: 0.744872 | Val Loss: 0.159886, Val Acc: 0.711340\n",
      "Epoch 7152 - Train Loss: 0.146613, Train Acc: 0.744872 | Val Loss: 0.159876, Val Acc: 0.711340\n",
      "Epoch 7153 - Train Loss: 0.146601, Train Acc: 0.744872 | Val Loss: 0.159865, Val Acc: 0.711340\n",
      "Epoch 7154 - Train Loss: 0.146590, Train Acc: 0.744872 | Val Loss: 0.159855, Val Acc: 0.711340\n",
      "Epoch 7155 - Train Loss: 0.146579, Train Acc: 0.744872 | Val Loss: 0.159845, Val Acc: 0.711340\n",
      "Epoch 7156 - Train Loss: 0.146567, Train Acc: 0.744872 | Val Loss: 0.159835, Val Acc: 0.711340\n",
      "Epoch 7157 - Train Loss: 0.146556, Train Acc: 0.744872 | Val Loss: 0.159825, Val Acc: 0.711340\n",
      "Epoch 7158 - Train Loss: 0.146544, Train Acc: 0.744872 | Val Loss: 0.159814, Val Acc: 0.711340\n",
      "Epoch 7159 - Train Loss: 0.146533, Train Acc: 0.744872 | Val Loss: 0.159804, Val Acc: 0.711340\n",
      "Epoch 7160 - Train Loss: 0.146522, Train Acc: 0.744872 | Val Loss: 0.159794, Val Acc: 0.711340\n",
      "Epoch 7161 - Train Loss: 0.146510, Train Acc: 0.744872 | Val Loss: 0.159784, Val Acc: 0.711340\n",
      "Epoch 7162 - Train Loss: 0.146499, Train Acc: 0.744872 | Val Loss: 0.159774, Val Acc: 0.711340\n",
      "Epoch 7163 - Train Loss: 0.146487, Train Acc: 0.744872 | Val Loss: 0.159763, Val Acc: 0.711340\n",
      "Epoch 7164 - Train Loss: 0.146476, Train Acc: 0.744872 | Val Loss: 0.159753, Val Acc: 0.711340\n",
      "Epoch 7165 - Train Loss: 0.146465, Train Acc: 0.744872 | Val Loss: 0.159743, Val Acc: 0.711340\n",
      "Epoch 7166 - Train Loss: 0.146453, Train Acc: 0.744872 | Val Loss: 0.159733, Val Acc: 0.711340\n",
      "Epoch 7167 - Train Loss: 0.146442, Train Acc: 0.744872 | Val Loss: 0.159723, Val Acc: 0.711340\n",
      "Epoch 7168 - Train Loss: 0.146431, Train Acc: 0.744872 | Val Loss: 0.159713, Val Acc: 0.711340\n",
      "Epoch 7169 - Train Loss: 0.146419, Train Acc: 0.744872 | Val Loss: 0.159702, Val Acc: 0.711340\n",
      "Epoch 7170 - Train Loss: 0.146408, Train Acc: 0.744872 | Val Loss: 0.159692, Val Acc: 0.711340\n",
      "Epoch 7171 - Train Loss: 0.146397, Train Acc: 0.744872 | Val Loss: 0.159682, Val Acc: 0.711340\n",
      "Epoch 7172 - Train Loss: 0.146385, Train Acc: 0.744872 | Val Loss: 0.159672, Val Acc: 0.711340\n",
      "Epoch 7173 - Train Loss: 0.146374, Train Acc: 0.744872 | Val Loss: 0.159662, Val Acc: 0.711340\n",
      "Epoch 7174 - Train Loss: 0.146363, Train Acc: 0.744872 | Val Loss: 0.159652, Val Acc: 0.711340\n",
      "Epoch 7175 - Train Loss: 0.146351, Train Acc: 0.744872 | Val Loss: 0.159641, Val Acc: 0.711340\n",
      "Epoch 7176 - Train Loss: 0.146340, Train Acc: 0.744872 | Val Loss: 0.159631, Val Acc: 0.711340\n",
      "Epoch 7177 - Train Loss: 0.146329, Train Acc: 0.744872 | Val Loss: 0.159621, Val Acc: 0.711340\n",
      "Epoch 7178 - Train Loss: 0.146317, Train Acc: 0.744872 | Val Loss: 0.159611, Val Acc: 0.711340\n",
      "Epoch 7179 - Train Loss: 0.146306, Train Acc: 0.744872 | Val Loss: 0.159601, Val Acc: 0.711340\n",
      "Epoch 7180 - Train Loss: 0.146294, Train Acc: 0.744872 | Val Loss: 0.159591, Val Acc: 0.711340\n",
      "Epoch 7181 - Train Loss: 0.146283, Train Acc: 0.744872 | Val Loss: 0.159580, Val Acc: 0.711340\n",
      "Epoch 7182 - Train Loss: 0.146272, Train Acc: 0.744872 | Val Loss: 0.159570, Val Acc: 0.711340\n",
      "Epoch 7183 - Train Loss: 0.146260, Train Acc: 0.744872 | Val Loss: 0.159560, Val Acc: 0.711340\n",
      "Epoch 7184 - Train Loss: 0.146249, Train Acc: 0.744872 | Val Loss: 0.159550, Val Acc: 0.711340\n",
      "Epoch 7185 - Train Loss: 0.146238, Train Acc: 0.744872 | Val Loss: 0.159540, Val Acc: 0.711340\n",
      "Epoch 7186 - Train Loss: 0.146226, Train Acc: 0.744872 | Val Loss: 0.159530, Val Acc: 0.711340\n",
      "Epoch 7187 - Train Loss: 0.146215, Train Acc: 0.744872 | Val Loss: 0.159520, Val Acc: 0.711340\n",
      "Epoch 7188 - Train Loss: 0.146204, Train Acc: 0.744872 | Val Loss: 0.159509, Val Acc: 0.711340\n",
      "Epoch 7189 - Train Loss: 0.146193, Train Acc: 0.744872 | Val Loss: 0.159499, Val Acc: 0.711340\n",
      "Epoch 7190 - Train Loss: 0.146181, Train Acc: 0.744872 | Val Loss: 0.159489, Val Acc: 0.711340\n",
      "Epoch 7191 - Train Loss: 0.146170, Train Acc: 0.744872 | Val Loss: 0.159479, Val Acc: 0.711340\n",
      "Epoch 7192 - Train Loss: 0.146159, Train Acc: 0.744872 | Val Loss: 0.159469, Val Acc: 0.711340\n",
      "Epoch 7193 - Train Loss: 0.146147, Train Acc: 0.744872 | Val Loss: 0.159459, Val Acc: 0.711340\n",
      "Epoch 7194 - Train Loss: 0.146136, Train Acc: 0.744872 | Val Loss: 0.159449, Val Acc: 0.711340\n",
      "Epoch 7195 - Train Loss: 0.146125, Train Acc: 0.744872 | Val Loss: 0.159438, Val Acc: 0.711340\n",
      "Epoch 7196 - Train Loss: 0.146113, Train Acc: 0.744872 | Val Loss: 0.159428, Val Acc: 0.711340\n",
      "Epoch 7197 - Train Loss: 0.146102, Train Acc: 0.744872 | Val Loss: 0.159418, Val Acc: 0.711340\n",
      "Epoch 7198 - Train Loss: 0.146091, Train Acc: 0.744872 | Val Loss: 0.159408, Val Acc: 0.711340\n",
      "Epoch 7199 - Train Loss: 0.146079, Train Acc: 0.744872 | Val Loss: 0.159398, Val Acc: 0.711340\n",
      "Epoch 7200 - Train Loss: 0.146068, Train Acc: 0.744872 | Val Loss: 0.159388, Val Acc: 0.711340\n",
      "Epoch 7201 - Train Loss: 0.146057, Train Acc: 0.744872 | Val Loss: 0.159378, Val Acc: 0.711340\n",
      "Epoch 7202 - Train Loss: 0.146045, Train Acc: 0.744872 | Val Loss: 0.159367, Val Acc: 0.711340\n",
      "Epoch 7203 - Train Loss: 0.146034, Train Acc: 0.744872 | Val Loss: 0.159357, Val Acc: 0.711340\n",
      "Epoch 7204 - Train Loss: 0.146023, Train Acc: 0.744872 | Val Loss: 0.159347, Val Acc: 0.711340\n",
      "Epoch 7205 - Train Loss: 0.146012, Train Acc: 0.744872 | Val Loss: 0.159337, Val Acc: 0.711340\n",
      "Epoch 7206 - Train Loss: 0.146000, Train Acc: 0.744872 | Val Loss: 0.159327, Val Acc: 0.711340\n",
      "Epoch 7207 - Train Loss: 0.145989, Train Acc: 0.744872 | Val Loss: 0.159317, Val Acc: 0.711340\n",
      "Epoch 7208 - Train Loss: 0.145978, Train Acc: 0.744872 | Val Loss: 0.159307, Val Acc: 0.711340\n",
      "Epoch 7209 - Train Loss: 0.145966, Train Acc: 0.744872 | Val Loss: 0.159297, Val Acc: 0.711340\n",
      "Epoch 7210 - Train Loss: 0.145955, Train Acc: 0.744872 | Val Loss: 0.159287, Val Acc: 0.711340\n",
      "Epoch 7211 - Train Loss: 0.145944, Train Acc: 0.744872 | Val Loss: 0.159276, Val Acc: 0.711340\n",
      "Epoch 7212 - Train Loss: 0.145932, Train Acc: 0.744872 | Val Loss: 0.159266, Val Acc: 0.711340\n",
      "Epoch 7213 - Train Loss: 0.145921, Train Acc: 0.744872 | Val Loss: 0.159256, Val Acc: 0.711340\n",
      "Epoch 7214 - Train Loss: 0.145910, Train Acc: 0.744872 | Val Loss: 0.159246, Val Acc: 0.711340\n",
      "Epoch 7215 - Train Loss: 0.145899, Train Acc: 0.744872 | Val Loss: 0.159236, Val Acc: 0.711340\n",
      "Epoch 7216 - Train Loss: 0.145887, Train Acc: 0.744872 | Val Loss: 0.159226, Val Acc: 0.711340\n",
      "Epoch 7217 - Train Loss: 0.145876, Train Acc: 0.744872 | Val Loss: 0.159216, Val Acc: 0.711340\n",
      "Epoch 7218 - Train Loss: 0.145865, Train Acc: 0.744872 | Val Loss: 0.159206, Val Acc: 0.711340\n",
      "Epoch 7219 - Train Loss: 0.145853, Train Acc: 0.744872 | Val Loss: 0.159196, Val Acc: 0.711340\n",
      "Epoch 7220 - Train Loss: 0.145842, Train Acc: 0.744872 | Val Loss: 0.159186, Val Acc: 0.711340\n",
      "Epoch 7221 - Train Loss: 0.145831, Train Acc: 0.744872 | Val Loss: 0.159175, Val Acc: 0.711340\n",
      "Epoch 7222 - Train Loss: 0.145820, Train Acc: 0.744872 | Val Loss: 0.159165, Val Acc: 0.711340\n",
      "Epoch 7223 - Train Loss: 0.145808, Train Acc: 0.744872 | Val Loss: 0.159155, Val Acc: 0.711340\n",
      "Epoch 7224 - Train Loss: 0.145797, Train Acc: 0.744872 | Val Loss: 0.159145, Val Acc: 0.711340\n",
      "Epoch 7225 - Train Loss: 0.145786, Train Acc: 0.744872 | Val Loss: 0.159135, Val Acc: 0.711340\n",
      "Epoch 7226 - Train Loss: 0.145775, Train Acc: 0.744872 | Val Loss: 0.159125, Val Acc: 0.711340\n",
      "Epoch 7227 - Train Loss: 0.145763, Train Acc: 0.744872 | Val Loss: 0.159115, Val Acc: 0.711340\n",
      "Epoch 7228 - Train Loss: 0.145752, Train Acc: 0.744872 | Val Loss: 0.159105, Val Acc: 0.711340\n",
      "Epoch 7229 - Train Loss: 0.145741, Train Acc: 0.744872 | Val Loss: 0.159095, Val Acc: 0.711340\n",
      "Epoch 7230 - Train Loss: 0.145730, Train Acc: 0.744872 | Val Loss: 0.159085, Val Acc: 0.711340\n",
      "Epoch 7231 - Train Loss: 0.145718, Train Acc: 0.744872 | Val Loss: 0.159075, Val Acc: 0.711340\n",
      "Epoch 7232 - Train Loss: 0.145707, Train Acc: 0.744872 | Val Loss: 0.159064, Val Acc: 0.711340\n",
      "Epoch 7233 - Train Loss: 0.145696, Train Acc: 0.744872 | Val Loss: 0.159054, Val Acc: 0.711340\n",
      "Epoch 7234 - Train Loss: 0.145684, Train Acc: 0.744872 | Val Loss: 0.159044, Val Acc: 0.711340\n",
      "Epoch 7235 - Train Loss: 0.145673, Train Acc: 0.744872 | Val Loss: 0.159034, Val Acc: 0.711340\n",
      "Epoch 7236 - Train Loss: 0.145662, Train Acc: 0.744872 | Val Loss: 0.159024, Val Acc: 0.711340\n",
      "Epoch 7237 - Train Loss: 0.145651, Train Acc: 0.744872 | Val Loss: 0.159014, Val Acc: 0.711340\n",
      "Epoch 7238 - Train Loss: 0.145639, Train Acc: 0.744872 | Val Loss: 0.159004, Val Acc: 0.711340\n",
      "Epoch 7239 - Train Loss: 0.145628, Train Acc: 0.744872 | Val Loss: 0.158994, Val Acc: 0.711340\n",
      "Epoch 7240 - Train Loss: 0.145617, Train Acc: 0.744872 | Val Loss: 0.158984, Val Acc: 0.711340\n",
      "Epoch 7241 - Train Loss: 0.145606, Train Acc: 0.744872 | Val Loss: 0.158974, Val Acc: 0.711340\n",
      "Epoch 7242 - Train Loss: 0.145594, Train Acc: 0.744872 | Val Loss: 0.158964, Val Acc: 0.711340\n",
      "Epoch 7243 - Train Loss: 0.145583, Train Acc: 0.744872 | Val Loss: 0.158954, Val Acc: 0.711340\n",
      "Epoch 7244 - Train Loss: 0.145572, Train Acc: 0.744872 | Val Loss: 0.158944, Val Acc: 0.711340\n",
      "Epoch 7245 - Train Loss: 0.145561, Train Acc: 0.744872 | Val Loss: 0.158934, Val Acc: 0.711340\n",
      "Epoch 7246 - Train Loss: 0.145550, Train Acc: 0.744872 | Val Loss: 0.158923, Val Acc: 0.711340\n",
      "Epoch 7247 - Train Loss: 0.145538, Train Acc: 0.744872 | Val Loss: 0.158913, Val Acc: 0.711340\n",
      "Epoch 7248 - Train Loss: 0.145527, Train Acc: 0.744872 | Val Loss: 0.158903, Val Acc: 0.711340\n",
      "Epoch 7249 - Train Loss: 0.145516, Train Acc: 0.744872 | Val Loss: 0.158893, Val Acc: 0.711340\n",
      "Epoch 7250 - Train Loss: 0.145505, Train Acc: 0.744872 | Val Loss: 0.158883, Val Acc: 0.711340\n",
      "Epoch 7251 - Train Loss: 0.145493, Train Acc: 0.744872 | Val Loss: 0.158873, Val Acc: 0.711340\n",
      "Epoch 7252 - Train Loss: 0.145482, Train Acc: 0.744872 | Val Loss: 0.158863, Val Acc: 0.711340\n",
      "Epoch 7253 - Train Loss: 0.145471, Train Acc: 0.744872 | Val Loss: 0.158853, Val Acc: 0.711340\n",
      "Epoch 7254 - Train Loss: 0.145460, Train Acc: 0.744872 | Val Loss: 0.158843, Val Acc: 0.711340\n",
      "Epoch 7255 - Train Loss: 0.145448, Train Acc: 0.744872 | Val Loss: 0.158833, Val Acc: 0.711340\n",
      "Epoch 7256 - Train Loss: 0.145437, Train Acc: 0.744872 | Val Loss: 0.158823, Val Acc: 0.711340\n",
      "Epoch 7257 - Train Loss: 0.145426, Train Acc: 0.744872 | Val Loss: 0.158813, Val Acc: 0.711340\n",
      "Epoch 7258 - Train Loss: 0.145415, Train Acc: 0.744872 | Val Loss: 0.158803, Val Acc: 0.711340\n",
      "Epoch 7259 - Train Loss: 0.145404, Train Acc: 0.744872 | Val Loss: 0.158793, Val Acc: 0.711340\n",
      "Epoch 7260 - Train Loss: 0.145392, Train Acc: 0.744872 | Val Loss: 0.158783, Val Acc: 0.711340\n",
      "Epoch 7261 - Train Loss: 0.145381, Train Acc: 0.744872 | Val Loss: 0.158773, Val Acc: 0.711340\n",
      "Epoch 7262 - Train Loss: 0.145370, Train Acc: 0.744872 | Val Loss: 0.158763, Val Acc: 0.711340\n",
      "Epoch 7263 - Train Loss: 0.145359, Train Acc: 0.744872 | Val Loss: 0.158753, Val Acc: 0.711340\n",
      "Epoch 7264 - Train Loss: 0.145348, Train Acc: 0.744872 | Val Loss: 0.158743, Val Acc: 0.711340\n",
      "Epoch 7265 - Train Loss: 0.145336, Train Acc: 0.744872 | Val Loss: 0.158733, Val Acc: 0.711340\n",
      "Epoch 7266 - Train Loss: 0.145325, Train Acc: 0.744872 | Val Loss: 0.158722, Val Acc: 0.711340\n",
      "Epoch 7267 - Train Loss: 0.145314, Train Acc: 0.744872 | Val Loss: 0.158713, Val Acc: 0.711340\n",
      "Epoch 7268 - Train Loss: 0.145303, Train Acc: 0.744872 | Val Loss: 0.158702, Val Acc: 0.711340\n",
      "Epoch 7269 - Train Loss: 0.145291, Train Acc: 0.744872 | Val Loss: 0.158692, Val Acc: 0.711340\n",
      "Epoch 7270 - Train Loss: 0.145280, Train Acc: 0.744872 | Val Loss: 0.158682, Val Acc: 0.711340\n",
      "Epoch 7271 - Train Loss: 0.145269, Train Acc: 0.744872 | Val Loss: 0.158672, Val Acc: 0.711340\n",
      "Epoch 7272 - Train Loss: 0.145258, Train Acc: 0.744872 | Val Loss: 0.158662, Val Acc: 0.711340\n",
      "Epoch 7273 - Train Loss: 0.145247, Train Acc: 0.744872 | Val Loss: 0.158652, Val Acc: 0.711340\n",
      "Epoch 7274 - Train Loss: 0.145236, Train Acc: 0.744872 | Val Loss: 0.158642, Val Acc: 0.711340\n",
      "Epoch 7275 - Train Loss: 0.145224, Train Acc: 0.744872 | Val Loss: 0.158632, Val Acc: 0.711340\n",
      "Epoch 7276 - Train Loss: 0.145213, Train Acc: 0.744872 | Val Loss: 0.158622, Val Acc: 0.711340\n",
      "Epoch 7277 - Train Loss: 0.145202, Train Acc: 0.744872 | Val Loss: 0.158612, Val Acc: 0.711340\n",
      "Epoch 7278 - Train Loss: 0.145191, Train Acc: 0.744872 | Val Loss: 0.158602, Val Acc: 0.711340\n",
      "Epoch 7279 - Train Loss: 0.145180, Train Acc: 0.744872 | Val Loss: 0.158592, Val Acc: 0.711340\n",
      "Epoch 7280 - Train Loss: 0.145168, Train Acc: 0.744872 | Val Loss: 0.158582, Val Acc: 0.711340\n",
      "Epoch 7281 - Train Loss: 0.145157, Train Acc: 0.744872 | Val Loss: 0.158572, Val Acc: 0.711340\n",
      "Epoch 7282 - Train Loss: 0.145146, Train Acc: 0.744872 | Val Loss: 0.158562, Val Acc: 0.711340\n",
      "Epoch 7283 - Train Loss: 0.145135, Train Acc: 0.744872 | Val Loss: 0.158552, Val Acc: 0.711340\n",
      "Epoch 7284 - Train Loss: 0.145124, Train Acc: 0.744872 | Val Loss: 0.158542, Val Acc: 0.711340\n",
      "Epoch 7285 - Train Loss: 0.145112, Train Acc: 0.744872 | Val Loss: 0.158532, Val Acc: 0.711340\n",
      "Epoch 7286 - Train Loss: 0.145101, Train Acc: 0.744872 | Val Loss: 0.158522, Val Acc: 0.711340\n",
      "Epoch 7287 - Train Loss: 0.145090, Train Acc: 0.744872 | Val Loss: 0.158512, Val Acc: 0.711340\n",
      "Epoch 7288 - Train Loss: 0.145079, Train Acc: 0.744872 | Val Loss: 0.158502, Val Acc: 0.711340\n",
      "Epoch 7289 - Train Loss: 0.145068, Train Acc: 0.744872 | Val Loss: 0.158492, Val Acc: 0.711340\n",
      "Epoch 7290 - Train Loss: 0.145057, Train Acc: 0.744872 | Val Loss: 0.158482, Val Acc: 0.711340\n",
      "Epoch 7291 - Train Loss: 0.145045, Train Acc: 0.744872 | Val Loss: 0.158472, Val Acc: 0.711340\n",
      "Epoch 7292 - Train Loss: 0.145034, Train Acc: 0.744872 | Val Loss: 0.158462, Val Acc: 0.711340\n",
      "Epoch 7293 - Train Loss: 0.145023, Train Acc: 0.744872 | Val Loss: 0.158452, Val Acc: 0.711340\n",
      "Epoch 7294 - Train Loss: 0.145012, Train Acc: 0.744872 | Val Loss: 0.158442, Val Acc: 0.711340\n",
      "Epoch 7295 - Train Loss: 0.145001, Train Acc: 0.744872 | Val Loss: 0.158432, Val Acc: 0.711340\n",
      "Epoch 7296 - Train Loss: 0.144990, Train Acc: 0.744872 | Val Loss: 0.158422, Val Acc: 0.711340\n",
      "Epoch 7297 - Train Loss: 0.144978, Train Acc: 0.744872 | Val Loss: 0.158412, Val Acc: 0.711340\n",
      "Epoch 7298 - Train Loss: 0.144967, Train Acc: 0.744872 | Val Loss: 0.158402, Val Acc: 0.711340\n",
      "Epoch 7299 - Train Loss: 0.144956, Train Acc: 0.744872 | Val Loss: 0.158392, Val Acc: 0.711340\n",
      "Epoch 7300 - Train Loss: 0.144945, Train Acc: 0.744872 | Val Loss: 0.158382, Val Acc: 0.711340\n",
      "Epoch 7301 - Train Loss: 0.144934, Train Acc: 0.744872 | Val Loss: 0.158373, Val Acc: 0.711340\n",
      "Epoch 7302 - Train Loss: 0.144923, Train Acc: 0.744872 | Val Loss: 0.158363, Val Acc: 0.711340\n",
      "Epoch 7303 - Train Loss: 0.144912, Train Acc: 0.744872 | Val Loss: 0.158353, Val Acc: 0.711340\n",
      "Epoch 7304 - Train Loss: 0.144900, Train Acc: 0.744872 | Val Loss: 0.158343, Val Acc: 0.711340\n",
      "Epoch 7305 - Train Loss: 0.144889, Train Acc: 0.744872 | Val Loss: 0.158333, Val Acc: 0.711340\n",
      "Epoch 7306 - Train Loss: 0.144878, Train Acc: 0.744872 | Val Loss: 0.158323, Val Acc: 0.711340\n",
      "Epoch 7307 - Train Loss: 0.144867, Train Acc: 0.744872 | Val Loss: 0.158313, Val Acc: 0.711340\n",
      "Epoch 7308 - Train Loss: 0.144856, Train Acc: 0.744872 | Val Loss: 0.158303, Val Acc: 0.711340\n",
      "Epoch 7309 - Train Loss: 0.144845, Train Acc: 0.744872 | Val Loss: 0.158293, Val Acc: 0.711340\n",
      "Epoch 7310 - Train Loss: 0.144834, Train Acc: 0.744872 | Val Loss: 0.158283, Val Acc: 0.711340\n",
      "Epoch 7311 - Train Loss: 0.144822, Train Acc: 0.744872 | Val Loss: 0.158273, Val Acc: 0.711340\n",
      "Epoch 7312 - Train Loss: 0.144811, Train Acc: 0.744872 | Val Loss: 0.158263, Val Acc: 0.711340\n",
      "Epoch 7313 - Train Loss: 0.144800, Train Acc: 0.744872 | Val Loss: 0.158253, Val Acc: 0.711340\n",
      "Epoch 7314 - Train Loss: 0.144789, Train Acc: 0.744872 | Val Loss: 0.158243, Val Acc: 0.711340\n",
      "Epoch 7315 - Train Loss: 0.144778, Train Acc: 0.744872 | Val Loss: 0.158233, Val Acc: 0.711340\n",
      "Epoch 7316 - Train Loss: 0.144767, Train Acc: 0.744872 | Val Loss: 0.158223, Val Acc: 0.711340\n",
      "Epoch 7317 - Train Loss: 0.144756, Train Acc: 0.744872 | Val Loss: 0.158213, Val Acc: 0.711340\n",
      "Epoch 7318 - Train Loss: 0.144745, Train Acc: 0.744872 | Val Loss: 0.158203, Val Acc: 0.711340\n",
      "Epoch 7319 - Train Loss: 0.144733, Train Acc: 0.744872 | Val Loss: 0.158193, Val Acc: 0.711340\n",
      "Epoch 7320 - Train Loss: 0.144722, Train Acc: 0.744872 | Val Loss: 0.158183, Val Acc: 0.711340\n",
      "Epoch 7321 - Train Loss: 0.144711, Train Acc: 0.744872 | Val Loss: 0.158173, Val Acc: 0.711340\n",
      "Epoch 7322 - Train Loss: 0.144700, Train Acc: 0.744872 | Val Loss: 0.158163, Val Acc: 0.711340\n",
      "Epoch 7323 - Train Loss: 0.144689, Train Acc: 0.744872 | Val Loss: 0.158153, Val Acc: 0.711340\n",
      "Epoch 7324 - Train Loss: 0.144678, Train Acc: 0.744872 | Val Loss: 0.158143, Val Acc: 0.711340\n",
      "Epoch 7325 - Train Loss: 0.144667, Train Acc: 0.744872 | Val Loss: 0.158134, Val Acc: 0.711340\n",
      "Epoch 7326 - Train Loss: 0.144656, Train Acc: 0.744872 | Val Loss: 0.158124, Val Acc: 0.711340\n",
      "Epoch 7327 - Train Loss: 0.144644, Train Acc: 0.744872 | Val Loss: 0.158114, Val Acc: 0.711340\n",
      "Epoch 7328 - Train Loss: 0.144633, Train Acc: 0.744872 | Val Loss: 0.158104, Val Acc: 0.711340\n",
      "Epoch 7329 - Train Loss: 0.144622, Train Acc: 0.744872 | Val Loss: 0.158094, Val Acc: 0.711340\n",
      "Epoch 7330 - Train Loss: 0.144611, Train Acc: 0.744872 | Val Loss: 0.158084, Val Acc: 0.711340\n",
      "Epoch 7331 - Train Loss: 0.144600, Train Acc: 0.746154 | Val Loss: 0.158074, Val Acc: 0.711340\n",
      "Epoch 7332 - Train Loss: 0.144589, Train Acc: 0.746154 | Val Loss: 0.158064, Val Acc: 0.711340\n",
      "Epoch 7333 - Train Loss: 0.144578, Train Acc: 0.746154 | Val Loss: 0.158054, Val Acc: 0.711340\n",
      "Epoch 7334 - Train Loss: 0.144567, Train Acc: 0.746154 | Val Loss: 0.158044, Val Acc: 0.711340\n",
      "Epoch 7335 - Train Loss: 0.144556, Train Acc: 0.746154 | Val Loss: 0.158034, Val Acc: 0.711340\n",
      "Epoch 7336 - Train Loss: 0.144544, Train Acc: 0.746154 | Val Loss: 0.158024, Val Acc: 0.711340\n",
      "Epoch 7337 - Train Loss: 0.144533, Train Acc: 0.746154 | Val Loss: 0.158014, Val Acc: 0.711340\n",
      "Epoch 7338 - Train Loss: 0.144522, Train Acc: 0.746154 | Val Loss: 0.158004, Val Acc: 0.711340\n",
      "Epoch 7339 - Train Loss: 0.144511, Train Acc: 0.746154 | Val Loss: 0.157995, Val Acc: 0.711340\n",
      "Epoch 7340 - Train Loss: 0.144500, Train Acc: 0.746154 | Val Loss: 0.157985, Val Acc: 0.711340\n",
      "Epoch 7341 - Train Loss: 0.144489, Train Acc: 0.746154 | Val Loss: 0.157975, Val Acc: 0.711340\n",
      "Epoch 7342 - Train Loss: 0.144478, Train Acc: 0.746154 | Val Loss: 0.157965, Val Acc: 0.711340\n",
      "Epoch 7343 - Train Loss: 0.144467, Train Acc: 0.746154 | Val Loss: 0.157955, Val Acc: 0.711340\n",
      "Epoch 7344 - Train Loss: 0.144456, Train Acc: 0.746154 | Val Loss: 0.157945, Val Acc: 0.711340\n",
      "Epoch 7345 - Train Loss: 0.144445, Train Acc: 0.746154 | Val Loss: 0.157935, Val Acc: 0.711340\n",
      "Epoch 7346 - Train Loss: 0.144434, Train Acc: 0.746154 | Val Loss: 0.157925, Val Acc: 0.711340\n",
      "Epoch 7347 - Train Loss: 0.144423, Train Acc: 0.746154 | Val Loss: 0.157915, Val Acc: 0.711340\n",
      "Epoch 7348 - Train Loss: 0.144411, Train Acc: 0.746154 | Val Loss: 0.157905, Val Acc: 0.711340\n",
      "Epoch 7349 - Train Loss: 0.144400, Train Acc: 0.746154 | Val Loss: 0.157896, Val Acc: 0.711340\n",
      "Epoch 7350 - Train Loss: 0.144389, Train Acc: 0.746154 | Val Loss: 0.157886, Val Acc: 0.711340\n",
      "Epoch 7351 - Train Loss: 0.144378, Train Acc: 0.746154 | Val Loss: 0.157876, Val Acc: 0.711340\n",
      "Epoch 7352 - Train Loss: 0.144367, Train Acc: 0.746154 | Val Loss: 0.157866, Val Acc: 0.711340\n",
      "Epoch 7353 - Train Loss: 0.144356, Train Acc: 0.746154 | Val Loss: 0.157856, Val Acc: 0.711340\n",
      "Epoch 7354 - Train Loss: 0.144345, Train Acc: 0.746154 | Val Loss: 0.157846, Val Acc: 0.711340\n",
      "Epoch 7355 - Train Loss: 0.144334, Train Acc: 0.746154 | Val Loss: 0.157836, Val Acc: 0.711340\n",
      "Epoch 7356 - Train Loss: 0.144323, Train Acc: 0.746154 | Val Loss: 0.157826, Val Acc: 0.711340\n",
      "Epoch 7357 - Train Loss: 0.144312, Train Acc: 0.746154 | Val Loss: 0.157816, Val Acc: 0.711340\n",
      "Epoch 7358 - Train Loss: 0.144301, Train Acc: 0.746154 | Val Loss: 0.157806, Val Acc: 0.711340\n",
      "Epoch 7359 - Train Loss: 0.144290, Train Acc: 0.746154 | Val Loss: 0.157797, Val Acc: 0.711340\n",
      "Epoch 7360 - Train Loss: 0.144279, Train Acc: 0.746154 | Val Loss: 0.157787, Val Acc: 0.711340\n",
      "Epoch 7361 - Train Loss: 0.144268, Train Acc: 0.746154 | Val Loss: 0.157777, Val Acc: 0.711340\n",
      "Epoch 7362 - Train Loss: 0.144256, Train Acc: 0.746154 | Val Loss: 0.157767, Val Acc: 0.711340\n",
      "Epoch 7363 - Train Loss: 0.144245, Train Acc: 0.746154 | Val Loss: 0.157757, Val Acc: 0.711340\n",
      "Epoch 7364 - Train Loss: 0.144234, Train Acc: 0.746154 | Val Loss: 0.157747, Val Acc: 0.711340\n",
      "Epoch 7365 - Train Loss: 0.144223, Train Acc: 0.746154 | Val Loss: 0.157737, Val Acc: 0.711340\n",
      "Epoch 7366 - Train Loss: 0.144212, Train Acc: 0.746154 | Val Loss: 0.157727, Val Acc: 0.711340\n",
      "Epoch 7367 - Train Loss: 0.144201, Train Acc: 0.746154 | Val Loss: 0.157718, Val Acc: 0.711340\n",
      "Epoch 7368 - Train Loss: 0.144190, Train Acc: 0.747436 | Val Loss: 0.157708, Val Acc: 0.711340\n",
      "Epoch 7369 - Train Loss: 0.144179, Train Acc: 0.747436 | Val Loss: 0.157698, Val Acc: 0.711340\n",
      "Epoch 7370 - Train Loss: 0.144168, Train Acc: 0.747436 | Val Loss: 0.157688, Val Acc: 0.711340\n",
      "Epoch 7371 - Train Loss: 0.144157, Train Acc: 0.747436 | Val Loss: 0.157678, Val Acc: 0.711340\n",
      "Epoch 7372 - Train Loss: 0.144146, Train Acc: 0.747436 | Val Loss: 0.157668, Val Acc: 0.711340\n",
      "Epoch 7373 - Train Loss: 0.144135, Train Acc: 0.747436 | Val Loss: 0.157658, Val Acc: 0.711340\n",
      "Epoch 7374 - Train Loss: 0.144124, Train Acc: 0.747436 | Val Loss: 0.157648, Val Acc: 0.711340\n",
      "Epoch 7375 - Train Loss: 0.144113, Train Acc: 0.747436 | Val Loss: 0.157639, Val Acc: 0.711340\n",
      "Epoch 7376 - Train Loss: 0.144102, Train Acc: 0.747436 | Val Loss: 0.157629, Val Acc: 0.711340\n",
      "Epoch 7377 - Train Loss: 0.144091, Train Acc: 0.747436 | Val Loss: 0.157619, Val Acc: 0.711340\n",
      "Epoch 7378 - Train Loss: 0.144080, Train Acc: 0.747436 | Val Loss: 0.157609, Val Acc: 0.711340\n",
      "Epoch 7379 - Train Loss: 0.144069, Train Acc: 0.747436 | Val Loss: 0.157599, Val Acc: 0.711340\n",
      "Epoch 7380 - Train Loss: 0.144058, Train Acc: 0.747436 | Val Loss: 0.157589, Val Acc: 0.711340\n",
      "Epoch 7381 - Train Loss: 0.144047, Train Acc: 0.747436 | Val Loss: 0.157579, Val Acc: 0.711340\n",
      "Epoch 7382 - Train Loss: 0.144036, Train Acc: 0.747436 | Val Loss: 0.157570, Val Acc: 0.711340\n",
      "Epoch 7383 - Train Loss: 0.144025, Train Acc: 0.747436 | Val Loss: 0.157560, Val Acc: 0.711340\n",
      "Epoch 7384 - Train Loss: 0.144014, Train Acc: 0.747436 | Val Loss: 0.157550, Val Acc: 0.711340\n",
      "Epoch 7385 - Train Loss: 0.144003, Train Acc: 0.747436 | Val Loss: 0.157540, Val Acc: 0.711340\n",
      "Epoch 7386 - Train Loss: 0.143992, Train Acc: 0.747436 | Val Loss: 0.157530, Val Acc: 0.711340\n",
      "Epoch 7387 - Train Loss: 0.143981, Train Acc: 0.747436 | Val Loss: 0.157520, Val Acc: 0.711340\n",
      "Epoch 7388 - Train Loss: 0.143969, Train Acc: 0.747436 | Val Loss: 0.157510, Val Acc: 0.711340\n",
      "Epoch 7389 - Train Loss: 0.143958, Train Acc: 0.747436 | Val Loss: 0.157501, Val Acc: 0.711340\n",
      "Epoch 7390 - Train Loss: 0.143947, Train Acc: 0.747436 | Val Loss: 0.157491, Val Acc: 0.711340\n",
      "Epoch 7391 - Train Loss: 0.143936, Train Acc: 0.747436 | Val Loss: 0.157481, Val Acc: 0.711340\n",
      "Epoch 7392 - Train Loss: 0.143925, Train Acc: 0.747436 | Val Loss: 0.157471, Val Acc: 0.711340\n",
      "Epoch 7393 - Train Loss: 0.143914, Train Acc: 0.747436 | Val Loss: 0.157461, Val Acc: 0.711340\n",
      "Epoch 7394 - Train Loss: 0.143903, Train Acc: 0.747436 | Val Loss: 0.157451, Val Acc: 0.711340\n",
      "Epoch 7395 - Train Loss: 0.143892, Train Acc: 0.747436 | Val Loss: 0.157442, Val Acc: 0.711340\n",
      "Epoch 7396 - Train Loss: 0.143881, Train Acc: 0.747436 | Val Loss: 0.157432, Val Acc: 0.711340\n",
      "Epoch 7397 - Train Loss: 0.143870, Train Acc: 0.747436 | Val Loss: 0.157422, Val Acc: 0.711340\n",
      "Epoch 7398 - Train Loss: 0.143859, Train Acc: 0.747436 | Val Loss: 0.157412, Val Acc: 0.711340\n",
      "Epoch 7399 - Train Loss: 0.143848, Train Acc: 0.748718 | Val Loss: 0.157402, Val Acc: 0.711340\n",
      "Epoch 7400 - Train Loss: 0.143837, Train Acc: 0.748718 | Val Loss: 0.157392, Val Acc: 0.711340\n",
      "Epoch 7401 - Train Loss: 0.143826, Train Acc: 0.748718 | Val Loss: 0.157383, Val Acc: 0.711340\n",
      "Epoch 7402 - Train Loss: 0.143815, Train Acc: 0.748718 | Val Loss: 0.157373, Val Acc: 0.711340\n",
      "Epoch 7403 - Train Loss: 0.143804, Train Acc: 0.748718 | Val Loss: 0.157363, Val Acc: 0.711340\n",
      "Epoch 7404 - Train Loss: 0.143793, Train Acc: 0.748718 | Val Loss: 0.157353, Val Acc: 0.711340\n",
      "Epoch 7405 - Train Loss: 0.143782, Train Acc: 0.748718 | Val Loss: 0.157343, Val Acc: 0.711340\n",
      "Epoch 7406 - Train Loss: 0.143771, Train Acc: 0.748718 | Val Loss: 0.157334, Val Acc: 0.711340\n",
      "Epoch 7407 - Train Loss: 0.143760, Train Acc: 0.748718 | Val Loss: 0.157324, Val Acc: 0.711340\n",
      "Epoch 7408 - Train Loss: 0.143749, Train Acc: 0.748718 | Val Loss: 0.157314, Val Acc: 0.711340\n",
      "Epoch 7409 - Train Loss: 0.143738, Train Acc: 0.748718 | Val Loss: 0.157304, Val Acc: 0.711340\n",
      "Epoch 7410 - Train Loss: 0.143727, Train Acc: 0.748718 | Val Loss: 0.157294, Val Acc: 0.711340\n",
      "Epoch 7411 - Train Loss: 0.143716, Train Acc: 0.748718 | Val Loss: 0.157284, Val Acc: 0.711340\n",
      "Epoch 7412 - Train Loss: 0.143706, Train Acc: 0.748718 | Val Loss: 0.157275, Val Acc: 0.711340\n",
      "Epoch 7413 - Train Loss: 0.143695, Train Acc: 0.748718 | Val Loss: 0.157265, Val Acc: 0.711340\n",
      "Epoch 7414 - Train Loss: 0.143684, Train Acc: 0.748718 | Val Loss: 0.157255, Val Acc: 0.711340\n",
      "Epoch 7415 - Train Loss: 0.143673, Train Acc: 0.748718 | Val Loss: 0.157245, Val Acc: 0.711340\n",
      "Epoch 7416 - Train Loss: 0.143662, Train Acc: 0.748718 | Val Loss: 0.157236, Val Acc: 0.711340\n",
      "Epoch 7417 - Train Loss: 0.143651, Train Acc: 0.748718 | Val Loss: 0.157226, Val Acc: 0.711340\n",
      "Epoch 7418 - Train Loss: 0.143640, Train Acc: 0.748718 | Val Loss: 0.157216, Val Acc: 0.711340\n",
      "Epoch 7419 - Train Loss: 0.143629, Train Acc: 0.748718 | Val Loss: 0.157206, Val Acc: 0.711340\n",
      "Epoch 7420 - Train Loss: 0.143618, Train Acc: 0.748718 | Val Loss: 0.157196, Val Acc: 0.711340\n",
      "Epoch 7421 - Train Loss: 0.143607, Train Acc: 0.748718 | Val Loss: 0.157187, Val Acc: 0.711340\n",
      "Epoch 7422 - Train Loss: 0.143596, Train Acc: 0.748718 | Val Loss: 0.157177, Val Acc: 0.711340\n",
      "Epoch 7423 - Train Loss: 0.143585, Train Acc: 0.748718 | Val Loss: 0.157167, Val Acc: 0.711340\n",
      "Epoch 7424 - Train Loss: 0.143574, Train Acc: 0.748718 | Val Loss: 0.157157, Val Acc: 0.711340\n",
      "Epoch 7425 - Train Loss: 0.143563, Train Acc: 0.748718 | Val Loss: 0.157147, Val Acc: 0.711340\n",
      "Epoch 7426 - Train Loss: 0.143552, Train Acc: 0.748718 | Val Loss: 0.157138, Val Acc: 0.711340\n",
      "Epoch 7427 - Train Loss: 0.143541, Train Acc: 0.748718 | Val Loss: 0.157128, Val Acc: 0.711340\n",
      "Epoch 7428 - Train Loss: 0.143530, Train Acc: 0.750000 | Val Loss: 0.157118, Val Acc: 0.711340\n",
      "Epoch 7429 - Train Loss: 0.143519, Train Acc: 0.750000 | Val Loss: 0.157108, Val Acc: 0.711340\n",
      "Epoch 7430 - Train Loss: 0.143508, Train Acc: 0.750000 | Val Loss: 0.157099, Val Acc: 0.711340\n",
      "Epoch 7431 - Train Loss: 0.143497, Train Acc: 0.750000 | Val Loss: 0.157089, Val Acc: 0.711340\n",
      "Epoch 7432 - Train Loss: 0.143486, Train Acc: 0.750000 | Val Loss: 0.157079, Val Acc: 0.711340\n",
      "Epoch 7433 - Train Loss: 0.143475, Train Acc: 0.750000 | Val Loss: 0.157069, Val Acc: 0.711340\n",
      "Epoch 7434 - Train Loss: 0.143464, Train Acc: 0.750000 | Val Loss: 0.157059, Val Acc: 0.711340\n",
      "Epoch 7435 - Train Loss: 0.143453, Train Acc: 0.750000 | Val Loss: 0.157050, Val Acc: 0.711340\n",
      "Epoch 7436 - Train Loss: 0.143442, Train Acc: 0.750000 | Val Loss: 0.157040, Val Acc: 0.711340\n",
      "Epoch 7437 - Train Loss: 0.143431, Train Acc: 0.750000 | Val Loss: 0.157030, Val Acc: 0.711340\n",
      "Epoch 7438 - Train Loss: 0.143421, Train Acc: 0.750000 | Val Loss: 0.157020, Val Acc: 0.711340\n",
      "Epoch 7439 - Train Loss: 0.143410, Train Acc: 0.750000 | Val Loss: 0.157011, Val Acc: 0.711340\n",
      "Epoch 7440 - Train Loss: 0.143399, Train Acc: 0.750000 | Val Loss: 0.157001, Val Acc: 0.711340\n",
      "Epoch 7441 - Train Loss: 0.143388, Train Acc: 0.750000 | Val Loss: 0.156991, Val Acc: 0.711340\n",
      "Epoch 7442 - Train Loss: 0.143377, Train Acc: 0.750000 | Val Loss: 0.156981, Val Acc: 0.711340\n",
      "Epoch 7443 - Train Loss: 0.143366, Train Acc: 0.750000 | Val Loss: 0.156972, Val Acc: 0.711340\n",
      "Epoch 7444 - Train Loss: 0.143355, Train Acc: 0.750000 | Val Loss: 0.156962, Val Acc: 0.711340\n",
      "Epoch 7445 - Train Loss: 0.143344, Train Acc: 0.750000 | Val Loss: 0.156952, Val Acc: 0.711340\n",
      "Epoch 7446 - Train Loss: 0.143333, Train Acc: 0.750000 | Val Loss: 0.156942, Val Acc: 0.711340\n",
      "Epoch 7447 - Train Loss: 0.143322, Train Acc: 0.750000 | Val Loss: 0.156933, Val Acc: 0.711340\n",
      "Epoch 7448 - Train Loss: 0.143311, Train Acc: 0.750000 | Val Loss: 0.156923, Val Acc: 0.711340\n",
      "Epoch 7449 - Train Loss: 0.143300, Train Acc: 0.750000 | Val Loss: 0.156913, Val Acc: 0.711340\n",
      "Epoch 7450 - Train Loss: 0.143289, Train Acc: 0.750000 | Val Loss: 0.156903, Val Acc: 0.711340\n",
      "Epoch 7451 - Train Loss: 0.143278, Train Acc: 0.751282 | Val Loss: 0.156894, Val Acc: 0.711340\n",
      "Epoch 7452 - Train Loss: 0.143268, Train Acc: 0.751282 | Val Loss: 0.156884, Val Acc: 0.711340\n",
      "Epoch 7453 - Train Loss: 0.143257, Train Acc: 0.751282 | Val Loss: 0.156874, Val Acc: 0.711340\n",
      "Epoch 7454 - Train Loss: 0.143246, Train Acc: 0.751282 | Val Loss: 0.156864, Val Acc: 0.711340\n",
      "Epoch 7455 - Train Loss: 0.143235, Train Acc: 0.751282 | Val Loss: 0.156855, Val Acc: 0.711340\n",
      "Epoch 7456 - Train Loss: 0.143224, Train Acc: 0.751282 | Val Loss: 0.156845, Val Acc: 0.711340\n",
      "Epoch 7457 - Train Loss: 0.143213, Train Acc: 0.751282 | Val Loss: 0.156835, Val Acc: 0.711340\n",
      "Epoch 7458 - Train Loss: 0.143202, Train Acc: 0.751282 | Val Loss: 0.156825, Val Acc: 0.711340\n",
      "Epoch 7459 - Train Loss: 0.143191, Train Acc: 0.751282 | Val Loss: 0.156816, Val Acc: 0.711340\n",
      "Epoch 7460 - Train Loss: 0.143180, Train Acc: 0.751282 | Val Loss: 0.156806, Val Acc: 0.711340\n",
      "Epoch 7461 - Train Loss: 0.143169, Train Acc: 0.751282 | Val Loss: 0.156796, Val Acc: 0.711340\n",
      "Epoch 7462 - Train Loss: 0.143158, Train Acc: 0.751282 | Val Loss: 0.156786, Val Acc: 0.711340\n",
      "Epoch 7463 - Train Loss: 0.143148, Train Acc: 0.751282 | Val Loss: 0.156777, Val Acc: 0.711340\n",
      "Epoch 7464 - Train Loss: 0.143137, Train Acc: 0.751282 | Val Loss: 0.156767, Val Acc: 0.711340\n",
      "Epoch 7465 - Train Loss: 0.143126, Train Acc: 0.751282 | Val Loss: 0.156757, Val Acc: 0.711340\n",
      "Epoch 7466 - Train Loss: 0.143115, Train Acc: 0.751282 | Val Loss: 0.156748, Val Acc: 0.711340\n",
      "Epoch 7467 - Train Loss: 0.143104, Train Acc: 0.751282 | Val Loss: 0.156738, Val Acc: 0.711340\n",
      "Epoch 7468 - Train Loss: 0.143093, Train Acc: 0.751282 | Val Loss: 0.156728, Val Acc: 0.711340\n",
      "Epoch 7469 - Train Loss: 0.143082, Train Acc: 0.751282 | Val Loss: 0.156718, Val Acc: 0.711340\n",
      "Epoch 7470 - Train Loss: 0.143071, Train Acc: 0.751282 | Val Loss: 0.156709, Val Acc: 0.711340\n",
      "Epoch 7471 - Train Loss: 0.143060, Train Acc: 0.751282 | Val Loss: 0.156699, Val Acc: 0.711340\n",
      "Epoch 7472 - Train Loss: 0.143049, Train Acc: 0.751282 | Val Loss: 0.156689, Val Acc: 0.711340\n",
      "Epoch 7473 - Train Loss: 0.143039, Train Acc: 0.751282 | Val Loss: 0.156680, Val Acc: 0.711340\n",
      "Epoch 7474 - Train Loss: 0.143028, Train Acc: 0.751282 | Val Loss: 0.156670, Val Acc: 0.711340\n",
      "Epoch 7475 - Train Loss: 0.143017, Train Acc: 0.751282 | Val Loss: 0.156660, Val Acc: 0.711340\n",
      "Epoch 7476 - Train Loss: 0.143006, Train Acc: 0.751282 | Val Loss: 0.156650, Val Acc: 0.711340\n",
      "Epoch 7477 - Train Loss: 0.142995, Train Acc: 0.751282 | Val Loss: 0.156641, Val Acc: 0.711340\n",
      "Epoch 7478 - Train Loss: 0.142984, Train Acc: 0.751282 | Val Loss: 0.156631, Val Acc: 0.711340\n",
      "Epoch 7479 - Train Loss: 0.142973, Train Acc: 0.751282 | Val Loss: 0.156621, Val Acc: 0.711340\n",
      "Epoch 7480 - Train Loss: 0.142962, Train Acc: 0.751282 | Val Loss: 0.156612, Val Acc: 0.711340\n",
      "Epoch 7481 - Train Loss: 0.142951, Train Acc: 0.751282 | Val Loss: 0.156602, Val Acc: 0.711340\n",
      "Epoch 7482 - Train Loss: 0.142941, Train Acc: 0.751282 | Val Loss: 0.156592, Val Acc: 0.711340\n",
      "Epoch 7483 - Train Loss: 0.142930, Train Acc: 0.751282 | Val Loss: 0.156582, Val Acc: 0.711340\n",
      "Epoch 7484 - Train Loss: 0.142919, Train Acc: 0.751282 | Val Loss: 0.156573, Val Acc: 0.711340\n",
      "Epoch 7485 - Train Loss: 0.142908, Train Acc: 0.751282 | Val Loss: 0.156563, Val Acc: 0.711340\n",
      "Epoch 7486 - Train Loss: 0.142897, Train Acc: 0.751282 | Val Loss: 0.156553, Val Acc: 0.711340\n",
      "Epoch 7487 - Train Loss: 0.142886, Train Acc: 0.751282 | Val Loss: 0.156544, Val Acc: 0.711340\n",
      "Epoch 7488 - Train Loss: 0.142875, Train Acc: 0.751282 | Val Loss: 0.156534, Val Acc: 0.711340\n",
      "Epoch 7489 - Train Loss: 0.142864, Train Acc: 0.751282 | Val Loss: 0.156524, Val Acc: 0.711340\n",
      "Epoch 7490 - Train Loss: 0.142854, Train Acc: 0.751282 | Val Loss: 0.156515, Val Acc: 0.711340\n",
      "Epoch 7491 - Train Loss: 0.142843, Train Acc: 0.751282 | Val Loss: 0.156505, Val Acc: 0.711340\n",
      "Epoch 7492 - Train Loss: 0.142832, Train Acc: 0.751282 | Val Loss: 0.156495, Val Acc: 0.711340\n",
      "Epoch 7493 - Train Loss: 0.142821, Train Acc: 0.751282 | Val Loss: 0.156486, Val Acc: 0.711340\n",
      "Epoch 7494 - Train Loss: 0.142810, Train Acc: 0.751282 | Val Loss: 0.156476, Val Acc: 0.711340\n",
      "Epoch 7495 - Train Loss: 0.142799, Train Acc: 0.751282 | Val Loss: 0.156466, Val Acc: 0.711340\n",
      "Epoch 7496 - Train Loss: 0.142788, Train Acc: 0.751282 | Val Loss: 0.156457, Val Acc: 0.711340\n",
      "Epoch 7497 - Train Loss: 0.142778, Train Acc: 0.751282 | Val Loss: 0.156447, Val Acc: 0.711340\n",
      "Epoch 7498 - Train Loss: 0.142767, Train Acc: 0.751282 | Val Loss: 0.156437, Val Acc: 0.711340\n",
      "Epoch 7499 - Train Loss: 0.142756, Train Acc: 0.751282 | Val Loss: 0.156427, Val Acc: 0.711340\n",
      "Epoch 7500 - Train Loss: 0.142745, Train Acc: 0.751282 | Val Loss: 0.156418, Val Acc: 0.711340\n",
      "Epoch 7501 - Train Loss: 0.142734, Train Acc: 0.751282 | Val Loss: 0.156408, Val Acc: 0.711340\n",
      "Epoch 7502 - Train Loss: 0.142723, Train Acc: 0.751282 | Val Loss: 0.156398, Val Acc: 0.711340\n",
      "Epoch 7503 - Train Loss: 0.142712, Train Acc: 0.751282 | Val Loss: 0.156389, Val Acc: 0.711340\n",
      "Epoch 7504 - Train Loss: 0.142702, Train Acc: 0.751282 | Val Loss: 0.156379, Val Acc: 0.711340\n",
      "Epoch 7505 - Train Loss: 0.142691, Train Acc: 0.751282 | Val Loss: 0.156369, Val Acc: 0.711340\n",
      "Epoch 7506 - Train Loss: 0.142680, Train Acc: 0.751282 | Val Loss: 0.156360, Val Acc: 0.711340\n",
      "Epoch 7507 - Train Loss: 0.142669, Train Acc: 0.751282 | Val Loss: 0.156350, Val Acc: 0.711340\n",
      "Epoch 7508 - Train Loss: 0.142658, Train Acc: 0.751282 | Val Loss: 0.156340, Val Acc: 0.711340\n",
      "Epoch 7509 - Train Loss: 0.142647, Train Acc: 0.751282 | Val Loss: 0.156331, Val Acc: 0.711340\n",
      "Epoch 7510 - Train Loss: 0.142637, Train Acc: 0.751282 | Val Loss: 0.156321, Val Acc: 0.711340\n",
      "Epoch 7511 - Train Loss: 0.142626, Train Acc: 0.751282 | Val Loss: 0.156311, Val Acc: 0.711340\n",
      "Epoch 7512 - Train Loss: 0.142615, Train Acc: 0.751282 | Val Loss: 0.156302, Val Acc: 0.711340\n",
      "Epoch 7513 - Train Loss: 0.142604, Train Acc: 0.751282 | Val Loss: 0.156292, Val Acc: 0.711340\n",
      "Epoch 7514 - Train Loss: 0.142593, Train Acc: 0.752564 | Val Loss: 0.156283, Val Acc: 0.711340\n",
      "Epoch 7515 - Train Loss: 0.142582, Train Acc: 0.752564 | Val Loss: 0.156273, Val Acc: 0.711340\n",
      "Epoch 7516 - Train Loss: 0.142572, Train Acc: 0.752564 | Val Loss: 0.156263, Val Acc: 0.711340\n",
      "Epoch 7517 - Train Loss: 0.142561, Train Acc: 0.752564 | Val Loss: 0.156254, Val Acc: 0.711340\n",
      "Epoch 7518 - Train Loss: 0.142550, Train Acc: 0.752564 | Val Loss: 0.156244, Val Acc: 0.711340\n",
      "Epoch 7519 - Train Loss: 0.142539, Train Acc: 0.752564 | Val Loss: 0.156234, Val Acc: 0.711340\n",
      "Epoch 7520 - Train Loss: 0.142528, Train Acc: 0.752564 | Val Loss: 0.156225, Val Acc: 0.711340\n",
      "Epoch 7521 - Train Loss: 0.142517, Train Acc: 0.752564 | Val Loss: 0.156215, Val Acc: 0.711340\n",
      "Epoch 7522 - Train Loss: 0.142507, Train Acc: 0.752564 | Val Loss: 0.156205, Val Acc: 0.711340\n",
      "Epoch 7523 - Train Loss: 0.142496, Train Acc: 0.752564 | Val Loss: 0.156196, Val Acc: 0.711340\n",
      "Epoch 7524 - Train Loss: 0.142485, Train Acc: 0.752564 | Val Loss: 0.156186, Val Acc: 0.711340\n",
      "Epoch 7525 - Train Loss: 0.142474, Train Acc: 0.752564 | Val Loss: 0.156177, Val Acc: 0.711340\n",
      "Epoch 7526 - Train Loss: 0.142463, Train Acc: 0.752564 | Val Loss: 0.156167, Val Acc: 0.711340\n",
      "Epoch 7527 - Train Loss: 0.142453, Train Acc: 0.752564 | Val Loss: 0.156157, Val Acc: 0.711340\n",
      "Epoch 7528 - Train Loss: 0.142442, Train Acc: 0.752564 | Val Loss: 0.156148, Val Acc: 0.711340\n",
      "Epoch 7529 - Train Loss: 0.142431, Train Acc: 0.752564 | Val Loss: 0.156138, Val Acc: 0.711340\n",
      "Epoch 7530 - Train Loss: 0.142420, Train Acc: 0.752564 | Val Loss: 0.156128, Val Acc: 0.711340\n",
      "Epoch 7531 - Train Loss: 0.142409, Train Acc: 0.752564 | Val Loss: 0.156119, Val Acc: 0.711340\n",
      "Epoch 7532 - Train Loss: 0.142398, Train Acc: 0.752564 | Val Loss: 0.156109, Val Acc: 0.711340\n",
      "Epoch 7533 - Train Loss: 0.142388, Train Acc: 0.752564 | Val Loss: 0.156100, Val Acc: 0.711340\n",
      "Epoch 7534 - Train Loss: 0.142377, Train Acc: 0.752564 | Val Loss: 0.156090, Val Acc: 0.711340\n",
      "Epoch 7535 - Train Loss: 0.142366, Train Acc: 0.752564 | Val Loss: 0.156080, Val Acc: 0.711340\n",
      "Epoch 7536 - Train Loss: 0.142355, Train Acc: 0.752564 | Val Loss: 0.156071, Val Acc: 0.711340\n",
      "Epoch 7537 - Train Loss: 0.142344, Train Acc: 0.752564 | Val Loss: 0.156061, Val Acc: 0.711340\n",
      "Epoch 7538 - Train Loss: 0.142334, Train Acc: 0.752564 | Val Loss: 0.156052, Val Acc: 0.711340\n",
      "Epoch 7539 - Train Loss: 0.142323, Train Acc: 0.752564 | Val Loss: 0.156042, Val Acc: 0.711340\n",
      "Epoch 7540 - Train Loss: 0.142312, Train Acc: 0.752564 | Val Loss: 0.156032, Val Acc: 0.711340\n",
      "Epoch 7541 - Train Loss: 0.142301, Train Acc: 0.752564 | Val Loss: 0.156023, Val Acc: 0.711340\n",
      "Epoch 7542 - Train Loss: 0.142291, Train Acc: 0.752564 | Val Loss: 0.156013, Val Acc: 0.701031\n",
      "Epoch 7543 - Train Loss: 0.142280, Train Acc: 0.752564 | Val Loss: 0.156004, Val Acc: 0.701031\n",
      "Epoch 7544 - Train Loss: 0.142269, Train Acc: 0.752564 | Val Loss: 0.155994, Val Acc: 0.701031\n",
      "Epoch 7545 - Train Loss: 0.142258, Train Acc: 0.752564 | Val Loss: 0.155984, Val Acc: 0.701031\n",
      "Epoch 7546 - Train Loss: 0.142247, Train Acc: 0.752564 | Val Loss: 0.155975, Val Acc: 0.701031\n",
      "Epoch 7547 - Train Loss: 0.142237, Train Acc: 0.752564 | Val Loss: 0.155965, Val Acc: 0.701031\n",
      "Epoch 7548 - Train Loss: 0.142226, Train Acc: 0.752564 | Val Loss: 0.155956, Val Acc: 0.701031\n",
      "Epoch 7549 - Train Loss: 0.142215, Train Acc: 0.752564 | Val Loss: 0.155946, Val Acc: 0.701031\n",
      "Epoch 7550 - Train Loss: 0.142204, Train Acc: 0.752564 | Val Loss: 0.155936, Val Acc: 0.701031\n",
      "Epoch 7551 - Train Loss: 0.142193, Train Acc: 0.752564 | Val Loss: 0.155927, Val Acc: 0.701031\n",
      "Epoch 7552 - Train Loss: 0.142183, Train Acc: 0.752564 | Val Loss: 0.155917, Val Acc: 0.701031\n",
      "Epoch 7553 - Train Loss: 0.142172, Train Acc: 0.752564 | Val Loss: 0.155908, Val Acc: 0.701031\n",
      "Epoch 7554 - Train Loss: 0.142161, Train Acc: 0.752564 | Val Loss: 0.155898, Val Acc: 0.701031\n",
      "Epoch 7555 - Train Loss: 0.142150, Train Acc: 0.752564 | Val Loss: 0.155889, Val Acc: 0.701031\n",
      "Epoch 7556 - Train Loss: 0.142140, Train Acc: 0.752564 | Val Loss: 0.155879, Val Acc: 0.701031\n",
      "Epoch 7557 - Train Loss: 0.142129, Train Acc: 0.752564 | Val Loss: 0.155869, Val Acc: 0.701031\n",
      "Epoch 7558 - Train Loss: 0.142118, Train Acc: 0.752564 | Val Loss: 0.155860, Val Acc: 0.701031\n",
      "Epoch 7559 - Train Loss: 0.142107, Train Acc: 0.752564 | Val Loss: 0.155850, Val Acc: 0.701031\n",
      "Epoch 7560 - Train Loss: 0.142097, Train Acc: 0.752564 | Val Loss: 0.155841, Val Acc: 0.701031\n",
      "Epoch 7561 - Train Loss: 0.142086, Train Acc: 0.752564 | Val Loss: 0.155831, Val Acc: 0.701031\n",
      "Epoch 7562 - Train Loss: 0.142075, Train Acc: 0.752564 | Val Loss: 0.155822, Val Acc: 0.701031\n",
      "Epoch 7563 - Train Loss: 0.142064, Train Acc: 0.752564 | Val Loss: 0.155812, Val Acc: 0.701031\n",
      "Epoch 7564 - Train Loss: 0.142054, Train Acc: 0.752564 | Val Loss: 0.155802, Val Acc: 0.701031\n",
      "Epoch 7565 - Train Loss: 0.142043, Train Acc: 0.752564 | Val Loss: 0.155793, Val Acc: 0.701031\n",
      "Epoch 7566 - Train Loss: 0.142032, Train Acc: 0.752564 | Val Loss: 0.155783, Val Acc: 0.701031\n",
      "Epoch 7567 - Train Loss: 0.142021, Train Acc: 0.753846 | Val Loss: 0.155774, Val Acc: 0.701031\n",
      "Epoch 7568 - Train Loss: 0.142011, Train Acc: 0.753846 | Val Loss: 0.155764, Val Acc: 0.701031\n",
      "Epoch 7569 - Train Loss: 0.142000, Train Acc: 0.753846 | Val Loss: 0.155755, Val Acc: 0.701031\n",
      "Epoch 7570 - Train Loss: 0.141989, Train Acc: 0.753846 | Val Loss: 0.155745, Val Acc: 0.701031\n",
      "Epoch 7571 - Train Loss: 0.141978, Train Acc: 0.753846 | Val Loss: 0.155735, Val Acc: 0.701031\n",
      "Epoch 7572 - Train Loss: 0.141968, Train Acc: 0.753846 | Val Loss: 0.155726, Val Acc: 0.701031\n",
      "Epoch 7573 - Train Loss: 0.141957, Train Acc: 0.753846 | Val Loss: 0.155716, Val Acc: 0.701031\n",
      "Epoch 7574 - Train Loss: 0.141946, Train Acc: 0.753846 | Val Loss: 0.155707, Val Acc: 0.701031\n",
      "Epoch 7575 - Train Loss: 0.141935, Train Acc: 0.753846 | Val Loss: 0.155697, Val Acc: 0.701031\n",
      "Epoch 7576 - Train Loss: 0.141925, Train Acc: 0.753846 | Val Loss: 0.155688, Val Acc: 0.701031\n",
      "Epoch 7577 - Train Loss: 0.141914, Train Acc: 0.753846 | Val Loss: 0.155678, Val Acc: 0.701031\n",
      "Epoch 7578 - Train Loss: 0.141903, Train Acc: 0.753846 | Val Loss: 0.155669, Val Acc: 0.701031\n",
      "Epoch 7579 - Train Loss: 0.141892, Train Acc: 0.753846 | Val Loss: 0.155659, Val Acc: 0.701031\n",
      "Epoch 7580 - Train Loss: 0.141882, Train Acc: 0.753846 | Val Loss: 0.155650, Val Acc: 0.701031\n",
      "Epoch 7581 - Train Loss: 0.141871, Train Acc: 0.753846 | Val Loss: 0.155640, Val Acc: 0.701031\n",
      "Epoch 7582 - Train Loss: 0.141860, Train Acc: 0.753846 | Val Loss: 0.155630, Val Acc: 0.701031\n",
      "Epoch 7583 - Train Loss: 0.141850, Train Acc: 0.753846 | Val Loss: 0.155621, Val Acc: 0.701031\n",
      "Epoch 7584 - Train Loss: 0.141839, Train Acc: 0.753846 | Val Loss: 0.155611, Val Acc: 0.701031\n",
      "Epoch 7585 - Train Loss: 0.141828, Train Acc: 0.753846 | Val Loss: 0.155602, Val Acc: 0.701031\n",
      "Epoch 7586 - Train Loss: 0.141817, Train Acc: 0.753846 | Val Loss: 0.155592, Val Acc: 0.701031\n",
      "Epoch 7587 - Train Loss: 0.141807, Train Acc: 0.753846 | Val Loss: 0.155583, Val Acc: 0.701031\n",
      "Epoch 7588 - Train Loss: 0.141796, Train Acc: 0.753846 | Val Loss: 0.155573, Val Acc: 0.701031\n",
      "Epoch 7589 - Train Loss: 0.141785, Train Acc: 0.753846 | Val Loss: 0.155564, Val Acc: 0.701031\n",
      "Epoch 7590 - Train Loss: 0.141774, Train Acc: 0.753846 | Val Loss: 0.155554, Val Acc: 0.701031\n",
      "Epoch 7591 - Train Loss: 0.141764, Train Acc: 0.753846 | Val Loss: 0.155545, Val Acc: 0.701031\n",
      "Epoch 7592 - Train Loss: 0.141753, Train Acc: 0.753846 | Val Loss: 0.155535, Val Acc: 0.701031\n",
      "Epoch 7593 - Train Loss: 0.141742, Train Acc: 0.753846 | Val Loss: 0.155526, Val Acc: 0.701031\n",
      "Epoch 7594 - Train Loss: 0.141732, Train Acc: 0.753846 | Val Loss: 0.155516, Val Acc: 0.701031\n",
      "Epoch 7595 - Train Loss: 0.141721, Train Acc: 0.753846 | Val Loss: 0.155507, Val Acc: 0.701031\n",
      "Epoch 7596 - Train Loss: 0.141710, Train Acc: 0.753846 | Val Loss: 0.155497, Val Acc: 0.701031\n",
      "Epoch 7597 - Train Loss: 0.141700, Train Acc: 0.753846 | Val Loss: 0.155488, Val Acc: 0.701031\n",
      "Epoch 7598 - Train Loss: 0.141689, Train Acc: 0.753846 | Val Loss: 0.155478, Val Acc: 0.701031\n",
      "Epoch 7599 - Train Loss: 0.141678, Train Acc: 0.753846 | Val Loss: 0.155469, Val Acc: 0.701031\n",
      "Epoch 7600 - Train Loss: 0.141667, Train Acc: 0.753846 | Val Loss: 0.155459, Val Acc: 0.701031\n",
      "Epoch 7601 - Train Loss: 0.141657, Train Acc: 0.753846 | Val Loss: 0.155450, Val Acc: 0.701031\n",
      "Epoch 7602 - Train Loss: 0.141646, Train Acc: 0.753846 | Val Loss: 0.155440, Val Acc: 0.701031\n",
      "Epoch 7603 - Train Loss: 0.141635, Train Acc: 0.753846 | Val Loss: 0.155431, Val Acc: 0.701031\n",
      "Epoch 7604 - Train Loss: 0.141625, Train Acc: 0.753846 | Val Loss: 0.155421, Val Acc: 0.701031\n",
      "Epoch 7605 - Train Loss: 0.141614, Train Acc: 0.753846 | Val Loss: 0.155412, Val Acc: 0.701031\n",
      "Epoch 7606 - Train Loss: 0.141603, Train Acc: 0.753846 | Val Loss: 0.155402, Val Acc: 0.701031\n",
      "Epoch 7607 - Train Loss: 0.141593, Train Acc: 0.753846 | Val Loss: 0.155393, Val Acc: 0.701031\n",
      "Epoch 7608 - Train Loss: 0.141582, Train Acc: 0.753846 | Val Loss: 0.155383, Val Acc: 0.701031\n",
      "Epoch 7609 - Train Loss: 0.141571, Train Acc: 0.753846 | Val Loss: 0.155374, Val Acc: 0.701031\n",
      "Epoch 7610 - Train Loss: 0.141560, Train Acc: 0.753846 | Val Loss: 0.155364, Val Acc: 0.701031\n",
      "Epoch 7611 - Train Loss: 0.141550, Train Acc: 0.753846 | Val Loss: 0.155355, Val Acc: 0.701031\n",
      "Epoch 7612 - Train Loss: 0.141539, Train Acc: 0.753846 | Val Loss: 0.155345, Val Acc: 0.701031\n",
      "Epoch 7613 - Train Loss: 0.141528, Train Acc: 0.753846 | Val Loss: 0.155336, Val Acc: 0.701031\n",
      "Epoch 7614 - Train Loss: 0.141518, Train Acc: 0.753846 | Val Loss: 0.155326, Val Acc: 0.701031\n",
      "Epoch 7615 - Train Loss: 0.141507, Train Acc: 0.753846 | Val Loss: 0.155317, Val Acc: 0.701031\n",
      "Epoch 7616 - Train Loss: 0.141496, Train Acc: 0.753846 | Val Loss: 0.155307, Val Acc: 0.701031\n",
      "Epoch 7617 - Train Loss: 0.141486, Train Acc: 0.753846 | Val Loss: 0.155298, Val Acc: 0.701031\n",
      "Epoch 7618 - Train Loss: 0.141475, Train Acc: 0.753846 | Val Loss: 0.155288, Val Acc: 0.701031\n",
      "Epoch 7619 - Train Loss: 0.141464, Train Acc: 0.753846 | Val Loss: 0.155279, Val Acc: 0.701031\n",
      "Epoch 7620 - Train Loss: 0.141454, Train Acc: 0.753846 | Val Loss: 0.155269, Val Acc: 0.701031\n",
      "Epoch 7621 - Train Loss: 0.141443, Train Acc: 0.753846 | Val Loss: 0.155260, Val Acc: 0.701031\n",
      "Epoch 7622 - Train Loss: 0.141432, Train Acc: 0.753846 | Val Loss: 0.155250, Val Acc: 0.701031\n",
      "Epoch 7623 - Train Loss: 0.141422, Train Acc: 0.755128 | Val Loss: 0.155241, Val Acc: 0.701031\n",
      "Epoch 7624 - Train Loss: 0.141411, Train Acc: 0.755128 | Val Loss: 0.155231, Val Acc: 0.701031\n",
      "Epoch 7625 - Train Loss: 0.141400, Train Acc: 0.755128 | Val Loss: 0.155222, Val Acc: 0.701031\n",
      "Epoch 7626 - Train Loss: 0.141390, Train Acc: 0.755128 | Val Loss: 0.155212, Val Acc: 0.701031\n",
      "Epoch 7627 - Train Loss: 0.141379, Train Acc: 0.755128 | Val Loss: 0.155203, Val Acc: 0.701031\n",
      "Epoch 7628 - Train Loss: 0.141368, Train Acc: 0.755128 | Val Loss: 0.155193, Val Acc: 0.701031\n",
      "Epoch 7629 - Train Loss: 0.141358, Train Acc: 0.755128 | Val Loss: 0.155184, Val Acc: 0.701031\n",
      "Epoch 7630 - Train Loss: 0.141347, Train Acc: 0.755128 | Val Loss: 0.155174, Val Acc: 0.701031\n",
      "Epoch 7631 - Train Loss: 0.141336, Train Acc: 0.755128 | Val Loss: 0.155165, Val Acc: 0.701031\n",
      "Epoch 7632 - Train Loss: 0.141326, Train Acc: 0.755128 | Val Loss: 0.155156, Val Acc: 0.701031\n",
      "Epoch 7633 - Train Loss: 0.141315, Train Acc: 0.755128 | Val Loss: 0.155146, Val Acc: 0.701031\n",
      "Epoch 7634 - Train Loss: 0.141304, Train Acc: 0.755128 | Val Loss: 0.155137, Val Acc: 0.701031\n",
      "Epoch 7635 - Train Loss: 0.141294, Train Acc: 0.755128 | Val Loss: 0.155127, Val Acc: 0.701031\n",
      "Epoch 7636 - Train Loss: 0.141283, Train Acc: 0.755128 | Val Loss: 0.155118, Val Acc: 0.701031\n",
      "Epoch 7637 - Train Loss: 0.141272, Train Acc: 0.755128 | Val Loss: 0.155108, Val Acc: 0.701031\n",
      "Epoch 7638 - Train Loss: 0.141262, Train Acc: 0.755128 | Val Loss: 0.155099, Val Acc: 0.701031\n",
      "Epoch 7639 - Train Loss: 0.141251, Train Acc: 0.755128 | Val Loss: 0.155089, Val Acc: 0.701031\n",
      "Epoch 7640 - Train Loss: 0.141240, Train Acc: 0.755128 | Val Loss: 0.155080, Val Acc: 0.701031\n",
      "Epoch 7641 - Train Loss: 0.141230, Train Acc: 0.755128 | Val Loss: 0.155070, Val Acc: 0.701031\n",
      "Epoch 7642 - Train Loss: 0.141219, Train Acc: 0.755128 | Val Loss: 0.155061, Val Acc: 0.701031\n",
      "Epoch 7643 - Train Loss: 0.141209, Train Acc: 0.755128 | Val Loss: 0.155052, Val Acc: 0.701031\n",
      "Epoch 7644 - Train Loss: 0.141198, Train Acc: 0.755128 | Val Loss: 0.155042, Val Acc: 0.701031\n",
      "Epoch 7645 - Train Loss: 0.141187, Train Acc: 0.755128 | Val Loss: 0.155033, Val Acc: 0.701031\n",
      "Epoch 7646 - Train Loss: 0.141177, Train Acc: 0.755128 | Val Loss: 0.155023, Val Acc: 0.701031\n",
      "Epoch 7647 - Train Loss: 0.141166, Train Acc: 0.755128 | Val Loss: 0.155014, Val Acc: 0.701031\n",
      "Epoch 7648 - Train Loss: 0.141155, Train Acc: 0.755128 | Val Loss: 0.155004, Val Acc: 0.701031\n",
      "Epoch 7649 - Train Loss: 0.141145, Train Acc: 0.755128 | Val Loss: 0.154995, Val Acc: 0.701031\n",
      "Epoch 7650 - Train Loss: 0.141134, Train Acc: 0.755128 | Val Loss: 0.154985, Val Acc: 0.701031\n",
      "Epoch 7651 - Train Loss: 0.141123, Train Acc: 0.756410 | Val Loss: 0.154976, Val Acc: 0.701031\n",
      "Epoch 7652 - Train Loss: 0.141113, Train Acc: 0.756410 | Val Loss: 0.154967, Val Acc: 0.701031\n",
      "Epoch 7653 - Train Loss: 0.141102, Train Acc: 0.756410 | Val Loss: 0.154957, Val Acc: 0.701031\n",
      "Epoch 7654 - Train Loss: 0.141092, Train Acc: 0.756410 | Val Loss: 0.154948, Val Acc: 0.701031\n",
      "Epoch 7655 - Train Loss: 0.141081, Train Acc: 0.756410 | Val Loss: 0.154938, Val Acc: 0.701031\n",
      "Epoch 7656 - Train Loss: 0.141070, Train Acc: 0.756410 | Val Loss: 0.154929, Val Acc: 0.701031\n",
      "Epoch 7657 - Train Loss: 0.141060, Train Acc: 0.756410 | Val Loss: 0.154919, Val Acc: 0.701031\n",
      "Epoch 7658 - Train Loss: 0.141049, Train Acc: 0.756410 | Val Loss: 0.154910, Val Acc: 0.701031\n",
      "Epoch 7659 - Train Loss: 0.141039, Train Acc: 0.756410 | Val Loss: 0.154901, Val Acc: 0.701031\n",
      "Epoch 7660 - Train Loss: 0.141028, Train Acc: 0.756410 | Val Loss: 0.154891, Val Acc: 0.701031\n",
      "Epoch 7661 - Train Loss: 0.141017, Train Acc: 0.756410 | Val Loss: 0.154882, Val Acc: 0.701031\n",
      "Epoch 7662 - Train Loss: 0.141007, Train Acc: 0.756410 | Val Loss: 0.154872, Val Acc: 0.701031\n",
      "Epoch 7663 - Train Loss: 0.140996, Train Acc: 0.756410 | Val Loss: 0.154863, Val Acc: 0.701031\n",
      "Epoch 7664 - Train Loss: 0.140985, Train Acc: 0.756410 | Val Loss: 0.154854, Val Acc: 0.701031\n",
      "Epoch 7665 - Train Loss: 0.140975, Train Acc: 0.756410 | Val Loss: 0.154844, Val Acc: 0.701031\n",
      "Epoch 7666 - Train Loss: 0.140964, Train Acc: 0.756410 | Val Loss: 0.154835, Val Acc: 0.701031\n",
      "Epoch 7667 - Train Loss: 0.140954, Train Acc: 0.756410 | Val Loss: 0.154825, Val Acc: 0.701031\n",
      "Epoch 7668 - Train Loss: 0.140943, Train Acc: 0.756410 | Val Loss: 0.154816, Val Acc: 0.701031\n",
      "Epoch 7669 - Train Loss: 0.140932, Train Acc: 0.756410 | Val Loss: 0.154806, Val Acc: 0.701031\n",
      "Epoch 7670 - Train Loss: 0.140922, Train Acc: 0.756410 | Val Loss: 0.154797, Val Acc: 0.701031\n",
      "Epoch 7671 - Train Loss: 0.140911, Train Acc: 0.756410 | Val Loss: 0.154788, Val Acc: 0.701031\n",
      "Epoch 7672 - Train Loss: 0.140901, Train Acc: 0.756410 | Val Loss: 0.154778, Val Acc: 0.701031\n",
      "Epoch 7673 - Train Loss: 0.140890, Train Acc: 0.756410 | Val Loss: 0.154769, Val Acc: 0.701031\n",
      "Epoch 7674 - Train Loss: 0.140879, Train Acc: 0.756410 | Val Loss: 0.154759, Val Acc: 0.701031\n",
      "Epoch 7675 - Train Loss: 0.140869, Train Acc: 0.756410 | Val Loss: 0.154750, Val Acc: 0.701031\n",
      "Epoch 7676 - Train Loss: 0.140858, Train Acc: 0.756410 | Val Loss: 0.154741, Val Acc: 0.701031\n",
      "Epoch 7677 - Train Loss: 0.140848, Train Acc: 0.756410 | Val Loss: 0.154731, Val Acc: 0.701031\n",
      "Epoch 7678 - Train Loss: 0.140837, Train Acc: 0.756410 | Val Loss: 0.154722, Val Acc: 0.701031\n",
      "Epoch 7679 - Train Loss: 0.140827, Train Acc: 0.756410 | Val Loss: 0.154712, Val Acc: 0.701031\n",
      "Epoch 7680 - Train Loss: 0.140816, Train Acc: 0.756410 | Val Loss: 0.154703, Val Acc: 0.701031\n",
      "Epoch 7681 - Train Loss: 0.140805, Train Acc: 0.756410 | Val Loss: 0.154694, Val Acc: 0.701031\n",
      "Epoch 7682 - Train Loss: 0.140795, Train Acc: 0.756410 | Val Loss: 0.154684, Val Acc: 0.701031\n",
      "Epoch 7683 - Train Loss: 0.140784, Train Acc: 0.756410 | Val Loss: 0.154675, Val Acc: 0.701031\n",
      "Epoch 7684 - Train Loss: 0.140774, Train Acc: 0.756410 | Val Loss: 0.154665, Val Acc: 0.701031\n",
      "Epoch 7685 - Train Loss: 0.140763, Train Acc: 0.756410 | Val Loss: 0.154656, Val Acc: 0.701031\n",
      "Epoch 7686 - Train Loss: 0.140752, Train Acc: 0.756410 | Val Loss: 0.154647, Val Acc: 0.701031\n",
      "Epoch 7687 - Train Loss: 0.140742, Train Acc: 0.756410 | Val Loss: 0.154637, Val Acc: 0.701031\n",
      "Epoch 7688 - Train Loss: 0.140731, Train Acc: 0.756410 | Val Loss: 0.154628, Val Acc: 0.701031\n",
      "Epoch 7689 - Train Loss: 0.140721, Train Acc: 0.756410 | Val Loss: 0.154619, Val Acc: 0.701031\n",
      "Epoch 7690 - Train Loss: 0.140710, Train Acc: 0.756410 | Val Loss: 0.154609, Val Acc: 0.701031\n",
      "Epoch 7691 - Train Loss: 0.140700, Train Acc: 0.756410 | Val Loss: 0.154600, Val Acc: 0.701031\n",
      "Epoch 7692 - Train Loss: 0.140689, Train Acc: 0.756410 | Val Loss: 0.154590, Val Acc: 0.701031\n",
      "Epoch 7693 - Train Loss: 0.140678, Train Acc: 0.756410 | Val Loss: 0.154581, Val Acc: 0.701031\n",
      "Epoch 7694 - Train Loss: 0.140668, Train Acc: 0.756410 | Val Loss: 0.154572, Val Acc: 0.701031\n",
      "Epoch 7695 - Train Loss: 0.140657, Train Acc: 0.756410 | Val Loss: 0.154562, Val Acc: 0.701031\n",
      "Epoch 7696 - Train Loss: 0.140647, Train Acc: 0.755128 | Val Loss: 0.154553, Val Acc: 0.701031\n",
      "Epoch 7697 - Train Loss: 0.140636, Train Acc: 0.755128 | Val Loss: 0.154544, Val Acc: 0.701031\n",
      "Epoch 7698 - Train Loss: 0.140626, Train Acc: 0.755128 | Val Loss: 0.154534, Val Acc: 0.701031\n",
      "Epoch 7699 - Train Loss: 0.140615, Train Acc: 0.755128 | Val Loss: 0.154525, Val Acc: 0.701031\n",
      "Epoch 7700 - Train Loss: 0.140605, Train Acc: 0.755128 | Val Loss: 0.154515, Val Acc: 0.701031\n",
      "Epoch 7701 - Train Loss: 0.140594, Train Acc: 0.755128 | Val Loss: 0.154506, Val Acc: 0.701031\n",
      "Epoch 7702 - Train Loss: 0.140583, Train Acc: 0.755128 | Val Loss: 0.154497, Val Acc: 0.701031\n",
      "Epoch 7703 - Train Loss: 0.140573, Train Acc: 0.755128 | Val Loss: 0.154487, Val Acc: 0.701031\n",
      "Epoch 7704 - Train Loss: 0.140562, Train Acc: 0.755128 | Val Loss: 0.154478, Val Acc: 0.701031\n",
      "Epoch 7705 - Train Loss: 0.140552, Train Acc: 0.755128 | Val Loss: 0.154469, Val Acc: 0.701031\n",
      "Epoch 7706 - Train Loss: 0.140541, Train Acc: 0.755128 | Val Loss: 0.154459, Val Acc: 0.701031\n",
      "Epoch 7707 - Train Loss: 0.140531, Train Acc: 0.755128 | Val Loss: 0.154450, Val Acc: 0.701031\n",
      "Epoch 7708 - Train Loss: 0.140520, Train Acc: 0.755128 | Val Loss: 0.154441, Val Acc: 0.701031\n",
      "Epoch 7709 - Train Loss: 0.140510, Train Acc: 0.755128 | Val Loss: 0.154431, Val Acc: 0.701031\n",
      "Epoch 7710 - Train Loss: 0.140499, Train Acc: 0.755128 | Val Loss: 0.154422, Val Acc: 0.701031\n",
      "Epoch 7711 - Train Loss: 0.140489, Train Acc: 0.755128 | Val Loss: 0.154413, Val Acc: 0.701031\n",
      "Epoch 7712 - Train Loss: 0.140478, Train Acc: 0.755128 | Val Loss: 0.154403, Val Acc: 0.701031\n",
      "Epoch 7713 - Train Loss: 0.140467, Train Acc: 0.755128 | Val Loss: 0.154394, Val Acc: 0.701031\n",
      "Epoch 7714 - Train Loss: 0.140457, Train Acc: 0.755128 | Val Loss: 0.154385, Val Acc: 0.701031\n",
      "Epoch 7715 - Train Loss: 0.140446, Train Acc: 0.755128 | Val Loss: 0.154375, Val Acc: 0.701031\n",
      "Epoch 7716 - Train Loss: 0.140436, Train Acc: 0.756410 | Val Loss: 0.154366, Val Acc: 0.701031\n",
      "Epoch 7717 - Train Loss: 0.140425, Train Acc: 0.756410 | Val Loss: 0.154357, Val Acc: 0.701031\n",
      "Epoch 7718 - Train Loss: 0.140415, Train Acc: 0.756410 | Val Loss: 0.154347, Val Acc: 0.701031\n",
      "Epoch 7719 - Train Loss: 0.140404, Train Acc: 0.756410 | Val Loss: 0.154338, Val Acc: 0.701031\n",
      "Epoch 7720 - Train Loss: 0.140394, Train Acc: 0.756410 | Val Loss: 0.154329, Val Acc: 0.701031\n",
      "Epoch 7721 - Train Loss: 0.140383, Train Acc: 0.756410 | Val Loss: 0.154319, Val Acc: 0.701031\n",
      "Epoch 7722 - Train Loss: 0.140373, Train Acc: 0.756410 | Val Loss: 0.154310, Val Acc: 0.701031\n",
      "Epoch 7723 - Train Loss: 0.140362, Train Acc: 0.756410 | Val Loss: 0.154301, Val Acc: 0.701031\n",
      "Epoch 7724 - Train Loss: 0.140352, Train Acc: 0.756410 | Val Loss: 0.154291, Val Acc: 0.701031\n",
      "Epoch 7725 - Train Loss: 0.140341, Train Acc: 0.756410 | Val Loss: 0.154282, Val Acc: 0.701031\n",
      "Epoch 7726 - Train Loss: 0.140331, Train Acc: 0.756410 | Val Loss: 0.154273, Val Acc: 0.701031\n",
      "Epoch 7727 - Train Loss: 0.140320, Train Acc: 0.756410 | Val Loss: 0.154263, Val Acc: 0.701031\n",
      "Epoch 7728 - Train Loss: 0.140310, Train Acc: 0.756410 | Val Loss: 0.154254, Val Acc: 0.701031\n",
      "Epoch 7729 - Train Loss: 0.140299, Train Acc: 0.756410 | Val Loss: 0.154245, Val Acc: 0.701031\n",
      "Epoch 7730 - Train Loss: 0.140289, Train Acc: 0.756410 | Val Loss: 0.154235, Val Acc: 0.701031\n",
      "Epoch 7731 - Train Loss: 0.140278, Train Acc: 0.756410 | Val Loss: 0.154226, Val Acc: 0.701031\n",
      "Epoch 7732 - Train Loss: 0.140267, Train Acc: 0.756410 | Val Loss: 0.154217, Val Acc: 0.701031\n",
      "Epoch 7733 - Train Loss: 0.140257, Train Acc: 0.756410 | Val Loss: 0.154207, Val Acc: 0.701031\n",
      "Epoch 7734 - Train Loss: 0.140246, Train Acc: 0.756410 | Val Loss: 0.154198, Val Acc: 0.701031\n",
      "Epoch 7735 - Train Loss: 0.140236, Train Acc: 0.756410 | Val Loss: 0.154189, Val Acc: 0.701031\n",
      "Epoch 7736 - Train Loss: 0.140225, Train Acc: 0.756410 | Val Loss: 0.154179, Val Acc: 0.701031\n",
      "Epoch 7737 - Train Loss: 0.140215, Train Acc: 0.756410 | Val Loss: 0.154170, Val Acc: 0.701031\n",
      "Epoch 7738 - Train Loss: 0.140204, Train Acc: 0.756410 | Val Loss: 0.154161, Val Acc: 0.701031\n",
      "Epoch 7739 - Train Loss: 0.140194, Train Acc: 0.756410 | Val Loss: 0.154152, Val Acc: 0.701031\n",
      "Epoch 7740 - Train Loss: 0.140183, Train Acc: 0.756410 | Val Loss: 0.154142, Val Acc: 0.701031\n",
      "Epoch 7741 - Train Loss: 0.140173, Train Acc: 0.757692 | Val Loss: 0.154133, Val Acc: 0.701031\n",
      "Epoch 7742 - Train Loss: 0.140162, Train Acc: 0.757692 | Val Loss: 0.154124, Val Acc: 0.701031\n",
      "Epoch 7743 - Train Loss: 0.140152, Train Acc: 0.757692 | Val Loss: 0.154114, Val Acc: 0.701031\n",
      "Epoch 7744 - Train Loss: 0.140141, Train Acc: 0.757692 | Val Loss: 0.154105, Val Acc: 0.701031\n",
      "Epoch 7745 - Train Loss: 0.140131, Train Acc: 0.757692 | Val Loss: 0.154096, Val Acc: 0.701031\n",
      "Epoch 7746 - Train Loss: 0.140120, Train Acc: 0.757692 | Val Loss: 0.154086, Val Acc: 0.701031\n",
      "Epoch 7747 - Train Loss: 0.140110, Train Acc: 0.757692 | Val Loss: 0.154077, Val Acc: 0.701031\n",
      "Epoch 7748 - Train Loss: 0.140099, Train Acc: 0.757692 | Val Loss: 0.154068, Val Acc: 0.701031\n",
      "Epoch 7749 - Train Loss: 0.140089, Train Acc: 0.757692 | Val Loss: 0.154059, Val Acc: 0.701031\n",
      "Epoch 7750 - Train Loss: 0.140079, Train Acc: 0.757692 | Val Loss: 0.154049, Val Acc: 0.701031\n",
      "Epoch 7751 - Train Loss: 0.140068, Train Acc: 0.757692 | Val Loss: 0.154040, Val Acc: 0.701031\n",
      "Epoch 7752 - Train Loss: 0.140058, Train Acc: 0.757692 | Val Loss: 0.154031, Val Acc: 0.701031\n",
      "Epoch 7753 - Train Loss: 0.140047, Train Acc: 0.757692 | Val Loss: 0.154021, Val Acc: 0.701031\n",
      "Epoch 7754 - Train Loss: 0.140037, Train Acc: 0.757692 | Val Loss: 0.154012, Val Acc: 0.701031\n",
      "Epoch 7755 - Train Loss: 0.140026, Train Acc: 0.757692 | Val Loss: 0.154003, Val Acc: 0.701031\n",
      "Epoch 7756 - Train Loss: 0.140016, Train Acc: 0.757692 | Val Loss: 0.153993, Val Acc: 0.701031\n",
      "Epoch 7757 - Train Loss: 0.140005, Train Acc: 0.757692 | Val Loss: 0.153984, Val Acc: 0.701031\n",
      "Epoch 7758 - Train Loss: 0.139995, Train Acc: 0.757692 | Val Loss: 0.153975, Val Acc: 0.701031\n",
      "Epoch 7759 - Train Loss: 0.139984, Train Acc: 0.757692 | Val Loss: 0.153966, Val Acc: 0.701031\n",
      "Epoch 7760 - Train Loss: 0.139974, Train Acc: 0.757692 | Val Loss: 0.153956, Val Acc: 0.701031\n",
      "Epoch 7761 - Train Loss: 0.139963, Train Acc: 0.757692 | Val Loss: 0.153947, Val Acc: 0.701031\n",
      "Epoch 7762 - Train Loss: 0.139953, Train Acc: 0.757692 | Val Loss: 0.153938, Val Acc: 0.701031\n",
      "Epoch 7763 - Train Loss: 0.139942, Train Acc: 0.757692 | Val Loss: 0.153929, Val Acc: 0.701031\n",
      "Epoch 7764 - Train Loss: 0.139932, Train Acc: 0.757692 | Val Loss: 0.153919, Val Acc: 0.701031\n",
      "Epoch 7765 - Train Loss: 0.139921, Train Acc: 0.757692 | Val Loss: 0.153910, Val Acc: 0.701031\n",
      "Epoch 7766 - Train Loss: 0.139911, Train Acc: 0.757692 | Val Loss: 0.153901, Val Acc: 0.701031\n",
      "Epoch 7767 - Train Loss: 0.139901, Train Acc: 0.757692 | Val Loss: 0.153891, Val Acc: 0.701031\n",
      "Epoch 7768 - Train Loss: 0.139890, Train Acc: 0.757692 | Val Loss: 0.153882, Val Acc: 0.701031\n",
      "Epoch 7769 - Train Loss: 0.139880, Train Acc: 0.757692 | Val Loss: 0.153873, Val Acc: 0.701031\n",
      "Epoch 7770 - Train Loss: 0.139869, Train Acc: 0.757692 | Val Loss: 0.153864, Val Acc: 0.701031\n",
      "Epoch 7771 - Train Loss: 0.139859, Train Acc: 0.757692 | Val Loss: 0.153854, Val Acc: 0.701031\n",
      "Epoch 7772 - Train Loss: 0.139848, Train Acc: 0.757692 | Val Loss: 0.153845, Val Acc: 0.701031\n",
      "Epoch 7773 - Train Loss: 0.139838, Train Acc: 0.757692 | Val Loss: 0.153836, Val Acc: 0.701031\n",
      "Epoch 7774 - Train Loss: 0.139827, Train Acc: 0.757692 | Val Loss: 0.153827, Val Acc: 0.701031\n",
      "Epoch 7775 - Train Loss: 0.139817, Train Acc: 0.757692 | Val Loss: 0.153817, Val Acc: 0.701031\n",
      "Epoch 7776 - Train Loss: 0.139806, Train Acc: 0.757692 | Val Loss: 0.153808, Val Acc: 0.701031\n",
      "Epoch 7777 - Train Loss: 0.139796, Train Acc: 0.757692 | Val Loss: 0.153799, Val Acc: 0.701031\n",
      "Epoch 7778 - Train Loss: 0.139786, Train Acc: 0.757692 | Val Loss: 0.153790, Val Acc: 0.701031\n",
      "Epoch 7779 - Train Loss: 0.139775, Train Acc: 0.757692 | Val Loss: 0.153780, Val Acc: 0.701031\n",
      "Epoch 7780 - Train Loss: 0.139765, Train Acc: 0.757692 | Val Loss: 0.153771, Val Acc: 0.701031\n",
      "Epoch 7781 - Train Loss: 0.139754, Train Acc: 0.757692 | Val Loss: 0.153762, Val Acc: 0.701031\n",
      "Epoch 7782 - Train Loss: 0.139744, Train Acc: 0.757692 | Val Loss: 0.153753, Val Acc: 0.701031\n",
      "Epoch 7783 - Train Loss: 0.139733, Train Acc: 0.757692 | Val Loss: 0.153743, Val Acc: 0.701031\n",
      "Epoch 7784 - Train Loss: 0.139723, Train Acc: 0.757692 | Val Loss: 0.153734, Val Acc: 0.701031\n",
      "Epoch 7785 - Train Loss: 0.139713, Train Acc: 0.757692 | Val Loss: 0.153725, Val Acc: 0.701031\n",
      "Epoch 7786 - Train Loss: 0.139702, Train Acc: 0.757692 | Val Loss: 0.153716, Val Acc: 0.701031\n",
      "Epoch 7787 - Train Loss: 0.139692, Train Acc: 0.757692 | Val Loss: 0.153707, Val Acc: 0.701031\n",
      "Epoch 7788 - Train Loss: 0.139681, Train Acc: 0.757692 | Val Loss: 0.153697, Val Acc: 0.701031\n",
      "Epoch 7789 - Train Loss: 0.139671, Train Acc: 0.757692 | Val Loss: 0.153688, Val Acc: 0.701031\n",
      "Epoch 7790 - Train Loss: 0.139660, Train Acc: 0.757692 | Val Loss: 0.153679, Val Acc: 0.701031\n",
      "Epoch 7791 - Train Loss: 0.139650, Train Acc: 0.757692 | Val Loss: 0.153670, Val Acc: 0.701031\n",
      "Epoch 7792 - Train Loss: 0.139640, Train Acc: 0.757692 | Val Loss: 0.153660, Val Acc: 0.701031\n",
      "Epoch 7793 - Train Loss: 0.139629, Train Acc: 0.757692 | Val Loss: 0.153651, Val Acc: 0.701031\n",
      "Epoch 7794 - Train Loss: 0.139619, Train Acc: 0.757692 | Val Loss: 0.153642, Val Acc: 0.701031\n",
      "Epoch 7795 - Train Loss: 0.139608, Train Acc: 0.757692 | Val Loss: 0.153633, Val Acc: 0.701031\n",
      "Epoch 7796 - Train Loss: 0.139598, Train Acc: 0.757692 | Val Loss: 0.153623, Val Acc: 0.701031\n",
      "Epoch 7797 - Train Loss: 0.139588, Train Acc: 0.757692 | Val Loss: 0.153614, Val Acc: 0.701031\n",
      "Epoch 7798 - Train Loss: 0.139577, Train Acc: 0.757692 | Val Loss: 0.153605, Val Acc: 0.701031\n",
      "Epoch 7799 - Train Loss: 0.139567, Train Acc: 0.757692 | Val Loss: 0.153596, Val Acc: 0.701031\n",
      "Epoch 7800 - Train Loss: 0.139556, Train Acc: 0.757692 | Val Loss: 0.153587, Val Acc: 0.701031\n",
      "Epoch 7801 - Train Loss: 0.139546, Train Acc: 0.757692 | Val Loss: 0.153577, Val Acc: 0.701031\n",
      "Epoch 7802 - Train Loss: 0.139535, Train Acc: 0.757692 | Val Loss: 0.153568, Val Acc: 0.701031\n",
      "Epoch 7803 - Train Loss: 0.139525, Train Acc: 0.757692 | Val Loss: 0.153559, Val Acc: 0.701031\n",
      "Epoch 7804 - Train Loss: 0.139515, Train Acc: 0.757692 | Val Loss: 0.153550, Val Acc: 0.711340\n",
      "Epoch 7805 - Train Loss: 0.139504, Train Acc: 0.757692 | Val Loss: 0.153540, Val Acc: 0.711340\n",
      "Epoch 7806 - Train Loss: 0.139494, Train Acc: 0.757692 | Val Loss: 0.153531, Val Acc: 0.711340\n",
      "Epoch 7807 - Train Loss: 0.139483, Train Acc: 0.757692 | Val Loss: 0.153522, Val Acc: 0.711340\n",
      "Epoch 7808 - Train Loss: 0.139473, Train Acc: 0.757692 | Val Loss: 0.153513, Val Acc: 0.711340\n",
      "Epoch 7809 - Train Loss: 0.139463, Train Acc: 0.757692 | Val Loss: 0.153504, Val Acc: 0.711340\n",
      "Epoch 7810 - Train Loss: 0.139452, Train Acc: 0.757692 | Val Loss: 0.153494, Val Acc: 0.711340\n",
      "Epoch 7811 - Train Loss: 0.139442, Train Acc: 0.757692 | Val Loss: 0.153485, Val Acc: 0.711340\n",
      "Epoch 7812 - Train Loss: 0.139432, Train Acc: 0.757692 | Val Loss: 0.153476, Val Acc: 0.711340\n",
      "Epoch 7813 - Train Loss: 0.139421, Train Acc: 0.757692 | Val Loss: 0.153467, Val Acc: 0.711340\n",
      "Epoch 7814 - Train Loss: 0.139411, Train Acc: 0.757692 | Val Loss: 0.153458, Val Acc: 0.711340\n",
      "Epoch 7815 - Train Loss: 0.139400, Train Acc: 0.757692 | Val Loss: 0.153448, Val Acc: 0.711340\n",
      "Epoch 7816 - Train Loss: 0.139390, Train Acc: 0.757692 | Val Loss: 0.153439, Val Acc: 0.711340\n",
      "Epoch 7817 - Train Loss: 0.139380, Train Acc: 0.758974 | Val Loss: 0.153430, Val Acc: 0.711340\n",
      "Epoch 7818 - Train Loss: 0.139369, Train Acc: 0.758974 | Val Loss: 0.153421, Val Acc: 0.711340\n",
      "Epoch 7819 - Train Loss: 0.139359, Train Acc: 0.758974 | Val Loss: 0.153412, Val Acc: 0.711340\n",
      "Epoch 7820 - Train Loss: 0.139348, Train Acc: 0.758974 | Val Loss: 0.153402, Val Acc: 0.711340\n",
      "Epoch 7821 - Train Loss: 0.139338, Train Acc: 0.758974 | Val Loss: 0.153393, Val Acc: 0.711340\n",
      "Epoch 7822 - Train Loss: 0.139328, Train Acc: 0.758974 | Val Loss: 0.153384, Val Acc: 0.711340\n",
      "Epoch 7823 - Train Loss: 0.139317, Train Acc: 0.758974 | Val Loss: 0.153375, Val Acc: 0.711340\n",
      "Epoch 7824 - Train Loss: 0.139307, Train Acc: 0.758974 | Val Loss: 0.153366, Val Acc: 0.711340\n",
      "Epoch 7825 - Train Loss: 0.139297, Train Acc: 0.758974 | Val Loss: 0.153356, Val Acc: 0.711340\n",
      "Epoch 7826 - Train Loss: 0.139286, Train Acc: 0.758974 | Val Loss: 0.153347, Val Acc: 0.711340\n",
      "Epoch 7827 - Train Loss: 0.139276, Train Acc: 0.758974 | Val Loss: 0.153338, Val Acc: 0.711340\n",
      "Epoch 7828 - Train Loss: 0.139265, Train Acc: 0.758974 | Val Loss: 0.153329, Val Acc: 0.711340\n",
      "Epoch 7829 - Train Loss: 0.139255, Train Acc: 0.758974 | Val Loss: 0.153320, Val Acc: 0.711340\n",
      "Epoch 7830 - Train Loss: 0.139245, Train Acc: 0.758974 | Val Loss: 0.153310, Val Acc: 0.711340\n",
      "Epoch 7831 - Train Loss: 0.139234, Train Acc: 0.758974 | Val Loss: 0.153301, Val Acc: 0.711340\n",
      "Epoch 7832 - Train Loss: 0.139224, Train Acc: 0.758974 | Val Loss: 0.153292, Val Acc: 0.711340\n",
      "Epoch 7833 - Train Loss: 0.139214, Train Acc: 0.758974 | Val Loss: 0.153283, Val Acc: 0.711340\n",
      "Epoch 7834 - Train Loss: 0.139203, Train Acc: 0.758974 | Val Loss: 0.153274, Val Acc: 0.711340\n",
      "Epoch 7835 - Train Loss: 0.139193, Train Acc: 0.758974 | Val Loss: 0.153265, Val Acc: 0.711340\n",
      "Epoch 7836 - Train Loss: 0.139183, Train Acc: 0.758974 | Val Loss: 0.153255, Val Acc: 0.711340\n",
      "Epoch 7837 - Train Loss: 0.139172, Train Acc: 0.758974 | Val Loss: 0.153246, Val Acc: 0.711340\n",
      "Epoch 7838 - Train Loss: 0.139162, Train Acc: 0.758974 | Val Loss: 0.153237, Val Acc: 0.711340\n",
      "Epoch 7839 - Train Loss: 0.139151, Train Acc: 0.758974 | Val Loss: 0.153228, Val Acc: 0.711340\n",
      "Epoch 7840 - Train Loss: 0.139141, Train Acc: 0.758974 | Val Loss: 0.153219, Val Acc: 0.711340\n",
      "Epoch 7841 - Train Loss: 0.139131, Train Acc: 0.758974 | Val Loss: 0.153210, Val Acc: 0.711340\n",
      "Epoch 7842 - Train Loss: 0.139120, Train Acc: 0.758974 | Val Loss: 0.153200, Val Acc: 0.711340\n",
      "Epoch 7843 - Train Loss: 0.139110, Train Acc: 0.758974 | Val Loss: 0.153191, Val Acc: 0.711340\n",
      "Epoch 7844 - Train Loss: 0.139100, Train Acc: 0.758974 | Val Loss: 0.153182, Val Acc: 0.711340\n",
      "Epoch 7845 - Train Loss: 0.139089, Train Acc: 0.758974 | Val Loss: 0.153173, Val Acc: 0.711340\n",
      "Epoch 7846 - Train Loss: 0.139079, Train Acc: 0.758974 | Val Loss: 0.153164, Val Acc: 0.711340\n",
      "Epoch 7847 - Train Loss: 0.139069, Train Acc: 0.758974 | Val Loss: 0.153155, Val Acc: 0.711340\n",
      "Epoch 7848 - Train Loss: 0.139058, Train Acc: 0.758974 | Val Loss: 0.153145, Val Acc: 0.711340\n",
      "Epoch 7849 - Train Loss: 0.139048, Train Acc: 0.758974 | Val Loss: 0.153136, Val Acc: 0.711340\n",
      "Epoch 7850 - Train Loss: 0.139038, Train Acc: 0.758974 | Val Loss: 0.153127, Val Acc: 0.711340\n",
      "Epoch 7851 - Train Loss: 0.139027, Train Acc: 0.758974 | Val Loss: 0.153118, Val Acc: 0.711340\n",
      "Epoch 7852 - Train Loss: 0.139017, Train Acc: 0.758974 | Val Loss: 0.153109, Val Acc: 0.711340\n",
      "Epoch 7853 - Train Loss: 0.139007, Train Acc: 0.758974 | Val Loss: 0.153100, Val Acc: 0.711340\n",
      "Epoch 7854 - Train Loss: 0.138996, Train Acc: 0.758974 | Val Loss: 0.153091, Val Acc: 0.711340\n",
      "Epoch 7855 - Train Loss: 0.138986, Train Acc: 0.758974 | Val Loss: 0.153081, Val Acc: 0.711340\n",
      "Epoch 7856 - Train Loss: 0.138976, Train Acc: 0.758974 | Val Loss: 0.153072, Val Acc: 0.711340\n",
      "Epoch 7857 - Train Loss: 0.138965, Train Acc: 0.758974 | Val Loss: 0.153063, Val Acc: 0.711340\n",
      "Epoch 7858 - Train Loss: 0.138955, Train Acc: 0.758974 | Val Loss: 0.153054, Val Acc: 0.711340\n",
      "Epoch 7859 - Train Loss: 0.138945, Train Acc: 0.758974 | Val Loss: 0.153045, Val Acc: 0.711340\n",
      "Epoch 7860 - Train Loss: 0.138934, Train Acc: 0.758974 | Val Loss: 0.153036, Val Acc: 0.711340\n",
      "Epoch 7861 - Train Loss: 0.138924, Train Acc: 0.758974 | Val Loss: 0.153026, Val Acc: 0.711340\n",
      "Epoch 7862 - Train Loss: 0.138914, Train Acc: 0.758974 | Val Loss: 0.153017, Val Acc: 0.711340\n",
      "Epoch 7863 - Train Loss: 0.138904, Train Acc: 0.758974 | Val Loss: 0.153008, Val Acc: 0.711340\n",
      "Epoch 7864 - Train Loss: 0.138893, Train Acc: 0.758974 | Val Loss: 0.152999, Val Acc: 0.711340\n",
      "Epoch 7865 - Train Loss: 0.138883, Train Acc: 0.758974 | Val Loss: 0.152990, Val Acc: 0.711340\n",
      "Epoch 7866 - Train Loss: 0.138873, Train Acc: 0.758974 | Val Loss: 0.152981, Val Acc: 0.711340\n",
      "Epoch 7867 - Train Loss: 0.138862, Train Acc: 0.760256 | Val Loss: 0.152972, Val Acc: 0.711340\n",
      "Epoch 7868 - Train Loss: 0.138852, Train Acc: 0.760256 | Val Loss: 0.152962, Val Acc: 0.711340\n",
      "Epoch 7869 - Train Loss: 0.138842, Train Acc: 0.760256 | Val Loss: 0.152953, Val Acc: 0.711340\n",
      "Epoch 7870 - Train Loss: 0.138831, Train Acc: 0.760256 | Val Loss: 0.152944, Val Acc: 0.711340\n",
      "Epoch 7871 - Train Loss: 0.138821, Train Acc: 0.760256 | Val Loss: 0.152935, Val Acc: 0.711340\n",
      "Epoch 7872 - Train Loss: 0.138811, Train Acc: 0.760256 | Val Loss: 0.152926, Val Acc: 0.711340\n",
      "Epoch 7873 - Train Loss: 0.138800, Train Acc: 0.760256 | Val Loss: 0.152917, Val Acc: 0.711340\n",
      "Epoch 7874 - Train Loss: 0.138790, Train Acc: 0.760256 | Val Loss: 0.152908, Val Acc: 0.711340\n",
      "Epoch 7875 - Train Loss: 0.138780, Train Acc: 0.760256 | Val Loss: 0.152898, Val Acc: 0.711340\n",
      "Epoch 7876 - Train Loss: 0.138770, Train Acc: 0.760256 | Val Loss: 0.152889, Val Acc: 0.711340\n",
      "Epoch 7877 - Train Loss: 0.138759, Train Acc: 0.760256 | Val Loss: 0.152880, Val Acc: 0.711340\n",
      "Epoch 7878 - Train Loss: 0.138749, Train Acc: 0.760256 | Val Loss: 0.152871, Val Acc: 0.711340\n",
      "Epoch 7879 - Train Loss: 0.138739, Train Acc: 0.760256 | Val Loss: 0.152862, Val Acc: 0.711340\n",
      "Epoch 7880 - Train Loss: 0.138728, Train Acc: 0.760256 | Val Loss: 0.152853, Val Acc: 0.711340\n",
      "Epoch 7881 - Train Loss: 0.138718, Train Acc: 0.760256 | Val Loss: 0.152844, Val Acc: 0.711340\n",
      "Epoch 7882 - Train Loss: 0.138708, Train Acc: 0.760256 | Val Loss: 0.152835, Val Acc: 0.711340\n",
      "Epoch 7883 - Train Loss: 0.138698, Train Acc: 0.760256 | Val Loss: 0.152826, Val Acc: 0.711340\n",
      "Epoch 7884 - Train Loss: 0.138687, Train Acc: 0.760256 | Val Loss: 0.152816, Val Acc: 0.711340\n",
      "Epoch 7885 - Train Loss: 0.138677, Train Acc: 0.760256 | Val Loss: 0.152807, Val Acc: 0.711340\n",
      "Epoch 7886 - Train Loss: 0.138667, Train Acc: 0.760256 | Val Loss: 0.152798, Val Acc: 0.711340\n",
      "Epoch 7887 - Train Loss: 0.138656, Train Acc: 0.760256 | Val Loss: 0.152789, Val Acc: 0.711340\n",
      "Epoch 7888 - Train Loss: 0.138646, Train Acc: 0.760256 | Val Loss: 0.152780, Val Acc: 0.711340\n",
      "Epoch 7889 - Train Loss: 0.138636, Train Acc: 0.760256 | Val Loss: 0.152771, Val Acc: 0.711340\n",
      "Epoch 7890 - Train Loss: 0.138626, Train Acc: 0.760256 | Val Loss: 0.152762, Val Acc: 0.711340\n",
      "Epoch 7891 - Train Loss: 0.138615, Train Acc: 0.760256 | Val Loss: 0.152753, Val Acc: 0.711340\n",
      "Epoch 7892 - Train Loss: 0.138605, Train Acc: 0.760256 | Val Loss: 0.152743, Val Acc: 0.711340\n",
      "Epoch 7893 - Train Loss: 0.138595, Train Acc: 0.760256 | Val Loss: 0.152734, Val Acc: 0.711340\n",
      "Epoch 7894 - Train Loss: 0.138584, Train Acc: 0.760256 | Val Loss: 0.152725, Val Acc: 0.711340\n",
      "Epoch 7895 - Train Loss: 0.138574, Train Acc: 0.760256 | Val Loss: 0.152716, Val Acc: 0.711340\n",
      "Epoch 7896 - Train Loss: 0.138564, Train Acc: 0.760256 | Val Loss: 0.152707, Val Acc: 0.711340\n",
      "Epoch 7897 - Train Loss: 0.138554, Train Acc: 0.760256 | Val Loss: 0.152698, Val Acc: 0.711340\n",
      "Epoch 7898 - Train Loss: 0.138543, Train Acc: 0.760256 | Val Loss: 0.152689, Val Acc: 0.711340\n",
      "Epoch 7899 - Train Loss: 0.138533, Train Acc: 0.760256 | Val Loss: 0.152680, Val Acc: 0.711340\n",
      "Epoch 7900 - Train Loss: 0.138523, Train Acc: 0.760256 | Val Loss: 0.152671, Val Acc: 0.711340\n",
      "Epoch 7901 - Train Loss: 0.138513, Train Acc: 0.760256 | Val Loss: 0.152662, Val Acc: 0.711340\n",
      "Epoch 7902 - Train Loss: 0.138502, Train Acc: 0.760256 | Val Loss: 0.152652, Val Acc: 0.711340\n",
      "Epoch 7903 - Train Loss: 0.138492, Train Acc: 0.760256 | Val Loss: 0.152643, Val Acc: 0.711340\n",
      "Epoch 7904 - Train Loss: 0.138482, Train Acc: 0.760256 | Val Loss: 0.152634, Val Acc: 0.711340\n",
      "Epoch 7905 - Train Loss: 0.138472, Train Acc: 0.760256 | Val Loss: 0.152625, Val Acc: 0.711340\n",
      "Epoch 7906 - Train Loss: 0.138461, Train Acc: 0.760256 | Val Loss: 0.152616, Val Acc: 0.711340\n",
      "Epoch 7907 - Train Loss: 0.138451, Train Acc: 0.760256 | Val Loss: 0.152607, Val Acc: 0.711340\n",
      "Epoch 7908 - Train Loss: 0.138441, Train Acc: 0.760256 | Val Loss: 0.152598, Val Acc: 0.711340\n",
      "Epoch 7909 - Train Loss: 0.138431, Train Acc: 0.760256 | Val Loss: 0.152589, Val Acc: 0.711340\n",
      "Epoch 7910 - Train Loss: 0.138420, Train Acc: 0.760256 | Val Loss: 0.152580, Val Acc: 0.711340\n",
      "Epoch 7911 - Train Loss: 0.138410, Train Acc: 0.760256 | Val Loss: 0.152571, Val Acc: 0.711340\n",
      "Epoch 7912 - Train Loss: 0.138400, Train Acc: 0.760256 | Val Loss: 0.152562, Val Acc: 0.711340\n",
      "Epoch 7913 - Train Loss: 0.138390, Train Acc: 0.760256 | Val Loss: 0.152553, Val Acc: 0.711340\n",
      "Epoch 7914 - Train Loss: 0.138379, Train Acc: 0.760256 | Val Loss: 0.152543, Val Acc: 0.711340\n",
      "Epoch 7915 - Train Loss: 0.138369, Train Acc: 0.760256 | Val Loss: 0.152534, Val Acc: 0.711340\n",
      "Epoch 7916 - Train Loss: 0.138359, Train Acc: 0.760256 | Val Loss: 0.152525, Val Acc: 0.711340\n",
      "Epoch 7917 - Train Loss: 0.138349, Train Acc: 0.760256 | Val Loss: 0.152516, Val Acc: 0.711340\n",
      "Epoch 7918 - Train Loss: 0.138338, Train Acc: 0.760256 | Val Loss: 0.152507, Val Acc: 0.711340\n",
      "Epoch 7919 - Train Loss: 0.138328, Train Acc: 0.760256 | Val Loss: 0.152498, Val Acc: 0.711340\n",
      "Epoch 7920 - Train Loss: 0.138318, Train Acc: 0.760256 | Val Loss: 0.152489, Val Acc: 0.711340\n",
      "Epoch 7921 - Train Loss: 0.138308, Train Acc: 0.760256 | Val Loss: 0.152480, Val Acc: 0.711340\n",
      "Epoch 7922 - Train Loss: 0.138297, Train Acc: 0.760256 | Val Loss: 0.152471, Val Acc: 0.711340\n",
      "Epoch 7923 - Train Loss: 0.138287, Train Acc: 0.760256 | Val Loss: 0.152462, Val Acc: 0.711340\n",
      "Epoch 7924 - Train Loss: 0.138277, Train Acc: 0.760256 | Val Loss: 0.152453, Val Acc: 0.711340\n",
      "Epoch 7925 - Train Loss: 0.138267, Train Acc: 0.760256 | Val Loss: 0.152444, Val Acc: 0.711340\n",
      "Epoch 7926 - Train Loss: 0.138257, Train Acc: 0.760256 | Val Loss: 0.152435, Val Acc: 0.711340\n",
      "Epoch 7927 - Train Loss: 0.138246, Train Acc: 0.760256 | Val Loss: 0.152426, Val Acc: 0.711340\n",
      "Epoch 7928 - Train Loss: 0.138236, Train Acc: 0.760256 | Val Loss: 0.152417, Val Acc: 0.711340\n",
      "Epoch 7929 - Train Loss: 0.138226, Train Acc: 0.760256 | Val Loss: 0.152408, Val Acc: 0.711340\n",
      "Epoch 7930 - Train Loss: 0.138216, Train Acc: 0.760256 | Val Loss: 0.152398, Val Acc: 0.711340\n",
      "Epoch 7931 - Train Loss: 0.138206, Train Acc: 0.760256 | Val Loss: 0.152389, Val Acc: 0.711340\n",
      "Epoch 7932 - Train Loss: 0.138195, Train Acc: 0.760256 | Val Loss: 0.152380, Val Acc: 0.711340\n",
      "Epoch 7933 - Train Loss: 0.138185, Train Acc: 0.760256 | Val Loss: 0.152371, Val Acc: 0.711340\n",
      "Epoch 7934 - Train Loss: 0.138175, Train Acc: 0.760256 | Val Loss: 0.152362, Val Acc: 0.711340\n",
      "Epoch 7935 - Train Loss: 0.138165, Train Acc: 0.760256 | Val Loss: 0.152353, Val Acc: 0.711340\n",
      "Epoch 7936 - Train Loss: 0.138154, Train Acc: 0.760256 | Val Loss: 0.152344, Val Acc: 0.711340\n",
      "Epoch 7937 - Train Loss: 0.138144, Train Acc: 0.760256 | Val Loss: 0.152335, Val Acc: 0.711340\n",
      "Epoch 7938 - Train Loss: 0.138134, Train Acc: 0.760256 | Val Loss: 0.152326, Val Acc: 0.711340\n",
      "Epoch 7939 - Train Loss: 0.138124, Train Acc: 0.760256 | Val Loss: 0.152317, Val Acc: 0.711340\n",
      "Epoch 7940 - Train Loss: 0.138114, Train Acc: 0.760256 | Val Loss: 0.152308, Val Acc: 0.711340\n",
      "Epoch 7941 - Train Loss: 0.138103, Train Acc: 0.760256 | Val Loss: 0.152299, Val Acc: 0.711340\n",
      "Epoch 7942 - Train Loss: 0.138093, Train Acc: 0.760256 | Val Loss: 0.152290, Val Acc: 0.711340\n",
      "Epoch 7943 - Train Loss: 0.138083, Train Acc: 0.760256 | Val Loss: 0.152281, Val Acc: 0.711340\n",
      "Epoch 7944 - Train Loss: 0.138073, Train Acc: 0.760256 | Val Loss: 0.152272, Val Acc: 0.711340\n",
      "Epoch 7945 - Train Loss: 0.138063, Train Acc: 0.760256 | Val Loss: 0.152263, Val Acc: 0.711340\n",
      "Epoch 7946 - Train Loss: 0.138053, Train Acc: 0.760256 | Val Loss: 0.152254, Val Acc: 0.711340\n",
      "Epoch 7947 - Train Loss: 0.138042, Train Acc: 0.760256 | Val Loss: 0.152245, Val Acc: 0.711340\n",
      "Epoch 7948 - Train Loss: 0.138032, Train Acc: 0.760256 | Val Loss: 0.152236, Val Acc: 0.711340\n",
      "Epoch 7949 - Train Loss: 0.138022, Train Acc: 0.760256 | Val Loss: 0.152227, Val Acc: 0.711340\n",
      "Epoch 7950 - Train Loss: 0.138012, Train Acc: 0.760256 | Val Loss: 0.152218, Val Acc: 0.711340\n",
      "Epoch 7951 - Train Loss: 0.138002, Train Acc: 0.760256 | Val Loss: 0.152209, Val Acc: 0.711340\n",
      "Epoch 7952 - Train Loss: 0.137991, Train Acc: 0.760256 | Val Loss: 0.152200, Val Acc: 0.711340\n",
      "Epoch 7953 - Train Loss: 0.137981, Train Acc: 0.760256 | Val Loss: 0.152191, Val Acc: 0.711340\n",
      "Epoch 7954 - Train Loss: 0.137971, Train Acc: 0.760256 | Val Loss: 0.152182, Val Acc: 0.711340\n",
      "Epoch 7955 - Train Loss: 0.137961, Train Acc: 0.760256 | Val Loss: 0.152173, Val Acc: 0.711340\n",
      "Epoch 7956 - Train Loss: 0.137951, Train Acc: 0.760256 | Val Loss: 0.152164, Val Acc: 0.711340\n",
      "Epoch 7957 - Train Loss: 0.137941, Train Acc: 0.760256 | Val Loss: 0.152155, Val Acc: 0.711340\n",
      "Epoch 7958 - Train Loss: 0.137930, Train Acc: 0.760256 | Val Loss: 0.152146, Val Acc: 0.711340\n",
      "Epoch 7959 - Train Loss: 0.137920, Train Acc: 0.760256 | Val Loss: 0.152137, Val Acc: 0.711340\n",
      "Epoch 7960 - Train Loss: 0.137910, Train Acc: 0.760256 | Val Loss: 0.152128, Val Acc: 0.711340\n",
      "Epoch 7961 - Train Loss: 0.137900, Train Acc: 0.760256 | Val Loss: 0.152119, Val Acc: 0.711340\n",
      "Epoch 7962 - Train Loss: 0.137890, Train Acc: 0.761538 | Val Loss: 0.152110, Val Acc: 0.711340\n",
      "Epoch 7963 - Train Loss: 0.137880, Train Acc: 0.761538 | Val Loss: 0.152101, Val Acc: 0.701031\n",
      "Epoch 7964 - Train Loss: 0.137869, Train Acc: 0.761538 | Val Loss: 0.152092, Val Acc: 0.701031\n",
      "Epoch 7965 - Train Loss: 0.137859, Train Acc: 0.761538 | Val Loss: 0.152083, Val Acc: 0.701031\n",
      "Epoch 7966 - Train Loss: 0.137849, Train Acc: 0.761538 | Val Loss: 0.152074, Val Acc: 0.701031\n",
      "Epoch 7967 - Train Loss: 0.137839, Train Acc: 0.761538 | Val Loss: 0.152065, Val Acc: 0.701031\n",
      "Epoch 7968 - Train Loss: 0.137829, Train Acc: 0.761538 | Val Loss: 0.152056, Val Acc: 0.701031\n",
      "Epoch 7969 - Train Loss: 0.137819, Train Acc: 0.761538 | Val Loss: 0.152047, Val Acc: 0.701031\n",
      "Epoch 7970 - Train Loss: 0.137808, Train Acc: 0.762821 | Val Loss: 0.152038, Val Acc: 0.701031\n",
      "Epoch 7971 - Train Loss: 0.137798, Train Acc: 0.762821 | Val Loss: 0.152029, Val Acc: 0.701031\n",
      "Epoch 7972 - Train Loss: 0.137788, Train Acc: 0.762821 | Val Loss: 0.152020, Val Acc: 0.701031\n",
      "Epoch 7973 - Train Loss: 0.137778, Train Acc: 0.762821 | Val Loss: 0.152011, Val Acc: 0.701031\n",
      "Epoch 7974 - Train Loss: 0.137768, Train Acc: 0.762821 | Val Loss: 0.152002, Val Acc: 0.701031\n",
      "Epoch 7975 - Train Loss: 0.137758, Train Acc: 0.762821 | Val Loss: 0.151993, Val Acc: 0.701031\n",
      "Epoch 7976 - Train Loss: 0.137748, Train Acc: 0.762821 | Val Loss: 0.151984, Val Acc: 0.701031\n",
      "Epoch 7977 - Train Loss: 0.137737, Train Acc: 0.762821 | Val Loss: 0.151975, Val Acc: 0.701031\n",
      "Epoch 7978 - Train Loss: 0.137727, Train Acc: 0.762821 | Val Loss: 0.151966, Val Acc: 0.701031\n",
      "Epoch 7979 - Train Loss: 0.137717, Train Acc: 0.762821 | Val Loss: 0.151957, Val Acc: 0.701031\n",
      "Epoch 7980 - Train Loss: 0.137707, Train Acc: 0.762821 | Val Loss: 0.151948, Val Acc: 0.701031\n",
      "Epoch 7981 - Train Loss: 0.137697, Train Acc: 0.762821 | Val Loss: 0.151939, Val Acc: 0.701031\n",
      "Epoch 7982 - Train Loss: 0.137687, Train Acc: 0.762821 | Val Loss: 0.151930, Val Acc: 0.701031\n",
      "Epoch 7983 - Train Loss: 0.137677, Train Acc: 0.762821 | Val Loss: 0.151921, Val Acc: 0.701031\n",
      "Epoch 7984 - Train Loss: 0.137666, Train Acc: 0.762821 | Val Loss: 0.151912, Val Acc: 0.701031\n",
      "Epoch 7985 - Train Loss: 0.137656, Train Acc: 0.762821 | Val Loss: 0.151903, Val Acc: 0.701031\n",
      "Epoch 7986 - Train Loss: 0.137646, Train Acc: 0.762821 | Val Loss: 0.151894, Val Acc: 0.701031\n",
      "Epoch 7987 - Train Loss: 0.137636, Train Acc: 0.762821 | Val Loss: 0.151885, Val Acc: 0.701031\n",
      "Epoch 7988 - Train Loss: 0.137626, Train Acc: 0.762821 | Val Loss: 0.151876, Val Acc: 0.701031\n",
      "Epoch 7989 - Train Loss: 0.137616, Train Acc: 0.762821 | Val Loss: 0.151867, Val Acc: 0.701031\n",
      "Epoch 7990 - Train Loss: 0.137606, Train Acc: 0.762821 | Val Loss: 0.151858, Val Acc: 0.701031\n",
      "Epoch 7991 - Train Loss: 0.137596, Train Acc: 0.762821 | Val Loss: 0.151849, Val Acc: 0.701031\n",
      "Epoch 7992 - Train Loss: 0.137585, Train Acc: 0.762821 | Val Loss: 0.151840, Val Acc: 0.701031\n",
      "Epoch 7993 - Train Loss: 0.137575, Train Acc: 0.762821 | Val Loss: 0.151831, Val Acc: 0.701031\n",
      "Epoch 7994 - Train Loss: 0.137565, Train Acc: 0.762821 | Val Loss: 0.151822, Val Acc: 0.701031\n",
      "Epoch 7995 - Train Loss: 0.137555, Train Acc: 0.762821 | Val Loss: 0.151813, Val Acc: 0.701031\n",
      "Epoch 7996 - Train Loss: 0.137545, Train Acc: 0.762821 | Val Loss: 0.151804, Val Acc: 0.701031\n",
      "Epoch 7997 - Train Loss: 0.137535, Train Acc: 0.762821 | Val Loss: 0.151795, Val Acc: 0.701031\n",
      "Epoch 7998 - Train Loss: 0.137525, Train Acc: 0.762821 | Val Loss: 0.151786, Val Acc: 0.701031\n",
      "Epoch 7999 - Train Loss: 0.137515, Train Acc: 0.762821 | Val Loss: 0.151777, Val Acc: 0.701031\n",
      "Epoch 8000 - Train Loss: 0.137504, Train Acc: 0.762821 | Val Loss: 0.151769, Val Acc: 0.701031\n",
      "Epoch 8001 - Train Loss: 0.137494, Train Acc: 0.762821 | Val Loss: 0.151760, Val Acc: 0.701031\n",
      "Epoch 8002 - Train Loss: 0.137484, Train Acc: 0.762821 | Val Loss: 0.151751, Val Acc: 0.701031\n",
      "Epoch 8003 - Train Loss: 0.137474, Train Acc: 0.762821 | Val Loss: 0.151742, Val Acc: 0.701031\n",
      "Epoch 8004 - Train Loss: 0.137464, Train Acc: 0.762821 | Val Loss: 0.151733, Val Acc: 0.701031\n",
      "Epoch 8005 - Train Loss: 0.137454, Train Acc: 0.762821 | Val Loss: 0.151724, Val Acc: 0.701031\n",
      "Epoch 8006 - Train Loss: 0.137444, Train Acc: 0.762821 | Val Loss: 0.151715, Val Acc: 0.701031\n",
      "Epoch 8007 - Train Loss: 0.137434, Train Acc: 0.762821 | Val Loss: 0.151706, Val Acc: 0.701031\n",
      "Epoch 8008 - Train Loss: 0.137424, Train Acc: 0.762821 | Val Loss: 0.151697, Val Acc: 0.701031\n",
      "Epoch 8009 - Train Loss: 0.137413, Train Acc: 0.762821 | Val Loss: 0.151688, Val Acc: 0.701031\n",
      "Epoch 8010 - Train Loss: 0.137403, Train Acc: 0.762821 | Val Loss: 0.151679, Val Acc: 0.701031\n",
      "Epoch 8011 - Train Loss: 0.137393, Train Acc: 0.762821 | Val Loss: 0.151670, Val Acc: 0.701031\n",
      "Epoch 8012 - Train Loss: 0.137383, Train Acc: 0.762821 | Val Loss: 0.151661, Val Acc: 0.701031\n",
      "Epoch 8013 - Train Loss: 0.137373, Train Acc: 0.762821 | Val Loss: 0.151653, Val Acc: 0.701031\n",
      "Epoch 8014 - Train Loss: 0.137363, Train Acc: 0.762821 | Val Loss: 0.151644, Val Acc: 0.701031\n",
      "Epoch 8015 - Train Loss: 0.137353, Train Acc: 0.762821 | Val Loss: 0.151635, Val Acc: 0.701031\n",
      "Epoch 8016 - Train Loss: 0.137343, Train Acc: 0.762821 | Val Loss: 0.151626, Val Acc: 0.701031\n",
      "Epoch 8017 - Train Loss: 0.137333, Train Acc: 0.762821 | Val Loss: 0.151617, Val Acc: 0.701031\n",
      "Epoch 8018 - Train Loss: 0.137323, Train Acc: 0.762821 | Val Loss: 0.151608, Val Acc: 0.701031\n",
      "Epoch 8019 - Train Loss: 0.137312, Train Acc: 0.762821 | Val Loss: 0.151599, Val Acc: 0.701031\n",
      "Epoch 8020 - Train Loss: 0.137302, Train Acc: 0.762821 | Val Loss: 0.151590, Val Acc: 0.701031\n",
      "Epoch 8021 - Train Loss: 0.137292, Train Acc: 0.762821 | Val Loss: 0.151581, Val Acc: 0.701031\n",
      "Epoch 8022 - Train Loss: 0.137282, Train Acc: 0.762821 | Val Loss: 0.151572, Val Acc: 0.701031\n",
      "Epoch 8023 - Train Loss: 0.137272, Train Acc: 0.762821 | Val Loss: 0.151563, Val Acc: 0.701031\n",
      "Epoch 8024 - Train Loss: 0.137262, Train Acc: 0.764103 | Val Loss: 0.151554, Val Acc: 0.701031\n",
      "Epoch 8025 - Train Loss: 0.137252, Train Acc: 0.764103 | Val Loss: 0.151546, Val Acc: 0.701031\n",
      "Epoch 8026 - Train Loss: 0.137242, Train Acc: 0.764103 | Val Loss: 0.151537, Val Acc: 0.701031\n",
      "Epoch 8027 - Train Loss: 0.137232, Train Acc: 0.764103 | Val Loss: 0.151528, Val Acc: 0.701031\n",
      "Epoch 8028 - Train Loss: 0.137222, Train Acc: 0.764103 | Val Loss: 0.151519, Val Acc: 0.701031\n",
      "Epoch 8029 - Train Loss: 0.137212, Train Acc: 0.764103 | Val Loss: 0.151510, Val Acc: 0.701031\n",
      "Epoch 8030 - Train Loss: 0.137202, Train Acc: 0.764103 | Val Loss: 0.151501, Val Acc: 0.701031\n",
      "Epoch 8031 - Train Loss: 0.137191, Train Acc: 0.764103 | Val Loss: 0.151492, Val Acc: 0.701031\n",
      "Epoch 8032 - Train Loss: 0.137181, Train Acc: 0.764103 | Val Loss: 0.151483, Val Acc: 0.701031\n",
      "Epoch 8033 - Train Loss: 0.137171, Train Acc: 0.764103 | Val Loss: 0.151474, Val Acc: 0.701031\n",
      "Epoch 8034 - Train Loss: 0.137161, Train Acc: 0.764103 | Val Loss: 0.151465, Val Acc: 0.701031\n",
      "Epoch 8035 - Train Loss: 0.137151, Train Acc: 0.764103 | Val Loss: 0.151457, Val Acc: 0.701031\n",
      "Epoch 8036 - Train Loss: 0.137141, Train Acc: 0.764103 | Val Loss: 0.151448, Val Acc: 0.701031\n",
      "Epoch 8037 - Train Loss: 0.137131, Train Acc: 0.764103 | Val Loss: 0.151439, Val Acc: 0.701031\n",
      "Epoch 8038 - Train Loss: 0.137121, Train Acc: 0.764103 | Val Loss: 0.151430, Val Acc: 0.701031\n",
      "Epoch 8039 - Train Loss: 0.137111, Train Acc: 0.764103 | Val Loss: 0.151421, Val Acc: 0.701031\n",
      "Epoch 8040 - Train Loss: 0.137101, Train Acc: 0.764103 | Val Loss: 0.151412, Val Acc: 0.701031\n",
      "Epoch 8041 - Train Loss: 0.137091, Train Acc: 0.764103 | Val Loss: 0.151403, Val Acc: 0.701031\n",
      "Epoch 8042 - Train Loss: 0.137081, Train Acc: 0.764103 | Val Loss: 0.151394, Val Acc: 0.701031\n",
      "Epoch 8043 - Train Loss: 0.137071, Train Acc: 0.764103 | Val Loss: 0.151385, Val Acc: 0.701031\n",
      "Epoch 8044 - Train Loss: 0.137061, Train Acc: 0.764103 | Val Loss: 0.151376, Val Acc: 0.701031\n",
      "Epoch 8045 - Train Loss: 0.137051, Train Acc: 0.764103 | Val Loss: 0.151368, Val Acc: 0.701031\n",
      "Epoch 8046 - Train Loss: 0.137040, Train Acc: 0.764103 | Val Loss: 0.151359, Val Acc: 0.701031\n",
      "Epoch 8047 - Train Loss: 0.137030, Train Acc: 0.764103 | Val Loss: 0.151350, Val Acc: 0.701031\n",
      "Epoch 8048 - Train Loss: 0.137020, Train Acc: 0.764103 | Val Loss: 0.151341, Val Acc: 0.701031\n",
      "Epoch 8049 - Train Loss: 0.137010, Train Acc: 0.764103 | Val Loss: 0.151332, Val Acc: 0.701031\n",
      "Epoch 8050 - Train Loss: 0.137000, Train Acc: 0.764103 | Val Loss: 0.151323, Val Acc: 0.701031\n",
      "Epoch 8051 - Train Loss: 0.136990, Train Acc: 0.764103 | Val Loss: 0.151314, Val Acc: 0.701031\n",
      "Epoch 8052 - Train Loss: 0.136980, Train Acc: 0.764103 | Val Loss: 0.151305, Val Acc: 0.701031\n",
      "Epoch 8053 - Train Loss: 0.136970, Train Acc: 0.764103 | Val Loss: 0.151297, Val Acc: 0.701031\n",
      "Epoch 8054 - Train Loss: 0.136960, Train Acc: 0.764103 | Val Loss: 0.151288, Val Acc: 0.701031\n",
      "Epoch 8055 - Train Loss: 0.136950, Train Acc: 0.764103 | Val Loss: 0.151279, Val Acc: 0.701031\n",
      "Epoch 8056 - Train Loss: 0.136940, Train Acc: 0.764103 | Val Loss: 0.151270, Val Acc: 0.701031\n",
      "Epoch 8057 - Train Loss: 0.136930, Train Acc: 0.764103 | Val Loss: 0.151261, Val Acc: 0.701031\n",
      "Epoch 8058 - Train Loss: 0.136920, Train Acc: 0.764103 | Val Loss: 0.151252, Val Acc: 0.701031\n",
      "Epoch 8059 - Train Loss: 0.136910, Train Acc: 0.764103 | Val Loss: 0.151243, Val Acc: 0.701031\n",
      "Epoch 8060 - Train Loss: 0.136900, Train Acc: 0.764103 | Val Loss: 0.151234, Val Acc: 0.701031\n",
      "Epoch 8061 - Train Loss: 0.136890, Train Acc: 0.764103 | Val Loss: 0.151226, Val Acc: 0.701031\n",
      "Epoch 8062 - Train Loss: 0.136880, Train Acc: 0.764103 | Val Loss: 0.151217, Val Acc: 0.701031\n",
      "Epoch 8063 - Train Loss: 0.136870, Train Acc: 0.764103 | Val Loss: 0.151208, Val Acc: 0.701031\n",
      "Epoch 8064 - Train Loss: 0.136860, Train Acc: 0.764103 | Val Loss: 0.151199, Val Acc: 0.701031\n",
      "Epoch 8065 - Train Loss: 0.136850, Train Acc: 0.764103 | Val Loss: 0.151190, Val Acc: 0.701031\n",
      "Epoch 8066 - Train Loss: 0.136840, Train Acc: 0.764103 | Val Loss: 0.151181, Val Acc: 0.701031\n",
      "Epoch 8067 - Train Loss: 0.136830, Train Acc: 0.764103 | Val Loss: 0.151172, Val Acc: 0.701031\n",
      "Epoch 8068 - Train Loss: 0.136819, Train Acc: 0.764103 | Val Loss: 0.151163, Val Acc: 0.701031\n",
      "Epoch 8069 - Train Loss: 0.136809, Train Acc: 0.764103 | Val Loss: 0.151155, Val Acc: 0.701031\n",
      "Epoch 8070 - Train Loss: 0.136799, Train Acc: 0.764103 | Val Loss: 0.151146, Val Acc: 0.701031\n",
      "Epoch 8071 - Train Loss: 0.136789, Train Acc: 0.764103 | Val Loss: 0.151137, Val Acc: 0.701031\n",
      "Epoch 8072 - Train Loss: 0.136779, Train Acc: 0.764103 | Val Loss: 0.151128, Val Acc: 0.701031\n",
      "Epoch 8073 - Train Loss: 0.136769, Train Acc: 0.764103 | Val Loss: 0.151119, Val Acc: 0.701031\n",
      "Epoch 8074 - Train Loss: 0.136759, Train Acc: 0.764103 | Val Loss: 0.151110, Val Acc: 0.701031\n",
      "Epoch 8075 - Train Loss: 0.136749, Train Acc: 0.764103 | Val Loss: 0.151101, Val Acc: 0.701031\n",
      "Epoch 8076 - Train Loss: 0.136739, Train Acc: 0.764103 | Val Loss: 0.151092, Val Acc: 0.701031\n",
      "Epoch 8077 - Train Loss: 0.136729, Train Acc: 0.764103 | Val Loss: 0.151084, Val Acc: 0.701031\n",
      "Epoch 8078 - Train Loss: 0.136719, Train Acc: 0.764103 | Val Loss: 0.151075, Val Acc: 0.701031\n",
      "Epoch 8079 - Train Loss: 0.136709, Train Acc: 0.764103 | Val Loss: 0.151066, Val Acc: 0.701031\n",
      "Epoch 8080 - Train Loss: 0.136699, Train Acc: 0.764103 | Val Loss: 0.151057, Val Acc: 0.701031\n",
      "Epoch 8081 - Train Loss: 0.136689, Train Acc: 0.764103 | Val Loss: 0.151048, Val Acc: 0.701031\n",
      "Epoch 8082 - Train Loss: 0.136679, Train Acc: 0.764103 | Val Loss: 0.151039, Val Acc: 0.701031\n",
      "Epoch 8083 - Train Loss: 0.136669, Train Acc: 0.764103 | Val Loss: 0.151030, Val Acc: 0.701031\n",
      "Epoch 8084 - Train Loss: 0.136659, Train Acc: 0.764103 | Val Loss: 0.151022, Val Acc: 0.701031\n",
      "Epoch 8085 - Train Loss: 0.136649, Train Acc: 0.764103 | Val Loss: 0.151013, Val Acc: 0.701031\n",
      "Epoch 8086 - Train Loss: 0.136639, Train Acc: 0.764103 | Val Loss: 0.151004, Val Acc: 0.701031\n",
      "Epoch 8087 - Train Loss: 0.136629, Train Acc: 0.764103 | Val Loss: 0.150995, Val Acc: 0.701031\n",
      "Epoch 8088 - Train Loss: 0.136619, Train Acc: 0.764103 | Val Loss: 0.150986, Val Acc: 0.701031\n",
      "Epoch 8089 - Train Loss: 0.136609, Train Acc: 0.764103 | Val Loss: 0.150977, Val Acc: 0.701031\n",
      "Epoch 8090 - Train Loss: 0.136599, Train Acc: 0.764103 | Val Loss: 0.150968, Val Acc: 0.701031\n",
      "Epoch 8091 - Train Loss: 0.136589, Train Acc: 0.764103 | Val Loss: 0.150960, Val Acc: 0.701031\n",
      "Epoch 8092 - Train Loss: 0.136579, Train Acc: 0.764103 | Val Loss: 0.150951, Val Acc: 0.701031\n",
      "Epoch 8093 - Train Loss: 0.136569, Train Acc: 0.764103 | Val Loss: 0.150942, Val Acc: 0.701031\n",
      "Epoch 8094 - Train Loss: 0.136559, Train Acc: 0.764103 | Val Loss: 0.150933, Val Acc: 0.701031\n",
      "Epoch 8095 - Train Loss: 0.136549, Train Acc: 0.764103 | Val Loss: 0.150924, Val Acc: 0.701031\n",
      "Epoch 8096 - Train Loss: 0.136539, Train Acc: 0.764103 | Val Loss: 0.150915, Val Acc: 0.701031\n",
      "Epoch 8097 - Train Loss: 0.136529, Train Acc: 0.764103 | Val Loss: 0.150906, Val Acc: 0.701031\n",
      "Epoch 8098 - Train Loss: 0.136519, Train Acc: 0.764103 | Val Loss: 0.150898, Val Acc: 0.701031\n",
      "Epoch 8099 - Train Loss: 0.136509, Train Acc: 0.764103 | Val Loss: 0.150889, Val Acc: 0.701031\n",
      "Epoch 8100 - Train Loss: 0.136499, Train Acc: 0.765385 | Val Loss: 0.150880, Val Acc: 0.701031\n",
      "Epoch 8101 - Train Loss: 0.136489, Train Acc: 0.765385 | Val Loss: 0.150871, Val Acc: 0.701031\n",
      "Epoch 8102 - Train Loss: 0.136479, Train Acc: 0.765385 | Val Loss: 0.150862, Val Acc: 0.701031\n",
      "Epoch 8103 - Train Loss: 0.136469, Train Acc: 0.765385 | Val Loss: 0.150853, Val Acc: 0.701031\n",
      "Epoch 8104 - Train Loss: 0.136459, Train Acc: 0.765385 | Val Loss: 0.150845, Val Acc: 0.701031\n",
      "Epoch 8105 - Train Loss: 0.136449, Train Acc: 0.765385 | Val Loss: 0.150836, Val Acc: 0.701031\n",
      "Epoch 8106 - Train Loss: 0.136439, Train Acc: 0.765385 | Val Loss: 0.150827, Val Acc: 0.701031\n",
      "Epoch 8107 - Train Loss: 0.136429, Train Acc: 0.765385 | Val Loss: 0.150818, Val Acc: 0.701031\n",
      "Epoch 8108 - Train Loss: 0.136419, Train Acc: 0.765385 | Val Loss: 0.150809, Val Acc: 0.701031\n",
      "Epoch 8109 - Train Loss: 0.136409, Train Acc: 0.765385 | Val Loss: 0.150800, Val Acc: 0.701031\n",
      "Epoch 8110 - Train Loss: 0.136399, Train Acc: 0.765385 | Val Loss: 0.150792, Val Acc: 0.701031\n",
      "Epoch 8111 - Train Loss: 0.136390, Train Acc: 0.765385 | Val Loss: 0.150783, Val Acc: 0.701031\n",
      "Epoch 8112 - Train Loss: 0.136380, Train Acc: 0.765385 | Val Loss: 0.150774, Val Acc: 0.701031\n",
      "Epoch 8113 - Train Loss: 0.136370, Train Acc: 0.765385 | Val Loss: 0.150765, Val Acc: 0.701031\n",
      "Epoch 8114 - Train Loss: 0.136360, Train Acc: 0.765385 | Val Loss: 0.150756, Val Acc: 0.701031\n",
      "Epoch 8115 - Train Loss: 0.136350, Train Acc: 0.765385 | Val Loss: 0.150747, Val Acc: 0.701031\n",
      "Epoch 8116 - Train Loss: 0.136340, Train Acc: 0.765385 | Val Loss: 0.150739, Val Acc: 0.701031\n",
      "Epoch 8117 - Train Loss: 0.136330, Train Acc: 0.765385 | Val Loss: 0.150730, Val Acc: 0.701031\n",
      "Epoch 8118 - Train Loss: 0.136320, Train Acc: 0.765385 | Val Loss: 0.150721, Val Acc: 0.701031\n",
      "Epoch 8119 - Train Loss: 0.136310, Train Acc: 0.765385 | Val Loss: 0.150712, Val Acc: 0.701031\n",
      "Epoch 8120 - Train Loss: 0.136300, Train Acc: 0.765385 | Val Loss: 0.150703, Val Acc: 0.701031\n",
      "Epoch 8121 - Train Loss: 0.136290, Train Acc: 0.765385 | Val Loss: 0.150695, Val Acc: 0.701031\n",
      "Epoch 8122 - Train Loss: 0.136280, Train Acc: 0.765385 | Val Loss: 0.150686, Val Acc: 0.701031\n",
      "Epoch 8123 - Train Loss: 0.136270, Train Acc: 0.765385 | Val Loss: 0.150677, Val Acc: 0.701031\n",
      "Epoch 8124 - Train Loss: 0.136260, Train Acc: 0.765385 | Val Loss: 0.150668, Val Acc: 0.701031\n",
      "Epoch 8125 - Train Loss: 0.136250, Train Acc: 0.765385 | Val Loss: 0.150659, Val Acc: 0.701031\n",
      "Epoch 8126 - Train Loss: 0.136240, Train Acc: 0.765385 | Val Loss: 0.150651, Val Acc: 0.701031\n",
      "Epoch 8127 - Train Loss: 0.136230, Train Acc: 0.765385 | Val Loss: 0.150642, Val Acc: 0.701031\n",
      "Epoch 8128 - Train Loss: 0.136220, Train Acc: 0.765385 | Val Loss: 0.150633, Val Acc: 0.701031\n",
      "Epoch 8129 - Train Loss: 0.136210, Train Acc: 0.765385 | Val Loss: 0.150624, Val Acc: 0.701031\n",
      "Epoch 8130 - Train Loss: 0.136200, Train Acc: 0.765385 | Val Loss: 0.150615, Val Acc: 0.701031\n",
      "Epoch 8131 - Train Loss: 0.136190, Train Acc: 0.765385 | Val Loss: 0.150607, Val Acc: 0.701031\n",
      "Epoch 8132 - Train Loss: 0.136180, Train Acc: 0.765385 | Val Loss: 0.150598, Val Acc: 0.701031\n",
      "Epoch 8133 - Train Loss: 0.136171, Train Acc: 0.765385 | Val Loss: 0.150589, Val Acc: 0.701031\n",
      "Epoch 8134 - Train Loss: 0.136161, Train Acc: 0.765385 | Val Loss: 0.150580, Val Acc: 0.701031\n",
      "Epoch 8135 - Train Loss: 0.136151, Train Acc: 0.765385 | Val Loss: 0.150572, Val Acc: 0.701031\n",
      "Epoch 8136 - Train Loss: 0.136141, Train Acc: 0.765385 | Val Loss: 0.150563, Val Acc: 0.701031\n",
      "Epoch 8137 - Train Loss: 0.136131, Train Acc: 0.765385 | Val Loss: 0.150554, Val Acc: 0.701031\n",
      "Epoch 8138 - Train Loss: 0.136121, Train Acc: 0.765385 | Val Loss: 0.150545, Val Acc: 0.701031\n",
      "Epoch 8139 - Train Loss: 0.136111, Train Acc: 0.765385 | Val Loss: 0.150537, Val Acc: 0.701031\n",
      "Epoch 8140 - Train Loss: 0.136101, Train Acc: 0.765385 | Val Loss: 0.150528, Val Acc: 0.701031\n",
      "Epoch 8141 - Train Loss: 0.136091, Train Acc: 0.765385 | Val Loss: 0.150519, Val Acc: 0.701031\n",
      "Epoch 8142 - Train Loss: 0.136081, Train Acc: 0.765385 | Val Loss: 0.150510, Val Acc: 0.701031\n",
      "Epoch 8143 - Train Loss: 0.136071, Train Acc: 0.765385 | Val Loss: 0.150501, Val Acc: 0.701031\n",
      "Epoch 8144 - Train Loss: 0.136061, Train Acc: 0.765385 | Val Loss: 0.150493, Val Acc: 0.701031\n",
      "Epoch 8145 - Train Loss: 0.136051, Train Acc: 0.765385 | Val Loss: 0.150484, Val Acc: 0.701031\n",
      "Epoch 8146 - Train Loss: 0.136041, Train Acc: 0.765385 | Val Loss: 0.150475, Val Acc: 0.701031\n",
      "Epoch 8147 - Train Loss: 0.136032, Train Acc: 0.765385 | Val Loss: 0.150466, Val Acc: 0.701031\n",
      "Epoch 8148 - Train Loss: 0.136022, Train Acc: 0.765385 | Val Loss: 0.150458, Val Acc: 0.701031\n",
      "Epoch 8149 - Train Loss: 0.136012, Train Acc: 0.765385 | Val Loss: 0.150449, Val Acc: 0.701031\n",
      "Epoch 8150 - Train Loss: 0.136002, Train Acc: 0.765385 | Val Loss: 0.150440, Val Acc: 0.701031\n",
      "Epoch 8151 - Train Loss: 0.135992, Train Acc: 0.765385 | Val Loss: 0.150431, Val Acc: 0.701031\n",
      "Epoch 8152 - Train Loss: 0.135982, Train Acc: 0.765385 | Val Loss: 0.150423, Val Acc: 0.701031\n",
      "Epoch 8153 - Train Loss: 0.135972, Train Acc: 0.765385 | Val Loss: 0.150414, Val Acc: 0.701031\n",
      "Epoch 8154 - Train Loss: 0.135962, Train Acc: 0.765385 | Val Loss: 0.150405, Val Acc: 0.701031\n",
      "Epoch 8155 - Train Loss: 0.135952, Train Acc: 0.765385 | Val Loss: 0.150396, Val Acc: 0.701031\n",
      "Epoch 8156 - Train Loss: 0.135942, Train Acc: 0.765385 | Val Loss: 0.150388, Val Acc: 0.701031\n",
      "Epoch 8157 - Train Loss: 0.135932, Train Acc: 0.765385 | Val Loss: 0.150379, Val Acc: 0.701031\n",
      "Epoch 8158 - Train Loss: 0.135923, Train Acc: 0.765385 | Val Loss: 0.150370, Val Acc: 0.701031\n",
      "Epoch 8159 - Train Loss: 0.135913, Train Acc: 0.765385 | Val Loss: 0.150361, Val Acc: 0.701031\n",
      "Epoch 8160 - Train Loss: 0.135903, Train Acc: 0.765385 | Val Loss: 0.150353, Val Acc: 0.701031\n",
      "Epoch 8161 - Train Loss: 0.135893, Train Acc: 0.765385 | Val Loss: 0.150344, Val Acc: 0.701031\n",
      "Epoch 8162 - Train Loss: 0.135883, Train Acc: 0.765385 | Val Loss: 0.150335, Val Acc: 0.701031\n",
      "Epoch 8163 - Train Loss: 0.135873, Train Acc: 0.765385 | Val Loss: 0.150326, Val Acc: 0.701031\n",
      "Epoch 8164 - Train Loss: 0.135863, Train Acc: 0.765385 | Val Loss: 0.150318, Val Acc: 0.701031\n",
      "Epoch 8165 - Train Loss: 0.135853, Train Acc: 0.765385 | Val Loss: 0.150309, Val Acc: 0.701031\n",
      "Epoch 8166 - Train Loss: 0.135843, Train Acc: 0.765385 | Val Loss: 0.150300, Val Acc: 0.701031\n",
      "Epoch 8167 - Train Loss: 0.135833, Train Acc: 0.765385 | Val Loss: 0.150291, Val Acc: 0.701031\n",
      "Epoch 8168 - Train Loss: 0.135824, Train Acc: 0.765385 | Val Loss: 0.150283, Val Acc: 0.701031\n",
      "Epoch 8169 - Train Loss: 0.135814, Train Acc: 0.765385 | Val Loss: 0.150274, Val Acc: 0.701031\n",
      "Epoch 8170 - Train Loss: 0.135804, Train Acc: 0.765385 | Val Loss: 0.150265, Val Acc: 0.701031\n",
      "Epoch 8171 - Train Loss: 0.135794, Train Acc: 0.765385 | Val Loss: 0.150256, Val Acc: 0.701031\n",
      "Epoch 8172 - Train Loss: 0.135784, Train Acc: 0.766667 | Val Loss: 0.150248, Val Acc: 0.701031\n",
      "Epoch 8173 - Train Loss: 0.135774, Train Acc: 0.767949 | Val Loss: 0.150239, Val Acc: 0.701031\n",
      "Epoch 8174 - Train Loss: 0.135764, Train Acc: 0.767949 | Val Loss: 0.150230, Val Acc: 0.701031\n",
      "Epoch 8175 - Train Loss: 0.135754, Train Acc: 0.767949 | Val Loss: 0.150222, Val Acc: 0.701031\n",
      "Epoch 8176 - Train Loss: 0.135744, Train Acc: 0.767949 | Val Loss: 0.150213, Val Acc: 0.701031\n",
      "Epoch 8177 - Train Loss: 0.135735, Train Acc: 0.767949 | Val Loss: 0.150204, Val Acc: 0.701031\n",
      "Epoch 8178 - Train Loss: 0.135725, Train Acc: 0.767949 | Val Loss: 0.150195, Val Acc: 0.701031\n",
      "Epoch 8179 - Train Loss: 0.135715, Train Acc: 0.767949 | Val Loss: 0.150187, Val Acc: 0.701031\n",
      "Epoch 8180 - Train Loss: 0.135705, Train Acc: 0.767949 | Val Loss: 0.150178, Val Acc: 0.701031\n",
      "Epoch 8181 - Train Loss: 0.135695, Train Acc: 0.767949 | Val Loss: 0.150169, Val Acc: 0.701031\n",
      "Epoch 8182 - Train Loss: 0.135685, Train Acc: 0.767949 | Val Loss: 0.150160, Val Acc: 0.701031\n",
      "Epoch 8183 - Train Loss: 0.135675, Train Acc: 0.767949 | Val Loss: 0.150152, Val Acc: 0.701031\n",
      "Epoch 8184 - Train Loss: 0.135665, Train Acc: 0.767949 | Val Loss: 0.150143, Val Acc: 0.701031\n",
      "Epoch 8185 - Train Loss: 0.135656, Train Acc: 0.767949 | Val Loss: 0.150134, Val Acc: 0.701031\n",
      "Epoch 8186 - Train Loss: 0.135646, Train Acc: 0.767949 | Val Loss: 0.150125, Val Acc: 0.701031\n",
      "Epoch 8187 - Train Loss: 0.135636, Train Acc: 0.767949 | Val Loss: 0.150117, Val Acc: 0.701031\n",
      "Epoch 8188 - Train Loss: 0.135626, Train Acc: 0.767949 | Val Loss: 0.150108, Val Acc: 0.701031\n",
      "Epoch 8189 - Train Loss: 0.135616, Train Acc: 0.767949 | Val Loss: 0.150099, Val Acc: 0.701031\n",
      "Epoch 8190 - Train Loss: 0.135606, Train Acc: 0.767949 | Val Loss: 0.150091, Val Acc: 0.701031\n",
      "Epoch 8191 - Train Loss: 0.135596, Train Acc: 0.767949 | Val Loss: 0.150082, Val Acc: 0.701031\n",
      "Epoch 8192 - Train Loss: 0.135586, Train Acc: 0.767949 | Val Loss: 0.150073, Val Acc: 0.701031\n",
      "Epoch 8193 - Train Loss: 0.135577, Train Acc: 0.767949 | Val Loss: 0.150064, Val Acc: 0.701031\n",
      "Epoch 8194 - Train Loss: 0.135567, Train Acc: 0.767949 | Val Loss: 0.150056, Val Acc: 0.701031\n",
      "Epoch 8195 - Train Loss: 0.135557, Train Acc: 0.767949 | Val Loss: 0.150047, Val Acc: 0.701031\n",
      "Epoch 8196 - Train Loss: 0.135547, Train Acc: 0.767949 | Val Loss: 0.150038, Val Acc: 0.701031\n",
      "Epoch 8197 - Train Loss: 0.135537, Train Acc: 0.767949 | Val Loss: 0.150030, Val Acc: 0.701031\n",
      "Epoch 8198 - Train Loss: 0.135527, Train Acc: 0.767949 | Val Loss: 0.150021, Val Acc: 0.701031\n",
      "Epoch 8199 - Train Loss: 0.135517, Train Acc: 0.767949 | Val Loss: 0.150012, Val Acc: 0.701031\n",
      "Epoch 8200 - Train Loss: 0.135508, Train Acc: 0.767949 | Val Loss: 0.150004, Val Acc: 0.701031\n",
      "Epoch 8201 - Train Loss: 0.135498, Train Acc: 0.766667 | Val Loss: 0.149995, Val Acc: 0.701031\n",
      "Epoch 8202 - Train Loss: 0.135488, Train Acc: 0.766667 | Val Loss: 0.149986, Val Acc: 0.701031\n",
      "Epoch 8203 - Train Loss: 0.135478, Train Acc: 0.766667 | Val Loss: 0.149977, Val Acc: 0.701031\n",
      "Epoch 8204 - Train Loss: 0.135468, Train Acc: 0.766667 | Val Loss: 0.149969, Val Acc: 0.701031\n",
      "Epoch 8205 - Train Loss: 0.135458, Train Acc: 0.766667 | Val Loss: 0.149960, Val Acc: 0.701031\n",
      "Epoch 8206 - Train Loss: 0.135448, Train Acc: 0.766667 | Val Loss: 0.149951, Val Acc: 0.701031\n",
      "Epoch 8207 - Train Loss: 0.135439, Train Acc: 0.766667 | Val Loss: 0.149943, Val Acc: 0.701031\n",
      "Epoch 8208 - Train Loss: 0.135429, Train Acc: 0.766667 | Val Loss: 0.149934, Val Acc: 0.701031\n",
      "Epoch 8209 - Train Loss: 0.135419, Train Acc: 0.766667 | Val Loss: 0.149925, Val Acc: 0.701031\n",
      "Epoch 8210 - Train Loss: 0.135409, Train Acc: 0.766667 | Val Loss: 0.149917, Val Acc: 0.701031\n",
      "Epoch 8211 - Train Loss: 0.135399, Train Acc: 0.766667 | Val Loss: 0.149908, Val Acc: 0.701031\n",
      "Epoch 8212 - Train Loss: 0.135389, Train Acc: 0.766667 | Val Loss: 0.149899, Val Acc: 0.701031\n",
      "Epoch 8213 - Train Loss: 0.135379, Train Acc: 0.766667 | Val Loss: 0.149890, Val Acc: 0.701031\n",
      "Epoch 8214 - Train Loss: 0.135370, Train Acc: 0.766667 | Val Loss: 0.149882, Val Acc: 0.701031\n",
      "Epoch 8215 - Train Loss: 0.135360, Train Acc: 0.766667 | Val Loss: 0.149873, Val Acc: 0.701031\n",
      "Epoch 8216 - Train Loss: 0.135350, Train Acc: 0.766667 | Val Loss: 0.149864, Val Acc: 0.701031\n",
      "Epoch 8217 - Train Loss: 0.135340, Train Acc: 0.766667 | Val Loss: 0.149856, Val Acc: 0.701031\n",
      "Epoch 8218 - Train Loss: 0.135330, Train Acc: 0.766667 | Val Loss: 0.149847, Val Acc: 0.701031\n",
      "Epoch 8219 - Train Loss: 0.135320, Train Acc: 0.766667 | Val Loss: 0.149838, Val Acc: 0.701031\n",
      "Epoch 8220 - Train Loss: 0.135311, Train Acc: 0.766667 | Val Loss: 0.149830, Val Acc: 0.701031\n",
      "Epoch 8221 - Train Loss: 0.135301, Train Acc: 0.766667 | Val Loss: 0.149821, Val Acc: 0.701031\n",
      "Epoch 8222 - Train Loss: 0.135291, Train Acc: 0.766667 | Val Loss: 0.149812, Val Acc: 0.701031\n",
      "Epoch 8223 - Train Loss: 0.135281, Train Acc: 0.766667 | Val Loss: 0.149804, Val Acc: 0.701031\n",
      "Epoch 8224 - Train Loss: 0.135271, Train Acc: 0.766667 | Val Loss: 0.149795, Val Acc: 0.701031\n",
      "Epoch 8225 - Train Loss: 0.135261, Train Acc: 0.766667 | Val Loss: 0.149786, Val Acc: 0.701031\n",
      "Epoch 8226 - Train Loss: 0.135252, Train Acc: 0.766667 | Val Loss: 0.149777, Val Acc: 0.701031\n",
      "Epoch 8227 - Train Loss: 0.135242, Train Acc: 0.766667 | Val Loss: 0.149769, Val Acc: 0.701031\n",
      "Epoch 8228 - Train Loss: 0.135232, Train Acc: 0.766667 | Val Loss: 0.149760, Val Acc: 0.701031\n",
      "Epoch 8229 - Train Loss: 0.135222, Train Acc: 0.766667 | Val Loss: 0.149751, Val Acc: 0.701031\n",
      "Epoch 8230 - Train Loss: 0.135212, Train Acc: 0.766667 | Val Loss: 0.149743, Val Acc: 0.701031\n",
      "Epoch 8231 - Train Loss: 0.135202, Train Acc: 0.766667 | Val Loss: 0.149734, Val Acc: 0.701031\n",
      "Epoch 8232 - Train Loss: 0.135193, Train Acc: 0.766667 | Val Loss: 0.149725, Val Acc: 0.701031\n",
      "Epoch 8233 - Train Loss: 0.135183, Train Acc: 0.766667 | Val Loss: 0.149717, Val Acc: 0.701031\n",
      "Epoch 8234 - Train Loss: 0.135173, Train Acc: 0.766667 | Val Loss: 0.149708, Val Acc: 0.701031\n",
      "Epoch 8235 - Train Loss: 0.135163, Train Acc: 0.766667 | Val Loss: 0.149699, Val Acc: 0.701031\n",
      "Epoch 8236 - Train Loss: 0.135153, Train Acc: 0.766667 | Val Loss: 0.149691, Val Acc: 0.701031\n",
      "Epoch 8237 - Train Loss: 0.135144, Train Acc: 0.766667 | Val Loss: 0.149682, Val Acc: 0.701031\n",
      "Epoch 8238 - Train Loss: 0.135134, Train Acc: 0.766667 | Val Loss: 0.149673, Val Acc: 0.701031\n",
      "Epoch 8239 - Train Loss: 0.135124, Train Acc: 0.766667 | Val Loss: 0.149665, Val Acc: 0.701031\n",
      "Epoch 8240 - Train Loss: 0.135114, Train Acc: 0.766667 | Val Loss: 0.149656, Val Acc: 0.701031\n",
      "Epoch 8241 - Train Loss: 0.135104, Train Acc: 0.766667 | Val Loss: 0.149648, Val Acc: 0.701031\n",
      "Epoch 8242 - Train Loss: 0.135094, Train Acc: 0.766667 | Val Loss: 0.149639, Val Acc: 0.701031\n",
      "Epoch 8243 - Train Loss: 0.135085, Train Acc: 0.766667 | Val Loss: 0.149630, Val Acc: 0.701031\n",
      "Epoch 8244 - Train Loss: 0.135075, Train Acc: 0.766667 | Val Loss: 0.149622, Val Acc: 0.701031\n",
      "Epoch 8245 - Train Loss: 0.135065, Train Acc: 0.766667 | Val Loss: 0.149613, Val Acc: 0.701031\n",
      "Epoch 8246 - Train Loss: 0.135055, Train Acc: 0.766667 | Val Loss: 0.149604, Val Acc: 0.701031\n",
      "Epoch 8247 - Train Loss: 0.135045, Train Acc: 0.766667 | Val Loss: 0.149596, Val Acc: 0.701031\n",
      "Epoch 8248 - Train Loss: 0.135036, Train Acc: 0.766667 | Val Loss: 0.149587, Val Acc: 0.701031\n",
      "Epoch 8249 - Train Loss: 0.135026, Train Acc: 0.766667 | Val Loss: 0.149578, Val Acc: 0.701031\n",
      "Epoch 8250 - Train Loss: 0.135016, Train Acc: 0.766667 | Val Loss: 0.149570, Val Acc: 0.701031\n",
      "Epoch 8251 - Train Loss: 0.135006, Train Acc: 0.766667 | Val Loss: 0.149561, Val Acc: 0.701031\n",
      "Epoch 8252 - Train Loss: 0.134996, Train Acc: 0.766667 | Val Loss: 0.149552, Val Acc: 0.701031\n",
      "Epoch 8253 - Train Loss: 0.134987, Train Acc: 0.766667 | Val Loss: 0.149544, Val Acc: 0.701031\n",
      "Epoch 8254 - Train Loss: 0.134977, Train Acc: 0.766667 | Val Loss: 0.149535, Val Acc: 0.701031\n",
      "Epoch 8255 - Train Loss: 0.134967, Train Acc: 0.766667 | Val Loss: 0.149526, Val Acc: 0.701031\n",
      "Epoch 8256 - Train Loss: 0.134957, Train Acc: 0.766667 | Val Loss: 0.149518, Val Acc: 0.701031\n",
      "Epoch 8257 - Train Loss: 0.134948, Train Acc: 0.766667 | Val Loss: 0.149509, Val Acc: 0.701031\n",
      "Epoch 8258 - Train Loss: 0.134938, Train Acc: 0.766667 | Val Loss: 0.149501, Val Acc: 0.701031\n",
      "Epoch 8259 - Train Loss: 0.134928, Train Acc: 0.766667 | Val Loss: 0.149492, Val Acc: 0.701031\n",
      "Epoch 8260 - Train Loss: 0.134918, Train Acc: 0.766667 | Val Loss: 0.149483, Val Acc: 0.701031\n",
      "Epoch 8261 - Train Loss: 0.134908, Train Acc: 0.766667 | Val Loss: 0.149475, Val Acc: 0.701031\n",
      "Epoch 8262 - Train Loss: 0.134899, Train Acc: 0.766667 | Val Loss: 0.149466, Val Acc: 0.701031\n",
      "Epoch 8263 - Train Loss: 0.134889, Train Acc: 0.766667 | Val Loss: 0.149457, Val Acc: 0.701031\n",
      "Epoch 8264 - Train Loss: 0.134879, Train Acc: 0.766667 | Val Loss: 0.149449, Val Acc: 0.701031\n",
      "Epoch 8265 - Train Loss: 0.134869, Train Acc: 0.766667 | Val Loss: 0.149440, Val Acc: 0.701031\n",
      "Epoch 8266 - Train Loss: 0.134859, Train Acc: 0.766667 | Val Loss: 0.149432, Val Acc: 0.701031\n",
      "Epoch 8267 - Train Loss: 0.134850, Train Acc: 0.766667 | Val Loss: 0.149423, Val Acc: 0.701031\n",
      "Epoch 8268 - Train Loss: 0.134840, Train Acc: 0.766667 | Val Loss: 0.149414, Val Acc: 0.701031\n",
      "Epoch 8269 - Train Loss: 0.134830, Train Acc: 0.766667 | Val Loss: 0.149406, Val Acc: 0.701031\n",
      "Epoch 8270 - Train Loss: 0.134820, Train Acc: 0.766667 | Val Loss: 0.149397, Val Acc: 0.701031\n",
      "Epoch 8271 - Train Loss: 0.134811, Train Acc: 0.766667 | Val Loss: 0.149388, Val Acc: 0.701031\n",
      "Epoch 8272 - Train Loss: 0.134801, Train Acc: 0.766667 | Val Loss: 0.149380, Val Acc: 0.701031\n",
      "Epoch 8273 - Train Loss: 0.134791, Train Acc: 0.766667 | Val Loss: 0.149371, Val Acc: 0.701031\n",
      "Epoch 8274 - Train Loss: 0.134781, Train Acc: 0.766667 | Val Loss: 0.149363, Val Acc: 0.701031\n",
      "Epoch 8275 - Train Loss: 0.134772, Train Acc: 0.766667 | Val Loss: 0.149354, Val Acc: 0.701031\n",
      "Epoch 8276 - Train Loss: 0.134762, Train Acc: 0.766667 | Val Loss: 0.149345, Val Acc: 0.701031\n",
      "Epoch 8277 - Train Loss: 0.134752, Train Acc: 0.766667 | Val Loss: 0.149337, Val Acc: 0.701031\n",
      "Epoch 8278 - Train Loss: 0.134742, Train Acc: 0.766667 | Val Loss: 0.149328, Val Acc: 0.701031\n",
      "Epoch 8279 - Train Loss: 0.134733, Train Acc: 0.766667 | Val Loss: 0.149320, Val Acc: 0.701031\n",
      "Epoch 8280 - Train Loss: 0.134723, Train Acc: 0.766667 | Val Loss: 0.149311, Val Acc: 0.701031\n",
      "Epoch 8281 - Train Loss: 0.134713, Train Acc: 0.766667 | Val Loss: 0.149302, Val Acc: 0.701031\n",
      "Epoch 8282 - Train Loss: 0.134703, Train Acc: 0.766667 | Val Loss: 0.149294, Val Acc: 0.701031\n",
      "Epoch 8283 - Train Loss: 0.134694, Train Acc: 0.766667 | Val Loss: 0.149285, Val Acc: 0.701031\n",
      "Epoch 8284 - Train Loss: 0.134684, Train Acc: 0.766667 | Val Loss: 0.149277, Val Acc: 0.701031\n",
      "Epoch 8285 - Train Loss: 0.134674, Train Acc: 0.766667 | Val Loss: 0.149268, Val Acc: 0.701031\n",
      "Epoch 8286 - Train Loss: 0.134664, Train Acc: 0.766667 | Val Loss: 0.149259, Val Acc: 0.701031\n",
      "Epoch 8287 - Train Loss: 0.134655, Train Acc: 0.766667 | Val Loss: 0.149251, Val Acc: 0.701031\n",
      "Epoch 8288 - Train Loss: 0.134645, Train Acc: 0.766667 | Val Loss: 0.149242, Val Acc: 0.701031\n",
      "Epoch 8289 - Train Loss: 0.134635, Train Acc: 0.766667 | Val Loss: 0.149234, Val Acc: 0.701031\n",
      "Epoch 8290 - Train Loss: 0.134625, Train Acc: 0.766667 | Val Loss: 0.149225, Val Acc: 0.701031\n",
      "Epoch 8291 - Train Loss: 0.134616, Train Acc: 0.766667 | Val Loss: 0.149217, Val Acc: 0.701031\n",
      "Epoch 8292 - Train Loss: 0.134606, Train Acc: 0.766667 | Val Loss: 0.149208, Val Acc: 0.701031\n",
      "Epoch 8293 - Train Loss: 0.134596, Train Acc: 0.766667 | Val Loss: 0.149199, Val Acc: 0.701031\n",
      "Epoch 8294 - Train Loss: 0.134586, Train Acc: 0.766667 | Val Loss: 0.149191, Val Acc: 0.701031\n",
      "Epoch 8295 - Train Loss: 0.134577, Train Acc: 0.766667 | Val Loss: 0.149182, Val Acc: 0.701031\n",
      "Epoch 8296 - Train Loss: 0.134567, Train Acc: 0.766667 | Val Loss: 0.149174, Val Acc: 0.701031\n",
      "Epoch 8297 - Train Loss: 0.134557, Train Acc: 0.766667 | Val Loss: 0.149165, Val Acc: 0.701031\n",
      "Epoch 8298 - Train Loss: 0.134547, Train Acc: 0.766667 | Val Loss: 0.149156, Val Acc: 0.701031\n",
      "Epoch 8299 - Train Loss: 0.134538, Train Acc: 0.766667 | Val Loss: 0.149148, Val Acc: 0.701031\n",
      "Epoch 8300 - Train Loss: 0.134528, Train Acc: 0.766667 | Val Loss: 0.149139, Val Acc: 0.701031\n",
      "Epoch 8301 - Train Loss: 0.134518, Train Acc: 0.766667 | Val Loss: 0.149131, Val Acc: 0.701031\n",
      "Epoch 8302 - Train Loss: 0.134508, Train Acc: 0.766667 | Val Loss: 0.149122, Val Acc: 0.701031\n",
      "Epoch 8303 - Train Loss: 0.134499, Train Acc: 0.766667 | Val Loss: 0.149114, Val Acc: 0.701031\n",
      "Epoch 8304 - Train Loss: 0.134489, Train Acc: 0.766667 | Val Loss: 0.149105, Val Acc: 0.701031\n",
      "Epoch 8305 - Train Loss: 0.134479, Train Acc: 0.766667 | Val Loss: 0.149096, Val Acc: 0.701031\n",
      "Epoch 8306 - Train Loss: 0.134469, Train Acc: 0.766667 | Val Loss: 0.149088, Val Acc: 0.701031\n",
      "Epoch 8307 - Train Loss: 0.134460, Train Acc: 0.766667 | Val Loss: 0.149079, Val Acc: 0.701031\n",
      "Epoch 8308 - Train Loss: 0.134450, Train Acc: 0.766667 | Val Loss: 0.149071, Val Acc: 0.701031\n",
      "Epoch 8309 - Train Loss: 0.134440, Train Acc: 0.766667 | Val Loss: 0.149062, Val Acc: 0.701031\n",
      "Epoch 8310 - Train Loss: 0.134431, Train Acc: 0.766667 | Val Loss: 0.149054, Val Acc: 0.701031\n",
      "Epoch 8311 - Train Loss: 0.134421, Train Acc: 0.766667 | Val Loss: 0.149045, Val Acc: 0.701031\n",
      "Epoch 8312 - Train Loss: 0.134411, Train Acc: 0.766667 | Val Loss: 0.149036, Val Acc: 0.701031\n",
      "Epoch 8313 - Train Loss: 0.134401, Train Acc: 0.766667 | Val Loss: 0.149028, Val Acc: 0.701031\n",
      "Epoch 8314 - Train Loss: 0.134392, Train Acc: 0.766667 | Val Loss: 0.149019, Val Acc: 0.701031\n",
      "Epoch 8315 - Train Loss: 0.134382, Train Acc: 0.766667 | Val Loss: 0.149011, Val Acc: 0.701031\n",
      "Epoch 8316 - Train Loss: 0.134372, Train Acc: 0.766667 | Val Loss: 0.149002, Val Acc: 0.701031\n",
      "Epoch 8317 - Train Loss: 0.134362, Train Acc: 0.766667 | Val Loss: 0.148994, Val Acc: 0.701031\n",
      "Epoch 8318 - Train Loss: 0.134353, Train Acc: 0.766667 | Val Loss: 0.148985, Val Acc: 0.701031\n",
      "Epoch 8319 - Train Loss: 0.134343, Train Acc: 0.766667 | Val Loss: 0.148977, Val Acc: 0.701031\n",
      "Epoch 8320 - Train Loss: 0.134333, Train Acc: 0.766667 | Val Loss: 0.148968, Val Acc: 0.701031\n",
      "Epoch 8321 - Train Loss: 0.134324, Train Acc: 0.766667 | Val Loss: 0.148959, Val Acc: 0.701031\n",
      "Epoch 8322 - Train Loss: 0.134314, Train Acc: 0.766667 | Val Loss: 0.148951, Val Acc: 0.701031\n",
      "Epoch 8323 - Train Loss: 0.134304, Train Acc: 0.766667 | Val Loss: 0.148942, Val Acc: 0.701031\n",
      "Epoch 8324 - Train Loss: 0.134294, Train Acc: 0.766667 | Val Loss: 0.148934, Val Acc: 0.701031\n",
      "Epoch 8325 - Train Loss: 0.134285, Train Acc: 0.766667 | Val Loss: 0.148925, Val Acc: 0.701031\n",
      "Epoch 8326 - Train Loss: 0.134275, Train Acc: 0.766667 | Val Loss: 0.148917, Val Acc: 0.701031\n",
      "Epoch 8327 - Train Loss: 0.134265, Train Acc: 0.766667 | Val Loss: 0.148908, Val Acc: 0.701031\n",
      "Epoch 8328 - Train Loss: 0.134255, Train Acc: 0.766667 | Val Loss: 0.148900, Val Acc: 0.701031\n",
      "Epoch 8329 - Train Loss: 0.134246, Train Acc: 0.766667 | Val Loss: 0.148891, Val Acc: 0.701031\n",
      "Epoch 8330 - Train Loss: 0.134236, Train Acc: 0.766667 | Val Loss: 0.148882, Val Acc: 0.701031\n",
      "Epoch 8331 - Train Loss: 0.134226, Train Acc: 0.766667 | Val Loss: 0.148874, Val Acc: 0.701031\n",
      "Epoch 8332 - Train Loss: 0.134217, Train Acc: 0.766667 | Val Loss: 0.148865, Val Acc: 0.701031\n",
      "Epoch 8333 - Train Loss: 0.134207, Train Acc: 0.766667 | Val Loss: 0.148857, Val Acc: 0.701031\n",
      "Epoch 8334 - Train Loss: 0.134197, Train Acc: 0.766667 | Val Loss: 0.148848, Val Acc: 0.701031\n",
      "Epoch 8335 - Train Loss: 0.134187, Train Acc: 0.766667 | Val Loss: 0.148840, Val Acc: 0.701031\n",
      "Epoch 8336 - Train Loss: 0.134178, Train Acc: 0.766667 | Val Loss: 0.148831, Val Acc: 0.701031\n",
      "Epoch 8337 - Train Loss: 0.134168, Train Acc: 0.766667 | Val Loss: 0.148823, Val Acc: 0.701031\n",
      "Epoch 8338 - Train Loss: 0.134158, Train Acc: 0.766667 | Val Loss: 0.148814, Val Acc: 0.701031\n",
      "Epoch 8339 - Train Loss: 0.134149, Train Acc: 0.766667 | Val Loss: 0.148806, Val Acc: 0.701031\n",
      "Epoch 8340 - Train Loss: 0.134139, Train Acc: 0.766667 | Val Loss: 0.148797, Val Acc: 0.701031\n",
      "Epoch 8341 - Train Loss: 0.134129, Train Acc: 0.766667 | Val Loss: 0.148789, Val Acc: 0.701031\n",
      "Epoch 8342 - Train Loss: 0.134119, Train Acc: 0.766667 | Val Loss: 0.148780, Val Acc: 0.701031\n",
      "Epoch 8343 - Train Loss: 0.134110, Train Acc: 0.766667 | Val Loss: 0.148771, Val Acc: 0.701031\n",
      "Epoch 8344 - Train Loss: 0.134100, Train Acc: 0.767949 | Val Loss: 0.148763, Val Acc: 0.701031\n",
      "Epoch 8345 - Train Loss: 0.134090, Train Acc: 0.767949 | Val Loss: 0.148754, Val Acc: 0.701031\n",
      "Epoch 8346 - Train Loss: 0.134081, Train Acc: 0.767949 | Val Loss: 0.148746, Val Acc: 0.701031\n",
      "Epoch 8347 - Train Loss: 0.134071, Train Acc: 0.767949 | Val Loss: 0.148737, Val Acc: 0.701031\n",
      "Epoch 8348 - Train Loss: 0.134061, Train Acc: 0.767949 | Val Loss: 0.148729, Val Acc: 0.701031\n",
      "Epoch 8349 - Train Loss: 0.134051, Train Acc: 0.767949 | Val Loss: 0.148720, Val Acc: 0.701031\n",
      "Epoch 8350 - Train Loss: 0.134042, Train Acc: 0.767949 | Val Loss: 0.148712, Val Acc: 0.701031\n",
      "Epoch 8351 - Train Loss: 0.134032, Train Acc: 0.767949 | Val Loss: 0.148703, Val Acc: 0.701031\n",
      "Epoch 8352 - Train Loss: 0.134022, Train Acc: 0.767949 | Val Loss: 0.148695, Val Acc: 0.701031\n",
      "Epoch 8353 - Train Loss: 0.134013, Train Acc: 0.767949 | Val Loss: 0.148686, Val Acc: 0.701031\n",
      "Epoch 8354 - Train Loss: 0.134003, Train Acc: 0.767949 | Val Loss: 0.148678, Val Acc: 0.701031\n",
      "Epoch 8355 - Train Loss: 0.133993, Train Acc: 0.767949 | Val Loss: 0.148669, Val Acc: 0.701031\n",
      "Epoch 8356 - Train Loss: 0.133983, Train Acc: 0.767949 | Val Loss: 0.148661, Val Acc: 0.701031\n",
      "Epoch 8357 - Train Loss: 0.133974, Train Acc: 0.767949 | Val Loss: 0.148652, Val Acc: 0.701031\n",
      "Epoch 8358 - Train Loss: 0.133964, Train Acc: 0.767949 | Val Loss: 0.148644, Val Acc: 0.701031\n",
      "Epoch 8359 - Train Loss: 0.133954, Train Acc: 0.767949 | Val Loss: 0.148635, Val Acc: 0.701031\n",
      "Epoch 8360 - Train Loss: 0.133945, Train Acc: 0.767949 | Val Loss: 0.148627, Val Acc: 0.701031\n",
      "Epoch 8361 - Train Loss: 0.133935, Train Acc: 0.767949 | Val Loss: 0.148618, Val Acc: 0.701031\n",
      "Epoch 8362 - Train Loss: 0.133925, Train Acc: 0.767949 | Val Loss: 0.148610, Val Acc: 0.701031\n",
      "Epoch 8363 - Train Loss: 0.133916, Train Acc: 0.767949 | Val Loss: 0.148601, Val Acc: 0.701031\n",
      "Epoch 8364 - Train Loss: 0.133906, Train Acc: 0.767949 | Val Loss: 0.148593, Val Acc: 0.701031\n",
      "Epoch 8365 - Train Loss: 0.133896, Train Acc: 0.767949 | Val Loss: 0.148584, Val Acc: 0.701031\n",
      "Epoch 8366 - Train Loss: 0.133887, Train Acc: 0.767949 | Val Loss: 0.148575, Val Acc: 0.701031\n",
      "Epoch 8367 - Train Loss: 0.133877, Train Acc: 0.767949 | Val Loss: 0.148567, Val Acc: 0.701031\n",
      "Epoch 8368 - Train Loss: 0.133867, Train Acc: 0.767949 | Val Loss: 0.148558, Val Acc: 0.701031\n",
      "Epoch 8369 - Train Loss: 0.133857, Train Acc: 0.767949 | Val Loss: 0.148550, Val Acc: 0.701031\n",
      "Epoch 8370 - Train Loss: 0.133848, Train Acc: 0.767949 | Val Loss: 0.148541, Val Acc: 0.701031\n",
      "Epoch 8371 - Train Loss: 0.133838, Train Acc: 0.767949 | Val Loss: 0.148533, Val Acc: 0.701031\n",
      "Epoch 8372 - Train Loss: 0.133828, Train Acc: 0.767949 | Val Loss: 0.148524, Val Acc: 0.701031\n",
      "Epoch 8373 - Train Loss: 0.133819, Train Acc: 0.767949 | Val Loss: 0.148516, Val Acc: 0.701031\n",
      "Epoch 8374 - Train Loss: 0.133809, Train Acc: 0.767949 | Val Loss: 0.148507, Val Acc: 0.701031\n",
      "Epoch 8375 - Train Loss: 0.133799, Train Acc: 0.767949 | Val Loss: 0.148499, Val Acc: 0.701031\n",
      "Epoch 8376 - Train Loss: 0.133790, Train Acc: 0.767949 | Val Loss: 0.148491, Val Acc: 0.701031\n",
      "Epoch 8377 - Train Loss: 0.133780, Train Acc: 0.767949 | Val Loss: 0.148482, Val Acc: 0.701031\n",
      "Epoch 8378 - Train Loss: 0.133770, Train Acc: 0.767949 | Val Loss: 0.148474, Val Acc: 0.701031\n",
      "Epoch 8379 - Train Loss: 0.133761, Train Acc: 0.767949 | Val Loss: 0.148465, Val Acc: 0.701031\n",
      "Epoch 8380 - Train Loss: 0.133751, Train Acc: 0.767949 | Val Loss: 0.148457, Val Acc: 0.701031\n",
      "Epoch 8381 - Train Loss: 0.133741, Train Acc: 0.767949 | Val Loss: 0.148448, Val Acc: 0.701031\n",
      "Epoch 8382 - Train Loss: 0.133732, Train Acc: 0.767949 | Val Loss: 0.148440, Val Acc: 0.701031\n",
      "Epoch 8383 - Train Loss: 0.133722, Train Acc: 0.767949 | Val Loss: 0.148431, Val Acc: 0.701031\n",
      "Epoch 8384 - Train Loss: 0.133712, Train Acc: 0.767949 | Val Loss: 0.148423, Val Acc: 0.701031\n",
      "Epoch 8385 - Train Loss: 0.133703, Train Acc: 0.767949 | Val Loss: 0.148414, Val Acc: 0.701031\n",
      "Epoch 8386 - Train Loss: 0.133693, Train Acc: 0.767949 | Val Loss: 0.148406, Val Acc: 0.701031\n",
      "Epoch 8387 - Train Loss: 0.133683, Train Acc: 0.767949 | Val Loss: 0.148397, Val Acc: 0.701031\n",
      "Epoch 8388 - Train Loss: 0.133674, Train Acc: 0.767949 | Val Loss: 0.148389, Val Acc: 0.701031\n",
      "Epoch 8389 - Train Loss: 0.133664, Train Acc: 0.767949 | Val Loss: 0.148380, Val Acc: 0.701031\n",
      "Epoch 8390 - Train Loss: 0.133654, Train Acc: 0.767949 | Val Loss: 0.148372, Val Acc: 0.701031\n",
      "Epoch 8391 - Train Loss: 0.133645, Train Acc: 0.767949 | Val Loss: 0.148363, Val Acc: 0.701031\n",
      "Epoch 8392 - Train Loss: 0.133635, Train Acc: 0.767949 | Val Loss: 0.148355, Val Acc: 0.701031\n",
      "Epoch 8393 - Train Loss: 0.133625, Train Acc: 0.767949 | Val Loss: 0.148346, Val Acc: 0.701031\n",
      "Epoch 8394 - Train Loss: 0.133616, Train Acc: 0.767949 | Val Loss: 0.148338, Val Acc: 0.701031\n",
      "Epoch 8395 - Train Loss: 0.133606, Train Acc: 0.767949 | Val Loss: 0.148329, Val Acc: 0.701031\n",
      "Epoch 8396 - Train Loss: 0.133596, Train Acc: 0.767949 | Val Loss: 0.148321, Val Acc: 0.701031\n",
      "Epoch 8397 - Train Loss: 0.133587, Train Acc: 0.767949 | Val Loss: 0.148312, Val Acc: 0.701031\n",
      "Epoch 8398 - Train Loss: 0.133577, Train Acc: 0.767949 | Val Loss: 0.148304, Val Acc: 0.701031\n",
      "Epoch 8399 - Train Loss: 0.133567, Train Acc: 0.767949 | Val Loss: 0.148295, Val Acc: 0.701031\n",
      "Epoch 8400 - Train Loss: 0.133558, Train Acc: 0.767949 | Val Loss: 0.148287, Val Acc: 0.701031\n",
      "Epoch 8401 - Train Loss: 0.133548, Train Acc: 0.767949 | Val Loss: 0.148278, Val Acc: 0.701031\n",
      "Epoch 8402 - Train Loss: 0.133539, Train Acc: 0.767949 | Val Loss: 0.148270, Val Acc: 0.701031\n",
      "Epoch 8403 - Train Loss: 0.133529, Train Acc: 0.767949 | Val Loss: 0.148262, Val Acc: 0.701031\n",
      "Epoch 8404 - Train Loss: 0.133519, Train Acc: 0.767949 | Val Loss: 0.148253, Val Acc: 0.701031\n",
      "Epoch 8405 - Train Loss: 0.133510, Train Acc: 0.767949 | Val Loss: 0.148245, Val Acc: 0.701031\n",
      "Epoch 8406 - Train Loss: 0.133500, Train Acc: 0.767949 | Val Loss: 0.148236, Val Acc: 0.701031\n",
      "Epoch 8407 - Train Loss: 0.133490, Train Acc: 0.767949 | Val Loss: 0.148228, Val Acc: 0.701031\n",
      "Epoch 8408 - Train Loss: 0.133481, Train Acc: 0.767949 | Val Loss: 0.148219, Val Acc: 0.701031\n",
      "Epoch 8409 - Train Loss: 0.133471, Train Acc: 0.767949 | Val Loss: 0.148211, Val Acc: 0.701031\n",
      "Epoch 8410 - Train Loss: 0.133461, Train Acc: 0.767949 | Val Loss: 0.148202, Val Acc: 0.701031\n",
      "Epoch 8411 - Train Loss: 0.133452, Train Acc: 0.767949 | Val Loss: 0.148194, Val Acc: 0.701031\n",
      "Epoch 8412 - Train Loss: 0.133442, Train Acc: 0.767949 | Val Loss: 0.148185, Val Acc: 0.701031\n",
      "Epoch 8413 - Train Loss: 0.133433, Train Acc: 0.767949 | Val Loss: 0.148177, Val Acc: 0.701031\n",
      "Epoch 8414 - Train Loss: 0.133423, Train Acc: 0.767949 | Val Loss: 0.148168, Val Acc: 0.701031\n",
      "Epoch 8415 - Train Loss: 0.133413, Train Acc: 0.767949 | Val Loss: 0.148160, Val Acc: 0.701031\n",
      "Epoch 8416 - Train Loss: 0.133404, Train Acc: 0.767949 | Val Loss: 0.148151, Val Acc: 0.701031\n",
      "Epoch 8417 - Train Loss: 0.133394, Train Acc: 0.767949 | Val Loss: 0.148143, Val Acc: 0.701031\n",
      "Epoch 8418 - Train Loss: 0.133384, Train Acc: 0.767949 | Val Loss: 0.148134, Val Acc: 0.701031\n",
      "Epoch 8419 - Train Loss: 0.133375, Train Acc: 0.767949 | Val Loss: 0.148126, Val Acc: 0.701031\n",
      "Epoch 8420 - Train Loss: 0.133365, Train Acc: 0.767949 | Val Loss: 0.148118, Val Acc: 0.701031\n",
      "Epoch 8421 - Train Loss: 0.133356, Train Acc: 0.767949 | Val Loss: 0.148109, Val Acc: 0.701031\n",
      "Epoch 8422 - Train Loss: 0.133346, Train Acc: 0.767949 | Val Loss: 0.148101, Val Acc: 0.701031\n",
      "Epoch 8423 - Train Loss: 0.133336, Train Acc: 0.767949 | Val Loss: 0.148092, Val Acc: 0.701031\n",
      "Epoch 8424 - Train Loss: 0.133327, Train Acc: 0.767949 | Val Loss: 0.148084, Val Acc: 0.701031\n",
      "Epoch 8425 - Train Loss: 0.133317, Train Acc: 0.767949 | Val Loss: 0.148075, Val Acc: 0.701031\n",
      "Epoch 8426 - Train Loss: 0.133308, Train Acc: 0.767949 | Val Loss: 0.148067, Val Acc: 0.701031\n",
      "Epoch 8427 - Train Loss: 0.133298, Train Acc: 0.767949 | Val Loss: 0.148058, Val Acc: 0.701031\n",
      "Epoch 8428 - Train Loss: 0.133288, Train Acc: 0.767949 | Val Loss: 0.148050, Val Acc: 0.701031\n",
      "Epoch 8429 - Train Loss: 0.133279, Train Acc: 0.767949 | Val Loss: 0.148041, Val Acc: 0.701031\n",
      "Epoch 8430 - Train Loss: 0.133269, Train Acc: 0.767949 | Val Loss: 0.148033, Val Acc: 0.701031\n",
      "Epoch 8431 - Train Loss: 0.133260, Train Acc: 0.767949 | Val Loss: 0.148024, Val Acc: 0.701031\n",
      "Epoch 8432 - Train Loss: 0.133250, Train Acc: 0.767949 | Val Loss: 0.148016, Val Acc: 0.701031\n",
      "Epoch 8433 - Train Loss: 0.133240, Train Acc: 0.767949 | Val Loss: 0.148008, Val Acc: 0.701031\n",
      "Epoch 8434 - Train Loss: 0.133231, Train Acc: 0.767949 | Val Loss: 0.147999, Val Acc: 0.701031\n",
      "Epoch 8435 - Train Loss: 0.133221, Train Acc: 0.767949 | Val Loss: 0.147991, Val Acc: 0.701031\n",
      "Epoch 8436 - Train Loss: 0.133212, Train Acc: 0.767949 | Val Loss: 0.147982, Val Acc: 0.701031\n",
      "Epoch 8437 - Train Loss: 0.133202, Train Acc: 0.767949 | Val Loss: 0.147974, Val Acc: 0.701031\n",
      "Epoch 8438 - Train Loss: 0.133192, Train Acc: 0.767949 | Val Loss: 0.147966, Val Acc: 0.701031\n",
      "Epoch 8439 - Train Loss: 0.133183, Train Acc: 0.767949 | Val Loss: 0.147957, Val Acc: 0.701031\n",
      "Epoch 8440 - Train Loss: 0.133173, Train Acc: 0.767949 | Val Loss: 0.147949, Val Acc: 0.701031\n",
      "Epoch 8441 - Train Loss: 0.133164, Train Acc: 0.767949 | Val Loss: 0.147940, Val Acc: 0.701031\n",
      "Epoch 8442 - Train Loss: 0.133154, Train Acc: 0.767949 | Val Loss: 0.147932, Val Acc: 0.701031\n",
      "Epoch 8443 - Train Loss: 0.133145, Train Acc: 0.767949 | Val Loss: 0.147924, Val Acc: 0.701031\n",
      "Epoch 8444 - Train Loss: 0.133135, Train Acc: 0.767949 | Val Loss: 0.147915, Val Acc: 0.701031\n",
      "Epoch 8445 - Train Loss: 0.133126, Train Acc: 0.767949 | Val Loss: 0.147907, Val Acc: 0.701031\n",
      "Epoch 8446 - Train Loss: 0.133116, Train Acc: 0.767949 | Val Loss: 0.147898, Val Acc: 0.701031\n",
      "Epoch 8447 - Train Loss: 0.133106, Train Acc: 0.767949 | Val Loss: 0.147890, Val Acc: 0.701031\n",
      "Epoch 8448 - Train Loss: 0.133097, Train Acc: 0.767949 | Val Loss: 0.147882, Val Acc: 0.701031\n",
      "Epoch 8449 - Train Loss: 0.133087, Train Acc: 0.767949 | Val Loss: 0.147873, Val Acc: 0.701031\n",
      "Epoch 8450 - Train Loss: 0.133078, Train Acc: 0.767949 | Val Loss: 0.147865, Val Acc: 0.701031\n",
      "Epoch 8451 - Train Loss: 0.133068, Train Acc: 0.767949 | Val Loss: 0.147857, Val Acc: 0.701031\n",
      "Epoch 8452 - Train Loss: 0.133059, Train Acc: 0.767949 | Val Loss: 0.147848, Val Acc: 0.701031\n",
      "Epoch 8453 - Train Loss: 0.133049, Train Acc: 0.767949 | Val Loss: 0.147840, Val Acc: 0.701031\n",
      "Epoch 8454 - Train Loss: 0.133040, Train Acc: 0.767949 | Val Loss: 0.147831, Val Acc: 0.701031\n",
      "Epoch 8455 - Train Loss: 0.133030, Train Acc: 0.767949 | Val Loss: 0.147823, Val Acc: 0.701031\n",
      "Epoch 8456 - Train Loss: 0.133021, Train Acc: 0.767949 | Val Loss: 0.147815, Val Acc: 0.701031\n",
      "Epoch 8457 - Train Loss: 0.133011, Train Acc: 0.767949 | Val Loss: 0.147806, Val Acc: 0.701031\n",
      "Epoch 8458 - Train Loss: 0.133002, Train Acc: 0.767949 | Val Loss: 0.147798, Val Acc: 0.701031\n",
      "Epoch 8459 - Train Loss: 0.132992, Train Acc: 0.767949 | Val Loss: 0.147790, Val Acc: 0.701031\n",
      "Epoch 8460 - Train Loss: 0.132983, Train Acc: 0.767949 | Val Loss: 0.147781, Val Acc: 0.701031\n",
      "Epoch 8461 - Train Loss: 0.132973, Train Acc: 0.767949 | Val Loss: 0.147773, Val Acc: 0.701031\n",
      "Epoch 8462 - Train Loss: 0.132964, Train Acc: 0.767949 | Val Loss: 0.147765, Val Acc: 0.701031\n",
      "Epoch 8463 - Train Loss: 0.132954, Train Acc: 0.767949 | Val Loss: 0.147756, Val Acc: 0.701031\n",
      "Epoch 8464 - Train Loss: 0.132944, Train Acc: 0.767949 | Val Loss: 0.147748, Val Acc: 0.701031\n",
      "Epoch 8465 - Train Loss: 0.132935, Train Acc: 0.767949 | Val Loss: 0.147740, Val Acc: 0.701031\n",
      "Epoch 8466 - Train Loss: 0.132925, Train Acc: 0.767949 | Val Loss: 0.147731, Val Acc: 0.701031\n",
      "Epoch 8467 - Train Loss: 0.132916, Train Acc: 0.767949 | Val Loss: 0.147723, Val Acc: 0.701031\n",
      "Epoch 8468 - Train Loss: 0.132907, Train Acc: 0.767949 | Val Loss: 0.147715, Val Acc: 0.701031\n",
      "Epoch 8469 - Train Loss: 0.132897, Train Acc: 0.767949 | Val Loss: 0.147706, Val Acc: 0.701031\n",
      "Epoch 8470 - Train Loss: 0.132888, Train Acc: 0.767949 | Val Loss: 0.147698, Val Acc: 0.701031\n",
      "Epoch 8471 - Train Loss: 0.132878, Train Acc: 0.767949 | Val Loss: 0.147690, Val Acc: 0.701031\n",
      "Epoch 8472 - Train Loss: 0.132869, Train Acc: 0.767949 | Val Loss: 0.147681, Val Acc: 0.701031\n",
      "Epoch 8473 - Train Loss: 0.132859, Train Acc: 0.767949 | Val Loss: 0.147673, Val Acc: 0.701031\n",
      "Epoch 8474 - Train Loss: 0.132850, Train Acc: 0.767949 | Val Loss: 0.147665, Val Acc: 0.701031\n",
      "Epoch 8475 - Train Loss: 0.132840, Train Acc: 0.767949 | Val Loss: 0.147656, Val Acc: 0.701031\n",
      "Epoch 8476 - Train Loss: 0.132831, Train Acc: 0.767949 | Val Loss: 0.147648, Val Acc: 0.701031\n",
      "Epoch 8477 - Train Loss: 0.132821, Train Acc: 0.767949 | Val Loss: 0.147640, Val Acc: 0.701031\n",
      "Epoch 8478 - Train Loss: 0.132812, Train Acc: 0.767949 | Val Loss: 0.147631, Val Acc: 0.701031\n",
      "Epoch 8479 - Train Loss: 0.132802, Train Acc: 0.767949 | Val Loss: 0.147623, Val Acc: 0.701031\n",
      "Epoch 8480 - Train Loss: 0.132793, Train Acc: 0.767949 | Val Loss: 0.147615, Val Acc: 0.701031\n",
      "Epoch 8481 - Train Loss: 0.132783, Train Acc: 0.767949 | Val Loss: 0.147606, Val Acc: 0.701031\n",
      "Epoch 8482 - Train Loss: 0.132774, Train Acc: 0.767949 | Val Loss: 0.147598, Val Acc: 0.701031\n",
      "Epoch 8483 - Train Loss: 0.132764, Train Acc: 0.767949 | Val Loss: 0.147590, Val Acc: 0.701031\n",
      "Epoch 8484 - Train Loss: 0.132755, Train Acc: 0.767949 | Val Loss: 0.147581, Val Acc: 0.701031\n",
      "Epoch 8485 - Train Loss: 0.132745, Train Acc: 0.767949 | Val Loss: 0.147573, Val Acc: 0.701031\n",
      "Epoch 8486 - Train Loss: 0.132736, Train Acc: 0.767949 | Val Loss: 0.147565, Val Acc: 0.701031\n",
      "Epoch 8487 - Train Loss: 0.132727, Train Acc: 0.767949 | Val Loss: 0.147557, Val Acc: 0.701031\n",
      "Epoch 8488 - Train Loss: 0.132717, Train Acc: 0.767949 | Val Loss: 0.147548, Val Acc: 0.701031\n",
      "Epoch 8489 - Train Loss: 0.132708, Train Acc: 0.767949 | Val Loss: 0.147540, Val Acc: 0.701031\n",
      "Epoch 8490 - Train Loss: 0.132698, Train Acc: 0.767949 | Val Loss: 0.147532, Val Acc: 0.701031\n",
      "Epoch 8491 - Train Loss: 0.132689, Train Acc: 0.767949 | Val Loss: 0.147523, Val Acc: 0.701031\n",
      "Epoch 8492 - Train Loss: 0.132679, Train Acc: 0.767949 | Val Loss: 0.147515, Val Acc: 0.701031\n",
      "Epoch 8493 - Train Loss: 0.132670, Train Acc: 0.767949 | Val Loss: 0.147507, Val Acc: 0.701031\n",
      "Epoch 8494 - Train Loss: 0.132660, Train Acc: 0.767949 | Val Loss: 0.147498, Val Acc: 0.701031\n",
      "Epoch 8495 - Train Loss: 0.132651, Train Acc: 0.767949 | Val Loss: 0.147490, Val Acc: 0.701031\n",
      "Epoch 8496 - Train Loss: 0.132641, Train Acc: 0.767949 | Val Loss: 0.147482, Val Acc: 0.701031\n",
      "Epoch 8497 - Train Loss: 0.132632, Train Acc: 0.767949 | Val Loss: 0.147474, Val Acc: 0.701031\n",
      "Epoch 8498 - Train Loss: 0.132622, Train Acc: 0.767949 | Val Loss: 0.147465, Val Acc: 0.701031\n",
      "Epoch 8499 - Train Loss: 0.132613, Train Acc: 0.767949 | Val Loss: 0.147457, Val Acc: 0.701031\n",
      "Epoch 8500 - Train Loss: 0.132604, Train Acc: 0.767949 | Val Loss: 0.147449, Val Acc: 0.701031\n",
      "Epoch 8501 - Train Loss: 0.132594, Train Acc: 0.767949 | Val Loss: 0.147440, Val Acc: 0.701031\n",
      "Epoch 8502 - Train Loss: 0.132585, Train Acc: 0.767949 | Val Loss: 0.147432, Val Acc: 0.701031\n",
      "Epoch 8503 - Train Loss: 0.132575, Train Acc: 0.767949 | Val Loss: 0.147424, Val Acc: 0.701031\n",
      "Epoch 8504 - Train Loss: 0.132566, Train Acc: 0.767949 | Val Loss: 0.147416, Val Acc: 0.701031\n",
      "Epoch 8505 - Train Loss: 0.132556, Train Acc: 0.767949 | Val Loss: 0.147407, Val Acc: 0.701031\n",
      "Epoch 8506 - Train Loss: 0.132547, Train Acc: 0.767949 | Val Loss: 0.147399, Val Acc: 0.701031\n",
      "Epoch 8507 - Train Loss: 0.132537, Train Acc: 0.767949 | Val Loss: 0.147391, Val Acc: 0.701031\n",
      "Epoch 8508 - Train Loss: 0.132528, Train Acc: 0.767949 | Val Loss: 0.147382, Val Acc: 0.701031\n",
      "Epoch 8509 - Train Loss: 0.132519, Train Acc: 0.767949 | Val Loss: 0.147374, Val Acc: 0.701031\n",
      "Epoch 8510 - Train Loss: 0.132509, Train Acc: 0.767949 | Val Loss: 0.147366, Val Acc: 0.701031\n",
      "Epoch 8511 - Train Loss: 0.132500, Train Acc: 0.767949 | Val Loss: 0.147358, Val Acc: 0.701031\n",
      "Epoch 8512 - Train Loss: 0.132490, Train Acc: 0.767949 | Val Loss: 0.147349, Val Acc: 0.701031\n",
      "Epoch 8513 - Train Loss: 0.132481, Train Acc: 0.767949 | Val Loss: 0.147341, Val Acc: 0.701031\n",
      "Epoch 8514 - Train Loss: 0.132471, Train Acc: 0.767949 | Val Loss: 0.147333, Val Acc: 0.701031\n",
      "Epoch 8515 - Train Loss: 0.132462, Train Acc: 0.767949 | Val Loss: 0.147325, Val Acc: 0.701031\n",
      "Epoch 8516 - Train Loss: 0.132452, Train Acc: 0.766667 | Val Loss: 0.147316, Val Acc: 0.701031\n",
      "Epoch 8517 - Train Loss: 0.132443, Train Acc: 0.766667 | Val Loss: 0.147308, Val Acc: 0.701031\n",
      "Epoch 8518 - Train Loss: 0.132434, Train Acc: 0.766667 | Val Loss: 0.147300, Val Acc: 0.701031\n",
      "Epoch 8519 - Train Loss: 0.132424, Train Acc: 0.766667 | Val Loss: 0.147291, Val Acc: 0.701031\n",
      "Epoch 8520 - Train Loss: 0.132415, Train Acc: 0.766667 | Val Loss: 0.147283, Val Acc: 0.701031\n",
      "Epoch 8521 - Train Loss: 0.132405, Train Acc: 0.766667 | Val Loss: 0.147275, Val Acc: 0.701031\n",
      "Epoch 8522 - Train Loss: 0.132396, Train Acc: 0.766667 | Val Loss: 0.147267, Val Acc: 0.701031\n",
      "Epoch 8523 - Train Loss: 0.132386, Train Acc: 0.766667 | Val Loss: 0.147258, Val Acc: 0.701031\n",
      "Epoch 8524 - Train Loss: 0.132377, Train Acc: 0.766667 | Val Loss: 0.147250, Val Acc: 0.701031\n",
      "Epoch 8525 - Train Loss: 0.132368, Train Acc: 0.766667 | Val Loss: 0.147242, Val Acc: 0.701031\n",
      "Epoch 8526 - Train Loss: 0.132358, Train Acc: 0.766667 | Val Loss: 0.147234, Val Acc: 0.701031\n",
      "Epoch 8527 - Train Loss: 0.132349, Train Acc: 0.766667 | Val Loss: 0.147225, Val Acc: 0.701031\n",
      "Epoch 8528 - Train Loss: 0.132339, Train Acc: 0.766667 | Val Loss: 0.147217, Val Acc: 0.701031\n",
      "Epoch 8529 - Train Loss: 0.132330, Train Acc: 0.766667 | Val Loss: 0.147209, Val Acc: 0.701031\n",
      "Epoch 8530 - Train Loss: 0.132321, Train Acc: 0.766667 | Val Loss: 0.147201, Val Acc: 0.701031\n",
      "Epoch 8531 - Train Loss: 0.132311, Train Acc: 0.766667 | Val Loss: 0.147192, Val Acc: 0.701031\n",
      "Epoch 8532 - Train Loss: 0.132302, Train Acc: 0.766667 | Val Loss: 0.147184, Val Acc: 0.701031\n",
      "Epoch 8533 - Train Loss: 0.132292, Train Acc: 0.766667 | Val Loss: 0.147176, Val Acc: 0.701031\n",
      "Epoch 8534 - Train Loss: 0.132283, Train Acc: 0.766667 | Val Loss: 0.147168, Val Acc: 0.701031\n",
      "Epoch 8535 - Train Loss: 0.132274, Train Acc: 0.766667 | Val Loss: 0.147159, Val Acc: 0.701031\n",
      "Epoch 8536 - Train Loss: 0.132264, Train Acc: 0.766667 | Val Loss: 0.147151, Val Acc: 0.701031\n",
      "Epoch 8537 - Train Loss: 0.132255, Train Acc: 0.766667 | Val Loss: 0.147143, Val Acc: 0.701031\n",
      "Epoch 8538 - Train Loss: 0.132245, Train Acc: 0.766667 | Val Loss: 0.147135, Val Acc: 0.701031\n",
      "Epoch 8539 - Train Loss: 0.132236, Train Acc: 0.766667 | Val Loss: 0.147127, Val Acc: 0.701031\n",
      "Epoch 8540 - Train Loss: 0.132227, Train Acc: 0.766667 | Val Loss: 0.147118, Val Acc: 0.701031\n",
      "Epoch 8541 - Train Loss: 0.132217, Train Acc: 0.766667 | Val Loss: 0.147110, Val Acc: 0.701031\n",
      "Epoch 8542 - Train Loss: 0.132208, Train Acc: 0.766667 | Val Loss: 0.147102, Val Acc: 0.701031\n",
      "Epoch 8543 - Train Loss: 0.132198, Train Acc: 0.766667 | Val Loss: 0.147094, Val Acc: 0.701031\n",
      "Epoch 8544 - Train Loss: 0.132189, Train Acc: 0.766667 | Val Loss: 0.147085, Val Acc: 0.701031\n",
      "Epoch 8545 - Train Loss: 0.132180, Train Acc: 0.766667 | Val Loss: 0.147077, Val Acc: 0.701031\n",
      "Epoch 8546 - Train Loss: 0.132170, Train Acc: 0.766667 | Val Loss: 0.147069, Val Acc: 0.701031\n",
      "Epoch 8547 - Train Loss: 0.132161, Train Acc: 0.766667 | Val Loss: 0.147061, Val Acc: 0.701031\n",
      "Epoch 8548 - Train Loss: 0.132151, Train Acc: 0.766667 | Val Loss: 0.147052, Val Acc: 0.701031\n",
      "Epoch 8549 - Train Loss: 0.132142, Train Acc: 0.766667 | Val Loss: 0.147044, Val Acc: 0.701031\n",
      "Epoch 8550 - Train Loss: 0.132133, Train Acc: 0.766667 | Val Loss: 0.147036, Val Acc: 0.701031\n",
      "Epoch 8551 - Train Loss: 0.132123, Train Acc: 0.766667 | Val Loss: 0.147028, Val Acc: 0.701031\n",
      "Epoch 8552 - Train Loss: 0.132114, Train Acc: 0.766667 | Val Loss: 0.147020, Val Acc: 0.701031\n",
      "Epoch 8553 - Train Loss: 0.132104, Train Acc: 0.766667 | Val Loss: 0.147011, Val Acc: 0.701031\n",
      "Epoch 8554 - Train Loss: 0.132095, Train Acc: 0.767949 | Val Loss: 0.147003, Val Acc: 0.701031\n",
      "Epoch 8555 - Train Loss: 0.132086, Train Acc: 0.767949 | Val Loss: 0.146995, Val Acc: 0.701031\n",
      "Epoch 8556 - Train Loss: 0.132076, Train Acc: 0.767949 | Val Loss: 0.146987, Val Acc: 0.701031\n",
      "Epoch 8557 - Train Loss: 0.132067, Train Acc: 0.767949 | Val Loss: 0.146979, Val Acc: 0.701031\n",
      "Epoch 8558 - Train Loss: 0.132058, Train Acc: 0.767949 | Val Loss: 0.146970, Val Acc: 0.701031\n",
      "Epoch 8559 - Train Loss: 0.132048, Train Acc: 0.767949 | Val Loss: 0.146962, Val Acc: 0.701031\n",
      "Epoch 8560 - Train Loss: 0.132039, Train Acc: 0.769231 | Val Loss: 0.146954, Val Acc: 0.701031\n",
      "Epoch 8561 - Train Loss: 0.132030, Train Acc: 0.769231 | Val Loss: 0.146946, Val Acc: 0.701031\n",
      "Epoch 8562 - Train Loss: 0.132020, Train Acc: 0.769231 | Val Loss: 0.146937, Val Acc: 0.701031\n",
      "Epoch 8563 - Train Loss: 0.132011, Train Acc: 0.769231 | Val Loss: 0.146929, Val Acc: 0.701031\n",
      "Epoch 8564 - Train Loss: 0.132001, Train Acc: 0.769231 | Val Loss: 0.146921, Val Acc: 0.701031\n",
      "Epoch 8565 - Train Loss: 0.131992, Train Acc: 0.769231 | Val Loss: 0.146913, Val Acc: 0.701031\n",
      "Epoch 8566 - Train Loss: 0.131983, Train Acc: 0.769231 | Val Loss: 0.146905, Val Acc: 0.701031\n",
      "Epoch 8567 - Train Loss: 0.131973, Train Acc: 0.769231 | Val Loss: 0.146897, Val Acc: 0.701031\n",
      "Epoch 8568 - Train Loss: 0.131964, Train Acc: 0.769231 | Val Loss: 0.146888, Val Acc: 0.701031\n",
      "Epoch 8569 - Train Loss: 0.131955, Train Acc: 0.769231 | Val Loss: 0.146880, Val Acc: 0.701031\n",
      "Epoch 8570 - Train Loss: 0.131945, Train Acc: 0.769231 | Val Loss: 0.146872, Val Acc: 0.701031\n",
      "Epoch 8571 - Train Loss: 0.131936, Train Acc: 0.769231 | Val Loss: 0.146864, Val Acc: 0.701031\n",
      "Epoch 8572 - Train Loss: 0.131927, Train Acc: 0.769231 | Val Loss: 0.146856, Val Acc: 0.701031\n",
      "Epoch 8573 - Train Loss: 0.131917, Train Acc: 0.770513 | Val Loss: 0.146847, Val Acc: 0.701031\n",
      "Epoch 8574 - Train Loss: 0.131908, Train Acc: 0.770513 | Val Loss: 0.146839, Val Acc: 0.701031\n",
      "Epoch 8575 - Train Loss: 0.131899, Train Acc: 0.770513 | Val Loss: 0.146831, Val Acc: 0.701031\n",
      "Epoch 8576 - Train Loss: 0.131889, Train Acc: 0.770513 | Val Loss: 0.146823, Val Acc: 0.701031\n",
      "Epoch 8577 - Train Loss: 0.131880, Train Acc: 0.770513 | Val Loss: 0.146815, Val Acc: 0.701031\n",
      "Epoch 8578 - Train Loss: 0.131870, Train Acc: 0.770513 | Val Loss: 0.146806, Val Acc: 0.701031\n",
      "Epoch 8579 - Train Loss: 0.131861, Train Acc: 0.770513 | Val Loss: 0.146798, Val Acc: 0.701031\n",
      "Epoch 8580 - Train Loss: 0.131852, Train Acc: 0.770513 | Val Loss: 0.146790, Val Acc: 0.701031\n",
      "Epoch 8581 - Train Loss: 0.131842, Train Acc: 0.770513 | Val Loss: 0.146782, Val Acc: 0.701031\n",
      "Epoch 8582 - Train Loss: 0.131833, Train Acc: 0.770513 | Val Loss: 0.146774, Val Acc: 0.701031\n",
      "Epoch 8583 - Train Loss: 0.131824, Train Acc: 0.770513 | Val Loss: 0.146766, Val Acc: 0.701031\n",
      "Epoch 8584 - Train Loss: 0.131814, Train Acc: 0.770513 | Val Loss: 0.146757, Val Acc: 0.701031\n",
      "Epoch 8585 - Train Loss: 0.131805, Train Acc: 0.770513 | Val Loss: 0.146749, Val Acc: 0.701031\n",
      "Epoch 8586 - Train Loss: 0.131796, Train Acc: 0.770513 | Val Loss: 0.146741, Val Acc: 0.701031\n",
      "Epoch 8587 - Train Loss: 0.131786, Train Acc: 0.770513 | Val Loss: 0.146733, Val Acc: 0.701031\n",
      "Epoch 8588 - Train Loss: 0.131777, Train Acc: 0.770513 | Val Loss: 0.146725, Val Acc: 0.701031\n",
      "Epoch 8589 - Train Loss: 0.131767, Train Acc: 0.770513 | Val Loss: 0.146716, Val Acc: 0.701031\n",
      "Epoch 8590 - Train Loss: 0.131758, Train Acc: 0.770513 | Val Loss: 0.146708, Val Acc: 0.701031\n",
      "Epoch 8591 - Train Loss: 0.131749, Train Acc: 0.770513 | Val Loss: 0.146700, Val Acc: 0.701031\n",
      "Epoch 8592 - Train Loss: 0.131739, Train Acc: 0.770513 | Val Loss: 0.146692, Val Acc: 0.701031\n",
      "Epoch 8593 - Train Loss: 0.131730, Train Acc: 0.770513 | Val Loss: 0.146684, Val Acc: 0.701031\n",
      "Epoch 8594 - Train Loss: 0.131721, Train Acc: 0.770513 | Val Loss: 0.146676, Val Acc: 0.701031\n",
      "Epoch 8595 - Train Loss: 0.131711, Train Acc: 0.770513 | Val Loss: 0.146667, Val Acc: 0.701031\n",
      "Epoch 8596 - Train Loss: 0.131702, Train Acc: 0.770513 | Val Loss: 0.146659, Val Acc: 0.701031\n",
      "Epoch 8597 - Train Loss: 0.131693, Train Acc: 0.770513 | Val Loss: 0.146651, Val Acc: 0.701031\n",
      "Epoch 8598 - Train Loss: 0.131683, Train Acc: 0.770513 | Val Loss: 0.146643, Val Acc: 0.701031\n",
      "Epoch 8599 - Train Loss: 0.131674, Train Acc: 0.770513 | Val Loss: 0.146635, Val Acc: 0.701031\n",
      "Epoch 8600 - Train Loss: 0.131665, Train Acc: 0.770513 | Val Loss: 0.146627, Val Acc: 0.701031\n",
      "Epoch 8601 - Train Loss: 0.131655, Train Acc: 0.770513 | Val Loss: 0.146618, Val Acc: 0.701031\n",
      "Epoch 8602 - Train Loss: 0.131646, Train Acc: 0.770513 | Val Loss: 0.146610, Val Acc: 0.701031\n",
      "Epoch 8603 - Train Loss: 0.131636, Train Acc: 0.770513 | Val Loss: 0.146602, Val Acc: 0.701031\n",
      "Epoch 8604 - Train Loss: 0.131627, Train Acc: 0.770513 | Val Loss: 0.146594, Val Acc: 0.701031\n",
      "Epoch 8605 - Train Loss: 0.131618, Train Acc: 0.770513 | Val Loss: 0.146586, Val Acc: 0.701031\n",
      "Epoch 8606 - Train Loss: 0.131608, Train Acc: 0.771795 | Val Loss: 0.146578, Val Acc: 0.701031\n",
      "Epoch 8607 - Train Loss: 0.131599, Train Acc: 0.773077 | Val Loss: 0.146570, Val Acc: 0.701031\n",
      "Epoch 8608 - Train Loss: 0.131590, Train Acc: 0.773077 | Val Loss: 0.146562, Val Acc: 0.701031\n",
      "Epoch 8609 - Train Loss: 0.131580, Train Acc: 0.773077 | Val Loss: 0.146553, Val Acc: 0.701031\n",
      "Epoch 8610 - Train Loss: 0.131571, Train Acc: 0.773077 | Val Loss: 0.146545, Val Acc: 0.701031\n",
      "Epoch 8611 - Train Loss: 0.131562, Train Acc: 0.773077 | Val Loss: 0.146537, Val Acc: 0.701031\n",
      "Epoch 8612 - Train Loss: 0.131552, Train Acc: 0.773077 | Val Loss: 0.146529, Val Acc: 0.701031\n",
      "Epoch 8613 - Train Loss: 0.131543, Train Acc: 0.773077 | Val Loss: 0.146521, Val Acc: 0.701031\n",
      "Epoch 8614 - Train Loss: 0.131534, Train Acc: 0.773077 | Val Loss: 0.146513, Val Acc: 0.701031\n",
      "Epoch 8615 - Train Loss: 0.131524, Train Acc: 0.773077 | Val Loss: 0.146505, Val Acc: 0.701031\n",
      "Epoch 8616 - Train Loss: 0.131515, Train Acc: 0.773077 | Val Loss: 0.146496, Val Acc: 0.701031\n",
      "Epoch 8617 - Train Loss: 0.131506, Train Acc: 0.773077 | Val Loss: 0.146488, Val Acc: 0.701031\n",
      "Epoch 8618 - Train Loss: 0.131496, Train Acc: 0.773077 | Val Loss: 0.146480, Val Acc: 0.701031\n",
      "Epoch 8619 - Train Loss: 0.131487, Train Acc: 0.773077 | Val Loss: 0.146472, Val Acc: 0.701031\n",
      "Epoch 8620 - Train Loss: 0.131478, Train Acc: 0.773077 | Val Loss: 0.146464, Val Acc: 0.701031\n",
      "Epoch 8621 - Train Loss: 0.131468, Train Acc: 0.773077 | Val Loss: 0.146456, Val Acc: 0.701031\n",
      "Epoch 8622 - Train Loss: 0.131459, Train Acc: 0.773077 | Val Loss: 0.146448, Val Acc: 0.701031\n",
      "Epoch 8623 - Train Loss: 0.131450, Train Acc: 0.773077 | Val Loss: 0.146439, Val Acc: 0.701031\n",
      "Epoch 8624 - Train Loss: 0.131440, Train Acc: 0.773077 | Val Loss: 0.146431, Val Acc: 0.701031\n",
      "Epoch 8625 - Train Loss: 0.131431, Train Acc: 0.773077 | Val Loss: 0.146423, Val Acc: 0.701031\n",
      "Epoch 8626 - Train Loss: 0.131422, Train Acc: 0.773077 | Val Loss: 0.146415, Val Acc: 0.701031\n",
      "Epoch 8627 - Train Loss: 0.131412, Train Acc: 0.773077 | Val Loss: 0.146407, Val Acc: 0.701031\n",
      "Epoch 8628 - Train Loss: 0.131403, Train Acc: 0.773077 | Val Loss: 0.146399, Val Acc: 0.701031\n",
      "Epoch 8629 - Train Loss: 0.131394, Train Acc: 0.773077 | Val Loss: 0.146390, Val Acc: 0.701031\n",
      "Epoch 8630 - Train Loss: 0.131384, Train Acc: 0.773077 | Val Loss: 0.146382, Val Acc: 0.701031\n",
      "Epoch 8631 - Train Loss: 0.131375, Train Acc: 0.773077 | Val Loss: 0.146374, Val Acc: 0.701031\n",
      "Epoch 8632 - Train Loss: 0.131366, Train Acc: 0.773077 | Val Loss: 0.146366, Val Acc: 0.701031\n",
      "Epoch 8633 - Train Loss: 0.131356, Train Acc: 0.773077 | Val Loss: 0.146358, Val Acc: 0.701031\n",
      "Epoch 8634 - Train Loss: 0.131347, Train Acc: 0.773077 | Val Loss: 0.146350, Val Acc: 0.701031\n",
      "Epoch 8635 - Train Loss: 0.131338, Train Acc: 0.773077 | Val Loss: 0.146341, Val Acc: 0.701031\n",
      "Epoch 8636 - Train Loss: 0.131328, Train Acc: 0.773077 | Val Loss: 0.146333, Val Acc: 0.701031\n",
      "Epoch 8637 - Train Loss: 0.131319, Train Acc: 0.773077 | Val Loss: 0.146325, Val Acc: 0.701031\n",
      "Epoch 8638 - Train Loss: 0.131310, Train Acc: 0.773077 | Val Loss: 0.146317, Val Acc: 0.701031\n",
      "Epoch 8639 - Train Loss: 0.131300, Train Acc: 0.773077 | Val Loss: 0.146309, Val Acc: 0.701031\n",
      "Epoch 8640 - Train Loss: 0.131291, Train Acc: 0.773077 | Val Loss: 0.146301, Val Acc: 0.701031\n",
      "Epoch 8641 - Train Loss: 0.131281, Train Acc: 0.774359 | Val Loss: 0.146292, Val Acc: 0.701031\n",
      "Epoch 8642 - Train Loss: 0.131272, Train Acc: 0.774359 | Val Loss: 0.146284, Val Acc: 0.701031\n",
      "Epoch 8643 - Train Loss: 0.131263, Train Acc: 0.774359 | Val Loss: 0.146276, Val Acc: 0.701031\n",
      "Epoch 8644 - Train Loss: 0.131253, Train Acc: 0.774359 | Val Loss: 0.146268, Val Acc: 0.701031\n",
      "Epoch 8645 - Train Loss: 0.131244, Train Acc: 0.774359 | Val Loss: 0.146260, Val Acc: 0.701031\n",
      "Epoch 8646 - Train Loss: 0.131235, Train Acc: 0.774359 | Val Loss: 0.146252, Val Acc: 0.701031\n",
      "Epoch 8647 - Train Loss: 0.131225, Train Acc: 0.774359 | Val Loss: 0.146243, Val Acc: 0.701031\n",
      "Epoch 8648 - Train Loss: 0.131216, Train Acc: 0.774359 | Val Loss: 0.146235, Val Acc: 0.701031\n",
      "Epoch 8649 - Train Loss: 0.131207, Train Acc: 0.774359 | Val Loss: 0.146227, Val Acc: 0.701031\n",
      "Epoch 8650 - Train Loss: 0.131197, Train Acc: 0.774359 | Val Loss: 0.146219, Val Acc: 0.701031\n",
      "Epoch 8651 - Train Loss: 0.131188, Train Acc: 0.774359 | Val Loss: 0.146211, Val Acc: 0.690722\n",
      "Epoch 8652 - Train Loss: 0.131179, Train Acc: 0.774359 | Val Loss: 0.146203, Val Acc: 0.690722\n",
      "Epoch 8653 - Train Loss: 0.131169, Train Acc: 0.774359 | Val Loss: 0.146195, Val Acc: 0.690722\n",
      "Epoch 8654 - Train Loss: 0.131160, Train Acc: 0.774359 | Val Loss: 0.146186, Val Acc: 0.690722\n",
      "Epoch 8655 - Train Loss: 0.131151, Train Acc: 0.774359 | Val Loss: 0.146178, Val Acc: 0.690722\n",
      "Epoch 8656 - Train Loss: 0.131141, Train Acc: 0.774359 | Val Loss: 0.146170, Val Acc: 0.690722\n",
      "Epoch 8657 - Train Loss: 0.131132, Train Acc: 0.774359 | Val Loss: 0.146162, Val Acc: 0.690722\n",
      "Epoch 8658 - Train Loss: 0.131123, Train Acc: 0.774359 | Val Loss: 0.146154, Val Acc: 0.690722\n",
      "Epoch 8659 - Train Loss: 0.131113, Train Acc: 0.774359 | Val Loss: 0.146146, Val Acc: 0.690722\n",
      "Epoch 8660 - Train Loss: 0.131104, Train Acc: 0.774359 | Val Loss: 0.146138, Val Acc: 0.690722\n",
      "Epoch 8661 - Train Loss: 0.131095, Train Acc: 0.774359 | Val Loss: 0.146129, Val Acc: 0.690722\n",
      "Epoch 8662 - Train Loss: 0.131086, Train Acc: 0.774359 | Val Loss: 0.146121, Val Acc: 0.690722\n",
      "Epoch 8663 - Train Loss: 0.131076, Train Acc: 0.774359 | Val Loss: 0.146113, Val Acc: 0.690722\n",
      "Epoch 8664 - Train Loss: 0.131067, Train Acc: 0.774359 | Val Loss: 0.146105, Val Acc: 0.690722\n",
      "Epoch 8665 - Train Loss: 0.131058, Train Acc: 0.774359 | Val Loss: 0.146097, Val Acc: 0.690722\n",
      "Epoch 8666 - Train Loss: 0.131048, Train Acc: 0.774359 | Val Loss: 0.146089, Val Acc: 0.690722\n",
      "Epoch 8667 - Train Loss: 0.131039, Train Acc: 0.774359 | Val Loss: 0.146081, Val Acc: 0.690722\n",
      "Epoch 8668 - Train Loss: 0.131030, Train Acc: 0.774359 | Val Loss: 0.146073, Val Acc: 0.690722\n",
      "Epoch 8669 - Train Loss: 0.131020, Train Acc: 0.774359 | Val Loss: 0.146064, Val Acc: 0.690722\n",
      "Epoch 8670 - Train Loss: 0.131011, Train Acc: 0.774359 | Val Loss: 0.146056, Val Acc: 0.690722\n",
      "Epoch 8671 - Train Loss: 0.131002, Train Acc: 0.774359 | Val Loss: 0.146048, Val Acc: 0.690722\n",
      "Epoch 8672 - Train Loss: 0.130992, Train Acc: 0.774359 | Val Loss: 0.146040, Val Acc: 0.690722\n",
      "Epoch 8673 - Train Loss: 0.130983, Train Acc: 0.774359 | Val Loss: 0.146032, Val Acc: 0.690722\n",
      "Epoch 8674 - Train Loss: 0.130974, Train Acc: 0.774359 | Val Loss: 0.146024, Val Acc: 0.690722\n",
      "Epoch 8675 - Train Loss: 0.130965, Train Acc: 0.774359 | Val Loss: 0.146016, Val Acc: 0.690722\n",
      "Epoch 8676 - Train Loss: 0.130955, Train Acc: 0.774359 | Val Loss: 0.146008, Val Acc: 0.690722\n",
      "Epoch 8677 - Train Loss: 0.130946, Train Acc: 0.774359 | Val Loss: 0.145999, Val Acc: 0.690722\n",
      "Epoch 8678 - Train Loss: 0.130937, Train Acc: 0.774359 | Val Loss: 0.145991, Val Acc: 0.690722\n",
      "Epoch 8679 - Train Loss: 0.130927, Train Acc: 0.774359 | Val Loss: 0.145983, Val Acc: 0.690722\n",
      "Epoch 8680 - Train Loss: 0.130918, Train Acc: 0.774359 | Val Loss: 0.145975, Val Acc: 0.690722\n",
      "Epoch 8681 - Train Loss: 0.130909, Train Acc: 0.774359 | Val Loss: 0.145967, Val Acc: 0.690722\n",
      "Epoch 8682 - Train Loss: 0.130900, Train Acc: 0.774359 | Val Loss: 0.145959, Val Acc: 0.690722\n",
      "Epoch 8683 - Train Loss: 0.130890, Train Acc: 0.774359 | Val Loss: 0.145951, Val Acc: 0.690722\n",
      "Epoch 8684 - Train Loss: 0.130881, Train Acc: 0.774359 | Val Loss: 0.145943, Val Acc: 0.690722\n",
      "Epoch 8685 - Train Loss: 0.130872, Train Acc: 0.774359 | Val Loss: 0.145935, Val Acc: 0.690722\n",
      "Epoch 8686 - Train Loss: 0.130863, Train Acc: 0.774359 | Val Loss: 0.145927, Val Acc: 0.690722\n",
      "Epoch 8687 - Train Loss: 0.130853, Train Acc: 0.774359 | Val Loss: 0.145918, Val Acc: 0.690722\n",
      "Epoch 8688 - Train Loss: 0.130844, Train Acc: 0.774359 | Val Loss: 0.145910, Val Acc: 0.690722\n",
      "Epoch 8689 - Train Loss: 0.130835, Train Acc: 0.774359 | Val Loss: 0.145902, Val Acc: 0.690722\n",
      "Epoch 8690 - Train Loss: 0.130826, Train Acc: 0.774359 | Val Loss: 0.145894, Val Acc: 0.690722\n",
      "Epoch 8691 - Train Loss: 0.130816, Train Acc: 0.774359 | Val Loss: 0.145886, Val Acc: 0.690722\n",
      "Epoch 8692 - Train Loss: 0.130807, Train Acc: 0.774359 | Val Loss: 0.145878, Val Acc: 0.690722\n",
      "Epoch 8693 - Train Loss: 0.130798, Train Acc: 0.774359 | Val Loss: 0.145870, Val Acc: 0.690722\n",
      "Epoch 8694 - Train Loss: 0.130789, Train Acc: 0.774359 | Val Loss: 0.145862, Val Acc: 0.690722\n",
      "Epoch 8695 - Train Loss: 0.130779, Train Acc: 0.774359 | Val Loss: 0.145854, Val Acc: 0.690722\n",
      "Epoch 8696 - Train Loss: 0.130770, Train Acc: 0.774359 | Val Loss: 0.145846, Val Acc: 0.690722\n",
      "Epoch 8697 - Train Loss: 0.130761, Train Acc: 0.774359 | Val Loss: 0.145838, Val Acc: 0.690722\n",
      "Epoch 8698 - Train Loss: 0.130752, Train Acc: 0.774359 | Val Loss: 0.145830, Val Acc: 0.690722\n",
      "Epoch 8699 - Train Loss: 0.130743, Train Acc: 0.774359 | Val Loss: 0.145822, Val Acc: 0.690722\n",
      "Epoch 8700 - Train Loss: 0.130733, Train Acc: 0.774359 | Val Loss: 0.145814, Val Acc: 0.690722\n",
      "Epoch 8701 - Train Loss: 0.130724, Train Acc: 0.774359 | Val Loss: 0.145805, Val Acc: 0.690722\n",
      "Epoch 8702 - Train Loss: 0.130715, Train Acc: 0.774359 | Val Loss: 0.145797, Val Acc: 0.690722\n",
      "Epoch 8703 - Train Loss: 0.130706, Train Acc: 0.774359 | Val Loss: 0.145789, Val Acc: 0.690722\n",
      "Epoch 8704 - Train Loss: 0.130696, Train Acc: 0.774359 | Val Loss: 0.145781, Val Acc: 0.690722\n",
      "Epoch 8705 - Train Loss: 0.130687, Train Acc: 0.774359 | Val Loss: 0.145773, Val Acc: 0.690722\n",
      "Epoch 8706 - Train Loss: 0.130678, Train Acc: 0.774359 | Val Loss: 0.145765, Val Acc: 0.690722\n",
      "Epoch 8707 - Train Loss: 0.130669, Train Acc: 0.774359 | Val Loss: 0.145757, Val Acc: 0.690722\n",
      "Epoch 8708 - Train Loss: 0.130660, Train Acc: 0.774359 | Val Loss: 0.145749, Val Acc: 0.690722\n",
      "Epoch 8709 - Train Loss: 0.130650, Train Acc: 0.774359 | Val Loss: 0.145741, Val Acc: 0.690722\n",
      "Epoch 8710 - Train Loss: 0.130641, Train Acc: 0.774359 | Val Loss: 0.145733, Val Acc: 0.690722\n",
      "Epoch 8711 - Train Loss: 0.130632, Train Acc: 0.774359 | Val Loss: 0.145725, Val Acc: 0.690722\n",
      "Epoch 8712 - Train Loss: 0.130623, Train Acc: 0.774359 | Val Loss: 0.145717, Val Acc: 0.690722\n",
      "Epoch 8713 - Train Loss: 0.130614, Train Acc: 0.774359 | Val Loss: 0.145709, Val Acc: 0.690722\n",
      "Epoch 8714 - Train Loss: 0.130605, Train Acc: 0.774359 | Val Loss: 0.145701, Val Acc: 0.690722\n",
      "Epoch 8715 - Train Loss: 0.130595, Train Acc: 0.774359 | Val Loss: 0.145693, Val Acc: 0.690722\n",
      "Epoch 8716 - Train Loss: 0.130586, Train Acc: 0.774359 | Val Loss: 0.145685, Val Acc: 0.690722\n",
      "Epoch 8717 - Train Loss: 0.130577, Train Acc: 0.774359 | Val Loss: 0.145677, Val Acc: 0.690722\n",
      "Epoch 8718 - Train Loss: 0.130568, Train Acc: 0.774359 | Val Loss: 0.145669, Val Acc: 0.690722\n",
      "Epoch 8719 - Train Loss: 0.130559, Train Acc: 0.774359 | Val Loss: 0.145661, Val Acc: 0.690722\n",
      "Epoch 8720 - Train Loss: 0.130550, Train Acc: 0.774359 | Val Loss: 0.145653, Val Acc: 0.690722\n",
      "Epoch 8721 - Train Loss: 0.130541, Train Acc: 0.774359 | Val Loss: 0.145645, Val Acc: 0.690722\n",
      "Epoch 8722 - Train Loss: 0.130531, Train Acc: 0.774359 | Val Loss: 0.145637, Val Acc: 0.690722\n",
      "Epoch 8723 - Train Loss: 0.130522, Train Acc: 0.774359 | Val Loss: 0.145629, Val Acc: 0.690722\n",
      "Epoch 8724 - Train Loss: 0.130513, Train Acc: 0.774359 | Val Loss: 0.145621, Val Acc: 0.690722\n",
      "Epoch 8725 - Train Loss: 0.130504, Train Acc: 0.774359 | Val Loss: 0.145613, Val Acc: 0.690722\n",
      "Epoch 8726 - Train Loss: 0.130495, Train Acc: 0.774359 | Val Loss: 0.145605, Val Acc: 0.690722\n",
      "Epoch 8727 - Train Loss: 0.130486, Train Acc: 0.774359 | Val Loss: 0.145597, Val Acc: 0.690722\n",
      "Epoch 8728 - Train Loss: 0.130477, Train Acc: 0.774359 | Val Loss: 0.145589, Val Acc: 0.690722\n",
      "Epoch 8729 - Train Loss: 0.130468, Train Acc: 0.774359 | Val Loss: 0.145581, Val Acc: 0.690722\n",
      "Epoch 8730 - Train Loss: 0.130458, Train Acc: 0.774359 | Val Loss: 0.145573, Val Acc: 0.690722\n",
      "Epoch 8731 - Train Loss: 0.130449, Train Acc: 0.774359 | Val Loss: 0.145565, Val Acc: 0.690722\n",
      "Epoch 8732 - Train Loss: 0.130440, Train Acc: 0.774359 | Val Loss: 0.145557, Val Acc: 0.690722\n",
      "Epoch 8733 - Train Loss: 0.130431, Train Acc: 0.774359 | Val Loss: 0.145549, Val Acc: 0.690722\n",
      "Epoch 8734 - Train Loss: 0.130422, Train Acc: 0.774359 | Val Loss: 0.145541, Val Acc: 0.690722\n",
      "Epoch 8735 - Train Loss: 0.130413, Train Acc: 0.774359 | Val Loss: 0.145533, Val Acc: 0.690722\n",
      "Epoch 8736 - Train Loss: 0.130404, Train Acc: 0.774359 | Val Loss: 0.145525, Val Acc: 0.690722\n",
      "Epoch 8737 - Train Loss: 0.130395, Train Acc: 0.774359 | Val Loss: 0.145517, Val Acc: 0.690722\n",
      "Epoch 8738 - Train Loss: 0.130386, Train Acc: 0.774359 | Val Loss: 0.145509, Val Acc: 0.690722\n",
      "Epoch 8739 - Train Loss: 0.130376, Train Acc: 0.774359 | Val Loss: 0.145501, Val Acc: 0.690722\n",
      "Epoch 8740 - Train Loss: 0.130367, Train Acc: 0.774359 | Val Loss: 0.145493, Val Acc: 0.690722\n",
      "Epoch 8741 - Train Loss: 0.130358, Train Acc: 0.774359 | Val Loss: 0.145485, Val Acc: 0.690722\n",
      "Epoch 8742 - Train Loss: 0.130349, Train Acc: 0.774359 | Val Loss: 0.145477, Val Acc: 0.690722\n",
      "Epoch 8743 - Train Loss: 0.130340, Train Acc: 0.774359 | Val Loss: 0.145469, Val Acc: 0.690722\n",
      "Epoch 8744 - Train Loss: 0.130331, Train Acc: 0.774359 | Val Loss: 0.145461, Val Acc: 0.690722\n",
      "Epoch 8745 - Train Loss: 0.130322, Train Acc: 0.774359 | Val Loss: 0.145453, Val Acc: 0.690722\n",
      "Epoch 8746 - Train Loss: 0.130313, Train Acc: 0.774359 | Val Loss: 0.145445, Val Acc: 0.690722\n",
      "Epoch 8747 - Train Loss: 0.130304, Train Acc: 0.774359 | Val Loss: 0.145437, Val Acc: 0.690722\n",
      "Epoch 8748 - Train Loss: 0.130295, Train Acc: 0.774359 | Val Loss: 0.145429, Val Acc: 0.690722\n",
      "Epoch 8749 - Train Loss: 0.130286, Train Acc: 0.774359 | Val Loss: 0.145421, Val Acc: 0.690722\n",
      "Epoch 8750 - Train Loss: 0.130276, Train Acc: 0.774359 | Val Loss: 0.145414, Val Acc: 0.690722\n",
      "Epoch 8751 - Train Loss: 0.130267, Train Acc: 0.774359 | Val Loss: 0.145406, Val Acc: 0.690722\n",
      "Epoch 8752 - Train Loss: 0.130258, Train Acc: 0.774359 | Val Loss: 0.145398, Val Acc: 0.690722\n",
      "Epoch 8753 - Train Loss: 0.130249, Train Acc: 0.774359 | Val Loss: 0.145390, Val Acc: 0.690722\n",
      "Epoch 8754 - Train Loss: 0.130240, Train Acc: 0.774359 | Val Loss: 0.145382, Val Acc: 0.690722\n",
      "Epoch 8755 - Train Loss: 0.130231, Train Acc: 0.774359 | Val Loss: 0.145374, Val Acc: 0.690722\n",
      "Epoch 8756 - Train Loss: 0.130222, Train Acc: 0.774359 | Val Loss: 0.145366, Val Acc: 0.690722\n",
      "Epoch 8757 - Train Loss: 0.130213, Train Acc: 0.774359 | Val Loss: 0.145358, Val Acc: 0.690722\n",
      "Epoch 8758 - Train Loss: 0.130204, Train Acc: 0.774359 | Val Loss: 0.145350, Val Acc: 0.690722\n",
      "Epoch 8759 - Train Loss: 0.130195, Train Acc: 0.774359 | Val Loss: 0.145342, Val Acc: 0.690722\n",
      "Epoch 8760 - Train Loss: 0.130186, Train Acc: 0.774359 | Val Loss: 0.145334, Val Acc: 0.690722\n",
      "Epoch 8761 - Train Loss: 0.130177, Train Acc: 0.774359 | Val Loss: 0.145326, Val Acc: 0.690722\n",
      "Epoch 8762 - Train Loss: 0.130168, Train Acc: 0.774359 | Val Loss: 0.145318, Val Acc: 0.690722\n",
      "Epoch 8763 - Train Loss: 0.130159, Train Acc: 0.774359 | Val Loss: 0.145310, Val Acc: 0.690722\n",
      "Epoch 8764 - Train Loss: 0.130149, Train Acc: 0.774359 | Val Loss: 0.145302, Val Acc: 0.690722\n",
      "Epoch 8765 - Train Loss: 0.130140, Train Acc: 0.774359 | Val Loss: 0.145294, Val Acc: 0.690722\n",
      "Epoch 8766 - Train Loss: 0.130131, Train Acc: 0.774359 | Val Loss: 0.145286, Val Acc: 0.690722\n",
      "Epoch 8767 - Train Loss: 0.130122, Train Acc: 0.774359 | Val Loss: 0.145278, Val Acc: 0.690722\n",
      "Epoch 8768 - Train Loss: 0.130113, Train Acc: 0.774359 | Val Loss: 0.145270, Val Acc: 0.690722\n",
      "Epoch 8769 - Train Loss: 0.130104, Train Acc: 0.774359 | Val Loss: 0.145262, Val Acc: 0.690722\n",
      "Epoch 8770 - Train Loss: 0.130095, Train Acc: 0.774359 | Val Loss: 0.145254, Val Acc: 0.690722\n",
      "Epoch 8771 - Train Loss: 0.130086, Train Acc: 0.774359 | Val Loss: 0.145247, Val Acc: 0.690722\n",
      "Epoch 8772 - Train Loss: 0.130077, Train Acc: 0.774359 | Val Loss: 0.145239, Val Acc: 0.690722\n",
      "Epoch 8773 - Train Loss: 0.130068, Train Acc: 0.775641 | Val Loss: 0.145231, Val Acc: 0.690722\n",
      "Epoch 8774 - Train Loss: 0.130059, Train Acc: 0.775641 | Val Loss: 0.145223, Val Acc: 0.690722\n",
      "Epoch 8775 - Train Loss: 0.130050, Train Acc: 0.775641 | Val Loss: 0.145215, Val Acc: 0.690722\n",
      "Epoch 8776 - Train Loss: 0.130041, Train Acc: 0.775641 | Val Loss: 0.145207, Val Acc: 0.690722\n",
      "Epoch 8777 - Train Loss: 0.130032, Train Acc: 0.775641 | Val Loss: 0.145199, Val Acc: 0.690722\n",
      "Epoch 8778 - Train Loss: 0.130023, Train Acc: 0.775641 | Val Loss: 0.145191, Val Acc: 0.690722\n",
      "Epoch 8779 - Train Loss: 0.130014, Train Acc: 0.775641 | Val Loss: 0.145183, Val Acc: 0.690722\n",
      "Epoch 8780 - Train Loss: 0.130005, Train Acc: 0.775641 | Val Loss: 0.145175, Val Acc: 0.690722\n",
      "Epoch 8781 - Train Loss: 0.129995, Train Acc: 0.775641 | Val Loss: 0.145167, Val Acc: 0.690722\n",
      "Epoch 8782 - Train Loss: 0.129986, Train Acc: 0.775641 | Val Loss: 0.145159, Val Acc: 0.690722\n",
      "Epoch 8783 - Train Loss: 0.129977, Train Acc: 0.775641 | Val Loss: 0.145151, Val Acc: 0.690722\n",
      "Epoch 8784 - Train Loss: 0.129968, Train Acc: 0.775641 | Val Loss: 0.145143, Val Acc: 0.690722\n",
      "Epoch 8785 - Train Loss: 0.129959, Train Acc: 0.775641 | Val Loss: 0.145136, Val Acc: 0.690722\n",
      "Epoch 8786 - Train Loss: 0.129950, Train Acc: 0.775641 | Val Loss: 0.145128, Val Acc: 0.690722\n",
      "Epoch 8787 - Train Loss: 0.129941, Train Acc: 0.775641 | Val Loss: 0.145120, Val Acc: 0.690722\n",
      "Epoch 8788 - Train Loss: 0.129932, Train Acc: 0.775641 | Val Loss: 0.145112, Val Acc: 0.690722\n",
      "Epoch 8789 - Train Loss: 0.129923, Train Acc: 0.775641 | Val Loss: 0.145104, Val Acc: 0.690722\n",
      "Epoch 8790 - Train Loss: 0.129914, Train Acc: 0.775641 | Val Loss: 0.145096, Val Acc: 0.690722\n",
      "Epoch 8791 - Train Loss: 0.129905, Train Acc: 0.775641 | Val Loss: 0.145088, Val Acc: 0.690722\n",
      "Epoch 8792 - Train Loss: 0.129896, Train Acc: 0.775641 | Val Loss: 0.145080, Val Acc: 0.690722\n",
      "Epoch 8793 - Train Loss: 0.129887, Train Acc: 0.775641 | Val Loss: 0.145072, Val Acc: 0.690722\n",
      "Epoch 8794 - Train Loss: 0.129878, Train Acc: 0.775641 | Val Loss: 0.145064, Val Acc: 0.690722\n",
      "Epoch 8795 - Train Loss: 0.129869, Train Acc: 0.775641 | Val Loss: 0.145057, Val Acc: 0.690722\n",
      "Epoch 8796 - Train Loss: 0.129860, Train Acc: 0.775641 | Val Loss: 0.145049, Val Acc: 0.690722\n",
      "Epoch 8797 - Train Loss: 0.129851, Train Acc: 0.775641 | Val Loss: 0.145041, Val Acc: 0.690722\n",
      "Epoch 8798 - Train Loss: 0.129842, Train Acc: 0.775641 | Val Loss: 0.145033, Val Acc: 0.690722\n",
      "Epoch 8799 - Train Loss: 0.129833, Train Acc: 0.775641 | Val Loss: 0.145025, Val Acc: 0.690722\n",
      "Epoch 8800 - Train Loss: 0.129824, Train Acc: 0.775641 | Val Loss: 0.145017, Val Acc: 0.690722\n",
      "Epoch 8801 - Train Loss: 0.129815, Train Acc: 0.775641 | Val Loss: 0.145009, Val Acc: 0.690722\n",
      "Epoch 8802 - Train Loss: 0.129806, Train Acc: 0.775641 | Val Loss: 0.145001, Val Acc: 0.690722\n",
      "Epoch 8803 - Train Loss: 0.129797, Train Acc: 0.775641 | Val Loss: 0.144993, Val Acc: 0.690722\n",
      "Epoch 8804 - Train Loss: 0.129788, Train Acc: 0.775641 | Val Loss: 0.144985, Val Acc: 0.690722\n",
      "Epoch 8805 - Train Loss: 0.129779, Train Acc: 0.775641 | Val Loss: 0.144978, Val Acc: 0.690722\n",
      "Epoch 8806 - Train Loss: 0.129770, Train Acc: 0.775641 | Val Loss: 0.144970, Val Acc: 0.690722\n",
      "Epoch 8807 - Train Loss: 0.129761, Train Acc: 0.775641 | Val Loss: 0.144962, Val Acc: 0.690722\n",
      "Epoch 8808 - Train Loss: 0.129752, Train Acc: 0.775641 | Val Loss: 0.144954, Val Acc: 0.690722\n",
      "Epoch 8809 - Train Loss: 0.129743, Train Acc: 0.775641 | Val Loss: 0.144946, Val Acc: 0.690722\n",
      "Epoch 8810 - Train Loss: 0.129734, Train Acc: 0.775641 | Val Loss: 0.144938, Val Acc: 0.690722\n",
      "Epoch 8811 - Train Loss: 0.129725, Train Acc: 0.775641 | Val Loss: 0.144930, Val Acc: 0.690722\n",
      "Epoch 8812 - Train Loss: 0.129716, Train Acc: 0.775641 | Val Loss: 0.144922, Val Acc: 0.690722\n",
      "Epoch 8813 - Train Loss: 0.129707, Train Acc: 0.775641 | Val Loss: 0.144915, Val Acc: 0.690722\n",
      "Epoch 8814 - Train Loss: 0.129698, Train Acc: 0.775641 | Val Loss: 0.144907, Val Acc: 0.690722\n",
      "Epoch 8815 - Train Loss: 0.129689, Train Acc: 0.775641 | Val Loss: 0.144899, Val Acc: 0.690722\n",
      "Epoch 8816 - Train Loss: 0.129680, Train Acc: 0.775641 | Val Loss: 0.144891, Val Acc: 0.690722\n",
      "Epoch 8817 - Train Loss: 0.129671, Train Acc: 0.775641 | Val Loss: 0.144883, Val Acc: 0.690722\n",
      "Epoch 8818 - Train Loss: 0.129662, Train Acc: 0.775641 | Val Loss: 0.144875, Val Acc: 0.690722\n",
      "Epoch 8819 - Train Loss: 0.129653, Train Acc: 0.775641 | Val Loss: 0.144867, Val Acc: 0.690722\n",
      "Epoch 8820 - Train Loss: 0.129644, Train Acc: 0.775641 | Val Loss: 0.144859, Val Acc: 0.690722\n",
      "Epoch 8821 - Train Loss: 0.129635, Train Acc: 0.775641 | Val Loss: 0.144852, Val Acc: 0.690722\n",
      "Epoch 8822 - Train Loss: 0.129626, Train Acc: 0.775641 | Val Loss: 0.144844, Val Acc: 0.690722\n",
      "Epoch 8823 - Train Loss: 0.129617, Train Acc: 0.775641 | Val Loss: 0.144836, Val Acc: 0.690722\n",
      "Epoch 8824 - Train Loss: 0.129608, Train Acc: 0.775641 | Val Loss: 0.144828, Val Acc: 0.690722\n",
      "Epoch 8825 - Train Loss: 0.129599, Train Acc: 0.775641 | Val Loss: 0.144820, Val Acc: 0.690722\n",
      "Epoch 8826 - Train Loss: 0.129590, Train Acc: 0.775641 | Val Loss: 0.144812, Val Acc: 0.690722\n",
      "Epoch 8827 - Train Loss: 0.129581, Train Acc: 0.775641 | Val Loss: 0.144804, Val Acc: 0.690722\n",
      "Epoch 8828 - Train Loss: 0.129572, Train Acc: 0.775641 | Val Loss: 0.144796, Val Acc: 0.690722\n",
      "Epoch 8829 - Train Loss: 0.129563, Train Acc: 0.775641 | Val Loss: 0.144788, Val Acc: 0.690722\n",
      "Epoch 8830 - Train Loss: 0.129554, Train Acc: 0.775641 | Val Loss: 0.144781, Val Acc: 0.690722\n",
      "Epoch 8831 - Train Loss: 0.129545, Train Acc: 0.775641 | Val Loss: 0.144773, Val Acc: 0.690722\n",
      "Epoch 8832 - Train Loss: 0.129536, Train Acc: 0.775641 | Val Loss: 0.144765, Val Acc: 0.690722\n",
      "Epoch 8833 - Train Loss: 0.129527, Train Acc: 0.775641 | Val Loss: 0.144757, Val Acc: 0.690722\n",
      "Epoch 8834 - Train Loss: 0.129518, Train Acc: 0.775641 | Val Loss: 0.144749, Val Acc: 0.690722\n",
      "Epoch 8835 - Train Loss: 0.129509, Train Acc: 0.775641 | Val Loss: 0.144741, Val Acc: 0.690722\n",
      "Epoch 8836 - Train Loss: 0.129501, Train Acc: 0.775641 | Val Loss: 0.144733, Val Acc: 0.690722\n",
      "Epoch 8837 - Train Loss: 0.129492, Train Acc: 0.775641 | Val Loss: 0.144725, Val Acc: 0.690722\n",
      "Epoch 8838 - Train Loss: 0.129483, Train Acc: 0.775641 | Val Loss: 0.144718, Val Acc: 0.690722\n",
      "Epoch 8839 - Train Loss: 0.129474, Train Acc: 0.775641 | Val Loss: 0.144710, Val Acc: 0.690722\n",
      "Epoch 8840 - Train Loss: 0.129465, Train Acc: 0.775641 | Val Loss: 0.144702, Val Acc: 0.690722\n",
      "Epoch 8841 - Train Loss: 0.129456, Train Acc: 0.775641 | Val Loss: 0.144694, Val Acc: 0.690722\n",
      "Epoch 8842 - Train Loss: 0.129447, Train Acc: 0.775641 | Val Loss: 0.144686, Val Acc: 0.690722\n",
      "Epoch 8843 - Train Loss: 0.129438, Train Acc: 0.775641 | Val Loss: 0.144678, Val Acc: 0.690722\n",
      "Epoch 8844 - Train Loss: 0.129429, Train Acc: 0.775641 | Val Loss: 0.144670, Val Acc: 0.690722\n",
      "Epoch 8845 - Train Loss: 0.129420, Train Acc: 0.775641 | Val Loss: 0.144662, Val Acc: 0.690722\n",
      "Epoch 8846 - Train Loss: 0.129411, Train Acc: 0.775641 | Val Loss: 0.144655, Val Acc: 0.690722\n",
      "Epoch 8847 - Train Loss: 0.129402, Train Acc: 0.775641 | Val Loss: 0.144647, Val Acc: 0.690722\n",
      "Epoch 8848 - Train Loss: 0.129393, Train Acc: 0.775641 | Val Loss: 0.144639, Val Acc: 0.690722\n",
      "Epoch 8849 - Train Loss: 0.129384, Train Acc: 0.775641 | Val Loss: 0.144631, Val Acc: 0.690722\n",
      "Epoch 8850 - Train Loss: 0.129375, Train Acc: 0.775641 | Val Loss: 0.144623, Val Acc: 0.690722\n",
      "Epoch 8851 - Train Loss: 0.129366, Train Acc: 0.775641 | Val Loss: 0.144615, Val Acc: 0.690722\n",
      "Epoch 8852 - Train Loss: 0.129357, Train Acc: 0.775641 | Val Loss: 0.144607, Val Acc: 0.690722\n",
      "Epoch 8853 - Train Loss: 0.129348, Train Acc: 0.775641 | Val Loss: 0.144599, Val Acc: 0.690722\n",
      "Epoch 8854 - Train Loss: 0.129339, Train Acc: 0.775641 | Val Loss: 0.144592, Val Acc: 0.690722\n",
      "Epoch 8855 - Train Loss: 0.129330, Train Acc: 0.775641 | Val Loss: 0.144584, Val Acc: 0.690722\n",
      "Epoch 8856 - Train Loss: 0.129321, Train Acc: 0.775641 | Val Loss: 0.144576, Val Acc: 0.690722\n",
      "Epoch 8857 - Train Loss: 0.129312, Train Acc: 0.775641 | Val Loss: 0.144568, Val Acc: 0.690722\n",
      "Epoch 8858 - Train Loss: 0.129303, Train Acc: 0.775641 | Val Loss: 0.144560, Val Acc: 0.690722\n",
      "Epoch 8859 - Train Loss: 0.129294, Train Acc: 0.775641 | Val Loss: 0.144552, Val Acc: 0.690722\n",
      "Epoch 8860 - Train Loss: 0.129286, Train Acc: 0.775641 | Val Loss: 0.144544, Val Acc: 0.690722\n",
      "Epoch 8861 - Train Loss: 0.129277, Train Acc: 0.775641 | Val Loss: 0.144537, Val Acc: 0.690722\n",
      "Epoch 8862 - Train Loss: 0.129268, Train Acc: 0.775641 | Val Loss: 0.144529, Val Acc: 0.690722\n",
      "Epoch 8863 - Train Loss: 0.129259, Train Acc: 0.775641 | Val Loss: 0.144521, Val Acc: 0.690722\n",
      "Epoch 8864 - Train Loss: 0.129250, Train Acc: 0.775641 | Val Loss: 0.144513, Val Acc: 0.690722\n",
      "Epoch 8865 - Train Loss: 0.129241, Train Acc: 0.775641 | Val Loss: 0.144505, Val Acc: 0.690722\n",
      "Epoch 8866 - Train Loss: 0.129232, Train Acc: 0.775641 | Val Loss: 0.144498, Val Acc: 0.690722\n",
      "Epoch 8867 - Train Loss: 0.129223, Train Acc: 0.775641 | Val Loss: 0.144490, Val Acc: 0.690722\n",
      "Epoch 8868 - Train Loss: 0.129214, Train Acc: 0.775641 | Val Loss: 0.144482, Val Acc: 0.690722\n",
      "Epoch 8869 - Train Loss: 0.129205, Train Acc: 0.775641 | Val Loss: 0.144474, Val Acc: 0.690722\n",
      "Epoch 8870 - Train Loss: 0.129196, Train Acc: 0.775641 | Val Loss: 0.144466, Val Acc: 0.690722\n",
      "Epoch 8871 - Train Loss: 0.129187, Train Acc: 0.775641 | Val Loss: 0.144459, Val Acc: 0.690722\n",
      "Epoch 8872 - Train Loss: 0.129178, Train Acc: 0.775641 | Val Loss: 0.144451, Val Acc: 0.690722\n",
      "Epoch 8873 - Train Loss: 0.129169, Train Acc: 0.776923 | Val Loss: 0.144443, Val Acc: 0.690722\n",
      "Epoch 8874 - Train Loss: 0.129160, Train Acc: 0.776923 | Val Loss: 0.144435, Val Acc: 0.690722\n",
      "Epoch 8875 - Train Loss: 0.129151, Train Acc: 0.776923 | Val Loss: 0.144427, Val Acc: 0.690722\n",
      "Epoch 8876 - Train Loss: 0.129143, Train Acc: 0.776923 | Val Loss: 0.144420, Val Acc: 0.690722\n",
      "Epoch 8877 - Train Loss: 0.129134, Train Acc: 0.776923 | Val Loss: 0.144412, Val Acc: 0.690722\n",
      "Epoch 8878 - Train Loss: 0.129125, Train Acc: 0.776923 | Val Loss: 0.144404, Val Acc: 0.690722\n",
      "Epoch 8879 - Train Loss: 0.129116, Train Acc: 0.776923 | Val Loss: 0.144396, Val Acc: 0.690722\n",
      "Epoch 8880 - Train Loss: 0.129107, Train Acc: 0.776923 | Val Loss: 0.144388, Val Acc: 0.690722\n",
      "Epoch 8881 - Train Loss: 0.129098, Train Acc: 0.776923 | Val Loss: 0.144381, Val Acc: 0.690722\n",
      "Epoch 8882 - Train Loss: 0.129089, Train Acc: 0.776923 | Val Loss: 0.144373, Val Acc: 0.690722\n",
      "Epoch 8883 - Train Loss: 0.129080, Train Acc: 0.776923 | Val Loss: 0.144365, Val Acc: 0.690722\n",
      "Epoch 8884 - Train Loss: 0.129071, Train Acc: 0.776923 | Val Loss: 0.144357, Val Acc: 0.690722\n",
      "Epoch 8885 - Train Loss: 0.129062, Train Acc: 0.776923 | Val Loss: 0.144350, Val Acc: 0.690722\n",
      "Epoch 8886 - Train Loss: 0.129053, Train Acc: 0.776923 | Val Loss: 0.144342, Val Acc: 0.690722\n",
      "Epoch 8887 - Train Loss: 0.129045, Train Acc: 0.776923 | Val Loss: 0.144334, Val Acc: 0.690722\n",
      "Epoch 8888 - Train Loss: 0.129036, Train Acc: 0.776923 | Val Loss: 0.144326, Val Acc: 0.690722\n",
      "Epoch 8889 - Train Loss: 0.129027, Train Acc: 0.776923 | Val Loss: 0.144318, Val Acc: 0.690722\n",
      "Epoch 8890 - Train Loss: 0.129018, Train Acc: 0.776923 | Val Loss: 0.144311, Val Acc: 0.690722\n",
      "Epoch 8891 - Train Loss: 0.129009, Train Acc: 0.778205 | Val Loss: 0.144303, Val Acc: 0.690722\n",
      "Epoch 8892 - Train Loss: 0.129000, Train Acc: 0.778205 | Val Loss: 0.144295, Val Acc: 0.690722\n",
      "Epoch 8893 - Train Loss: 0.128991, Train Acc: 0.778205 | Val Loss: 0.144287, Val Acc: 0.690722\n",
      "Epoch 8894 - Train Loss: 0.128982, Train Acc: 0.778205 | Val Loss: 0.144280, Val Acc: 0.690722\n",
      "Epoch 8895 - Train Loss: 0.128973, Train Acc: 0.778205 | Val Loss: 0.144272, Val Acc: 0.690722\n",
      "Epoch 8896 - Train Loss: 0.128964, Train Acc: 0.778205 | Val Loss: 0.144264, Val Acc: 0.690722\n",
      "Epoch 8897 - Train Loss: 0.128956, Train Acc: 0.778205 | Val Loss: 0.144256, Val Acc: 0.690722\n",
      "Epoch 8898 - Train Loss: 0.128947, Train Acc: 0.778205 | Val Loss: 0.144248, Val Acc: 0.690722\n",
      "Epoch 8899 - Train Loss: 0.128938, Train Acc: 0.778205 | Val Loss: 0.144241, Val Acc: 0.690722\n",
      "Epoch 8900 - Train Loss: 0.128929, Train Acc: 0.778205 | Val Loss: 0.144233, Val Acc: 0.690722\n",
      "Epoch 8901 - Train Loss: 0.128920, Train Acc: 0.778205 | Val Loss: 0.144225, Val Acc: 0.690722\n",
      "Epoch 8902 - Train Loss: 0.128911, Train Acc: 0.778205 | Val Loss: 0.144217, Val Acc: 0.690722\n",
      "Epoch 8903 - Train Loss: 0.128902, Train Acc: 0.778205 | Val Loss: 0.144210, Val Acc: 0.690722\n",
      "Epoch 8904 - Train Loss: 0.128893, Train Acc: 0.778205 | Val Loss: 0.144202, Val Acc: 0.690722\n",
      "Epoch 8905 - Train Loss: 0.128885, Train Acc: 0.778205 | Val Loss: 0.144194, Val Acc: 0.690722\n",
      "Epoch 8906 - Train Loss: 0.128876, Train Acc: 0.778205 | Val Loss: 0.144186, Val Acc: 0.690722\n",
      "Epoch 8907 - Train Loss: 0.128867, Train Acc: 0.778205 | Val Loss: 0.144179, Val Acc: 0.690722\n",
      "Epoch 8908 - Train Loss: 0.128858, Train Acc: 0.778205 | Val Loss: 0.144171, Val Acc: 0.690722\n",
      "Epoch 8909 - Train Loss: 0.128849, Train Acc: 0.778205 | Val Loss: 0.144163, Val Acc: 0.690722\n",
      "Epoch 8910 - Train Loss: 0.128840, Train Acc: 0.778205 | Val Loss: 0.144155, Val Acc: 0.690722\n",
      "Epoch 8911 - Train Loss: 0.128831, Train Acc: 0.778205 | Val Loss: 0.144148, Val Acc: 0.690722\n",
      "Epoch 8912 - Train Loss: 0.128822, Train Acc: 0.778205 | Val Loss: 0.144140, Val Acc: 0.690722\n",
      "Epoch 8913 - Train Loss: 0.128814, Train Acc: 0.778205 | Val Loss: 0.144132, Val Acc: 0.690722\n",
      "Epoch 8914 - Train Loss: 0.128805, Train Acc: 0.778205 | Val Loss: 0.144124, Val Acc: 0.690722\n",
      "Epoch 8915 - Train Loss: 0.128796, Train Acc: 0.778205 | Val Loss: 0.144117, Val Acc: 0.690722\n",
      "Epoch 8916 - Train Loss: 0.128787, Train Acc: 0.778205 | Val Loss: 0.144109, Val Acc: 0.690722\n",
      "Epoch 8917 - Train Loss: 0.128778, Train Acc: 0.778205 | Val Loss: 0.144101, Val Acc: 0.690722\n",
      "Epoch 8918 - Train Loss: 0.128769, Train Acc: 0.778205 | Val Loss: 0.144093, Val Acc: 0.690722\n",
      "Epoch 8919 - Train Loss: 0.128760, Train Acc: 0.778205 | Val Loss: 0.144086, Val Acc: 0.690722\n",
      "Epoch 8920 - Train Loss: 0.128752, Train Acc: 0.778205 | Val Loss: 0.144078, Val Acc: 0.690722\n",
      "Epoch 8921 - Train Loss: 0.128743, Train Acc: 0.778205 | Val Loss: 0.144070, Val Acc: 0.690722\n",
      "Epoch 8922 - Train Loss: 0.128734, Train Acc: 0.778205 | Val Loss: 0.144062, Val Acc: 0.690722\n",
      "Epoch 8923 - Train Loss: 0.128725, Train Acc: 0.778205 | Val Loss: 0.144054, Val Acc: 0.690722\n",
      "Epoch 8924 - Train Loss: 0.128716, Train Acc: 0.778205 | Val Loss: 0.144047, Val Acc: 0.690722\n",
      "Epoch 8925 - Train Loss: 0.128707, Train Acc: 0.778205 | Val Loss: 0.144039, Val Acc: 0.690722\n",
      "Epoch 8926 - Train Loss: 0.128698, Train Acc: 0.778205 | Val Loss: 0.144031, Val Acc: 0.690722\n",
      "Epoch 8927 - Train Loss: 0.128690, Train Acc: 0.778205 | Val Loss: 0.144023, Val Acc: 0.690722\n",
      "Epoch 8928 - Train Loss: 0.128681, Train Acc: 0.778205 | Val Loss: 0.144015, Val Acc: 0.690722\n",
      "Epoch 8929 - Train Loss: 0.128672, Train Acc: 0.778205 | Val Loss: 0.144008, Val Acc: 0.690722\n",
      "Epoch 8930 - Train Loss: 0.128663, Train Acc: 0.778205 | Val Loss: 0.144000, Val Acc: 0.690722\n",
      "Epoch 8931 - Train Loss: 0.128654, Train Acc: 0.778205 | Val Loss: 0.143992, Val Acc: 0.690722\n",
      "Epoch 8932 - Train Loss: 0.128645, Train Acc: 0.778205 | Val Loss: 0.143984, Val Acc: 0.690722\n",
      "Epoch 8933 - Train Loss: 0.128637, Train Acc: 0.778205 | Val Loss: 0.143977, Val Acc: 0.690722\n",
      "Epoch 8934 - Train Loss: 0.128628, Train Acc: 0.778205 | Val Loss: 0.143969, Val Acc: 0.690722\n",
      "Epoch 8935 - Train Loss: 0.128619, Train Acc: 0.778205 | Val Loss: 0.143961, Val Acc: 0.690722\n",
      "Epoch 8936 - Train Loss: 0.128610, Train Acc: 0.778205 | Val Loss: 0.143953, Val Acc: 0.690722\n",
      "Epoch 8937 - Train Loss: 0.128601, Train Acc: 0.778205 | Val Loss: 0.143945, Val Acc: 0.690722\n",
      "Epoch 8938 - Train Loss: 0.128592, Train Acc: 0.778205 | Val Loss: 0.143938, Val Acc: 0.690722\n",
      "Epoch 8939 - Train Loss: 0.128584, Train Acc: 0.778205 | Val Loss: 0.143930, Val Acc: 0.690722\n",
      "Epoch 8940 - Train Loss: 0.128575, Train Acc: 0.778205 | Val Loss: 0.143922, Val Acc: 0.690722\n",
      "Epoch 8941 - Train Loss: 0.128566, Train Acc: 0.778205 | Val Loss: 0.143914, Val Acc: 0.690722\n",
      "Epoch 8942 - Train Loss: 0.128557, Train Acc: 0.778205 | Val Loss: 0.143907, Val Acc: 0.690722\n",
      "Epoch 8943 - Train Loss: 0.128548, Train Acc: 0.778205 | Val Loss: 0.143899, Val Acc: 0.690722\n",
      "Epoch 8944 - Train Loss: 0.128540, Train Acc: 0.778205 | Val Loss: 0.143891, Val Acc: 0.690722\n",
      "Epoch 8945 - Train Loss: 0.128531, Train Acc: 0.778205 | Val Loss: 0.143884, Val Acc: 0.690722\n",
      "Epoch 8946 - Train Loss: 0.128522, Train Acc: 0.778205 | Val Loss: 0.143876, Val Acc: 0.690722\n",
      "Epoch 8947 - Train Loss: 0.128513, Train Acc: 0.778205 | Val Loss: 0.143868, Val Acc: 0.690722\n",
      "Epoch 8948 - Train Loss: 0.128504, Train Acc: 0.778205 | Val Loss: 0.143860, Val Acc: 0.690722\n",
      "Epoch 8949 - Train Loss: 0.128496, Train Acc: 0.778205 | Val Loss: 0.143853, Val Acc: 0.690722\n",
      "Epoch 8950 - Train Loss: 0.128487, Train Acc: 0.778205 | Val Loss: 0.143845, Val Acc: 0.690722\n",
      "Epoch 8951 - Train Loss: 0.128478, Train Acc: 0.778205 | Val Loss: 0.143837, Val Acc: 0.690722\n",
      "Epoch 8952 - Train Loss: 0.128469, Train Acc: 0.778205 | Val Loss: 0.143829, Val Acc: 0.690722\n",
      "Epoch 8953 - Train Loss: 0.128460, Train Acc: 0.778205 | Val Loss: 0.143822, Val Acc: 0.690722\n",
      "Epoch 8954 - Train Loss: 0.128452, Train Acc: 0.778205 | Val Loss: 0.143814, Val Acc: 0.690722\n",
      "Epoch 8955 - Train Loss: 0.128443, Train Acc: 0.778205 | Val Loss: 0.143806, Val Acc: 0.690722\n",
      "Epoch 8956 - Train Loss: 0.128434, Train Acc: 0.778205 | Val Loss: 0.143798, Val Acc: 0.690722\n",
      "Epoch 8957 - Train Loss: 0.128425, Train Acc: 0.778205 | Val Loss: 0.143791, Val Acc: 0.690722\n",
      "Epoch 8958 - Train Loss: 0.128416, Train Acc: 0.778205 | Val Loss: 0.143783, Val Acc: 0.690722\n",
      "Epoch 8959 - Train Loss: 0.128408, Train Acc: 0.778205 | Val Loss: 0.143775, Val Acc: 0.690722\n",
      "Epoch 8960 - Train Loss: 0.128399, Train Acc: 0.778205 | Val Loss: 0.143768, Val Acc: 0.690722\n",
      "Epoch 8961 - Train Loss: 0.128390, Train Acc: 0.778205 | Val Loss: 0.143760, Val Acc: 0.690722\n",
      "Epoch 8962 - Train Loss: 0.128381, Train Acc: 0.778205 | Val Loss: 0.143752, Val Acc: 0.690722\n",
      "Epoch 8963 - Train Loss: 0.128372, Train Acc: 0.778205 | Val Loss: 0.143744, Val Acc: 0.690722\n",
      "Epoch 8964 - Train Loss: 0.128364, Train Acc: 0.778205 | Val Loss: 0.143737, Val Acc: 0.690722\n",
      "Epoch 8965 - Train Loss: 0.128355, Train Acc: 0.778205 | Val Loss: 0.143729, Val Acc: 0.690722\n",
      "Epoch 8966 - Train Loss: 0.128346, Train Acc: 0.778205 | Val Loss: 0.143721, Val Acc: 0.690722\n",
      "Epoch 8967 - Train Loss: 0.128337, Train Acc: 0.778205 | Val Loss: 0.143714, Val Acc: 0.690722\n",
      "Epoch 8968 - Train Loss: 0.128329, Train Acc: 0.778205 | Val Loss: 0.143706, Val Acc: 0.690722\n",
      "Epoch 8969 - Train Loss: 0.128320, Train Acc: 0.778205 | Val Loss: 0.143698, Val Acc: 0.690722\n",
      "Epoch 8970 - Train Loss: 0.128311, Train Acc: 0.778205 | Val Loss: 0.143690, Val Acc: 0.690722\n",
      "Epoch 8971 - Train Loss: 0.128302, Train Acc: 0.778205 | Val Loss: 0.143683, Val Acc: 0.690722\n",
      "Epoch 8972 - Train Loss: 0.128293, Train Acc: 0.778205 | Val Loss: 0.143675, Val Acc: 0.690722\n",
      "Epoch 8973 - Train Loss: 0.128285, Train Acc: 0.778205 | Val Loss: 0.143667, Val Acc: 0.690722\n",
      "Epoch 8974 - Train Loss: 0.128276, Train Acc: 0.778205 | Val Loss: 0.143659, Val Acc: 0.690722\n",
      "Epoch 8975 - Train Loss: 0.128267, Train Acc: 0.778205 | Val Loss: 0.143652, Val Acc: 0.690722\n",
      "Epoch 8976 - Train Loss: 0.128258, Train Acc: 0.778205 | Val Loss: 0.143644, Val Acc: 0.690722\n",
      "Epoch 8977 - Train Loss: 0.128250, Train Acc: 0.778205 | Val Loss: 0.143636, Val Acc: 0.690722\n",
      "Epoch 8978 - Train Loss: 0.128241, Train Acc: 0.778205 | Val Loss: 0.143629, Val Acc: 0.690722\n",
      "Epoch 8979 - Train Loss: 0.128232, Train Acc: 0.778205 | Val Loss: 0.143621, Val Acc: 0.690722\n",
      "Epoch 8980 - Train Loss: 0.128223, Train Acc: 0.778205 | Val Loss: 0.143613, Val Acc: 0.690722\n",
      "Epoch 8981 - Train Loss: 0.128214, Train Acc: 0.778205 | Val Loss: 0.143605, Val Acc: 0.690722\n",
      "Epoch 8982 - Train Loss: 0.128206, Train Acc: 0.778205 | Val Loss: 0.143598, Val Acc: 0.690722\n",
      "Epoch 8983 - Train Loss: 0.128197, Train Acc: 0.778205 | Val Loss: 0.143590, Val Acc: 0.690722\n",
      "Epoch 8984 - Train Loss: 0.128188, Train Acc: 0.778205 | Val Loss: 0.143582, Val Acc: 0.690722\n",
      "Epoch 8985 - Train Loss: 0.128179, Train Acc: 0.778205 | Val Loss: 0.143574, Val Acc: 0.690722\n",
      "Epoch 8986 - Train Loss: 0.128171, Train Acc: 0.778205 | Val Loss: 0.143567, Val Acc: 0.690722\n",
      "Epoch 8987 - Train Loss: 0.128162, Train Acc: 0.778205 | Val Loss: 0.143559, Val Acc: 0.690722\n",
      "Epoch 8988 - Train Loss: 0.128153, Train Acc: 0.778205 | Val Loss: 0.143551, Val Acc: 0.690722\n",
      "Epoch 8989 - Train Loss: 0.128144, Train Acc: 0.778205 | Val Loss: 0.143544, Val Acc: 0.690722\n",
      "Epoch 8990 - Train Loss: 0.128136, Train Acc: 0.778205 | Val Loss: 0.143536, Val Acc: 0.690722\n",
      "Epoch 8991 - Train Loss: 0.128127, Train Acc: 0.778205 | Val Loss: 0.143528, Val Acc: 0.690722\n",
      "Epoch 8992 - Train Loss: 0.128118, Train Acc: 0.778205 | Val Loss: 0.143520, Val Acc: 0.690722\n",
      "Epoch 8993 - Train Loss: 0.128109, Train Acc: 0.778205 | Val Loss: 0.143513, Val Acc: 0.690722\n",
      "Epoch 8994 - Train Loss: 0.128101, Train Acc: 0.778205 | Val Loss: 0.143505, Val Acc: 0.690722\n",
      "Epoch 8995 - Train Loss: 0.128092, Train Acc: 0.778205 | Val Loss: 0.143497, Val Acc: 0.690722\n",
      "Epoch 8996 - Train Loss: 0.128083, Train Acc: 0.778205 | Val Loss: 0.143490, Val Acc: 0.690722\n",
      "Epoch 8997 - Train Loss: 0.128074, Train Acc: 0.778205 | Val Loss: 0.143482, Val Acc: 0.690722\n",
      "Epoch 8998 - Train Loss: 0.128066, Train Acc: 0.778205 | Val Loss: 0.143474, Val Acc: 0.690722\n",
      "Epoch 8999 - Train Loss: 0.128057, Train Acc: 0.778205 | Val Loss: 0.143467, Val Acc: 0.690722\n",
      "Epoch 9000 - Train Loss: 0.128048, Train Acc: 0.778205 | Val Loss: 0.143459, Val Acc: 0.690722\n",
      "Epoch 9001 - Train Loss: 0.128039, Train Acc: 0.778205 | Val Loss: 0.143451, Val Acc: 0.690722\n",
      "Epoch 9002 - Train Loss: 0.128031, Train Acc: 0.778205 | Val Loss: 0.143444, Val Acc: 0.690722\n",
      "Epoch 9003 - Train Loss: 0.128022, Train Acc: 0.778205 | Val Loss: 0.143436, Val Acc: 0.690722\n",
      "Epoch 9004 - Train Loss: 0.128013, Train Acc: 0.778205 | Val Loss: 0.143428, Val Acc: 0.690722\n",
      "Epoch 9005 - Train Loss: 0.128005, Train Acc: 0.778205 | Val Loss: 0.143421, Val Acc: 0.690722\n",
      "Epoch 9006 - Train Loss: 0.127996, Train Acc: 0.778205 | Val Loss: 0.143413, Val Acc: 0.690722\n",
      "Epoch 9007 - Train Loss: 0.127987, Train Acc: 0.778205 | Val Loss: 0.143405, Val Acc: 0.690722\n",
      "Epoch 9008 - Train Loss: 0.127978, Train Acc: 0.778205 | Val Loss: 0.143398, Val Acc: 0.690722\n",
      "Epoch 9009 - Train Loss: 0.127970, Train Acc: 0.778205 | Val Loss: 0.143390, Val Acc: 0.690722\n",
      "Epoch 9010 - Train Loss: 0.127961, Train Acc: 0.778205 | Val Loss: 0.143382, Val Acc: 0.690722\n",
      "Epoch 9011 - Train Loss: 0.127952, Train Acc: 0.778205 | Val Loss: 0.143375, Val Acc: 0.690722\n",
      "Epoch 9012 - Train Loss: 0.127943, Train Acc: 0.778205 | Val Loss: 0.143367, Val Acc: 0.690722\n",
      "Epoch 9013 - Train Loss: 0.127935, Train Acc: 0.778205 | Val Loss: 0.143359, Val Acc: 0.690722\n",
      "Epoch 9014 - Train Loss: 0.127926, Train Acc: 0.778205 | Val Loss: 0.143352, Val Acc: 0.690722\n",
      "Epoch 9015 - Train Loss: 0.127917, Train Acc: 0.778205 | Val Loss: 0.143344, Val Acc: 0.690722\n",
      "Epoch 9016 - Train Loss: 0.127909, Train Acc: 0.778205 | Val Loss: 0.143336, Val Acc: 0.690722\n",
      "Epoch 9017 - Train Loss: 0.127900, Train Acc: 0.778205 | Val Loss: 0.143329, Val Acc: 0.690722\n",
      "Epoch 9018 - Train Loss: 0.127891, Train Acc: 0.778205 | Val Loss: 0.143321, Val Acc: 0.690722\n",
      "Epoch 9019 - Train Loss: 0.127883, Train Acc: 0.779487 | Val Loss: 0.143313, Val Acc: 0.690722\n",
      "Epoch 9020 - Train Loss: 0.127874, Train Acc: 0.779487 | Val Loss: 0.143306, Val Acc: 0.690722\n",
      "Epoch 9021 - Train Loss: 0.127865, Train Acc: 0.779487 | Val Loss: 0.143298, Val Acc: 0.690722\n",
      "Epoch 9022 - Train Loss: 0.127856, Train Acc: 0.779487 | Val Loss: 0.143290, Val Acc: 0.690722\n",
      "Epoch 9023 - Train Loss: 0.127848, Train Acc: 0.779487 | Val Loss: 0.143283, Val Acc: 0.690722\n",
      "Epoch 9024 - Train Loss: 0.127839, Train Acc: 0.779487 | Val Loss: 0.143275, Val Acc: 0.690722\n",
      "Epoch 9025 - Train Loss: 0.127830, Train Acc: 0.779487 | Val Loss: 0.143267, Val Acc: 0.690722\n",
      "Epoch 9026 - Train Loss: 0.127822, Train Acc: 0.779487 | Val Loss: 0.143260, Val Acc: 0.690722\n",
      "Epoch 9027 - Train Loss: 0.127813, Train Acc: 0.779487 | Val Loss: 0.143252, Val Acc: 0.690722\n",
      "Epoch 9028 - Train Loss: 0.127804, Train Acc: 0.779487 | Val Loss: 0.143245, Val Acc: 0.690722\n",
      "Epoch 9029 - Train Loss: 0.127796, Train Acc: 0.779487 | Val Loss: 0.143237, Val Acc: 0.690722\n",
      "Epoch 9030 - Train Loss: 0.127787, Train Acc: 0.779487 | Val Loss: 0.143229, Val Acc: 0.690722\n",
      "Epoch 9031 - Train Loss: 0.127778, Train Acc: 0.779487 | Val Loss: 0.143222, Val Acc: 0.690722\n",
      "Epoch 9032 - Train Loss: 0.127770, Train Acc: 0.779487 | Val Loss: 0.143214, Val Acc: 0.690722\n",
      "Epoch 9033 - Train Loss: 0.127761, Train Acc: 0.779487 | Val Loss: 0.143207, Val Acc: 0.690722\n",
      "Epoch 9034 - Train Loss: 0.127752, Train Acc: 0.779487 | Val Loss: 0.143199, Val Acc: 0.690722\n",
      "Epoch 9035 - Train Loss: 0.127744, Train Acc: 0.779487 | Val Loss: 0.143191, Val Acc: 0.690722\n",
      "Epoch 9036 - Train Loss: 0.127735, Train Acc: 0.779487 | Val Loss: 0.143184, Val Acc: 0.690722\n",
      "Epoch 9037 - Train Loss: 0.127726, Train Acc: 0.779487 | Val Loss: 0.143176, Val Acc: 0.690722\n",
      "Epoch 9038 - Train Loss: 0.127718, Train Acc: 0.779487 | Val Loss: 0.143168, Val Acc: 0.690722\n",
      "Epoch 9039 - Train Loss: 0.127709, Train Acc: 0.779487 | Val Loss: 0.143161, Val Acc: 0.690722\n",
      "Epoch 9040 - Train Loss: 0.127700, Train Acc: 0.779487 | Val Loss: 0.143153, Val Acc: 0.690722\n",
      "Epoch 9041 - Train Loss: 0.127691, Train Acc: 0.779487 | Val Loss: 0.143146, Val Acc: 0.690722\n",
      "Epoch 9042 - Train Loss: 0.127683, Train Acc: 0.779487 | Val Loss: 0.143138, Val Acc: 0.690722\n",
      "Epoch 9043 - Train Loss: 0.127674, Train Acc: 0.779487 | Val Loss: 0.143130, Val Acc: 0.690722\n",
      "Epoch 9044 - Train Loss: 0.127666, Train Acc: 0.779487 | Val Loss: 0.143123, Val Acc: 0.690722\n",
      "Epoch 9045 - Train Loss: 0.127657, Train Acc: 0.779487 | Val Loss: 0.143115, Val Acc: 0.690722\n",
      "Epoch 9046 - Train Loss: 0.127648, Train Acc: 0.779487 | Val Loss: 0.143108, Val Acc: 0.690722\n",
      "Epoch 9047 - Train Loss: 0.127640, Train Acc: 0.779487 | Val Loss: 0.143100, Val Acc: 0.690722\n",
      "Epoch 9048 - Train Loss: 0.127631, Train Acc: 0.779487 | Val Loss: 0.143092, Val Acc: 0.690722\n",
      "Epoch 9049 - Train Loss: 0.127622, Train Acc: 0.779487 | Val Loss: 0.143085, Val Acc: 0.690722\n",
      "Epoch 9050 - Train Loss: 0.127614, Train Acc: 0.779487 | Val Loss: 0.143077, Val Acc: 0.690722\n",
      "Epoch 9051 - Train Loss: 0.127605, Train Acc: 0.779487 | Val Loss: 0.143069, Val Acc: 0.690722\n",
      "Epoch 9052 - Train Loss: 0.127596, Train Acc: 0.779487 | Val Loss: 0.143062, Val Acc: 0.690722\n",
      "Epoch 9053 - Train Loss: 0.127588, Train Acc: 0.779487 | Val Loss: 0.143054, Val Acc: 0.690722\n",
      "Epoch 9054 - Train Loss: 0.127579, Train Acc: 0.779487 | Val Loss: 0.143047, Val Acc: 0.690722\n",
      "Epoch 9055 - Train Loss: 0.127570, Train Acc: 0.779487 | Val Loss: 0.143039, Val Acc: 0.690722\n",
      "Epoch 9056 - Train Loss: 0.127562, Train Acc: 0.779487 | Val Loss: 0.143032, Val Acc: 0.690722\n",
      "Epoch 9057 - Train Loss: 0.127553, Train Acc: 0.779487 | Val Loss: 0.143024, Val Acc: 0.690722\n",
      "Epoch 9058 - Train Loss: 0.127544, Train Acc: 0.779487 | Val Loss: 0.143016, Val Acc: 0.690722\n",
      "Epoch 9059 - Train Loss: 0.127536, Train Acc: 0.779487 | Val Loss: 0.143009, Val Acc: 0.690722\n",
      "Epoch 9060 - Train Loss: 0.127527, Train Acc: 0.779487 | Val Loss: 0.143001, Val Acc: 0.690722\n",
      "Epoch 9061 - Train Loss: 0.127519, Train Acc: 0.779487 | Val Loss: 0.142994, Val Acc: 0.690722\n",
      "Epoch 9062 - Train Loss: 0.127510, Train Acc: 0.779487 | Val Loss: 0.142986, Val Acc: 0.690722\n",
      "Epoch 9063 - Train Loss: 0.127501, Train Acc: 0.779487 | Val Loss: 0.142978, Val Acc: 0.690722\n",
      "Epoch 9064 - Train Loss: 0.127493, Train Acc: 0.779487 | Val Loss: 0.142971, Val Acc: 0.690722\n",
      "Epoch 9065 - Train Loss: 0.127484, Train Acc: 0.779487 | Val Loss: 0.142963, Val Acc: 0.690722\n",
      "Epoch 9066 - Train Loss: 0.127475, Train Acc: 0.779487 | Val Loss: 0.142956, Val Acc: 0.690722\n",
      "Epoch 9067 - Train Loss: 0.127467, Train Acc: 0.779487 | Val Loss: 0.142948, Val Acc: 0.690722\n",
      "Epoch 9068 - Train Loss: 0.127458, Train Acc: 0.779487 | Val Loss: 0.142941, Val Acc: 0.690722\n",
      "Epoch 9069 - Train Loss: 0.127449, Train Acc: 0.779487 | Val Loss: 0.142933, Val Acc: 0.690722\n",
      "Epoch 9070 - Train Loss: 0.127441, Train Acc: 0.779487 | Val Loss: 0.142925, Val Acc: 0.690722\n",
      "Epoch 9071 - Train Loss: 0.127432, Train Acc: 0.779487 | Val Loss: 0.142918, Val Acc: 0.690722\n",
      "Epoch 9072 - Train Loss: 0.127424, Train Acc: 0.779487 | Val Loss: 0.142910, Val Acc: 0.690722\n",
      "Epoch 9073 - Train Loss: 0.127415, Train Acc: 0.779487 | Val Loss: 0.142903, Val Acc: 0.690722\n",
      "Epoch 9074 - Train Loss: 0.127406, Train Acc: 0.779487 | Val Loss: 0.142895, Val Acc: 0.690722\n",
      "Epoch 9075 - Train Loss: 0.127398, Train Acc: 0.779487 | Val Loss: 0.142888, Val Acc: 0.690722\n",
      "Epoch 9076 - Train Loss: 0.127389, Train Acc: 0.779487 | Val Loss: 0.142880, Val Acc: 0.690722\n",
      "Epoch 9077 - Train Loss: 0.127381, Train Acc: 0.779487 | Val Loss: 0.142872, Val Acc: 0.690722\n",
      "Epoch 9078 - Train Loss: 0.127372, Train Acc: 0.779487 | Val Loss: 0.142865, Val Acc: 0.690722\n",
      "Epoch 9079 - Train Loss: 0.127363, Train Acc: 0.779487 | Val Loss: 0.142857, Val Acc: 0.690722\n",
      "Epoch 9080 - Train Loss: 0.127355, Train Acc: 0.779487 | Val Loss: 0.142850, Val Acc: 0.690722\n",
      "Epoch 9081 - Train Loss: 0.127346, Train Acc: 0.779487 | Val Loss: 0.142842, Val Acc: 0.690722\n",
      "Epoch 9082 - Train Loss: 0.127337, Train Acc: 0.779487 | Val Loss: 0.142835, Val Acc: 0.690722\n",
      "Epoch 9083 - Train Loss: 0.127329, Train Acc: 0.779487 | Val Loss: 0.142827, Val Acc: 0.690722\n",
      "Epoch 9084 - Train Loss: 0.127320, Train Acc: 0.779487 | Val Loss: 0.142820, Val Acc: 0.690722\n",
      "Epoch 9085 - Train Loss: 0.127312, Train Acc: 0.779487 | Val Loss: 0.142812, Val Acc: 0.690722\n",
      "Epoch 9086 - Train Loss: 0.127303, Train Acc: 0.779487 | Val Loss: 0.142805, Val Acc: 0.690722\n",
      "Epoch 9087 - Train Loss: 0.127294, Train Acc: 0.779487 | Val Loss: 0.142797, Val Acc: 0.690722\n",
      "Epoch 9088 - Train Loss: 0.127286, Train Acc: 0.779487 | Val Loss: 0.142790, Val Acc: 0.690722\n",
      "Epoch 9089 - Train Loss: 0.127277, Train Acc: 0.779487 | Val Loss: 0.142782, Val Acc: 0.690722\n",
      "Epoch 9090 - Train Loss: 0.127269, Train Acc: 0.779487 | Val Loss: 0.142774, Val Acc: 0.690722\n",
      "Epoch 9091 - Train Loss: 0.127260, Train Acc: 0.779487 | Val Loss: 0.142767, Val Acc: 0.690722\n",
      "Epoch 9092 - Train Loss: 0.127251, Train Acc: 0.779487 | Val Loss: 0.142759, Val Acc: 0.690722\n",
      "Epoch 9093 - Train Loss: 0.127243, Train Acc: 0.779487 | Val Loss: 0.142752, Val Acc: 0.690722\n",
      "Epoch 9094 - Train Loss: 0.127234, Train Acc: 0.779487 | Val Loss: 0.142744, Val Acc: 0.690722\n",
      "Epoch 9095 - Train Loss: 0.127226, Train Acc: 0.779487 | Val Loss: 0.142737, Val Acc: 0.690722\n",
      "Epoch 9096 - Train Loss: 0.127217, Train Acc: 0.779487 | Val Loss: 0.142729, Val Acc: 0.690722\n",
      "Epoch 9097 - Train Loss: 0.127209, Train Acc: 0.780769 | Val Loss: 0.142722, Val Acc: 0.690722\n",
      "Epoch 9098 - Train Loss: 0.127200, Train Acc: 0.780769 | Val Loss: 0.142714, Val Acc: 0.690722\n",
      "Epoch 9099 - Train Loss: 0.127191, Train Acc: 0.780769 | Val Loss: 0.142707, Val Acc: 0.690722\n",
      "Epoch 9100 - Train Loss: 0.127183, Train Acc: 0.780769 | Val Loss: 0.142699, Val Acc: 0.690722\n",
      "Epoch 9101 - Train Loss: 0.127174, Train Acc: 0.780769 | Val Loss: 0.142692, Val Acc: 0.690722\n",
      "Epoch 9102 - Train Loss: 0.127166, Train Acc: 0.780769 | Val Loss: 0.142684, Val Acc: 0.690722\n",
      "Epoch 9103 - Train Loss: 0.127157, Train Acc: 0.780769 | Val Loss: 0.142677, Val Acc: 0.690722\n",
      "Epoch 9104 - Train Loss: 0.127149, Train Acc: 0.780769 | Val Loss: 0.142669, Val Acc: 0.690722\n",
      "Epoch 9105 - Train Loss: 0.127140, Train Acc: 0.780769 | Val Loss: 0.142662, Val Acc: 0.690722\n",
      "Epoch 9106 - Train Loss: 0.127131, Train Acc: 0.780769 | Val Loss: 0.142654, Val Acc: 0.690722\n",
      "Epoch 9107 - Train Loss: 0.127123, Train Acc: 0.780769 | Val Loss: 0.142647, Val Acc: 0.690722\n",
      "Epoch 9108 - Train Loss: 0.127114, Train Acc: 0.780769 | Val Loss: 0.142639, Val Acc: 0.690722\n",
      "Epoch 9109 - Train Loss: 0.127106, Train Acc: 0.780769 | Val Loss: 0.142632, Val Acc: 0.690722\n",
      "Epoch 9110 - Train Loss: 0.127097, Train Acc: 0.780769 | Val Loss: 0.142624, Val Acc: 0.690722\n",
      "Epoch 9111 - Train Loss: 0.127089, Train Acc: 0.780769 | Val Loss: 0.142617, Val Acc: 0.690722\n",
      "Epoch 9112 - Train Loss: 0.127080, Train Acc: 0.780769 | Val Loss: 0.142609, Val Acc: 0.690722\n",
      "Epoch 9113 - Train Loss: 0.127071, Train Acc: 0.780769 | Val Loss: 0.142602, Val Acc: 0.690722\n",
      "Epoch 9114 - Train Loss: 0.127063, Train Acc: 0.780769 | Val Loss: 0.142594, Val Acc: 0.690722\n",
      "Epoch 9115 - Train Loss: 0.127054, Train Acc: 0.780769 | Val Loss: 0.142587, Val Acc: 0.690722\n",
      "Epoch 9116 - Train Loss: 0.127046, Train Acc: 0.780769 | Val Loss: 0.142579, Val Acc: 0.690722\n",
      "Epoch 9117 - Train Loss: 0.127037, Train Acc: 0.780769 | Val Loss: 0.142572, Val Acc: 0.690722\n",
      "Epoch 9118 - Train Loss: 0.127029, Train Acc: 0.780769 | Val Loss: 0.142564, Val Acc: 0.690722\n",
      "Epoch 9119 - Train Loss: 0.127020, Train Acc: 0.780769 | Val Loss: 0.142557, Val Acc: 0.690722\n",
      "Epoch 9120 - Train Loss: 0.127011, Train Acc: 0.780769 | Val Loss: 0.142549, Val Acc: 0.690722\n",
      "Epoch 9121 - Train Loss: 0.127003, Train Acc: 0.780769 | Val Loss: 0.142542, Val Acc: 0.690722\n",
      "Epoch 9122 - Train Loss: 0.126994, Train Acc: 0.780769 | Val Loss: 0.142534, Val Acc: 0.690722\n",
      "Epoch 9123 - Train Loss: 0.126986, Train Acc: 0.780769 | Val Loss: 0.142527, Val Acc: 0.690722\n",
      "Epoch 9124 - Train Loss: 0.126977, Train Acc: 0.780769 | Val Loss: 0.142519, Val Acc: 0.690722\n",
      "Epoch 9125 - Train Loss: 0.126969, Train Acc: 0.780769 | Val Loss: 0.142512, Val Acc: 0.690722\n",
      "Epoch 9126 - Train Loss: 0.126960, Train Acc: 0.780769 | Val Loss: 0.142504, Val Acc: 0.690722\n",
      "Epoch 9127 - Train Loss: 0.126952, Train Acc: 0.780769 | Val Loss: 0.142497, Val Acc: 0.690722\n",
      "Epoch 9128 - Train Loss: 0.126943, Train Acc: 0.780769 | Val Loss: 0.142490, Val Acc: 0.690722\n",
      "Epoch 9129 - Train Loss: 0.126935, Train Acc: 0.780769 | Val Loss: 0.142482, Val Acc: 0.690722\n",
      "Epoch 9130 - Train Loss: 0.126926, Train Acc: 0.780769 | Val Loss: 0.142475, Val Acc: 0.690722\n",
      "Epoch 9131 - Train Loss: 0.126917, Train Acc: 0.780769 | Val Loss: 0.142467, Val Acc: 0.690722\n",
      "Epoch 9132 - Train Loss: 0.126909, Train Acc: 0.780769 | Val Loss: 0.142460, Val Acc: 0.690722\n",
      "Epoch 9133 - Train Loss: 0.126900, Train Acc: 0.780769 | Val Loss: 0.142452, Val Acc: 0.690722\n",
      "Epoch 9134 - Train Loss: 0.126892, Train Acc: 0.780769 | Val Loss: 0.142445, Val Acc: 0.690722\n",
      "Epoch 9135 - Train Loss: 0.126883, Train Acc: 0.780769 | Val Loss: 0.142437, Val Acc: 0.690722\n",
      "Epoch 9136 - Train Loss: 0.126875, Train Acc: 0.780769 | Val Loss: 0.142430, Val Acc: 0.690722\n",
      "Epoch 9137 - Train Loss: 0.126866, Train Acc: 0.780769 | Val Loss: 0.142422, Val Acc: 0.690722\n",
      "Epoch 9138 - Train Loss: 0.126858, Train Acc: 0.780769 | Val Loss: 0.142415, Val Acc: 0.690722\n",
      "Epoch 9139 - Train Loss: 0.126849, Train Acc: 0.780769 | Val Loss: 0.142408, Val Acc: 0.690722\n",
      "Epoch 9140 - Train Loss: 0.126841, Train Acc: 0.780769 | Val Loss: 0.142400, Val Acc: 0.690722\n",
      "Epoch 9141 - Train Loss: 0.126832, Train Acc: 0.780769 | Val Loss: 0.142393, Val Acc: 0.690722\n",
      "Epoch 9142 - Train Loss: 0.126824, Train Acc: 0.780769 | Val Loss: 0.142385, Val Acc: 0.690722\n",
      "Epoch 9143 - Train Loss: 0.126815, Train Acc: 0.780769 | Val Loss: 0.142378, Val Acc: 0.690722\n",
      "Epoch 9144 - Train Loss: 0.126807, Train Acc: 0.780769 | Val Loss: 0.142370, Val Acc: 0.690722\n",
      "Epoch 9145 - Train Loss: 0.126798, Train Acc: 0.780769 | Val Loss: 0.142363, Val Acc: 0.690722\n",
      "Epoch 9146 - Train Loss: 0.126790, Train Acc: 0.780769 | Val Loss: 0.142355, Val Acc: 0.690722\n",
      "Epoch 9147 - Train Loss: 0.126781, Train Acc: 0.780769 | Val Loss: 0.142348, Val Acc: 0.690722\n",
      "Epoch 9148 - Train Loss: 0.126772, Train Acc: 0.780769 | Val Loss: 0.142340, Val Acc: 0.690722\n",
      "Epoch 9149 - Train Loss: 0.126764, Train Acc: 0.780769 | Val Loss: 0.142333, Val Acc: 0.690722\n",
      "Epoch 9150 - Train Loss: 0.126755, Train Acc: 0.780769 | Val Loss: 0.142326, Val Acc: 0.690722\n",
      "Epoch 9151 - Train Loss: 0.126747, Train Acc: 0.780769 | Val Loss: 0.142318, Val Acc: 0.690722\n",
      "Epoch 9152 - Train Loss: 0.126738, Train Acc: 0.780769 | Val Loss: 0.142311, Val Acc: 0.690722\n",
      "Epoch 9153 - Train Loss: 0.126730, Train Acc: 0.780769 | Val Loss: 0.142303, Val Acc: 0.690722\n",
      "Epoch 9154 - Train Loss: 0.126721, Train Acc: 0.780769 | Val Loss: 0.142296, Val Acc: 0.690722\n",
      "Epoch 9155 - Train Loss: 0.126713, Train Acc: 0.780769 | Val Loss: 0.142288, Val Acc: 0.690722\n",
      "Epoch 9156 - Train Loss: 0.126704, Train Acc: 0.780769 | Val Loss: 0.142281, Val Acc: 0.690722\n",
      "Epoch 9157 - Train Loss: 0.126696, Train Acc: 0.780769 | Val Loss: 0.142274, Val Acc: 0.690722\n",
      "Epoch 9158 - Train Loss: 0.126687, Train Acc: 0.780769 | Val Loss: 0.142266, Val Acc: 0.690722\n",
      "Epoch 9159 - Train Loss: 0.126679, Train Acc: 0.780769 | Val Loss: 0.142259, Val Acc: 0.690722\n",
      "Epoch 9160 - Train Loss: 0.126670, Train Acc: 0.780769 | Val Loss: 0.142251, Val Acc: 0.690722\n",
      "Epoch 9161 - Train Loss: 0.126662, Train Acc: 0.780769 | Val Loss: 0.142244, Val Acc: 0.690722\n",
      "Epoch 9162 - Train Loss: 0.126653, Train Acc: 0.780769 | Val Loss: 0.142237, Val Acc: 0.690722\n",
      "Epoch 9163 - Train Loss: 0.126645, Train Acc: 0.780769 | Val Loss: 0.142229, Val Acc: 0.690722\n",
      "Epoch 9164 - Train Loss: 0.126636, Train Acc: 0.780769 | Val Loss: 0.142222, Val Acc: 0.690722\n",
      "Epoch 9165 - Train Loss: 0.126628, Train Acc: 0.780769 | Val Loss: 0.142214, Val Acc: 0.690722\n",
      "Epoch 9166 - Train Loss: 0.126619, Train Acc: 0.780769 | Val Loss: 0.142207, Val Acc: 0.690722\n",
      "Epoch 9167 - Train Loss: 0.126611, Train Acc: 0.780769 | Val Loss: 0.142200, Val Acc: 0.690722\n",
      "Epoch 9168 - Train Loss: 0.126602, Train Acc: 0.780769 | Val Loss: 0.142192, Val Acc: 0.690722\n",
      "Epoch 9169 - Train Loss: 0.126594, Train Acc: 0.780769 | Val Loss: 0.142185, Val Acc: 0.690722\n",
      "Epoch 9170 - Train Loss: 0.126585, Train Acc: 0.780769 | Val Loss: 0.142177, Val Acc: 0.690722\n",
      "Epoch 9171 - Train Loss: 0.126577, Train Acc: 0.780769 | Val Loss: 0.142170, Val Acc: 0.690722\n",
      "Epoch 9172 - Train Loss: 0.126569, Train Acc: 0.780769 | Val Loss: 0.142163, Val Acc: 0.690722\n",
      "Epoch 9173 - Train Loss: 0.126560, Train Acc: 0.780769 | Val Loss: 0.142155, Val Acc: 0.690722\n",
      "Epoch 9174 - Train Loss: 0.126552, Train Acc: 0.780769 | Val Loss: 0.142148, Val Acc: 0.690722\n",
      "Epoch 9175 - Train Loss: 0.126543, Train Acc: 0.780769 | Val Loss: 0.142140, Val Acc: 0.690722\n",
      "Epoch 9176 - Train Loss: 0.126535, Train Acc: 0.780769 | Val Loss: 0.142133, Val Acc: 0.690722\n",
      "Epoch 9177 - Train Loss: 0.126526, Train Acc: 0.780769 | Val Loss: 0.142126, Val Acc: 0.690722\n",
      "Epoch 9178 - Train Loss: 0.126518, Train Acc: 0.780769 | Val Loss: 0.142118, Val Acc: 0.690722\n",
      "Epoch 9179 - Train Loss: 0.126509, Train Acc: 0.780769 | Val Loss: 0.142111, Val Acc: 0.690722\n",
      "Epoch 9180 - Train Loss: 0.126501, Train Acc: 0.780769 | Val Loss: 0.142103, Val Acc: 0.690722\n",
      "Epoch 9181 - Train Loss: 0.126492, Train Acc: 0.780769 | Val Loss: 0.142096, Val Acc: 0.690722\n",
      "Epoch 9182 - Train Loss: 0.126484, Train Acc: 0.780769 | Val Loss: 0.142089, Val Acc: 0.690722\n",
      "Epoch 9183 - Train Loss: 0.126475, Train Acc: 0.780769 | Val Loss: 0.142081, Val Acc: 0.690722\n",
      "Epoch 9184 - Train Loss: 0.126467, Train Acc: 0.780769 | Val Loss: 0.142074, Val Acc: 0.690722\n",
      "Epoch 9185 - Train Loss: 0.126458, Train Acc: 0.780769 | Val Loss: 0.142067, Val Acc: 0.690722\n",
      "Epoch 9186 - Train Loss: 0.126450, Train Acc: 0.780769 | Val Loss: 0.142059, Val Acc: 0.690722\n",
      "Epoch 9187 - Train Loss: 0.126441, Train Acc: 0.780769 | Val Loss: 0.142052, Val Acc: 0.690722\n",
      "Epoch 9188 - Train Loss: 0.126433, Train Acc: 0.780769 | Val Loss: 0.142045, Val Acc: 0.690722\n",
      "Epoch 9189 - Train Loss: 0.126425, Train Acc: 0.780769 | Val Loss: 0.142037, Val Acc: 0.690722\n",
      "Epoch 9190 - Train Loss: 0.126416, Train Acc: 0.780769 | Val Loss: 0.142030, Val Acc: 0.690722\n",
      "Epoch 9191 - Train Loss: 0.126408, Train Acc: 0.780769 | Val Loss: 0.142022, Val Acc: 0.690722\n",
      "Epoch 9192 - Train Loss: 0.126399, Train Acc: 0.780769 | Val Loss: 0.142015, Val Acc: 0.690722\n",
      "Epoch 9193 - Train Loss: 0.126391, Train Acc: 0.780769 | Val Loss: 0.142008, Val Acc: 0.690722\n",
      "Epoch 9194 - Train Loss: 0.126382, Train Acc: 0.780769 | Val Loss: 0.142000, Val Acc: 0.690722\n",
      "Epoch 9195 - Train Loss: 0.126374, Train Acc: 0.780769 | Val Loss: 0.141993, Val Acc: 0.690722\n",
      "Epoch 9196 - Train Loss: 0.126365, Train Acc: 0.780769 | Val Loss: 0.141986, Val Acc: 0.690722\n",
      "Epoch 9197 - Train Loss: 0.126357, Train Acc: 0.780769 | Val Loss: 0.141978, Val Acc: 0.690722\n",
      "Epoch 9198 - Train Loss: 0.126348, Train Acc: 0.780769 | Val Loss: 0.141971, Val Acc: 0.690722\n",
      "Epoch 9199 - Train Loss: 0.126340, Train Acc: 0.780769 | Val Loss: 0.141964, Val Acc: 0.690722\n",
      "Epoch 9200 - Train Loss: 0.126332, Train Acc: 0.780769 | Val Loss: 0.141956, Val Acc: 0.690722\n",
      "Epoch 9201 - Train Loss: 0.126323, Train Acc: 0.780769 | Val Loss: 0.141949, Val Acc: 0.690722\n",
      "Epoch 9202 - Train Loss: 0.126315, Train Acc: 0.780769 | Val Loss: 0.141942, Val Acc: 0.690722\n",
      "Epoch 9203 - Train Loss: 0.126306, Train Acc: 0.780769 | Val Loss: 0.141934, Val Acc: 0.690722\n",
      "Epoch 9204 - Train Loss: 0.126298, Train Acc: 0.780769 | Val Loss: 0.141927, Val Acc: 0.690722\n",
      "Epoch 9205 - Train Loss: 0.126289, Train Acc: 0.780769 | Val Loss: 0.141920, Val Acc: 0.690722\n",
      "Epoch 9206 - Train Loss: 0.126281, Train Acc: 0.780769 | Val Loss: 0.141912, Val Acc: 0.690722\n",
      "Epoch 9207 - Train Loss: 0.126272, Train Acc: 0.780769 | Val Loss: 0.141905, Val Acc: 0.690722\n",
      "Epoch 9208 - Train Loss: 0.126264, Train Acc: 0.780769 | Val Loss: 0.141898, Val Acc: 0.690722\n",
      "Epoch 9209 - Train Loss: 0.126256, Train Acc: 0.780769 | Val Loss: 0.141890, Val Acc: 0.690722\n",
      "Epoch 9210 - Train Loss: 0.126247, Train Acc: 0.780769 | Val Loss: 0.141883, Val Acc: 0.690722\n",
      "Epoch 9211 - Train Loss: 0.126239, Train Acc: 0.780769 | Val Loss: 0.141876, Val Acc: 0.690722\n",
      "Epoch 9212 - Train Loss: 0.126230, Train Acc: 0.780769 | Val Loss: 0.141868, Val Acc: 0.690722\n",
      "Epoch 9213 - Train Loss: 0.126222, Train Acc: 0.780769 | Val Loss: 0.141861, Val Acc: 0.690722\n",
      "Epoch 9214 - Train Loss: 0.126213, Train Acc: 0.780769 | Val Loss: 0.141854, Val Acc: 0.690722\n",
      "Epoch 9215 - Train Loss: 0.126205, Train Acc: 0.780769 | Val Loss: 0.141846, Val Acc: 0.690722\n",
      "Epoch 9216 - Train Loss: 0.126197, Train Acc: 0.780769 | Val Loss: 0.141839, Val Acc: 0.690722\n",
      "Epoch 9217 - Train Loss: 0.126188, Train Acc: 0.780769 | Val Loss: 0.141832, Val Acc: 0.690722\n",
      "Epoch 9218 - Train Loss: 0.126180, Train Acc: 0.780769 | Val Loss: 0.141824, Val Acc: 0.690722\n",
      "Epoch 9219 - Train Loss: 0.126171, Train Acc: 0.780769 | Val Loss: 0.141817, Val Acc: 0.690722\n",
      "Epoch 9220 - Train Loss: 0.126163, Train Acc: 0.780769 | Val Loss: 0.141810, Val Acc: 0.690722\n",
      "Epoch 9221 - Train Loss: 0.126154, Train Acc: 0.780769 | Val Loss: 0.141803, Val Acc: 0.690722\n",
      "Epoch 9222 - Train Loss: 0.126146, Train Acc: 0.780769 | Val Loss: 0.141795, Val Acc: 0.690722\n",
      "Epoch 9223 - Train Loss: 0.126138, Train Acc: 0.780769 | Val Loss: 0.141788, Val Acc: 0.690722\n",
      "Epoch 9224 - Train Loss: 0.126129, Train Acc: 0.780769 | Val Loss: 0.141781, Val Acc: 0.690722\n",
      "Epoch 9225 - Train Loss: 0.126121, Train Acc: 0.780769 | Val Loss: 0.141773, Val Acc: 0.690722\n",
      "Epoch 9226 - Train Loss: 0.126112, Train Acc: 0.780769 | Val Loss: 0.141766, Val Acc: 0.690722\n",
      "Epoch 9227 - Train Loss: 0.126104, Train Acc: 0.780769 | Val Loss: 0.141759, Val Acc: 0.690722\n",
      "Epoch 9228 - Train Loss: 0.126095, Train Acc: 0.780769 | Val Loss: 0.141751, Val Acc: 0.690722\n",
      "Epoch 9229 - Train Loss: 0.126087, Train Acc: 0.780769 | Val Loss: 0.141744, Val Acc: 0.690722\n",
      "Epoch 9230 - Train Loss: 0.126079, Train Acc: 0.780769 | Val Loss: 0.141737, Val Acc: 0.690722\n",
      "Epoch 9231 - Train Loss: 0.126070, Train Acc: 0.780769 | Val Loss: 0.141729, Val Acc: 0.690722\n",
      "Epoch 9232 - Train Loss: 0.126062, Train Acc: 0.780769 | Val Loss: 0.141722, Val Acc: 0.690722\n",
      "Epoch 9233 - Train Loss: 0.126053, Train Acc: 0.780769 | Val Loss: 0.141715, Val Acc: 0.690722\n",
      "Epoch 9234 - Train Loss: 0.126045, Train Acc: 0.780769 | Val Loss: 0.141708, Val Acc: 0.690722\n",
      "Epoch 9235 - Train Loss: 0.126037, Train Acc: 0.780769 | Val Loss: 0.141700, Val Acc: 0.690722\n",
      "Epoch 9236 - Train Loss: 0.126028, Train Acc: 0.780769 | Val Loss: 0.141693, Val Acc: 0.690722\n",
      "Epoch 9237 - Train Loss: 0.126020, Train Acc: 0.780769 | Val Loss: 0.141686, Val Acc: 0.690722\n",
      "Epoch 9238 - Train Loss: 0.126011, Train Acc: 0.780769 | Val Loss: 0.141678, Val Acc: 0.690722\n",
      "Epoch 9239 - Train Loss: 0.126003, Train Acc: 0.780769 | Val Loss: 0.141671, Val Acc: 0.690722\n",
      "Epoch 9240 - Train Loss: 0.125995, Train Acc: 0.780769 | Val Loss: 0.141664, Val Acc: 0.690722\n",
      "Epoch 9241 - Train Loss: 0.125986, Train Acc: 0.780769 | Val Loss: 0.141656, Val Acc: 0.690722\n",
      "Epoch 9242 - Train Loss: 0.125978, Train Acc: 0.780769 | Val Loss: 0.141649, Val Acc: 0.690722\n",
      "Epoch 9243 - Train Loss: 0.125969, Train Acc: 0.780769 | Val Loss: 0.141642, Val Acc: 0.690722\n",
      "Epoch 9244 - Train Loss: 0.125961, Train Acc: 0.780769 | Val Loss: 0.141635, Val Acc: 0.690722\n",
      "Epoch 9245 - Train Loss: 0.125953, Train Acc: 0.780769 | Val Loss: 0.141627, Val Acc: 0.690722\n",
      "Epoch 9246 - Train Loss: 0.125944, Train Acc: 0.780769 | Val Loss: 0.141620, Val Acc: 0.690722\n",
      "Epoch 9247 - Train Loss: 0.125936, Train Acc: 0.780769 | Val Loss: 0.141613, Val Acc: 0.690722\n",
      "Epoch 9248 - Train Loss: 0.125927, Train Acc: 0.780769 | Val Loss: 0.141605, Val Acc: 0.690722\n",
      "Epoch 9249 - Train Loss: 0.125919, Train Acc: 0.780769 | Val Loss: 0.141598, Val Acc: 0.690722\n",
      "Epoch 9250 - Train Loss: 0.125911, Train Acc: 0.780769 | Val Loss: 0.141591, Val Acc: 0.690722\n",
      "Epoch 9251 - Train Loss: 0.125902, Train Acc: 0.780769 | Val Loss: 0.141583, Val Acc: 0.690722\n",
      "Epoch 9252 - Train Loss: 0.125894, Train Acc: 0.780769 | Val Loss: 0.141576, Val Acc: 0.690722\n",
      "Epoch 9253 - Train Loss: 0.125886, Train Acc: 0.780769 | Val Loss: 0.141569, Val Acc: 0.690722\n",
      "Epoch 9254 - Train Loss: 0.125877, Train Acc: 0.780769 | Val Loss: 0.141562, Val Acc: 0.690722\n",
      "Epoch 9255 - Train Loss: 0.125869, Train Acc: 0.780769 | Val Loss: 0.141554, Val Acc: 0.690722\n",
      "Epoch 9256 - Train Loss: 0.125860, Train Acc: 0.780769 | Val Loss: 0.141547, Val Acc: 0.690722\n",
      "Epoch 9257 - Train Loss: 0.125852, Train Acc: 0.780769 | Val Loss: 0.141540, Val Acc: 0.690722\n",
      "Epoch 9258 - Train Loss: 0.125844, Train Acc: 0.780769 | Val Loss: 0.141532, Val Acc: 0.690722\n",
      "Epoch 9259 - Train Loss: 0.125835, Train Acc: 0.780769 | Val Loss: 0.141525, Val Acc: 0.690722\n",
      "Epoch 9260 - Train Loss: 0.125827, Train Acc: 0.780769 | Val Loss: 0.141518, Val Acc: 0.690722\n",
      "Epoch 9261 - Train Loss: 0.125818, Train Acc: 0.780769 | Val Loss: 0.141511, Val Acc: 0.690722\n",
      "Epoch 9262 - Train Loss: 0.125810, Train Acc: 0.780769 | Val Loss: 0.141503, Val Acc: 0.690722\n",
      "Epoch 9263 - Train Loss: 0.125802, Train Acc: 0.780769 | Val Loss: 0.141496, Val Acc: 0.690722\n",
      "Epoch 9264 - Train Loss: 0.125793, Train Acc: 0.780769 | Val Loss: 0.141489, Val Acc: 0.690722\n",
      "Epoch 9265 - Train Loss: 0.125785, Train Acc: 0.780769 | Val Loss: 0.141481, Val Acc: 0.690722\n",
      "Epoch 9266 - Train Loss: 0.125777, Train Acc: 0.780769 | Val Loss: 0.141474, Val Acc: 0.690722\n",
      "Epoch 9267 - Train Loss: 0.125768, Train Acc: 0.780769 | Val Loss: 0.141467, Val Acc: 0.690722\n",
      "Epoch 9268 - Train Loss: 0.125760, Train Acc: 0.780769 | Val Loss: 0.141459, Val Acc: 0.690722\n",
      "Epoch 9269 - Train Loss: 0.125751, Train Acc: 0.780769 | Val Loss: 0.141452, Val Acc: 0.690722\n",
      "Epoch 9270 - Train Loss: 0.125743, Train Acc: 0.780769 | Val Loss: 0.141445, Val Acc: 0.690722\n",
      "Epoch 9271 - Train Loss: 0.125735, Train Acc: 0.780769 | Val Loss: 0.141438, Val Acc: 0.690722\n",
      "Epoch 9272 - Train Loss: 0.125726, Train Acc: 0.780769 | Val Loss: 0.141430, Val Acc: 0.690722\n",
      "Epoch 9273 - Train Loss: 0.125718, Train Acc: 0.780769 | Val Loss: 0.141423, Val Acc: 0.690722\n",
      "Epoch 9274 - Train Loss: 0.125710, Train Acc: 0.780769 | Val Loss: 0.141416, Val Acc: 0.690722\n",
      "Epoch 9275 - Train Loss: 0.125701, Train Acc: 0.780769 | Val Loss: 0.141409, Val Acc: 0.690722\n",
      "Epoch 9276 - Train Loss: 0.125693, Train Acc: 0.780769 | Val Loss: 0.141401, Val Acc: 0.690722\n",
      "Epoch 9277 - Train Loss: 0.125685, Train Acc: 0.780769 | Val Loss: 0.141394, Val Acc: 0.690722\n",
      "Epoch 9278 - Train Loss: 0.125676, Train Acc: 0.780769 | Val Loss: 0.141387, Val Acc: 0.690722\n",
      "Epoch 9279 - Train Loss: 0.125668, Train Acc: 0.780769 | Val Loss: 0.141379, Val Acc: 0.690722\n",
      "Epoch 9280 - Train Loss: 0.125660, Train Acc: 0.780769 | Val Loss: 0.141372, Val Acc: 0.690722\n",
      "Epoch 9281 - Train Loss: 0.125651, Train Acc: 0.780769 | Val Loss: 0.141365, Val Acc: 0.690722\n",
      "Epoch 9282 - Train Loss: 0.125643, Train Acc: 0.780769 | Val Loss: 0.141358, Val Acc: 0.690722\n",
      "Epoch 9283 - Train Loss: 0.125634, Train Acc: 0.780769 | Val Loss: 0.141350, Val Acc: 0.690722\n",
      "Epoch 9284 - Train Loss: 0.125626, Train Acc: 0.780769 | Val Loss: 0.141343, Val Acc: 0.690722\n",
      "Epoch 9285 - Train Loss: 0.125618, Train Acc: 0.780769 | Val Loss: 0.141336, Val Acc: 0.690722\n",
      "Epoch 9286 - Train Loss: 0.125609, Train Acc: 0.780769 | Val Loss: 0.141328, Val Acc: 0.690722\n",
      "Epoch 9287 - Train Loss: 0.125601, Train Acc: 0.780769 | Val Loss: 0.141321, Val Acc: 0.690722\n",
      "Epoch 9288 - Train Loss: 0.125593, Train Acc: 0.780769 | Val Loss: 0.141314, Val Acc: 0.690722\n",
      "Epoch 9289 - Train Loss: 0.125584, Train Acc: 0.780769 | Val Loss: 0.141307, Val Acc: 0.690722\n",
      "Epoch 9290 - Train Loss: 0.125576, Train Acc: 0.782051 | Val Loss: 0.141299, Val Acc: 0.690722\n",
      "Epoch 9291 - Train Loss: 0.125568, Train Acc: 0.782051 | Val Loss: 0.141292, Val Acc: 0.690722\n",
      "Epoch 9292 - Train Loss: 0.125559, Train Acc: 0.782051 | Val Loss: 0.141285, Val Acc: 0.690722\n",
      "Epoch 9293 - Train Loss: 0.125551, Train Acc: 0.782051 | Val Loss: 0.141278, Val Acc: 0.690722\n",
      "Epoch 9294 - Train Loss: 0.125543, Train Acc: 0.782051 | Val Loss: 0.141270, Val Acc: 0.690722\n",
      "Epoch 9295 - Train Loss: 0.125534, Train Acc: 0.782051 | Val Loss: 0.141263, Val Acc: 0.690722\n",
      "Epoch 9296 - Train Loss: 0.125526, Train Acc: 0.782051 | Val Loss: 0.141256, Val Acc: 0.690722\n",
      "Epoch 9297 - Train Loss: 0.125518, Train Acc: 0.782051 | Val Loss: 0.141249, Val Acc: 0.690722\n",
      "Epoch 9298 - Train Loss: 0.125509, Train Acc: 0.782051 | Val Loss: 0.141241, Val Acc: 0.690722\n",
      "Epoch 9299 - Train Loss: 0.125501, Train Acc: 0.782051 | Val Loss: 0.141234, Val Acc: 0.690722\n",
      "Epoch 9300 - Train Loss: 0.125493, Train Acc: 0.782051 | Val Loss: 0.141227, Val Acc: 0.690722\n",
      "Epoch 9301 - Train Loss: 0.125484, Train Acc: 0.782051 | Val Loss: 0.141220, Val Acc: 0.690722\n",
      "Epoch 9302 - Train Loss: 0.125476, Train Acc: 0.782051 | Val Loss: 0.141212, Val Acc: 0.690722\n",
      "Epoch 9303 - Train Loss: 0.125468, Train Acc: 0.782051 | Val Loss: 0.141205, Val Acc: 0.690722\n",
      "Epoch 9304 - Train Loss: 0.125459, Train Acc: 0.782051 | Val Loss: 0.141198, Val Acc: 0.690722\n",
      "Epoch 9305 - Train Loss: 0.125451, Train Acc: 0.782051 | Val Loss: 0.141191, Val Acc: 0.690722\n",
      "Epoch 9306 - Train Loss: 0.125443, Train Acc: 0.782051 | Val Loss: 0.141183, Val Acc: 0.690722\n",
      "Epoch 9307 - Train Loss: 0.125434, Train Acc: 0.782051 | Val Loss: 0.141176, Val Acc: 0.690722\n",
      "Epoch 9308 - Train Loss: 0.125426, Train Acc: 0.782051 | Val Loss: 0.141169, Val Acc: 0.690722\n",
      "Epoch 9309 - Train Loss: 0.125418, Train Acc: 0.782051 | Val Loss: 0.141162, Val Acc: 0.690722\n",
      "Epoch 9310 - Train Loss: 0.125409, Train Acc: 0.782051 | Val Loss: 0.141155, Val Acc: 0.690722\n",
      "Epoch 9311 - Train Loss: 0.125401, Train Acc: 0.782051 | Val Loss: 0.141147, Val Acc: 0.690722\n",
      "Epoch 9312 - Train Loss: 0.125393, Train Acc: 0.782051 | Val Loss: 0.141140, Val Acc: 0.690722\n",
      "Epoch 9313 - Train Loss: 0.125385, Train Acc: 0.782051 | Val Loss: 0.141133, Val Acc: 0.690722\n",
      "Epoch 9314 - Train Loss: 0.125376, Train Acc: 0.782051 | Val Loss: 0.141126, Val Acc: 0.690722\n",
      "Epoch 9315 - Train Loss: 0.125368, Train Acc: 0.782051 | Val Loss: 0.141118, Val Acc: 0.690722\n",
      "Epoch 9316 - Train Loss: 0.125360, Train Acc: 0.782051 | Val Loss: 0.141111, Val Acc: 0.690722\n",
      "Epoch 9317 - Train Loss: 0.125351, Train Acc: 0.782051 | Val Loss: 0.141104, Val Acc: 0.690722\n",
      "Epoch 9318 - Train Loss: 0.125343, Train Acc: 0.782051 | Val Loss: 0.141097, Val Acc: 0.690722\n",
      "Epoch 9319 - Train Loss: 0.125335, Train Acc: 0.782051 | Val Loss: 0.141090, Val Acc: 0.690722\n",
      "Epoch 9320 - Train Loss: 0.125326, Train Acc: 0.782051 | Val Loss: 0.141082, Val Acc: 0.690722\n",
      "Epoch 9321 - Train Loss: 0.125318, Train Acc: 0.782051 | Val Loss: 0.141075, Val Acc: 0.690722\n",
      "Epoch 9322 - Train Loss: 0.125310, Train Acc: 0.782051 | Val Loss: 0.141068, Val Acc: 0.690722\n",
      "Epoch 9323 - Train Loss: 0.125301, Train Acc: 0.782051 | Val Loss: 0.141061, Val Acc: 0.690722\n",
      "Epoch 9324 - Train Loss: 0.125293, Train Acc: 0.782051 | Val Loss: 0.141053, Val Acc: 0.690722\n",
      "Epoch 9325 - Train Loss: 0.125285, Train Acc: 0.782051 | Val Loss: 0.141046, Val Acc: 0.690722\n",
      "Epoch 9326 - Train Loss: 0.125277, Train Acc: 0.782051 | Val Loss: 0.141039, Val Acc: 0.690722\n",
      "Epoch 9327 - Train Loss: 0.125268, Train Acc: 0.782051 | Val Loss: 0.141032, Val Acc: 0.690722\n",
      "Epoch 9328 - Train Loss: 0.125260, Train Acc: 0.782051 | Val Loss: 0.141025, Val Acc: 0.690722\n",
      "Epoch 9329 - Train Loss: 0.125252, Train Acc: 0.782051 | Val Loss: 0.141017, Val Acc: 0.690722\n",
      "Epoch 9330 - Train Loss: 0.125243, Train Acc: 0.782051 | Val Loss: 0.141010, Val Acc: 0.690722\n",
      "Epoch 9331 - Train Loss: 0.125235, Train Acc: 0.782051 | Val Loss: 0.141003, Val Acc: 0.690722\n",
      "Epoch 9332 - Train Loss: 0.125227, Train Acc: 0.782051 | Val Loss: 0.140996, Val Acc: 0.690722\n",
      "Epoch 9333 - Train Loss: 0.125219, Train Acc: 0.782051 | Val Loss: 0.140989, Val Acc: 0.690722\n",
      "Epoch 9334 - Train Loss: 0.125210, Train Acc: 0.782051 | Val Loss: 0.140981, Val Acc: 0.690722\n",
      "Epoch 9335 - Train Loss: 0.125202, Train Acc: 0.782051 | Val Loss: 0.140974, Val Acc: 0.690722\n",
      "Epoch 9336 - Train Loss: 0.125194, Train Acc: 0.782051 | Val Loss: 0.140967, Val Acc: 0.690722\n",
      "Epoch 9337 - Train Loss: 0.125185, Train Acc: 0.782051 | Val Loss: 0.140960, Val Acc: 0.690722\n",
      "Epoch 9338 - Train Loss: 0.125177, Train Acc: 0.782051 | Val Loss: 0.140953, Val Acc: 0.690722\n",
      "Epoch 9339 - Train Loss: 0.125169, Train Acc: 0.782051 | Val Loss: 0.140945, Val Acc: 0.690722\n",
      "Epoch 9340 - Train Loss: 0.125161, Train Acc: 0.782051 | Val Loss: 0.140938, Val Acc: 0.690722\n",
      "Epoch 9341 - Train Loss: 0.125152, Train Acc: 0.782051 | Val Loss: 0.140931, Val Acc: 0.690722\n",
      "Epoch 9342 - Train Loss: 0.125144, Train Acc: 0.782051 | Val Loss: 0.140924, Val Acc: 0.690722\n",
      "Epoch 9343 - Train Loss: 0.125136, Train Acc: 0.782051 | Val Loss: 0.140917, Val Acc: 0.690722\n",
      "Epoch 9344 - Train Loss: 0.125127, Train Acc: 0.782051 | Val Loss: 0.140909, Val Acc: 0.690722\n",
      "Epoch 9345 - Train Loss: 0.125119, Train Acc: 0.782051 | Val Loss: 0.140902, Val Acc: 0.690722\n",
      "Epoch 9346 - Train Loss: 0.125111, Train Acc: 0.782051 | Val Loss: 0.140895, Val Acc: 0.690722\n",
      "Epoch 9347 - Train Loss: 0.125103, Train Acc: 0.782051 | Val Loss: 0.140888, Val Acc: 0.690722\n",
      "Epoch 9348 - Train Loss: 0.125094, Train Acc: 0.782051 | Val Loss: 0.140881, Val Acc: 0.690722\n",
      "Epoch 9349 - Train Loss: 0.125086, Train Acc: 0.782051 | Val Loss: 0.140874, Val Acc: 0.690722\n",
      "Epoch 9350 - Train Loss: 0.125078, Train Acc: 0.782051 | Val Loss: 0.140866, Val Acc: 0.690722\n",
      "Epoch 9351 - Train Loss: 0.125069, Train Acc: 0.782051 | Val Loss: 0.140859, Val Acc: 0.690722\n",
      "Epoch 9352 - Train Loss: 0.125061, Train Acc: 0.782051 | Val Loss: 0.140852, Val Acc: 0.690722\n",
      "Epoch 9353 - Train Loss: 0.125053, Train Acc: 0.782051 | Val Loss: 0.140845, Val Acc: 0.690722\n",
      "Epoch 9354 - Train Loss: 0.125045, Train Acc: 0.782051 | Val Loss: 0.140838, Val Acc: 0.690722\n",
      "Epoch 9355 - Train Loss: 0.125036, Train Acc: 0.782051 | Val Loss: 0.140830, Val Acc: 0.690722\n",
      "Epoch 9356 - Train Loss: 0.125028, Train Acc: 0.782051 | Val Loss: 0.140823, Val Acc: 0.690722\n",
      "Epoch 9357 - Train Loss: 0.125020, Train Acc: 0.782051 | Val Loss: 0.140816, Val Acc: 0.690722\n",
      "Epoch 9358 - Train Loss: 0.125012, Train Acc: 0.782051 | Val Loss: 0.140809, Val Acc: 0.690722\n",
      "Epoch 9359 - Train Loss: 0.125003, Train Acc: 0.782051 | Val Loss: 0.140802, Val Acc: 0.690722\n",
      "Epoch 9360 - Train Loss: 0.124995, Train Acc: 0.782051 | Val Loss: 0.140794, Val Acc: 0.690722\n",
      "Epoch 9361 - Train Loss: 0.124987, Train Acc: 0.782051 | Val Loss: 0.140787, Val Acc: 0.690722\n",
      "Epoch 9362 - Train Loss: 0.124979, Train Acc: 0.782051 | Val Loss: 0.140780, Val Acc: 0.690722\n",
      "Epoch 9363 - Train Loss: 0.124970, Train Acc: 0.782051 | Val Loss: 0.140773, Val Acc: 0.690722\n",
      "Epoch 9364 - Train Loss: 0.124962, Train Acc: 0.782051 | Val Loss: 0.140766, Val Acc: 0.690722\n",
      "Epoch 9365 - Train Loss: 0.124954, Train Acc: 0.780769 | Val Loss: 0.140759, Val Acc: 0.690722\n",
      "Epoch 9366 - Train Loss: 0.124946, Train Acc: 0.780769 | Val Loss: 0.140751, Val Acc: 0.690722\n",
      "Epoch 9367 - Train Loss: 0.124937, Train Acc: 0.780769 | Val Loss: 0.140744, Val Acc: 0.690722\n",
      "Epoch 9368 - Train Loss: 0.124929, Train Acc: 0.780769 | Val Loss: 0.140737, Val Acc: 0.690722\n",
      "Epoch 9369 - Train Loss: 0.124921, Train Acc: 0.780769 | Val Loss: 0.140730, Val Acc: 0.690722\n",
      "Epoch 9370 - Train Loss: 0.124913, Train Acc: 0.780769 | Val Loss: 0.140723, Val Acc: 0.690722\n",
      "Epoch 9371 - Train Loss: 0.124904, Train Acc: 0.780769 | Val Loss: 0.140716, Val Acc: 0.690722\n",
      "Epoch 9372 - Train Loss: 0.124896, Train Acc: 0.780769 | Val Loss: 0.140708, Val Acc: 0.690722\n",
      "Epoch 9373 - Train Loss: 0.124888, Train Acc: 0.780769 | Val Loss: 0.140701, Val Acc: 0.690722\n",
      "Epoch 9374 - Train Loss: 0.124880, Train Acc: 0.780769 | Val Loss: 0.140694, Val Acc: 0.690722\n",
      "Epoch 9375 - Train Loss: 0.124871, Train Acc: 0.780769 | Val Loss: 0.140687, Val Acc: 0.690722\n",
      "Epoch 9376 - Train Loss: 0.124863, Train Acc: 0.780769 | Val Loss: 0.140680, Val Acc: 0.690722\n",
      "Epoch 9377 - Train Loss: 0.124855, Train Acc: 0.780769 | Val Loss: 0.140673, Val Acc: 0.690722\n",
      "Epoch 9378 - Train Loss: 0.124847, Train Acc: 0.780769 | Val Loss: 0.140665, Val Acc: 0.690722\n",
      "Epoch 9379 - Train Loss: 0.124838, Train Acc: 0.782051 | Val Loss: 0.140658, Val Acc: 0.690722\n",
      "Epoch 9380 - Train Loss: 0.124830, Train Acc: 0.782051 | Val Loss: 0.140651, Val Acc: 0.690722\n",
      "Epoch 9381 - Train Loss: 0.124822, Train Acc: 0.782051 | Val Loss: 0.140644, Val Acc: 0.690722\n",
      "Epoch 9382 - Train Loss: 0.124814, Train Acc: 0.782051 | Val Loss: 0.140637, Val Acc: 0.690722\n",
      "Epoch 9383 - Train Loss: 0.124805, Train Acc: 0.783333 | Val Loss: 0.140630, Val Acc: 0.690722\n",
      "Epoch 9384 - Train Loss: 0.124797, Train Acc: 0.783333 | Val Loss: 0.140623, Val Acc: 0.690722\n",
      "Epoch 9385 - Train Loss: 0.124789, Train Acc: 0.783333 | Val Loss: 0.140616, Val Acc: 0.690722\n",
      "Epoch 9386 - Train Loss: 0.124781, Train Acc: 0.783333 | Val Loss: 0.140608, Val Acc: 0.690722\n",
      "Epoch 9387 - Train Loss: 0.124773, Train Acc: 0.783333 | Val Loss: 0.140601, Val Acc: 0.690722\n",
      "Epoch 9388 - Train Loss: 0.124764, Train Acc: 0.783333 | Val Loss: 0.140594, Val Acc: 0.690722\n",
      "Epoch 9389 - Train Loss: 0.124756, Train Acc: 0.783333 | Val Loss: 0.140587, Val Acc: 0.690722\n",
      "Epoch 9390 - Train Loss: 0.124748, Train Acc: 0.783333 | Val Loss: 0.140580, Val Acc: 0.690722\n",
      "Epoch 9391 - Train Loss: 0.124740, Train Acc: 0.783333 | Val Loss: 0.140573, Val Acc: 0.690722\n",
      "Epoch 9392 - Train Loss: 0.124731, Train Acc: 0.783333 | Val Loss: 0.140566, Val Acc: 0.690722\n",
      "Epoch 9393 - Train Loss: 0.124723, Train Acc: 0.783333 | Val Loss: 0.140559, Val Acc: 0.690722\n",
      "Epoch 9394 - Train Loss: 0.124715, Train Acc: 0.783333 | Val Loss: 0.140552, Val Acc: 0.690722\n",
      "Epoch 9395 - Train Loss: 0.124707, Train Acc: 0.783333 | Val Loss: 0.140544, Val Acc: 0.690722\n",
      "Epoch 9396 - Train Loss: 0.124699, Train Acc: 0.783333 | Val Loss: 0.140537, Val Acc: 0.690722\n",
      "Epoch 9397 - Train Loss: 0.124690, Train Acc: 0.783333 | Val Loss: 0.140530, Val Acc: 0.690722\n",
      "Epoch 9398 - Train Loss: 0.124682, Train Acc: 0.783333 | Val Loss: 0.140523, Val Acc: 0.690722\n",
      "Epoch 9399 - Train Loss: 0.124674, Train Acc: 0.783333 | Val Loss: 0.140516, Val Acc: 0.690722\n",
      "Epoch 9400 - Train Loss: 0.124666, Train Acc: 0.783333 | Val Loss: 0.140509, Val Acc: 0.690722\n",
      "Epoch 9401 - Train Loss: 0.124658, Train Acc: 0.783333 | Val Loss: 0.140502, Val Acc: 0.690722\n",
      "Epoch 9402 - Train Loss: 0.124649, Train Acc: 0.783333 | Val Loss: 0.140495, Val Acc: 0.690722\n",
      "Epoch 9403 - Train Loss: 0.124641, Train Acc: 0.783333 | Val Loss: 0.140488, Val Acc: 0.690722\n",
      "Epoch 9404 - Train Loss: 0.124633, Train Acc: 0.783333 | Val Loss: 0.140481, Val Acc: 0.690722\n",
      "Epoch 9405 - Train Loss: 0.124625, Train Acc: 0.783333 | Val Loss: 0.140473, Val Acc: 0.690722\n",
      "Epoch 9406 - Train Loss: 0.124617, Train Acc: 0.783333 | Val Loss: 0.140466, Val Acc: 0.690722\n",
      "Epoch 9407 - Train Loss: 0.124608, Train Acc: 0.783333 | Val Loss: 0.140459, Val Acc: 0.690722\n",
      "Epoch 9408 - Train Loss: 0.124600, Train Acc: 0.783333 | Val Loss: 0.140452, Val Acc: 0.690722\n",
      "Epoch 9409 - Train Loss: 0.124592, Train Acc: 0.783333 | Val Loss: 0.140445, Val Acc: 0.690722\n",
      "Epoch 9410 - Train Loss: 0.124584, Train Acc: 0.783333 | Val Loss: 0.140438, Val Acc: 0.690722\n",
      "Epoch 9411 - Train Loss: 0.124576, Train Acc: 0.783333 | Val Loss: 0.140431, Val Acc: 0.690722\n",
      "Epoch 9412 - Train Loss: 0.124567, Train Acc: 0.783333 | Val Loss: 0.140424, Val Acc: 0.690722\n",
      "Epoch 9413 - Train Loss: 0.124559, Train Acc: 0.783333 | Val Loss: 0.140417, Val Acc: 0.690722\n",
      "Epoch 9414 - Train Loss: 0.124551, Train Acc: 0.783333 | Val Loss: 0.140410, Val Acc: 0.690722\n",
      "Epoch 9415 - Train Loss: 0.124543, Train Acc: 0.783333 | Val Loss: 0.140403, Val Acc: 0.690722\n",
      "Epoch 9416 - Train Loss: 0.124535, Train Acc: 0.783333 | Val Loss: 0.140396, Val Acc: 0.690722\n",
      "Epoch 9417 - Train Loss: 0.124527, Train Acc: 0.783333 | Val Loss: 0.140389, Val Acc: 0.690722\n",
      "Epoch 9418 - Train Loss: 0.124518, Train Acc: 0.783333 | Val Loss: 0.140381, Val Acc: 0.690722\n",
      "Epoch 9419 - Train Loss: 0.124510, Train Acc: 0.783333 | Val Loss: 0.140374, Val Acc: 0.690722\n",
      "Epoch 9420 - Train Loss: 0.124502, Train Acc: 0.783333 | Val Loss: 0.140367, Val Acc: 0.690722\n",
      "Epoch 9421 - Train Loss: 0.124494, Train Acc: 0.783333 | Val Loss: 0.140360, Val Acc: 0.690722\n",
      "Epoch 9422 - Train Loss: 0.124486, Train Acc: 0.783333 | Val Loss: 0.140353, Val Acc: 0.690722\n",
      "Epoch 9423 - Train Loss: 0.124477, Train Acc: 0.783333 | Val Loss: 0.140346, Val Acc: 0.690722\n",
      "Epoch 9424 - Train Loss: 0.124469, Train Acc: 0.783333 | Val Loss: 0.140339, Val Acc: 0.690722\n",
      "Epoch 9425 - Train Loss: 0.124461, Train Acc: 0.783333 | Val Loss: 0.140332, Val Acc: 0.690722\n",
      "Epoch 9426 - Train Loss: 0.124453, Train Acc: 0.783333 | Val Loss: 0.140325, Val Acc: 0.690722\n",
      "Epoch 9427 - Train Loss: 0.124445, Train Acc: 0.783333 | Val Loss: 0.140318, Val Acc: 0.690722\n",
      "Epoch 9428 - Train Loss: 0.124437, Train Acc: 0.783333 | Val Loss: 0.140311, Val Acc: 0.701031\n",
      "Epoch 9429 - Train Loss: 0.124428, Train Acc: 0.783333 | Val Loss: 0.140304, Val Acc: 0.701031\n",
      "Epoch 9430 - Train Loss: 0.124420, Train Acc: 0.783333 | Val Loss: 0.140297, Val Acc: 0.701031\n",
      "Epoch 9431 - Train Loss: 0.124412, Train Acc: 0.783333 | Val Loss: 0.140290, Val Acc: 0.701031\n",
      "Epoch 9432 - Train Loss: 0.124404, Train Acc: 0.783333 | Val Loss: 0.140283, Val Acc: 0.701031\n",
      "Epoch 9433 - Train Loss: 0.124396, Train Acc: 0.783333 | Val Loss: 0.140276, Val Acc: 0.701031\n",
      "Epoch 9434 - Train Loss: 0.124388, Train Acc: 0.783333 | Val Loss: 0.140268, Val Acc: 0.701031\n",
      "Epoch 9435 - Train Loss: 0.124379, Train Acc: 0.783333 | Val Loss: 0.140261, Val Acc: 0.701031\n",
      "Epoch 9436 - Train Loss: 0.124371, Train Acc: 0.783333 | Val Loss: 0.140254, Val Acc: 0.701031\n",
      "Epoch 9437 - Train Loss: 0.124363, Train Acc: 0.783333 | Val Loss: 0.140247, Val Acc: 0.701031\n",
      "Epoch 9438 - Train Loss: 0.124355, Train Acc: 0.783333 | Val Loss: 0.140240, Val Acc: 0.701031\n",
      "Epoch 9439 - Train Loss: 0.124347, Train Acc: 0.783333 | Val Loss: 0.140233, Val Acc: 0.701031\n",
      "Epoch 9440 - Train Loss: 0.124339, Train Acc: 0.783333 | Val Loss: 0.140226, Val Acc: 0.701031\n",
      "Epoch 9441 - Train Loss: 0.124330, Train Acc: 0.783333 | Val Loss: 0.140219, Val Acc: 0.701031\n",
      "Epoch 9442 - Train Loss: 0.124322, Train Acc: 0.783333 | Val Loss: 0.140212, Val Acc: 0.701031\n",
      "Epoch 9443 - Train Loss: 0.124314, Train Acc: 0.783333 | Val Loss: 0.140205, Val Acc: 0.701031\n",
      "Epoch 9444 - Train Loss: 0.124306, Train Acc: 0.784615 | Val Loss: 0.140198, Val Acc: 0.701031\n",
      "Epoch 9445 - Train Loss: 0.124298, Train Acc: 0.784615 | Val Loss: 0.140191, Val Acc: 0.701031\n",
      "Epoch 9446 - Train Loss: 0.124290, Train Acc: 0.784615 | Val Loss: 0.140184, Val Acc: 0.701031\n",
      "Epoch 9447 - Train Loss: 0.124282, Train Acc: 0.784615 | Val Loss: 0.140177, Val Acc: 0.701031\n",
      "Epoch 9448 - Train Loss: 0.124273, Train Acc: 0.784615 | Val Loss: 0.140170, Val Acc: 0.701031\n",
      "Epoch 9449 - Train Loss: 0.124265, Train Acc: 0.784615 | Val Loss: 0.140163, Val Acc: 0.701031\n",
      "Epoch 9450 - Train Loss: 0.124257, Train Acc: 0.784615 | Val Loss: 0.140156, Val Acc: 0.701031\n",
      "Epoch 9451 - Train Loss: 0.124249, Train Acc: 0.784615 | Val Loss: 0.140149, Val Acc: 0.701031\n",
      "Epoch 9452 - Train Loss: 0.124241, Train Acc: 0.784615 | Val Loss: 0.140142, Val Acc: 0.701031\n",
      "Epoch 9453 - Train Loss: 0.124233, Train Acc: 0.784615 | Val Loss: 0.140134, Val Acc: 0.701031\n",
      "Epoch 9454 - Train Loss: 0.124225, Train Acc: 0.784615 | Val Loss: 0.140127, Val Acc: 0.701031\n",
      "Epoch 9455 - Train Loss: 0.124216, Train Acc: 0.784615 | Val Loss: 0.140120, Val Acc: 0.701031\n",
      "Epoch 9456 - Train Loss: 0.124208, Train Acc: 0.784615 | Val Loss: 0.140113, Val Acc: 0.701031\n",
      "Epoch 9457 - Train Loss: 0.124200, Train Acc: 0.784615 | Val Loss: 0.140106, Val Acc: 0.701031\n",
      "Epoch 9458 - Train Loss: 0.124192, Train Acc: 0.784615 | Val Loss: 0.140099, Val Acc: 0.701031\n",
      "Epoch 9459 - Train Loss: 0.124184, Train Acc: 0.784615 | Val Loss: 0.140092, Val Acc: 0.701031\n",
      "Epoch 9460 - Train Loss: 0.124176, Train Acc: 0.784615 | Val Loss: 0.140085, Val Acc: 0.701031\n",
      "Epoch 9461 - Train Loss: 0.124168, Train Acc: 0.784615 | Val Loss: 0.140078, Val Acc: 0.701031\n",
      "Epoch 9462 - Train Loss: 0.124160, Train Acc: 0.784615 | Val Loss: 0.140071, Val Acc: 0.701031\n",
      "Epoch 9463 - Train Loss: 0.124151, Train Acc: 0.784615 | Val Loss: 0.140064, Val Acc: 0.701031\n",
      "Epoch 9464 - Train Loss: 0.124143, Train Acc: 0.784615 | Val Loss: 0.140057, Val Acc: 0.701031\n",
      "Epoch 9465 - Train Loss: 0.124135, Train Acc: 0.784615 | Val Loss: 0.140050, Val Acc: 0.701031\n",
      "Epoch 9466 - Train Loss: 0.124127, Train Acc: 0.784615 | Val Loss: 0.140043, Val Acc: 0.701031\n",
      "Epoch 9467 - Train Loss: 0.124119, Train Acc: 0.784615 | Val Loss: 0.140036, Val Acc: 0.701031\n",
      "Epoch 9468 - Train Loss: 0.124111, Train Acc: 0.784615 | Val Loss: 0.140029, Val Acc: 0.701031\n",
      "Epoch 9469 - Train Loss: 0.124103, Train Acc: 0.784615 | Val Loss: 0.140022, Val Acc: 0.701031\n",
      "Epoch 9470 - Train Loss: 0.124095, Train Acc: 0.784615 | Val Loss: 0.140015, Val Acc: 0.701031\n",
      "Epoch 9471 - Train Loss: 0.124086, Train Acc: 0.784615 | Val Loss: 0.140008, Val Acc: 0.701031\n",
      "Epoch 9472 - Train Loss: 0.124078, Train Acc: 0.784615 | Val Loss: 0.140001, Val Acc: 0.701031\n",
      "Epoch 9473 - Train Loss: 0.124070, Train Acc: 0.784615 | Val Loss: 0.139994, Val Acc: 0.701031\n",
      "Epoch 9474 - Train Loss: 0.124062, Train Acc: 0.784615 | Val Loss: 0.139987, Val Acc: 0.701031\n",
      "Epoch 9475 - Train Loss: 0.124054, Train Acc: 0.784615 | Val Loss: 0.139980, Val Acc: 0.701031\n",
      "Epoch 9476 - Train Loss: 0.124046, Train Acc: 0.784615 | Val Loss: 0.139972, Val Acc: 0.701031\n",
      "Epoch 9477 - Train Loss: 0.124038, Train Acc: 0.784615 | Val Loss: 0.139965, Val Acc: 0.701031\n",
      "Epoch 9478 - Train Loss: 0.124030, Train Acc: 0.784615 | Val Loss: 0.139958, Val Acc: 0.701031\n",
      "Epoch 9479 - Train Loss: 0.124022, Train Acc: 0.784615 | Val Loss: 0.139951, Val Acc: 0.701031\n",
      "Epoch 9480 - Train Loss: 0.124013, Train Acc: 0.785897 | Val Loss: 0.139944, Val Acc: 0.701031\n",
      "Epoch 9481 - Train Loss: 0.124005, Train Acc: 0.785897 | Val Loss: 0.139937, Val Acc: 0.701031\n",
      "Epoch 9482 - Train Loss: 0.123997, Train Acc: 0.785897 | Val Loss: 0.139930, Val Acc: 0.701031\n",
      "Epoch 9483 - Train Loss: 0.123989, Train Acc: 0.785897 | Val Loss: 0.139923, Val Acc: 0.701031\n",
      "Epoch 9484 - Train Loss: 0.123981, Train Acc: 0.785897 | Val Loss: 0.139916, Val Acc: 0.701031\n",
      "Epoch 9485 - Train Loss: 0.123973, Train Acc: 0.785897 | Val Loss: 0.139909, Val Acc: 0.701031\n",
      "Epoch 9486 - Train Loss: 0.123965, Train Acc: 0.785897 | Val Loss: 0.139902, Val Acc: 0.701031\n",
      "Epoch 9487 - Train Loss: 0.123957, Train Acc: 0.785897 | Val Loss: 0.139895, Val Acc: 0.701031\n",
      "Epoch 9488 - Train Loss: 0.123949, Train Acc: 0.785897 | Val Loss: 0.139888, Val Acc: 0.701031\n",
      "Epoch 9489 - Train Loss: 0.123941, Train Acc: 0.785897 | Val Loss: 0.139881, Val Acc: 0.701031\n",
      "Epoch 9490 - Train Loss: 0.123932, Train Acc: 0.785897 | Val Loss: 0.139874, Val Acc: 0.701031\n",
      "Epoch 9491 - Train Loss: 0.123924, Train Acc: 0.785897 | Val Loss: 0.139867, Val Acc: 0.701031\n",
      "Epoch 9492 - Train Loss: 0.123916, Train Acc: 0.785897 | Val Loss: 0.139860, Val Acc: 0.701031\n",
      "Epoch 9493 - Train Loss: 0.123908, Train Acc: 0.785897 | Val Loss: 0.139853, Val Acc: 0.701031\n",
      "Epoch 9494 - Train Loss: 0.123900, Train Acc: 0.785897 | Val Loss: 0.139846, Val Acc: 0.701031\n",
      "Epoch 9495 - Train Loss: 0.123892, Train Acc: 0.784615 | Val Loss: 0.139839, Val Acc: 0.701031\n",
      "Epoch 9496 - Train Loss: 0.123884, Train Acc: 0.784615 | Val Loss: 0.139832, Val Acc: 0.701031\n",
      "Epoch 9497 - Train Loss: 0.123876, Train Acc: 0.784615 | Val Loss: 0.139825, Val Acc: 0.701031\n",
      "Epoch 9498 - Train Loss: 0.123868, Train Acc: 0.784615 | Val Loss: 0.139818, Val Acc: 0.701031\n",
      "Epoch 9499 - Train Loss: 0.123860, Train Acc: 0.784615 | Val Loss: 0.139811, Val Acc: 0.701031\n",
      "Epoch 9500 - Train Loss: 0.123852, Train Acc: 0.784615 | Val Loss: 0.139804, Val Acc: 0.701031\n",
      "Epoch 9501 - Train Loss: 0.123843, Train Acc: 0.784615 | Val Loss: 0.139797, Val Acc: 0.701031\n",
      "Epoch 9502 - Train Loss: 0.123835, Train Acc: 0.784615 | Val Loss: 0.139790, Val Acc: 0.701031\n",
      "Epoch 9503 - Train Loss: 0.123827, Train Acc: 0.784615 | Val Loss: 0.139783, Val Acc: 0.701031\n",
      "Epoch 9504 - Train Loss: 0.123819, Train Acc: 0.784615 | Val Loss: 0.139776, Val Acc: 0.701031\n",
      "Epoch 9505 - Train Loss: 0.123811, Train Acc: 0.784615 | Val Loss: 0.139769, Val Acc: 0.701031\n",
      "Epoch 9506 - Train Loss: 0.123803, Train Acc: 0.784615 | Val Loss: 0.139762, Val Acc: 0.701031\n",
      "Epoch 9507 - Train Loss: 0.123795, Train Acc: 0.784615 | Val Loss: 0.139755, Val Acc: 0.701031\n",
      "Epoch 9508 - Train Loss: 0.123787, Train Acc: 0.784615 | Val Loss: 0.139748, Val Acc: 0.701031\n",
      "Epoch 9509 - Train Loss: 0.123779, Train Acc: 0.784615 | Val Loss: 0.139741, Val Acc: 0.701031\n",
      "Epoch 9510 - Train Loss: 0.123771, Train Acc: 0.784615 | Val Loss: 0.139734, Val Acc: 0.701031\n",
      "Epoch 9511 - Train Loss: 0.123763, Train Acc: 0.784615 | Val Loss: 0.139727, Val Acc: 0.701031\n",
      "Epoch 9512 - Train Loss: 0.123755, Train Acc: 0.784615 | Val Loss: 0.139720, Val Acc: 0.701031\n",
      "Epoch 9513 - Train Loss: 0.123747, Train Acc: 0.784615 | Val Loss: 0.139713, Val Acc: 0.701031\n",
      "Epoch 9514 - Train Loss: 0.123739, Train Acc: 0.784615 | Val Loss: 0.139706, Val Acc: 0.701031\n",
      "Epoch 9515 - Train Loss: 0.123730, Train Acc: 0.784615 | Val Loss: 0.139699, Val Acc: 0.701031\n",
      "Epoch 9516 - Train Loss: 0.123722, Train Acc: 0.784615 | Val Loss: 0.139692, Val Acc: 0.701031\n",
      "Epoch 9517 - Train Loss: 0.123714, Train Acc: 0.784615 | Val Loss: 0.139685, Val Acc: 0.701031\n",
      "Epoch 9518 - Train Loss: 0.123706, Train Acc: 0.784615 | Val Loss: 0.139679, Val Acc: 0.701031\n",
      "Epoch 9519 - Train Loss: 0.123698, Train Acc: 0.784615 | Val Loss: 0.139672, Val Acc: 0.701031\n",
      "Epoch 9520 - Train Loss: 0.123690, Train Acc: 0.784615 | Val Loss: 0.139665, Val Acc: 0.701031\n",
      "Epoch 9521 - Train Loss: 0.123682, Train Acc: 0.784615 | Val Loss: 0.139658, Val Acc: 0.701031\n",
      "Epoch 9522 - Train Loss: 0.123674, Train Acc: 0.784615 | Val Loss: 0.139651, Val Acc: 0.701031\n",
      "Epoch 9523 - Train Loss: 0.123666, Train Acc: 0.784615 | Val Loss: 0.139644, Val Acc: 0.701031\n",
      "Epoch 9524 - Train Loss: 0.123658, Train Acc: 0.784615 | Val Loss: 0.139637, Val Acc: 0.701031\n",
      "Epoch 9525 - Train Loss: 0.123650, Train Acc: 0.784615 | Val Loss: 0.139630, Val Acc: 0.701031\n",
      "Epoch 9526 - Train Loss: 0.123642, Train Acc: 0.784615 | Val Loss: 0.139623, Val Acc: 0.701031\n",
      "Epoch 9527 - Train Loss: 0.123634, Train Acc: 0.784615 | Val Loss: 0.139616, Val Acc: 0.701031\n",
      "Epoch 9528 - Train Loss: 0.123626, Train Acc: 0.784615 | Val Loss: 0.139609, Val Acc: 0.701031\n",
      "Epoch 9529 - Train Loss: 0.123618, Train Acc: 0.784615 | Val Loss: 0.139602, Val Acc: 0.701031\n",
      "Epoch 9530 - Train Loss: 0.123610, Train Acc: 0.784615 | Val Loss: 0.139595, Val Acc: 0.701031\n",
      "Epoch 9531 - Train Loss: 0.123602, Train Acc: 0.784615 | Val Loss: 0.139588, Val Acc: 0.701031\n",
      "Epoch 9532 - Train Loss: 0.123593, Train Acc: 0.784615 | Val Loss: 0.139581, Val Acc: 0.701031\n",
      "Epoch 9533 - Train Loss: 0.123585, Train Acc: 0.784615 | Val Loss: 0.139574, Val Acc: 0.701031\n",
      "Epoch 9534 - Train Loss: 0.123577, Train Acc: 0.784615 | Val Loss: 0.139567, Val Acc: 0.701031\n",
      "Epoch 9535 - Train Loss: 0.123569, Train Acc: 0.784615 | Val Loss: 0.139560, Val Acc: 0.701031\n",
      "Epoch 9536 - Train Loss: 0.123561, Train Acc: 0.784615 | Val Loss: 0.139553, Val Acc: 0.701031\n",
      "Epoch 9537 - Train Loss: 0.123553, Train Acc: 0.784615 | Val Loss: 0.139546, Val Acc: 0.701031\n",
      "Epoch 9538 - Train Loss: 0.123545, Train Acc: 0.784615 | Val Loss: 0.139539, Val Acc: 0.701031\n",
      "Epoch 9539 - Train Loss: 0.123537, Train Acc: 0.784615 | Val Loss: 0.139532, Val Acc: 0.701031\n",
      "Epoch 9540 - Train Loss: 0.123529, Train Acc: 0.784615 | Val Loss: 0.139525, Val Acc: 0.701031\n",
      "Epoch 9541 - Train Loss: 0.123521, Train Acc: 0.784615 | Val Loss: 0.139518, Val Acc: 0.701031\n",
      "Epoch 9542 - Train Loss: 0.123513, Train Acc: 0.784615 | Val Loss: 0.139511, Val Acc: 0.701031\n",
      "Epoch 9543 - Train Loss: 0.123505, Train Acc: 0.784615 | Val Loss: 0.139504, Val Acc: 0.701031\n",
      "Epoch 9544 - Train Loss: 0.123497, Train Acc: 0.784615 | Val Loss: 0.139497, Val Acc: 0.701031\n",
      "Epoch 9545 - Train Loss: 0.123489, Train Acc: 0.784615 | Val Loss: 0.139490, Val Acc: 0.701031\n",
      "Epoch 9546 - Train Loss: 0.123481, Train Acc: 0.784615 | Val Loss: 0.139484, Val Acc: 0.701031\n",
      "Epoch 9547 - Train Loss: 0.123473, Train Acc: 0.784615 | Val Loss: 0.139477, Val Acc: 0.701031\n",
      "Epoch 9548 - Train Loss: 0.123465, Train Acc: 0.784615 | Val Loss: 0.139470, Val Acc: 0.701031\n",
      "Epoch 9549 - Train Loss: 0.123457, Train Acc: 0.784615 | Val Loss: 0.139463, Val Acc: 0.701031\n",
      "Epoch 9550 - Train Loss: 0.123449, Train Acc: 0.784615 | Val Loss: 0.139456, Val Acc: 0.701031\n",
      "Epoch 9551 - Train Loss: 0.123441, Train Acc: 0.784615 | Val Loss: 0.139449, Val Acc: 0.701031\n",
      "Epoch 9552 - Train Loss: 0.123433, Train Acc: 0.784615 | Val Loss: 0.139442, Val Acc: 0.701031\n",
      "Epoch 9553 - Train Loss: 0.123425, Train Acc: 0.784615 | Val Loss: 0.139435, Val Acc: 0.701031\n",
      "Epoch 9554 - Train Loss: 0.123417, Train Acc: 0.784615 | Val Loss: 0.139428, Val Acc: 0.701031\n",
      "Epoch 9555 - Train Loss: 0.123409, Train Acc: 0.784615 | Val Loss: 0.139421, Val Acc: 0.701031\n",
      "Epoch 9556 - Train Loss: 0.123401, Train Acc: 0.784615 | Val Loss: 0.139414, Val Acc: 0.701031\n",
      "Epoch 9557 - Train Loss: 0.123393, Train Acc: 0.784615 | Val Loss: 0.139407, Val Acc: 0.701031\n",
      "Epoch 9558 - Train Loss: 0.123385, Train Acc: 0.784615 | Val Loss: 0.139400, Val Acc: 0.701031\n",
      "Epoch 9559 - Train Loss: 0.123377, Train Acc: 0.784615 | Val Loss: 0.139393, Val Acc: 0.701031\n",
      "Epoch 9560 - Train Loss: 0.123369, Train Acc: 0.784615 | Val Loss: 0.139386, Val Acc: 0.701031\n",
      "Epoch 9561 - Train Loss: 0.123361, Train Acc: 0.784615 | Val Loss: 0.139380, Val Acc: 0.701031\n",
      "Epoch 9562 - Train Loss: 0.123353, Train Acc: 0.784615 | Val Loss: 0.139373, Val Acc: 0.701031\n",
      "Epoch 9563 - Train Loss: 0.123345, Train Acc: 0.784615 | Val Loss: 0.139366, Val Acc: 0.701031\n",
      "Epoch 9564 - Train Loss: 0.123337, Train Acc: 0.784615 | Val Loss: 0.139359, Val Acc: 0.701031\n",
      "Epoch 9565 - Train Loss: 0.123329, Train Acc: 0.784615 | Val Loss: 0.139352, Val Acc: 0.701031\n",
      "Epoch 9566 - Train Loss: 0.123321, Train Acc: 0.784615 | Val Loss: 0.139345, Val Acc: 0.701031\n",
      "Epoch 9567 - Train Loss: 0.123313, Train Acc: 0.784615 | Val Loss: 0.139338, Val Acc: 0.701031\n",
      "Epoch 9568 - Train Loss: 0.123305, Train Acc: 0.784615 | Val Loss: 0.139331, Val Acc: 0.701031\n",
      "Epoch 9569 - Train Loss: 0.123297, Train Acc: 0.784615 | Val Loss: 0.139324, Val Acc: 0.701031\n",
      "Epoch 9570 - Train Loss: 0.123289, Train Acc: 0.784615 | Val Loss: 0.139317, Val Acc: 0.701031\n",
      "Epoch 9571 - Train Loss: 0.123280, Train Acc: 0.784615 | Val Loss: 0.139310, Val Acc: 0.701031\n",
      "Epoch 9572 - Train Loss: 0.123272, Train Acc: 0.784615 | Val Loss: 0.139303, Val Acc: 0.701031\n",
      "Epoch 9573 - Train Loss: 0.123264, Train Acc: 0.784615 | Val Loss: 0.139296, Val Acc: 0.701031\n",
      "Epoch 9574 - Train Loss: 0.123256, Train Acc: 0.784615 | Val Loss: 0.139289, Val Acc: 0.701031\n",
      "Epoch 9575 - Train Loss: 0.123248, Train Acc: 0.784615 | Val Loss: 0.139282, Val Acc: 0.701031\n",
      "Epoch 9576 - Train Loss: 0.123240, Train Acc: 0.784615 | Val Loss: 0.139276, Val Acc: 0.701031\n",
      "Epoch 9577 - Train Loss: 0.123232, Train Acc: 0.784615 | Val Loss: 0.139269, Val Acc: 0.701031\n",
      "Epoch 9578 - Train Loss: 0.123224, Train Acc: 0.784615 | Val Loss: 0.139262, Val Acc: 0.701031\n",
      "Epoch 9579 - Train Loss: 0.123216, Train Acc: 0.784615 | Val Loss: 0.139255, Val Acc: 0.701031\n",
      "Epoch 9580 - Train Loss: 0.123209, Train Acc: 0.784615 | Val Loss: 0.139248, Val Acc: 0.701031\n",
      "Epoch 9581 - Train Loss: 0.123201, Train Acc: 0.784615 | Val Loss: 0.139241, Val Acc: 0.701031\n",
      "Epoch 9582 - Train Loss: 0.123193, Train Acc: 0.784615 | Val Loss: 0.139234, Val Acc: 0.701031\n",
      "Epoch 9583 - Train Loss: 0.123185, Train Acc: 0.784615 | Val Loss: 0.139227, Val Acc: 0.701031\n",
      "Epoch 9584 - Train Loss: 0.123177, Train Acc: 0.784615 | Val Loss: 0.139220, Val Acc: 0.701031\n",
      "Epoch 9585 - Train Loss: 0.123169, Train Acc: 0.784615 | Val Loss: 0.139214, Val Acc: 0.701031\n",
      "Epoch 9586 - Train Loss: 0.123161, Train Acc: 0.784615 | Val Loss: 0.139207, Val Acc: 0.701031\n",
      "Epoch 9587 - Train Loss: 0.123153, Train Acc: 0.784615 | Val Loss: 0.139200, Val Acc: 0.701031\n",
      "Epoch 9588 - Train Loss: 0.123145, Train Acc: 0.784615 | Val Loss: 0.139193, Val Acc: 0.701031\n",
      "Epoch 9589 - Train Loss: 0.123137, Train Acc: 0.784615 | Val Loss: 0.139186, Val Acc: 0.701031\n",
      "Epoch 9590 - Train Loss: 0.123129, Train Acc: 0.784615 | Val Loss: 0.139179, Val Acc: 0.701031\n",
      "Epoch 9591 - Train Loss: 0.123121, Train Acc: 0.784615 | Val Loss: 0.139172, Val Acc: 0.701031\n",
      "Epoch 9592 - Train Loss: 0.123113, Train Acc: 0.784615 | Val Loss: 0.139165, Val Acc: 0.701031\n",
      "Epoch 9593 - Train Loss: 0.123105, Train Acc: 0.784615 | Val Loss: 0.139158, Val Acc: 0.701031\n",
      "Epoch 9594 - Train Loss: 0.123097, Train Acc: 0.784615 | Val Loss: 0.139151, Val Acc: 0.701031\n",
      "Epoch 9595 - Train Loss: 0.123089, Train Acc: 0.784615 | Val Loss: 0.139145, Val Acc: 0.701031\n",
      "Epoch 9596 - Train Loss: 0.123081, Train Acc: 0.784615 | Val Loss: 0.139138, Val Acc: 0.701031\n",
      "Epoch 9597 - Train Loss: 0.123073, Train Acc: 0.784615 | Val Loss: 0.139131, Val Acc: 0.701031\n",
      "Epoch 9598 - Train Loss: 0.123065, Train Acc: 0.784615 | Val Loss: 0.139124, Val Acc: 0.701031\n",
      "Epoch 9599 - Train Loss: 0.123057, Train Acc: 0.784615 | Val Loss: 0.139117, Val Acc: 0.701031\n",
      "Epoch 9600 - Train Loss: 0.123049, Train Acc: 0.784615 | Val Loss: 0.139110, Val Acc: 0.701031\n",
      "Epoch 9601 - Train Loss: 0.123041, Train Acc: 0.784615 | Val Loss: 0.139103, Val Acc: 0.701031\n",
      "Epoch 9602 - Train Loss: 0.123033, Train Acc: 0.784615 | Val Loss: 0.139096, Val Acc: 0.701031\n",
      "Epoch 9603 - Train Loss: 0.123025, Train Acc: 0.784615 | Val Loss: 0.139089, Val Acc: 0.701031\n",
      "Epoch 9604 - Train Loss: 0.123017, Train Acc: 0.784615 | Val Loss: 0.139082, Val Acc: 0.701031\n",
      "Epoch 9605 - Train Loss: 0.123009, Train Acc: 0.784615 | Val Loss: 0.139076, Val Acc: 0.701031\n",
      "Epoch 9606 - Train Loss: 0.123001, Train Acc: 0.784615 | Val Loss: 0.139069, Val Acc: 0.701031\n",
      "Epoch 9607 - Train Loss: 0.122993, Train Acc: 0.784615 | Val Loss: 0.139062, Val Acc: 0.701031\n",
      "Epoch 9608 - Train Loss: 0.122985, Train Acc: 0.784615 | Val Loss: 0.139055, Val Acc: 0.701031\n",
      "Epoch 9609 - Train Loss: 0.122977, Train Acc: 0.784615 | Val Loss: 0.139048, Val Acc: 0.701031\n",
      "Epoch 9610 - Train Loss: 0.122969, Train Acc: 0.784615 | Val Loss: 0.139041, Val Acc: 0.701031\n",
      "Epoch 9611 - Train Loss: 0.122961, Train Acc: 0.784615 | Val Loss: 0.139034, Val Acc: 0.701031\n",
      "Epoch 9612 - Train Loss: 0.122953, Train Acc: 0.784615 | Val Loss: 0.139027, Val Acc: 0.701031\n",
      "Epoch 9613 - Train Loss: 0.122945, Train Acc: 0.784615 | Val Loss: 0.139020, Val Acc: 0.701031\n",
      "Epoch 9614 - Train Loss: 0.122937, Train Acc: 0.784615 | Val Loss: 0.139013, Val Acc: 0.701031\n",
      "Epoch 9615 - Train Loss: 0.122929, Train Acc: 0.784615 | Val Loss: 0.139007, Val Acc: 0.701031\n",
      "Epoch 9616 - Train Loss: 0.122921, Train Acc: 0.784615 | Val Loss: 0.139000, Val Acc: 0.701031\n",
      "Epoch 9617 - Train Loss: 0.122913, Train Acc: 0.784615 | Val Loss: 0.138993, Val Acc: 0.701031\n",
      "Epoch 9618 - Train Loss: 0.122905, Train Acc: 0.784615 | Val Loss: 0.138986, Val Acc: 0.701031\n",
      "Epoch 9619 - Train Loss: 0.122897, Train Acc: 0.784615 | Val Loss: 0.138979, Val Acc: 0.701031\n",
      "Epoch 9620 - Train Loss: 0.122889, Train Acc: 0.784615 | Val Loss: 0.138972, Val Acc: 0.701031\n",
      "Epoch 9621 - Train Loss: 0.122881, Train Acc: 0.784615 | Val Loss: 0.138965, Val Acc: 0.701031\n",
      "Epoch 9622 - Train Loss: 0.122874, Train Acc: 0.784615 | Val Loss: 0.138958, Val Acc: 0.701031\n",
      "Epoch 9623 - Train Loss: 0.122866, Train Acc: 0.784615 | Val Loss: 0.138951, Val Acc: 0.701031\n",
      "Epoch 9624 - Train Loss: 0.122858, Train Acc: 0.784615 | Val Loss: 0.138944, Val Acc: 0.701031\n",
      "Epoch 9625 - Train Loss: 0.122850, Train Acc: 0.784615 | Val Loss: 0.138938, Val Acc: 0.701031\n",
      "Epoch 9626 - Train Loss: 0.122842, Train Acc: 0.784615 | Val Loss: 0.138931, Val Acc: 0.701031\n",
      "Epoch 9627 - Train Loss: 0.122834, Train Acc: 0.784615 | Val Loss: 0.138924, Val Acc: 0.701031\n",
      "Epoch 9628 - Train Loss: 0.122826, Train Acc: 0.784615 | Val Loss: 0.138917, Val Acc: 0.701031\n",
      "Epoch 9629 - Train Loss: 0.122818, Train Acc: 0.784615 | Val Loss: 0.138910, Val Acc: 0.701031\n",
      "Epoch 9630 - Train Loss: 0.122810, Train Acc: 0.784615 | Val Loss: 0.138903, Val Acc: 0.701031\n",
      "Epoch 9631 - Train Loss: 0.122802, Train Acc: 0.784615 | Val Loss: 0.138896, Val Acc: 0.701031\n",
      "Epoch 9632 - Train Loss: 0.122794, Train Acc: 0.784615 | Val Loss: 0.138889, Val Acc: 0.701031\n",
      "Epoch 9633 - Train Loss: 0.122786, Train Acc: 0.784615 | Val Loss: 0.138882, Val Acc: 0.701031\n",
      "Epoch 9634 - Train Loss: 0.122778, Train Acc: 0.784615 | Val Loss: 0.138875, Val Acc: 0.701031\n",
      "Epoch 9635 - Train Loss: 0.122770, Train Acc: 0.784615 | Val Loss: 0.138869, Val Acc: 0.701031\n",
      "Epoch 9636 - Train Loss: 0.122762, Train Acc: 0.784615 | Val Loss: 0.138862, Val Acc: 0.701031\n",
      "Epoch 9637 - Train Loss: 0.122754, Train Acc: 0.784615 | Val Loss: 0.138855, Val Acc: 0.701031\n",
      "Epoch 9638 - Train Loss: 0.122746, Train Acc: 0.784615 | Val Loss: 0.138848, Val Acc: 0.701031\n",
      "Epoch 9639 - Train Loss: 0.122739, Train Acc: 0.784615 | Val Loss: 0.138841, Val Acc: 0.701031\n",
      "Epoch 9640 - Train Loss: 0.122731, Train Acc: 0.784615 | Val Loss: 0.138834, Val Acc: 0.701031\n",
      "Epoch 9641 - Train Loss: 0.122723, Train Acc: 0.784615 | Val Loss: 0.138827, Val Acc: 0.701031\n",
      "Epoch 9642 - Train Loss: 0.122715, Train Acc: 0.784615 | Val Loss: 0.138820, Val Acc: 0.701031\n",
      "Epoch 9643 - Train Loss: 0.122707, Train Acc: 0.784615 | Val Loss: 0.138813, Val Acc: 0.701031\n",
      "Epoch 9644 - Train Loss: 0.122699, Train Acc: 0.784615 | Val Loss: 0.138807, Val Acc: 0.701031\n",
      "Epoch 9645 - Train Loss: 0.122691, Train Acc: 0.784615 | Val Loss: 0.138800, Val Acc: 0.701031\n",
      "Epoch 9646 - Train Loss: 0.122683, Train Acc: 0.784615 | Val Loss: 0.138793, Val Acc: 0.701031\n",
      "Epoch 9647 - Train Loss: 0.122675, Train Acc: 0.784615 | Val Loss: 0.138786, Val Acc: 0.701031\n",
      "Epoch 9648 - Train Loss: 0.122667, Train Acc: 0.784615 | Val Loss: 0.138779, Val Acc: 0.701031\n",
      "Epoch 9649 - Train Loss: 0.122659, Train Acc: 0.784615 | Val Loss: 0.138772, Val Acc: 0.701031\n",
      "Epoch 9650 - Train Loss: 0.122651, Train Acc: 0.784615 | Val Loss: 0.138765, Val Acc: 0.701031\n",
      "Epoch 9651 - Train Loss: 0.122643, Train Acc: 0.784615 | Val Loss: 0.138758, Val Acc: 0.701031\n",
      "Epoch 9652 - Train Loss: 0.122635, Train Acc: 0.784615 | Val Loss: 0.138751, Val Acc: 0.701031\n",
      "Epoch 9653 - Train Loss: 0.122628, Train Acc: 0.784615 | Val Loss: 0.138745, Val Acc: 0.701031\n",
      "Epoch 9654 - Train Loss: 0.122620, Train Acc: 0.784615 | Val Loss: 0.138738, Val Acc: 0.701031\n",
      "Epoch 9655 - Train Loss: 0.122612, Train Acc: 0.784615 | Val Loss: 0.138731, Val Acc: 0.701031\n",
      "Epoch 9656 - Train Loss: 0.122604, Train Acc: 0.784615 | Val Loss: 0.138724, Val Acc: 0.701031\n",
      "Epoch 9657 - Train Loss: 0.122596, Train Acc: 0.784615 | Val Loss: 0.138717, Val Acc: 0.701031\n",
      "Epoch 9658 - Train Loss: 0.122588, Train Acc: 0.784615 | Val Loss: 0.138710, Val Acc: 0.701031\n",
      "Epoch 9659 - Train Loss: 0.122580, Train Acc: 0.784615 | Val Loss: 0.138703, Val Acc: 0.701031\n",
      "Epoch 9660 - Train Loss: 0.122572, Train Acc: 0.784615 | Val Loss: 0.138697, Val Acc: 0.701031\n",
      "Epoch 9661 - Train Loss: 0.122564, Train Acc: 0.784615 | Val Loss: 0.138690, Val Acc: 0.701031\n",
      "Epoch 9662 - Train Loss: 0.122556, Train Acc: 0.784615 | Val Loss: 0.138683, Val Acc: 0.701031\n",
      "Epoch 9663 - Train Loss: 0.122548, Train Acc: 0.785897 | Val Loss: 0.138676, Val Acc: 0.701031\n",
      "Epoch 9664 - Train Loss: 0.122541, Train Acc: 0.785897 | Val Loss: 0.138669, Val Acc: 0.701031\n",
      "Epoch 9665 - Train Loss: 0.122533, Train Acc: 0.785897 | Val Loss: 0.138662, Val Acc: 0.701031\n",
      "Epoch 9666 - Train Loss: 0.122525, Train Acc: 0.785897 | Val Loss: 0.138655, Val Acc: 0.701031\n",
      "Epoch 9667 - Train Loss: 0.122517, Train Acc: 0.785897 | Val Loss: 0.138648, Val Acc: 0.701031\n",
      "Epoch 9668 - Train Loss: 0.122509, Train Acc: 0.785897 | Val Loss: 0.138642, Val Acc: 0.701031\n",
      "Epoch 9669 - Train Loss: 0.122501, Train Acc: 0.785897 | Val Loss: 0.138635, Val Acc: 0.701031\n",
      "Epoch 9670 - Train Loss: 0.122493, Train Acc: 0.785897 | Val Loss: 0.138628, Val Acc: 0.701031\n",
      "Epoch 9671 - Train Loss: 0.122485, Train Acc: 0.785897 | Val Loss: 0.138621, Val Acc: 0.701031\n",
      "Epoch 9672 - Train Loss: 0.122477, Train Acc: 0.785897 | Val Loss: 0.138614, Val Acc: 0.701031\n",
      "Epoch 9673 - Train Loss: 0.122469, Train Acc: 0.785897 | Val Loss: 0.138607, Val Acc: 0.701031\n",
      "Epoch 9674 - Train Loss: 0.122462, Train Acc: 0.785897 | Val Loss: 0.138601, Val Acc: 0.701031\n",
      "Epoch 9675 - Train Loss: 0.122454, Train Acc: 0.785897 | Val Loss: 0.138594, Val Acc: 0.701031\n",
      "Epoch 9676 - Train Loss: 0.122446, Train Acc: 0.785897 | Val Loss: 0.138587, Val Acc: 0.701031\n",
      "Epoch 9677 - Train Loss: 0.122438, Train Acc: 0.785897 | Val Loss: 0.138580, Val Acc: 0.701031\n",
      "Epoch 9678 - Train Loss: 0.122430, Train Acc: 0.785897 | Val Loss: 0.138573, Val Acc: 0.701031\n",
      "Epoch 9679 - Train Loss: 0.122422, Train Acc: 0.785897 | Val Loss: 0.138566, Val Acc: 0.701031\n",
      "Epoch 9680 - Train Loss: 0.122414, Train Acc: 0.785897 | Val Loss: 0.138559, Val Acc: 0.701031\n",
      "Epoch 9681 - Train Loss: 0.122406, Train Acc: 0.785897 | Val Loss: 0.138553, Val Acc: 0.701031\n",
      "Epoch 9682 - Train Loss: 0.122398, Train Acc: 0.785897 | Val Loss: 0.138546, Val Acc: 0.701031\n",
      "Epoch 9683 - Train Loss: 0.122391, Train Acc: 0.785897 | Val Loss: 0.138539, Val Acc: 0.701031\n",
      "Epoch 9684 - Train Loss: 0.122383, Train Acc: 0.785897 | Val Loss: 0.138532, Val Acc: 0.701031\n",
      "Epoch 9685 - Train Loss: 0.122375, Train Acc: 0.785897 | Val Loss: 0.138525, Val Acc: 0.701031\n",
      "Epoch 9686 - Train Loss: 0.122367, Train Acc: 0.785897 | Val Loss: 0.138518, Val Acc: 0.701031\n",
      "Epoch 9687 - Train Loss: 0.122359, Train Acc: 0.785897 | Val Loss: 0.138512, Val Acc: 0.701031\n",
      "Epoch 9688 - Train Loss: 0.122351, Train Acc: 0.785897 | Val Loss: 0.138505, Val Acc: 0.701031\n",
      "Epoch 9689 - Train Loss: 0.122343, Train Acc: 0.785897 | Val Loss: 0.138498, Val Acc: 0.701031\n",
      "Epoch 9690 - Train Loss: 0.122335, Train Acc: 0.785897 | Val Loss: 0.138491, Val Acc: 0.701031\n",
      "Epoch 9691 - Train Loss: 0.122328, Train Acc: 0.785897 | Val Loss: 0.138484, Val Acc: 0.701031\n",
      "Epoch 9692 - Train Loss: 0.122320, Train Acc: 0.785897 | Val Loss: 0.138477, Val Acc: 0.701031\n",
      "Epoch 9693 - Train Loss: 0.122312, Train Acc: 0.785897 | Val Loss: 0.138471, Val Acc: 0.701031\n",
      "Epoch 9694 - Train Loss: 0.122304, Train Acc: 0.785897 | Val Loss: 0.138464, Val Acc: 0.701031\n",
      "Epoch 9695 - Train Loss: 0.122296, Train Acc: 0.785897 | Val Loss: 0.138457, Val Acc: 0.701031\n",
      "Epoch 9696 - Train Loss: 0.122288, Train Acc: 0.785897 | Val Loss: 0.138450, Val Acc: 0.701031\n",
      "Epoch 9697 - Train Loss: 0.122280, Train Acc: 0.785897 | Val Loss: 0.138443, Val Acc: 0.701031\n",
      "Epoch 9698 - Train Loss: 0.122272, Train Acc: 0.785897 | Val Loss: 0.138436, Val Acc: 0.701031\n",
      "Epoch 9699 - Train Loss: 0.122265, Train Acc: 0.785897 | Val Loss: 0.138430, Val Acc: 0.701031\n",
      "Epoch 9700 - Train Loss: 0.122257, Train Acc: 0.785897 | Val Loss: 0.138423, Val Acc: 0.701031\n",
      "Epoch 9701 - Train Loss: 0.122249, Train Acc: 0.785897 | Val Loss: 0.138416, Val Acc: 0.701031\n",
      "Epoch 9702 - Train Loss: 0.122241, Train Acc: 0.785897 | Val Loss: 0.138409, Val Acc: 0.701031\n",
      "Epoch 9703 - Train Loss: 0.122233, Train Acc: 0.785897 | Val Loss: 0.138402, Val Acc: 0.701031\n",
      "Epoch 9704 - Train Loss: 0.122225, Train Acc: 0.785897 | Val Loss: 0.138395, Val Acc: 0.701031\n",
      "Epoch 9705 - Train Loss: 0.122217, Train Acc: 0.785897 | Val Loss: 0.138389, Val Acc: 0.701031\n",
      "Epoch 9706 - Train Loss: 0.122210, Train Acc: 0.785897 | Val Loss: 0.138382, Val Acc: 0.701031\n",
      "Epoch 9707 - Train Loss: 0.122202, Train Acc: 0.785897 | Val Loss: 0.138375, Val Acc: 0.701031\n",
      "Epoch 9708 - Train Loss: 0.122194, Train Acc: 0.785897 | Val Loss: 0.138368, Val Acc: 0.701031\n",
      "Epoch 9709 - Train Loss: 0.122186, Train Acc: 0.785897 | Val Loss: 0.138361, Val Acc: 0.701031\n",
      "Epoch 9710 - Train Loss: 0.122178, Train Acc: 0.785897 | Val Loss: 0.138355, Val Acc: 0.701031\n",
      "Epoch 9711 - Train Loss: 0.122170, Train Acc: 0.785897 | Val Loss: 0.138348, Val Acc: 0.701031\n",
      "Epoch 9712 - Train Loss: 0.122162, Train Acc: 0.785897 | Val Loss: 0.138341, Val Acc: 0.701031\n",
      "Epoch 9713 - Train Loss: 0.122155, Train Acc: 0.785897 | Val Loss: 0.138334, Val Acc: 0.701031\n",
      "Epoch 9714 - Train Loss: 0.122147, Train Acc: 0.785897 | Val Loss: 0.138327, Val Acc: 0.701031\n",
      "Epoch 9715 - Train Loss: 0.122139, Train Acc: 0.785897 | Val Loss: 0.138320, Val Acc: 0.701031\n",
      "Epoch 9716 - Train Loss: 0.122131, Train Acc: 0.785897 | Val Loss: 0.138314, Val Acc: 0.701031\n",
      "Epoch 9717 - Train Loss: 0.122123, Train Acc: 0.785897 | Val Loss: 0.138307, Val Acc: 0.701031\n",
      "Epoch 9718 - Train Loss: 0.122115, Train Acc: 0.785897 | Val Loss: 0.138300, Val Acc: 0.701031\n",
      "Epoch 9719 - Train Loss: 0.122107, Train Acc: 0.785897 | Val Loss: 0.138293, Val Acc: 0.701031\n",
      "Epoch 9720 - Train Loss: 0.122100, Train Acc: 0.785897 | Val Loss: 0.138286, Val Acc: 0.701031\n",
      "Epoch 9721 - Train Loss: 0.122092, Train Acc: 0.785897 | Val Loss: 0.138280, Val Acc: 0.701031\n",
      "Epoch 9722 - Train Loss: 0.122084, Train Acc: 0.785897 | Val Loss: 0.138273, Val Acc: 0.701031\n",
      "Epoch 9723 - Train Loss: 0.122076, Train Acc: 0.785897 | Val Loss: 0.138266, Val Acc: 0.701031\n",
      "Epoch 9724 - Train Loss: 0.122068, Train Acc: 0.785897 | Val Loss: 0.138259, Val Acc: 0.701031\n",
      "Epoch 9725 - Train Loss: 0.122060, Train Acc: 0.785897 | Val Loss: 0.138253, Val Acc: 0.701031\n",
      "Epoch 9726 - Train Loss: 0.122053, Train Acc: 0.785897 | Val Loss: 0.138246, Val Acc: 0.701031\n",
      "Epoch 9727 - Train Loss: 0.122045, Train Acc: 0.785897 | Val Loss: 0.138239, Val Acc: 0.701031\n",
      "Epoch 9728 - Train Loss: 0.122037, Train Acc: 0.785897 | Val Loss: 0.138232, Val Acc: 0.701031\n",
      "Epoch 9729 - Train Loss: 0.122029, Train Acc: 0.785897 | Val Loss: 0.138225, Val Acc: 0.701031\n",
      "Epoch 9730 - Train Loss: 0.122021, Train Acc: 0.785897 | Val Loss: 0.138219, Val Acc: 0.701031\n",
      "Epoch 9731 - Train Loss: 0.122013, Train Acc: 0.785897 | Val Loss: 0.138212, Val Acc: 0.701031\n",
      "Epoch 9732 - Train Loss: 0.122006, Train Acc: 0.785897 | Val Loss: 0.138205, Val Acc: 0.701031\n",
      "Epoch 9733 - Train Loss: 0.121998, Train Acc: 0.785897 | Val Loss: 0.138198, Val Acc: 0.701031\n",
      "Epoch 9734 - Train Loss: 0.121990, Train Acc: 0.785897 | Val Loss: 0.138192, Val Acc: 0.701031\n",
      "Epoch 9735 - Train Loss: 0.121982, Train Acc: 0.785897 | Val Loss: 0.138185, Val Acc: 0.701031\n",
      "Epoch 9736 - Train Loss: 0.121974, Train Acc: 0.785897 | Val Loss: 0.138178, Val Acc: 0.701031\n",
      "Epoch 9737 - Train Loss: 0.121967, Train Acc: 0.785897 | Val Loss: 0.138171, Val Acc: 0.701031\n",
      "Epoch 9738 - Train Loss: 0.121959, Train Acc: 0.785897 | Val Loss: 0.138165, Val Acc: 0.701031\n",
      "Epoch 9739 - Train Loss: 0.121951, Train Acc: 0.785897 | Val Loss: 0.138158, Val Acc: 0.701031\n",
      "Epoch 9740 - Train Loss: 0.121943, Train Acc: 0.785897 | Val Loss: 0.138151, Val Acc: 0.701031\n",
      "Epoch 9741 - Train Loss: 0.121935, Train Acc: 0.785897 | Val Loss: 0.138145, Val Acc: 0.701031\n",
      "Epoch 9742 - Train Loss: 0.121927, Train Acc: 0.785897 | Val Loss: 0.138138, Val Acc: 0.701031\n",
      "Epoch 9743 - Train Loss: 0.121920, Train Acc: 0.787179 | Val Loss: 0.138131, Val Acc: 0.701031\n",
      "Epoch 9744 - Train Loss: 0.121912, Train Acc: 0.787179 | Val Loss: 0.138124, Val Acc: 0.701031\n",
      "Epoch 9745 - Train Loss: 0.121904, Train Acc: 0.787179 | Val Loss: 0.138118, Val Acc: 0.701031\n",
      "Epoch 9746 - Train Loss: 0.121896, Train Acc: 0.787179 | Val Loss: 0.138111, Val Acc: 0.701031\n",
      "Epoch 9747 - Train Loss: 0.121888, Train Acc: 0.787179 | Val Loss: 0.138104, Val Acc: 0.701031\n",
      "Epoch 9748 - Train Loss: 0.121881, Train Acc: 0.787179 | Val Loss: 0.138097, Val Acc: 0.701031\n",
      "Epoch 9749 - Train Loss: 0.121873, Train Acc: 0.787179 | Val Loss: 0.138091, Val Acc: 0.701031\n",
      "Epoch 9750 - Train Loss: 0.121865, Train Acc: 0.787179 | Val Loss: 0.138084, Val Acc: 0.701031\n",
      "Epoch 9751 - Train Loss: 0.121857, Train Acc: 0.787179 | Val Loss: 0.138077, Val Acc: 0.701031\n",
      "Epoch 9752 - Train Loss: 0.121849, Train Acc: 0.787179 | Val Loss: 0.138071, Val Acc: 0.701031\n",
      "Epoch 9753 - Train Loss: 0.121842, Train Acc: 0.787179 | Val Loss: 0.138064, Val Acc: 0.701031\n",
      "Epoch 9754 - Train Loss: 0.121834, Train Acc: 0.787179 | Val Loss: 0.138057, Val Acc: 0.701031\n",
      "Epoch 9755 - Train Loss: 0.121826, Train Acc: 0.787179 | Val Loss: 0.138050, Val Acc: 0.701031\n",
      "Epoch 9756 - Train Loss: 0.121818, Train Acc: 0.787179 | Val Loss: 0.138044, Val Acc: 0.701031\n",
      "Epoch 9757 - Train Loss: 0.121810, Train Acc: 0.787179 | Val Loss: 0.138037, Val Acc: 0.701031\n",
      "Epoch 9758 - Train Loss: 0.121803, Train Acc: 0.787179 | Val Loss: 0.138030, Val Acc: 0.701031\n",
      "Epoch 9759 - Train Loss: 0.121795, Train Acc: 0.787179 | Val Loss: 0.138024, Val Acc: 0.701031\n",
      "Epoch 9760 - Train Loss: 0.121787, Train Acc: 0.787179 | Val Loss: 0.138017, Val Acc: 0.701031\n",
      "Epoch 9761 - Train Loss: 0.121779, Train Acc: 0.787179 | Val Loss: 0.138010, Val Acc: 0.701031\n",
      "Epoch 9762 - Train Loss: 0.121772, Train Acc: 0.787179 | Val Loss: 0.138004, Val Acc: 0.701031\n",
      "Epoch 9763 - Train Loss: 0.121764, Train Acc: 0.787179 | Val Loss: 0.137997, Val Acc: 0.701031\n",
      "Epoch 9764 - Train Loss: 0.121756, Train Acc: 0.787179 | Val Loss: 0.137990, Val Acc: 0.701031\n",
      "Epoch 9765 - Train Loss: 0.121748, Train Acc: 0.787179 | Val Loss: 0.137983, Val Acc: 0.701031\n",
      "Epoch 9766 - Train Loss: 0.121740, Train Acc: 0.787179 | Val Loss: 0.137977, Val Acc: 0.701031\n",
      "Epoch 9767 - Train Loss: 0.121733, Train Acc: 0.787179 | Val Loss: 0.137970, Val Acc: 0.701031\n",
      "Epoch 9768 - Train Loss: 0.121725, Train Acc: 0.787179 | Val Loss: 0.137963, Val Acc: 0.701031\n",
      "Epoch 9769 - Train Loss: 0.121717, Train Acc: 0.787179 | Val Loss: 0.137957, Val Acc: 0.701031\n",
      "Epoch 9770 - Train Loss: 0.121709, Train Acc: 0.787179 | Val Loss: 0.137950, Val Acc: 0.701031\n",
      "Epoch 9771 - Train Loss: 0.121702, Train Acc: 0.787179 | Val Loss: 0.137943, Val Acc: 0.701031\n",
      "Epoch 9772 - Train Loss: 0.121694, Train Acc: 0.787179 | Val Loss: 0.137937, Val Acc: 0.701031\n",
      "Epoch 9773 - Train Loss: 0.121686, Train Acc: 0.787179 | Val Loss: 0.137930, Val Acc: 0.701031\n",
      "Epoch 9774 - Train Loss: 0.121678, Train Acc: 0.787179 | Val Loss: 0.137923, Val Acc: 0.701031\n",
      "Epoch 9775 - Train Loss: 0.121670, Train Acc: 0.787179 | Val Loss: 0.137917, Val Acc: 0.701031\n",
      "Epoch 9776 - Train Loss: 0.121663, Train Acc: 0.787179 | Val Loss: 0.137910, Val Acc: 0.701031\n",
      "Epoch 9777 - Train Loss: 0.121655, Train Acc: 0.787179 | Val Loss: 0.137903, Val Acc: 0.701031\n",
      "Epoch 9778 - Train Loss: 0.121647, Train Acc: 0.787179 | Val Loss: 0.137896, Val Acc: 0.701031\n",
      "Epoch 9779 - Train Loss: 0.121639, Train Acc: 0.787179 | Val Loss: 0.137890, Val Acc: 0.701031\n",
      "Epoch 9780 - Train Loss: 0.121632, Train Acc: 0.787179 | Val Loss: 0.137883, Val Acc: 0.701031\n",
      "Epoch 9781 - Train Loss: 0.121624, Train Acc: 0.787179 | Val Loss: 0.137876, Val Acc: 0.701031\n",
      "Epoch 9782 - Train Loss: 0.121616, Train Acc: 0.787179 | Val Loss: 0.137870, Val Acc: 0.701031\n",
      "Epoch 9783 - Train Loss: 0.121608, Train Acc: 0.787179 | Val Loss: 0.137863, Val Acc: 0.701031\n",
      "Epoch 9784 - Train Loss: 0.121601, Train Acc: 0.787179 | Val Loss: 0.137856, Val Acc: 0.701031\n",
      "Epoch 9785 - Train Loss: 0.121593, Train Acc: 0.787179 | Val Loss: 0.137850, Val Acc: 0.701031\n",
      "Epoch 9786 - Train Loss: 0.121585, Train Acc: 0.787179 | Val Loss: 0.137843, Val Acc: 0.701031\n",
      "Epoch 9787 - Train Loss: 0.121577, Train Acc: 0.787179 | Val Loss: 0.137836, Val Acc: 0.701031\n",
      "Epoch 9788 - Train Loss: 0.121570, Train Acc: 0.787179 | Val Loss: 0.137830, Val Acc: 0.701031\n",
      "Epoch 9789 - Train Loss: 0.121562, Train Acc: 0.787179 | Val Loss: 0.137823, Val Acc: 0.701031\n",
      "Epoch 9790 - Train Loss: 0.121554, Train Acc: 0.787179 | Val Loss: 0.137816, Val Acc: 0.701031\n",
      "Epoch 9791 - Train Loss: 0.121546, Train Acc: 0.787179 | Val Loss: 0.137810, Val Acc: 0.701031\n",
      "Epoch 9792 - Train Loss: 0.121539, Train Acc: 0.787179 | Val Loss: 0.137803, Val Acc: 0.701031\n",
      "Epoch 9793 - Train Loss: 0.121531, Train Acc: 0.787179 | Val Loss: 0.137796, Val Acc: 0.701031\n",
      "Epoch 9794 - Train Loss: 0.121523, Train Acc: 0.787179 | Val Loss: 0.137790, Val Acc: 0.701031\n",
      "Epoch 9795 - Train Loss: 0.121515, Train Acc: 0.787179 | Val Loss: 0.137783, Val Acc: 0.701031\n",
      "Epoch 9796 - Train Loss: 0.121508, Train Acc: 0.787179 | Val Loss: 0.137776, Val Acc: 0.701031\n",
      "Epoch 9797 - Train Loss: 0.121500, Train Acc: 0.787179 | Val Loss: 0.137770, Val Acc: 0.701031\n",
      "Epoch 9798 - Train Loss: 0.121492, Train Acc: 0.787179 | Val Loss: 0.137763, Val Acc: 0.701031\n",
      "Epoch 9799 - Train Loss: 0.121484, Train Acc: 0.787179 | Val Loss: 0.137756, Val Acc: 0.701031\n",
      "Epoch 9800 - Train Loss: 0.121477, Train Acc: 0.787179 | Val Loss: 0.137750, Val Acc: 0.701031\n",
      "Epoch 9801 - Train Loss: 0.121469, Train Acc: 0.787179 | Val Loss: 0.137743, Val Acc: 0.701031\n",
      "Epoch 9802 - Train Loss: 0.121461, Train Acc: 0.787179 | Val Loss: 0.137737, Val Acc: 0.701031\n",
      "Epoch 9803 - Train Loss: 0.121453, Train Acc: 0.787179 | Val Loss: 0.137730, Val Acc: 0.701031\n",
      "Epoch 9804 - Train Loss: 0.121446, Train Acc: 0.787179 | Val Loss: 0.137723, Val Acc: 0.701031\n",
      "Epoch 9805 - Train Loss: 0.121438, Train Acc: 0.787179 | Val Loss: 0.137717, Val Acc: 0.701031\n",
      "Epoch 9806 - Train Loss: 0.121430, Train Acc: 0.787179 | Val Loss: 0.137710, Val Acc: 0.701031\n",
      "Epoch 9807 - Train Loss: 0.121422, Train Acc: 0.787179 | Val Loss: 0.137703, Val Acc: 0.701031\n",
      "Epoch 9808 - Train Loss: 0.121415, Train Acc: 0.787179 | Val Loss: 0.137697, Val Acc: 0.701031\n",
      "Epoch 9809 - Train Loss: 0.121407, Train Acc: 0.787179 | Val Loss: 0.137690, Val Acc: 0.701031\n",
      "Epoch 9810 - Train Loss: 0.121399, Train Acc: 0.787179 | Val Loss: 0.137684, Val Acc: 0.701031\n",
      "Epoch 9811 - Train Loss: 0.121392, Train Acc: 0.787179 | Val Loss: 0.137677, Val Acc: 0.701031\n",
      "Epoch 9812 - Train Loss: 0.121384, Train Acc: 0.787179 | Val Loss: 0.137670, Val Acc: 0.701031\n",
      "Epoch 9813 - Train Loss: 0.121376, Train Acc: 0.787179 | Val Loss: 0.137664, Val Acc: 0.701031\n",
      "Epoch 9814 - Train Loss: 0.121368, Train Acc: 0.787179 | Val Loss: 0.137657, Val Acc: 0.701031\n",
      "Epoch 9815 - Train Loss: 0.121361, Train Acc: 0.787179 | Val Loss: 0.137650, Val Acc: 0.701031\n",
      "Epoch 9816 - Train Loss: 0.121353, Train Acc: 0.787179 | Val Loss: 0.137644, Val Acc: 0.701031\n",
      "Epoch 9817 - Train Loss: 0.121345, Train Acc: 0.787179 | Val Loss: 0.137637, Val Acc: 0.701031\n",
      "Epoch 9818 - Train Loss: 0.121338, Train Acc: 0.787179 | Val Loss: 0.137631, Val Acc: 0.701031\n",
      "Epoch 9819 - Train Loss: 0.121330, Train Acc: 0.787179 | Val Loss: 0.137624, Val Acc: 0.701031\n",
      "Epoch 9820 - Train Loss: 0.121322, Train Acc: 0.787179 | Val Loss: 0.137617, Val Acc: 0.701031\n",
      "Epoch 9821 - Train Loss: 0.121314, Train Acc: 0.787179 | Val Loss: 0.137611, Val Acc: 0.701031\n",
      "Epoch 9822 - Train Loss: 0.121307, Train Acc: 0.787179 | Val Loss: 0.137604, Val Acc: 0.701031\n",
      "Epoch 9823 - Train Loss: 0.121299, Train Acc: 0.787179 | Val Loss: 0.137598, Val Acc: 0.701031\n",
      "Epoch 9824 - Train Loss: 0.121291, Train Acc: 0.787179 | Val Loss: 0.137591, Val Acc: 0.701031\n",
      "Epoch 9825 - Train Loss: 0.121284, Train Acc: 0.788462 | Val Loss: 0.137584, Val Acc: 0.701031\n",
      "Epoch 9826 - Train Loss: 0.121276, Train Acc: 0.788462 | Val Loss: 0.137578, Val Acc: 0.701031\n",
      "Epoch 9827 - Train Loss: 0.121268, Train Acc: 0.788462 | Val Loss: 0.137571, Val Acc: 0.701031\n",
      "Epoch 9828 - Train Loss: 0.121260, Train Acc: 0.788462 | Val Loss: 0.137565, Val Acc: 0.701031\n",
      "Epoch 9829 - Train Loss: 0.121253, Train Acc: 0.788462 | Val Loss: 0.137558, Val Acc: 0.701031\n",
      "Epoch 9830 - Train Loss: 0.121245, Train Acc: 0.788462 | Val Loss: 0.137551, Val Acc: 0.701031\n",
      "Epoch 9831 - Train Loss: 0.121237, Train Acc: 0.788462 | Val Loss: 0.137545, Val Acc: 0.701031\n",
      "Epoch 9832 - Train Loss: 0.121230, Train Acc: 0.788462 | Val Loss: 0.137538, Val Acc: 0.701031\n",
      "Epoch 9833 - Train Loss: 0.121222, Train Acc: 0.788462 | Val Loss: 0.137532, Val Acc: 0.701031\n",
      "Epoch 9834 - Train Loss: 0.121214, Train Acc: 0.788462 | Val Loss: 0.137525, Val Acc: 0.701031\n",
      "Epoch 9835 - Train Loss: 0.121207, Train Acc: 0.788462 | Val Loss: 0.137518, Val Acc: 0.701031\n",
      "Epoch 9836 - Train Loss: 0.121199, Train Acc: 0.788462 | Val Loss: 0.137512, Val Acc: 0.701031\n",
      "Epoch 9837 - Train Loss: 0.121191, Train Acc: 0.788462 | Val Loss: 0.137505, Val Acc: 0.701031\n",
      "Epoch 9838 - Train Loss: 0.121183, Train Acc: 0.788462 | Val Loss: 0.137499, Val Acc: 0.701031\n",
      "Epoch 9839 - Train Loss: 0.121176, Train Acc: 0.788462 | Val Loss: 0.137492, Val Acc: 0.701031\n",
      "Epoch 9840 - Train Loss: 0.121168, Train Acc: 0.788462 | Val Loss: 0.137485, Val Acc: 0.701031\n",
      "Epoch 9841 - Train Loss: 0.121160, Train Acc: 0.789744 | Val Loss: 0.137479, Val Acc: 0.701031\n",
      "Epoch 9842 - Train Loss: 0.121153, Train Acc: 0.789744 | Val Loss: 0.137472, Val Acc: 0.701031\n",
      "Epoch 9843 - Train Loss: 0.121145, Train Acc: 0.789744 | Val Loss: 0.137466, Val Acc: 0.701031\n",
      "Epoch 9844 - Train Loss: 0.121137, Train Acc: 0.789744 | Val Loss: 0.137459, Val Acc: 0.701031\n",
      "Epoch 9845 - Train Loss: 0.121130, Train Acc: 0.789744 | Val Loss: 0.137452, Val Acc: 0.701031\n",
      "Epoch 9846 - Train Loss: 0.121122, Train Acc: 0.789744 | Val Loss: 0.137446, Val Acc: 0.701031\n",
      "Epoch 9847 - Train Loss: 0.121114, Train Acc: 0.789744 | Val Loss: 0.137439, Val Acc: 0.701031\n",
      "Epoch 9848 - Train Loss: 0.121107, Train Acc: 0.789744 | Val Loss: 0.137433, Val Acc: 0.701031\n",
      "Epoch 9849 - Train Loss: 0.121099, Train Acc: 0.789744 | Val Loss: 0.137426, Val Acc: 0.701031\n",
      "Epoch 9850 - Train Loss: 0.121091, Train Acc: 0.789744 | Val Loss: 0.137419, Val Acc: 0.701031\n",
      "Epoch 9851 - Train Loss: 0.121084, Train Acc: 0.789744 | Val Loss: 0.137413, Val Acc: 0.701031\n",
      "Epoch 9852 - Train Loss: 0.121076, Train Acc: 0.789744 | Val Loss: 0.137406, Val Acc: 0.701031\n",
      "Epoch 9853 - Train Loss: 0.121068, Train Acc: 0.789744 | Val Loss: 0.137400, Val Acc: 0.701031\n",
      "Epoch 9854 - Train Loss: 0.121061, Train Acc: 0.789744 | Val Loss: 0.137393, Val Acc: 0.701031\n",
      "Epoch 9855 - Train Loss: 0.121053, Train Acc: 0.789744 | Val Loss: 0.137387, Val Acc: 0.701031\n",
      "Epoch 9856 - Train Loss: 0.121045, Train Acc: 0.789744 | Val Loss: 0.137380, Val Acc: 0.701031\n",
      "Epoch 9857 - Train Loss: 0.121037, Train Acc: 0.789744 | Val Loss: 0.137373, Val Acc: 0.701031\n",
      "Epoch 9858 - Train Loss: 0.121030, Train Acc: 0.789744 | Val Loss: 0.137367, Val Acc: 0.701031\n",
      "Epoch 9859 - Train Loss: 0.121022, Train Acc: 0.789744 | Val Loss: 0.137360, Val Acc: 0.701031\n",
      "Epoch 9860 - Train Loss: 0.121014, Train Acc: 0.789744 | Val Loss: 0.137354, Val Acc: 0.701031\n",
      "Epoch 9861 - Train Loss: 0.121007, Train Acc: 0.789744 | Val Loss: 0.137347, Val Acc: 0.701031\n",
      "Epoch 9862 - Train Loss: 0.120999, Train Acc: 0.789744 | Val Loss: 0.137341, Val Acc: 0.701031\n",
      "Epoch 9863 - Train Loss: 0.120991, Train Acc: 0.789744 | Val Loss: 0.137334, Val Acc: 0.701031\n",
      "Epoch 9864 - Train Loss: 0.120984, Train Acc: 0.789744 | Val Loss: 0.137327, Val Acc: 0.701031\n",
      "Epoch 9865 - Train Loss: 0.120976, Train Acc: 0.789744 | Val Loss: 0.137321, Val Acc: 0.701031\n",
      "Epoch 9866 - Train Loss: 0.120968, Train Acc: 0.789744 | Val Loss: 0.137314, Val Acc: 0.701031\n",
      "Epoch 9867 - Train Loss: 0.120961, Train Acc: 0.789744 | Val Loss: 0.137308, Val Acc: 0.701031\n",
      "Epoch 9868 - Train Loss: 0.120953, Train Acc: 0.789744 | Val Loss: 0.137301, Val Acc: 0.701031\n",
      "Epoch 9869 - Train Loss: 0.120945, Train Acc: 0.789744 | Val Loss: 0.137295, Val Acc: 0.701031\n",
      "Epoch 9870 - Train Loss: 0.120938, Train Acc: 0.789744 | Val Loss: 0.137288, Val Acc: 0.701031\n",
      "Epoch 9871 - Train Loss: 0.120930, Train Acc: 0.789744 | Val Loss: 0.137282, Val Acc: 0.701031\n",
      "Epoch 9872 - Train Loss: 0.120923, Train Acc: 0.789744 | Val Loss: 0.137275, Val Acc: 0.701031\n",
      "Epoch 9873 - Train Loss: 0.120915, Train Acc: 0.789744 | Val Loss: 0.137268, Val Acc: 0.701031\n",
      "Epoch 9874 - Train Loss: 0.120907, Train Acc: 0.789744 | Val Loss: 0.137262, Val Acc: 0.701031\n",
      "Epoch 9875 - Train Loss: 0.120900, Train Acc: 0.789744 | Val Loss: 0.137255, Val Acc: 0.701031\n",
      "Epoch 9876 - Train Loss: 0.120892, Train Acc: 0.789744 | Val Loss: 0.137249, Val Acc: 0.701031\n",
      "Epoch 9877 - Train Loss: 0.120884, Train Acc: 0.789744 | Val Loss: 0.137242, Val Acc: 0.701031\n",
      "Epoch 9878 - Train Loss: 0.120877, Train Acc: 0.789744 | Val Loss: 0.137236, Val Acc: 0.701031\n",
      "Epoch 9879 - Train Loss: 0.120869, Train Acc: 0.789744 | Val Loss: 0.137229, Val Acc: 0.701031\n",
      "Epoch 9880 - Train Loss: 0.120861, Train Acc: 0.789744 | Val Loss: 0.137223, Val Acc: 0.701031\n",
      "Epoch 9881 - Train Loss: 0.120854, Train Acc: 0.789744 | Val Loss: 0.137216, Val Acc: 0.701031\n",
      "Epoch 9882 - Train Loss: 0.120846, Train Acc: 0.789744 | Val Loss: 0.137210, Val Acc: 0.701031\n",
      "Epoch 9883 - Train Loss: 0.120838, Train Acc: 0.789744 | Val Loss: 0.137203, Val Acc: 0.701031\n",
      "Epoch 9884 - Train Loss: 0.120831, Train Acc: 0.789744 | Val Loss: 0.137196, Val Acc: 0.701031\n",
      "Epoch 9885 - Train Loss: 0.120823, Train Acc: 0.789744 | Val Loss: 0.137190, Val Acc: 0.701031\n",
      "Epoch 9886 - Train Loss: 0.120815, Train Acc: 0.789744 | Val Loss: 0.137183, Val Acc: 0.701031\n",
      "Epoch 9887 - Train Loss: 0.120808, Train Acc: 0.789744 | Val Loss: 0.137177, Val Acc: 0.701031\n",
      "Epoch 9888 - Train Loss: 0.120800, Train Acc: 0.789744 | Val Loss: 0.137170, Val Acc: 0.701031\n",
      "Epoch 9889 - Train Loss: 0.120793, Train Acc: 0.789744 | Val Loss: 0.137164, Val Acc: 0.701031\n",
      "Epoch 9890 - Train Loss: 0.120785, Train Acc: 0.789744 | Val Loss: 0.137157, Val Acc: 0.701031\n",
      "Epoch 9891 - Train Loss: 0.120777, Train Acc: 0.789744 | Val Loss: 0.137151, Val Acc: 0.701031\n",
      "Epoch 9892 - Train Loss: 0.120770, Train Acc: 0.789744 | Val Loss: 0.137144, Val Acc: 0.701031\n",
      "Epoch 9893 - Train Loss: 0.120762, Train Acc: 0.789744 | Val Loss: 0.137138, Val Acc: 0.701031\n",
      "Epoch 9894 - Train Loss: 0.120754, Train Acc: 0.789744 | Val Loss: 0.137131, Val Acc: 0.701031\n",
      "Epoch 9895 - Train Loss: 0.120747, Train Acc: 0.789744 | Val Loss: 0.137125, Val Acc: 0.701031\n",
      "Epoch 9896 - Train Loss: 0.120739, Train Acc: 0.789744 | Val Loss: 0.137118, Val Acc: 0.701031\n",
      "Epoch 9897 - Train Loss: 0.120732, Train Acc: 0.791026 | Val Loss: 0.137112, Val Acc: 0.701031\n",
      "Epoch 9898 - Train Loss: 0.120724, Train Acc: 0.791026 | Val Loss: 0.137105, Val Acc: 0.701031\n",
      "Epoch 9899 - Train Loss: 0.120716, Train Acc: 0.791026 | Val Loss: 0.137099, Val Acc: 0.701031\n",
      "Epoch 9900 - Train Loss: 0.120709, Train Acc: 0.791026 | Val Loss: 0.137092, Val Acc: 0.701031\n",
      "Epoch 9901 - Train Loss: 0.120701, Train Acc: 0.791026 | Val Loss: 0.137086, Val Acc: 0.701031\n",
      "Epoch 9902 - Train Loss: 0.120693, Train Acc: 0.791026 | Val Loss: 0.137079, Val Acc: 0.701031\n",
      "Epoch 9903 - Train Loss: 0.120686, Train Acc: 0.791026 | Val Loss: 0.137073, Val Acc: 0.701031\n",
      "Epoch 9904 - Train Loss: 0.120678, Train Acc: 0.791026 | Val Loss: 0.137066, Val Acc: 0.701031\n",
      "Epoch 9905 - Train Loss: 0.120671, Train Acc: 0.791026 | Val Loss: 0.137060, Val Acc: 0.701031\n",
      "Epoch 9906 - Train Loss: 0.120663, Train Acc: 0.791026 | Val Loss: 0.137053, Val Acc: 0.701031\n",
      "Epoch 9907 - Train Loss: 0.120655, Train Acc: 0.791026 | Val Loss: 0.137047, Val Acc: 0.701031\n",
      "Epoch 9908 - Train Loss: 0.120648, Train Acc: 0.791026 | Val Loss: 0.137040, Val Acc: 0.701031\n",
      "Epoch 9909 - Train Loss: 0.120640, Train Acc: 0.791026 | Val Loss: 0.137033, Val Acc: 0.701031\n",
      "Epoch 9910 - Train Loss: 0.120632, Train Acc: 0.791026 | Val Loss: 0.137027, Val Acc: 0.701031\n",
      "Epoch 9911 - Train Loss: 0.120625, Train Acc: 0.791026 | Val Loss: 0.137020, Val Acc: 0.701031\n",
      "Epoch 9912 - Train Loss: 0.120617, Train Acc: 0.791026 | Val Loss: 0.137014, Val Acc: 0.701031\n",
      "Epoch 9913 - Train Loss: 0.120610, Train Acc: 0.791026 | Val Loss: 0.137007, Val Acc: 0.701031\n",
      "Epoch 9914 - Train Loss: 0.120602, Train Acc: 0.791026 | Val Loss: 0.137001, Val Acc: 0.701031\n",
      "Epoch 9915 - Train Loss: 0.120594, Train Acc: 0.791026 | Val Loss: 0.136994, Val Acc: 0.701031\n",
      "Epoch 9916 - Train Loss: 0.120587, Train Acc: 0.791026 | Val Loss: 0.136988, Val Acc: 0.701031\n",
      "Epoch 9917 - Train Loss: 0.120579, Train Acc: 0.791026 | Val Loss: 0.136981, Val Acc: 0.701031\n",
      "Epoch 9918 - Train Loss: 0.120572, Train Acc: 0.791026 | Val Loss: 0.136975, Val Acc: 0.701031\n",
      "Epoch 9919 - Train Loss: 0.120564, Train Acc: 0.792308 | Val Loss: 0.136968, Val Acc: 0.701031\n",
      "Epoch 9920 - Train Loss: 0.120556, Train Acc: 0.792308 | Val Loss: 0.136962, Val Acc: 0.701031\n",
      "Epoch 9921 - Train Loss: 0.120549, Train Acc: 0.792308 | Val Loss: 0.136955, Val Acc: 0.701031\n",
      "Epoch 9922 - Train Loss: 0.120541, Train Acc: 0.792308 | Val Loss: 0.136949, Val Acc: 0.701031\n",
      "Epoch 9923 - Train Loss: 0.120534, Train Acc: 0.792308 | Val Loss: 0.136942, Val Acc: 0.701031\n",
      "Epoch 9924 - Train Loss: 0.120526, Train Acc: 0.793590 | Val Loss: 0.136936, Val Acc: 0.701031\n",
      "Epoch 9925 - Train Loss: 0.120518, Train Acc: 0.793590 | Val Loss: 0.136929, Val Acc: 0.701031\n",
      "Epoch 9926 - Train Loss: 0.120511, Train Acc: 0.793590 | Val Loss: 0.136923, Val Acc: 0.701031\n",
      "Epoch 9927 - Train Loss: 0.120503, Train Acc: 0.793590 | Val Loss: 0.136916, Val Acc: 0.701031\n",
      "Epoch 9928 - Train Loss: 0.120496, Train Acc: 0.793590 | Val Loss: 0.136910, Val Acc: 0.701031\n",
      "Epoch 9929 - Train Loss: 0.120488, Train Acc: 0.793590 | Val Loss: 0.136903, Val Acc: 0.701031\n",
      "Epoch 9930 - Train Loss: 0.120480, Train Acc: 0.793590 | Val Loss: 0.136897, Val Acc: 0.701031\n",
      "Epoch 9931 - Train Loss: 0.120473, Train Acc: 0.793590 | Val Loss: 0.136890, Val Acc: 0.701031\n",
      "Epoch 9932 - Train Loss: 0.120465, Train Acc: 0.793590 | Val Loss: 0.136884, Val Acc: 0.701031\n",
      "Epoch 9933 - Train Loss: 0.120458, Train Acc: 0.793590 | Val Loss: 0.136877, Val Acc: 0.701031\n",
      "Epoch 9934 - Train Loss: 0.120450, Train Acc: 0.793590 | Val Loss: 0.136871, Val Acc: 0.701031\n",
      "Epoch 9935 - Train Loss: 0.120442, Train Acc: 0.793590 | Val Loss: 0.136864, Val Acc: 0.701031\n",
      "Epoch 9936 - Train Loss: 0.120435, Train Acc: 0.793590 | Val Loss: 0.136858, Val Acc: 0.701031\n",
      "Epoch 9937 - Train Loss: 0.120427, Train Acc: 0.793590 | Val Loss: 0.136852, Val Acc: 0.701031\n",
      "Epoch 9938 - Train Loss: 0.120420, Train Acc: 0.793590 | Val Loss: 0.136845, Val Acc: 0.701031\n",
      "Epoch 9939 - Train Loss: 0.120412, Train Acc: 0.793590 | Val Loss: 0.136839, Val Acc: 0.701031\n",
      "Epoch 9940 - Train Loss: 0.120405, Train Acc: 0.793590 | Val Loss: 0.136832, Val Acc: 0.701031\n",
      "Epoch 9941 - Train Loss: 0.120397, Train Acc: 0.793590 | Val Loss: 0.136826, Val Acc: 0.701031\n",
      "Epoch 9942 - Train Loss: 0.120389, Train Acc: 0.793590 | Val Loss: 0.136819, Val Acc: 0.701031\n",
      "Epoch 9943 - Train Loss: 0.120382, Train Acc: 0.793590 | Val Loss: 0.136813, Val Acc: 0.701031\n",
      "Epoch 9944 - Train Loss: 0.120374, Train Acc: 0.793590 | Val Loss: 0.136806, Val Acc: 0.701031\n",
      "Epoch 9945 - Train Loss: 0.120367, Train Acc: 0.793590 | Val Loss: 0.136800, Val Acc: 0.701031\n",
      "Epoch 9946 - Train Loss: 0.120359, Train Acc: 0.793590 | Val Loss: 0.136793, Val Acc: 0.701031\n",
      "Epoch 9947 - Train Loss: 0.120352, Train Acc: 0.793590 | Val Loss: 0.136787, Val Acc: 0.701031\n",
      "Epoch 9948 - Train Loss: 0.120344, Train Acc: 0.793590 | Val Loss: 0.136780, Val Acc: 0.701031\n",
      "Epoch 9949 - Train Loss: 0.120336, Train Acc: 0.793590 | Val Loss: 0.136774, Val Acc: 0.701031\n",
      "Epoch 9950 - Train Loss: 0.120329, Train Acc: 0.793590 | Val Loss: 0.136767, Val Acc: 0.701031\n",
      "Epoch 9951 - Train Loss: 0.120321, Train Acc: 0.793590 | Val Loss: 0.136761, Val Acc: 0.701031\n",
      "Epoch 9952 - Train Loss: 0.120314, Train Acc: 0.793590 | Val Loss: 0.136754, Val Acc: 0.701031\n",
      "Epoch 9953 - Train Loss: 0.120306, Train Acc: 0.793590 | Val Loss: 0.136748, Val Acc: 0.701031\n",
      "Epoch 9954 - Train Loss: 0.120299, Train Acc: 0.793590 | Val Loss: 0.136742, Val Acc: 0.701031\n",
      "Epoch 9955 - Train Loss: 0.120291, Train Acc: 0.793590 | Val Loss: 0.136735, Val Acc: 0.701031\n",
      "Epoch 9956 - Train Loss: 0.120283, Train Acc: 0.793590 | Val Loss: 0.136729, Val Acc: 0.701031\n",
      "Epoch 9957 - Train Loss: 0.120276, Train Acc: 0.793590 | Val Loss: 0.136722, Val Acc: 0.701031\n",
      "Epoch 9958 - Train Loss: 0.120268, Train Acc: 0.793590 | Val Loss: 0.136716, Val Acc: 0.701031\n",
      "Epoch 9959 - Train Loss: 0.120261, Train Acc: 0.794872 | Val Loss: 0.136709, Val Acc: 0.701031\n",
      "Epoch 9960 - Train Loss: 0.120253, Train Acc: 0.794872 | Val Loss: 0.136703, Val Acc: 0.701031\n",
      "Epoch 9961 - Train Loss: 0.120246, Train Acc: 0.794872 | Val Loss: 0.136696, Val Acc: 0.701031\n",
      "Epoch 9962 - Train Loss: 0.120238, Train Acc: 0.794872 | Val Loss: 0.136690, Val Acc: 0.701031\n",
      "Epoch 9963 - Train Loss: 0.120231, Train Acc: 0.794872 | Val Loss: 0.136684, Val Acc: 0.701031\n",
      "Epoch 9964 - Train Loss: 0.120223, Train Acc: 0.794872 | Val Loss: 0.136677, Val Acc: 0.701031\n",
      "Epoch 9965 - Train Loss: 0.120215, Train Acc: 0.794872 | Val Loss: 0.136671, Val Acc: 0.701031\n",
      "Epoch 9966 - Train Loss: 0.120208, Train Acc: 0.794872 | Val Loss: 0.136664, Val Acc: 0.701031\n",
      "Epoch 9967 - Train Loss: 0.120200, Train Acc: 0.794872 | Val Loss: 0.136658, Val Acc: 0.701031\n",
      "Epoch 9968 - Train Loss: 0.120193, Train Acc: 0.794872 | Val Loss: 0.136651, Val Acc: 0.701031\n",
      "Epoch 9969 - Train Loss: 0.120185, Train Acc: 0.794872 | Val Loss: 0.136645, Val Acc: 0.701031\n",
      "Epoch 9970 - Train Loss: 0.120178, Train Acc: 0.794872 | Val Loss: 0.136638, Val Acc: 0.701031\n",
      "Epoch 9971 - Train Loss: 0.120170, Train Acc: 0.794872 | Val Loss: 0.136632, Val Acc: 0.701031\n",
      "Epoch 9972 - Train Loss: 0.120163, Train Acc: 0.794872 | Val Loss: 0.136626, Val Acc: 0.701031\n",
      "Epoch 9973 - Train Loss: 0.120155, Train Acc: 0.794872 | Val Loss: 0.136619, Val Acc: 0.701031\n",
      "Epoch 9974 - Train Loss: 0.120147, Train Acc: 0.794872 | Val Loss: 0.136613, Val Acc: 0.701031\n",
      "Epoch 9975 - Train Loss: 0.120140, Train Acc: 0.794872 | Val Loss: 0.136606, Val Acc: 0.701031\n",
      "Epoch 9976 - Train Loss: 0.120132, Train Acc: 0.794872 | Val Loss: 0.136600, Val Acc: 0.701031\n",
      "Epoch 9977 - Train Loss: 0.120125, Train Acc: 0.794872 | Val Loss: 0.136593, Val Acc: 0.701031\n",
      "Epoch 9978 - Train Loss: 0.120117, Train Acc: 0.794872 | Val Loss: 0.136587, Val Acc: 0.701031\n",
      "Epoch 9979 - Train Loss: 0.120110, Train Acc: 0.794872 | Val Loss: 0.136581, Val Acc: 0.701031\n",
      "Epoch 9980 - Train Loss: 0.120102, Train Acc: 0.794872 | Val Loss: 0.136574, Val Acc: 0.701031\n",
      "Epoch 9981 - Train Loss: 0.120095, Train Acc: 0.794872 | Val Loss: 0.136568, Val Acc: 0.701031\n",
      "Epoch 9982 - Train Loss: 0.120087, Train Acc: 0.794872 | Val Loss: 0.136561, Val Acc: 0.701031\n",
      "Epoch 9983 - Train Loss: 0.120080, Train Acc: 0.794872 | Val Loss: 0.136555, Val Acc: 0.701031\n",
      "Epoch 9984 - Train Loss: 0.120072, Train Acc: 0.794872 | Val Loss: 0.136549, Val Acc: 0.701031\n",
      "Epoch 9985 - Train Loss: 0.120065, Train Acc: 0.794872 | Val Loss: 0.136542, Val Acc: 0.701031\n",
      "Epoch 9986 - Train Loss: 0.120057, Train Acc: 0.794872 | Val Loss: 0.136536, Val Acc: 0.701031\n",
      "Epoch 9987 - Train Loss: 0.120050, Train Acc: 0.794872 | Val Loss: 0.136529, Val Acc: 0.701031\n",
      "Epoch 9988 - Train Loss: 0.120042, Train Acc: 0.794872 | Val Loss: 0.136523, Val Acc: 0.701031\n",
      "Epoch 9989 - Train Loss: 0.120035, Train Acc: 0.794872 | Val Loss: 0.136517, Val Acc: 0.701031\n",
      "Epoch 9990 - Train Loss: 0.120027, Train Acc: 0.794872 | Val Loss: 0.136510, Val Acc: 0.701031\n",
      "Epoch 9991 - Train Loss: 0.120019, Train Acc: 0.794872 | Val Loss: 0.136504, Val Acc: 0.701031\n",
      "Epoch 9992 - Train Loss: 0.120012, Train Acc: 0.794872 | Val Loss: 0.136497, Val Acc: 0.701031\n",
      "Epoch 9993 - Train Loss: 0.120004, Train Acc: 0.794872 | Val Loss: 0.136491, Val Acc: 0.701031\n",
      "Epoch 9994 - Train Loss: 0.119997, Train Acc: 0.794872 | Val Loss: 0.136484, Val Acc: 0.701031\n",
      "Epoch 9995 - Train Loss: 0.119989, Train Acc: 0.794872 | Val Loss: 0.136478, Val Acc: 0.701031\n",
      "Epoch 9996 - Train Loss: 0.119982, Train Acc: 0.794872 | Val Loss: 0.136472, Val Acc: 0.701031\n",
      "Epoch 9997 - Train Loss: 0.119974, Train Acc: 0.794872 | Val Loss: 0.136465, Val Acc: 0.701031\n",
      "Epoch 9998 - Train Loss: 0.119967, Train Acc: 0.794872 | Val Loss: 0.136459, Val Acc: 0.701031\n",
      "Epoch 9999 - Train Loss: 0.119959, Train Acc: 0.794872 | Val Loss: 0.136452, Val Acc: 0.701031\n",
      "Epoch 10000 - Train Loss: 0.119952, Train Acc: 0.794872 | Val Loss: 0.136446, Val Acc: 0.701031\n",
      "Epoch 10001 - Train Loss: 0.119944, Train Acc: 0.794872 | Val Loss: 0.136440, Val Acc: 0.701031\n",
      "Epoch 10002 - Train Loss: 0.119937, Train Acc: 0.794872 | Val Loss: 0.136433, Val Acc: 0.701031\n",
      "Epoch 10003 - Train Loss: 0.119929, Train Acc: 0.794872 | Val Loss: 0.136427, Val Acc: 0.701031\n",
      "Epoch 10004 - Train Loss: 0.119922, Train Acc: 0.794872 | Val Loss: 0.136420, Val Acc: 0.701031\n",
      "Epoch 10005 - Train Loss: 0.119914, Train Acc: 0.794872 | Val Loss: 0.136414, Val Acc: 0.701031\n",
      "Epoch 10006 - Train Loss: 0.119907, Train Acc: 0.794872 | Val Loss: 0.136408, Val Acc: 0.701031\n",
      "Epoch 10007 - Train Loss: 0.119899, Train Acc: 0.794872 | Val Loss: 0.136401, Val Acc: 0.701031\n",
      "Epoch 10008 - Train Loss: 0.119892, Train Acc: 0.794872 | Val Loss: 0.136395, Val Acc: 0.701031\n",
      "Epoch 10009 - Train Loss: 0.119884, Train Acc: 0.794872 | Val Loss: 0.136389, Val Acc: 0.701031\n",
      "Epoch 10010 - Train Loss: 0.119877, Train Acc: 0.794872 | Val Loss: 0.136382, Val Acc: 0.701031\n",
      "Epoch 10011 - Train Loss: 0.119869, Train Acc: 0.794872 | Val Loss: 0.136376, Val Acc: 0.701031\n",
      "Epoch 10012 - Train Loss: 0.119862, Train Acc: 0.794872 | Val Loss: 0.136369, Val Acc: 0.701031\n",
      "Epoch 10013 - Train Loss: 0.119854, Train Acc: 0.794872 | Val Loss: 0.136363, Val Acc: 0.701031\n",
      "Epoch 10014 - Train Loss: 0.119847, Train Acc: 0.794872 | Val Loss: 0.136357, Val Acc: 0.701031\n",
      "Epoch 10015 - Train Loss: 0.119839, Train Acc: 0.794872 | Val Loss: 0.136350, Val Acc: 0.701031\n",
      "Epoch 10016 - Train Loss: 0.119832, Train Acc: 0.794872 | Val Loss: 0.136344, Val Acc: 0.701031\n",
      "Epoch 10017 - Train Loss: 0.119824, Train Acc: 0.794872 | Val Loss: 0.136338, Val Acc: 0.701031\n",
      "Epoch 10018 - Train Loss: 0.119817, Train Acc: 0.794872 | Val Loss: 0.136331, Val Acc: 0.701031\n",
      "Epoch 10019 - Train Loss: 0.119809, Train Acc: 0.794872 | Val Loss: 0.136325, Val Acc: 0.701031\n",
      "Epoch 10020 - Train Loss: 0.119802, Train Acc: 0.794872 | Val Loss: 0.136318, Val Acc: 0.701031\n",
      "Epoch 10021 - Train Loss: 0.119794, Train Acc: 0.794872 | Val Loss: 0.136312, Val Acc: 0.701031\n",
      "Epoch 10022 - Train Loss: 0.119787, Train Acc: 0.794872 | Val Loss: 0.136306, Val Acc: 0.701031\n",
      "Epoch 10023 - Train Loss: 0.119779, Train Acc: 0.794872 | Val Loss: 0.136299, Val Acc: 0.701031\n",
      "Epoch 10024 - Train Loss: 0.119772, Train Acc: 0.794872 | Val Loss: 0.136293, Val Acc: 0.701031\n",
      "Epoch 10025 - Train Loss: 0.119764, Train Acc: 0.796154 | Val Loss: 0.136287, Val Acc: 0.701031\n",
      "Epoch 10026 - Train Loss: 0.119757, Train Acc: 0.796154 | Val Loss: 0.136280, Val Acc: 0.701031\n",
      "Epoch 10027 - Train Loss: 0.119749, Train Acc: 0.796154 | Val Loss: 0.136274, Val Acc: 0.701031\n",
      "Epoch 10028 - Train Loss: 0.119742, Train Acc: 0.796154 | Val Loss: 0.136268, Val Acc: 0.701031\n",
      "Epoch 10029 - Train Loss: 0.119734, Train Acc: 0.796154 | Val Loss: 0.136261, Val Acc: 0.701031\n",
      "Epoch 10030 - Train Loss: 0.119727, Train Acc: 0.796154 | Val Loss: 0.136255, Val Acc: 0.711340\n",
      "Epoch 10031 - Train Loss: 0.119719, Train Acc: 0.796154 | Val Loss: 0.136248, Val Acc: 0.711340\n",
      "Epoch 10032 - Train Loss: 0.119712, Train Acc: 0.796154 | Val Loss: 0.136242, Val Acc: 0.711340\n",
      "Epoch 10033 - Train Loss: 0.119705, Train Acc: 0.796154 | Val Loss: 0.136236, Val Acc: 0.711340\n",
      "Epoch 10034 - Train Loss: 0.119697, Train Acc: 0.796154 | Val Loss: 0.136229, Val Acc: 0.711340\n",
      "Epoch 10035 - Train Loss: 0.119690, Train Acc: 0.796154 | Val Loss: 0.136223, Val Acc: 0.711340\n",
      "Epoch 10036 - Train Loss: 0.119682, Train Acc: 0.796154 | Val Loss: 0.136217, Val Acc: 0.711340\n",
      "Epoch 10037 - Train Loss: 0.119675, Train Acc: 0.796154 | Val Loss: 0.136210, Val Acc: 0.711340\n",
      "Epoch 10038 - Train Loss: 0.119667, Train Acc: 0.796154 | Val Loss: 0.136204, Val Acc: 0.711340\n",
      "Epoch 10039 - Train Loss: 0.119660, Train Acc: 0.796154 | Val Loss: 0.136198, Val Acc: 0.711340\n",
      "Epoch 10040 - Train Loss: 0.119652, Train Acc: 0.796154 | Val Loss: 0.136191, Val Acc: 0.711340\n",
      "Epoch 10041 - Train Loss: 0.119645, Train Acc: 0.796154 | Val Loss: 0.136185, Val Acc: 0.711340\n",
      "Epoch 10042 - Train Loss: 0.119637, Train Acc: 0.796154 | Val Loss: 0.136179, Val Acc: 0.711340\n",
      "Epoch 10043 - Train Loss: 0.119630, Train Acc: 0.796154 | Val Loss: 0.136172, Val Acc: 0.711340\n",
      "Epoch 10044 - Train Loss: 0.119622, Train Acc: 0.796154 | Val Loss: 0.136166, Val Acc: 0.711340\n",
      "Epoch 10045 - Train Loss: 0.119615, Train Acc: 0.796154 | Val Loss: 0.136160, Val Acc: 0.711340\n",
      "Epoch 10046 - Train Loss: 0.119607, Train Acc: 0.796154 | Val Loss: 0.136153, Val Acc: 0.711340\n",
      "Epoch 10047 - Train Loss: 0.119600, Train Acc: 0.796154 | Val Loss: 0.136147, Val Acc: 0.711340\n",
      "Epoch 10048 - Train Loss: 0.119593, Train Acc: 0.796154 | Val Loss: 0.136141, Val Acc: 0.711340\n",
      "Epoch 10049 - Train Loss: 0.119585, Train Acc: 0.796154 | Val Loss: 0.136134, Val Acc: 0.711340\n",
      "Epoch 10050 - Train Loss: 0.119578, Train Acc: 0.796154 | Val Loss: 0.136128, Val Acc: 0.711340\n",
      "Epoch 10051 - Train Loss: 0.119570, Train Acc: 0.796154 | Val Loss: 0.136122, Val Acc: 0.711340\n",
      "Epoch 10052 - Train Loss: 0.119563, Train Acc: 0.796154 | Val Loss: 0.136115, Val Acc: 0.711340\n",
      "Epoch 10053 - Train Loss: 0.119555, Train Acc: 0.796154 | Val Loss: 0.136109, Val Acc: 0.711340\n",
      "Epoch 10054 - Train Loss: 0.119548, Train Acc: 0.796154 | Val Loss: 0.136103, Val Acc: 0.711340\n",
      "Epoch 10055 - Train Loss: 0.119540, Train Acc: 0.796154 | Val Loss: 0.136096, Val Acc: 0.711340\n",
      "Epoch 10056 - Train Loss: 0.119533, Train Acc: 0.796154 | Val Loss: 0.136090, Val Acc: 0.711340\n",
      "Epoch 10057 - Train Loss: 0.119525, Train Acc: 0.796154 | Val Loss: 0.136084, Val Acc: 0.711340\n",
      "Epoch 10058 - Train Loss: 0.119518, Train Acc: 0.796154 | Val Loss: 0.136077, Val Acc: 0.711340\n",
      "Epoch 10059 - Train Loss: 0.119511, Train Acc: 0.796154 | Val Loss: 0.136071, Val Acc: 0.711340\n",
      "Epoch 10060 - Train Loss: 0.119503, Train Acc: 0.796154 | Val Loss: 0.136065, Val Acc: 0.711340\n",
      "Epoch 10061 - Train Loss: 0.119496, Train Acc: 0.796154 | Val Loss: 0.136058, Val Acc: 0.711340\n",
      "Epoch 10062 - Train Loss: 0.119488, Train Acc: 0.796154 | Val Loss: 0.136052, Val Acc: 0.711340\n",
      "Epoch 10063 - Train Loss: 0.119481, Train Acc: 0.796154 | Val Loss: 0.136046, Val Acc: 0.711340\n",
      "Epoch 10064 - Train Loss: 0.119473, Train Acc: 0.796154 | Val Loss: 0.136039, Val Acc: 0.711340\n",
      "Epoch 10065 - Train Loss: 0.119466, Train Acc: 0.796154 | Val Loss: 0.136033, Val Acc: 0.711340\n",
      "Epoch 10066 - Train Loss: 0.119458, Train Acc: 0.796154 | Val Loss: 0.136027, Val Acc: 0.711340\n",
      "Epoch 10067 - Train Loss: 0.119451, Train Acc: 0.796154 | Val Loss: 0.136021, Val Acc: 0.711340\n",
      "Epoch 10068 - Train Loss: 0.119444, Train Acc: 0.796154 | Val Loss: 0.136014, Val Acc: 0.711340\n",
      "Epoch 10069 - Train Loss: 0.119436, Train Acc: 0.798718 | Val Loss: 0.136008, Val Acc: 0.711340\n",
      "Epoch 10070 - Train Loss: 0.119429, Train Acc: 0.798718 | Val Loss: 0.136002, Val Acc: 0.711340\n",
      "Epoch 10071 - Train Loss: 0.119421, Train Acc: 0.798718 | Val Loss: 0.135995, Val Acc: 0.711340\n",
      "Epoch 10072 - Train Loss: 0.119414, Train Acc: 0.798718 | Val Loss: 0.135989, Val Acc: 0.711340\n",
      "Epoch 10073 - Train Loss: 0.119406, Train Acc: 0.798718 | Val Loss: 0.135983, Val Acc: 0.711340\n",
      "Epoch 10074 - Train Loss: 0.119399, Train Acc: 0.798718 | Val Loss: 0.135976, Val Acc: 0.711340\n",
      "Epoch 10075 - Train Loss: 0.119392, Train Acc: 0.798718 | Val Loss: 0.135970, Val Acc: 0.711340\n",
      "Epoch 10076 - Train Loss: 0.119384, Train Acc: 0.800000 | Val Loss: 0.135964, Val Acc: 0.711340\n",
      "Epoch 10077 - Train Loss: 0.119377, Train Acc: 0.800000 | Val Loss: 0.135957, Val Acc: 0.711340\n",
      "Epoch 10078 - Train Loss: 0.119369, Train Acc: 0.800000 | Val Loss: 0.135951, Val Acc: 0.711340\n",
      "Epoch 10079 - Train Loss: 0.119362, Train Acc: 0.800000 | Val Loss: 0.135945, Val Acc: 0.711340\n",
      "Epoch 10080 - Train Loss: 0.119354, Train Acc: 0.800000 | Val Loss: 0.135938, Val Acc: 0.711340\n",
      "Epoch 10081 - Train Loss: 0.119347, Train Acc: 0.800000 | Val Loss: 0.135932, Val Acc: 0.711340\n",
      "Epoch 10082 - Train Loss: 0.119340, Train Acc: 0.800000 | Val Loss: 0.135926, Val Acc: 0.711340\n",
      "Epoch 10083 - Train Loss: 0.119332, Train Acc: 0.800000 | Val Loss: 0.135920, Val Acc: 0.711340\n",
      "Epoch 10084 - Train Loss: 0.119325, Train Acc: 0.800000 | Val Loss: 0.135913, Val Acc: 0.711340\n",
      "Epoch 10085 - Train Loss: 0.119317, Train Acc: 0.800000 | Val Loss: 0.135907, Val Acc: 0.711340\n",
      "Epoch 10086 - Train Loss: 0.119310, Train Acc: 0.800000 | Val Loss: 0.135901, Val Acc: 0.711340\n",
      "Epoch 10087 - Train Loss: 0.119302, Train Acc: 0.800000 | Val Loss: 0.135894, Val Acc: 0.711340\n",
      "Epoch 10088 - Train Loss: 0.119295, Train Acc: 0.800000 | Val Loss: 0.135888, Val Acc: 0.711340\n",
      "Epoch 10089 - Train Loss: 0.119288, Train Acc: 0.800000 | Val Loss: 0.135882, Val Acc: 0.711340\n",
      "Epoch 10090 - Train Loss: 0.119280, Train Acc: 0.801282 | Val Loss: 0.135876, Val Acc: 0.711340\n",
      "Epoch 10091 - Train Loss: 0.119273, Train Acc: 0.801282 | Val Loss: 0.135869, Val Acc: 0.711340\n",
      "Epoch 10092 - Train Loss: 0.119265, Train Acc: 0.801282 | Val Loss: 0.135863, Val Acc: 0.711340\n",
      "Epoch 10093 - Train Loss: 0.119258, Train Acc: 0.801282 | Val Loss: 0.135857, Val Acc: 0.711340\n",
      "Epoch 10094 - Train Loss: 0.119251, Train Acc: 0.801282 | Val Loss: 0.135850, Val Acc: 0.711340\n",
      "Epoch 10095 - Train Loss: 0.119243, Train Acc: 0.801282 | Val Loss: 0.135844, Val Acc: 0.711340\n",
      "Epoch 10096 - Train Loss: 0.119236, Train Acc: 0.801282 | Val Loss: 0.135838, Val Acc: 0.711340\n",
      "Epoch 10097 - Train Loss: 0.119228, Train Acc: 0.801282 | Val Loss: 0.135832, Val Acc: 0.711340\n",
      "Epoch 10098 - Train Loss: 0.119221, Train Acc: 0.801282 | Val Loss: 0.135825, Val Acc: 0.711340\n",
      "Epoch 10099 - Train Loss: 0.119213, Train Acc: 0.801282 | Val Loss: 0.135819, Val Acc: 0.711340\n",
      "Epoch 10100 - Train Loss: 0.119206, Train Acc: 0.801282 | Val Loss: 0.135813, Val Acc: 0.711340\n",
      "Epoch 10101 - Train Loss: 0.119199, Train Acc: 0.801282 | Val Loss: 0.135806, Val Acc: 0.711340\n",
      "Epoch 10102 - Train Loss: 0.119191, Train Acc: 0.801282 | Val Loss: 0.135800, Val Acc: 0.711340\n",
      "Epoch 10103 - Train Loss: 0.119184, Train Acc: 0.801282 | Val Loss: 0.135794, Val Acc: 0.711340\n",
      "Epoch 10104 - Train Loss: 0.119176, Train Acc: 0.801282 | Val Loss: 0.135788, Val Acc: 0.711340\n",
      "Epoch 10105 - Train Loss: 0.119169, Train Acc: 0.801282 | Val Loss: 0.135781, Val Acc: 0.711340\n",
      "Epoch 10106 - Train Loss: 0.119162, Train Acc: 0.801282 | Val Loss: 0.135775, Val Acc: 0.711340\n",
      "Epoch 10107 - Train Loss: 0.119154, Train Acc: 0.801282 | Val Loss: 0.135769, Val Acc: 0.711340\n",
      "Epoch 10108 - Train Loss: 0.119147, Train Acc: 0.801282 | Val Loss: 0.135763, Val Acc: 0.711340\n",
      "Epoch 10109 - Train Loss: 0.119140, Train Acc: 0.801282 | Val Loss: 0.135756, Val Acc: 0.711340\n",
      "Epoch 10110 - Train Loss: 0.119132, Train Acc: 0.801282 | Val Loss: 0.135750, Val Acc: 0.711340\n",
      "Epoch 10111 - Train Loss: 0.119125, Train Acc: 0.801282 | Val Loss: 0.135744, Val Acc: 0.711340\n",
      "Epoch 10112 - Train Loss: 0.119117, Train Acc: 0.801282 | Val Loss: 0.135738, Val Acc: 0.711340\n",
      "Epoch 10113 - Train Loss: 0.119110, Train Acc: 0.801282 | Val Loss: 0.135731, Val Acc: 0.711340\n",
      "Epoch 10114 - Train Loss: 0.119103, Train Acc: 0.801282 | Val Loss: 0.135725, Val Acc: 0.711340\n",
      "Epoch 10115 - Train Loss: 0.119095, Train Acc: 0.801282 | Val Loss: 0.135719, Val Acc: 0.711340\n",
      "Epoch 10116 - Train Loss: 0.119088, Train Acc: 0.801282 | Val Loss: 0.135713, Val Acc: 0.711340\n",
      "Epoch 10117 - Train Loss: 0.119080, Train Acc: 0.801282 | Val Loss: 0.135706, Val Acc: 0.711340\n",
      "Epoch 10118 - Train Loss: 0.119073, Train Acc: 0.801282 | Val Loss: 0.135700, Val Acc: 0.711340\n",
      "Epoch 10119 - Train Loss: 0.119066, Train Acc: 0.801282 | Val Loss: 0.135694, Val Acc: 0.711340\n",
      "Epoch 10120 - Train Loss: 0.119058, Train Acc: 0.801282 | Val Loss: 0.135688, Val Acc: 0.711340\n",
      "Epoch 10121 - Train Loss: 0.119051, Train Acc: 0.801282 | Val Loss: 0.135681, Val Acc: 0.711340\n",
      "Epoch 10122 - Train Loss: 0.119044, Train Acc: 0.801282 | Val Loss: 0.135675, Val Acc: 0.711340\n",
      "Epoch 10123 - Train Loss: 0.119036, Train Acc: 0.801282 | Val Loss: 0.135669, Val Acc: 0.711340\n",
      "Epoch 10124 - Train Loss: 0.119029, Train Acc: 0.801282 | Val Loss: 0.135663, Val Acc: 0.711340\n",
      "Epoch 10125 - Train Loss: 0.119021, Train Acc: 0.801282 | Val Loss: 0.135656, Val Acc: 0.711340\n",
      "Epoch 10126 - Train Loss: 0.119014, Train Acc: 0.801282 | Val Loss: 0.135650, Val Acc: 0.711340\n",
      "Epoch 10127 - Train Loss: 0.119007, Train Acc: 0.801282 | Val Loss: 0.135644, Val Acc: 0.711340\n",
      "Epoch 10128 - Train Loss: 0.118999, Train Acc: 0.801282 | Val Loss: 0.135638, Val Acc: 0.711340\n",
      "Epoch 10129 - Train Loss: 0.118992, Train Acc: 0.801282 | Val Loss: 0.135631, Val Acc: 0.711340\n",
      "Epoch 10130 - Train Loss: 0.118985, Train Acc: 0.801282 | Val Loss: 0.135625, Val Acc: 0.711340\n",
      "Epoch 10131 - Train Loss: 0.118977, Train Acc: 0.801282 | Val Loss: 0.135619, Val Acc: 0.711340\n",
      "Epoch 10132 - Train Loss: 0.118970, Train Acc: 0.801282 | Val Loss: 0.135613, Val Acc: 0.711340\n",
      "Epoch 10133 - Train Loss: 0.118962, Train Acc: 0.801282 | Val Loss: 0.135606, Val Acc: 0.711340\n",
      "Epoch 10134 - Train Loss: 0.118955, Train Acc: 0.801282 | Val Loss: 0.135600, Val Acc: 0.711340\n",
      "Epoch 10135 - Train Loss: 0.118948, Train Acc: 0.801282 | Val Loss: 0.135594, Val Acc: 0.711340\n",
      "Epoch 10136 - Train Loss: 0.118940, Train Acc: 0.801282 | Val Loss: 0.135588, Val Acc: 0.711340\n",
      "Epoch 10137 - Train Loss: 0.118933, Train Acc: 0.801282 | Val Loss: 0.135581, Val Acc: 0.711340\n",
      "Epoch 10138 - Train Loss: 0.118926, Train Acc: 0.801282 | Val Loss: 0.135575, Val Acc: 0.711340\n",
      "Epoch 10139 - Train Loss: 0.118918, Train Acc: 0.801282 | Val Loss: 0.135569, Val Acc: 0.711340\n",
      "Epoch 10140 - Train Loss: 0.118911, Train Acc: 0.802564 | Val Loss: 0.135563, Val Acc: 0.711340\n",
      "Epoch 10141 - Train Loss: 0.118903, Train Acc: 0.802564 | Val Loss: 0.135557, Val Acc: 0.711340\n",
      "Epoch 10142 - Train Loss: 0.118896, Train Acc: 0.802564 | Val Loss: 0.135550, Val Acc: 0.711340\n",
      "Epoch 10143 - Train Loss: 0.118889, Train Acc: 0.802564 | Val Loss: 0.135544, Val Acc: 0.711340\n",
      "Epoch 10144 - Train Loss: 0.118881, Train Acc: 0.802564 | Val Loss: 0.135538, Val Acc: 0.711340\n",
      "Epoch 10145 - Train Loss: 0.118874, Train Acc: 0.802564 | Val Loss: 0.135532, Val Acc: 0.711340\n",
      "Epoch 10146 - Train Loss: 0.118867, Train Acc: 0.802564 | Val Loss: 0.135525, Val Acc: 0.711340\n",
      "Epoch 10147 - Train Loss: 0.118859, Train Acc: 0.802564 | Val Loss: 0.135519, Val Acc: 0.711340\n",
      "Epoch 10148 - Train Loss: 0.118852, Train Acc: 0.802564 | Val Loss: 0.135513, Val Acc: 0.711340\n",
      "Epoch 10149 - Train Loss: 0.118845, Train Acc: 0.802564 | Val Loss: 0.135507, Val Acc: 0.711340\n",
      "Epoch 10150 - Train Loss: 0.118837, Train Acc: 0.802564 | Val Loss: 0.135500, Val Acc: 0.711340\n",
      "Epoch 10151 - Train Loss: 0.118830, Train Acc: 0.802564 | Val Loss: 0.135494, Val Acc: 0.711340\n",
      "Epoch 10152 - Train Loss: 0.118823, Train Acc: 0.802564 | Val Loss: 0.135488, Val Acc: 0.711340\n",
      "Epoch 10153 - Train Loss: 0.118815, Train Acc: 0.802564 | Val Loss: 0.135482, Val Acc: 0.711340\n",
      "Epoch 10154 - Train Loss: 0.118808, Train Acc: 0.802564 | Val Loss: 0.135475, Val Acc: 0.711340\n",
      "Epoch 10155 - Train Loss: 0.118801, Train Acc: 0.802564 | Val Loss: 0.135469, Val Acc: 0.711340\n",
      "Epoch 10156 - Train Loss: 0.118793, Train Acc: 0.802564 | Val Loss: 0.135463, Val Acc: 0.711340\n",
      "Epoch 10157 - Train Loss: 0.118786, Train Acc: 0.802564 | Val Loss: 0.135457, Val Acc: 0.711340\n",
      "Epoch 10158 - Train Loss: 0.118779, Train Acc: 0.802564 | Val Loss: 0.135450, Val Acc: 0.711340\n",
      "Epoch 10159 - Train Loss: 0.118771, Train Acc: 0.802564 | Val Loss: 0.135444, Val Acc: 0.711340\n",
      "Epoch 10160 - Train Loss: 0.118764, Train Acc: 0.802564 | Val Loss: 0.135438, Val Acc: 0.711340\n",
      "Epoch 10161 - Train Loss: 0.118757, Train Acc: 0.802564 | Val Loss: 0.135432, Val Acc: 0.711340\n",
      "Epoch 10162 - Train Loss: 0.118749, Train Acc: 0.802564 | Val Loss: 0.135426, Val Acc: 0.711340\n",
      "Epoch 10163 - Train Loss: 0.118742, Train Acc: 0.802564 | Val Loss: 0.135419, Val Acc: 0.711340\n",
      "Epoch 10164 - Train Loss: 0.118734, Train Acc: 0.802564 | Val Loss: 0.135413, Val Acc: 0.711340\n",
      "Epoch 10165 - Train Loss: 0.118727, Train Acc: 0.802564 | Val Loss: 0.135407, Val Acc: 0.711340\n",
      "Epoch 10166 - Train Loss: 0.118720, Train Acc: 0.802564 | Val Loss: 0.135401, Val Acc: 0.711340\n",
      "Epoch 10167 - Train Loss: 0.118712, Train Acc: 0.802564 | Val Loss: 0.135395, Val Acc: 0.711340\n",
      "Epoch 10168 - Train Loss: 0.118705, Train Acc: 0.802564 | Val Loss: 0.135388, Val Acc: 0.711340\n",
      "Epoch 10169 - Train Loss: 0.118698, Train Acc: 0.802564 | Val Loss: 0.135382, Val Acc: 0.711340\n",
      "Epoch 10170 - Train Loss: 0.118690, Train Acc: 0.802564 | Val Loss: 0.135376, Val Acc: 0.711340\n",
      "Epoch 10171 - Train Loss: 0.118683, Train Acc: 0.802564 | Val Loss: 0.135370, Val Acc: 0.711340\n",
      "Epoch 10172 - Train Loss: 0.118676, Train Acc: 0.802564 | Val Loss: 0.135363, Val Acc: 0.711340\n",
      "Epoch 10173 - Train Loss: 0.118669, Train Acc: 0.802564 | Val Loss: 0.135357, Val Acc: 0.711340\n",
      "Epoch 10174 - Train Loss: 0.118661, Train Acc: 0.802564 | Val Loss: 0.135351, Val Acc: 0.711340\n",
      "Epoch 10175 - Train Loss: 0.118654, Train Acc: 0.802564 | Val Loss: 0.135345, Val Acc: 0.711340\n",
      "Epoch 10176 - Train Loss: 0.118647, Train Acc: 0.802564 | Val Loss: 0.135339, Val Acc: 0.711340\n",
      "Epoch 10177 - Train Loss: 0.118639, Train Acc: 0.802564 | Val Loss: 0.135332, Val Acc: 0.711340\n",
      "Epoch 10178 - Train Loss: 0.118632, Train Acc: 0.802564 | Val Loss: 0.135326, Val Acc: 0.711340\n",
      "Epoch 10179 - Train Loss: 0.118625, Train Acc: 0.802564 | Val Loss: 0.135320, Val Acc: 0.711340\n",
      "Epoch 10180 - Train Loss: 0.118617, Train Acc: 0.802564 | Val Loss: 0.135314, Val Acc: 0.711340\n",
      "Epoch 10181 - Train Loss: 0.118610, Train Acc: 0.802564 | Val Loss: 0.135308, Val Acc: 0.711340\n",
      "Epoch 10182 - Train Loss: 0.118603, Train Acc: 0.802564 | Val Loss: 0.135301, Val Acc: 0.711340\n",
      "Epoch 10183 - Train Loss: 0.118595, Train Acc: 0.802564 | Val Loss: 0.135295, Val Acc: 0.711340\n",
      "Epoch 10184 - Train Loss: 0.118588, Train Acc: 0.802564 | Val Loss: 0.135289, Val Acc: 0.711340\n",
      "Epoch 10185 - Train Loss: 0.118581, Train Acc: 0.802564 | Val Loss: 0.135283, Val Acc: 0.711340\n",
      "Epoch 10186 - Train Loss: 0.118573, Train Acc: 0.802564 | Val Loss: 0.135277, Val Acc: 0.711340\n",
      "Epoch 10187 - Train Loss: 0.118566, Train Acc: 0.802564 | Val Loss: 0.135270, Val Acc: 0.711340\n",
      "Epoch 10188 - Train Loss: 0.118559, Train Acc: 0.802564 | Val Loss: 0.135264, Val Acc: 0.711340\n",
      "Epoch 10189 - Train Loss: 0.118551, Train Acc: 0.802564 | Val Loss: 0.135258, Val Acc: 0.711340\n",
      "Epoch 10190 - Train Loss: 0.118544, Train Acc: 0.802564 | Val Loss: 0.135252, Val Acc: 0.711340\n",
      "Epoch 10191 - Train Loss: 0.118537, Train Acc: 0.802564 | Val Loss: 0.135246, Val Acc: 0.711340\n",
      "Epoch 10192 - Train Loss: 0.118529, Train Acc: 0.802564 | Val Loss: 0.135239, Val Acc: 0.711340\n",
      "Epoch 10193 - Train Loss: 0.118522, Train Acc: 0.802564 | Val Loss: 0.135233, Val Acc: 0.711340\n",
      "Epoch 10194 - Train Loss: 0.118515, Train Acc: 0.802564 | Val Loss: 0.135227, Val Acc: 0.711340\n",
      "Epoch 10195 - Train Loss: 0.118507, Train Acc: 0.802564 | Val Loss: 0.135221, Val Acc: 0.711340\n",
      "Epoch 10196 - Train Loss: 0.118500, Train Acc: 0.802564 | Val Loss: 0.135214, Val Acc: 0.711340\n",
      "Epoch 10197 - Train Loss: 0.118493, Train Acc: 0.802564 | Val Loss: 0.135208, Val Acc: 0.711340\n",
      "Epoch 10198 - Train Loss: 0.118486, Train Acc: 0.802564 | Val Loss: 0.135202, Val Acc: 0.711340\n",
      "Epoch 10199 - Train Loss: 0.118478, Train Acc: 0.802564 | Val Loss: 0.135196, Val Acc: 0.711340\n",
      "Epoch 10200 - Train Loss: 0.118471, Train Acc: 0.802564 | Val Loss: 0.135190, Val Acc: 0.711340\n",
      "Epoch 10201 - Train Loss: 0.118464, Train Acc: 0.802564 | Val Loss: 0.135183, Val Acc: 0.711340\n",
      "Epoch 10202 - Train Loss: 0.118456, Train Acc: 0.802564 | Val Loss: 0.135177, Val Acc: 0.711340\n",
      "Epoch 10203 - Train Loss: 0.118449, Train Acc: 0.802564 | Val Loss: 0.135171, Val Acc: 0.711340\n",
      "Epoch 10204 - Train Loss: 0.118442, Train Acc: 0.802564 | Val Loss: 0.135165, Val Acc: 0.711340\n",
      "Epoch 10205 - Train Loss: 0.118434, Train Acc: 0.802564 | Val Loss: 0.135159, Val Acc: 0.711340\n",
      "Epoch 10206 - Train Loss: 0.118427, Train Acc: 0.802564 | Val Loss: 0.135152, Val Acc: 0.711340\n",
      "Epoch 10207 - Train Loss: 0.118420, Train Acc: 0.802564 | Val Loss: 0.135146, Val Acc: 0.711340\n",
      "Epoch 10208 - Train Loss: 0.118413, Train Acc: 0.802564 | Val Loss: 0.135140, Val Acc: 0.711340\n",
      "Epoch 10209 - Train Loss: 0.118405, Train Acc: 0.802564 | Val Loss: 0.135134, Val Acc: 0.711340\n",
      "Epoch 10210 - Train Loss: 0.118398, Train Acc: 0.802564 | Val Loss: 0.135128, Val Acc: 0.711340\n",
      "Epoch 10211 - Train Loss: 0.118391, Train Acc: 0.802564 | Val Loss: 0.135122, Val Acc: 0.711340\n",
      "Epoch 10212 - Train Loss: 0.118383, Train Acc: 0.802564 | Val Loss: 0.135115, Val Acc: 0.711340\n",
      "Epoch 10213 - Train Loss: 0.118376, Train Acc: 0.802564 | Val Loss: 0.135109, Val Acc: 0.711340\n",
      "Epoch 10214 - Train Loss: 0.118369, Train Acc: 0.802564 | Val Loss: 0.135103, Val Acc: 0.711340\n",
      "Epoch 10215 - Train Loss: 0.118361, Train Acc: 0.802564 | Val Loss: 0.135097, Val Acc: 0.711340\n",
      "Epoch 10216 - Train Loss: 0.118354, Train Acc: 0.802564 | Val Loss: 0.135091, Val Acc: 0.711340\n",
      "Epoch 10217 - Train Loss: 0.118347, Train Acc: 0.802564 | Val Loss: 0.135084, Val Acc: 0.711340\n",
      "Epoch 10218 - Train Loss: 0.118340, Train Acc: 0.802564 | Val Loss: 0.135078, Val Acc: 0.711340\n",
      "Epoch 10219 - Train Loss: 0.118332, Train Acc: 0.802564 | Val Loss: 0.135072, Val Acc: 0.711340\n",
      "Epoch 10220 - Train Loss: 0.118325, Train Acc: 0.802564 | Val Loss: 0.135066, Val Acc: 0.711340\n",
      "Epoch 10221 - Train Loss: 0.118318, Train Acc: 0.802564 | Val Loss: 0.135060, Val Acc: 0.711340\n",
      "Epoch 10222 - Train Loss: 0.118310, Train Acc: 0.802564 | Val Loss: 0.135054, Val Acc: 0.711340\n",
      "Epoch 10223 - Train Loss: 0.118303, Train Acc: 0.802564 | Val Loss: 0.135047, Val Acc: 0.711340\n",
      "Epoch 10224 - Train Loss: 0.118296, Train Acc: 0.802564 | Val Loss: 0.135041, Val Acc: 0.711340\n",
      "Epoch 10225 - Train Loss: 0.118289, Train Acc: 0.802564 | Val Loss: 0.135035, Val Acc: 0.711340\n",
      "Epoch 10226 - Train Loss: 0.118281, Train Acc: 0.802564 | Val Loss: 0.135029, Val Acc: 0.711340\n",
      "Epoch 10227 - Train Loss: 0.118274, Train Acc: 0.802564 | Val Loss: 0.135023, Val Acc: 0.711340\n",
      "Epoch 10228 - Train Loss: 0.118267, Train Acc: 0.802564 | Val Loss: 0.135016, Val Acc: 0.711340\n",
      "Epoch 10229 - Train Loss: 0.118259, Train Acc: 0.802564 | Val Loss: 0.135010, Val Acc: 0.711340\n",
      "Epoch 10230 - Train Loss: 0.118252, Train Acc: 0.802564 | Val Loss: 0.135004, Val Acc: 0.711340\n",
      "Epoch 10231 - Train Loss: 0.118245, Train Acc: 0.802564 | Val Loss: 0.134998, Val Acc: 0.711340\n",
      "Epoch 10232 - Train Loss: 0.118238, Train Acc: 0.802564 | Val Loss: 0.134992, Val Acc: 0.711340\n",
      "Epoch 10233 - Train Loss: 0.118230, Train Acc: 0.802564 | Val Loss: 0.134986, Val Acc: 0.711340\n",
      "Epoch 10234 - Train Loss: 0.118223, Train Acc: 0.802564 | Val Loss: 0.134979, Val Acc: 0.711340\n",
      "Epoch 10235 - Train Loss: 0.118216, Train Acc: 0.802564 | Val Loss: 0.134973, Val Acc: 0.711340\n",
      "Epoch 10236 - Train Loss: 0.118209, Train Acc: 0.802564 | Val Loss: 0.134967, Val Acc: 0.711340\n",
      "Epoch 10237 - Train Loss: 0.118201, Train Acc: 0.802564 | Val Loss: 0.134961, Val Acc: 0.711340\n",
      "Epoch 10238 - Train Loss: 0.118194, Train Acc: 0.802564 | Val Loss: 0.134955, Val Acc: 0.711340\n",
      "Epoch 10239 - Train Loss: 0.118187, Train Acc: 0.802564 | Val Loss: 0.134949, Val Acc: 0.711340\n",
      "Epoch 10240 - Train Loss: 0.118180, Train Acc: 0.802564 | Val Loss: 0.134942, Val Acc: 0.711340\n",
      "Epoch 10241 - Train Loss: 0.118172, Train Acc: 0.802564 | Val Loss: 0.134936, Val Acc: 0.711340\n",
      "Epoch 10242 - Train Loss: 0.118165, Train Acc: 0.802564 | Val Loss: 0.134930, Val Acc: 0.711340\n",
      "Epoch 10243 - Train Loss: 0.118158, Train Acc: 0.802564 | Val Loss: 0.134924, Val Acc: 0.711340\n",
      "Epoch 10244 - Train Loss: 0.118150, Train Acc: 0.802564 | Val Loss: 0.134918, Val Acc: 0.711340\n",
      "Epoch 10245 - Train Loss: 0.118143, Train Acc: 0.802564 | Val Loss: 0.134912, Val Acc: 0.711340\n",
      "Epoch 10246 - Train Loss: 0.118136, Train Acc: 0.802564 | Val Loss: 0.134906, Val Acc: 0.711340\n",
      "Epoch 10247 - Train Loss: 0.118129, Train Acc: 0.802564 | Val Loss: 0.134899, Val Acc: 0.711340\n",
      "Epoch 10248 - Train Loss: 0.118121, Train Acc: 0.802564 | Val Loss: 0.134893, Val Acc: 0.711340\n",
      "Epoch 10249 - Train Loss: 0.118114, Train Acc: 0.802564 | Val Loss: 0.134887, Val Acc: 0.711340\n",
      "Epoch 10250 - Train Loss: 0.118107, Train Acc: 0.802564 | Val Loss: 0.134881, Val Acc: 0.711340\n",
      "Epoch 10251 - Train Loss: 0.118100, Train Acc: 0.802564 | Val Loss: 0.134875, Val Acc: 0.711340\n",
      "Epoch 10252 - Train Loss: 0.118092, Train Acc: 0.802564 | Val Loss: 0.134869, Val Acc: 0.711340\n",
      "Epoch 10253 - Train Loss: 0.118085, Train Acc: 0.802564 | Val Loss: 0.134863, Val Acc: 0.711340\n",
      "Epoch 10254 - Train Loss: 0.118078, Train Acc: 0.802564 | Val Loss: 0.134856, Val Acc: 0.711340\n",
      "Epoch 10255 - Train Loss: 0.118071, Train Acc: 0.802564 | Val Loss: 0.134850, Val Acc: 0.711340\n",
      "Epoch 10256 - Train Loss: 0.118063, Train Acc: 0.802564 | Val Loss: 0.134844, Val Acc: 0.711340\n",
      "Epoch 10257 - Train Loss: 0.118056, Train Acc: 0.802564 | Val Loss: 0.134838, Val Acc: 0.711340\n",
      "Epoch 10258 - Train Loss: 0.118049, Train Acc: 0.802564 | Val Loss: 0.134832, Val Acc: 0.711340\n",
      "Epoch 10259 - Train Loss: 0.118042, Train Acc: 0.802564 | Val Loss: 0.134826, Val Acc: 0.711340\n",
      "Epoch 10260 - Train Loss: 0.118035, Train Acc: 0.802564 | Val Loss: 0.134820, Val Acc: 0.711340\n",
      "Epoch 10261 - Train Loss: 0.118027, Train Acc: 0.802564 | Val Loss: 0.134814, Val Acc: 0.711340\n",
      "Epoch 10262 - Train Loss: 0.118020, Train Acc: 0.802564 | Val Loss: 0.134807, Val Acc: 0.711340\n",
      "Epoch 10263 - Train Loss: 0.118013, Train Acc: 0.802564 | Val Loss: 0.134801, Val Acc: 0.711340\n",
      "Epoch 10264 - Train Loss: 0.118006, Train Acc: 0.802564 | Val Loss: 0.134795, Val Acc: 0.711340\n",
      "Epoch 10265 - Train Loss: 0.117998, Train Acc: 0.802564 | Val Loss: 0.134789, Val Acc: 0.711340\n",
      "Epoch 10266 - Train Loss: 0.117991, Train Acc: 0.802564 | Val Loss: 0.134783, Val Acc: 0.711340\n",
      "Epoch 10267 - Train Loss: 0.117984, Train Acc: 0.802564 | Val Loss: 0.134777, Val Acc: 0.711340\n",
      "Epoch 10268 - Train Loss: 0.117977, Train Acc: 0.802564 | Val Loss: 0.134771, Val Acc: 0.711340\n",
      "Epoch 10269 - Train Loss: 0.117969, Train Acc: 0.802564 | Val Loss: 0.134765, Val Acc: 0.711340\n",
      "Epoch 10270 - Train Loss: 0.117962, Train Acc: 0.802564 | Val Loss: 0.134759, Val Acc: 0.711340\n",
      "Epoch 10271 - Train Loss: 0.117955, Train Acc: 0.802564 | Val Loss: 0.134752, Val Acc: 0.711340\n",
      "Epoch 10272 - Train Loss: 0.117948, Train Acc: 0.802564 | Val Loss: 0.134746, Val Acc: 0.711340\n",
      "Epoch 10273 - Train Loss: 0.117941, Train Acc: 0.802564 | Val Loss: 0.134740, Val Acc: 0.711340\n",
      "Epoch 10274 - Train Loss: 0.117933, Train Acc: 0.802564 | Val Loss: 0.134734, Val Acc: 0.711340\n",
      "Epoch 10275 - Train Loss: 0.117926, Train Acc: 0.802564 | Val Loss: 0.134728, Val Acc: 0.711340\n",
      "Epoch 10276 - Train Loss: 0.117919, Train Acc: 0.802564 | Val Loss: 0.134722, Val Acc: 0.711340\n",
      "Epoch 10277 - Train Loss: 0.117912, Train Acc: 0.802564 | Val Loss: 0.134716, Val Acc: 0.711340\n",
      "Epoch 10278 - Train Loss: 0.117904, Train Acc: 0.802564 | Val Loss: 0.134710, Val Acc: 0.711340\n",
      "Epoch 10279 - Train Loss: 0.117897, Train Acc: 0.802564 | Val Loss: 0.134704, Val Acc: 0.711340\n",
      "Epoch 10280 - Train Loss: 0.117890, Train Acc: 0.802564 | Val Loss: 0.134698, Val Acc: 0.711340\n",
      "Epoch 10281 - Train Loss: 0.117883, Train Acc: 0.802564 | Val Loss: 0.134692, Val Acc: 0.711340\n",
      "Epoch 10282 - Train Loss: 0.117876, Train Acc: 0.802564 | Val Loss: 0.134685, Val Acc: 0.711340\n",
      "Epoch 10283 - Train Loss: 0.117868, Train Acc: 0.802564 | Val Loss: 0.134679, Val Acc: 0.711340\n",
      "Epoch 10284 - Train Loss: 0.117861, Train Acc: 0.802564 | Val Loss: 0.134673, Val Acc: 0.711340\n",
      "Epoch 10285 - Train Loss: 0.117854, Train Acc: 0.802564 | Val Loss: 0.134667, Val Acc: 0.711340\n",
      "Epoch 10286 - Train Loss: 0.117847, Train Acc: 0.802564 | Val Loss: 0.134661, Val Acc: 0.711340\n",
      "Epoch 10287 - Train Loss: 0.117840, Train Acc: 0.802564 | Val Loss: 0.134655, Val Acc: 0.711340\n",
      "Epoch 10288 - Train Loss: 0.117832, Train Acc: 0.802564 | Val Loss: 0.134649, Val Acc: 0.711340\n",
      "Epoch 10289 - Train Loss: 0.117825, Train Acc: 0.802564 | Val Loss: 0.134643, Val Acc: 0.711340\n",
      "Epoch 10290 - Train Loss: 0.117818, Train Acc: 0.802564 | Val Loss: 0.134637, Val Acc: 0.711340\n",
      "Epoch 10291 - Train Loss: 0.117811, Train Acc: 0.802564 | Val Loss: 0.134631, Val Acc: 0.711340\n",
      "Epoch 10292 - Train Loss: 0.117804, Train Acc: 0.803846 | Val Loss: 0.134625, Val Acc: 0.711340\n",
      "Epoch 10293 - Train Loss: 0.117796, Train Acc: 0.803846 | Val Loss: 0.134619, Val Acc: 0.711340\n",
      "Epoch 10294 - Train Loss: 0.117789, Train Acc: 0.803846 | Val Loss: 0.134612, Val Acc: 0.711340\n",
      "Epoch 10295 - Train Loss: 0.117782, Train Acc: 0.803846 | Val Loss: 0.134606, Val Acc: 0.711340\n",
      "Epoch 10296 - Train Loss: 0.117775, Train Acc: 0.803846 | Val Loss: 0.134600, Val Acc: 0.711340\n",
      "Epoch 10297 - Train Loss: 0.117768, Train Acc: 0.803846 | Val Loss: 0.134594, Val Acc: 0.711340\n",
      "Epoch 10298 - Train Loss: 0.117760, Train Acc: 0.803846 | Val Loss: 0.134588, Val Acc: 0.711340\n",
      "Epoch 10299 - Train Loss: 0.117753, Train Acc: 0.803846 | Val Loss: 0.134582, Val Acc: 0.711340\n",
      "Epoch 10300 - Train Loss: 0.117746, Train Acc: 0.803846 | Val Loss: 0.134576, Val Acc: 0.711340\n",
      "Epoch 10301 - Train Loss: 0.117739, Train Acc: 0.803846 | Val Loss: 0.134570, Val Acc: 0.711340\n",
      "Epoch 10302 - Train Loss: 0.117732, Train Acc: 0.803846 | Val Loss: 0.134564, Val Acc: 0.711340\n",
      "Epoch 10303 - Train Loss: 0.117724, Train Acc: 0.803846 | Val Loss: 0.134558, Val Acc: 0.711340\n",
      "Epoch 10304 - Train Loss: 0.117717, Train Acc: 0.803846 | Val Loss: 0.134552, Val Acc: 0.711340\n",
      "Epoch 10305 - Train Loss: 0.117710, Train Acc: 0.803846 | Val Loss: 0.134546, Val Acc: 0.711340\n",
      "Epoch 10306 - Train Loss: 0.117703, Train Acc: 0.803846 | Val Loss: 0.134540, Val Acc: 0.711340\n",
      "Epoch 10307 - Train Loss: 0.117696, Train Acc: 0.803846 | Val Loss: 0.134534, Val Acc: 0.711340\n",
      "Epoch 10308 - Train Loss: 0.117688, Train Acc: 0.803846 | Val Loss: 0.134528, Val Acc: 0.711340\n",
      "Epoch 10309 - Train Loss: 0.117681, Train Acc: 0.803846 | Val Loss: 0.134522, Val Acc: 0.711340\n",
      "Epoch 10310 - Train Loss: 0.117674, Train Acc: 0.803846 | Val Loss: 0.134516, Val Acc: 0.711340\n",
      "Epoch 10311 - Train Loss: 0.117667, Train Acc: 0.803846 | Val Loss: 0.134509, Val Acc: 0.711340\n",
      "Epoch 10312 - Train Loss: 0.117660, Train Acc: 0.803846 | Val Loss: 0.134503, Val Acc: 0.711340\n",
      "Epoch 10313 - Train Loss: 0.117653, Train Acc: 0.803846 | Val Loss: 0.134497, Val Acc: 0.711340\n",
      "Epoch 10314 - Train Loss: 0.117645, Train Acc: 0.803846 | Val Loss: 0.134491, Val Acc: 0.711340\n",
      "Epoch 10315 - Train Loss: 0.117638, Train Acc: 0.803846 | Val Loss: 0.134485, Val Acc: 0.711340\n",
      "Epoch 10316 - Train Loss: 0.117631, Train Acc: 0.803846 | Val Loss: 0.134479, Val Acc: 0.711340\n",
      "Epoch 10317 - Train Loss: 0.117624, Train Acc: 0.803846 | Val Loss: 0.134473, Val Acc: 0.711340\n",
      "Epoch 10318 - Train Loss: 0.117617, Train Acc: 0.803846 | Val Loss: 0.134467, Val Acc: 0.711340\n",
      "Epoch 10319 - Train Loss: 0.117609, Train Acc: 0.803846 | Val Loss: 0.134461, Val Acc: 0.711340\n",
      "Epoch 10320 - Train Loss: 0.117602, Train Acc: 0.803846 | Val Loss: 0.134455, Val Acc: 0.711340\n",
      "Epoch 10321 - Train Loss: 0.117595, Train Acc: 0.803846 | Val Loss: 0.134449, Val Acc: 0.711340\n",
      "Epoch 10322 - Train Loss: 0.117588, Train Acc: 0.803846 | Val Loss: 0.134443, Val Acc: 0.711340\n",
      "Epoch 10323 - Train Loss: 0.117581, Train Acc: 0.803846 | Val Loss: 0.134437, Val Acc: 0.711340\n",
      "Epoch 10324 - Train Loss: 0.117574, Train Acc: 0.803846 | Val Loss: 0.134431, Val Acc: 0.711340\n",
      "Epoch 10325 - Train Loss: 0.117566, Train Acc: 0.803846 | Val Loss: 0.134425, Val Acc: 0.711340\n",
      "Epoch 10326 - Train Loss: 0.117559, Train Acc: 0.803846 | Val Loss: 0.134419, Val Acc: 0.711340\n",
      "Epoch 10327 - Train Loss: 0.117552, Train Acc: 0.803846 | Val Loss: 0.134413, Val Acc: 0.711340\n",
      "Epoch 10328 - Train Loss: 0.117545, Train Acc: 0.803846 | Val Loss: 0.134407, Val Acc: 0.711340\n",
      "Epoch 10329 - Train Loss: 0.117538, Train Acc: 0.803846 | Val Loss: 0.134401, Val Acc: 0.711340\n",
      "Epoch 10330 - Train Loss: 0.117531, Train Acc: 0.803846 | Val Loss: 0.134395, Val Acc: 0.711340\n",
      "Epoch 10331 - Train Loss: 0.117524, Train Acc: 0.803846 | Val Loss: 0.134389, Val Acc: 0.711340\n",
      "Epoch 10332 - Train Loss: 0.117516, Train Acc: 0.803846 | Val Loss: 0.134383, Val Acc: 0.711340\n",
      "Epoch 10333 - Train Loss: 0.117509, Train Acc: 0.803846 | Val Loss: 0.134377, Val Acc: 0.711340\n",
      "Epoch 10334 - Train Loss: 0.117502, Train Acc: 0.803846 | Val Loss: 0.134371, Val Acc: 0.711340\n",
      "Epoch 10335 - Train Loss: 0.117495, Train Acc: 0.803846 | Val Loss: 0.134365, Val Acc: 0.711340\n",
      "Epoch 10336 - Train Loss: 0.117488, Train Acc: 0.803846 | Val Loss: 0.134359, Val Acc: 0.711340\n",
      "Epoch 10337 - Train Loss: 0.117481, Train Acc: 0.803846 | Val Loss: 0.134353, Val Acc: 0.711340\n",
      "Epoch 10338 - Train Loss: 0.117473, Train Acc: 0.803846 | Val Loss: 0.134347, Val Acc: 0.711340\n",
      "Epoch 10339 - Train Loss: 0.117466, Train Acc: 0.803846 | Val Loss: 0.134341, Val Acc: 0.711340\n",
      "Epoch 10340 - Train Loss: 0.117459, Train Acc: 0.803846 | Val Loss: 0.134335, Val Acc: 0.711340\n",
      "Epoch 10341 - Train Loss: 0.117452, Train Acc: 0.803846 | Val Loss: 0.134329, Val Acc: 0.711340\n",
      "Epoch 10342 - Train Loss: 0.117445, Train Acc: 0.803846 | Val Loss: 0.134323, Val Acc: 0.711340\n",
      "Epoch 10343 - Train Loss: 0.117438, Train Acc: 0.803846 | Val Loss: 0.134317, Val Acc: 0.711340\n",
      "Epoch 10344 - Train Loss: 0.117431, Train Acc: 0.803846 | Val Loss: 0.134311, Val Acc: 0.711340\n",
      "Epoch 10345 - Train Loss: 0.117423, Train Acc: 0.803846 | Val Loss: 0.134305, Val Acc: 0.711340\n",
      "Epoch 10346 - Train Loss: 0.117416, Train Acc: 0.805128 | Val Loss: 0.134299, Val Acc: 0.711340\n",
      "Epoch 10347 - Train Loss: 0.117409, Train Acc: 0.805128 | Val Loss: 0.134293, Val Acc: 0.711340\n",
      "Epoch 10348 - Train Loss: 0.117402, Train Acc: 0.805128 | Val Loss: 0.134287, Val Acc: 0.711340\n",
      "Epoch 10349 - Train Loss: 0.117395, Train Acc: 0.805128 | Val Loss: 0.134281, Val Acc: 0.711340\n",
      "Epoch 10350 - Train Loss: 0.117388, Train Acc: 0.805128 | Val Loss: 0.134275, Val Acc: 0.711340\n",
      "Epoch 10351 - Train Loss: 0.117381, Train Acc: 0.805128 | Val Loss: 0.134269, Val Acc: 0.711340\n",
      "Epoch 10352 - Train Loss: 0.117374, Train Acc: 0.805128 | Val Loss: 0.134263, Val Acc: 0.711340\n",
      "Epoch 10353 - Train Loss: 0.117366, Train Acc: 0.805128 | Val Loss: 0.134257, Val Acc: 0.711340\n",
      "Epoch 10354 - Train Loss: 0.117359, Train Acc: 0.805128 | Val Loss: 0.134251, Val Acc: 0.711340\n",
      "Epoch 10355 - Train Loss: 0.117352, Train Acc: 0.805128 | Val Loss: 0.134245, Val Acc: 0.711340\n",
      "Epoch 10356 - Train Loss: 0.117345, Train Acc: 0.805128 | Val Loss: 0.134239, Val Acc: 0.711340\n",
      "Epoch 10357 - Train Loss: 0.117338, Train Acc: 0.805128 | Val Loss: 0.134234, Val Acc: 0.711340\n",
      "Epoch 10358 - Train Loss: 0.117331, Train Acc: 0.805128 | Val Loss: 0.134228, Val Acc: 0.711340\n",
      "Epoch 10359 - Train Loss: 0.117324, Train Acc: 0.805128 | Val Loss: 0.134222, Val Acc: 0.711340\n",
      "Epoch 10360 - Train Loss: 0.117316, Train Acc: 0.805128 | Val Loss: 0.134216, Val Acc: 0.711340\n",
      "Epoch 10361 - Train Loss: 0.117309, Train Acc: 0.805128 | Val Loss: 0.134210, Val Acc: 0.711340\n",
      "Epoch 10362 - Train Loss: 0.117302, Train Acc: 0.805128 | Val Loss: 0.134204, Val Acc: 0.711340\n",
      "Epoch 10363 - Train Loss: 0.117295, Train Acc: 0.805128 | Val Loss: 0.134198, Val Acc: 0.711340\n",
      "Epoch 10364 - Train Loss: 0.117288, Train Acc: 0.805128 | Val Loss: 0.134192, Val Acc: 0.711340\n",
      "Epoch 10365 - Train Loss: 0.117281, Train Acc: 0.805128 | Val Loss: 0.134186, Val Acc: 0.711340\n",
      "Epoch 10366 - Train Loss: 0.117274, Train Acc: 0.805128 | Val Loss: 0.134180, Val Acc: 0.711340\n",
      "Epoch 10367 - Train Loss: 0.117267, Train Acc: 0.805128 | Val Loss: 0.134174, Val Acc: 0.711340\n",
      "Epoch 10368 - Train Loss: 0.117260, Train Acc: 0.805128 | Val Loss: 0.134168, Val Acc: 0.711340\n",
      "Epoch 10369 - Train Loss: 0.117252, Train Acc: 0.805128 | Val Loss: 0.134162, Val Acc: 0.711340\n",
      "Epoch 10370 - Train Loss: 0.117245, Train Acc: 0.805128 | Val Loss: 0.134156, Val Acc: 0.711340\n",
      "Epoch 10371 - Train Loss: 0.117238, Train Acc: 0.805128 | Val Loss: 0.134150, Val Acc: 0.711340\n",
      "Epoch 10372 - Train Loss: 0.117231, Train Acc: 0.805128 | Val Loss: 0.134144, Val Acc: 0.711340\n",
      "Epoch 10373 - Train Loss: 0.117224, Train Acc: 0.805128 | Val Loss: 0.134138, Val Acc: 0.711340\n",
      "Epoch 10374 - Train Loss: 0.117217, Train Acc: 0.805128 | Val Loss: 0.134132, Val Acc: 0.711340\n",
      "Epoch 10375 - Train Loss: 0.117210, Train Acc: 0.805128 | Val Loss: 0.134126, Val Acc: 0.711340\n",
      "Epoch 10376 - Train Loss: 0.117203, Train Acc: 0.805128 | Val Loss: 0.134120, Val Acc: 0.711340\n",
      "Epoch 10377 - Train Loss: 0.117196, Train Acc: 0.805128 | Val Loss: 0.134114, Val Acc: 0.711340\n",
      "Epoch 10378 - Train Loss: 0.117188, Train Acc: 0.805128 | Val Loss: 0.134109, Val Acc: 0.711340\n",
      "Epoch 10379 - Train Loss: 0.117181, Train Acc: 0.805128 | Val Loss: 0.134103, Val Acc: 0.711340\n",
      "Epoch 10380 - Train Loss: 0.117174, Train Acc: 0.805128 | Val Loss: 0.134097, Val Acc: 0.711340\n",
      "Epoch 10381 - Train Loss: 0.117167, Train Acc: 0.805128 | Val Loss: 0.134091, Val Acc: 0.711340\n",
      "Epoch 10382 - Train Loss: 0.117160, Train Acc: 0.805128 | Val Loss: 0.134085, Val Acc: 0.711340\n",
      "Epoch 10383 - Train Loss: 0.117153, Train Acc: 0.805128 | Val Loss: 0.134079, Val Acc: 0.711340\n",
      "Epoch 10384 - Train Loss: 0.117146, Train Acc: 0.805128 | Val Loss: 0.134073, Val Acc: 0.711340\n",
      "Epoch 10385 - Train Loss: 0.117139, Train Acc: 0.805128 | Val Loss: 0.134067, Val Acc: 0.711340\n",
      "Epoch 10386 - Train Loss: 0.117132, Train Acc: 0.805128 | Val Loss: 0.134061, Val Acc: 0.711340\n",
      "Epoch 10387 - Train Loss: 0.117124, Train Acc: 0.805128 | Val Loss: 0.134055, Val Acc: 0.711340\n",
      "Epoch 10388 - Train Loss: 0.117117, Train Acc: 0.805128 | Val Loss: 0.134049, Val Acc: 0.711340\n",
      "Epoch 10389 - Train Loss: 0.117110, Train Acc: 0.805128 | Val Loss: 0.134043, Val Acc: 0.711340\n",
      "Epoch 10390 - Train Loss: 0.117103, Train Acc: 0.805128 | Val Loss: 0.134037, Val Acc: 0.711340\n",
      "Epoch 10391 - Train Loss: 0.117096, Train Acc: 0.805128 | Val Loss: 0.134031, Val Acc: 0.711340\n",
      "Epoch 10392 - Train Loss: 0.117089, Train Acc: 0.805128 | Val Loss: 0.134026, Val Acc: 0.711340\n",
      "Epoch 10393 - Train Loss: 0.117082, Train Acc: 0.805128 | Val Loss: 0.134020, Val Acc: 0.711340\n",
      "Epoch 10394 - Train Loss: 0.117075, Train Acc: 0.805128 | Val Loss: 0.134014, Val Acc: 0.711340\n",
      "Epoch 10395 - Train Loss: 0.117068, Train Acc: 0.805128 | Val Loss: 0.134008, Val Acc: 0.711340\n",
      "Epoch 10396 - Train Loss: 0.117061, Train Acc: 0.806410 | Val Loss: 0.134002, Val Acc: 0.711340\n",
      "Epoch 10397 - Train Loss: 0.117054, Train Acc: 0.806410 | Val Loss: 0.133996, Val Acc: 0.711340\n",
      "Epoch 10398 - Train Loss: 0.117046, Train Acc: 0.806410 | Val Loss: 0.133990, Val Acc: 0.711340\n",
      "Epoch 10399 - Train Loss: 0.117039, Train Acc: 0.806410 | Val Loss: 0.133984, Val Acc: 0.711340\n",
      "Epoch 10400 - Train Loss: 0.117032, Train Acc: 0.806410 | Val Loss: 0.133978, Val Acc: 0.711340\n",
      "Epoch 10401 - Train Loss: 0.117025, Train Acc: 0.806410 | Val Loss: 0.133972, Val Acc: 0.711340\n",
      "Epoch 10402 - Train Loss: 0.117018, Train Acc: 0.806410 | Val Loss: 0.133966, Val Acc: 0.711340\n",
      "Epoch 10403 - Train Loss: 0.117011, Train Acc: 0.806410 | Val Loss: 0.133960, Val Acc: 0.711340\n",
      "Epoch 10404 - Train Loss: 0.117004, Train Acc: 0.806410 | Val Loss: 0.133955, Val Acc: 0.711340\n",
      "Epoch 10405 - Train Loss: 0.116997, Train Acc: 0.806410 | Val Loss: 0.133949, Val Acc: 0.711340\n",
      "Epoch 10406 - Train Loss: 0.116990, Train Acc: 0.806410 | Val Loss: 0.133943, Val Acc: 0.711340\n",
      "Epoch 10407 - Train Loss: 0.116983, Train Acc: 0.806410 | Val Loss: 0.133937, Val Acc: 0.711340\n",
      "Epoch 10408 - Train Loss: 0.116976, Train Acc: 0.806410 | Val Loss: 0.133931, Val Acc: 0.711340\n",
      "Epoch 10409 - Train Loss: 0.116969, Train Acc: 0.806410 | Val Loss: 0.133925, Val Acc: 0.711340\n",
      "Epoch 10410 - Train Loss: 0.116961, Train Acc: 0.806410 | Val Loss: 0.133919, Val Acc: 0.711340\n",
      "Epoch 10411 - Train Loss: 0.116954, Train Acc: 0.806410 | Val Loss: 0.133913, Val Acc: 0.711340\n",
      "Epoch 10412 - Train Loss: 0.116947, Train Acc: 0.807692 | Val Loss: 0.133907, Val Acc: 0.711340\n",
      "Epoch 10413 - Train Loss: 0.116940, Train Acc: 0.807692 | Val Loss: 0.133901, Val Acc: 0.711340\n",
      "Epoch 10414 - Train Loss: 0.116933, Train Acc: 0.807692 | Val Loss: 0.133895, Val Acc: 0.711340\n",
      "Epoch 10415 - Train Loss: 0.116926, Train Acc: 0.807692 | Val Loss: 0.133890, Val Acc: 0.711340\n",
      "Epoch 10416 - Train Loss: 0.116919, Train Acc: 0.807692 | Val Loss: 0.133884, Val Acc: 0.711340\n",
      "Epoch 10417 - Train Loss: 0.116912, Train Acc: 0.807692 | Val Loss: 0.133878, Val Acc: 0.711340\n",
      "Epoch 10418 - Train Loss: 0.116905, Train Acc: 0.807692 | Val Loss: 0.133872, Val Acc: 0.711340\n",
      "Epoch 10419 - Train Loss: 0.116898, Train Acc: 0.807692 | Val Loss: 0.133866, Val Acc: 0.711340\n",
      "Epoch 10420 - Train Loss: 0.116891, Train Acc: 0.807692 | Val Loss: 0.133860, Val Acc: 0.711340\n",
      "Epoch 10421 - Train Loss: 0.116884, Train Acc: 0.807692 | Val Loss: 0.133854, Val Acc: 0.711340\n",
      "Epoch 10422 - Train Loss: 0.116877, Train Acc: 0.807692 | Val Loss: 0.133848, Val Acc: 0.711340\n",
      "Epoch 10423 - Train Loss: 0.116870, Train Acc: 0.807692 | Val Loss: 0.133842, Val Acc: 0.711340\n",
      "Epoch 10424 - Train Loss: 0.116863, Train Acc: 0.807692 | Val Loss: 0.133836, Val Acc: 0.711340\n",
      "Epoch 10425 - Train Loss: 0.116855, Train Acc: 0.807692 | Val Loss: 0.133830, Val Acc: 0.711340\n",
      "Epoch 10426 - Train Loss: 0.116848, Train Acc: 0.807692 | Val Loss: 0.133825, Val Acc: 0.711340\n",
      "Epoch 10427 - Train Loss: 0.116841, Train Acc: 0.807692 | Val Loss: 0.133819, Val Acc: 0.711340\n",
      "Epoch 10428 - Train Loss: 0.116834, Train Acc: 0.808974 | Val Loss: 0.133813, Val Acc: 0.711340\n",
      "Epoch 10429 - Train Loss: 0.116827, Train Acc: 0.808974 | Val Loss: 0.133807, Val Acc: 0.711340\n",
      "Epoch 10430 - Train Loss: 0.116820, Train Acc: 0.808974 | Val Loss: 0.133801, Val Acc: 0.711340\n",
      "Epoch 10431 - Train Loss: 0.116813, Train Acc: 0.808974 | Val Loss: 0.133795, Val Acc: 0.711340\n",
      "Epoch 10432 - Train Loss: 0.116806, Train Acc: 0.808974 | Val Loss: 0.133789, Val Acc: 0.711340\n",
      "Epoch 10433 - Train Loss: 0.116799, Train Acc: 0.808974 | Val Loss: 0.133783, Val Acc: 0.711340\n",
      "Epoch 10434 - Train Loss: 0.116792, Train Acc: 0.808974 | Val Loss: 0.133777, Val Acc: 0.711340\n",
      "Epoch 10435 - Train Loss: 0.116785, Train Acc: 0.808974 | Val Loss: 0.133772, Val Acc: 0.711340\n",
      "Epoch 10436 - Train Loss: 0.116778, Train Acc: 0.808974 | Val Loss: 0.133766, Val Acc: 0.711340\n",
      "Epoch 10437 - Train Loss: 0.116771, Train Acc: 0.808974 | Val Loss: 0.133760, Val Acc: 0.711340\n",
      "Epoch 10438 - Train Loss: 0.116764, Train Acc: 0.808974 | Val Loss: 0.133754, Val Acc: 0.711340\n",
      "Epoch 10439 - Train Loss: 0.116757, Train Acc: 0.808974 | Val Loss: 0.133748, Val Acc: 0.711340\n",
      "Epoch 10440 - Train Loss: 0.116750, Train Acc: 0.808974 | Val Loss: 0.133742, Val Acc: 0.711340\n",
      "Epoch 10441 - Train Loss: 0.116743, Train Acc: 0.808974 | Val Loss: 0.133736, Val Acc: 0.711340\n",
      "Epoch 10442 - Train Loss: 0.116736, Train Acc: 0.808974 | Val Loss: 0.133730, Val Acc: 0.711340\n",
      "Epoch 10443 - Train Loss: 0.116729, Train Acc: 0.808974 | Val Loss: 0.133725, Val Acc: 0.711340\n",
      "Epoch 10444 - Train Loss: 0.116722, Train Acc: 0.808974 | Val Loss: 0.133719, Val Acc: 0.711340\n",
      "Epoch 10445 - Train Loss: 0.116714, Train Acc: 0.810256 | Val Loss: 0.133713, Val Acc: 0.711340\n",
      "Epoch 10446 - Train Loss: 0.116707, Train Acc: 0.810256 | Val Loss: 0.133707, Val Acc: 0.711340\n",
      "Epoch 10447 - Train Loss: 0.116700, Train Acc: 0.810256 | Val Loss: 0.133701, Val Acc: 0.711340\n",
      "Epoch 10448 - Train Loss: 0.116693, Train Acc: 0.810256 | Val Loss: 0.133695, Val Acc: 0.711340\n",
      "Epoch 10449 - Train Loss: 0.116686, Train Acc: 0.810256 | Val Loss: 0.133689, Val Acc: 0.711340\n",
      "Epoch 10450 - Train Loss: 0.116679, Train Acc: 0.810256 | Val Loss: 0.133683, Val Acc: 0.711340\n",
      "Epoch 10451 - Train Loss: 0.116672, Train Acc: 0.810256 | Val Loss: 0.133678, Val Acc: 0.711340\n",
      "Epoch 10452 - Train Loss: 0.116665, Train Acc: 0.810256 | Val Loss: 0.133672, Val Acc: 0.711340\n",
      "Epoch 10453 - Train Loss: 0.116658, Train Acc: 0.810256 | Val Loss: 0.133666, Val Acc: 0.711340\n",
      "Epoch 10454 - Train Loss: 0.116651, Train Acc: 0.810256 | Val Loss: 0.133660, Val Acc: 0.711340\n",
      "Epoch 10455 - Train Loss: 0.116644, Train Acc: 0.810256 | Val Loss: 0.133654, Val Acc: 0.711340\n",
      "Epoch 10456 - Train Loss: 0.116637, Train Acc: 0.810256 | Val Loss: 0.133648, Val Acc: 0.711340\n",
      "Epoch 10457 - Train Loss: 0.116630, Train Acc: 0.810256 | Val Loss: 0.133642, Val Acc: 0.711340\n",
      "Epoch 10458 - Train Loss: 0.116623, Train Acc: 0.810256 | Val Loss: 0.133637, Val Acc: 0.711340\n",
      "Epoch 10459 - Train Loss: 0.116616, Train Acc: 0.810256 | Val Loss: 0.133631, Val Acc: 0.711340\n",
      "Epoch 10460 - Train Loss: 0.116609, Train Acc: 0.810256 | Val Loss: 0.133625, Val Acc: 0.711340\n",
      "Epoch 10461 - Train Loss: 0.116602, Train Acc: 0.810256 | Val Loss: 0.133619, Val Acc: 0.711340\n",
      "Epoch 10462 - Train Loss: 0.116595, Train Acc: 0.810256 | Val Loss: 0.133613, Val Acc: 0.711340\n",
      "Epoch 10463 - Train Loss: 0.116588, Train Acc: 0.810256 | Val Loss: 0.133607, Val Acc: 0.711340\n",
      "Epoch 10464 - Train Loss: 0.116581, Train Acc: 0.810256 | Val Loss: 0.133601, Val Acc: 0.711340\n",
      "Epoch 10465 - Train Loss: 0.116574, Train Acc: 0.810256 | Val Loss: 0.133596, Val Acc: 0.711340\n",
      "Epoch 10466 - Train Loss: 0.116567, Train Acc: 0.810256 | Val Loss: 0.133590, Val Acc: 0.711340\n",
      "Epoch 10467 - Train Loss: 0.116560, Train Acc: 0.811538 | Val Loss: 0.133584, Val Acc: 0.711340\n",
      "Epoch 10468 - Train Loss: 0.116553, Train Acc: 0.811538 | Val Loss: 0.133578, Val Acc: 0.711340\n",
      "Epoch 10469 - Train Loss: 0.116546, Train Acc: 0.811538 | Val Loss: 0.133572, Val Acc: 0.711340\n",
      "Epoch 10470 - Train Loss: 0.116539, Train Acc: 0.811538 | Val Loss: 0.133566, Val Acc: 0.711340\n",
      "Epoch 10471 - Train Loss: 0.116532, Train Acc: 0.811538 | Val Loss: 0.133560, Val Acc: 0.711340\n",
      "Epoch 10472 - Train Loss: 0.116525, Train Acc: 0.811538 | Val Loss: 0.133555, Val Acc: 0.711340\n",
      "Epoch 10473 - Train Loss: 0.116518, Train Acc: 0.811538 | Val Loss: 0.133549, Val Acc: 0.711340\n",
      "Epoch 10474 - Train Loss: 0.116511, Train Acc: 0.811538 | Val Loss: 0.133543, Val Acc: 0.711340\n",
      "Epoch 10475 - Train Loss: 0.116504, Train Acc: 0.811538 | Val Loss: 0.133537, Val Acc: 0.711340\n",
      "Epoch 10476 - Train Loss: 0.116497, Train Acc: 0.811538 | Val Loss: 0.133531, Val Acc: 0.711340\n",
      "Epoch 10477 - Train Loss: 0.116490, Train Acc: 0.811538 | Val Loss: 0.133525, Val Acc: 0.711340\n",
      "Epoch 10478 - Train Loss: 0.116483, Train Acc: 0.811538 | Val Loss: 0.133520, Val Acc: 0.711340\n",
      "Epoch 10479 - Train Loss: 0.116476, Train Acc: 0.811538 | Val Loss: 0.133514, Val Acc: 0.711340\n",
      "Epoch 10480 - Train Loss: 0.116469, Train Acc: 0.811538 | Val Loss: 0.133508, Val Acc: 0.711340\n",
      "Epoch 10481 - Train Loss: 0.116462, Train Acc: 0.811538 | Val Loss: 0.133502, Val Acc: 0.711340\n",
      "Epoch 10482 - Train Loss: 0.116455, Train Acc: 0.811538 | Val Loss: 0.133496, Val Acc: 0.711340\n",
      "Epoch 10483 - Train Loss: 0.116448, Train Acc: 0.811538 | Val Loss: 0.133490, Val Acc: 0.711340\n",
      "Epoch 10484 - Train Loss: 0.116441, Train Acc: 0.811538 | Val Loss: 0.133485, Val Acc: 0.711340\n",
      "Epoch 10485 - Train Loss: 0.116434, Train Acc: 0.811538 | Val Loss: 0.133479, Val Acc: 0.711340\n",
      "Epoch 10486 - Train Loss: 0.116427, Train Acc: 0.811538 | Val Loss: 0.133473, Val Acc: 0.711340\n",
      "Epoch 10487 - Train Loss: 0.116420, Train Acc: 0.811538 | Val Loss: 0.133467, Val Acc: 0.711340\n",
      "Epoch 10488 - Train Loss: 0.116413, Train Acc: 0.811538 | Val Loss: 0.133461, Val Acc: 0.711340\n",
      "Epoch 10489 - Train Loss: 0.116406, Train Acc: 0.811538 | Val Loss: 0.133455, Val Acc: 0.711340\n",
      "Epoch 10490 - Train Loss: 0.116399, Train Acc: 0.811538 | Val Loss: 0.133450, Val Acc: 0.711340\n",
      "Epoch 10491 - Train Loss: 0.116392, Train Acc: 0.811538 | Val Loss: 0.133444, Val Acc: 0.711340\n",
      "Epoch 10492 - Train Loss: 0.116385, Train Acc: 0.811538 | Val Loss: 0.133438, Val Acc: 0.711340\n",
      "Epoch 10493 - Train Loss: 0.116378, Train Acc: 0.811538 | Val Loss: 0.133432, Val Acc: 0.711340\n",
      "Epoch 10494 - Train Loss: 0.116371, Train Acc: 0.811538 | Val Loss: 0.133426, Val Acc: 0.711340\n",
      "Epoch 10495 - Train Loss: 0.116364, Train Acc: 0.811538 | Val Loss: 0.133420, Val Acc: 0.711340\n",
      "Epoch 10496 - Train Loss: 0.116357, Train Acc: 0.811538 | Val Loss: 0.133415, Val Acc: 0.711340\n",
      "Epoch 10497 - Train Loss: 0.116350, Train Acc: 0.811538 | Val Loss: 0.133409, Val Acc: 0.711340\n",
      "Epoch 10498 - Train Loss: 0.116343, Train Acc: 0.811538 | Val Loss: 0.133403, Val Acc: 0.711340\n",
      "Epoch 10499 - Train Loss: 0.116336, Train Acc: 0.811538 | Val Loss: 0.133397, Val Acc: 0.711340\n",
      "Epoch 10500 - Train Loss: 0.116329, Train Acc: 0.811538 | Val Loss: 0.133391, Val Acc: 0.711340\n",
      "Epoch 10501 - Train Loss: 0.116322, Train Acc: 0.811538 | Val Loss: 0.133385, Val Acc: 0.711340\n",
      "Epoch 10502 - Train Loss: 0.116315, Train Acc: 0.811538 | Val Loss: 0.133380, Val Acc: 0.711340\n",
      "Epoch 10503 - Train Loss: 0.116308, Train Acc: 0.811538 | Val Loss: 0.133374, Val Acc: 0.711340\n",
      "Epoch 10504 - Train Loss: 0.116301, Train Acc: 0.811538 | Val Loss: 0.133368, Val Acc: 0.711340\n",
      "Epoch 10505 - Train Loss: 0.116294, Train Acc: 0.811538 | Val Loss: 0.133362, Val Acc: 0.711340\n",
      "Epoch 10506 - Train Loss: 0.116287, Train Acc: 0.811538 | Val Loss: 0.133356, Val Acc: 0.711340\n",
      "Epoch 10507 - Train Loss: 0.116280, Train Acc: 0.811538 | Val Loss: 0.133351, Val Acc: 0.711340\n",
      "Epoch 10508 - Train Loss: 0.116273, Train Acc: 0.811538 | Val Loss: 0.133345, Val Acc: 0.711340\n",
      "Epoch 10509 - Train Loss: 0.116266, Train Acc: 0.811538 | Val Loss: 0.133339, Val Acc: 0.711340\n",
      "Epoch 10510 - Train Loss: 0.116259, Train Acc: 0.811538 | Val Loss: 0.133333, Val Acc: 0.711340\n",
      "Epoch 10511 - Train Loss: 0.116252, Train Acc: 0.811538 | Val Loss: 0.133327, Val Acc: 0.711340\n",
      "Epoch 10512 - Train Loss: 0.116245, Train Acc: 0.811538 | Val Loss: 0.133321, Val Acc: 0.711340\n",
      "Epoch 10513 - Train Loss: 0.116238, Train Acc: 0.811538 | Val Loss: 0.133316, Val Acc: 0.711340\n",
      "Epoch 10514 - Train Loss: 0.116231, Train Acc: 0.811538 | Val Loss: 0.133310, Val Acc: 0.711340\n",
      "Epoch 10515 - Train Loss: 0.116224, Train Acc: 0.811538 | Val Loss: 0.133304, Val Acc: 0.711340\n",
      "Epoch 10516 - Train Loss: 0.116217, Train Acc: 0.811538 | Val Loss: 0.133298, Val Acc: 0.711340\n",
      "Epoch 10517 - Train Loss: 0.116210, Train Acc: 0.811538 | Val Loss: 0.133292, Val Acc: 0.711340\n",
      "Epoch 10518 - Train Loss: 0.116203, Train Acc: 0.811538 | Val Loss: 0.133287, Val Acc: 0.711340\n",
      "Epoch 10519 - Train Loss: 0.116196, Train Acc: 0.811538 | Val Loss: 0.133281, Val Acc: 0.711340\n",
      "Epoch 10520 - Train Loss: 0.116189, Train Acc: 0.811538 | Val Loss: 0.133275, Val Acc: 0.711340\n",
      "Epoch 10521 - Train Loss: 0.116182, Train Acc: 0.811538 | Val Loss: 0.133269, Val Acc: 0.711340\n",
      "Epoch 10522 - Train Loss: 0.116175, Train Acc: 0.811538 | Val Loss: 0.133263, Val Acc: 0.711340\n",
      "Epoch 10523 - Train Loss: 0.116168, Train Acc: 0.811538 | Val Loss: 0.133257, Val Acc: 0.711340\n",
      "Epoch 10524 - Train Loss: 0.116161, Train Acc: 0.811538 | Val Loss: 0.133252, Val Acc: 0.711340\n",
      "Epoch 10525 - Train Loss: 0.116154, Train Acc: 0.811538 | Val Loss: 0.133246, Val Acc: 0.711340\n",
      "Epoch 10526 - Train Loss: 0.116147, Train Acc: 0.811538 | Val Loss: 0.133240, Val Acc: 0.711340\n",
      "Epoch 10527 - Train Loss: 0.116141, Train Acc: 0.811538 | Val Loss: 0.133234, Val Acc: 0.711340\n",
      "Epoch 10528 - Train Loss: 0.116134, Train Acc: 0.811538 | Val Loss: 0.133228, Val Acc: 0.711340\n",
      "Epoch 10529 - Train Loss: 0.116127, Train Acc: 0.811538 | Val Loss: 0.133223, Val Acc: 0.711340\n",
      "Epoch 10530 - Train Loss: 0.116120, Train Acc: 0.811538 | Val Loss: 0.133217, Val Acc: 0.711340\n",
      "Epoch 10531 - Train Loss: 0.116113, Train Acc: 0.811538 | Val Loss: 0.133211, Val Acc: 0.711340\n",
      "Epoch 10532 - Train Loss: 0.116106, Train Acc: 0.811538 | Val Loss: 0.133205, Val Acc: 0.711340\n",
      "Epoch 10533 - Train Loss: 0.116099, Train Acc: 0.811538 | Val Loss: 0.133199, Val Acc: 0.711340\n",
      "Epoch 10534 - Train Loss: 0.116092, Train Acc: 0.811538 | Val Loss: 0.133193, Val Acc: 0.711340\n",
      "Epoch 10535 - Train Loss: 0.116085, Train Acc: 0.811538 | Val Loss: 0.133188, Val Acc: 0.711340\n",
      "Epoch 10536 - Train Loss: 0.116078, Train Acc: 0.811538 | Val Loss: 0.133182, Val Acc: 0.711340\n",
      "Epoch 10537 - Train Loss: 0.116071, Train Acc: 0.811538 | Val Loss: 0.133176, Val Acc: 0.711340\n",
      "Epoch 10538 - Train Loss: 0.116064, Train Acc: 0.811538 | Val Loss: 0.133170, Val Acc: 0.711340\n",
      "Epoch 10539 - Train Loss: 0.116057, Train Acc: 0.811538 | Val Loss: 0.133164, Val Acc: 0.711340\n",
      "Epoch 10540 - Train Loss: 0.116050, Train Acc: 0.811538 | Val Loss: 0.133159, Val Acc: 0.711340\n",
      "Epoch 10541 - Train Loss: 0.116043, Train Acc: 0.811538 | Val Loss: 0.133153, Val Acc: 0.711340\n",
      "Epoch 10542 - Train Loss: 0.116036, Train Acc: 0.811538 | Val Loss: 0.133147, Val Acc: 0.711340\n",
      "Epoch 10543 - Train Loss: 0.116029, Train Acc: 0.811538 | Val Loss: 0.133141, Val Acc: 0.711340\n",
      "Epoch 10544 - Train Loss: 0.116022, Train Acc: 0.811538 | Val Loss: 0.133135, Val Acc: 0.711340\n",
      "Epoch 10545 - Train Loss: 0.116015, Train Acc: 0.811538 | Val Loss: 0.133130, Val Acc: 0.711340\n",
      "Epoch 10546 - Train Loss: 0.116008, Train Acc: 0.812821 | Val Loss: 0.133124, Val Acc: 0.711340\n",
      "Epoch 10547 - Train Loss: 0.116001, Train Acc: 0.812821 | Val Loss: 0.133118, Val Acc: 0.711340\n",
      "Epoch 10548 - Train Loss: 0.115994, Train Acc: 0.812821 | Val Loss: 0.133112, Val Acc: 0.711340\n",
      "Epoch 10549 - Train Loss: 0.115988, Train Acc: 0.812821 | Val Loss: 0.133106, Val Acc: 0.711340\n",
      "Epoch 10550 - Train Loss: 0.115981, Train Acc: 0.812821 | Val Loss: 0.133101, Val Acc: 0.711340\n",
      "Epoch 10551 - Train Loss: 0.115974, Train Acc: 0.812821 | Val Loss: 0.133095, Val Acc: 0.711340\n",
      "Epoch 10552 - Train Loss: 0.115967, Train Acc: 0.814103 | Val Loss: 0.133089, Val Acc: 0.711340\n",
      "Epoch 10553 - Train Loss: 0.115960, Train Acc: 0.814103 | Val Loss: 0.133083, Val Acc: 0.711340\n",
      "Epoch 10554 - Train Loss: 0.115953, Train Acc: 0.814103 | Val Loss: 0.133077, Val Acc: 0.711340\n",
      "Epoch 10555 - Train Loss: 0.115946, Train Acc: 0.814103 | Val Loss: 0.133072, Val Acc: 0.711340\n",
      "Epoch 10556 - Train Loss: 0.115939, Train Acc: 0.814103 | Val Loss: 0.133066, Val Acc: 0.711340\n",
      "Epoch 10557 - Train Loss: 0.115932, Train Acc: 0.814103 | Val Loss: 0.133060, Val Acc: 0.711340\n",
      "Epoch 10558 - Train Loss: 0.115925, Train Acc: 0.814103 | Val Loss: 0.133054, Val Acc: 0.711340\n",
      "Epoch 10559 - Train Loss: 0.115918, Train Acc: 0.814103 | Val Loss: 0.133048, Val Acc: 0.711340\n",
      "Epoch 10560 - Train Loss: 0.115911, Train Acc: 0.814103 | Val Loss: 0.133043, Val Acc: 0.711340\n",
      "Epoch 10561 - Train Loss: 0.115904, Train Acc: 0.814103 | Val Loss: 0.133037, Val Acc: 0.711340\n",
      "Epoch 10562 - Train Loss: 0.115897, Train Acc: 0.814103 | Val Loss: 0.133031, Val Acc: 0.711340\n",
      "Epoch 10563 - Train Loss: 0.115890, Train Acc: 0.814103 | Val Loss: 0.133025, Val Acc: 0.711340\n",
      "Epoch 10564 - Train Loss: 0.115884, Train Acc: 0.814103 | Val Loss: 0.133020, Val Acc: 0.711340\n",
      "Epoch 10565 - Train Loss: 0.115877, Train Acc: 0.814103 | Val Loss: 0.133014, Val Acc: 0.711340\n",
      "Epoch 10566 - Train Loss: 0.115870, Train Acc: 0.814103 | Val Loss: 0.133008, Val Acc: 0.711340\n",
      "Epoch 10567 - Train Loss: 0.115863, Train Acc: 0.814103 | Val Loss: 0.133002, Val Acc: 0.711340\n",
      "Epoch 10568 - Train Loss: 0.115856, Train Acc: 0.814103 | Val Loss: 0.132996, Val Acc: 0.711340\n",
      "Epoch 10569 - Train Loss: 0.115849, Train Acc: 0.814103 | Val Loss: 0.132991, Val Acc: 0.711340\n",
      "Epoch 10570 - Train Loss: 0.115842, Train Acc: 0.814103 | Val Loss: 0.132985, Val Acc: 0.711340\n",
      "Epoch 10571 - Train Loss: 0.115835, Train Acc: 0.814103 | Val Loss: 0.132979, Val Acc: 0.711340\n",
      "Epoch 10572 - Train Loss: 0.115828, Train Acc: 0.814103 | Val Loss: 0.132973, Val Acc: 0.711340\n",
      "Epoch 10573 - Train Loss: 0.115821, Train Acc: 0.814103 | Val Loss: 0.132968, Val Acc: 0.711340\n",
      "Epoch 10574 - Train Loss: 0.115814, Train Acc: 0.814103 | Val Loss: 0.132962, Val Acc: 0.711340\n",
      "Epoch 10575 - Train Loss: 0.115807, Train Acc: 0.814103 | Val Loss: 0.132956, Val Acc: 0.711340\n",
      "Epoch 10576 - Train Loss: 0.115800, Train Acc: 0.814103 | Val Loss: 0.132950, Val Acc: 0.711340\n",
      "Epoch 10577 - Train Loss: 0.115794, Train Acc: 0.814103 | Val Loss: 0.132944, Val Acc: 0.711340\n",
      "Epoch 10578 - Train Loss: 0.115787, Train Acc: 0.814103 | Val Loss: 0.132939, Val Acc: 0.711340\n",
      "Epoch 10579 - Train Loss: 0.115780, Train Acc: 0.814103 | Val Loss: 0.132933, Val Acc: 0.711340\n",
      "Epoch 10580 - Train Loss: 0.115773, Train Acc: 0.814103 | Val Loss: 0.132927, Val Acc: 0.711340\n",
      "Epoch 10581 - Train Loss: 0.115766, Train Acc: 0.814103 | Val Loss: 0.132921, Val Acc: 0.711340\n",
      "Epoch 10582 - Train Loss: 0.115759, Train Acc: 0.814103 | Val Loss: 0.132916, Val Acc: 0.711340\n",
      "Epoch 10583 - Train Loss: 0.115752, Train Acc: 0.814103 | Val Loss: 0.132910, Val Acc: 0.711340\n",
      "Epoch 10584 - Train Loss: 0.115745, Train Acc: 0.814103 | Val Loss: 0.132904, Val Acc: 0.711340\n",
      "Epoch 10585 - Train Loss: 0.115738, Train Acc: 0.814103 | Val Loss: 0.132898, Val Acc: 0.711340\n",
      "Epoch 10586 - Train Loss: 0.115731, Train Acc: 0.814103 | Val Loss: 0.132893, Val Acc: 0.711340\n",
      "Epoch 10587 - Train Loss: 0.115725, Train Acc: 0.814103 | Val Loss: 0.132887, Val Acc: 0.711340\n",
      "Epoch 10588 - Train Loss: 0.115718, Train Acc: 0.814103 | Val Loss: 0.132881, Val Acc: 0.711340\n",
      "Epoch 10589 - Train Loss: 0.115711, Train Acc: 0.814103 | Val Loss: 0.132875, Val Acc: 0.711340\n",
      "Epoch 10590 - Train Loss: 0.115704, Train Acc: 0.814103 | Val Loss: 0.132870, Val Acc: 0.711340\n",
      "Epoch 10591 - Train Loss: 0.115697, Train Acc: 0.814103 | Val Loss: 0.132864, Val Acc: 0.711340\n",
      "Epoch 10592 - Train Loss: 0.115690, Train Acc: 0.814103 | Val Loss: 0.132858, Val Acc: 0.711340\n",
      "Epoch 10593 - Train Loss: 0.115683, Train Acc: 0.814103 | Val Loss: 0.132852, Val Acc: 0.711340\n",
      "Epoch 10594 - Train Loss: 0.115676, Train Acc: 0.814103 | Val Loss: 0.132847, Val Acc: 0.711340\n",
      "Epoch 10595 - Train Loss: 0.115669, Train Acc: 0.814103 | Val Loss: 0.132841, Val Acc: 0.711340\n",
      "Epoch 10596 - Train Loss: 0.115662, Train Acc: 0.814103 | Val Loss: 0.132835, Val Acc: 0.711340\n",
      "Epoch 10597 - Train Loss: 0.115656, Train Acc: 0.814103 | Val Loss: 0.132829, Val Acc: 0.711340\n",
      "Epoch 10598 - Train Loss: 0.115649, Train Acc: 0.814103 | Val Loss: 0.132824, Val Acc: 0.711340\n",
      "Epoch 10599 - Train Loss: 0.115642, Train Acc: 0.814103 | Val Loss: 0.132818, Val Acc: 0.711340\n",
      "Epoch 10600 - Train Loss: 0.115635, Train Acc: 0.814103 | Val Loss: 0.132812, Val Acc: 0.711340\n",
      "Epoch 10601 - Train Loss: 0.115628, Train Acc: 0.814103 | Val Loss: 0.132806, Val Acc: 0.711340\n",
      "Epoch 10602 - Train Loss: 0.115621, Train Acc: 0.814103 | Val Loss: 0.132801, Val Acc: 0.711340\n",
      "Epoch 10603 - Train Loss: 0.115614, Train Acc: 0.814103 | Val Loss: 0.132795, Val Acc: 0.711340\n",
      "Epoch 10604 - Train Loss: 0.115607, Train Acc: 0.815385 | Val Loss: 0.132789, Val Acc: 0.711340\n",
      "Epoch 10605 - Train Loss: 0.115600, Train Acc: 0.815385 | Val Loss: 0.132783, Val Acc: 0.711340\n",
      "Epoch 10606 - Train Loss: 0.115594, Train Acc: 0.815385 | Val Loss: 0.132778, Val Acc: 0.711340\n",
      "Epoch 10607 - Train Loss: 0.115587, Train Acc: 0.815385 | Val Loss: 0.132772, Val Acc: 0.711340\n",
      "Epoch 10608 - Train Loss: 0.115580, Train Acc: 0.815385 | Val Loss: 0.132766, Val Acc: 0.711340\n",
      "Epoch 10609 - Train Loss: 0.115573, Train Acc: 0.815385 | Val Loss: 0.132761, Val Acc: 0.711340\n",
      "Epoch 10610 - Train Loss: 0.115566, Train Acc: 0.815385 | Val Loss: 0.132755, Val Acc: 0.711340\n",
      "Epoch 10611 - Train Loss: 0.115559, Train Acc: 0.815385 | Val Loss: 0.132749, Val Acc: 0.711340\n",
      "Epoch 10612 - Train Loss: 0.115552, Train Acc: 0.815385 | Val Loss: 0.132743, Val Acc: 0.711340\n",
      "Epoch 10613 - Train Loss: 0.115545, Train Acc: 0.815385 | Val Loss: 0.132738, Val Acc: 0.711340\n",
      "Epoch 10614 - Train Loss: 0.115539, Train Acc: 0.815385 | Val Loss: 0.132732, Val Acc: 0.711340\n",
      "Epoch 10615 - Train Loss: 0.115532, Train Acc: 0.815385 | Val Loss: 0.132726, Val Acc: 0.711340\n",
      "Epoch 10616 - Train Loss: 0.115525, Train Acc: 0.815385 | Val Loss: 0.132720, Val Acc: 0.711340\n",
      "Epoch 10617 - Train Loss: 0.115518, Train Acc: 0.815385 | Val Loss: 0.132715, Val Acc: 0.711340\n",
      "Epoch 10618 - Train Loss: 0.115511, Train Acc: 0.815385 | Val Loss: 0.132709, Val Acc: 0.711340\n",
      "Epoch 10619 - Train Loss: 0.115504, Train Acc: 0.815385 | Val Loss: 0.132703, Val Acc: 0.711340\n",
      "Epoch 10620 - Train Loss: 0.115497, Train Acc: 0.815385 | Val Loss: 0.132698, Val Acc: 0.711340\n",
      "Epoch 10621 - Train Loss: 0.115490, Train Acc: 0.815385 | Val Loss: 0.132692, Val Acc: 0.711340\n",
      "Epoch 10622 - Train Loss: 0.115484, Train Acc: 0.815385 | Val Loss: 0.132686, Val Acc: 0.711340\n",
      "Epoch 10623 - Train Loss: 0.115477, Train Acc: 0.815385 | Val Loss: 0.132680, Val Acc: 0.711340\n",
      "Epoch 10624 - Train Loss: 0.115470, Train Acc: 0.815385 | Val Loss: 0.132675, Val Acc: 0.711340\n",
      "Epoch 10625 - Train Loss: 0.115463, Train Acc: 0.815385 | Val Loss: 0.132669, Val Acc: 0.711340\n",
      "Epoch 10626 - Train Loss: 0.115456, Train Acc: 0.815385 | Val Loss: 0.132663, Val Acc: 0.711340\n",
      "Epoch 10627 - Train Loss: 0.115449, Train Acc: 0.815385 | Val Loss: 0.132658, Val Acc: 0.711340\n",
      "Epoch 10628 - Train Loss: 0.115442, Train Acc: 0.815385 | Val Loss: 0.132652, Val Acc: 0.711340\n",
      "Epoch 10629 - Train Loss: 0.115435, Train Acc: 0.815385 | Val Loss: 0.132646, Val Acc: 0.711340\n",
      "Epoch 10630 - Train Loss: 0.115429, Train Acc: 0.815385 | Val Loss: 0.132640, Val Acc: 0.711340\n",
      "Epoch 10631 - Train Loss: 0.115422, Train Acc: 0.815385 | Val Loss: 0.132635, Val Acc: 0.711340\n",
      "Epoch 10632 - Train Loss: 0.115415, Train Acc: 0.815385 | Val Loss: 0.132629, Val Acc: 0.711340\n",
      "Epoch 10633 - Train Loss: 0.115408, Train Acc: 0.815385 | Val Loss: 0.132623, Val Acc: 0.711340\n",
      "Epoch 10634 - Train Loss: 0.115401, Train Acc: 0.815385 | Val Loss: 0.132618, Val Acc: 0.711340\n",
      "Epoch 10635 - Train Loss: 0.115394, Train Acc: 0.815385 | Val Loss: 0.132612, Val Acc: 0.711340\n",
      "Epoch 10636 - Train Loss: 0.115387, Train Acc: 0.815385 | Val Loss: 0.132606, Val Acc: 0.711340\n",
      "Epoch 10637 - Train Loss: 0.115381, Train Acc: 0.815385 | Val Loss: 0.132600, Val Acc: 0.711340\n",
      "Epoch 10638 - Train Loss: 0.115374, Train Acc: 0.815385 | Val Loss: 0.132595, Val Acc: 0.711340\n",
      "Epoch 10639 - Train Loss: 0.115367, Train Acc: 0.815385 | Val Loss: 0.132589, Val Acc: 0.711340\n",
      "Epoch 10640 - Train Loss: 0.115360, Train Acc: 0.815385 | Val Loss: 0.132583, Val Acc: 0.711340\n",
      "Epoch 10641 - Train Loss: 0.115353, Train Acc: 0.815385 | Val Loss: 0.132578, Val Acc: 0.711340\n",
      "Epoch 10642 - Train Loss: 0.115346, Train Acc: 0.815385 | Val Loss: 0.132572, Val Acc: 0.711340\n",
      "Epoch 10643 - Train Loss: 0.115340, Train Acc: 0.815385 | Val Loss: 0.132566, Val Acc: 0.711340\n",
      "Epoch 10644 - Train Loss: 0.115333, Train Acc: 0.815385 | Val Loss: 0.132561, Val Acc: 0.711340\n",
      "Epoch 10645 - Train Loss: 0.115326, Train Acc: 0.815385 | Val Loss: 0.132555, Val Acc: 0.711340\n",
      "Epoch 10646 - Train Loss: 0.115319, Train Acc: 0.815385 | Val Loss: 0.132549, Val Acc: 0.711340\n",
      "Epoch 10647 - Train Loss: 0.115312, Train Acc: 0.815385 | Val Loss: 0.132543, Val Acc: 0.711340\n",
      "Epoch 10648 - Train Loss: 0.115305, Train Acc: 0.815385 | Val Loss: 0.132538, Val Acc: 0.711340\n",
      "Epoch 10649 - Train Loss: 0.115298, Train Acc: 0.815385 | Val Loss: 0.132532, Val Acc: 0.711340\n",
      "Epoch 10650 - Train Loss: 0.115292, Train Acc: 0.815385 | Val Loss: 0.132526, Val Acc: 0.711340\n",
      "Epoch 10651 - Train Loss: 0.115285, Train Acc: 0.815385 | Val Loss: 0.132521, Val Acc: 0.711340\n",
      "Epoch 10652 - Train Loss: 0.115278, Train Acc: 0.815385 | Val Loss: 0.132515, Val Acc: 0.711340\n",
      "Epoch 10653 - Train Loss: 0.115271, Train Acc: 0.815385 | Val Loss: 0.132509, Val Acc: 0.711340\n",
      "Epoch 10654 - Train Loss: 0.115264, Train Acc: 0.815385 | Val Loss: 0.132504, Val Acc: 0.711340\n",
      "Epoch 10655 - Train Loss: 0.115257, Train Acc: 0.815385 | Val Loss: 0.132498, Val Acc: 0.711340\n",
      "Epoch 10656 - Train Loss: 0.115251, Train Acc: 0.815385 | Val Loss: 0.132492, Val Acc: 0.711340\n",
      "Epoch 10657 - Train Loss: 0.115244, Train Acc: 0.815385 | Val Loss: 0.132487, Val Acc: 0.711340\n",
      "Epoch 10658 - Train Loss: 0.115237, Train Acc: 0.815385 | Val Loss: 0.132481, Val Acc: 0.711340\n",
      "Epoch 10659 - Train Loss: 0.115230, Train Acc: 0.815385 | Val Loss: 0.132475, Val Acc: 0.711340\n",
      "Epoch 10660 - Train Loss: 0.115223, Train Acc: 0.815385 | Val Loss: 0.132469, Val Acc: 0.711340\n",
      "Epoch 10661 - Train Loss: 0.115216, Train Acc: 0.815385 | Val Loss: 0.132464, Val Acc: 0.711340\n",
      "Epoch 10662 - Train Loss: 0.115210, Train Acc: 0.815385 | Val Loss: 0.132458, Val Acc: 0.711340\n",
      "Epoch 10663 - Train Loss: 0.115203, Train Acc: 0.815385 | Val Loss: 0.132452, Val Acc: 0.711340\n",
      "Epoch 10664 - Train Loss: 0.115196, Train Acc: 0.815385 | Val Loss: 0.132447, Val Acc: 0.711340\n",
      "Epoch 10665 - Train Loss: 0.115189, Train Acc: 0.815385 | Val Loss: 0.132441, Val Acc: 0.711340\n",
      "Epoch 10666 - Train Loss: 0.115182, Train Acc: 0.815385 | Val Loss: 0.132435, Val Acc: 0.711340\n",
      "Epoch 10667 - Train Loss: 0.115175, Train Acc: 0.816667 | Val Loss: 0.132430, Val Acc: 0.711340\n",
      "Epoch 10668 - Train Loss: 0.115169, Train Acc: 0.816667 | Val Loss: 0.132424, Val Acc: 0.711340\n",
      "Epoch 10669 - Train Loss: 0.115162, Train Acc: 0.816667 | Val Loss: 0.132418, Val Acc: 0.711340\n",
      "Epoch 10670 - Train Loss: 0.115155, Train Acc: 0.816667 | Val Loss: 0.132413, Val Acc: 0.711340\n",
      "Epoch 10671 - Train Loss: 0.115148, Train Acc: 0.816667 | Val Loss: 0.132407, Val Acc: 0.711340\n",
      "Epoch 10672 - Train Loss: 0.115141, Train Acc: 0.816667 | Val Loss: 0.132401, Val Acc: 0.711340\n",
      "Epoch 10673 - Train Loss: 0.115134, Train Acc: 0.816667 | Val Loss: 0.132396, Val Acc: 0.711340\n",
      "Epoch 10674 - Train Loss: 0.115128, Train Acc: 0.816667 | Val Loss: 0.132390, Val Acc: 0.711340\n",
      "Epoch 10675 - Train Loss: 0.115121, Train Acc: 0.816667 | Val Loss: 0.132384, Val Acc: 0.711340\n",
      "Epoch 10676 - Train Loss: 0.115114, Train Acc: 0.816667 | Val Loss: 0.132379, Val Acc: 0.711340\n",
      "Epoch 10677 - Train Loss: 0.115107, Train Acc: 0.816667 | Val Loss: 0.132373, Val Acc: 0.711340\n",
      "Epoch 10678 - Train Loss: 0.115100, Train Acc: 0.816667 | Val Loss: 0.132367, Val Acc: 0.711340\n",
      "Epoch 10679 - Train Loss: 0.115093, Train Acc: 0.816667 | Val Loss: 0.132361, Val Acc: 0.711340\n",
      "Epoch 10680 - Train Loss: 0.115087, Train Acc: 0.816667 | Val Loss: 0.132356, Val Acc: 0.711340\n",
      "Epoch 10681 - Train Loss: 0.115080, Train Acc: 0.816667 | Val Loss: 0.132350, Val Acc: 0.711340\n",
      "Epoch 10682 - Train Loss: 0.115073, Train Acc: 0.817949 | Val Loss: 0.132344, Val Acc: 0.711340\n",
      "Epoch 10683 - Train Loss: 0.115066, Train Acc: 0.817949 | Val Loss: 0.132339, Val Acc: 0.711340\n",
      "Epoch 10684 - Train Loss: 0.115059, Train Acc: 0.817949 | Val Loss: 0.132333, Val Acc: 0.711340\n",
      "Epoch 10685 - Train Loss: 0.115053, Train Acc: 0.817949 | Val Loss: 0.132327, Val Acc: 0.711340\n",
      "Epoch 10686 - Train Loss: 0.115046, Train Acc: 0.817949 | Val Loss: 0.132322, Val Acc: 0.711340\n",
      "Epoch 10687 - Train Loss: 0.115039, Train Acc: 0.817949 | Val Loss: 0.132316, Val Acc: 0.711340\n",
      "Epoch 10688 - Train Loss: 0.115032, Train Acc: 0.817949 | Val Loss: 0.132310, Val Acc: 0.711340\n",
      "Epoch 10689 - Train Loss: 0.115025, Train Acc: 0.817949 | Val Loss: 0.132305, Val Acc: 0.711340\n",
      "Epoch 10690 - Train Loss: 0.115018, Train Acc: 0.817949 | Val Loss: 0.132299, Val Acc: 0.711340\n",
      "Epoch 10691 - Train Loss: 0.115012, Train Acc: 0.817949 | Val Loss: 0.132293, Val Acc: 0.711340\n",
      "Epoch 10692 - Train Loss: 0.115005, Train Acc: 0.817949 | Val Loss: 0.132288, Val Acc: 0.711340\n",
      "Epoch 10693 - Train Loss: 0.114998, Train Acc: 0.817949 | Val Loss: 0.132282, Val Acc: 0.711340\n",
      "Epoch 10694 - Train Loss: 0.114991, Train Acc: 0.817949 | Val Loss: 0.132276, Val Acc: 0.711340\n",
      "Epoch 10695 - Train Loss: 0.114984, Train Acc: 0.817949 | Val Loss: 0.132271, Val Acc: 0.711340\n",
      "Epoch 10696 - Train Loss: 0.114978, Train Acc: 0.817949 | Val Loss: 0.132265, Val Acc: 0.711340\n",
      "Epoch 10697 - Train Loss: 0.114971, Train Acc: 0.817949 | Val Loss: 0.132259, Val Acc: 0.711340\n",
      "Epoch 10698 - Train Loss: 0.114964, Train Acc: 0.817949 | Val Loss: 0.132254, Val Acc: 0.711340\n",
      "Epoch 10699 - Train Loss: 0.114957, Train Acc: 0.817949 | Val Loss: 0.132248, Val Acc: 0.711340\n",
      "Epoch 10700 - Train Loss: 0.114950, Train Acc: 0.817949 | Val Loss: 0.132242, Val Acc: 0.711340\n",
      "Epoch 10701 - Train Loss: 0.114944, Train Acc: 0.817949 | Val Loss: 0.132237, Val Acc: 0.711340\n",
      "Epoch 10702 - Train Loss: 0.114937, Train Acc: 0.817949 | Val Loss: 0.132231, Val Acc: 0.711340\n",
      "Epoch 10703 - Train Loss: 0.114930, Train Acc: 0.817949 | Val Loss: 0.132225, Val Acc: 0.711340\n",
      "Epoch 10704 - Train Loss: 0.114923, Train Acc: 0.817949 | Val Loss: 0.132220, Val Acc: 0.711340\n",
      "Epoch 10705 - Train Loss: 0.114916, Train Acc: 0.817949 | Val Loss: 0.132214, Val Acc: 0.711340\n",
      "Epoch 10706 - Train Loss: 0.114910, Train Acc: 0.817949 | Val Loss: 0.132208, Val Acc: 0.711340\n",
      "Epoch 10707 - Train Loss: 0.114903, Train Acc: 0.817949 | Val Loss: 0.132203, Val Acc: 0.711340\n",
      "Epoch 10708 - Train Loss: 0.114896, Train Acc: 0.817949 | Val Loss: 0.132197, Val Acc: 0.711340\n",
      "Epoch 10709 - Train Loss: 0.114889, Train Acc: 0.817949 | Val Loss: 0.132191, Val Acc: 0.711340\n",
      "Epoch 10710 - Train Loss: 0.114883, Train Acc: 0.817949 | Val Loss: 0.132186, Val Acc: 0.711340\n",
      "Epoch 10711 - Train Loss: 0.114876, Train Acc: 0.817949 | Val Loss: 0.132180, Val Acc: 0.711340\n",
      "Epoch 10712 - Train Loss: 0.114869, Train Acc: 0.817949 | Val Loss: 0.132174, Val Acc: 0.711340\n",
      "Epoch 10713 - Train Loss: 0.114862, Train Acc: 0.817949 | Val Loss: 0.132169, Val Acc: 0.711340\n",
      "Epoch 10714 - Train Loss: 0.114855, Train Acc: 0.817949 | Val Loss: 0.132163, Val Acc: 0.711340\n",
      "Epoch 10715 - Train Loss: 0.114849, Train Acc: 0.817949 | Val Loss: 0.132157, Val Acc: 0.711340\n",
      "Epoch 10716 - Train Loss: 0.114842, Train Acc: 0.817949 | Val Loss: 0.132152, Val Acc: 0.711340\n",
      "Epoch 10717 - Train Loss: 0.114835, Train Acc: 0.817949 | Val Loss: 0.132146, Val Acc: 0.711340\n",
      "Epoch 10718 - Train Loss: 0.114828, Train Acc: 0.817949 | Val Loss: 0.132141, Val Acc: 0.711340\n",
      "Epoch 10719 - Train Loss: 0.114821, Train Acc: 0.817949 | Val Loss: 0.132135, Val Acc: 0.711340\n",
      "Epoch 10720 - Train Loss: 0.114815, Train Acc: 0.817949 | Val Loss: 0.132129, Val Acc: 0.711340\n",
      "Epoch 10721 - Train Loss: 0.114808, Train Acc: 0.817949 | Val Loss: 0.132124, Val Acc: 0.711340\n",
      "Epoch 10722 - Train Loss: 0.114801, Train Acc: 0.817949 | Val Loss: 0.132118, Val Acc: 0.711340\n",
      "Epoch 10723 - Train Loss: 0.114794, Train Acc: 0.817949 | Val Loss: 0.132112, Val Acc: 0.711340\n",
      "Epoch 10724 - Train Loss: 0.114788, Train Acc: 0.817949 | Val Loss: 0.132107, Val Acc: 0.711340\n",
      "Epoch 10725 - Train Loss: 0.114781, Train Acc: 0.817949 | Val Loss: 0.132101, Val Acc: 0.711340\n",
      "Epoch 10726 - Train Loss: 0.114774, Train Acc: 0.817949 | Val Loss: 0.132095, Val Acc: 0.711340\n",
      "Epoch 10727 - Train Loss: 0.114767, Train Acc: 0.817949 | Val Loss: 0.132090, Val Acc: 0.711340\n",
      "Epoch 10728 - Train Loss: 0.114761, Train Acc: 0.817949 | Val Loss: 0.132084, Val Acc: 0.711340\n",
      "Epoch 10729 - Train Loss: 0.114754, Train Acc: 0.817949 | Val Loss: 0.132079, Val Acc: 0.711340\n",
      "Epoch 10730 - Train Loss: 0.114747, Train Acc: 0.817949 | Val Loss: 0.132073, Val Acc: 0.711340\n",
      "Epoch 10731 - Train Loss: 0.114740, Train Acc: 0.817949 | Val Loss: 0.132067, Val Acc: 0.711340\n",
      "Epoch 10732 - Train Loss: 0.114733, Train Acc: 0.817949 | Val Loss: 0.132062, Val Acc: 0.711340\n",
      "Epoch 10733 - Train Loss: 0.114727, Train Acc: 0.817949 | Val Loss: 0.132056, Val Acc: 0.711340\n",
      "Epoch 10734 - Train Loss: 0.114720, Train Acc: 0.817949 | Val Loss: 0.132050, Val Acc: 0.711340\n",
      "Epoch 10735 - Train Loss: 0.114713, Train Acc: 0.817949 | Val Loss: 0.132045, Val Acc: 0.711340\n",
      "Epoch 10736 - Train Loss: 0.114706, Train Acc: 0.817949 | Val Loss: 0.132039, Val Acc: 0.711340\n",
      "Epoch 10737 - Train Loss: 0.114700, Train Acc: 0.817949 | Val Loss: 0.132034, Val Acc: 0.711340\n",
      "Epoch 10738 - Train Loss: 0.114693, Train Acc: 0.817949 | Val Loss: 0.132028, Val Acc: 0.711340\n",
      "Epoch 10739 - Train Loss: 0.114686, Train Acc: 0.817949 | Val Loss: 0.132022, Val Acc: 0.711340\n",
      "Epoch 10740 - Train Loss: 0.114679, Train Acc: 0.817949 | Val Loss: 0.132017, Val Acc: 0.711340\n",
      "Epoch 10741 - Train Loss: 0.114673, Train Acc: 0.817949 | Val Loss: 0.132011, Val Acc: 0.711340\n",
      "Epoch 10742 - Train Loss: 0.114666, Train Acc: 0.817949 | Val Loss: 0.132005, Val Acc: 0.711340\n",
      "Epoch 10743 - Train Loss: 0.114659, Train Acc: 0.817949 | Val Loss: 0.132000, Val Acc: 0.711340\n",
      "Epoch 10744 - Train Loss: 0.114652, Train Acc: 0.817949 | Val Loss: 0.131994, Val Acc: 0.711340\n",
      "Epoch 10745 - Train Loss: 0.114646, Train Acc: 0.817949 | Val Loss: 0.131989, Val Acc: 0.711340\n",
      "Epoch 10746 - Train Loss: 0.114639, Train Acc: 0.817949 | Val Loss: 0.131983, Val Acc: 0.711340\n",
      "Epoch 10747 - Train Loss: 0.114632, Train Acc: 0.817949 | Val Loss: 0.131977, Val Acc: 0.711340\n",
      "Epoch 10748 - Train Loss: 0.114625, Train Acc: 0.819231 | Val Loss: 0.131972, Val Acc: 0.711340\n",
      "Epoch 10749 - Train Loss: 0.114619, Train Acc: 0.819231 | Val Loss: 0.131966, Val Acc: 0.711340\n",
      "Epoch 10750 - Train Loss: 0.114612, Train Acc: 0.819231 | Val Loss: 0.131961, Val Acc: 0.711340\n",
      "Epoch 10751 - Train Loss: 0.114605, Train Acc: 0.819231 | Val Loss: 0.131955, Val Acc: 0.711340\n",
      "Epoch 10752 - Train Loss: 0.114598, Train Acc: 0.819231 | Val Loss: 0.131949, Val Acc: 0.711340\n",
      "Epoch 10753 - Train Loss: 0.114592, Train Acc: 0.819231 | Val Loss: 0.131944, Val Acc: 0.711340\n",
      "Epoch 10754 - Train Loss: 0.114585, Train Acc: 0.819231 | Val Loss: 0.131938, Val Acc: 0.711340\n",
      "Epoch 10755 - Train Loss: 0.114578, Train Acc: 0.819231 | Val Loss: 0.131933, Val Acc: 0.711340\n",
      "Epoch 10756 - Train Loss: 0.114571, Train Acc: 0.819231 | Val Loss: 0.131927, Val Acc: 0.711340\n",
      "Epoch 10757 - Train Loss: 0.114565, Train Acc: 0.819231 | Val Loss: 0.131921, Val Acc: 0.711340\n",
      "Epoch 10758 - Train Loss: 0.114558, Train Acc: 0.819231 | Val Loss: 0.131916, Val Acc: 0.711340\n",
      "Epoch 10759 - Train Loss: 0.114551, Train Acc: 0.819231 | Val Loss: 0.131910, Val Acc: 0.711340\n",
      "Epoch 10760 - Train Loss: 0.114544, Train Acc: 0.819231 | Val Loss: 0.131905, Val Acc: 0.711340\n",
      "Epoch 10761 - Train Loss: 0.114538, Train Acc: 0.819231 | Val Loss: 0.131899, Val Acc: 0.711340\n",
      "Epoch 10762 - Train Loss: 0.114531, Train Acc: 0.819231 | Val Loss: 0.131893, Val Acc: 0.711340\n",
      "Epoch 10763 - Train Loss: 0.114524, Train Acc: 0.819231 | Val Loss: 0.131888, Val Acc: 0.711340\n",
      "Epoch 10764 - Train Loss: 0.114517, Train Acc: 0.819231 | Val Loss: 0.131882, Val Acc: 0.711340\n",
      "Epoch 10765 - Train Loss: 0.114511, Train Acc: 0.819231 | Val Loss: 0.131877, Val Acc: 0.711340\n",
      "Epoch 10766 - Train Loss: 0.114504, Train Acc: 0.819231 | Val Loss: 0.131871, Val Acc: 0.711340\n",
      "Epoch 10767 - Train Loss: 0.114497, Train Acc: 0.819231 | Val Loss: 0.131865, Val Acc: 0.711340\n",
      "Epoch 10768 - Train Loss: 0.114491, Train Acc: 0.819231 | Val Loss: 0.131860, Val Acc: 0.711340\n",
      "Epoch 10769 - Train Loss: 0.114484, Train Acc: 0.819231 | Val Loss: 0.131854, Val Acc: 0.711340\n",
      "Epoch 10770 - Train Loss: 0.114477, Train Acc: 0.819231 | Val Loss: 0.131849, Val Acc: 0.711340\n",
      "Epoch 10771 - Train Loss: 0.114470, Train Acc: 0.819231 | Val Loss: 0.131843, Val Acc: 0.711340\n",
      "Epoch 10772 - Train Loss: 0.114464, Train Acc: 0.819231 | Val Loss: 0.131837, Val Acc: 0.711340\n",
      "Epoch 10773 - Train Loss: 0.114457, Train Acc: 0.819231 | Val Loss: 0.131832, Val Acc: 0.711340\n",
      "Epoch 10774 - Train Loss: 0.114450, Train Acc: 0.819231 | Val Loss: 0.131826, Val Acc: 0.711340\n",
      "Epoch 10775 - Train Loss: 0.114443, Train Acc: 0.819231 | Val Loss: 0.131821, Val Acc: 0.711340\n",
      "Epoch 10776 - Train Loss: 0.114437, Train Acc: 0.819231 | Val Loss: 0.131815, Val Acc: 0.711340\n",
      "Epoch 10777 - Train Loss: 0.114430, Train Acc: 0.819231 | Val Loss: 0.131809, Val Acc: 0.711340\n",
      "Epoch 10778 - Train Loss: 0.114423, Train Acc: 0.819231 | Val Loss: 0.131804, Val Acc: 0.711340\n",
      "Epoch 10779 - Train Loss: 0.114417, Train Acc: 0.819231 | Val Loss: 0.131798, Val Acc: 0.711340\n",
      "Epoch 10780 - Train Loss: 0.114410, Train Acc: 0.819231 | Val Loss: 0.131793, Val Acc: 0.711340\n",
      "Epoch 10781 - Train Loss: 0.114403, Train Acc: 0.819231 | Val Loss: 0.131787, Val Acc: 0.711340\n",
      "Epoch 10782 - Train Loss: 0.114396, Train Acc: 0.819231 | Val Loss: 0.131782, Val Acc: 0.711340\n",
      "Epoch 10783 - Train Loss: 0.114390, Train Acc: 0.819231 | Val Loss: 0.131776, Val Acc: 0.711340\n",
      "Epoch 10784 - Train Loss: 0.114383, Train Acc: 0.819231 | Val Loss: 0.131770, Val Acc: 0.711340\n",
      "Epoch 10785 - Train Loss: 0.114376, Train Acc: 0.819231 | Val Loss: 0.131765, Val Acc: 0.711340\n",
      "Epoch 10786 - Train Loss: 0.114369, Train Acc: 0.819231 | Val Loss: 0.131759, Val Acc: 0.711340\n",
      "Epoch 10787 - Train Loss: 0.114363, Train Acc: 0.819231 | Val Loss: 0.131754, Val Acc: 0.711340\n",
      "Epoch 10788 - Train Loss: 0.114356, Train Acc: 0.819231 | Val Loss: 0.131748, Val Acc: 0.711340\n",
      "Epoch 10789 - Train Loss: 0.114349, Train Acc: 0.819231 | Val Loss: 0.131743, Val Acc: 0.711340\n",
      "Epoch 10790 - Train Loss: 0.114343, Train Acc: 0.819231 | Val Loss: 0.131737, Val Acc: 0.711340\n",
      "Epoch 10791 - Train Loss: 0.114336, Train Acc: 0.819231 | Val Loss: 0.131731, Val Acc: 0.711340\n",
      "Epoch 10792 - Train Loss: 0.114329, Train Acc: 0.819231 | Val Loss: 0.131726, Val Acc: 0.711340\n",
      "Epoch 10793 - Train Loss: 0.114322, Train Acc: 0.819231 | Val Loss: 0.131720, Val Acc: 0.711340\n",
      "Epoch 10794 - Train Loss: 0.114316, Train Acc: 0.819231 | Val Loss: 0.131715, Val Acc: 0.711340\n",
      "Epoch 10795 - Train Loss: 0.114309, Train Acc: 0.819231 | Val Loss: 0.131709, Val Acc: 0.711340\n",
      "Epoch 10796 - Train Loss: 0.114302, Train Acc: 0.819231 | Val Loss: 0.131704, Val Acc: 0.711340\n",
      "Epoch 10797 - Train Loss: 0.114296, Train Acc: 0.819231 | Val Loss: 0.131698, Val Acc: 0.711340\n",
      "Epoch 10798 - Train Loss: 0.114289, Train Acc: 0.819231 | Val Loss: 0.131692, Val Acc: 0.711340\n",
      "Epoch 10799 - Train Loss: 0.114282, Train Acc: 0.819231 | Val Loss: 0.131687, Val Acc: 0.711340\n",
      "Epoch 10800 - Train Loss: 0.114276, Train Acc: 0.819231 | Val Loss: 0.131681, Val Acc: 0.711340\n",
      "Epoch 10801 - Train Loss: 0.114269, Train Acc: 0.819231 | Val Loss: 0.131676, Val Acc: 0.711340\n",
      "Epoch 10802 - Train Loss: 0.114262, Train Acc: 0.819231 | Val Loss: 0.131670, Val Acc: 0.711340\n",
      "Epoch 10803 - Train Loss: 0.114255, Train Acc: 0.819231 | Val Loss: 0.131665, Val Acc: 0.711340\n",
      "Epoch 10804 - Train Loss: 0.114249, Train Acc: 0.819231 | Val Loss: 0.131659, Val Acc: 0.711340\n",
      "Epoch 10805 - Train Loss: 0.114242, Train Acc: 0.819231 | Val Loss: 0.131653, Val Acc: 0.711340\n",
      "Epoch 10806 - Train Loss: 0.114235, Train Acc: 0.819231 | Val Loss: 0.131648, Val Acc: 0.711340\n",
      "Epoch 10807 - Train Loss: 0.114229, Train Acc: 0.819231 | Val Loss: 0.131642, Val Acc: 0.711340\n",
      "Epoch 10808 - Train Loss: 0.114222, Train Acc: 0.819231 | Val Loss: 0.131637, Val Acc: 0.711340\n",
      "Epoch 10809 - Train Loss: 0.114215, Train Acc: 0.819231 | Val Loss: 0.131631, Val Acc: 0.711340\n",
      "Epoch 10810 - Train Loss: 0.114209, Train Acc: 0.819231 | Val Loss: 0.131626, Val Acc: 0.711340\n",
      "Epoch 10811 - Train Loss: 0.114202, Train Acc: 0.819231 | Val Loss: 0.131620, Val Acc: 0.711340\n",
      "Epoch 10812 - Train Loss: 0.114195, Train Acc: 0.819231 | Val Loss: 0.131615, Val Acc: 0.711340\n",
      "Epoch 10813 - Train Loss: 0.114188, Train Acc: 0.819231 | Val Loss: 0.131609, Val Acc: 0.711340\n",
      "Epoch 10814 - Train Loss: 0.114182, Train Acc: 0.819231 | Val Loss: 0.131603, Val Acc: 0.711340\n",
      "Epoch 10815 - Train Loss: 0.114175, Train Acc: 0.819231 | Val Loss: 0.131598, Val Acc: 0.711340\n",
      "Epoch 10816 - Train Loss: 0.114168, Train Acc: 0.819231 | Val Loss: 0.131592, Val Acc: 0.711340\n",
      "Epoch 10817 - Train Loss: 0.114162, Train Acc: 0.819231 | Val Loss: 0.131587, Val Acc: 0.711340\n",
      "Epoch 10818 - Train Loss: 0.114155, Train Acc: 0.819231 | Val Loss: 0.131581, Val Acc: 0.711340\n",
      "Epoch 10819 - Train Loss: 0.114148, Train Acc: 0.819231 | Val Loss: 0.131576, Val Acc: 0.711340\n",
      "Epoch 10820 - Train Loss: 0.114142, Train Acc: 0.819231 | Val Loss: 0.131570, Val Acc: 0.711340\n",
      "Epoch 10821 - Train Loss: 0.114135, Train Acc: 0.819231 | Val Loss: 0.131565, Val Acc: 0.711340\n",
      "Epoch 10822 - Train Loss: 0.114128, Train Acc: 0.819231 | Val Loss: 0.131559, Val Acc: 0.711340\n",
      "Epoch 10823 - Train Loss: 0.114122, Train Acc: 0.819231 | Val Loss: 0.131553, Val Acc: 0.711340\n",
      "Epoch 10824 - Train Loss: 0.114115, Train Acc: 0.819231 | Val Loss: 0.131548, Val Acc: 0.711340\n",
      "Epoch 10825 - Train Loss: 0.114108, Train Acc: 0.819231 | Val Loss: 0.131542, Val Acc: 0.711340\n",
      "Epoch 10826 - Train Loss: 0.114102, Train Acc: 0.819231 | Val Loss: 0.131537, Val Acc: 0.711340\n",
      "Epoch 10827 - Train Loss: 0.114095, Train Acc: 0.819231 | Val Loss: 0.131531, Val Acc: 0.711340\n",
      "Epoch 10828 - Train Loss: 0.114088, Train Acc: 0.819231 | Val Loss: 0.131526, Val Acc: 0.711340\n",
      "Epoch 10829 - Train Loss: 0.114082, Train Acc: 0.819231 | Val Loss: 0.131520, Val Acc: 0.711340\n",
      "Epoch 10830 - Train Loss: 0.114075, Train Acc: 0.819231 | Val Loss: 0.131515, Val Acc: 0.711340\n",
      "Epoch 10831 - Train Loss: 0.114068, Train Acc: 0.819231 | Val Loss: 0.131509, Val Acc: 0.711340\n",
      "Epoch 10832 - Train Loss: 0.114061, Train Acc: 0.819231 | Val Loss: 0.131504, Val Acc: 0.711340\n",
      "Epoch 10833 - Train Loss: 0.114055, Train Acc: 0.819231 | Val Loss: 0.131498, Val Acc: 0.711340\n",
      "Epoch 10834 - Train Loss: 0.114048, Train Acc: 0.819231 | Val Loss: 0.131492, Val Acc: 0.711340\n",
      "Epoch 10835 - Train Loss: 0.114041, Train Acc: 0.819231 | Val Loss: 0.131487, Val Acc: 0.711340\n",
      "Epoch 10836 - Train Loss: 0.114035, Train Acc: 0.819231 | Val Loss: 0.131481, Val Acc: 0.711340\n",
      "Epoch 10837 - Train Loss: 0.114028, Train Acc: 0.819231 | Val Loss: 0.131476, Val Acc: 0.711340\n",
      "Epoch 10838 - Train Loss: 0.114021, Train Acc: 0.819231 | Val Loss: 0.131470, Val Acc: 0.711340\n",
      "Epoch 10839 - Train Loss: 0.114015, Train Acc: 0.819231 | Val Loss: 0.131465, Val Acc: 0.711340\n",
      "Epoch 10840 - Train Loss: 0.114008, Train Acc: 0.819231 | Val Loss: 0.131459, Val Acc: 0.711340\n",
      "Epoch 10841 - Train Loss: 0.114001, Train Acc: 0.819231 | Val Loss: 0.131454, Val Acc: 0.711340\n",
      "Epoch 10842 - Train Loss: 0.113995, Train Acc: 0.819231 | Val Loss: 0.131448, Val Acc: 0.711340\n",
      "Epoch 10843 - Train Loss: 0.113988, Train Acc: 0.819231 | Val Loss: 0.131443, Val Acc: 0.711340\n",
      "Epoch 10844 - Train Loss: 0.113981, Train Acc: 0.819231 | Val Loss: 0.131437, Val Acc: 0.711340\n",
      "Epoch 10845 - Train Loss: 0.113975, Train Acc: 0.819231 | Val Loss: 0.131432, Val Acc: 0.711340\n",
      "Epoch 10846 - Train Loss: 0.113968, Train Acc: 0.819231 | Val Loss: 0.131426, Val Acc: 0.711340\n",
      "Epoch 10847 - Train Loss: 0.113961, Train Acc: 0.819231 | Val Loss: 0.131421, Val Acc: 0.711340\n",
      "Epoch 10848 - Train Loss: 0.113955, Train Acc: 0.819231 | Val Loss: 0.131415, Val Acc: 0.711340\n",
      "Epoch 10849 - Train Loss: 0.113948, Train Acc: 0.819231 | Val Loss: 0.131410, Val Acc: 0.711340\n",
      "Epoch 10850 - Train Loss: 0.113942, Train Acc: 0.819231 | Val Loss: 0.131404, Val Acc: 0.711340\n",
      "Epoch 10851 - Train Loss: 0.113935, Train Acc: 0.819231 | Val Loss: 0.131399, Val Acc: 0.711340\n",
      "Epoch 10852 - Train Loss: 0.113928, Train Acc: 0.819231 | Val Loss: 0.131393, Val Acc: 0.711340\n",
      "Epoch 10853 - Train Loss: 0.113922, Train Acc: 0.819231 | Val Loss: 0.131387, Val Acc: 0.711340\n",
      "Epoch 10854 - Train Loss: 0.113915, Train Acc: 0.819231 | Val Loss: 0.131382, Val Acc: 0.711340\n",
      "Epoch 10855 - Train Loss: 0.113908, Train Acc: 0.819231 | Val Loss: 0.131376, Val Acc: 0.711340\n",
      "Epoch 10856 - Train Loss: 0.113902, Train Acc: 0.819231 | Val Loss: 0.131371, Val Acc: 0.711340\n",
      "Epoch 10857 - Train Loss: 0.113895, Train Acc: 0.819231 | Val Loss: 0.131365, Val Acc: 0.711340\n",
      "Epoch 10858 - Train Loss: 0.113888, Train Acc: 0.819231 | Val Loss: 0.131360, Val Acc: 0.711340\n",
      "Epoch 10859 - Train Loss: 0.113882, Train Acc: 0.819231 | Val Loss: 0.131354, Val Acc: 0.711340\n",
      "Epoch 10860 - Train Loss: 0.113875, Train Acc: 0.819231 | Val Loss: 0.131349, Val Acc: 0.711340\n",
      "Epoch 10861 - Train Loss: 0.113868, Train Acc: 0.819231 | Val Loss: 0.131343, Val Acc: 0.711340\n",
      "Epoch 10862 - Train Loss: 0.113862, Train Acc: 0.819231 | Val Loss: 0.131338, Val Acc: 0.711340\n",
      "Epoch 10863 - Train Loss: 0.113855, Train Acc: 0.819231 | Val Loss: 0.131332, Val Acc: 0.711340\n",
      "Epoch 10864 - Train Loss: 0.113848, Train Acc: 0.819231 | Val Loss: 0.131327, Val Acc: 0.711340\n",
      "Epoch 10865 - Train Loss: 0.113842, Train Acc: 0.819231 | Val Loss: 0.131321, Val Acc: 0.711340\n",
      "Epoch 10866 - Train Loss: 0.113835, Train Acc: 0.819231 | Val Loss: 0.131316, Val Acc: 0.711340\n",
      "Epoch 10867 - Train Loss: 0.113829, Train Acc: 0.819231 | Val Loss: 0.131310, Val Acc: 0.711340\n",
      "Epoch 10868 - Train Loss: 0.113822, Train Acc: 0.819231 | Val Loss: 0.131305, Val Acc: 0.711340\n",
      "Epoch 10869 - Train Loss: 0.113815, Train Acc: 0.819231 | Val Loss: 0.131299, Val Acc: 0.711340\n",
      "Epoch 10870 - Train Loss: 0.113809, Train Acc: 0.819231 | Val Loss: 0.131294, Val Acc: 0.711340\n",
      "Epoch 10871 - Train Loss: 0.113802, Train Acc: 0.819231 | Val Loss: 0.131288, Val Acc: 0.711340\n",
      "Epoch 10872 - Train Loss: 0.113795, Train Acc: 0.819231 | Val Loss: 0.131283, Val Acc: 0.711340\n",
      "Epoch 10873 - Train Loss: 0.113789, Train Acc: 0.819231 | Val Loss: 0.131277, Val Acc: 0.711340\n",
      "Epoch 10874 - Train Loss: 0.113782, Train Acc: 0.819231 | Val Loss: 0.131272, Val Acc: 0.711340\n",
      "Epoch 10875 - Train Loss: 0.113775, Train Acc: 0.819231 | Val Loss: 0.131267, Val Acc: 0.711340\n",
      "Epoch 10876 - Train Loss: 0.113769, Train Acc: 0.819231 | Val Loss: 0.131261, Val Acc: 0.711340\n",
      "Epoch 10877 - Train Loss: 0.113762, Train Acc: 0.819231 | Val Loss: 0.131256, Val Acc: 0.711340\n",
      "Epoch 10878 - Train Loss: 0.113756, Train Acc: 0.819231 | Val Loss: 0.131250, Val Acc: 0.711340\n",
      "Epoch 10879 - Train Loss: 0.113749, Train Acc: 0.819231 | Val Loss: 0.131245, Val Acc: 0.711340\n",
      "Epoch 10880 - Train Loss: 0.113742, Train Acc: 0.819231 | Val Loss: 0.131239, Val Acc: 0.711340\n",
      "Epoch 10881 - Train Loss: 0.113736, Train Acc: 0.819231 | Val Loss: 0.131234, Val Acc: 0.711340\n",
      "Epoch 10882 - Train Loss: 0.113729, Train Acc: 0.819231 | Val Loss: 0.131228, Val Acc: 0.711340\n",
      "Epoch 10883 - Train Loss: 0.113722, Train Acc: 0.819231 | Val Loss: 0.131223, Val Acc: 0.711340\n",
      "Epoch 10884 - Train Loss: 0.113716, Train Acc: 0.819231 | Val Loss: 0.131217, Val Acc: 0.711340\n",
      "Epoch 10885 - Train Loss: 0.113709, Train Acc: 0.819231 | Val Loss: 0.131212, Val Acc: 0.711340\n",
      "Epoch 10886 - Train Loss: 0.113703, Train Acc: 0.819231 | Val Loss: 0.131206, Val Acc: 0.711340\n",
      "Epoch 10887 - Train Loss: 0.113696, Train Acc: 0.819231 | Val Loss: 0.131201, Val Acc: 0.711340\n",
      "Epoch 10888 - Train Loss: 0.113689, Train Acc: 0.819231 | Val Loss: 0.131195, Val Acc: 0.711340\n",
      "Epoch 10889 - Train Loss: 0.113683, Train Acc: 0.819231 | Val Loss: 0.131190, Val Acc: 0.711340\n",
      "Epoch 10890 - Train Loss: 0.113676, Train Acc: 0.819231 | Val Loss: 0.131184, Val Acc: 0.711340\n",
      "Epoch 10891 - Train Loss: 0.113670, Train Acc: 0.819231 | Val Loss: 0.131179, Val Acc: 0.711340\n",
      "Epoch 10892 - Train Loss: 0.113663, Train Acc: 0.819231 | Val Loss: 0.131173, Val Acc: 0.711340\n",
      "Epoch 10893 - Train Loss: 0.113656, Train Acc: 0.819231 | Val Loss: 0.131168, Val Acc: 0.711340\n",
      "Epoch 10894 - Train Loss: 0.113650, Train Acc: 0.819231 | Val Loss: 0.131162, Val Acc: 0.711340\n",
      "Epoch 10895 - Train Loss: 0.113643, Train Acc: 0.819231 | Val Loss: 0.131157, Val Acc: 0.711340\n",
      "Epoch 10896 - Train Loss: 0.113636, Train Acc: 0.819231 | Val Loss: 0.131151, Val Acc: 0.711340\n",
      "Epoch 10897 - Train Loss: 0.113630, Train Acc: 0.819231 | Val Loss: 0.131146, Val Acc: 0.711340\n",
      "Epoch 10898 - Train Loss: 0.113623, Train Acc: 0.819231 | Val Loss: 0.131141, Val Acc: 0.711340\n",
      "Epoch 10899 - Train Loss: 0.113617, Train Acc: 0.819231 | Val Loss: 0.131135, Val Acc: 0.711340\n",
      "Epoch 10900 - Train Loss: 0.113610, Train Acc: 0.819231 | Val Loss: 0.131130, Val Acc: 0.711340\n",
      "Epoch 10901 - Train Loss: 0.113603, Train Acc: 0.819231 | Val Loss: 0.131124, Val Acc: 0.711340\n",
      "Epoch 10902 - Train Loss: 0.113597, Train Acc: 0.819231 | Val Loss: 0.131119, Val Acc: 0.711340\n",
      "Epoch 10903 - Train Loss: 0.113590, Train Acc: 0.819231 | Val Loss: 0.131113, Val Acc: 0.711340\n",
      "Epoch 10904 - Train Loss: 0.113584, Train Acc: 0.819231 | Val Loss: 0.131108, Val Acc: 0.711340\n",
      "Epoch 10905 - Train Loss: 0.113577, Train Acc: 0.819231 | Val Loss: 0.131102, Val Acc: 0.711340\n",
      "Epoch 10906 - Train Loss: 0.113570, Train Acc: 0.819231 | Val Loss: 0.131097, Val Acc: 0.711340\n",
      "Epoch 10907 - Train Loss: 0.113564, Train Acc: 0.819231 | Val Loss: 0.131091, Val Acc: 0.711340\n",
      "Epoch 10908 - Train Loss: 0.113557, Train Acc: 0.819231 | Val Loss: 0.131086, Val Acc: 0.711340\n",
      "Epoch 10909 - Train Loss: 0.113551, Train Acc: 0.819231 | Val Loss: 0.131081, Val Acc: 0.711340\n",
      "Epoch 10910 - Train Loss: 0.113544, Train Acc: 0.819231 | Val Loss: 0.131075, Val Acc: 0.711340\n",
      "Epoch 10911 - Train Loss: 0.113537, Train Acc: 0.819231 | Val Loss: 0.131070, Val Acc: 0.711340\n",
      "Epoch 10912 - Train Loss: 0.113531, Train Acc: 0.819231 | Val Loss: 0.131064, Val Acc: 0.711340\n",
      "Epoch 10913 - Train Loss: 0.113524, Train Acc: 0.819231 | Val Loss: 0.131059, Val Acc: 0.711340\n",
      "Epoch 10914 - Train Loss: 0.113518, Train Acc: 0.819231 | Val Loss: 0.131053, Val Acc: 0.711340\n",
      "Epoch 10915 - Train Loss: 0.113511, Train Acc: 0.819231 | Val Loss: 0.131048, Val Acc: 0.711340\n",
      "Epoch 10916 - Train Loss: 0.113505, Train Acc: 0.819231 | Val Loss: 0.131042, Val Acc: 0.711340\n",
      "Epoch 10917 - Train Loss: 0.113498, Train Acc: 0.819231 | Val Loss: 0.131037, Val Acc: 0.711340\n",
      "Epoch 10918 - Train Loss: 0.113491, Train Acc: 0.819231 | Val Loss: 0.131032, Val Acc: 0.711340\n",
      "Epoch 10919 - Train Loss: 0.113485, Train Acc: 0.819231 | Val Loss: 0.131026, Val Acc: 0.711340\n",
      "Epoch 10920 - Train Loss: 0.113478, Train Acc: 0.819231 | Val Loss: 0.131021, Val Acc: 0.711340\n",
      "Epoch 10921 - Train Loss: 0.113472, Train Acc: 0.819231 | Val Loss: 0.131015, Val Acc: 0.701031\n",
      "Epoch 10922 - Train Loss: 0.113465, Train Acc: 0.819231 | Val Loss: 0.131010, Val Acc: 0.701031\n",
      "Epoch 10923 - Train Loss: 0.113458, Train Acc: 0.819231 | Val Loss: 0.131004, Val Acc: 0.701031\n",
      "Epoch 10924 - Train Loss: 0.113452, Train Acc: 0.819231 | Val Loss: 0.130999, Val Acc: 0.701031\n",
      "Epoch 10925 - Train Loss: 0.113445, Train Acc: 0.819231 | Val Loss: 0.130994, Val Acc: 0.701031\n",
      "Epoch 10926 - Train Loss: 0.113439, Train Acc: 0.819231 | Val Loss: 0.130988, Val Acc: 0.701031\n",
      "Epoch 10927 - Train Loss: 0.113432, Train Acc: 0.819231 | Val Loss: 0.130983, Val Acc: 0.701031\n",
      "Epoch 10928 - Train Loss: 0.113426, Train Acc: 0.819231 | Val Loss: 0.130977, Val Acc: 0.701031\n",
      "Epoch 10929 - Train Loss: 0.113419, Train Acc: 0.819231 | Val Loss: 0.130972, Val Acc: 0.701031\n",
      "Epoch 10930 - Train Loss: 0.113412, Train Acc: 0.819231 | Val Loss: 0.130966, Val Acc: 0.701031\n",
      "Epoch 10931 - Train Loss: 0.113406, Train Acc: 0.819231 | Val Loss: 0.130961, Val Acc: 0.701031\n",
      "Epoch 10932 - Train Loss: 0.113399, Train Acc: 0.819231 | Val Loss: 0.130956, Val Acc: 0.701031\n",
      "Epoch 10933 - Train Loss: 0.113393, Train Acc: 0.819231 | Val Loss: 0.130950, Val Acc: 0.701031\n",
      "Epoch 10934 - Train Loss: 0.113386, Train Acc: 0.819231 | Val Loss: 0.130945, Val Acc: 0.701031\n",
      "Epoch 10935 - Train Loss: 0.113380, Train Acc: 0.819231 | Val Loss: 0.130939, Val Acc: 0.701031\n",
      "Epoch 10936 - Train Loss: 0.113373, Train Acc: 0.819231 | Val Loss: 0.130934, Val Acc: 0.701031\n",
      "Epoch 10937 - Train Loss: 0.113366, Train Acc: 0.819231 | Val Loss: 0.130928, Val Acc: 0.701031\n",
      "Epoch 10938 - Train Loss: 0.113360, Train Acc: 0.819231 | Val Loss: 0.130923, Val Acc: 0.701031\n",
      "Epoch 10939 - Train Loss: 0.113353, Train Acc: 0.819231 | Val Loss: 0.130918, Val Acc: 0.701031\n",
      "Epoch 10940 - Train Loss: 0.113347, Train Acc: 0.819231 | Val Loss: 0.130912, Val Acc: 0.701031\n",
      "Epoch 10941 - Train Loss: 0.113340, Train Acc: 0.819231 | Val Loss: 0.130907, Val Acc: 0.701031\n",
      "Epoch 10942 - Train Loss: 0.113334, Train Acc: 0.819231 | Val Loss: 0.130901, Val Acc: 0.701031\n",
      "Epoch 10943 - Train Loss: 0.113327, Train Acc: 0.819231 | Val Loss: 0.130896, Val Acc: 0.701031\n",
      "Epoch 10944 - Train Loss: 0.113320, Train Acc: 0.819231 | Val Loss: 0.130891, Val Acc: 0.701031\n",
      "Epoch 10945 - Train Loss: 0.113314, Train Acc: 0.819231 | Val Loss: 0.130885, Val Acc: 0.701031\n",
      "Epoch 10946 - Train Loss: 0.113307, Train Acc: 0.819231 | Val Loss: 0.130880, Val Acc: 0.701031\n",
      "Epoch 10947 - Train Loss: 0.113301, Train Acc: 0.819231 | Val Loss: 0.130874, Val Acc: 0.701031\n",
      "Epoch 10948 - Train Loss: 0.113294, Train Acc: 0.819231 | Val Loss: 0.130869, Val Acc: 0.701031\n",
      "Epoch 10949 - Train Loss: 0.113288, Train Acc: 0.819231 | Val Loss: 0.130863, Val Acc: 0.701031\n",
      "Epoch 10950 - Train Loss: 0.113281, Train Acc: 0.819231 | Val Loss: 0.130858, Val Acc: 0.701031\n",
      "Epoch 10951 - Train Loss: 0.113274, Train Acc: 0.819231 | Val Loss: 0.130853, Val Acc: 0.701031\n",
      "Epoch 10952 - Train Loss: 0.113268, Train Acc: 0.819231 | Val Loss: 0.130847, Val Acc: 0.701031\n",
      "Epoch 10953 - Train Loss: 0.113261, Train Acc: 0.819231 | Val Loss: 0.130842, Val Acc: 0.701031\n",
      "Epoch 10954 - Train Loss: 0.113255, Train Acc: 0.819231 | Val Loss: 0.130836, Val Acc: 0.701031\n",
      "Epoch 10955 - Train Loss: 0.113248, Train Acc: 0.819231 | Val Loss: 0.130831, Val Acc: 0.701031\n",
      "Epoch 10956 - Train Loss: 0.113242, Train Acc: 0.819231 | Val Loss: 0.130826, Val Acc: 0.701031\n",
      "Epoch 10957 - Train Loss: 0.113235, Train Acc: 0.819231 | Val Loss: 0.130820, Val Acc: 0.701031\n",
      "Epoch 10958 - Train Loss: 0.113229, Train Acc: 0.819231 | Val Loss: 0.130815, Val Acc: 0.701031\n",
      "Epoch 10959 - Train Loss: 0.113222, Train Acc: 0.819231 | Val Loss: 0.130809, Val Acc: 0.701031\n",
      "Epoch 10960 - Train Loss: 0.113215, Train Acc: 0.819231 | Val Loss: 0.130804, Val Acc: 0.701031\n",
      "Epoch 10961 - Train Loss: 0.113209, Train Acc: 0.819231 | Val Loss: 0.130798, Val Acc: 0.701031\n",
      "Epoch 10962 - Train Loss: 0.113202, Train Acc: 0.819231 | Val Loss: 0.130793, Val Acc: 0.701031\n",
      "Epoch 10963 - Train Loss: 0.113196, Train Acc: 0.819231 | Val Loss: 0.130788, Val Acc: 0.701031\n",
      "Epoch 10964 - Train Loss: 0.113189, Train Acc: 0.819231 | Val Loss: 0.130782, Val Acc: 0.701031\n",
      "Epoch 10965 - Train Loss: 0.113183, Train Acc: 0.819231 | Val Loss: 0.130777, Val Acc: 0.701031\n",
      "Epoch 10966 - Train Loss: 0.113176, Train Acc: 0.819231 | Val Loss: 0.130771, Val Acc: 0.701031\n",
      "Epoch 10967 - Train Loss: 0.113170, Train Acc: 0.819231 | Val Loss: 0.130766, Val Acc: 0.701031\n",
      "Epoch 10968 - Train Loss: 0.113163, Train Acc: 0.819231 | Val Loss: 0.130761, Val Acc: 0.701031\n",
      "Epoch 10969 - Train Loss: 0.113157, Train Acc: 0.819231 | Val Loss: 0.130755, Val Acc: 0.701031\n",
      "Epoch 10970 - Train Loss: 0.113150, Train Acc: 0.819231 | Val Loss: 0.130750, Val Acc: 0.701031\n",
      "Epoch 10971 - Train Loss: 0.113143, Train Acc: 0.819231 | Val Loss: 0.130744, Val Acc: 0.701031\n",
      "Epoch 10972 - Train Loss: 0.113137, Train Acc: 0.819231 | Val Loss: 0.130739, Val Acc: 0.701031\n",
      "Epoch 10973 - Train Loss: 0.113130, Train Acc: 0.819231 | Val Loss: 0.130733, Val Acc: 0.701031\n",
      "Epoch 10974 - Train Loss: 0.113124, Train Acc: 0.819231 | Val Loss: 0.130728, Val Acc: 0.701031\n",
      "Epoch 10975 - Train Loss: 0.113117, Train Acc: 0.819231 | Val Loss: 0.130723, Val Acc: 0.701031\n",
      "Epoch 10976 - Train Loss: 0.113111, Train Acc: 0.820513 | Val Loss: 0.130717, Val Acc: 0.701031\n",
      "Epoch 10977 - Train Loss: 0.113104, Train Acc: 0.820513 | Val Loss: 0.130712, Val Acc: 0.701031\n",
      "Epoch 10978 - Train Loss: 0.113098, Train Acc: 0.820513 | Val Loss: 0.130706, Val Acc: 0.701031\n",
      "Epoch 10979 - Train Loss: 0.113091, Train Acc: 0.820513 | Val Loss: 0.130701, Val Acc: 0.701031\n",
      "Epoch 10980 - Train Loss: 0.113085, Train Acc: 0.820513 | Val Loss: 0.130696, Val Acc: 0.701031\n",
      "Epoch 10981 - Train Loss: 0.113078, Train Acc: 0.820513 | Val Loss: 0.130690, Val Acc: 0.701031\n",
      "Epoch 10982 - Train Loss: 0.113071, Train Acc: 0.820513 | Val Loss: 0.130685, Val Acc: 0.701031\n",
      "Epoch 10983 - Train Loss: 0.113065, Train Acc: 0.820513 | Val Loss: 0.130679, Val Acc: 0.701031\n",
      "Epoch 10984 - Train Loss: 0.113058, Train Acc: 0.820513 | Val Loss: 0.130674, Val Acc: 0.701031\n",
      "Epoch 10985 - Train Loss: 0.113052, Train Acc: 0.820513 | Val Loss: 0.130669, Val Acc: 0.701031\n",
      "Epoch 10986 - Train Loss: 0.113045, Train Acc: 0.820513 | Val Loss: 0.130663, Val Acc: 0.701031\n",
      "Epoch 10987 - Train Loss: 0.113039, Train Acc: 0.820513 | Val Loss: 0.130658, Val Acc: 0.701031\n",
      "Epoch 10988 - Train Loss: 0.113032, Train Acc: 0.820513 | Val Loss: 0.130652, Val Acc: 0.701031\n",
      "Epoch 10989 - Train Loss: 0.113026, Train Acc: 0.821795 | Val Loss: 0.130647, Val Acc: 0.701031\n",
      "Epoch 10990 - Train Loss: 0.113019, Train Acc: 0.821795 | Val Loss: 0.130642, Val Acc: 0.701031\n",
      "Epoch 10991 - Train Loss: 0.113013, Train Acc: 0.821795 | Val Loss: 0.130636, Val Acc: 0.701031\n",
      "Epoch 10992 - Train Loss: 0.113006, Train Acc: 0.821795 | Val Loss: 0.130631, Val Acc: 0.701031\n",
      "Epoch 10993 - Train Loss: 0.113000, Train Acc: 0.821795 | Val Loss: 0.130625, Val Acc: 0.701031\n",
      "Epoch 10994 - Train Loss: 0.112993, Train Acc: 0.821795 | Val Loss: 0.130620, Val Acc: 0.701031\n",
      "Epoch 10995 - Train Loss: 0.112987, Train Acc: 0.821795 | Val Loss: 0.130615, Val Acc: 0.701031\n",
      "Epoch 10996 - Train Loss: 0.112980, Train Acc: 0.821795 | Val Loss: 0.130609, Val Acc: 0.701031\n",
      "Epoch 10997 - Train Loss: 0.112973, Train Acc: 0.821795 | Val Loss: 0.130604, Val Acc: 0.701031\n",
      "Epoch 10998 - Train Loss: 0.112967, Train Acc: 0.823077 | Val Loss: 0.130598, Val Acc: 0.701031\n",
      "Epoch 10999 - Train Loss: 0.112960, Train Acc: 0.823077 | Val Loss: 0.130593, Val Acc: 0.701031\n",
      "Epoch 11000 - Train Loss: 0.112954, Train Acc: 0.823077 | Val Loss: 0.130588, Val Acc: 0.701031\n",
      "Epoch 11001 - Train Loss: 0.112947, Train Acc: 0.823077 | Val Loss: 0.130582, Val Acc: 0.701031\n",
      "Epoch 11002 - Train Loss: 0.112941, Train Acc: 0.823077 | Val Loss: 0.130577, Val Acc: 0.701031\n",
      "Epoch 11003 - Train Loss: 0.112934, Train Acc: 0.823077 | Val Loss: 0.130572, Val Acc: 0.701031\n",
      "Epoch 11004 - Train Loss: 0.112928, Train Acc: 0.823077 | Val Loss: 0.130566, Val Acc: 0.701031\n",
      "Epoch 11005 - Train Loss: 0.112921, Train Acc: 0.823077 | Val Loss: 0.130561, Val Acc: 0.701031\n",
      "Epoch 11006 - Train Loss: 0.112915, Train Acc: 0.823077 | Val Loss: 0.130555, Val Acc: 0.701031\n",
      "Epoch 11007 - Train Loss: 0.112908, Train Acc: 0.823077 | Val Loss: 0.130550, Val Acc: 0.701031\n",
      "Epoch 11008 - Train Loss: 0.112902, Train Acc: 0.823077 | Val Loss: 0.130545, Val Acc: 0.701031\n",
      "Epoch 11009 - Train Loss: 0.112895, Train Acc: 0.823077 | Val Loss: 0.130539, Val Acc: 0.701031\n",
      "Epoch 11010 - Train Loss: 0.112889, Train Acc: 0.823077 | Val Loss: 0.130534, Val Acc: 0.701031\n",
      "Epoch 11011 - Train Loss: 0.112882, Train Acc: 0.823077 | Val Loss: 0.130528, Val Acc: 0.701031\n",
      "Epoch 11012 - Train Loss: 0.112876, Train Acc: 0.823077 | Val Loss: 0.130523, Val Acc: 0.701031\n",
      "Epoch 11013 - Train Loss: 0.112869, Train Acc: 0.823077 | Val Loss: 0.130518, Val Acc: 0.701031\n",
      "Epoch 11014 - Train Loss: 0.112863, Train Acc: 0.823077 | Val Loss: 0.130512, Val Acc: 0.701031\n",
      "Epoch 11015 - Train Loss: 0.112856, Train Acc: 0.823077 | Val Loss: 0.130507, Val Acc: 0.701031\n",
      "Epoch 11016 - Train Loss: 0.112850, Train Acc: 0.823077 | Val Loss: 0.130502, Val Acc: 0.701031\n",
      "Epoch 11017 - Train Loss: 0.112843, Train Acc: 0.823077 | Val Loss: 0.130496, Val Acc: 0.701031\n",
      "Epoch 11018 - Train Loss: 0.112837, Train Acc: 0.823077 | Val Loss: 0.130491, Val Acc: 0.701031\n",
      "Epoch 11019 - Train Loss: 0.112830, Train Acc: 0.823077 | Val Loss: 0.130485, Val Acc: 0.701031\n",
      "Epoch 11020 - Train Loss: 0.112824, Train Acc: 0.823077 | Val Loss: 0.130480, Val Acc: 0.701031\n",
      "Epoch 11021 - Train Loss: 0.112817, Train Acc: 0.823077 | Val Loss: 0.130475, Val Acc: 0.701031\n",
      "Epoch 11022 - Train Loss: 0.112811, Train Acc: 0.823077 | Val Loss: 0.130469, Val Acc: 0.701031\n",
      "Epoch 11023 - Train Loss: 0.112804, Train Acc: 0.823077 | Val Loss: 0.130464, Val Acc: 0.701031\n",
      "Epoch 11024 - Train Loss: 0.112798, Train Acc: 0.823077 | Val Loss: 0.130459, Val Acc: 0.701031\n",
      "Epoch 11025 - Train Loss: 0.112791, Train Acc: 0.823077 | Val Loss: 0.130453, Val Acc: 0.701031\n",
      "Epoch 11026 - Train Loss: 0.112785, Train Acc: 0.823077 | Val Loss: 0.130448, Val Acc: 0.701031\n",
      "Epoch 11027 - Train Loss: 0.112778, Train Acc: 0.823077 | Val Loss: 0.130442, Val Acc: 0.701031\n",
      "Epoch 11028 - Train Loss: 0.112772, Train Acc: 0.823077 | Val Loss: 0.130437, Val Acc: 0.701031\n",
      "Epoch 11029 - Train Loss: 0.112765, Train Acc: 0.823077 | Val Loss: 0.130432, Val Acc: 0.701031\n",
      "Epoch 11030 - Train Loss: 0.112759, Train Acc: 0.823077 | Val Loss: 0.130426, Val Acc: 0.701031\n",
      "Epoch 11031 - Train Loss: 0.112752, Train Acc: 0.823077 | Val Loss: 0.130421, Val Acc: 0.701031\n",
      "Epoch 11032 - Train Loss: 0.112746, Train Acc: 0.823077 | Val Loss: 0.130416, Val Acc: 0.701031\n",
      "Epoch 11033 - Train Loss: 0.112739, Train Acc: 0.823077 | Val Loss: 0.130410, Val Acc: 0.701031\n",
      "Epoch 11034 - Train Loss: 0.112733, Train Acc: 0.823077 | Val Loss: 0.130405, Val Acc: 0.701031\n",
      "Epoch 11035 - Train Loss: 0.112726, Train Acc: 0.823077 | Val Loss: 0.130400, Val Acc: 0.701031\n",
      "Epoch 11036 - Train Loss: 0.112720, Train Acc: 0.823077 | Val Loss: 0.130394, Val Acc: 0.701031\n",
      "Epoch 11037 - Train Loss: 0.112713, Train Acc: 0.823077 | Val Loss: 0.130389, Val Acc: 0.701031\n",
      "Epoch 11038 - Train Loss: 0.112707, Train Acc: 0.823077 | Val Loss: 0.130384, Val Acc: 0.701031\n",
      "Epoch 11039 - Train Loss: 0.112700, Train Acc: 0.823077 | Val Loss: 0.130378, Val Acc: 0.701031\n",
      "Epoch 11040 - Train Loss: 0.112694, Train Acc: 0.823077 | Val Loss: 0.130373, Val Acc: 0.701031\n",
      "Epoch 11041 - Train Loss: 0.112687, Train Acc: 0.823077 | Val Loss: 0.130367, Val Acc: 0.701031\n",
      "Epoch 11042 - Train Loss: 0.112681, Train Acc: 0.823077 | Val Loss: 0.130362, Val Acc: 0.701031\n",
      "Epoch 11043 - Train Loss: 0.112674, Train Acc: 0.823077 | Val Loss: 0.130357, Val Acc: 0.701031\n",
      "Epoch 11044 - Train Loss: 0.112668, Train Acc: 0.823077 | Val Loss: 0.130351, Val Acc: 0.701031\n",
      "Epoch 11045 - Train Loss: 0.112661, Train Acc: 0.823077 | Val Loss: 0.130346, Val Acc: 0.701031\n",
      "Epoch 11046 - Train Loss: 0.112655, Train Acc: 0.823077 | Val Loss: 0.130341, Val Acc: 0.701031\n",
      "Epoch 11047 - Train Loss: 0.112648, Train Acc: 0.823077 | Val Loss: 0.130335, Val Acc: 0.701031\n",
      "Epoch 11048 - Train Loss: 0.112642, Train Acc: 0.823077 | Val Loss: 0.130330, Val Acc: 0.701031\n",
      "Epoch 11049 - Train Loss: 0.112635, Train Acc: 0.823077 | Val Loss: 0.130325, Val Acc: 0.701031\n",
      "Epoch 11050 - Train Loss: 0.112629, Train Acc: 0.823077 | Val Loss: 0.130319, Val Acc: 0.701031\n",
      "Epoch 11051 - Train Loss: 0.112622, Train Acc: 0.823077 | Val Loss: 0.130314, Val Acc: 0.701031\n",
      "Epoch 11052 - Train Loss: 0.112616, Train Acc: 0.823077 | Val Loss: 0.130309, Val Acc: 0.701031\n",
      "Epoch 11053 - Train Loss: 0.112610, Train Acc: 0.823077 | Val Loss: 0.130303, Val Acc: 0.701031\n",
      "Epoch 11054 - Train Loss: 0.112603, Train Acc: 0.823077 | Val Loss: 0.130298, Val Acc: 0.701031\n",
      "Epoch 11055 - Train Loss: 0.112597, Train Acc: 0.823077 | Val Loss: 0.130293, Val Acc: 0.701031\n",
      "Epoch 11056 - Train Loss: 0.112590, Train Acc: 0.823077 | Val Loss: 0.130287, Val Acc: 0.701031\n",
      "Epoch 11057 - Train Loss: 0.112584, Train Acc: 0.823077 | Val Loss: 0.130282, Val Acc: 0.701031\n",
      "Epoch 11058 - Train Loss: 0.112577, Train Acc: 0.823077 | Val Loss: 0.130277, Val Acc: 0.701031\n",
      "Epoch 11059 - Train Loss: 0.112571, Train Acc: 0.823077 | Val Loss: 0.130271, Val Acc: 0.701031\n",
      "Epoch 11060 - Train Loss: 0.112564, Train Acc: 0.823077 | Val Loss: 0.130266, Val Acc: 0.701031\n",
      "Epoch 11061 - Train Loss: 0.112558, Train Acc: 0.823077 | Val Loss: 0.130261, Val Acc: 0.701031\n",
      "Epoch 11062 - Train Loss: 0.112551, Train Acc: 0.823077 | Val Loss: 0.130255, Val Acc: 0.701031\n",
      "Epoch 11063 - Train Loss: 0.112545, Train Acc: 0.823077 | Val Loss: 0.130250, Val Acc: 0.701031\n",
      "Epoch 11064 - Train Loss: 0.112538, Train Acc: 0.823077 | Val Loss: 0.130245, Val Acc: 0.701031\n",
      "Epoch 11065 - Train Loss: 0.112532, Train Acc: 0.823077 | Val Loss: 0.130239, Val Acc: 0.701031\n",
      "Epoch 11066 - Train Loss: 0.112525, Train Acc: 0.823077 | Val Loss: 0.130234, Val Acc: 0.701031\n",
      "Epoch 11067 - Train Loss: 0.112519, Train Acc: 0.823077 | Val Loss: 0.130229, Val Acc: 0.701031\n",
      "Epoch 11068 - Train Loss: 0.112513, Train Acc: 0.823077 | Val Loss: 0.130223, Val Acc: 0.701031\n",
      "Epoch 11069 - Train Loss: 0.112506, Train Acc: 0.823077 | Val Loss: 0.130218, Val Acc: 0.701031\n",
      "Epoch 11070 - Train Loss: 0.112500, Train Acc: 0.823077 | Val Loss: 0.130213, Val Acc: 0.701031\n",
      "Epoch 11071 - Train Loss: 0.112493, Train Acc: 0.823077 | Val Loss: 0.130207, Val Acc: 0.701031\n",
      "Epoch 11072 - Train Loss: 0.112487, Train Acc: 0.823077 | Val Loss: 0.130202, Val Acc: 0.701031\n",
      "Epoch 11073 - Train Loss: 0.112480, Train Acc: 0.823077 | Val Loss: 0.130197, Val Acc: 0.701031\n",
      "Epoch 11074 - Train Loss: 0.112474, Train Acc: 0.823077 | Val Loss: 0.130191, Val Acc: 0.701031\n",
      "Epoch 11075 - Train Loss: 0.112467, Train Acc: 0.823077 | Val Loss: 0.130186, Val Acc: 0.701031\n",
      "Epoch 11076 - Train Loss: 0.112461, Train Acc: 0.823077 | Val Loss: 0.130181, Val Acc: 0.701031\n",
      "Epoch 11077 - Train Loss: 0.112454, Train Acc: 0.823077 | Val Loss: 0.130175, Val Acc: 0.701031\n",
      "Epoch 11078 - Train Loss: 0.112448, Train Acc: 0.823077 | Val Loss: 0.130170, Val Acc: 0.701031\n",
      "Epoch 11079 - Train Loss: 0.112442, Train Acc: 0.823077 | Val Loss: 0.130165, Val Acc: 0.701031\n",
      "Epoch 11080 - Train Loss: 0.112435, Train Acc: 0.823077 | Val Loss: 0.130159, Val Acc: 0.701031\n",
      "Epoch 11081 - Train Loss: 0.112429, Train Acc: 0.823077 | Val Loss: 0.130154, Val Acc: 0.701031\n",
      "Epoch 11082 - Train Loss: 0.112422, Train Acc: 0.823077 | Val Loss: 0.130149, Val Acc: 0.701031\n",
      "Epoch 11083 - Train Loss: 0.112416, Train Acc: 0.823077 | Val Loss: 0.130144, Val Acc: 0.701031\n",
      "Epoch 11084 - Train Loss: 0.112409, Train Acc: 0.823077 | Val Loss: 0.130138, Val Acc: 0.701031\n",
      "Epoch 11085 - Train Loss: 0.112403, Train Acc: 0.823077 | Val Loss: 0.130133, Val Acc: 0.701031\n",
      "Epoch 11086 - Train Loss: 0.112396, Train Acc: 0.823077 | Val Loss: 0.130128, Val Acc: 0.701031\n",
      "Epoch 11087 - Train Loss: 0.112390, Train Acc: 0.823077 | Val Loss: 0.130122, Val Acc: 0.701031\n",
      "Epoch 11088 - Train Loss: 0.112384, Train Acc: 0.823077 | Val Loss: 0.130117, Val Acc: 0.701031\n",
      "Epoch 11089 - Train Loss: 0.112377, Train Acc: 0.823077 | Val Loss: 0.130112, Val Acc: 0.701031\n",
      "Epoch 11090 - Train Loss: 0.112371, Train Acc: 0.823077 | Val Loss: 0.130107, Val Acc: 0.701031\n",
      "Epoch 11091 - Train Loss: 0.112364, Train Acc: 0.823077 | Val Loss: 0.130101, Val Acc: 0.701031\n",
      "Epoch 11092 - Train Loss: 0.112358, Train Acc: 0.823077 | Val Loss: 0.130096, Val Acc: 0.701031\n",
      "Epoch 11093 - Train Loss: 0.112351, Train Acc: 0.823077 | Val Loss: 0.130091, Val Acc: 0.701031\n",
      "Epoch 11094 - Train Loss: 0.112345, Train Acc: 0.823077 | Val Loss: 0.130085, Val Acc: 0.701031\n",
      "Epoch 11095 - Train Loss: 0.112339, Train Acc: 0.823077 | Val Loss: 0.130080, Val Acc: 0.701031\n",
      "Epoch 11096 - Train Loss: 0.112332, Train Acc: 0.823077 | Val Loss: 0.130075, Val Acc: 0.701031\n",
      "Epoch 11097 - Train Loss: 0.112326, Train Acc: 0.823077 | Val Loss: 0.130070, Val Acc: 0.701031\n",
      "Epoch 11098 - Train Loss: 0.112319, Train Acc: 0.823077 | Val Loss: 0.130064, Val Acc: 0.701031\n",
      "Epoch 11099 - Train Loss: 0.112313, Train Acc: 0.823077 | Val Loss: 0.130059, Val Acc: 0.701031\n",
      "Epoch 11100 - Train Loss: 0.112306, Train Acc: 0.823077 | Val Loss: 0.130054, Val Acc: 0.701031\n",
      "Epoch 11101 - Train Loss: 0.112300, Train Acc: 0.823077 | Val Loss: 0.130048, Val Acc: 0.701031\n",
      "Epoch 11102 - Train Loss: 0.112294, Train Acc: 0.823077 | Val Loss: 0.130043, Val Acc: 0.701031\n",
      "Epoch 11103 - Train Loss: 0.112287, Train Acc: 0.823077 | Val Loss: 0.130038, Val Acc: 0.701031\n",
      "Epoch 11104 - Train Loss: 0.112281, Train Acc: 0.823077 | Val Loss: 0.130033, Val Acc: 0.701031\n",
      "Epoch 11105 - Train Loss: 0.112274, Train Acc: 0.823077 | Val Loss: 0.130027, Val Acc: 0.701031\n",
      "Epoch 11106 - Train Loss: 0.112268, Train Acc: 0.823077 | Val Loss: 0.130022, Val Acc: 0.701031\n",
      "Epoch 11107 - Train Loss: 0.112262, Train Acc: 0.823077 | Val Loss: 0.130017, Val Acc: 0.701031\n",
      "Epoch 11108 - Train Loss: 0.112255, Train Acc: 0.823077 | Val Loss: 0.130012, Val Acc: 0.701031\n",
      "Epoch 11109 - Train Loss: 0.112249, Train Acc: 0.823077 | Val Loss: 0.130006, Val Acc: 0.701031\n",
      "Epoch 11110 - Train Loss: 0.112242, Train Acc: 0.823077 | Val Loss: 0.130001, Val Acc: 0.701031\n",
      "Epoch 11111 - Train Loss: 0.112236, Train Acc: 0.823077 | Val Loss: 0.129996, Val Acc: 0.701031\n",
      "Epoch 11112 - Train Loss: 0.112229, Train Acc: 0.823077 | Val Loss: 0.129991, Val Acc: 0.701031\n",
      "Epoch 11113 - Train Loss: 0.112223, Train Acc: 0.823077 | Val Loss: 0.129985, Val Acc: 0.701031\n",
      "Epoch 11114 - Train Loss: 0.112217, Train Acc: 0.823077 | Val Loss: 0.129980, Val Acc: 0.701031\n",
      "Epoch 11115 - Train Loss: 0.112210, Train Acc: 0.823077 | Val Loss: 0.129975, Val Acc: 0.701031\n",
      "Epoch 11116 - Train Loss: 0.112204, Train Acc: 0.823077 | Val Loss: 0.129969, Val Acc: 0.701031\n",
      "Epoch 11117 - Train Loss: 0.112197, Train Acc: 0.823077 | Val Loss: 0.129964, Val Acc: 0.701031\n",
      "Epoch 11118 - Train Loss: 0.112191, Train Acc: 0.823077 | Val Loss: 0.129959, Val Acc: 0.701031\n",
      "Epoch 11119 - Train Loss: 0.112185, Train Acc: 0.823077 | Val Loss: 0.129954, Val Acc: 0.701031\n",
      "Epoch 11120 - Train Loss: 0.112178, Train Acc: 0.823077 | Val Loss: 0.129948, Val Acc: 0.701031\n",
      "Epoch 11121 - Train Loss: 0.112172, Train Acc: 0.823077 | Val Loss: 0.129943, Val Acc: 0.701031\n",
      "Epoch 11122 - Train Loss: 0.112165, Train Acc: 0.823077 | Val Loss: 0.129938, Val Acc: 0.701031\n",
      "Epoch 11123 - Train Loss: 0.112159, Train Acc: 0.823077 | Val Loss: 0.129933, Val Acc: 0.701031\n",
      "Epoch 11124 - Train Loss: 0.112153, Train Acc: 0.823077 | Val Loss: 0.129927, Val Acc: 0.701031\n",
      "Epoch 11125 - Train Loss: 0.112146, Train Acc: 0.823077 | Val Loss: 0.129922, Val Acc: 0.701031\n",
      "Epoch 11126 - Train Loss: 0.112140, Train Acc: 0.823077 | Val Loss: 0.129917, Val Acc: 0.701031\n",
      "Epoch 11127 - Train Loss: 0.112133, Train Acc: 0.823077 | Val Loss: 0.129912, Val Acc: 0.701031\n",
      "Epoch 11128 - Train Loss: 0.112127, Train Acc: 0.823077 | Val Loss: 0.129906, Val Acc: 0.701031\n",
      "Epoch 11129 - Train Loss: 0.112121, Train Acc: 0.823077 | Val Loss: 0.129901, Val Acc: 0.701031\n",
      "Epoch 11130 - Train Loss: 0.112114, Train Acc: 0.823077 | Val Loss: 0.129896, Val Acc: 0.701031\n",
      "Epoch 11131 - Train Loss: 0.112108, Train Acc: 0.823077 | Val Loss: 0.129891, Val Acc: 0.701031\n",
      "Epoch 11132 - Train Loss: 0.112101, Train Acc: 0.823077 | Val Loss: 0.129886, Val Acc: 0.701031\n",
      "Epoch 11133 - Train Loss: 0.112095, Train Acc: 0.823077 | Val Loss: 0.129880, Val Acc: 0.701031\n",
      "Epoch 11134 - Train Loss: 0.112089, Train Acc: 0.823077 | Val Loss: 0.129875, Val Acc: 0.701031\n",
      "Epoch 11135 - Train Loss: 0.112082, Train Acc: 0.823077 | Val Loss: 0.129870, Val Acc: 0.701031\n",
      "Epoch 11136 - Train Loss: 0.112076, Train Acc: 0.823077 | Val Loss: 0.129865, Val Acc: 0.701031\n",
      "Epoch 11137 - Train Loss: 0.112069, Train Acc: 0.823077 | Val Loss: 0.129859, Val Acc: 0.701031\n",
      "Epoch 11138 - Train Loss: 0.112063, Train Acc: 0.823077 | Val Loss: 0.129854, Val Acc: 0.701031\n",
      "Epoch 11139 - Train Loss: 0.112057, Train Acc: 0.823077 | Val Loss: 0.129849, Val Acc: 0.701031\n",
      "Epoch 11140 - Train Loss: 0.112050, Train Acc: 0.823077 | Val Loss: 0.129844, Val Acc: 0.701031\n",
      "Epoch 11141 - Train Loss: 0.112044, Train Acc: 0.823077 | Val Loss: 0.129838, Val Acc: 0.701031\n",
      "Epoch 11142 - Train Loss: 0.112038, Train Acc: 0.823077 | Val Loss: 0.129833, Val Acc: 0.701031\n",
      "Epoch 11143 - Train Loss: 0.112031, Train Acc: 0.823077 | Val Loss: 0.129828, Val Acc: 0.701031\n",
      "Epoch 11144 - Train Loss: 0.112025, Train Acc: 0.823077 | Val Loss: 0.129823, Val Acc: 0.701031\n",
      "Epoch 11145 - Train Loss: 0.112018, Train Acc: 0.823077 | Val Loss: 0.129818, Val Acc: 0.701031\n",
      "Epoch 11146 - Train Loss: 0.112012, Train Acc: 0.823077 | Val Loss: 0.129812, Val Acc: 0.701031\n",
      "Epoch 11147 - Train Loss: 0.112006, Train Acc: 0.823077 | Val Loss: 0.129807, Val Acc: 0.701031\n",
      "Epoch 11148 - Train Loss: 0.111999, Train Acc: 0.823077 | Val Loss: 0.129802, Val Acc: 0.701031\n",
      "Epoch 11149 - Train Loss: 0.111993, Train Acc: 0.823077 | Val Loss: 0.129797, Val Acc: 0.701031\n",
      "Epoch 11150 - Train Loss: 0.111987, Train Acc: 0.823077 | Val Loss: 0.129791, Val Acc: 0.701031\n",
      "Epoch 11151 - Train Loss: 0.111980, Train Acc: 0.823077 | Val Loss: 0.129786, Val Acc: 0.701031\n",
      "Epoch 11152 - Train Loss: 0.111974, Train Acc: 0.823077 | Val Loss: 0.129781, Val Acc: 0.701031\n",
      "Epoch 11153 - Train Loss: 0.111967, Train Acc: 0.823077 | Val Loss: 0.129776, Val Acc: 0.701031\n",
      "Epoch 11154 - Train Loss: 0.111961, Train Acc: 0.823077 | Val Loss: 0.129770, Val Acc: 0.701031\n",
      "Epoch 11155 - Train Loss: 0.111955, Train Acc: 0.823077 | Val Loss: 0.129765, Val Acc: 0.701031\n",
      "Epoch 11156 - Train Loss: 0.111948, Train Acc: 0.823077 | Val Loss: 0.129760, Val Acc: 0.701031\n",
      "Epoch 11157 - Train Loss: 0.111942, Train Acc: 0.823077 | Val Loss: 0.129755, Val Acc: 0.701031\n",
      "Epoch 11158 - Train Loss: 0.111935, Train Acc: 0.823077 | Val Loss: 0.129750, Val Acc: 0.701031\n",
      "Epoch 11159 - Train Loss: 0.111929, Train Acc: 0.823077 | Val Loss: 0.129744, Val Acc: 0.701031\n",
      "Epoch 11160 - Train Loss: 0.111923, Train Acc: 0.823077 | Val Loss: 0.129739, Val Acc: 0.701031\n",
      "Epoch 11161 - Train Loss: 0.111916, Train Acc: 0.823077 | Val Loss: 0.129734, Val Acc: 0.701031\n",
      "Epoch 11162 - Train Loss: 0.111910, Train Acc: 0.823077 | Val Loss: 0.129729, Val Acc: 0.701031\n",
      "Epoch 11163 - Train Loss: 0.111904, Train Acc: 0.823077 | Val Loss: 0.129723, Val Acc: 0.701031\n",
      "Epoch 11164 - Train Loss: 0.111897, Train Acc: 0.823077 | Val Loss: 0.129718, Val Acc: 0.701031\n",
      "Epoch 11165 - Train Loss: 0.111891, Train Acc: 0.823077 | Val Loss: 0.129713, Val Acc: 0.701031\n",
      "Epoch 11166 - Train Loss: 0.111885, Train Acc: 0.823077 | Val Loss: 0.129708, Val Acc: 0.701031\n",
      "Epoch 11167 - Train Loss: 0.111878, Train Acc: 0.823077 | Val Loss: 0.129703, Val Acc: 0.701031\n",
      "Epoch 11168 - Train Loss: 0.111872, Train Acc: 0.823077 | Val Loss: 0.129697, Val Acc: 0.701031\n",
      "Epoch 11169 - Train Loss: 0.111865, Train Acc: 0.823077 | Val Loss: 0.129692, Val Acc: 0.701031\n",
      "Epoch 11170 - Train Loss: 0.111859, Train Acc: 0.823077 | Val Loss: 0.129687, Val Acc: 0.701031\n",
      "Epoch 11171 - Train Loss: 0.111853, Train Acc: 0.823077 | Val Loss: 0.129682, Val Acc: 0.701031\n",
      "Epoch 11172 - Train Loss: 0.111846, Train Acc: 0.823077 | Val Loss: 0.129677, Val Acc: 0.701031\n",
      "Epoch 11173 - Train Loss: 0.111840, Train Acc: 0.823077 | Val Loss: 0.129671, Val Acc: 0.701031\n",
      "Epoch 11174 - Train Loss: 0.111834, Train Acc: 0.823077 | Val Loss: 0.129666, Val Acc: 0.701031\n",
      "Epoch 11175 - Train Loss: 0.111827, Train Acc: 0.823077 | Val Loss: 0.129661, Val Acc: 0.701031\n",
      "Epoch 11176 - Train Loss: 0.111821, Train Acc: 0.823077 | Val Loss: 0.129656, Val Acc: 0.701031\n",
      "Epoch 11177 - Train Loss: 0.111815, Train Acc: 0.823077 | Val Loss: 0.129651, Val Acc: 0.701031\n",
      "Epoch 11178 - Train Loss: 0.111808, Train Acc: 0.823077 | Val Loss: 0.129645, Val Acc: 0.701031\n",
      "Epoch 11179 - Train Loss: 0.111802, Train Acc: 0.823077 | Val Loss: 0.129640, Val Acc: 0.701031\n",
      "Epoch 11180 - Train Loss: 0.111795, Train Acc: 0.823077 | Val Loss: 0.129635, Val Acc: 0.701031\n",
      "Epoch 11181 - Train Loss: 0.111789, Train Acc: 0.823077 | Val Loss: 0.129630, Val Acc: 0.701031\n",
      "Epoch 11182 - Train Loss: 0.111783, Train Acc: 0.823077 | Val Loss: 0.129625, Val Acc: 0.701031\n",
      "Epoch 11183 - Train Loss: 0.111776, Train Acc: 0.823077 | Val Loss: 0.129619, Val Acc: 0.701031\n",
      "Epoch 11184 - Train Loss: 0.111770, Train Acc: 0.823077 | Val Loss: 0.129614, Val Acc: 0.701031\n",
      "Epoch 11185 - Train Loss: 0.111764, Train Acc: 0.823077 | Val Loss: 0.129609, Val Acc: 0.701031\n",
      "Epoch 11186 - Train Loss: 0.111757, Train Acc: 0.823077 | Val Loss: 0.129604, Val Acc: 0.701031\n",
      "Epoch 11187 - Train Loss: 0.111751, Train Acc: 0.823077 | Val Loss: 0.129599, Val Acc: 0.701031\n",
      "Epoch 11188 - Train Loss: 0.111745, Train Acc: 0.823077 | Val Loss: 0.129593, Val Acc: 0.701031\n",
      "Epoch 11189 - Train Loss: 0.111738, Train Acc: 0.823077 | Val Loss: 0.129588, Val Acc: 0.701031\n",
      "Epoch 11190 - Train Loss: 0.111732, Train Acc: 0.823077 | Val Loss: 0.129583, Val Acc: 0.701031\n",
      "Epoch 11191 - Train Loss: 0.111726, Train Acc: 0.824359 | Val Loss: 0.129578, Val Acc: 0.701031\n",
      "Epoch 11192 - Train Loss: 0.111719, Train Acc: 0.824359 | Val Loss: 0.129573, Val Acc: 0.701031\n",
      "Epoch 11193 - Train Loss: 0.111713, Train Acc: 0.824359 | Val Loss: 0.129568, Val Acc: 0.701031\n",
      "Epoch 11194 - Train Loss: 0.111707, Train Acc: 0.824359 | Val Loss: 0.129562, Val Acc: 0.701031\n",
      "Epoch 11195 - Train Loss: 0.111700, Train Acc: 0.824359 | Val Loss: 0.129557, Val Acc: 0.701031\n",
      "Epoch 11196 - Train Loss: 0.111694, Train Acc: 0.824359 | Val Loss: 0.129552, Val Acc: 0.701031\n",
      "Epoch 11197 - Train Loss: 0.111688, Train Acc: 0.824359 | Val Loss: 0.129547, Val Acc: 0.701031\n",
      "Epoch 11198 - Train Loss: 0.111681, Train Acc: 0.824359 | Val Loss: 0.129542, Val Acc: 0.701031\n",
      "Epoch 11199 - Train Loss: 0.111675, Train Acc: 0.824359 | Val Loss: 0.129536, Val Acc: 0.701031\n",
      "Epoch 11200 - Train Loss: 0.111669, Train Acc: 0.824359 | Val Loss: 0.129531, Val Acc: 0.701031\n",
      "Epoch 11201 - Train Loss: 0.111662, Train Acc: 0.824359 | Val Loss: 0.129526, Val Acc: 0.701031\n",
      "Epoch 11202 - Train Loss: 0.111656, Train Acc: 0.824359 | Val Loss: 0.129521, Val Acc: 0.701031\n",
      "Epoch 11203 - Train Loss: 0.111650, Train Acc: 0.824359 | Val Loss: 0.129516, Val Acc: 0.701031\n",
      "Epoch 11204 - Train Loss: 0.111643, Train Acc: 0.824359 | Val Loss: 0.129511, Val Acc: 0.701031\n",
      "Epoch 11205 - Train Loss: 0.111637, Train Acc: 0.824359 | Val Loss: 0.129505, Val Acc: 0.701031\n",
      "Epoch 11206 - Train Loss: 0.111631, Train Acc: 0.824359 | Val Loss: 0.129500, Val Acc: 0.701031\n",
      "Epoch 11207 - Train Loss: 0.111624, Train Acc: 0.824359 | Val Loss: 0.129495, Val Acc: 0.701031\n",
      "Epoch 11208 - Train Loss: 0.111618, Train Acc: 0.824359 | Val Loss: 0.129490, Val Acc: 0.701031\n",
      "Epoch 11209 - Train Loss: 0.111612, Train Acc: 0.824359 | Val Loss: 0.129485, Val Acc: 0.701031\n",
      "Epoch 11210 - Train Loss: 0.111605, Train Acc: 0.824359 | Val Loss: 0.129480, Val Acc: 0.701031\n",
      "Epoch 11211 - Train Loss: 0.111599, Train Acc: 0.824359 | Val Loss: 0.129474, Val Acc: 0.701031\n",
      "Epoch 11212 - Train Loss: 0.111593, Train Acc: 0.824359 | Val Loss: 0.129469, Val Acc: 0.701031\n",
      "Epoch 11213 - Train Loss: 0.111586, Train Acc: 0.824359 | Val Loss: 0.129464, Val Acc: 0.701031\n",
      "Epoch 11214 - Train Loss: 0.111580, Train Acc: 0.824359 | Val Loss: 0.129459, Val Acc: 0.701031\n",
      "Epoch 11215 - Train Loss: 0.111574, Train Acc: 0.824359 | Val Loss: 0.129454, Val Acc: 0.701031\n",
      "Epoch 11216 - Train Loss: 0.111567, Train Acc: 0.824359 | Val Loss: 0.129449, Val Acc: 0.701031\n",
      "Epoch 11217 - Train Loss: 0.111561, Train Acc: 0.824359 | Val Loss: 0.129443, Val Acc: 0.701031\n",
      "Epoch 11218 - Train Loss: 0.111555, Train Acc: 0.824359 | Val Loss: 0.129438, Val Acc: 0.701031\n",
      "Epoch 11219 - Train Loss: 0.111548, Train Acc: 0.824359 | Val Loss: 0.129433, Val Acc: 0.701031\n",
      "Epoch 11220 - Train Loss: 0.111542, Train Acc: 0.824359 | Val Loss: 0.129428, Val Acc: 0.701031\n",
      "Epoch 11221 - Train Loss: 0.111536, Train Acc: 0.824359 | Val Loss: 0.129423, Val Acc: 0.701031\n",
      "Epoch 11222 - Train Loss: 0.111529, Train Acc: 0.824359 | Val Loss: 0.129418, Val Acc: 0.701031\n",
      "Epoch 11223 - Train Loss: 0.111523, Train Acc: 0.824359 | Val Loss: 0.129413, Val Acc: 0.701031\n",
      "Epoch 11224 - Train Loss: 0.111517, Train Acc: 0.824359 | Val Loss: 0.129407, Val Acc: 0.701031\n",
      "Epoch 11225 - Train Loss: 0.111511, Train Acc: 0.824359 | Val Loss: 0.129402, Val Acc: 0.701031\n",
      "Epoch 11226 - Train Loss: 0.111504, Train Acc: 0.824359 | Val Loss: 0.129397, Val Acc: 0.701031\n",
      "Epoch 11227 - Train Loss: 0.111498, Train Acc: 0.824359 | Val Loss: 0.129392, Val Acc: 0.701031\n",
      "Epoch 11228 - Train Loss: 0.111492, Train Acc: 0.824359 | Val Loss: 0.129387, Val Acc: 0.701031\n",
      "Epoch 11229 - Train Loss: 0.111485, Train Acc: 0.824359 | Val Loss: 0.129382, Val Acc: 0.701031\n",
      "Epoch 11230 - Train Loss: 0.111479, Train Acc: 0.824359 | Val Loss: 0.129376, Val Acc: 0.701031\n",
      "Epoch 11231 - Train Loss: 0.111473, Train Acc: 0.824359 | Val Loss: 0.129371, Val Acc: 0.701031\n",
      "Epoch 11232 - Train Loss: 0.111466, Train Acc: 0.824359 | Val Loss: 0.129366, Val Acc: 0.701031\n",
      "Epoch 11233 - Train Loss: 0.111460, Train Acc: 0.824359 | Val Loss: 0.129361, Val Acc: 0.701031\n",
      "Epoch 11234 - Train Loss: 0.111454, Train Acc: 0.824359 | Val Loss: 0.129356, Val Acc: 0.701031\n",
      "Epoch 11235 - Train Loss: 0.111447, Train Acc: 0.824359 | Val Loss: 0.129351, Val Acc: 0.701031\n",
      "Epoch 11236 - Train Loss: 0.111441, Train Acc: 0.824359 | Val Loss: 0.129346, Val Acc: 0.701031\n",
      "Epoch 11237 - Train Loss: 0.111435, Train Acc: 0.824359 | Val Loss: 0.129340, Val Acc: 0.701031\n",
      "Epoch 11238 - Train Loss: 0.111428, Train Acc: 0.824359 | Val Loss: 0.129335, Val Acc: 0.701031\n",
      "Epoch 11239 - Train Loss: 0.111422, Train Acc: 0.824359 | Val Loss: 0.129330, Val Acc: 0.701031\n",
      "Epoch 11240 - Train Loss: 0.111416, Train Acc: 0.824359 | Val Loss: 0.129325, Val Acc: 0.701031\n",
      "Epoch 11241 - Train Loss: 0.111410, Train Acc: 0.824359 | Val Loss: 0.129320, Val Acc: 0.701031\n",
      "Epoch 11242 - Train Loss: 0.111403, Train Acc: 0.824359 | Val Loss: 0.129315, Val Acc: 0.701031\n",
      "Epoch 11243 - Train Loss: 0.111397, Train Acc: 0.824359 | Val Loss: 0.129310, Val Acc: 0.701031\n",
      "Epoch 11244 - Train Loss: 0.111391, Train Acc: 0.824359 | Val Loss: 0.129304, Val Acc: 0.701031\n",
      "Epoch 11245 - Train Loss: 0.111384, Train Acc: 0.824359 | Val Loss: 0.129299, Val Acc: 0.701031\n",
      "Epoch 11246 - Train Loss: 0.111378, Train Acc: 0.824359 | Val Loss: 0.129294, Val Acc: 0.701031\n",
      "Epoch 11247 - Train Loss: 0.111372, Train Acc: 0.824359 | Val Loss: 0.129289, Val Acc: 0.701031\n",
      "Epoch 11248 - Train Loss: 0.111366, Train Acc: 0.824359 | Val Loss: 0.129284, Val Acc: 0.701031\n",
      "Epoch 11249 - Train Loss: 0.111359, Train Acc: 0.824359 | Val Loss: 0.129279, Val Acc: 0.701031\n",
      "Epoch 11250 - Train Loss: 0.111353, Train Acc: 0.824359 | Val Loss: 0.129274, Val Acc: 0.701031\n",
      "Epoch 11251 - Train Loss: 0.111347, Train Acc: 0.824359 | Val Loss: 0.129269, Val Acc: 0.701031\n",
      "Epoch 11252 - Train Loss: 0.111340, Train Acc: 0.824359 | Val Loss: 0.129264, Val Acc: 0.701031\n",
      "Epoch 11253 - Train Loss: 0.111334, Train Acc: 0.824359 | Val Loss: 0.129258, Val Acc: 0.701031\n",
      "Epoch 11254 - Train Loss: 0.111328, Train Acc: 0.824359 | Val Loss: 0.129253, Val Acc: 0.701031\n",
      "Epoch 11255 - Train Loss: 0.111322, Train Acc: 0.824359 | Val Loss: 0.129248, Val Acc: 0.701031\n",
      "Epoch 11256 - Train Loss: 0.111315, Train Acc: 0.824359 | Val Loss: 0.129243, Val Acc: 0.701031\n",
      "Epoch 11257 - Train Loss: 0.111309, Train Acc: 0.824359 | Val Loss: 0.129238, Val Acc: 0.701031\n",
      "Epoch 11258 - Train Loss: 0.111303, Train Acc: 0.824359 | Val Loss: 0.129233, Val Acc: 0.701031\n",
      "Epoch 11259 - Train Loss: 0.111296, Train Acc: 0.824359 | Val Loss: 0.129228, Val Acc: 0.701031\n",
      "Epoch 11260 - Train Loss: 0.111290, Train Acc: 0.824359 | Val Loss: 0.129223, Val Acc: 0.701031\n",
      "Epoch 11261 - Train Loss: 0.111284, Train Acc: 0.824359 | Val Loss: 0.129218, Val Acc: 0.701031\n",
      "Epoch 11262 - Train Loss: 0.111278, Train Acc: 0.824359 | Val Loss: 0.129213, Val Acc: 0.701031\n",
      "Epoch 11263 - Train Loss: 0.111271, Train Acc: 0.824359 | Val Loss: 0.129207, Val Acc: 0.701031\n",
      "Epoch 11264 - Train Loss: 0.111265, Train Acc: 0.824359 | Val Loss: 0.129202, Val Acc: 0.701031\n",
      "Epoch 11265 - Train Loss: 0.111259, Train Acc: 0.824359 | Val Loss: 0.129197, Val Acc: 0.701031\n",
      "Epoch 11266 - Train Loss: 0.111253, Train Acc: 0.824359 | Val Loss: 0.129192, Val Acc: 0.701031\n",
      "Epoch 11267 - Train Loss: 0.111246, Train Acc: 0.824359 | Val Loss: 0.129187, Val Acc: 0.701031\n",
      "Epoch 11268 - Train Loss: 0.111240, Train Acc: 0.824359 | Val Loss: 0.129182, Val Acc: 0.701031\n",
      "Epoch 11269 - Train Loss: 0.111234, Train Acc: 0.824359 | Val Loss: 0.129177, Val Acc: 0.701031\n",
      "Epoch 11270 - Train Loss: 0.111227, Train Acc: 0.824359 | Val Loss: 0.129172, Val Acc: 0.701031\n",
      "Epoch 11271 - Train Loss: 0.111221, Train Acc: 0.824359 | Val Loss: 0.129167, Val Acc: 0.701031\n",
      "Epoch 11272 - Train Loss: 0.111215, Train Acc: 0.824359 | Val Loss: 0.129162, Val Acc: 0.701031\n",
      "Epoch 11273 - Train Loss: 0.111209, Train Acc: 0.824359 | Val Loss: 0.129156, Val Acc: 0.701031\n",
      "Epoch 11274 - Train Loss: 0.111202, Train Acc: 0.824359 | Val Loss: 0.129151, Val Acc: 0.701031\n",
      "Epoch 11275 - Train Loss: 0.111196, Train Acc: 0.824359 | Val Loss: 0.129146, Val Acc: 0.701031\n",
      "Epoch 11276 - Train Loss: 0.111190, Train Acc: 0.824359 | Val Loss: 0.129141, Val Acc: 0.701031\n",
      "Epoch 11277 - Train Loss: 0.111184, Train Acc: 0.824359 | Val Loss: 0.129136, Val Acc: 0.701031\n",
      "Epoch 11278 - Train Loss: 0.111177, Train Acc: 0.824359 | Val Loss: 0.129131, Val Acc: 0.701031\n",
      "Epoch 11279 - Train Loss: 0.111171, Train Acc: 0.824359 | Val Loss: 0.129126, Val Acc: 0.701031\n",
      "Epoch 11280 - Train Loss: 0.111165, Train Acc: 0.824359 | Val Loss: 0.129121, Val Acc: 0.701031\n",
      "Epoch 11281 - Train Loss: 0.111159, Train Acc: 0.824359 | Val Loss: 0.129116, Val Acc: 0.701031\n",
      "Epoch 11282 - Train Loss: 0.111152, Train Acc: 0.824359 | Val Loss: 0.129111, Val Acc: 0.701031\n",
      "Epoch 11283 - Train Loss: 0.111146, Train Acc: 0.824359 | Val Loss: 0.129106, Val Acc: 0.701031\n",
      "Epoch 11284 - Train Loss: 0.111140, Train Acc: 0.824359 | Val Loss: 0.129101, Val Acc: 0.701031\n",
      "Epoch 11285 - Train Loss: 0.111134, Train Acc: 0.824359 | Val Loss: 0.129095, Val Acc: 0.701031\n",
      "Epoch 11286 - Train Loss: 0.111127, Train Acc: 0.824359 | Val Loss: 0.129090, Val Acc: 0.701031\n",
      "Epoch 11287 - Train Loss: 0.111121, Train Acc: 0.824359 | Val Loss: 0.129085, Val Acc: 0.701031\n",
      "Epoch 11288 - Train Loss: 0.111115, Train Acc: 0.824359 | Val Loss: 0.129080, Val Acc: 0.701031\n",
      "Epoch 11289 - Train Loss: 0.111109, Train Acc: 0.824359 | Val Loss: 0.129075, Val Acc: 0.701031\n",
      "Epoch 11290 - Train Loss: 0.111102, Train Acc: 0.824359 | Val Loss: 0.129070, Val Acc: 0.701031\n",
      "Epoch 11291 - Train Loss: 0.111096, Train Acc: 0.824359 | Val Loss: 0.129065, Val Acc: 0.701031\n",
      "Epoch 11292 - Train Loss: 0.111090, Train Acc: 0.824359 | Val Loss: 0.129060, Val Acc: 0.701031\n",
      "Epoch 11293 - Train Loss: 0.111084, Train Acc: 0.824359 | Val Loss: 0.129055, Val Acc: 0.701031\n",
      "Epoch 11294 - Train Loss: 0.111077, Train Acc: 0.824359 | Val Loss: 0.129050, Val Acc: 0.701031\n",
      "Epoch 11295 - Train Loss: 0.111071, Train Acc: 0.824359 | Val Loss: 0.129045, Val Acc: 0.701031\n",
      "Epoch 11296 - Train Loss: 0.111065, Train Acc: 0.824359 | Val Loss: 0.129040, Val Acc: 0.701031\n",
      "Epoch 11297 - Train Loss: 0.111059, Train Acc: 0.824359 | Val Loss: 0.129035, Val Acc: 0.701031\n",
      "Epoch 11298 - Train Loss: 0.111052, Train Acc: 0.824359 | Val Loss: 0.129030, Val Acc: 0.701031\n",
      "Epoch 11299 - Train Loss: 0.111046, Train Acc: 0.823077 | Val Loss: 0.129025, Val Acc: 0.701031\n",
      "Epoch 11300 - Train Loss: 0.111040, Train Acc: 0.823077 | Val Loss: 0.129019, Val Acc: 0.701031\n",
      "Epoch 11301 - Train Loss: 0.111034, Train Acc: 0.823077 | Val Loss: 0.129014, Val Acc: 0.701031\n",
      "Epoch 11302 - Train Loss: 0.111027, Train Acc: 0.823077 | Val Loss: 0.129009, Val Acc: 0.701031\n",
      "Epoch 11303 - Train Loss: 0.111021, Train Acc: 0.823077 | Val Loss: 0.129004, Val Acc: 0.701031\n",
      "Epoch 11304 - Train Loss: 0.111015, Train Acc: 0.823077 | Val Loss: 0.128999, Val Acc: 0.701031\n",
      "Epoch 11305 - Train Loss: 0.111009, Train Acc: 0.823077 | Val Loss: 0.128994, Val Acc: 0.701031\n",
      "Epoch 11306 - Train Loss: 0.111003, Train Acc: 0.823077 | Val Loss: 0.128989, Val Acc: 0.701031\n",
      "Epoch 11307 - Train Loss: 0.110996, Train Acc: 0.823077 | Val Loss: 0.128984, Val Acc: 0.701031\n",
      "Epoch 11308 - Train Loss: 0.110990, Train Acc: 0.823077 | Val Loss: 0.128979, Val Acc: 0.701031\n",
      "Epoch 11309 - Train Loss: 0.110984, Train Acc: 0.823077 | Val Loss: 0.128974, Val Acc: 0.701031\n",
      "Epoch 11310 - Train Loss: 0.110978, Train Acc: 0.823077 | Val Loss: 0.128969, Val Acc: 0.701031\n",
      "Epoch 11311 - Train Loss: 0.110971, Train Acc: 0.823077 | Val Loss: 0.128964, Val Acc: 0.701031\n",
      "Epoch 11312 - Train Loss: 0.110965, Train Acc: 0.823077 | Val Loss: 0.128959, Val Acc: 0.701031\n",
      "Epoch 11313 - Train Loss: 0.110959, Train Acc: 0.823077 | Val Loss: 0.128954, Val Acc: 0.701031\n",
      "Epoch 11314 - Train Loss: 0.110953, Train Acc: 0.823077 | Val Loss: 0.128949, Val Acc: 0.701031\n",
      "Epoch 11315 - Train Loss: 0.110946, Train Acc: 0.823077 | Val Loss: 0.128944, Val Acc: 0.701031\n",
      "Epoch 11316 - Train Loss: 0.110940, Train Acc: 0.823077 | Val Loss: 0.128939, Val Acc: 0.701031\n",
      "Epoch 11317 - Train Loss: 0.110934, Train Acc: 0.823077 | Val Loss: 0.128934, Val Acc: 0.701031\n",
      "Epoch 11318 - Train Loss: 0.110928, Train Acc: 0.823077 | Val Loss: 0.128929, Val Acc: 0.701031\n",
      "Epoch 11319 - Train Loss: 0.110922, Train Acc: 0.823077 | Val Loss: 0.128923, Val Acc: 0.701031\n",
      "Epoch 11320 - Train Loss: 0.110915, Train Acc: 0.823077 | Val Loss: 0.128918, Val Acc: 0.701031\n",
      "Epoch 11321 - Train Loss: 0.110909, Train Acc: 0.823077 | Val Loss: 0.128913, Val Acc: 0.701031\n",
      "Epoch 11322 - Train Loss: 0.110903, Train Acc: 0.823077 | Val Loss: 0.128908, Val Acc: 0.701031\n",
      "Epoch 11323 - Train Loss: 0.110897, Train Acc: 0.823077 | Val Loss: 0.128903, Val Acc: 0.701031\n",
      "Epoch 11324 - Train Loss: 0.110890, Train Acc: 0.823077 | Val Loss: 0.128898, Val Acc: 0.701031\n",
      "Epoch 11325 - Train Loss: 0.110884, Train Acc: 0.823077 | Val Loss: 0.128893, Val Acc: 0.701031\n",
      "Epoch 11326 - Train Loss: 0.110878, Train Acc: 0.823077 | Val Loss: 0.128888, Val Acc: 0.701031\n",
      "Epoch 11327 - Train Loss: 0.110872, Train Acc: 0.823077 | Val Loss: 0.128883, Val Acc: 0.701031\n",
      "Epoch 11328 - Train Loss: 0.110866, Train Acc: 0.823077 | Val Loss: 0.128878, Val Acc: 0.701031\n",
      "Epoch 11329 - Train Loss: 0.110859, Train Acc: 0.823077 | Val Loss: 0.128873, Val Acc: 0.701031\n",
      "Epoch 11330 - Train Loss: 0.110853, Train Acc: 0.823077 | Val Loss: 0.128868, Val Acc: 0.701031\n",
      "Epoch 11331 - Train Loss: 0.110847, Train Acc: 0.823077 | Val Loss: 0.128863, Val Acc: 0.701031\n",
      "Epoch 11332 - Train Loss: 0.110841, Train Acc: 0.823077 | Val Loss: 0.128858, Val Acc: 0.701031\n",
      "Epoch 11333 - Train Loss: 0.110835, Train Acc: 0.823077 | Val Loss: 0.128853, Val Acc: 0.701031\n",
      "Epoch 11334 - Train Loss: 0.110828, Train Acc: 0.823077 | Val Loss: 0.128848, Val Acc: 0.701031\n",
      "Epoch 11335 - Train Loss: 0.110822, Train Acc: 0.823077 | Val Loss: 0.128843, Val Acc: 0.701031\n",
      "Epoch 11336 - Train Loss: 0.110816, Train Acc: 0.823077 | Val Loss: 0.128838, Val Acc: 0.701031\n",
      "Epoch 11337 - Train Loss: 0.110810, Train Acc: 0.823077 | Val Loss: 0.128833, Val Acc: 0.701031\n",
      "Epoch 11338 - Train Loss: 0.110804, Train Acc: 0.823077 | Val Loss: 0.128828, Val Acc: 0.701031\n",
      "Epoch 11339 - Train Loss: 0.110797, Train Acc: 0.823077 | Val Loss: 0.128823, Val Acc: 0.701031\n",
      "Epoch 11340 - Train Loss: 0.110791, Train Acc: 0.823077 | Val Loss: 0.128818, Val Acc: 0.701031\n",
      "Epoch 11341 - Train Loss: 0.110785, Train Acc: 0.823077 | Val Loss: 0.128813, Val Acc: 0.701031\n",
      "Epoch 11342 - Train Loss: 0.110779, Train Acc: 0.823077 | Val Loss: 0.128808, Val Acc: 0.701031\n",
      "Epoch 11343 - Train Loss: 0.110773, Train Acc: 0.823077 | Val Loss: 0.128803, Val Acc: 0.701031\n",
      "Epoch 11344 - Train Loss: 0.110766, Train Acc: 0.823077 | Val Loss: 0.128798, Val Acc: 0.701031\n",
      "Epoch 11345 - Train Loss: 0.110760, Train Acc: 0.823077 | Val Loss: 0.128793, Val Acc: 0.701031\n",
      "Epoch 11346 - Train Loss: 0.110754, Train Acc: 0.823077 | Val Loss: 0.128788, Val Acc: 0.701031\n",
      "Epoch 11347 - Train Loss: 0.110748, Train Acc: 0.823077 | Val Loss: 0.128783, Val Acc: 0.701031\n",
      "Epoch 11348 - Train Loss: 0.110742, Train Acc: 0.823077 | Val Loss: 0.128778, Val Acc: 0.701031\n",
      "Epoch 11349 - Train Loss: 0.110735, Train Acc: 0.823077 | Val Loss: 0.128773, Val Acc: 0.701031\n",
      "Epoch 11350 - Train Loss: 0.110729, Train Acc: 0.823077 | Val Loss: 0.128768, Val Acc: 0.701031\n",
      "Epoch 11351 - Train Loss: 0.110723, Train Acc: 0.823077 | Val Loss: 0.128763, Val Acc: 0.701031\n",
      "Epoch 11352 - Train Loss: 0.110717, Train Acc: 0.823077 | Val Loss: 0.128758, Val Acc: 0.701031\n",
      "Epoch 11353 - Train Loss: 0.110711, Train Acc: 0.823077 | Val Loss: 0.128753, Val Acc: 0.701031\n",
      "Epoch 11354 - Train Loss: 0.110704, Train Acc: 0.823077 | Val Loss: 0.128748, Val Acc: 0.701031\n",
      "Epoch 11355 - Train Loss: 0.110698, Train Acc: 0.823077 | Val Loss: 0.128743, Val Acc: 0.701031\n",
      "Epoch 11356 - Train Loss: 0.110692, Train Acc: 0.823077 | Val Loss: 0.128738, Val Acc: 0.701031\n",
      "Epoch 11357 - Train Loss: 0.110686, Train Acc: 0.823077 | Val Loss: 0.128733, Val Acc: 0.701031\n",
      "Epoch 11358 - Train Loss: 0.110680, Train Acc: 0.823077 | Val Loss: 0.128728, Val Acc: 0.701031\n",
      "Epoch 11359 - Train Loss: 0.110673, Train Acc: 0.823077 | Val Loss: 0.128723, Val Acc: 0.701031\n",
      "Epoch 11360 - Train Loss: 0.110667, Train Acc: 0.823077 | Val Loss: 0.128718, Val Acc: 0.701031\n",
      "Epoch 11361 - Train Loss: 0.110661, Train Acc: 0.823077 | Val Loss: 0.128713, Val Acc: 0.701031\n",
      "Epoch 11362 - Train Loss: 0.110655, Train Acc: 0.823077 | Val Loss: 0.128708, Val Acc: 0.701031\n",
      "Epoch 11363 - Train Loss: 0.110649, Train Acc: 0.823077 | Val Loss: 0.128703, Val Acc: 0.701031\n",
      "Epoch 11364 - Train Loss: 0.110643, Train Acc: 0.823077 | Val Loss: 0.128698, Val Acc: 0.701031\n",
      "Epoch 11365 - Train Loss: 0.110636, Train Acc: 0.823077 | Val Loss: 0.128693, Val Acc: 0.701031\n",
      "Epoch 11366 - Train Loss: 0.110630, Train Acc: 0.823077 | Val Loss: 0.128688, Val Acc: 0.701031\n",
      "Epoch 11367 - Train Loss: 0.110624, Train Acc: 0.823077 | Val Loss: 0.128683, Val Acc: 0.701031\n",
      "Epoch 11368 - Train Loss: 0.110618, Train Acc: 0.823077 | Val Loss: 0.128678, Val Acc: 0.701031\n",
      "Epoch 11369 - Train Loss: 0.110612, Train Acc: 0.823077 | Val Loss: 0.128673, Val Acc: 0.701031\n",
      "Epoch 11370 - Train Loss: 0.110605, Train Acc: 0.823077 | Val Loss: 0.128668, Val Acc: 0.701031\n",
      "Epoch 11371 - Train Loss: 0.110599, Train Acc: 0.823077 | Val Loss: 0.128663, Val Acc: 0.701031\n",
      "Epoch 11372 - Train Loss: 0.110593, Train Acc: 0.823077 | Val Loss: 0.128658, Val Acc: 0.701031\n",
      "Epoch 11373 - Train Loss: 0.110587, Train Acc: 0.823077 | Val Loss: 0.128653, Val Acc: 0.701031\n",
      "Epoch 11374 - Train Loss: 0.110581, Train Acc: 0.823077 | Val Loss: 0.128648, Val Acc: 0.701031\n",
      "Epoch 11375 - Train Loss: 0.110575, Train Acc: 0.823077 | Val Loss: 0.128643, Val Acc: 0.701031\n",
      "Epoch 11376 - Train Loss: 0.110568, Train Acc: 0.823077 | Val Loss: 0.128638, Val Acc: 0.701031\n",
      "Epoch 11377 - Train Loss: 0.110562, Train Acc: 0.823077 | Val Loss: 0.128633, Val Acc: 0.701031\n",
      "Epoch 11378 - Train Loss: 0.110556, Train Acc: 0.823077 | Val Loss: 0.128628, Val Acc: 0.701031\n",
      "Epoch 11379 - Train Loss: 0.110550, Train Acc: 0.823077 | Val Loss: 0.128623, Val Acc: 0.701031\n",
      "Epoch 11380 - Train Loss: 0.110544, Train Acc: 0.823077 | Val Loss: 0.128618, Val Acc: 0.701031\n",
      "Epoch 11381 - Train Loss: 0.110538, Train Acc: 0.823077 | Val Loss: 0.128613, Val Acc: 0.701031\n",
      "Epoch 11382 - Train Loss: 0.110531, Train Acc: 0.823077 | Val Loss: 0.128608, Val Acc: 0.701031\n",
      "Epoch 11383 - Train Loss: 0.110525, Train Acc: 0.823077 | Val Loss: 0.128603, Val Acc: 0.701031\n",
      "Epoch 11384 - Train Loss: 0.110519, Train Acc: 0.823077 | Val Loss: 0.128598, Val Acc: 0.701031\n",
      "Epoch 11385 - Train Loss: 0.110513, Train Acc: 0.823077 | Val Loss: 0.128593, Val Acc: 0.701031\n",
      "Epoch 11386 - Train Loss: 0.110507, Train Acc: 0.823077 | Val Loss: 0.128588, Val Acc: 0.701031\n",
      "Epoch 11387 - Train Loss: 0.110501, Train Acc: 0.823077 | Val Loss: 0.128583, Val Acc: 0.701031\n",
      "Epoch 11388 - Train Loss: 0.110494, Train Acc: 0.823077 | Val Loss: 0.128578, Val Acc: 0.701031\n",
      "Epoch 11389 - Train Loss: 0.110488, Train Acc: 0.823077 | Val Loss: 0.128573, Val Acc: 0.701031\n",
      "Epoch 11390 - Train Loss: 0.110482, Train Acc: 0.823077 | Val Loss: 0.128568, Val Acc: 0.701031\n",
      "Epoch 11391 - Train Loss: 0.110476, Train Acc: 0.823077 | Val Loss: 0.128563, Val Acc: 0.701031\n",
      "Epoch 11392 - Train Loss: 0.110470, Train Acc: 0.823077 | Val Loss: 0.128558, Val Acc: 0.701031\n",
      "Epoch 11393 - Train Loss: 0.110464, Train Acc: 0.823077 | Val Loss: 0.128553, Val Acc: 0.701031\n",
      "Epoch 11394 - Train Loss: 0.110458, Train Acc: 0.823077 | Val Loss: 0.128548, Val Acc: 0.701031\n",
      "Epoch 11395 - Train Loss: 0.110451, Train Acc: 0.823077 | Val Loss: 0.128543, Val Acc: 0.701031\n",
      "Epoch 11396 - Train Loss: 0.110445, Train Acc: 0.823077 | Val Loss: 0.128538, Val Acc: 0.701031\n",
      "Epoch 11397 - Train Loss: 0.110439, Train Acc: 0.823077 | Val Loss: 0.128533, Val Acc: 0.701031\n",
      "Epoch 11398 - Train Loss: 0.110433, Train Acc: 0.823077 | Val Loss: 0.128528, Val Acc: 0.701031\n",
      "Epoch 11399 - Train Loss: 0.110427, Train Acc: 0.823077 | Val Loss: 0.128523, Val Acc: 0.701031\n",
      "Epoch 11400 - Train Loss: 0.110421, Train Acc: 0.823077 | Val Loss: 0.128518, Val Acc: 0.701031\n",
      "Epoch 11401 - Train Loss: 0.110414, Train Acc: 0.823077 | Val Loss: 0.128513, Val Acc: 0.701031\n",
      "Epoch 11402 - Train Loss: 0.110408, Train Acc: 0.823077 | Val Loss: 0.128508, Val Acc: 0.701031\n",
      "Epoch 11403 - Train Loss: 0.110402, Train Acc: 0.823077 | Val Loss: 0.128503, Val Acc: 0.701031\n",
      "Epoch 11404 - Train Loss: 0.110396, Train Acc: 0.823077 | Val Loss: 0.128498, Val Acc: 0.701031\n",
      "Epoch 11405 - Train Loss: 0.110390, Train Acc: 0.823077 | Val Loss: 0.128494, Val Acc: 0.701031\n",
      "Epoch 11406 - Train Loss: 0.110384, Train Acc: 0.823077 | Val Loss: 0.128489, Val Acc: 0.701031\n",
      "Epoch 11407 - Train Loss: 0.110378, Train Acc: 0.823077 | Val Loss: 0.128484, Val Acc: 0.701031\n",
      "Epoch 11408 - Train Loss: 0.110371, Train Acc: 0.823077 | Val Loss: 0.128479, Val Acc: 0.701031\n",
      "Epoch 11409 - Train Loss: 0.110365, Train Acc: 0.823077 | Val Loss: 0.128474, Val Acc: 0.701031\n",
      "Epoch 11410 - Train Loss: 0.110359, Train Acc: 0.823077 | Val Loss: 0.128469, Val Acc: 0.701031\n",
      "Epoch 11411 - Train Loss: 0.110353, Train Acc: 0.823077 | Val Loss: 0.128464, Val Acc: 0.701031\n",
      "Epoch 11412 - Train Loss: 0.110347, Train Acc: 0.823077 | Val Loss: 0.128459, Val Acc: 0.701031\n",
      "Epoch 11413 - Train Loss: 0.110341, Train Acc: 0.823077 | Val Loss: 0.128454, Val Acc: 0.701031\n",
      "Epoch 11414 - Train Loss: 0.110335, Train Acc: 0.823077 | Val Loss: 0.128449, Val Acc: 0.701031\n",
      "Epoch 11415 - Train Loss: 0.110329, Train Acc: 0.823077 | Val Loss: 0.128444, Val Acc: 0.701031\n",
      "Epoch 11416 - Train Loss: 0.110322, Train Acc: 0.823077 | Val Loss: 0.128439, Val Acc: 0.701031\n",
      "Epoch 11417 - Train Loss: 0.110316, Train Acc: 0.823077 | Val Loss: 0.128434, Val Acc: 0.701031\n",
      "Epoch 11418 - Train Loss: 0.110310, Train Acc: 0.824359 | Val Loss: 0.128429, Val Acc: 0.701031\n",
      "Epoch 11419 - Train Loss: 0.110304, Train Acc: 0.824359 | Val Loss: 0.128424, Val Acc: 0.701031\n",
      "Epoch 11420 - Train Loss: 0.110298, Train Acc: 0.824359 | Val Loss: 0.128419, Val Acc: 0.701031\n",
      "Epoch 11421 - Train Loss: 0.110292, Train Acc: 0.824359 | Val Loss: 0.128414, Val Acc: 0.701031\n",
      "Epoch 11422 - Train Loss: 0.110286, Train Acc: 0.824359 | Val Loss: 0.128409, Val Acc: 0.701031\n",
      "Epoch 11423 - Train Loss: 0.110280, Train Acc: 0.824359 | Val Loss: 0.128404, Val Acc: 0.701031\n",
      "Epoch 11424 - Train Loss: 0.110273, Train Acc: 0.824359 | Val Loss: 0.128399, Val Acc: 0.701031\n",
      "Epoch 11425 - Train Loss: 0.110267, Train Acc: 0.824359 | Val Loss: 0.128395, Val Acc: 0.701031\n",
      "Epoch 11426 - Train Loss: 0.110261, Train Acc: 0.824359 | Val Loss: 0.128390, Val Acc: 0.701031\n",
      "Epoch 11427 - Train Loss: 0.110255, Train Acc: 0.824359 | Val Loss: 0.128385, Val Acc: 0.701031\n",
      "Epoch 11428 - Train Loss: 0.110249, Train Acc: 0.824359 | Val Loss: 0.128380, Val Acc: 0.701031\n",
      "Epoch 11429 - Train Loss: 0.110243, Train Acc: 0.824359 | Val Loss: 0.128375, Val Acc: 0.701031\n",
      "Epoch 11430 - Train Loss: 0.110237, Train Acc: 0.824359 | Val Loss: 0.128370, Val Acc: 0.701031\n",
      "Epoch 11431 - Train Loss: 0.110231, Train Acc: 0.824359 | Val Loss: 0.128365, Val Acc: 0.701031\n",
      "Epoch 11432 - Train Loss: 0.110224, Train Acc: 0.824359 | Val Loss: 0.128360, Val Acc: 0.701031\n",
      "Epoch 11433 - Train Loss: 0.110218, Train Acc: 0.824359 | Val Loss: 0.128355, Val Acc: 0.701031\n",
      "Epoch 11434 - Train Loss: 0.110212, Train Acc: 0.824359 | Val Loss: 0.128350, Val Acc: 0.701031\n",
      "Epoch 11435 - Train Loss: 0.110206, Train Acc: 0.824359 | Val Loss: 0.128345, Val Acc: 0.701031\n",
      "Epoch 11436 - Train Loss: 0.110200, Train Acc: 0.824359 | Val Loss: 0.128340, Val Acc: 0.701031\n",
      "Epoch 11437 - Train Loss: 0.110194, Train Acc: 0.824359 | Val Loss: 0.128335, Val Acc: 0.701031\n",
      "Epoch 11438 - Train Loss: 0.110188, Train Acc: 0.824359 | Val Loss: 0.128330, Val Acc: 0.701031\n",
      "Epoch 11439 - Train Loss: 0.110182, Train Acc: 0.824359 | Val Loss: 0.128326, Val Acc: 0.701031\n",
      "Epoch 11440 - Train Loss: 0.110175, Train Acc: 0.824359 | Val Loss: 0.128321, Val Acc: 0.701031\n",
      "Epoch 11441 - Train Loss: 0.110169, Train Acc: 0.824359 | Val Loss: 0.128316, Val Acc: 0.701031\n",
      "Epoch 11442 - Train Loss: 0.110163, Train Acc: 0.824359 | Val Loss: 0.128311, Val Acc: 0.701031\n",
      "Epoch 11443 - Train Loss: 0.110157, Train Acc: 0.824359 | Val Loss: 0.128306, Val Acc: 0.701031\n",
      "Epoch 11444 - Train Loss: 0.110151, Train Acc: 0.824359 | Val Loss: 0.128301, Val Acc: 0.701031\n",
      "Epoch 11445 - Train Loss: 0.110145, Train Acc: 0.824359 | Val Loss: 0.128296, Val Acc: 0.701031\n",
      "Epoch 11446 - Train Loss: 0.110139, Train Acc: 0.824359 | Val Loss: 0.128291, Val Acc: 0.701031\n",
      "Epoch 11447 - Train Loss: 0.110133, Train Acc: 0.824359 | Val Loss: 0.128286, Val Acc: 0.701031\n",
      "Epoch 11448 - Train Loss: 0.110127, Train Acc: 0.824359 | Val Loss: 0.128281, Val Acc: 0.701031\n",
      "Epoch 11449 - Train Loss: 0.110121, Train Acc: 0.824359 | Val Loss: 0.128276, Val Acc: 0.701031\n",
      "Epoch 11450 - Train Loss: 0.110114, Train Acc: 0.824359 | Val Loss: 0.128271, Val Acc: 0.701031\n",
      "Epoch 11451 - Train Loss: 0.110108, Train Acc: 0.824359 | Val Loss: 0.128267, Val Acc: 0.701031\n",
      "Epoch 11452 - Train Loss: 0.110102, Train Acc: 0.824359 | Val Loss: 0.128262, Val Acc: 0.701031\n",
      "Epoch 11453 - Train Loss: 0.110096, Train Acc: 0.824359 | Val Loss: 0.128257, Val Acc: 0.701031\n",
      "Epoch 11454 - Train Loss: 0.110090, Train Acc: 0.824359 | Val Loss: 0.128252, Val Acc: 0.701031\n",
      "Epoch 11455 - Train Loss: 0.110084, Train Acc: 0.824359 | Val Loss: 0.128247, Val Acc: 0.701031\n",
      "Epoch 11456 - Train Loss: 0.110078, Train Acc: 0.824359 | Val Loss: 0.128242, Val Acc: 0.701031\n",
      "Epoch 11457 - Train Loss: 0.110072, Train Acc: 0.824359 | Val Loss: 0.128237, Val Acc: 0.701031\n",
      "Epoch 11458 - Train Loss: 0.110066, Train Acc: 0.824359 | Val Loss: 0.128232, Val Acc: 0.701031\n",
      "Epoch 11459 - Train Loss: 0.110060, Train Acc: 0.824359 | Val Loss: 0.128227, Val Acc: 0.701031\n",
      "Epoch 11460 - Train Loss: 0.110053, Train Acc: 0.824359 | Val Loss: 0.128222, Val Acc: 0.701031\n",
      "Epoch 11461 - Train Loss: 0.110047, Train Acc: 0.824359 | Val Loss: 0.128218, Val Acc: 0.701031\n",
      "Epoch 11462 - Train Loss: 0.110041, Train Acc: 0.824359 | Val Loss: 0.128213, Val Acc: 0.701031\n",
      "Epoch 11463 - Train Loss: 0.110035, Train Acc: 0.824359 | Val Loss: 0.128208, Val Acc: 0.701031\n",
      "Epoch 11464 - Train Loss: 0.110029, Train Acc: 0.824359 | Val Loss: 0.128203, Val Acc: 0.701031\n",
      "Epoch 11465 - Train Loss: 0.110023, Train Acc: 0.824359 | Val Loss: 0.128198, Val Acc: 0.701031\n",
      "Epoch 11466 - Train Loss: 0.110017, Train Acc: 0.824359 | Val Loss: 0.128193, Val Acc: 0.701031\n",
      "Epoch 11467 - Train Loss: 0.110011, Train Acc: 0.825641 | Val Loss: 0.128188, Val Acc: 0.701031\n",
      "Epoch 11468 - Train Loss: 0.110005, Train Acc: 0.825641 | Val Loss: 0.128183, Val Acc: 0.701031\n",
      "Epoch 11469 - Train Loss: 0.109999, Train Acc: 0.825641 | Val Loss: 0.128178, Val Acc: 0.701031\n",
      "Epoch 11470 - Train Loss: 0.109993, Train Acc: 0.825641 | Val Loss: 0.128174, Val Acc: 0.701031\n",
      "Epoch 11471 - Train Loss: 0.109986, Train Acc: 0.825641 | Val Loss: 0.128169, Val Acc: 0.701031\n",
      "Epoch 11472 - Train Loss: 0.109980, Train Acc: 0.825641 | Val Loss: 0.128164, Val Acc: 0.701031\n",
      "Epoch 11473 - Train Loss: 0.109974, Train Acc: 0.825641 | Val Loss: 0.128159, Val Acc: 0.701031\n",
      "Epoch 11474 - Train Loss: 0.109968, Train Acc: 0.825641 | Val Loss: 0.128154, Val Acc: 0.701031\n",
      "Epoch 11475 - Train Loss: 0.109962, Train Acc: 0.825641 | Val Loss: 0.128149, Val Acc: 0.701031\n",
      "Epoch 11476 - Train Loss: 0.109956, Train Acc: 0.825641 | Val Loss: 0.128144, Val Acc: 0.701031\n",
      "Epoch 11477 - Train Loss: 0.109950, Train Acc: 0.825641 | Val Loss: 0.128139, Val Acc: 0.701031\n",
      "Epoch 11478 - Train Loss: 0.109944, Train Acc: 0.825641 | Val Loss: 0.128134, Val Acc: 0.701031\n",
      "Epoch 11479 - Train Loss: 0.109938, Train Acc: 0.825641 | Val Loss: 0.128130, Val Acc: 0.701031\n",
      "Epoch 11480 - Train Loss: 0.109932, Train Acc: 0.825641 | Val Loss: 0.128125, Val Acc: 0.701031\n",
      "Epoch 11481 - Train Loss: 0.109926, Train Acc: 0.825641 | Val Loss: 0.128120, Val Acc: 0.701031\n",
      "Epoch 11482 - Train Loss: 0.109920, Train Acc: 0.825641 | Val Loss: 0.128115, Val Acc: 0.701031\n",
      "Epoch 11483 - Train Loss: 0.109913, Train Acc: 0.825641 | Val Loss: 0.128110, Val Acc: 0.701031\n",
      "Epoch 11484 - Train Loss: 0.109907, Train Acc: 0.825641 | Val Loss: 0.128105, Val Acc: 0.701031\n",
      "Epoch 11485 - Train Loss: 0.109901, Train Acc: 0.825641 | Val Loss: 0.128100, Val Acc: 0.701031\n",
      "Epoch 11486 - Train Loss: 0.109895, Train Acc: 0.825641 | Val Loss: 0.128095, Val Acc: 0.701031\n",
      "Epoch 11487 - Train Loss: 0.109889, Train Acc: 0.826923 | Val Loss: 0.128091, Val Acc: 0.701031\n",
      "Epoch 11488 - Train Loss: 0.109883, Train Acc: 0.826923 | Val Loss: 0.128086, Val Acc: 0.701031\n",
      "Epoch 11489 - Train Loss: 0.109877, Train Acc: 0.826923 | Val Loss: 0.128081, Val Acc: 0.701031\n",
      "Epoch 11490 - Train Loss: 0.109871, Train Acc: 0.826923 | Val Loss: 0.128076, Val Acc: 0.701031\n",
      "Epoch 11491 - Train Loss: 0.109865, Train Acc: 0.826923 | Val Loss: 0.128071, Val Acc: 0.701031\n",
      "Epoch 11492 - Train Loss: 0.109859, Train Acc: 0.826923 | Val Loss: 0.128066, Val Acc: 0.701031\n",
      "Epoch 11493 - Train Loss: 0.109853, Train Acc: 0.826923 | Val Loss: 0.128061, Val Acc: 0.701031\n",
      "Epoch 11494 - Train Loss: 0.109847, Train Acc: 0.826923 | Val Loss: 0.128056, Val Acc: 0.701031\n",
      "Epoch 11495 - Train Loss: 0.109841, Train Acc: 0.826923 | Val Loss: 0.128052, Val Acc: 0.701031\n",
      "Epoch 11496 - Train Loss: 0.109834, Train Acc: 0.826923 | Val Loss: 0.128047, Val Acc: 0.701031\n",
      "Epoch 11497 - Train Loss: 0.109828, Train Acc: 0.826923 | Val Loss: 0.128042, Val Acc: 0.701031\n",
      "Epoch 11498 - Train Loss: 0.109822, Train Acc: 0.826923 | Val Loss: 0.128037, Val Acc: 0.701031\n",
      "Epoch 11499 - Train Loss: 0.109816, Train Acc: 0.826923 | Val Loss: 0.128032, Val Acc: 0.701031\n",
      "Epoch 11500 - Train Loss: 0.109810, Train Acc: 0.826923 | Val Loss: 0.128027, Val Acc: 0.701031\n",
      "Epoch 11501 - Train Loss: 0.109804, Train Acc: 0.826923 | Val Loss: 0.128022, Val Acc: 0.701031\n",
      "Epoch 11502 - Train Loss: 0.109798, Train Acc: 0.826923 | Val Loss: 0.128018, Val Acc: 0.701031\n",
      "Epoch 11503 - Train Loss: 0.109792, Train Acc: 0.826923 | Val Loss: 0.128013, Val Acc: 0.701031\n",
      "Epoch 11504 - Train Loss: 0.109786, Train Acc: 0.826923 | Val Loss: 0.128008, Val Acc: 0.701031\n",
      "Epoch 11505 - Train Loss: 0.109780, Train Acc: 0.826923 | Val Loss: 0.128003, Val Acc: 0.701031\n",
      "Epoch 11506 - Train Loss: 0.109774, Train Acc: 0.826923 | Val Loss: 0.127998, Val Acc: 0.701031\n",
      "Epoch 11507 - Train Loss: 0.109768, Train Acc: 0.826923 | Val Loss: 0.127993, Val Acc: 0.701031\n",
      "Epoch 11508 - Train Loss: 0.109762, Train Acc: 0.826923 | Val Loss: 0.127988, Val Acc: 0.701031\n",
      "Epoch 11509 - Train Loss: 0.109756, Train Acc: 0.826923 | Val Loss: 0.127983, Val Acc: 0.701031\n",
      "Epoch 11510 - Train Loss: 0.109750, Train Acc: 0.826923 | Val Loss: 0.127979, Val Acc: 0.701031\n",
      "Epoch 11511 - Train Loss: 0.109744, Train Acc: 0.826923 | Val Loss: 0.127974, Val Acc: 0.701031\n",
      "Epoch 11512 - Train Loss: 0.109738, Train Acc: 0.826923 | Val Loss: 0.127969, Val Acc: 0.701031\n",
      "Epoch 11513 - Train Loss: 0.109731, Train Acc: 0.826923 | Val Loss: 0.127964, Val Acc: 0.701031\n",
      "Epoch 11514 - Train Loss: 0.109725, Train Acc: 0.826923 | Val Loss: 0.127959, Val Acc: 0.701031\n",
      "Epoch 11515 - Train Loss: 0.109719, Train Acc: 0.826923 | Val Loss: 0.127954, Val Acc: 0.701031\n",
      "Epoch 11516 - Train Loss: 0.109713, Train Acc: 0.826923 | Val Loss: 0.127950, Val Acc: 0.701031\n",
      "Epoch 11517 - Train Loss: 0.109707, Train Acc: 0.826923 | Val Loss: 0.127945, Val Acc: 0.701031\n",
      "Epoch 11518 - Train Loss: 0.109701, Train Acc: 0.826923 | Val Loss: 0.127940, Val Acc: 0.701031\n",
      "Epoch 11519 - Train Loss: 0.109695, Train Acc: 0.826923 | Val Loss: 0.127935, Val Acc: 0.701031\n",
      "Epoch 11520 - Train Loss: 0.109689, Train Acc: 0.826923 | Val Loss: 0.127930, Val Acc: 0.701031\n",
      "Epoch 11521 - Train Loss: 0.109683, Train Acc: 0.826923 | Val Loss: 0.127925, Val Acc: 0.701031\n",
      "Epoch 11522 - Train Loss: 0.109677, Train Acc: 0.826923 | Val Loss: 0.127920, Val Acc: 0.701031\n",
      "Epoch 11523 - Train Loss: 0.109671, Train Acc: 0.826923 | Val Loss: 0.127916, Val Acc: 0.701031\n",
      "Epoch 11524 - Train Loss: 0.109665, Train Acc: 0.826923 | Val Loss: 0.127911, Val Acc: 0.701031\n",
      "Epoch 11525 - Train Loss: 0.109659, Train Acc: 0.826923 | Val Loss: 0.127906, Val Acc: 0.701031\n",
      "Epoch 11526 - Train Loss: 0.109653, Train Acc: 0.826923 | Val Loss: 0.127901, Val Acc: 0.701031\n",
      "Epoch 11527 - Train Loss: 0.109647, Train Acc: 0.826923 | Val Loss: 0.127896, Val Acc: 0.701031\n",
      "Epoch 11528 - Train Loss: 0.109641, Train Acc: 0.826923 | Val Loss: 0.127891, Val Acc: 0.701031\n",
      "Epoch 11529 - Train Loss: 0.109635, Train Acc: 0.826923 | Val Loss: 0.127887, Val Acc: 0.701031\n",
      "Epoch 11530 - Train Loss: 0.109629, Train Acc: 0.826923 | Val Loss: 0.127882, Val Acc: 0.701031\n",
      "Epoch 11531 - Train Loss: 0.109623, Train Acc: 0.828205 | Val Loss: 0.127877, Val Acc: 0.701031\n",
      "Epoch 11532 - Train Loss: 0.109617, Train Acc: 0.828205 | Val Loss: 0.127872, Val Acc: 0.701031\n",
      "Epoch 11533 - Train Loss: 0.109611, Train Acc: 0.828205 | Val Loss: 0.127867, Val Acc: 0.701031\n",
      "Epoch 11534 - Train Loss: 0.109605, Train Acc: 0.828205 | Val Loss: 0.127862, Val Acc: 0.701031\n",
      "Epoch 11535 - Train Loss: 0.109599, Train Acc: 0.828205 | Val Loss: 0.127858, Val Acc: 0.701031\n",
      "Epoch 11536 - Train Loss: 0.109593, Train Acc: 0.828205 | Val Loss: 0.127853, Val Acc: 0.701031\n",
      "Epoch 11537 - Train Loss: 0.109586, Train Acc: 0.828205 | Val Loss: 0.127848, Val Acc: 0.701031\n",
      "Epoch 11538 - Train Loss: 0.109580, Train Acc: 0.828205 | Val Loss: 0.127843, Val Acc: 0.701031\n",
      "Epoch 11539 - Train Loss: 0.109574, Train Acc: 0.828205 | Val Loss: 0.127838, Val Acc: 0.701031\n",
      "Epoch 11540 - Train Loss: 0.109568, Train Acc: 0.828205 | Val Loss: 0.127833, Val Acc: 0.701031\n",
      "Epoch 11541 - Train Loss: 0.109562, Train Acc: 0.828205 | Val Loss: 0.127829, Val Acc: 0.701031\n",
      "Epoch 11542 - Train Loss: 0.109556, Train Acc: 0.828205 | Val Loss: 0.127824, Val Acc: 0.701031\n",
      "Epoch 11543 - Train Loss: 0.109550, Train Acc: 0.828205 | Val Loss: 0.127819, Val Acc: 0.701031\n",
      "Epoch 11544 - Train Loss: 0.109544, Train Acc: 0.828205 | Val Loss: 0.127814, Val Acc: 0.701031\n",
      "Epoch 11545 - Train Loss: 0.109538, Train Acc: 0.828205 | Val Loss: 0.127809, Val Acc: 0.701031\n",
      "Epoch 11546 - Train Loss: 0.109532, Train Acc: 0.828205 | Val Loss: 0.127804, Val Acc: 0.701031\n",
      "Epoch 11547 - Train Loss: 0.109526, Train Acc: 0.828205 | Val Loss: 0.127800, Val Acc: 0.701031\n",
      "Epoch 11548 - Train Loss: 0.109520, Train Acc: 0.828205 | Val Loss: 0.127795, Val Acc: 0.701031\n",
      "Epoch 11549 - Train Loss: 0.109514, Train Acc: 0.828205 | Val Loss: 0.127790, Val Acc: 0.701031\n",
      "Epoch 11550 - Train Loss: 0.109508, Train Acc: 0.828205 | Val Loss: 0.127785, Val Acc: 0.701031\n",
      "Epoch 11551 - Train Loss: 0.109502, Train Acc: 0.828205 | Val Loss: 0.127780, Val Acc: 0.701031\n",
      "Epoch 11552 - Train Loss: 0.109496, Train Acc: 0.828205 | Val Loss: 0.127775, Val Acc: 0.701031\n",
      "Epoch 11553 - Train Loss: 0.109490, Train Acc: 0.828205 | Val Loss: 0.127771, Val Acc: 0.701031\n",
      "Epoch 11554 - Train Loss: 0.109484, Train Acc: 0.828205 | Val Loss: 0.127766, Val Acc: 0.701031\n",
      "Epoch 11555 - Train Loss: 0.109478, Train Acc: 0.828205 | Val Loss: 0.127761, Val Acc: 0.701031\n",
      "Epoch 11556 - Train Loss: 0.109472, Train Acc: 0.828205 | Val Loss: 0.127756, Val Acc: 0.701031\n",
      "Epoch 11557 - Train Loss: 0.109466, Train Acc: 0.828205 | Val Loss: 0.127751, Val Acc: 0.701031\n",
      "Epoch 11558 - Train Loss: 0.109460, Train Acc: 0.828205 | Val Loss: 0.127747, Val Acc: 0.701031\n",
      "Epoch 11559 - Train Loss: 0.109454, Train Acc: 0.828205 | Val Loss: 0.127742, Val Acc: 0.701031\n",
      "Epoch 11560 - Train Loss: 0.109448, Train Acc: 0.828205 | Val Loss: 0.127737, Val Acc: 0.701031\n",
      "Epoch 11561 - Train Loss: 0.109442, Train Acc: 0.828205 | Val Loss: 0.127732, Val Acc: 0.701031\n",
      "Epoch 11562 - Train Loss: 0.109436, Train Acc: 0.828205 | Val Loss: 0.127727, Val Acc: 0.701031\n",
      "Epoch 11563 - Train Loss: 0.109430, Train Acc: 0.828205 | Val Loss: 0.127722, Val Acc: 0.701031\n",
      "Epoch 11564 - Train Loss: 0.109424, Train Acc: 0.828205 | Val Loss: 0.127718, Val Acc: 0.701031\n",
      "Epoch 11565 - Train Loss: 0.109418, Train Acc: 0.828205 | Val Loss: 0.127713, Val Acc: 0.701031\n",
      "Epoch 11566 - Train Loss: 0.109412, Train Acc: 0.829487 | Val Loss: 0.127708, Val Acc: 0.701031\n",
      "Epoch 11567 - Train Loss: 0.109406, Train Acc: 0.829487 | Val Loss: 0.127703, Val Acc: 0.701031\n",
      "Epoch 11568 - Train Loss: 0.109400, Train Acc: 0.829487 | Val Loss: 0.127698, Val Acc: 0.701031\n",
      "Epoch 11569 - Train Loss: 0.109394, Train Acc: 0.829487 | Val Loss: 0.127694, Val Acc: 0.701031\n",
      "Epoch 11570 - Train Loss: 0.109388, Train Acc: 0.829487 | Val Loss: 0.127689, Val Acc: 0.701031\n",
      "Epoch 11571 - Train Loss: 0.109382, Train Acc: 0.829487 | Val Loss: 0.127684, Val Acc: 0.701031\n",
      "Epoch 11572 - Train Loss: 0.109376, Train Acc: 0.829487 | Val Loss: 0.127679, Val Acc: 0.701031\n",
      "Epoch 11573 - Train Loss: 0.109370, Train Acc: 0.829487 | Val Loss: 0.127674, Val Acc: 0.701031\n",
      "Epoch 11574 - Train Loss: 0.109364, Train Acc: 0.829487 | Val Loss: 0.127670, Val Acc: 0.701031\n",
      "Epoch 11575 - Train Loss: 0.109358, Train Acc: 0.829487 | Val Loss: 0.127665, Val Acc: 0.701031\n",
      "Epoch 11576 - Train Loss: 0.109352, Train Acc: 0.829487 | Val Loss: 0.127660, Val Acc: 0.701031\n",
      "Epoch 11577 - Train Loss: 0.109346, Train Acc: 0.830769 | Val Loss: 0.127655, Val Acc: 0.701031\n",
      "Epoch 11578 - Train Loss: 0.109340, Train Acc: 0.830769 | Val Loss: 0.127650, Val Acc: 0.701031\n",
      "Epoch 11579 - Train Loss: 0.109334, Train Acc: 0.830769 | Val Loss: 0.127646, Val Acc: 0.701031\n",
      "Epoch 11580 - Train Loss: 0.109328, Train Acc: 0.830769 | Val Loss: 0.127641, Val Acc: 0.701031\n",
      "Epoch 11581 - Train Loss: 0.109322, Train Acc: 0.830769 | Val Loss: 0.127636, Val Acc: 0.701031\n",
      "Epoch 11582 - Train Loss: 0.109316, Train Acc: 0.830769 | Val Loss: 0.127631, Val Acc: 0.701031\n",
      "Epoch 11583 - Train Loss: 0.109310, Train Acc: 0.830769 | Val Loss: 0.127626, Val Acc: 0.701031\n",
      "Epoch 11584 - Train Loss: 0.109304, Train Acc: 0.830769 | Val Loss: 0.127622, Val Acc: 0.701031\n",
      "Epoch 11585 - Train Loss: 0.109298, Train Acc: 0.830769 | Val Loss: 0.127617, Val Acc: 0.701031\n",
      "Epoch 11586 - Train Loss: 0.109292, Train Acc: 0.830769 | Val Loss: 0.127612, Val Acc: 0.711340\n",
      "Epoch 11587 - Train Loss: 0.109286, Train Acc: 0.830769 | Val Loss: 0.127607, Val Acc: 0.711340\n",
      "Epoch 11588 - Train Loss: 0.109280, Train Acc: 0.830769 | Val Loss: 0.127602, Val Acc: 0.711340\n",
      "Epoch 11589 - Train Loss: 0.109274, Train Acc: 0.830769 | Val Loss: 0.127598, Val Acc: 0.711340\n",
      "Epoch 11590 - Train Loss: 0.109268, Train Acc: 0.830769 | Val Loss: 0.127593, Val Acc: 0.711340\n",
      "Epoch 11591 - Train Loss: 0.109262, Train Acc: 0.830769 | Val Loss: 0.127588, Val Acc: 0.711340\n",
      "Epoch 11592 - Train Loss: 0.109256, Train Acc: 0.830769 | Val Loss: 0.127583, Val Acc: 0.711340\n",
      "Epoch 11593 - Train Loss: 0.109250, Train Acc: 0.830769 | Val Loss: 0.127579, Val Acc: 0.711340\n",
      "Epoch 11594 - Train Loss: 0.109244, Train Acc: 0.830769 | Val Loss: 0.127574, Val Acc: 0.711340\n",
      "Epoch 11595 - Train Loss: 0.109238, Train Acc: 0.830769 | Val Loss: 0.127569, Val Acc: 0.711340\n",
      "Epoch 11596 - Train Loss: 0.109232, Train Acc: 0.830769 | Val Loss: 0.127564, Val Acc: 0.711340\n",
      "Epoch 11597 - Train Loss: 0.109226, Train Acc: 0.830769 | Val Loss: 0.127559, Val Acc: 0.711340\n",
      "Epoch 11598 - Train Loss: 0.109220, Train Acc: 0.830769 | Val Loss: 0.127555, Val Acc: 0.711340\n",
      "Epoch 11599 - Train Loss: 0.109214, Train Acc: 0.830769 | Val Loss: 0.127550, Val Acc: 0.711340\n",
      "Epoch 11600 - Train Loss: 0.109208, Train Acc: 0.830769 | Val Loss: 0.127545, Val Acc: 0.711340\n",
      "Epoch 11601 - Train Loss: 0.109202, Train Acc: 0.830769 | Val Loss: 0.127540, Val Acc: 0.711340\n",
      "Epoch 11602 - Train Loss: 0.109196, Train Acc: 0.830769 | Val Loss: 0.127536, Val Acc: 0.711340\n",
      "Epoch 11603 - Train Loss: 0.109190, Train Acc: 0.830769 | Val Loss: 0.127531, Val Acc: 0.711340\n",
      "Epoch 11604 - Train Loss: 0.109184, Train Acc: 0.830769 | Val Loss: 0.127526, Val Acc: 0.711340\n",
      "Epoch 11605 - Train Loss: 0.109178, Train Acc: 0.830769 | Val Loss: 0.127521, Val Acc: 0.711340\n",
      "Epoch 11606 - Train Loss: 0.109172, Train Acc: 0.830769 | Val Loss: 0.127516, Val Acc: 0.711340\n",
      "Epoch 11607 - Train Loss: 0.109166, Train Acc: 0.830769 | Val Loss: 0.127512, Val Acc: 0.711340\n",
      "Epoch 11608 - Train Loss: 0.109160, Train Acc: 0.830769 | Val Loss: 0.127507, Val Acc: 0.711340\n",
      "Epoch 11609 - Train Loss: 0.109154, Train Acc: 0.830769 | Val Loss: 0.127502, Val Acc: 0.711340\n",
      "Epoch 11610 - Train Loss: 0.109148, Train Acc: 0.830769 | Val Loss: 0.127497, Val Acc: 0.711340\n",
      "Epoch 11611 - Train Loss: 0.109142, Train Acc: 0.830769 | Val Loss: 0.127493, Val Acc: 0.711340\n",
      "Epoch 11612 - Train Loss: 0.109136, Train Acc: 0.830769 | Val Loss: 0.127488, Val Acc: 0.711340\n",
      "Epoch 11613 - Train Loss: 0.109130, Train Acc: 0.830769 | Val Loss: 0.127483, Val Acc: 0.711340\n",
      "Epoch 11614 - Train Loss: 0.109125, Train Acc: 0.830769 | Val Loss: 0.127478, Val Acc: 0.711340\n",
      "Epoch 11615 - Train Loss: 0.109119, Train Acc: 0.830769 | Val Loss: 0.127474, Val Acc: 0.711340\n",
      "Epoch 11616 - Train Loss: 0.109113, Train Acc: 0.830769 | Val Loss: 0.127469, Val Acc: 0.711340\n",
      "Epoch 11617 - Train Loss: 0.109107, Train Acc: 0.830769 | Val Loss: 0.127464, Val Acc: 0.711340\n",
      "Epoch 11618 - Train Loss: 0.109101, Train Acc: 0.830769 | Val Loss: 0.127459, Val Acc: 0.711340\n",
      "Epoch 11619 - Train Loss: 0.109095, Train Acc: 0.830769 | Val Loss: 0.127454, Val Acc: 0.711340\n",
      "Epoch 11620 - Train Loss: 0.109089, Train Acc: 0.830769 | Val Loss: 0.127450, Val Acc: 0.711340\n",
      "Epoch 11621 - Train Loss: 0.109083, Train Acc: 0.830769 | Val Loss: 0.127445, Val Acc: 0.711340\n",
      "Epoch 11622 - Train Loss: 0.109077, Train Acc: 0.830769 | Val Loss: 0.127440, Val Acc: 0.711340\n",
      "Epoch 11623 - Train Loss: 0.109071, Train Acc: 0.830769 | Val Loss: 0.127435, Val Acc: 0.711340\n",
      "Epoch 11624 - Train Loss: 0.109065, Train Acc: 0.830769 | Val Loss: 0.127431, Val Acc: 0.711340\n",
      "Epoch 11625 - Train Loss: 0.109059, Train Acc: 0.830769 | Val Loss: 0.127426, Val Acc: 0.711340\n",
      "Epoch 11626 - Train Loss: 0.109053, Train Acc: 0.830769 | Val Loss: 0.127421, Val Acc: 0.711340\n",
      "Epoch 11627 - Train Loss: 0.109047, Train Acc: 0.830769 | Val Loss: 0.127416, Val Acc: 0.711340\n",
      "Epoch 11628 - Train Loss: 0.109041, Train Acc: 0.830769 | Val Loss: 0.127412, Val Acc: 0.711340\n",
      "Epoch 11629 - Train Loss: 0.109035, Train Acc: 0.830769 | Val Loss: 0.127407, Val Acc: 0.711340\n",
      "Epoch 11630 - Train Loss: 0.109029, Train Acc: 0.830769 | Val Loss: 0.127402, Val Acc: 0.711340\n",
      "Epoch 11631 - Train Loss: 0.109023, Train Acc: 0.830769 | Val Loss: 0.127397, Val Acc: 0.711340\n",
      "Epoch 11632 - Train Loss: 0.109017, Train Acc: 0.830769 | Val Loss: 0.127393, Val Acc: 0.711340\n",
      "Epoch 11633 - Train Loss: 0.109011, Train Acc: 0.830769 | Val Loss: 0.127388, Val Acc: 0.711340\n",
      "Epoch 11634 - Train Loss: 0.109005, Train Acc: 0.830769 | Val Loss: 0.127383, Val Acc: 0.711340\n",
      "Epoch 11635 - Train Loss: 0.108999, Train Acc: 0.830769 | Val Loss: 0.127378, Val Acc: 0.711340\n",
      "Epoch 11636 - Train Loss: 0.108993, Train Acc: 0.830769 | Val Loss: 0.127374, Val Acc: 0.711340\n",
      "Epoch 11637 - Train Loss: 0.108987, Train Acc: 0.830769 | Val Loss: 0.127369, Val Acc: 0.711340\n",
      "Epoch 11638 - Train Loss: 0.108982, Train Acc: 0.830769 | Val Loss: 0.127364, Val Acc: 0.711340\n",
      "Epoch 11639 - Train Loss: 0.108976, Train Acc: 0.830769 | Val Loss: 0.127359, Val Acc: 0.711340\n",
      "Epoch 11640 - Train Loss: 0.108970, Train Acc: 0.832051 | Val Loss: 0.127355, Val Acc: 0.711340\n",
      "Epoch 11641 - Train Loss: 0.108964, Train Acc: 0.832051 | Val Loss: 0.127350, Val Acc: 0.711340\n",
      "Epoch 11642 - Train Loss: 0.108958, Train Acc: 0.832051 | Val Loss: 0.127345, Val Acc: 0.711340\n",
      "Epoch 11643 - Train Loss: 0.108952, Train Acc: 0.832051 | Val Loss: 0.127340, Val Acc: 0.711340\n",
      "Epoch 11644 - Train Loss: 0.108946, Train Acc: 0.832051 | Val Loss: 0.127336, Val Acc: 0.711340\n",
      "Epoch 11645 - Train Loss: 0.108940, Train Acc: 0.832051 | Val Loss: 0.127331, Val Acc: 0.711340\n",
      "Epoch 11646 - Train Loss: 0.108934, Train Acc: 0.832051 | Val Loss: 0.127326, Val Acc: 0.711340\n",
      "Epoch 11647 - Train Loss: 0.108928, Train Acc: 0.832051 | Val Loss: 0.127321, Val Acc: 0.711340\n",
      "Epoch 11648 - Train Loss: 0.108922, Train Acc: 0.832051 | Val Loss: 0.127317, Val Acc: 0.711340\n",
      "Epoch 11649 - Train Loss: 0.108916, Train Acc: 0.832051 | Val Loss: 0.127312, Val Acc: 0.711340\n",
      "Epoch 11650 - Train Loss: 0.108910, Train Acc: 0.832051 | Val Loss: 0.127307, Val Acc: 0.711340\n",
      "Epoch 11651 - Train Loss: 0.108904, Train Acc: 0.832051 | Val Loss: 0.127303, Val Acc: 0.711340\n",
      "Epoch 11652 - Train Loss: 0.108898, Train Acc: 0.832051 | Val Loss: 0.127298, Val Acc: 0.711340\n",
      "Epoch 11653 - Train Loss: 0.108892, Train Acc: 0.832051 | Val Loss: 0.127293, Val Acc: 0.711340\n",
      "Epoch 11654 - Train Loss: 0.108886, Train Acc: 0.832051 | Val Loss: 0.127288, Val Acc: 0.711340\n",
      "Epoch 11655 - Train Loss: 0.108881, Train Acc: 0.832051 | Val Loss: 0.127284, Val Acc: 0.711340\n",
      "Epoch 11656 - Train Loss: 0.108875, Train Acc: 0.832051 | Val Loss: 0.127279, Val Acc: 0.711340\n",
      "Epoch 11657 - Train Loss: 0.108869, Train Acc: 0.832051 | Val Loss: 0.127274, Val Acc: 0.711340\n",
      "Epoch 11658 - Train Loss: 0.108863, Train Acc: 0.832051 | Val Loss: 0.127269, Val Acc: 0.711340\n",
      "Epoch 11659 - Train Loss: 0.108857, Train Acc: 0.832051 | Val Loss: 0.127265, Val Acc: 0.711340\n",
      "Epoch 11660 - Train Loss: 0.108851, Train Acc: 0.832051 | Val Loss: 0.127260, Val Acc: 0.711340\n",
      "Epoch 11661 - Train Loss: 0.108845, Train Acc: 0.832051 | Val Loss: 0.127255, Val Acc: 0.711340\n",
      "Epoch 11662 - Train Loss: 0.108839, Train Acc: 0.832051 | Val Loss: 0.127250, Val Acc: 0.711340\n",
      "Epoch 11663 - Train Loss: 0.108833, Train Acc: 0.832051 | Val Loss: 0.127246, Val Acc: 0.711340\n",
      "Epoch 11664 - Train Loss: 0.108827, Train Acc: 0.832051 | Val Loss: 0.127241, Val Acc: 0.711340\n",
      "Epoch 11665 - Train Loss: 0.108821, Train Acc: 0.832051 | Val Loss: 0.127236, Val Acc: 0.711340\n",
      "Epoch 11666 - Train Loss: 0.108815, Train Acc: 0.832051 | Val Loss: 0.127232, Val Acc: 0.711340\n",
      "Epoch 11667 - Train Loss: 0.108809, Train Acc: 0.832051 | Val Loss: 0.127227, Val Acc: 0.711340\n",
      "Epoch 11668 - Train Loss: 0.108803, Train Acc: 0.832051 | Val Loss: 0.127222, Val Acc: 0.711340\n",
      "Epoch 11669 - Train Loss: 0.108798, Train Acc: 0.832051 | Val Loss: 0.127217, Val Acc: 0.711340\n",
      "Epoch 11670 - Train Loss: 0.108792, Train Acc: 0.832051 | Val Loss: 0.127213, Val Acc: 0.711340\n",
      "Epoch 11671 - Train Loss: 0.108786, Train Acc: 0.832051 | Val Loss: 0.127208, Val Acc: 0.711340\n",
      "Epoch 11672 - Train Loss: 0.108780, Train Acc: 0.832051 | Val Loss: 0.127203, Val Acc: 0.711340\n",
      "Epoch 11673 - Train Loss: 0.108774, Train Acc: 0.832051 | Val Loss: 0.127199, Val Acc: 0.711340\n",
      "Epoch 11674 - Train Loss: 0.108768, Train Acc: 0.832051 | Val Loss: 0.127194, Val Acc: 0.711340\n",
      "Epoch 11675 - Train Loss: 0.108762, Train Acc: 0.832051 | Val Loss: 0.127189, Val Acc: 0.711340\n",
      "Epoch 11676 - Train Loss: 0.108756, Train Acc: 0.832051 | Val Loss: 0.127184, Val Acc: 0.711340\n",
      "Epoch 11677 - Train Loss: 0.108750, Train Acc: 0.832051 | Val Loss: 0.127180, Val Acc: 0.711340\n",
      "Epoch 11678 - Train Loss: 0.108744, Train Acc: 0.832051 | Val Loss: 0.127175, Val Acc: 0.711340\n",
      "Epoch 11679 - Train Loss: 0.108738, Train Acc: 0.832051 | Val Loss: 0.127170, Val Acc: 0.711340\n",
      "Epoch 11680 - Train Loss: 0.108732, Train Acc: 0.832051 | Val Loss: 0.127166, Val Acc: 0.711340\n",
      "Epoch 11681 - Train Loss: 0.108727, Train Acc: 0.832051 | Val Loss: 0.127161, Val Acc: 0.711340\n",
      "Epoch 11682 - Train Loss: 0.108721, Train Acc: 0.832051 | Val Loss: 0.127156, Val Acc: 0.711340\n",
      "Epoch 11683 - Train Loss: 0.108715, Train Acc: 0.832051 | Val Loss: 0.127151, Val Acc: 0.711340\n",
      "Epoch 11684 - Train Loss: 0.108709, Train Acc: 0.832051 | Val Loss: 0.127147, Val Acc: 0.711340\n",
      "Epoch 11685 - Train Loss: 0.108703, Train Acc: 0.832051 | Val Loss: 0.127142, Val Acc: 0.711340\n",
      "Epoch 11686 - Train Loss: 0.108697, Train Acc: 0.832051 | Val Loss: 0.127137, Val Acc: 0.711340\n",
      "Epoch 11687 - Train Loss: 0.108691, Train Acc: 0.832051 | Val Loss: 0.127133, Val Acc: 0.711340\n",
      "Epoch 11688 - Train Loss: 0.108685, Train Acc: 0.832051 | Val Loss: 0.127128, Val Acc: 0.711340\n",
      "Epoch 11689 - Train Loss: 0.108679, Train Acc: 0.832051 | Val Loss: 0.127123, Val Acc: 0.711340\n",
      "Epoch 11690 - Train Loss: 0.108673, Train Acc: 0.832051 | Val Loss: 0.127119, Val Acc: 0.711340\n",
      "Epoch 11691 - Train Loss: 0.108667, Train Acc: 0.832051 | Val Loss: 0.127114, Val Acc: 0.711340\n",
      "Epoch 11692 - Train Loss: 0.108662, Train Acc: 0.832051 | Val Loss: 0.127109, Val Acc: 0.711340\n",
      "Epoch 11693 - Train Loss: 0.108656, Train Acc: 0.832051 | Val Loss: 0.127104, Val Acc: 0.711340\n",
      "Epoch 11694 - Train Loss: 0.108650, Train Acc: 0.832051 | Val Loss: 0.127100, Val Acc: 0.711340\n",
      "Epoch 11695 - Train Loss: 0.108644, Train Acc: 0.832051 | Val Loss: 0.127095, Val Acc: 0.711340\n",
      "Epoch 11696 - Train Loss: 0.108638, Train Acc: 0.832051 | Val Loss: 0.127090, Val Acc: 0.711340\n",
      "Epoch 11697 - Train Loss: 0.108632, Train Acc: 0.832051 | Val Loss: 0.127086, Val Acc: 0.711340\n",
      "Epoch 11698 - Train Loss: 0.108626, Train Acc: 0.832051 | Val Loss: 0.127081, Val Acc: 0.711340\n",
      "Epoch 11699 - Train Loss: 0.108620, Train Acc: 0.832051 | Val Loss: 0.127076, Val Acc: 0.711340\n",
      "Epoch 11700 - Train Loss: 0.108614, Train Acc: 0.832051 | Val Loss: 0.127072, Val Acc: 0.711340\n",
      "Epoch 11701 - Train Loss: 0.108608, Train Acc: 0.832051 | Val Loss: 0.127067, Val Acc: 0.711340\n",
      "Epoch 11702 - Train Loss: 0.108603, Train Acc: 0.832051 | Val Loss: 0.127062, Val Acc: 0.711340\n",
      "Epoch 11703 - Train Loss: 0.108597, Train Acc: 0.832051 | Val Loss: 0.127057, Val Acc: 0.711340\n",
      "Epoch 11704 - Train Loss: 0.108591, Train Acc: 0.832051 | Val Loss: 0.127053, Val Acc: 0.711340\n",
      "Epoch 11705 - Train Loss: 0.108585, Train Acc: 0.832051 | Val Loss: 0.127048, Val Acc: 0.711340\n",
      "Epoch 11706 - Train Loss: 0.108579, Train Acc: 0.832051 | Val Loss: 0.127043, Val Acc: 0.711340\n",
      "Epoch 11707 - Train Loss: 0.108573, Train Acc: 0.832051 | Val Loss: 0.127039, Val Acc: 0.711340\n",
      "Epoch 11708 - Train Loss: 0.108567, Train Acc: 0.832051 | Val Loss: 0.127034, Val Acc: 0.711340\n",
      "Epoch 11709 - Train Loss: 0.108561, Train Acc: 0.832051 | Val Loss: 0.127029, Val Acc: 0.711340\n",
      "Epoch 11710 - Train Loss: 0.108555, Train Acc: 0.832051 | Val Loss: 0.127025, Val Acc: 0.711340\n",
      "Epoch 11711 - Train Loss: 0.108550, Train Acc: 0.832051 | Val Loss: 0.127020, Val Acc: 0.711340\n",
      "Epoch 11712 - Train Loss: 0.108544, Train Acc: 0.832051 | Val Loss: 0.127015, Val Acc: 0.711340\n",
      "Epoch 11713 - Train Loss: 0.108538, Train Acc: 0.832051 | Val Loss: 0.127011, Val Acc: 0.711340\n",
      "Epoch 11714 - Train Loss: 0.108532, Train Acc: 0.832051 | Val Loss: 0.127006, Val Acc: 0.711340\n",
      "Epoch 11715 - Train Loss: 0.108526, Train Acc: 0.832051 | Val Loss: 0.127001, Val Acc: 0.711340\n",
      "Epoch 11716 - Train Loss: 0.108520, Train Acc: 0.832051 | Val Loss: 0.126997, Val Acc: 0.711340\n",
      "Epoch 11717 - Train Loss: 0.108514, Train Acc: 0.832051 | Val Loss: 0.126992, Val Acc: 0.711340\n",
      "Epoch 11718 - Train Loss: 0.108508, Train Acc: 0.832051 | Val Loss: 0.126987, Val Acc: 0.711340\n",
      "Epoch 11719 - Train Loss: 0.108502, Train Acc: 0.832051 | Val Loss: 0.126983, Val Acc: 0.711340\n",
      "Epoch 11720 - Train Loss: 0.108497, Train Acc: 0.832051 | Val Loss: 0.126978, Val Acc: 0.711340\n",
      "Epoch 11721 - Train Loss: 0.108491, Train Acc: 0.832051 | Val Loss: 0.126973, Val Acc: 0.711340\n",
      "Epoch 11722 - Train Loss: 0.108485, Train Acc: 0.832051 | Val Loss: 0.126969, Val Acc: 0.711340\n",
      "Epoch 11723 - Train Loss: 0.108479, Train Acc: 0.832051 | Val Loss: 0.126964, Val Acc: 0.711340\n",
      "Epoch 11724 - Train Loss: 0.108473, Train Acc: 0.832051 | Val Loss: 0.126959, Val Acc: 0.711340\n",
      "Epoch 11725 - Train Loss: 0.108467, Train Acc: 0.832051 | Val Loss: 0.126955, Val Acc: 0.711340\n",
      "Epoch 11726 - Train Loss: 0.108461, Train Acc: 0.832051 | Val Loss: 0.126950, Val Acc: 0.711340\n",
      "Epoch 11727 - Train Loss: 0.108455, Train Acc: 0.832051 | Val Loss: 0.126945, Val Acc: 0.711340\n",
      "Epoch 11728 - Train Loss: 0.108450, Train Acc: 0.832051 | Val Loss: 0.126941, Val Acc: 0.711340\n",
      "Epoch 11729 - Train Loss: 0.108444, Train Acc: 0.832051 | Val Loss: 0.126936, Val Acc: 0.711340\n",
      "Epoch 11730 - Train Loss: 0.108438, Train Acc: 0.832051 | Val Loss: 0.126931, Val Acc: 0.711340\n",
      "Epoch 11731 - Train Loss: 0.108432, Train Acc: 0.832051 | Val Loss: 0.126926, Val Acc: 0.711340\n",
      "Epoch 11732 - Train Loss: 0.108426, Train Acc: 0.832051 | Val Loss: 0.126922, Val Acc: 0.711340\n",
      "Epoch 11733 - Train Loss: 0.108420, Train Acc: 0.832051 | Val Loss: 0.126917, Val Acc: 0.711340\n",
      "Epoch 11734 - Train Loss: 0.108414, Train Acc: 0.832051 | Val Loss: 0.126913, Val Acc: 0.711340\n",
      "Epoch 11735 - Train Loss: 0.108408, Train Acc: 0.832051 | Val Loss: 0.126908, Val Acc: 0.711340\n",
      "Epoch 11736 - Train Loss: 0.108403, Train Acc: 0.832051 | Val Loss: 0.126903, Val Acc: 0.711340\n",
      "Epoch 11737 - Train Loss: 0.108397, Train Acc: 0.832051 | Val Loss: 0.126899, Val Acc: 0.711340\n",
      "Epoch 11738 - Train Loss: 0.108391, Train Acc: 0.832051 | Val Loss: 0.126894, Val Acc: 0.711340\n",
      "Epoch 11739 - Train Loss: 0.108385, Train Acc: 0.832051 | Val Loss: 0.126889, Val Acc: 0.711340\n",
      "Epoch 11740 - Train Loss: 0.108379, Train Acc: 0.832051 | Val Loss: 0.126885, Val Acc: 0.711340\n",
      "Epoch 11741 - Train Loss: 0.108373, Train Acc: 0.832051 | Val Loss: 0.126880, Val Acc: 0.711340\n",
      "Epoch 11742 - Train Loss: 0.108367, Train Acc: 0.832051 | Val Loss: 0.126875, Val Acc: 0.711340\n",
      "Epoch 11743 - Train Loss: 0.108362, Train Acc: 0.832051 | Val Loss: 0.126871, Val Acc: 0.711340\n",
      "Epoch 11744 - Train Loss: 0.108356, Train Acc: 0.832051 | Val Loss: 0.126866, Val Acc: 0.711340\n",
      "Epoch 11745 - Train Loss: 0.108350, Train Acc: 0.832051 | Val Loss: 0.126861, Val Acc: 0.711340\n",
      "Epoch 11746 - Train Loss: 0.108344, Train Acc: 0.832051 | Val Loss: 0.126857, Val Acc: 0.711340\n",
      "Epoch 11747 - Train Loss: 0.108338, Train Acc: 0.832051 | Val Loss: 0.126852, Val Acc: 0.711340\n",
      "Epoch 11748 - Train Loss: 0.108332, Train Acc: 0.832051 | Val Loss: 0.126847, Val Acc: 0.711340\n",
      "Epoch 11749 - Train Loss: 0.108326, Train Acc: 0.832051 | Val Loss: 0.126843, Val Acc: 0.711340\n",
      "Epoch 11750 - Train Loss: 0.108321, Train Acc: 0.832051 | Val Loss: 0.126838, Val Acc: 0.711340\n",
      "Epoch 11751 - Train Loss: 0.108315, Train Acc: 0.832051 | Val Loss: 0.126833, Val Acc: 0.711340\n",
      "Epoch 11752 - Train Loss: 0.108309, Train Acc: 0.832051 | Val Loss: 0.126829, Val Acc: 0.711340\n",
      "Epoch 11753 - Train Loss: 0.108303, Train Acc: 0.832051 | Val Loss: 0.126824, Val Acc: 0.711340\n",
      "Epoch 11754 - Train Loss: 0.108297, Train Acc: 0.832051 | Val Loss: 0.126819, Val Acc: 0.711340\n",
      "Epoch 11755 - Train Loss: 0.108291, Train Acc: 0.832051 | Val Loss: 0.126815, Val Acc: 0.711340\n",
      "Epoch 11756 - Train Loss: 0.108285, Train Acc: 0.832051 | Val Loss: 0.126810, Val Acc: 0.711340\n",
      "Epoch 11757 - Train Loss: 0.108280, Train Acc: 0.832051 | Val Loss: 0.126805, Val Acc: 0.711340\n",
      "Epoch 11758 - Train Loss: 0.108274, Train Acc: 0.832051 | Val Loss: 0.126801, Val Acc: 0.711340\n",
      "Epoch 11759 - Train Loss: 0.108268, Train Acc: 0.832051 | Val Loss: 0.126796, Val Acc: 0.711340\n",
      "Epoch 11760 - Train Loss: 0.108262, Train Acc: 0.832051 | Val Loss: 0.126792, Val Acc: 0.711340\n",
      "Epoch 11761 - Train Loss: 0.108256, Train Acc: 0.832051 | Val Loss: 0.126787, Val Acc: 0.711340\n",
      "Epoch 11762 - Train Loss: 0.108250, Train Acc: 0.832051 | Val Loss: 0.126782, Val Acc: 0.711340\n",
      "Epoch 11763 - Train Loss: 0.108244, Train Acc: 0.832051 | Val Loss: 0.126778, Val Acc: 0.711340\n",
      "Epoch 11764 - Train Loss: 0.108239, Train Acc: 0.832051 | Val Loss: 0.126773, Val Acc: 0.711340\n",
      "Epoch 11765 - Train Loss: 0.108233, Train Acc: 0.832051 | Val Loss: 0.126768, Val Acc: 0.711340\n",
      "Epoch 11766 - Train Loss: 0.108227, Train Acc: 0.832051 | Val Loss: 0.126764, Val Acc: 0.711340\n",
      "Epoch 11767 - Train Loss: 0.108221, Train Acc: 0.832051 | Val Loss: 0.126759, Val Acc: 0.711340\n",
      "Epoch 11768 - Train Loss: 0.108215, Train Acc: 0.832051 | Val Loss: 0.126754, Val Acc: 0.711340\n",
      "Epoch 11769 - Train Loss: 0.108209, Train Acc: 0.832051 | Val Loss: 0.126750, Val Acc: 0.711340\n",
      "Epoch 11770 - Train Loss: 0.108204, Train Acc: 0.832051 | Val Loss: 0.126745, Val Acc: 0.711340\n",
      "Epoch 11771 - Train Loss: 0.108198, Train Acc: 0.832051 | Val Loss: 0.126740, Val Acc: 0.711340\n",
      "Epoch 11772 - Train Loss: 0.108192, Train Acc: 0.832051 | Val Loss: 0.126736, Val Acc: 0.711340\n",
      "Epoch 11773 - Train Loss: 0.108186, Train Acc: 0.832051 | Val Loss: 0.126731, Val Acc: 0.711340\n",
      "Epoch 11774 - Train Loss: 0.108180, Train Acc: 0.832051 | Val Loss: 0.126727, Val Acc: 0.711340\n",
      "Epoch 11775 - Train Loss: 0.108174, Train Acc: 0.832051 | Val Loss: 0.126722, Val Acc: 0.711340\n",
      "Epoch 11776 - Train Loss: 0.108169, Train Acc: 0.832051 | Val Loss: 0.126717, Val Acc: 0.711340\n",
      "Epoch 11777 - Train Loss: 0.108163, Train Acc: 0.832051 | Val Loss: 0.126713, Val Acc: 0.711340\n",
      "Epoch 11778 - Train Loss: 0.108157, Train Acc: 0.832051 | Val Loss: 0.126708, Val Acc: 0.711340\n",
      "Epoch 11779 - Train Loss: 0.108151, Train Acc: 0.832051 | Val Loss: 0.126703, Val Acc: 0.711340\n",
      "Epoch 11780 - Train Loss: 0.108145, Train Acc: 0.832051 | Val Loss: 0.126699, Val Acc: 0.711340\n",
      "Epoch 11781 - Train Loss: 0.108139, Train Acc: 0.832051 | Val Loss: 0.126694, Val Acc: 0.711340\n",
      "Epoch 11782 - Train Loss: 0.108134, Train Acc: 0.832051 | Val Loss: 0.126690, Val Acc: 0.711340\n",
      "Epoch 11783 - Train Loss: 0.108128, Train Acc: 0.832051 | Val Loss: 0.126685, Val Acc: 0.711340\n",
      "Epoch 11784 - Train Loss: 0.108122, Train Acc: 0.832051 | Val Loss: 0.126680, Val Acc: 0.711340\n",
      "Epoch 11785 - Train Loss: 0.108116, Train Acc: 0.832051 | Val Loss: 0.126676, Val Acc: 0.711340\n",
      "Epoch 11786 - Train Loss: 0.108110, Train Acc: 0.832051 | Val Loss: 0.126671, Val Acc: 0.711340\n",
      "Epoch 11787 - Train Loss: 0.108104, Train Acc: 0.832051 | Val Loss: 0.126666, Val Acc: 0.711340\n",
      "Epoch 11788 - Train Loss: 0.108099, Train Acc: 0.832051 | Val Loss: 0.126662, Val Acc: 0.711340\n",
      "Epoch 11789 - Train Loss: 0.108093, Train Acc: 0.832051 | Val Loss: 0.126657, Val Acc: 0.711340\n",
      "Epoch 11790 - Train Loss: 0.108087, Train Acc: 0.832051 | Val Loss: 0.126653, Val Acc: 0.711340\n",
      "Epoch 11791 - Train Loss: 0.108081, Train Acc: 0.832051 | Val Loss: 0.126648, Val Acc: 0.711340\n",
      "Epoch 11792 - Train Loss: 0.108075, Train Acc: 0.832051 | Val Loss: 0.126643, Val Acc: 0.711340\n",
      "Epoch 11793 - Train Loss: 0.108069, Train Acc: 0.832051 | Val Loss: 0.126639, Val Acc: 0.711340\n",
      "Epoch 11794 - Train Loss: 0.108064, Train Acc: 0.832051 | Val Loss: 0.126634, Val Acc: 0.711340\n",
      "Epoch 11795 - Train Loss: 0.108058, Train Acc: 0.832051 | Val Loss: 0.126630, Val Acc: 0.711340\n",
      "Epoch 11796 - Train Loss: 0.108052, Train Acc: 0.832051 | Val Loss: 0.126625, Val Acc: 0.711340\n",
      "Epoch 11797 - Train Loss: 0.108046, Train Acc: 0.832051 | Val Loss: 0.126620, Val Acc: 0.711340\n",
      "Epoch 11798 - Train Loss: 0.108040, Train Acc: 0.832051 | Val Loss: 0.126616, Val Acc: 0.711340\n",
      "Epoch 11799 - Train Loss: 0.108035, Train Acc: 0.832051 | Val Loss: 0.126611, Val Acc: 0.711340\n",
      "Epoch 11800 - Train Loss: 0.108029, Train Acc: 0.832051 | Val Loss: 0.126606, Val Acc: 0.711340\n",
      "Epoch 11801 - Train Loss: 0.108023, Train Acc: 0.832051 | Val Loss: 0.126602, Val Acc: 0.711340\n",
      "Epoch 11802 - Train Loss: 0.108017, Train Acc: 0.832051 | Val Loss: 0.126597, Val Acc: 0.711340\n",
      "Epoch 11803 - Train Loss: 0.108011, Train Acc: 0.832051 | Val Loss: 0.126593, Val Acc: 0.711340\n",
      "Epoch 11804 - Train Loss: 0.108005, Train Acc: 0.832051 | Val Loss: 0.126588, Val Acc: 0.711340\n",
      "Epoch 11805 - Train Loss: 0.108000, Train Acc: 0.832051 | Val Loss: 0.126583, Val Acc: 0.711340\n",
      "Epoch 11806 - Train Loss: 0.107994, Train Acc: 0.832051 | Val Loss: 0.126579, Val Acc: 0.711340\n",
      "Epoch 11807 - Train Loss: 0.107988, Train Acc: 0.832051 | Val Loss: 0.126574, Val Acc: 0.711340\n",
      "Epoch 11808 - Train Loss: 0.107982, Train Acc: 0.832051 | Val Loss: 0.126570, Val Acc: 0.711340\n",
      "Epoch 11809 - Train Loss: 0.107976, Train Acc: 0.832051 | Val Loss: 0.126565, Val Acc: 0.711340\n",
      "Epoch 11810 - Train Loss: 0.107971, Train Acc: 0.832051 | Val Loss: 0.126560, Val Acc: 0.711340\n",
      "Epoch 11811 - Train Loss: 0.107965, Train Acc: 0.832051 | Val Loss: 0.126556, Val Acc: 0.711340\n",
      "Epoch 11812 - Train Loss: 0.107959, Train Acc: 0.832051 | Val Loss: 0.126551, Val Acc: 0.711340\n",
      "Epoch 11813 - Train Loss: 0.107953, Train Acc: 0.832051 | Val Loss: 0.126547, Val Acc: 0.711340\n",
      "Epoch 11814 - Train Loss: 0.107947, Train Acc: 0.832051 | Val Loss: 0.126542, Val Acc: 0.711340\n",
      "Epoch 11815 - Train Loss: 0.107942, Train Acc: 0.832051 | Val Loss: 0.126537, Val Acc: 0.711340\n",
      "Epoch 11816 - Train Loss: 0.107936, Train Acc: 0.832051 | Val Loss: 0.126533, Val Acc: 0.711340\n",
      "Epoch 11817 - Train Loss: 0.107930, Train Acc: 0.832051 | Val Loss: 0.126528, Val Acc: 0.711340\n",
      "Epoch 11818 - Train Loss: 0.107924, Train Acc: 0.832051 | Val Loss: 0.126524, Val Acc: 0.711340\n",
      "Epoch 11819 - Train Loss: 0.107918, Train Acc: 0.832051 | Val Loss: 0.126519, Val Acc: 0.711340\n",
      "Epoch 11820 - Train Loss: 0.107913, Train Acc: 0.832051 | Val Loss: 0.126514, Val Acc: 0.711340\n",
      "Epoch 11821 - Train Loss: 0.107907, Train Acc: 0.832051 | Val Loss: 0.126510, Val Acc: 0.711340\n",
      "Epoch 11822 - Train Loss: 0.107901, Train Acc: 0.832051 | Val Loss: 0.126505, Val Acc: 0.711340\n",
      "Epoch 11823 - Train Loss: 0.107895, Train Acc: 0.832051 | Val Loss: 0.126501, Val Acc: 0.711340\n",
      "Epoch 11824 - Train Loss: 0.107889, Train Acc: 0.832051 | Val Loss: 0.126496, Val Acc: 0.711340\n",
      "Epoch 11825 - Train Loss: 0.107884, Train Acc: 0.832051 | Val Loss: 0.126492, Val Acc: 0.711340\n",
      "Epoch 11826 - Train Loss: 0.107878, Train Acc: 0.832051 | Val Loss: 0.126487, Val Acc: 0.711340\n",
      "Epoch 11827 - Train Loss: 0.107872, Train Acc: 0.832051 | Val Loss: 0.126482, Val Acc: 0.711340\n",
      "Epoch 11828 - Train Loss: 0.107866, Train Acc: 0.832051 | Val Loss: 0.126478, Val Acc: 0.711340\n",
      "Epoch 11829 - Train Loss: 0.107860, Train Acc: 0.832051 | Val Loss: 0.126473, Val Acc: 0.721649\n",
      "Epoch 11830 - Train Loss: 0.107855, Train Acc: 0.832051 | Val Loss: 0.126469, Val Acc: 0.721649\n",
      "Epoch 11831 - Train Loss: 0.107849, Train Acc: 0.832051 | Val Loss: 0.126464, Val Acc: 0.721649\n",
      "Epoch 11832 - Train Loss: 0.107843, Train Acc: 0.832051 | Val Loss: 0.126459, Val Acc: 0.721649\n",
      "Epoch 11833 - Train Loss: 0.107837, Train Acc: 0.832051 | Val Loss: 0.126455, Val Acc: 0.721649\n",
      "Epoch 11834 - Train Loss: 0.107831, Train Acc: 0.832051 | Val Loss: 0.126450, Val Acc: 0.721649\n",
      "Epoch 11835 - Train Loss: 0.107826, Train Acc: 0.832051 | Val Loss: 0.126446, Val Acc: 0.721649\n",
      "Epoch 11836 - Train Loss: 0.107820, Train Acc: 0.832051 | Val Loss: 0.126441, Val Acc: 0.721649\n",
      "Epoch 11837 - Train Loss: 0.107814, Train Acc: 0.832051 | Val Loss: 0.126437, Val Acc: 0.721649\n",
      "Epoch 11838 - Train Loss: 0.107808, Train Acc: 0.832051 | Val Loss: 0.126432, Val Acc: 0.721649\n",
      "Epoch 11839 - Train Loss: 0.107802, Train Acc: 0.832051 | Val Loss: 0.126427, Val Acc: 0.721649\n",
      "Epoch 11840 - Train Loss: 0.107797, Train Acc: 0.832051 | Val Loss: 0.126423, Val Acc: 0.721649\n",
      "Epoch 11841 - Train Loss: 0.107791, Train Acc: 0.832051 | Val Loss: 0.126418, Val Acc: 0.721649\n",
      "Epoch 11842 - Train Loss: 0.107785, Train Acc: 0.832051 | Val Loss: 0.126414, Val Acc: 0.721649\n",
      "Epoch 11843 - Train Loss: 0.107779, Train Acc: 0.832051 | Val Loss: 0.126409, Val Acc: 0.721649\n",
      "Epoch 11844 - Train Loss: 0.107774, Train Acc: 0.832051 | Val Loss: 0.126405, Val Acc: 0.721649\n",
      "Epoch 11845 - Train Loss: 0.107768, Train Acc: 0.832051 | Val Loss: 0.126400, Val Acc: 0.721649\n",
      "Epoch 11846 - Train Loss: 0.107762, Train Acc: 0.832051 | Val Loss: 0.126395, Val Acc: 0.721649\n",
      "Epoch 11847 - Train Loss: 0.107756, Train Acc: 0.832051 | Val Loss: 0.126391, Val Acc: 0.721649\n",
      "Epoch 11848 - Train Loss: 0.107750, Train Acc: 0.832051 | Val Loss: 0.126386, Val Acc: 0.721649\n",
      "Epoch 11849 - Train Loss: 0.107745, Train Acc: 0.832051 | Val Loss: 0.126382, Val Acc: 0.721649\n",
      "Epoch 11850 - Train Loss: 0.107739, Train Acc: 0.832051 | Val Loss: 0.126377, Val Acc: 0.721649\n",
      "Epoch 11851 - Train Loss: 0.107733, Train Acc: 0.832051 | Val Loss: 0.126373, Val Acc: 0.721649\n",
      "Epoch 11852 - Train Loss: 0.107727, Train Acc: 0.832051 | Val Loss: 0.126368, Val Acc: 0.721649\n",
      "Epoch 11853 - Train Loss: 0.107722, Train Acc: 0.832051 | Val Loss: 0.126363, Val Acc: 0.721649\n",
      "Epoch 11854 - Train Loss: 0.107716, Train Acc: 0.832051 | Val Loss: 0.126359, Val Acc: 0.721649\n",
      "Epoch 11855 - Train Loss: 0.107710, Train Acc: 0.832051 | Val Loss: 0.126354, Val Acc: 0.721649\n",
      "Epoch 11856 - Train Loss: 0.107704, Train Acc: 0.832051 | Val Loss: 0.126350, Val Acc: 0.721649\n",
      "Epoch 11857 - Train Loss: 0.107698, Train Acc: 0.832051 | Val Loss: 0.126345, Val Acc: 0.721649\n",
      "Epoch 11858 - Train Loss: 0.107693, Train Acc: 0.832051 | Val Loss: 0.126341, Val Acc: 0.721649\n",
      "Epoch 11859 - Train Loss: 0.107687, Train Acc: 0.832051 | Val Loss: 0.126336, Val Acc: 0.721649\n",
      "Epoch 11860 - Train Loss: 0.107681, Train Acc: 0.832051 | Val Loss: 0.126332, Val Acc: 0.721649\n",
      "Epoch 11861 - Train Loss: 0.107675, Train Acc: 0.832051 | Val Loss: 0.126327, Val Acc: 0.721649\n",
      "Epoch 11862 - Train Loss: 0.107670, Train Acc: 0.832051 | Val Loss: 0.126322, Val Acc: 0.721649\n",
      "Epoch 11863 - Train Loss: 0.107664, Train Acc: 0.832051 | Val Loss: 0.126318, Val Acc: 0.721649\n",
      "Epoch 11864 - Train Loss: 0.107658, Train Acc: 0.832051 | Val Loss: 0.126313, Val Acc: 0.721649\n",
      "Epoch 11865 - Train Loss: 0.107652, Train Acc: 0.832051 | Val Loss: 0.126309, Val Acc: 0.721649\n",
      "Epoch 11866 - Train Loss: 0.107647, Train Acc: 0.832051 | Val Loss: 0.126304, Val Acc: 0.721649\n",
      "Epoch 11867 - Train Loss: 0.107641, Train Acc: 0.832051 | Val Loss: 0.126300, Val Acc: 0.721649\n",
      "Epoch 11868 - Train Loss: 0.107635, Train Acc: 0.832051 | Val Loss: 0.126295, Val Acc: 0.721649\n",
      "Epoch 11869 - Train Loss: 0.107629, Train Acc: 0.832051 | Val Loss: 0.126291, Val Acc: 0.721649\n",
      "Epoch 11870 - Train Loss: 0.107624, Train Acc: 0.832051 | Val Loss: 0.126286, Val Acc: 0.721649\n",
      "Epoch 11871 - Train Loss: 0.107618, Train Acc: 0.832051 | Val Loss: 0.126282, Val Acc: 0.721649\n",
      "Epoch 11872 - Train Loss: 0.107612, Train Acc: 0.832051 | Val Loss: 0.126277, Val Acc: 0.721649\n",
      "Epoch 11873 - Train Loss: 0.107606, Train Acc: 0.832051 | Val Loss: 0.126272, Val Acc: 0.721649\n",
      "Epoch 11874 - Train Loss: 0.107601, Train Acc: 0.832051 | Val Loss: 0.126268, Val Acc: 0.721649\n",
      "Epoch 11875 - Train Loss: 0.107595, Train Acc: 0.832051 | Val Loss: 0.126263, Val Acc: 0.721649\n",
      "Epoch 11876 - Train Loss: 0.107589, Train Acc: 0.832051 | Val Loss: 0.126259, Val Acc: 0.721649\n",
      "Epoch 11877 - Train Loss: 0.107583, Train Acc: 0.832051 | Val Loss: 0.126254, Val Acc: 0.721649\n",
      "Epoch 11878 - Train Loss: 0.107577, Train Acc: 0.832051 | Val Loss: 0.126250, Val Acc: 0.721649\n",
      "Epoch 11879 - Train Loss: 0.107572, Train Acc: 0.832051 | Val Loss: 0.126245, Val Acc: 0.721649\n",
      "Epoch 11880 - Train Loss: 0.107566, Train Acc: 0.832051 | Val Loss: 0.126241, Val Acc: 0.721649\n",
      "Epoch 11881 - Train Loss: 0.107560, Train Acc: 0.832051 | Val Loss: 0.126236, Val Acc: 0.721649\n",
      "Epoch 11882 - Train Loss: 0.107554, Train Acc: 0.832051 | Val Loss: 0.126232, Val Acc: 0.721649\n",
      "Epoch 11883 - Train Loss: 0.107549, Train Acc: 0.832051 | Val Loss: 0.126227, Val Acc: 0.721649\n",
      "Epoch 11884 - Train Loss: 0.107543, Train Acc: 0.832051 | Val Loss: 0.126222, Val Acc: 0.721649\n",
      "Epoch 11885 - Train Loss: 0.107537, Train Acc: 0.832051 | Val Loss: 0.126218, Val Acc: 0.721649\n",
      "Epoch 11886 - Train Loss: 0.107531, Train Acc: 0.832051 | Val Loss: 0.126213, Val Acc: 0.721649\n",
      "Epoch 11887 - Train Loss: 0.107526, Train Acc: 0.832051 | Val Loss: 0.126209, Val Acc: 0.721649\n",
      "Epoch 11888 - Train Loss: 0.107520, Train Acc: 0.832051 | Val Loss: 0.126204, Val Acc: 0.721649\n",
      "Epoch 11889 - Train Loss: 0.107514, Train Acc: 0.832051 | Val Loss: 0.126200, Val Acc: 0.721649\n",
      "Epoch 11890 - Train Loss: 0.107509, Train Acc: 0.832051 | Val Loss: 0.126195, Val Acc: 0.721649\n",
      "Epoch 11891 - Train Loss: 0.107503, Train Acc: 0.832051 | Val Loss: 0.126191, Val Acc: 0.721649\n",
      "Epoch 11892 - Train Loss: 0.107497, Train Acc: 0.832051 | Val Loss: 0.126186, Val Acc: 0.721649\n",
      "Epoch 11893 - Train Loss: 0.107491, Train Acc: 0.832051 | Val Loss: 0.126182, Val Acc: 0.721649\n",
      "Epoch 11894 - Train Loss: 0.107486, Train Acc: 0.832051 | Val Loss: 0.126177, Val Acc: 0.721649\n",
      "Epoch 11895 - Train Loss: 0.107480, Train Acc: 0.832051 | Val Loss: 0.126173, Val Acc: 0.721649\n",
      "Epoch 11896 - Train Loss: 0.107474, Train Acc: 0.832051 | Val Loss: 0.126168, Val Acc: 0.721649\n",
      "Epoch 11897 - Train Loss: 0.107468, Train Acc: 0.832051 | Val Loss: 0.126164, Val Acc: 0.721649\n",
      "Epoch 11898 - Train Loss: 0.107463, Train Acc: 0.832051 | Val Loss: 0.126159, Val Acc: 0.721649\n",
      "Epoch 11899 - Train Loss: 0.107457, Train Acc: 0.832051 | Val Loss: 0.126155, Val Acc: 0.721649\n",
      "Epoch 11900 - Train Loss: 0.107451, Train Acc: 0.832051 | Val Loss: 0.126150, Val Acc: 0.721649\n",
      "Epoch 11901 - Train Loss: 0.107445, Train Acc: 0.832051 | Val Loss: 0.126145, Val Acc: 0.721649\n",
      "Epoch 11902 - Train Loss: 0.107440, Train Acc: 0.832051 | Val Loss: 0.126141, Val Acc: 0.721649\n",
      "Epoch 11903 - Train Loss: 0.107434, Train Acc: 0.832051 | Val Loss: 0.126136, Val Acc: 0.721649\n",
      "Epoch 11904 - Train Loss: 0.107428, Train Acc: 0.832051 | Val Loss: 0.126132, Val Acc: 0.721649\n",
      "Epoch 11905 - Train Loss: 0.107422, Train Acc: 0.832051 | Val Loss: 0.126127, Val Acc: 0.721649\n",
      "Epoch 11906 - Train Loss: 0.107417, Train Acc: 0.832051 | Val Loss: 0.126123, Val Acc: 0.721649\n",
      "Epoch 11907 - Train Loss: 0.107411, Train Acc: 0.832051 | Val Loss: 0.126118, Val Acc: 0.721649\n",
      "Epoch 11908 - Train Loss: 0.107405, Train Acc: 0.832051 | Val Loss: 0.126114, Val Acc: 0.721649\n",
      "Epoch 11909 - Train Loss: 0.107400, Train Acc: 0.832051 | Val Loss: 0.126109, Val Acc: 0.721649\n",
      "Epoch 11910 - Train Loss: 0.107394, Train Acc: 0.832051 | Val Loss: 0.126105, Val Acc: 0.721649\n",
      "Epoch 11911 - Train Loss: 0.107388, Train Acc: 0.832051 | Val Loss: 0.126100, Val Acc: 0.721649\n",
      "Epoch 11912 - Train Loss: 0.107382, Train Acc: 0.832051 | Val Loss: 0.126096, Val Acc: 0.721649\n",
      "Epoch 11913 - Train Loss: 0.107377, Train Acc: 0.832051 | Val Loss: 0.126091, Val Acc: 0.721649\n",
      "Epoch 11914 - Train Loss: 0.107371, Train Acc: 0.832051 | Val Loss: 0.126087, Val Acc: 0.721649\n",
      "Epoch 11915 - Train Loss: 0.107365, Train Acc: 0.832051 | Val Loss: 0.126082, Val Acc: 0.721649\n",
      "Epoch 11916 - Train Loss: 0.107359, Train Acc: 0.832051 | Val Loss: 0.126078, Val Acc: 0.721649\n",
      "Epoch 11917 - Train Loss: 0.107354, Train Acc: 0.832051 | Val Loss: 0.126073, Val Acc: 0.721649\n",
      "Epoch 11918 - Train Loss: 0.107348, Train Acc: 0.832051 | Val Loss: 0.126069, Val Acc: 0.721649\n",
      "Epoch 11919 - Train Loss: 0.107342, Train Acc: 0.832051 | Val Loss: 0.126064, Val Acc: 0.721649\n",
      "Epoch 11920 - Train Loss: 0.107337, Train Acc: 0.832051 | Val Loss: 0.126060, Val Acc: 0.721649\n",
      "Epoch 11921 - Train Loss: 0.107331, Train Acc: 0.832051 | Val Loss: 0.126055, Val Acc: 0.721649\n",
      "Epoch 11922 - Train Loss: 0.107325, Train Acc: 0.832051 | Val Loss: 0.126051, Val Acc: 0.721649\n",
      "Epoch 11923 - Train Loss: 0.107319, Train Acc: 0.832051 | Val Loss: 0.126046, Val Acc: 0.721649\n",
      "Epoch 11924 - Train Loss: 0.107314, Train Acc: 0.832051 | Val Loss: 0.126042, Val Acc: 0.721649\n",
      "Epoch 11925 - Train Loss: 0.107308, Train Acc: 0.832051 | Val Loss: 0.126037, Val Acc: 0.721649\n",
      "Epoch 11926 - Train Loss: 0.107302, Train Acc: 0.832051 | Val Loss: 0.126033, Val Acc: 0.721649\n",
      "Epoch 11927 - Train Loss: 0.107297, Train Acc: 0.832051 | Val Loss: 0.126028, Val Acc: 0.721649\n",
      "Epoch 11928 - Train Loss: 0.107291, Train Acc: 0.832051 | Val Loss: 0.126024, Val Acc: 0.721649\n",
      "Epoch 11929 - Train Loss: 0.107285, Train Acc: 0.832051 | Val Loss: 0.126019, Val Acc: 0.721649\n",
      "Epoch 11930 - Train Loss: 0.107279, Train Acc: 0.832051 | Val Loss: 0.126015, Val Acc: 0.721649\n",
      "Epoch 11931 - Train Loss: 0.107274, Train Acc: 0.832051 | Val Loss: 0.126010, Val Acc: 0.721649\n",
      "Epoch 11932 - Train Loss: 0.107268, Train Acc: 0.832051 | Val Loss: 0.126006, Val Acc: 0.721649\n",
      "Epoch 11933 - Train Loss: 0.107262, Train Acc: 0.832051 | Val Loss: 0.126001, Val Acc: 0.721649\n",
      "Epoch 11934 - Train Loss: 0.107257, Train Acc: 0.832051 | Val Loss: 0.125997, Val Acc: 0.721649\n",
      "Epoch 11935 - Train Loss: 0.107251, Train Acc: 0.832051 | Val Loss: 0.125992, Val Acc: 0.721649\n",
      "Epoch 11936 - Train Loss: 0.107245, Train Acc: 0.832051 | Val Loss: 0.125988, Val Acc: 0.721649\n",
      "Epoch 11937 - Train Loss: 0.107239, Train Acc: 0.832051 | Val Loss: 0.125983, Val Acc: 0.721649\n",
      "Epoch 11938 - Train Loss: 0.107234, Train Acc: 0.832051 | Val Loss: 0.125979, Val Acc: 0.721649\n",
      "Epoch 11939 - Train Loss: 0.107228, Train Acc: 0.832051 | Val Loss: 0.125974, Val Acc: 0.721649\n",
      "Epoch 11940 - Train Loss: 0.107222, Train Acc: 0.832051 | Val Loss: 0.125970, Val Acc: 0.721649\n",
      "Epoch 11941 - Train Loss: 0.107217, Train Acc: 0.832051 | Val Loss: 0.125965, Val Acc: 0.721649\n",
      "Epoch 11942 - Train Loss: 0.107211, Train Acc: 0.832051 | Val Loss: 0.125961, Val Acc: 0.721649\n",
      "Epoch 11943 - Train Loss: 0.107205, Train Acc: 0.832051 | Val Loss: 0.125956, Val Acc: 0.721649\n",
      "Epoch 11944 - Train Loss: 0.107199, Train Acc: 0.832051 | Val Loss: 0.125952, Val Acc: 0.721649\n",
      "Epoch 11945 - Train Loss: 0.107194, Train Acc: 0.832051 | Val Loss: 0.125947, Val Acc: 0.721649\n",
      "Epoch 11946 - Train Loss: 0.107188, Train Acc: 0.832051 | Val Loss: 0.125943, Val Acc: 0.721649\n",
      "Epoch 11947 - Train Loss: 0.107182, Train Acc: 0.832051 | Val Loss: 0.125938, Val Acc: 0.721649\n",
      "Epoch 11948 - Train Loss: 0.107177, Train Acc: 0.832051 | Val Loss: 0.125934, Val Acc: 0.721649\n",
      "Epoch 11949 - Train Loss: 0.107171, Train Acc: 0.832051 | Val Loss: 0.125929, Val Acc: 0.721649\n",
      "Epoch 11950 - Train Loss: 0.107165, Train Acc: 0.832051 | Val Loss: 0.125925, Val Acc: 0.721649\n",
      "Epoch 11951 - Train Loss: 0.107160, Train Acc: 0.832051 | Val Loss: 0.125920, Val Acc: 0.721649\n",
      "Epoch 11952 - Train Loss: 0.107154, Train Acc: 0.832051 | Val Loss: 0.125916, Val Acc: 0.721649\n",
      "Epoch 11953 - Train Loss: 0.107148, Train Acc: 0.832051 | Val Loss: 0.125912, Val Acc: 0.721649\n",
      "Epoch 11954 - Train Loss: 0.107142, Train Acc: 0.832051 | Val Loss: 0.125907, Val Acc: 0.721649\n",
      "Epoch 11955 - Train Loss: 0.107137, Train Acc: 0.832051 | Val Loss: 0.125903, Val Acc: 0.721649\n",
      "Epoch 11956 - Train Loss: 0.107131, Train Acc: 0.832051 | Val Loss: 0.125898, Val Acc: 0.721649\n",
      "Epoch 11957 - Train Loss: 0.107125, Train Acc: 0.832051 | Val Loss: 0.125894, Val Acc: 0.721649\n",
      "Epoch 11958 - Train Loss: 0.107120, Train Acc: 0.832051 | Val Loss: 0.125889, Val Acc: 0.721649\n",
      "Epoch 11959 - Train Loss: 0.107114, Train Acc: 0.832051 | Val Loss: 0.125885, Val Acc: 0.721649\n",
      "Epoch 11960 - Train Loss: 0.107108, Train Acc: 0.832051 | Val Loss: 0.125880, Val Acc: 0.721649\n",
      "Epoch 11961 - Train Loss: 0.107103, Train Acc: 0.832051 | Val Loss: 0.125876, Val Acc: 0.721649\n",
      "Epoch 11962 - Train Loss: 0.107097, Train Acc: 0.832051 | Val Loss: 0.125871, Val Acc: 0.721649\n",
      "Epoch 11963 - Train Loss: 0.107091, Train Acc: 0.832051 | Val Loss: 0.125867, Val Acc: 0.721649\n",
      "Epoch 11964 - Train Loss: 0.107086, Train Acc: 0.832051 | Val Loss: 0.125862, Val Acc: 0.721649\n",
      "Epoch 11965 - Train Loss: 0.107080, Train Acc: 0.832051 | Val Loss: 0.125858, Val Acc: 0.721649\n",
      "Epoch 11966 - Train Loss: 0.107074, Train Acc: 0.832051 | Val Loss: 0.125853, Val Acc: 0.721649\n",
      "Epoch 11967 - Train Loss: 0.107069, Train Acc: 0.832051 | Val Loss: 0.125849, Val Acc: 0.721649\n",
      "Epoch 11968 - Train Loss: 0.107063, Train Acc: 0.832051 | Val Loss: 0.125844, Val Acc: 0.721649\n",
      "Epoch 11969 - Train Loss: 0.107057, Train Acc: 0.832051 | Val Loss: 0.125840, Val Acc: 0.721649\n",
      "Epoch 11970 - Train Loss: 0.107051, Train Acc: 0.832051 | Val Loss: 0.125836, Val Acc: 0.721649\n",
      "Epoch 11971 - Train Loss: 0.107046, Train Acc: 0.832051 | Val Loss: 0.125831, Val Acc: 0.721649\n",
      "Epoch 11972 - Train Loss: 0.107040, Train Acc: 0.832051 | Val Loss: 0.125827, Val Acc: 0.721649\n",
      "Epoch 11973 - Train Loss: 0.107034, Train Acc: 0.832051 | Val Loss: 0.125822, Val Acc: 0.721649\n",
      "Epoch 11974 - Train Loss: 0.107029, Train Acc: 0.832051 | Val Loss: 0.125818, Val Acc: 0.721649\n",
      "Epoch 11975 - Train Loss: 0.107023, Train Acc: 0.832051 | Val Loss: 0.125813, Val Acc: 0.721649\n",
      "Epoch 11976 - Train Loss: 0.107017, Train Acc: 0.832051 | Val Loss: 0.125809, Val Acc: 0.721649\n",
      "Epoch 11977 - Train Loss: 0.107012, Train Acc: 0.832051 | Val Loss: 0.125804, Val Acc: 0.721649\n",
      "Epoch 11978 - Train Loss: 0.107006, Train Acc: 0.832051 | Val Loss: 0.125800, Val Acc: 0.721649\n",
      "Epoch 11979 - Train Loss: 0.107000, Train Acc: 0.832051 | Val Loss: 0.125795, Val Acc: 0.721649\n",
      "Epoch 11980 - Train Loss: 0.106995, Train Acc: 0.832051 | Val Loss: 0.125791, Val Acc: 0.721649\n",
      "Epoch 11981 - Train Loss: 0.106989, Train Acc: 0.832051 | Val Loss: 0.125787, Val Acc: 0.721649\n",
      "Epoch 11982 - Train Loss: 0.106983, Train Acc: 0.832051 | Val Loss: 0.125782, Val Acc: 0.721649\n",
      "Epoch 11983 - Train Loss: 0.106978, Train Acc: 0.832051 | Val Loss: 0.125778, Val Acc: 0.721649\n",
      "Epoch 11984 - Train Loss: 0.106972, Train Acc: 0.832051 | Val Loss: 0.125773, Val Acc: 0.721649\n",
      "Epoch 11985 - Train Loss: 0.106966, Train Acc: 0.832051 | Val Loss: 0.125769, Val Acc: 0.721649\n",
      "Epoch 11986 - Train Loss: 0.106961, Train Acc: 0.832051 | Val Loss: 0.125764, Val Acc: 0.721649\n",
      "Epoch 11987 - Train Loss: 0.106955, Train Acc: 0.832051 | Val Loss: 0.125760, Val Acc: 0.721649\n",
      "Epoch 11988 - Train Loss: 0.106949, Train Acc: 0.832051 | Val Loss: 0.125755, Val Acc: 0.721649\n",
      "Epoch 11989 - Train Loss: 0.106944, Train Acc: 0.832051 | Val Loss: 0.125751, Val Acc: 0.721649\n",
      "Epoch 11990 - Train Loss: 0.106938, Train Acc: 0.832051 | Val Loss: 0.125747, Val Acc: 0.721649\n",
      "Epoch 11991 - Train Loss: 0.106932, Train Acc: 0.832051 | Val Loss: 0.125742, Val Acc: 0.721649\n",
      "Epoch 11992 - Train Loss: 0.106927, Train Acc: 0.832051 | Val Loss: 0.125738, Val Acc: 0.721649\n",
      "Epoch 11993 - Train Loss: 0.106921, Train Acc: 0.832051 | Val Loss: 0.125733, Val Acc: 0.721649\n",
      "Epoch 11994 - Train Loss: 0.106915, Train Acc: 0.832051 | Val Loss: 0.125729, Val Acc: 0.721649\n",
      "Epoch 11995 - Train Loss: 0.106910, Train Acc: 0.832051 | Val Loss: 0.125724, Val Acc: 0.721649\n",
      "Epoch 11996 - Train Loss: 0.106904, Train Acc: 0.832051 | Val Loss: 0.125720, Val Acc: 0.721649\n",
      "Epoch 11997 - Train Loss: 0.106898, Train Acc: 0.832051 | Val Loss: 0.125715, Val Acc: 0.721649\n",
      "Epoch 11998 - Train Loss: 0.106893, Train Acc: 0.832051 | Val Loss: 0.125711, Val Acc: 0.721649\n",
      "Epoch 11999 - Train Loss: 0.106887, Train Acc: 0.832051 | Val Loss: 0.125707, Val Acc: 0.721649\n",
      "Epoch 12000 - Train Loss: 0.106881, Train Acc: 0.832051 | Val Loss: 0.125702, Val Acc: 0.721649\n",
      "Epoch 12001 - Train Loss: 0.106876, Train Acc: 0.832051 | Val Loss: 0.125698, Val Acc: 0.721649\n",
      "Epoch 12002 - Train Loss: 0.106870, Train Acc: 0.832051 | Val Loss: 0.125693, Val Acc: 0.721649\n",
      "Epoch 12003 - Train Loss: 0.106864, Train Acc: 0.832051 | Val Loss: 0.125689, Val Acc: 0.721649\n",
      "Epoch 12004 - Train Loss: 0.106859, Train Acc: 0.832051 | Val Loss: 0.125684, Val Acc: 0.721649\n",
      "Epoch 12005 - Train Loss: 0.106853, Train Acc: 0.832051 | Val Loss: 0.125680, Val Acc: 0.721649\n",
      "Epoch 12006 - Train Loss: 0.106847, Train Acc: 0.832051 | Val Loss: 0.125676, Val Acc: 0.721649\n",
      "Epoch 12007 - Train Loss: 0.106842, Train Acc: 0.832051 | Val Loss: 0.125671, Val Acc: 0.721649\n",
      "Epoch 12008 - Train Loss: 0.106836, Train Acc: 0.832051 | Val Loss: 0.125667, Val Acc: 0.721649\n",
      "Epoch 12009 - Train Loss: 0.106830, Train Acc: 0.832051 | Val Loss: 0.125662, Val Acc: 0.721649\n",
      "Epoch 12010 - Train Loss: 0.106825, Train Acc: 0.832051 | Val Loss: 0.125658, Val Acc: 0.721649\n",
      "Epoch 12011 - Train Loss: 0.106819, Train Acc: 0.832051 | Val Loss: 0.125653, Val Acc: 0.721649\n",
      "Epoch 12012 - Train Loss: 0.106814, Train Acc: 0.832051 | Val Loss: 0.125649, Val Acc: 0.721649\n",
      "Epoch 12013 - Train Loss: 0.106808, Train Acc: 0.832051 | Val Loss: 0.125645, Val Acc: 0.721649\n",
      "Epoch 12014 - Train Loss: 0.106802, Train Acc: 0.832051 | Val Loss: 0.125640, Val Acc: 0.721649\n",
      "Epoch 12015 - Train Loss: 0.106797, Train Acc: 0.832051 | Val Loss: 0.125636, Val Acc: 0.721649\n",
      "Epoch 12016 - Train Loss: 0.106791, Train Acc: 0.832051 | Val Loss: 0.125631, Val Acc: 0.721649\n",
      "Epoch 12017 - Train Loss: 0.106785, Train Acc: 0.832051 | Val Loss: 0.125627, Val Acc: 0.721649\n",
      "Epoch 12018 - Train Loss: 0.106780, Train Acc: 0.832051 | Val Loss: 0.125622, Val Acc: 0.721649\n",
      "Epoch 12019 - Train Loss: 0.106774, Train Acc: 0.832051 | Val Loss: 0.125618, Val Acc: 0.721649\n",
      "Epoch 12020 - Train Loss: 0.106768, Train Acc: 0.832051 | Val Loss: 0.125614, Val Acc: 0.721649\n",
      "Epoch 12021 - Train Loss: 0.106763, Train Acc: 0.832051 | Val Loss: 0.125609, Val Acc: 0.721649\n",
      "Epoch 12022 - Train Loss: 0.106757, Train Acc: 0.832051 | Val Loss: 0.125605, Val Acc: 0.721649\n",
      "Epoch 12023 - Train Loss: 0.106751, Train Acc: 0.832051 | Val Loss: 0.125600, Val Acc: 0.721649\n",
      "Epoch 12024 - Train Loss: 0.106746, Train Acc: 0.832051 | Val Loss: 0.125596, Val Acc: 0.721649\n",
      "Epoch 12025 - Train Loss: 0.106740, Train Acc: 0.834615 | Val Loss: 0.125592, Val Acc: 0.721649\n",
      "Epoch 12026 - Train Loss: 0.106735, Train Acc: 0.834615 | Val Loss: 0.125587, Val Acc: 0.721649\n",
      "Epoch 12027 - Train Loss: 0.106729, Train Acc: 0.834615 | Val Loss: 0.125583, Val Acc: 0.721649\n",
      "Epoch 12028 - Train Loss: 0.106723, Train Acc: 0.834615 | Val Loss: 0.125578, Val Acc: 0.721649\n",
      "Epoch 12029 - Train Loss: 0.106718, Train Acc: 0.834615 | Val Loss: 0.125574, Val Acc: 0.721649\n",
      "Epoch 12030 - Train Loss: 0.106712, Train Acc: 0.834615 | Val Loss: 0.125570, Val Acc: 0.721649\n",
      "Epoch 12031 - Train Loss: 0.106706, Train Acc: 0.834615 | Val Loss: 0.125565, Val Acc: 0.721649\n",
      "Epoch 12032 - Train Loss: 0.106701, Train Acc: 0.834615 | Val Loss: 0.125561, Val Acc: 0.721649\n",
      "Epoch 12033 - Train Loss: 0.106695, Train Acc: 0.834615 | Val Loss: 0.125556, Val Acc: 0.721649\n",
      "Epoch 12034 - Train Loss: 0.106690, Train Acc: 0.834615 | Val Loss: 0.125552, Val Acc: 0.721649\n",
      "Epoch 12035 - Train Loss: 0.106684, Train Acc: 0.834615 | Val Loss: 0.125548, Val Acc: 0.721649\n",
      "Epoch 12036 - Train Loss: 0.106678, Train Acc: 0.834615 | Val Loss: 0.125543, Val Acc: 0.721649\n",
      "Epoch 12037 - Train Loss: 0.106673, Train Acc: 0.834615 | Val Loss: 0.125539, Val Acc: 0.721649\n",
      "Epoch 12038 - Train Loss: 0.106667, Train Acc: 0.834615 | Val Loss: 0.125534, Val Acc: 0.721649\n",
      "Epoch 12039 - Train Loss: 0.106661, Train Acc: 0.834615 | Val Loss: 0.125530, Val Acc: 0.721649\n",
      "Epoch 12040 - Train Loss: 0.106656, Train Acc: 0.834615 | Val Loss: 0.125526, Val Acc: 0.721649\n",
      "Epoch 12041 - Train Loss: 0.106650, Train Acc: 0.834615 | Val Loss: 0.125521, Val Acc: 0.721649\n",
      "Epoch 12042 - Train Loss: 0.106645, Train Acc: 0.834615 | Val Loss: 0.125517, Val Acc: 0.721649\n",
      "Epoch 12043 - Train Loss: 0.106639, Train Acc: 0.834615 | Val Loss: 0.125512, Val Acc: 0.721649\n",
      "Epoch 12044 - Train Loss: 0.106633, Train Acc: 0.834615 | Val Loss: 0.125508, Val Acc: 0.721649\n",
      "Epoch 12045 - Train Loss: 0.106628, Train Acc: 0.834615 | Val Loss: 0.125504, Val Acc: 0.721649\n",
      "Epoch 12046 - Train Loss: 0.106622, Train Acc: 0.834615 | Val Loss: 0.125499, Val Acc: 0.721649\n",
      "Epoch 12047 - Train Loss: 0.106616, Train Acc: 0.835897 | Val Loss: 0.125495, Val Acc: 0.721649\n",
      "Epoch 12048 - Train Loss: 0.106611, Train Acc: 0.835897 | Val Loss: 0.125490, Val Acc: 0.721649\n",
      "Epoch 12049 - Train Loss: 0.106605, Train Acc: 0.835897 | Val Loss: 0.125486, Val Acc: 0.721649\n",
      "Epoch 12050 - Train Loss: 0.106600, Train Acc: 0.835897 | Val Loss: 0.125482, Val Acc: 0.721649\n",
      "Epoch 12051 - Train Loss: 0.106594, Train Acc: 0.835897 | Val Loss: 0.125477, Val Acc: 0.721649\n",
      "Epoch 12052 - Train Loss: 0.106588, Train Acc: 0.835897 | Val Loss: 0.125473, Val Acc: 0.721649\n",
      "Epoch 12053 - Train Loss: 0.106583, Train Acc: 0.835897 | Val Loss: 0.125468, Val Acc: 0.721649\n",
      "Epoch 12054 - Train Loss: 0.106577, Train Acc: 0.835897 | Val Loss: 0.125464, Val Acc: 0.721649\n",
      "Epoch 12055 - Train Loss: 0.106572, Train Acc: 0.835897 | Val Loss: 0.125460, Val Acc: 0.721649\n",
      "Epoch 12056 - Train Loss: 0.106566, Train Acc: 0.835897 | Val Loss: 0.125455, Val Acc: 0.721649\n",
      "Epoch 12057 - Train Loss: 0.106560, Train Acc: 0.835897 | Val Loss: 0.125451, Val Acc: 0.721649\n",
      "Epoch 12058 - Train Loss: 0.106555, Train Acc: 0.835897 | Val Loss: 0.125447, Val Acc: 0.721649\n",
      "Epoch 12059 - Train Loss: 0.106549, Train Acc: 0.835897 | Val Loss: 0.125442, Val Acc: 0.721649\n",
      "Epoch 12060 - Train Loss: 0.106544, Train Acc: 0.835897 | Val Loss: 0.125438, Val Acc: 0.721649\n",
      "Epoch 12061 - Train Loss: 0.106538, Train Acc: 0.835897 | Val Loss: 0.125433, Val Acc: 0.721649\n",
      "Epoch 12062 - Train Loss: 0.106532, Train Acc: 0.835897 | Val Loss: 0.125429, Val Acc: 0.721649\n",
      "Epoch 12063 - Train Loss: 0.106527, Train Acc: 0.835897 | Val Loss: 0.125425, Val Acc: 0.721649\n",
      "Epoch 12064 - Train Loss: 0.106521, Train Acc: 0.835897 | Val Loss: 0.125420, Val Acc: 0.721649\n",
      "Epoch 12065 - Train Loss: 0.106515, Train Acc: 0.835897 | Val Loss: 0.125416, Val Acc: 0.721649\n",
      "Epoch 12066 - Train Loss: 0.106510, Train Acc: 0.835897 | Val Loss: 0.125412, Val Acc: 0.721649\n",
      "Epoch 12067 - Train Loss: 0.106504, Train Acc: 0.835897 | Val Loss: 0.125407, Val Acc: 0.721649\n",
      "Epoch 12068 - Train Loss: 0.106499, Train Acc: 0.835897 | Val Loss: 0.125403, Val Acc: 0.721649\n",
      "Epoch 12069 - Train Loss: 0.106493, Train Acc: 0.835897 | Val Loss: 0.125398, Val Acc: 0.721649\n",
      "Epoch 12070 - Train Loss: 0.106487, Train Acc: 0.835897 | Val Loss: 0.125394, Val Acc: 0.721649\n",
      "Epoch 12071 - Train Loss: 0.106482, Train Acc: 0.835897 | Val Loss: 0.125390, Val Acc: 0.721649\n",
      "Epoch 12072 - Train Loss: 0.106476, Train Acc: 0.835897 | Val Loss: 0.125385, Val Acc: 0.721649\n",
      "Epoch 12073 - Train Loss: 0.106471, Train Acc: 0.835897 | Val Loss: 0.125381, Val Acc: 0.721649\n",
      "Epoch 12074 - Train Loss: 0.106465, Train Acc: 0.835897 | Val Loss: 0.125377, Val Acc: 0.721649\n",
      "Epoch 12075 - Train Loss: 0.106460, Train Acc: 0.835897 | Val Loss: 0.125372, Val Acc: 0.721649\n",
      "Epoch 12076 - Train Loss: 0.106454, Train Acc: 0.835897 | Val Loss: 0.125368, Val Acc: 0.721649\n",
      "Epoch 12077 - Train Loss: 0.106448, Train Acc: 0.835897 | Val Loss: 0.125363, Val Acc: 0.721649\n",
      "Epoch 12078 - Train Loss: 0.106443, Train Acc: 0.835897 | Val Loss: 0.125359, Val Acc: 0.721649\n",
      "Epoch 12079 - Train Loss: 0.106437, Train Acc: 0.835897 | Val Loss: 0.125355, Val Acc: 0.721649\n",
      "Epoch 12080 - Train Loss: 0.106432, Train Acc: 0.835897 | Val Loss: 0.125350, Val Acc: 0.721649\n",
      "Epoch 12081 - Train Loss: 0.106426, Train Acc: 0.835897 | Val Loss: 0.125346, Val Acc: 0.721649\n",
      "Epoch 12082 - Train Loss: 0.106420, Train Acc: 0.835897 | Val Loss: 0.125342, Val Acc: 0.721649\n",
      "Epoch 12083 - Train Loss: 0.106415, Train Acc: 0.835897 | Val Loss: 0.125337, Val Acc: 0.721649\n",
      "Epoch 12084 - Train Loss: 0.106409, Train Acc: 0.835897 | Val Loss: 0.125333, Val Acc: 0.721649\n",
      "Epoch 12085 - Train Loss: 0.106404, Train Acc: 0.835897 | Val Loss: 0.125329, Val Acc: 0.721649\n",
      "Epoch 12086 - Train Loss: 0.106398, Train Acc: 0.835897 | Val Loss: 0.125324, Val Acc: 0.721649\n",
      "Epoch 12087 - Train Loss: 0.106392, Train Acc: 0.835897 | Val Loss: 0.125320, Val Acc: 0.721649\n",
      "Epoch 12088 - Train Loss: 0.106387, Train Acc: 0.835897 | Val Loss: 0.125316, Val Acc: 0.721649\n",
      "Epoch 12089 - Train Loss: 0.106381, Train Acc: 0.835897 | Val Loss: 0.125311, Val Acc: 0.721649\n",
      "Epoch 12090 - Train Loss: 0.106376, Train Acc: 0.835897 | Val Loss: 0.125307, Val Acc: 0.721649\n",
      "Epoch 12091 - Train Loss: 0.106370, Train Acc: 0.835897 | Val Loss: 0.125302, Val Acc: 0.721649\n",
      "Epoch 12092 - Train Loss: 0.106365, Train Acc: 0.835897 | Val Loss: 0.125298, Val Acc: 0.721649\n",
      "Epoch 12093 - Train Loss: 0.106359, Train Acc: 0.835897 | Val Loss: 0.125294, Val Acc: 0.721649\n",
      "Epoch 12094 - Train Loss: 0.106353, Train Acc: 0.835897 | Val Loss: 0.125289, Val Acc: 0.721649\n",
      "Epoch 12095 - Train Loss: 0.106348, Train Acc: 0.835897 | Val Loss: 0.125285, Val Acc: 0.721649\n",
      "Epoch 12096 - Train Loss: 0.106342, Train Acc: 0.835897 | Val Loss: 0.125281, Val Acc: 0.721649\n",
      "Epoch 12097 - Train Loss: 0.106337, Train Acc: 0.835897 | Val Loss: 0.125276, Val Acc: 0.721649\n",
      "Epoch 12098 - Train Loss: 0.106331, Train Acc: 0.835897 | Val Loss: 0.125272, Val Acc: 0.721649\n",
      "Epoch 12099 - Train Loss: 0.106325, Train Acc: 0.835897 | Val Loss: 0.125268, Val Acc: 0.721649\n",
      "Epoch 12100 - Train Loss: 0.106320, Train Acc: 0.835897 | Val Loss: 0.125263, Val Acc: 0.721649\n",
      "Epoch 12101 - Train Loss: 0.106314, Train Acc: 0.835897 | Val Loss: 0.125259, Val Acc: 0.721649\n",
      "Epoch 12102 - Train Loss: 0.106309, Train Acc: 0.835897 | Val Loss: 0.125255, Val Acc: 0.721649\n",
      "Epoch 12103 - Train Loss: 0.106303, Train Acc: 0.835897 | Val Loss: 0.125250, Val Acc: 0.721649\n",
      "Epoch 12104 - Train Loss: 0.106298, Train Acc: 0.835897 | Val Loss: 0.125246, Val Acc: 0.721649\n",
      "Epoch 12105 - Train Loss: 0.106292, Train Acc: 0.835897 | Val Loss: 0.125242, Val Acc: 0.721649\n",
      "Epoch 12106 - Train Loss: 0.106286, Train Acc: 0.835897 | Val Loss: 0.125237, Val Acc: 0.721649\n",
      "Epoch 12107 - Train Loss: 0.106281, Train Acc: 0.835897 | Val Loss: 0.125233, Val Acc: 0.721649\n",
      "Epoch 12108 - Train Loss: 0.106275, Train Acc: 0.835897 | Val Loss: 0.125229, Val Acc: 0.721649\n",
      "Epoch 12109 - Train Loss: 0.106270, Train Acc: 0.835897 | Val Loss: 0.125224, Val Acc: 0.721649\n",
      "Epoch 12110 - Train Loss: 0.106264, Train Acc: 0.835897 | Val Loss: 0.125220, Val Acc: 0.721649\n",
      "Epoch 12111 - Train Loss: 0.106259, Train Acc: 0.835897 | Val Loss: 0.125216, Val Acc: 0.721649\n",
      "Epoch 12112 - Train Loss: 0.106253, Train Acc: 0.835897 | Val Loss: 0.125211, Val Acc: 0.721649\n",
      "Epoch 12113 - Train Loss: 0.106247, Train Acc: 0.835897 | Val Loss: 0.125207, Val Acc: 0.721649\n",
      "Epoch 12114 - Train Loss: 0.106242, Train Acc: 0.835897 | Val Loss: 0.125203, Val Acc: 0.721649\n",
      "Epoch 12115 - Train Loss: 0.106236, Train Acc: 0.835897 | Val Loss: 0.125198, Val Acc: 0.721649\n",
      "Epoch 12116 - Train Loss: 0.106231, Train Acc: 0.835897 | Val Loss: 0.125194, Val Acc: 0.721649\n",
      "Epoch 12117 - Train Loss: 0.106225, Train Acc: 0.835897 | Val Loss: 0.125190, Val Acc: 0.721649\n",
      "Epoch 12118 - Train Loss: 0.106220, Train Acc: 0.835897 | Val Loss: 0.125185, Val Acc: 0.721649\n",
      "Epoch 12119 - Train Loss: 0.106214, Train Acc: 0.835897 | Val Loss: 0.125181, Val Acc: 0.721649\n",
      "Epoch 12120 - Train Loss: 0.106209, Train Acc: 0.835897 | Val Loss: 0.125177, Val Acc: 0.721649\n",
      "Epoch 12121 - Train Loss: 0.106203, Train Acc: 0.835897 | Val Loss: 0.125172, Val Acc: 0.721649\n",
      "Epoch 12122 - Train Loss: 0.106197, Train Acc: 0.835897 | Val Loss: 0.125168, Val Acc: 0.721649\n",
      "Epoch 12123 - Train Loss: 0.106192, Train Acc: 0.835897 | Val Loss: 0.125164, Val Acc: 0.721649\n",
      "Epoch 12124 - Train Loss: 0.106186, Train Acc: 0.835897 | Val Loss: 0.125159, Val Acc: 0.721649\n",
      "Epoch 12125 - Train Loss: 0.106181, Train Acc: 0.835897 | Val Loss: 0.125155, Val Acc: 0.721649\n",
      "Epoch 12126 - Train Loss: 0.106175, Train Acc: 0.835897 | Val Loss: 0.125151, Val Acc: 0.721649\n",
      "Epoch 12127 - Train Loss: 0.106170, Train Acc: 0.835897 | Val Loss: 0.125146, Val Acc: 0.721649\n",
      "Epoch 12128 - Train Loss: 0.106164, Train Acc: 0.835897 | Val Loss: 0.125142, Val Acc: 0.721649\n",
      "Epoch 12129 - Train Loss: 0.106159, Train Acc: 0.835897 | Val Loss: 0.125138, Val Acc: 0.721649\n",
      "Epoch 12130 - Train Loss: 0.106153, Train Acc: 0.835897 | Val Loss: 0.125133, Val Acc: 0.721649\n",
      "Epoch 12131 - Train Loss: 0.106147, Train Acc: 0.835897 | Val Loss: 0.125129, Val Acc: 0.721649\n",
      "Epoch 12132 - Train Loss: 0.106142, Train Acc: 0.835897 | Val Loss: 0.125125, Val Acc: 0.721649\n",
      "Epoch 12133 - Train Loss: 0.106136, Train Acc: 0.835897 | Val Loss: 0.125120, Val Acc: 0.721649\n",
      "Epoch 12134 - Train Loss: 0.106131, Train Acc: 0.835897 | Val Loss: 0.125116, Val Acc: 0.721649\n",
      "Epoch 12135 - Train Loss: 0.106125, Train Acc: 0.835897 | Val Loss: 0.125112, Val Acc: 0.721649\n",
      "Epoch 12136 - Train Loss: 0.106120, Train Acc: 0.835897 | Val Loss: 0.125107, Val Acc: 0.731959\n",
      "Epoch 12137 - Train Loss: 0.106114, Train Acc: 0.835897 | Val Loss: 0.125103, Val Acc: 0.731959\n",
      "Epoch 12138 - Train Loss: 0.106109, Train Acc: 0.835897 | Val Loss: 0.125099, Val Acc: 0.731959\n",
      "Epoch 12139 - Train Loss: 0.106103, Train Acc: 0.835897 | Val Loss: 0.125094, Val Acc: 0.731959\n",
      "Epoch 12140 - Train Loss: 0.106098, Train Acc: 0.835897 | Val Loss: 0.125090, Val Acc: 0.731959\n",
      "Epoch 12141 - Train Loss: 0.106092, Train Acc: 0.835897 | Val Loss: 0.125086, Val Acc: 0.731959\n",
      "Epoch 12142 - Train Loss: 0.106086, Train Acc: 0.835897 | Val Loss: 0.125081, Val Acc: 0.731959\n",
      "Epoch 12143 - Train Loss: 0.106081, Train Acc: 0.835897 | Val Loss: 0.125077, Val Acc: 0.731959\n",
      "Epoch 12144 - Train Loss: 0.106075, Train Acc: 0.835897 | Val Loss: 0.125073, Val Acc: 0.731959\n",
      "Epoch 12145 - Train Loss: 0.106070, Train Acc: 0.835897 | Val Loss: 0.125069, Val Acc: 0.731959\n",
      "Epoch 12146 - Train Loss: 0.106064, Train Acc: 0.835897 | Val Loss: 0.125064, Val Acc: 0.731959\n",
      "Epoch 12147 - Train Loss: 0.106059, Train Acc: 0.835897 | Val Loss: 0.125060, Val Acc: 0.731959\n",
      "Epoch 12148 - Train Loss: 0.106053, Train Acc: 0.835897 | Val Loss: 0.125056, Val Acc: 0.731959\n",
      "Epoch 12149 - Train Loss: 0.106048, Train Acc: 0.835897 | Val Loss: 0.125051, Val Acc: 0.731959\n",
      "Epoch 12150 - Train Loss: 0.106042, Train Acc: 0.835897 | Val Loss: 0.125047, Val Acc: 0.731959\n",
      "Epoch 12151 - Train Loss: 0.106037, Train Acc: 0.835897 | Val Loss: 0.125043, Val Acc: 0.731959\n",
      "Epoch 12152 - Train Loss: 0.106031, Train Acc: 0.835897 | Val Loss: 0.125038, Val Acc: 0.731959\n",
      "Epoch 12153 - Train Loss: 0.106026, Train Acc: 0.835897 | Val Loss: 0.125034, Val Acc: 0.731959\n",
      "Epoch 12154 - Train Loss: 0.106020, Train Acc: 0.835897 | Val Loss: 0.125030, Val Acc: 0.731959\n",
      "Epoch 12155 - Train Loss: 0.106014, Train Acc: 0.835897 | Val Loss: 0.125025, Val Acc: 0.731959\n",
      "Epoch 12156 - Train Loss: 0.106009, Train Acc: 0.835897 | Val Loss: 0.125021, Val Acc: 0.731959\n",
      "Epoch 12157 - Train Loss: 0.106003, Train Acc: 0.835897 | Val Loss: 0.125017, Val Acc: 0.731959\n",
      "Epoch 12158 - Train Loss: 0.105998, Train Acc: 0.835897 | Val Loss: 0.125012, Val Acc: 0.731959\n",
      "Epoch 12159 - Train Loss: 0.105992, Train Acc: 0.835897 | Val Loss: 0.125008, Val Acc: 0.731959\n",
      "Epoch 12160 - Train Loss: 0.105987, Train Acc: 0.835897 | Val Loss: 0.125004, Val Acc: 0.731959\n",
      "Epoch 12161 - Train Loss: 0.105981, Train Acc: 0.835897 | Val Loss: 0.125000, Val Acc: 0.731959\n",
      "Epoch 12162 - Train Loss: 0.105976, Train Acc: 0.835897 | Val Loss: 0.124995, Val Acc: 0.731959\n",
      "Epoch 12163 - Train Loss: 0.105970, Train Acc: 0.835897 | Val Loss: 0.124991, Val Acc: 0.731959\n",
      "Epoch 12164 - Train Loss: 0.105965, Train Acc: 0.835897 | Val Loss: 0.124987, Val Acc: 0.731959\n",
      "Epoch 12165 - Train Loss: 0.105959, Train Acc: 0.835897 | Val Loss: 0.124982, Val Acc: 0.731959\n",
      "Epoch 12166 - Train Loss: 0.105954, Train Acc: 0.835897 | Val Loss: 0.124978, Val Acc: 0.731959\n",
      "Epoch 12167 - Train Loss: 0.105948, Train Acc: 0.835897 | Val Loss: 0.124974, Val Acc: 0.731959\n",
      "Epoch 12168 - Train Loss: 0.105943, Train Acc: 0.835897 | Val Loss: 0.124970, Val Acc: 0.731959\n",
      "Epoch 12169 - Train Loss: 0.105937, Train Acc: 0.835897 | Val Loss: 0.124965, Val Acc: 0.731959\n",
      "Epoch 12170 - Train Loss: 0.105932, Train Acc: 0.835897 | Val Loss: 0.124961, Val Acc: 0.731959\n",
      "Epoch 12171 - Train Loss: 0.105926, Train Acc: 0.835897 | Val Loss: 0.124957, Val Acc: 0.731959\n",
      "Epoch 12172 - Train Loss: 0.105921, Train Acc: 0.835897 | Val Loss: 0.124952, Val Acc: 0.731959\n",
      "Epoch 12173 - Train Loss: 0.105915, Train Acc: 0.835897 | Val Loss: 0.124948, Val Acc: 0.731959\n",
      "Epoch 12174 - Train Loss: 0.105910, Train Acc: 0.835897 | Val Loss: 0.124944, Val Acc: 0.731959\n",
      "Epoch 12175 - Train Loss: 0.105904, Train Acc: 0.835897 | Val Loss: 0.124940, Val Acc: 0.731959\n",
      "Epoch 12176 - Train Loss: 0.105898, Train Acc: 0.835897 | Val Loss: 0.124935, Val Acc: 0.731959\n",
      "Epoch 12177 - Train Loss: 0.105893, Train Acc: 0.835897 | Val Loss: 0.124931, Val Acc: 0.731959\n",
      "Epoch 12178 - Train Loss: 0.105887, Train Acc: 0.835897 | Val Loss: 0.124927, Val Acc: 0.731959\n",
      "Epoch 12179 - Train Loss: 0.105882, Train Acc: 0.835897 | Val Loss: 0.124922, Val Acc: 0.731959\n",
      "Epoch 12180 - Train Loss: 0.105876, Train Acc: 0.835897 | Val Loss: 0.124918, Val Acc: 0.731959\n",
      "Epoch 12181 - Train Loss: 0.105871, Train Acc: 0.835897 | Val Loss: 0.124914, Val Acc: 0.731959\n",
      "Epoch 12182 - Train Loss: 0.105865, Train Acc: 0.835897 | Val Loss: 0.124910, Val Acc: 0.731959\n",
      "Epoch 12183 - Train Loss: 0.105860, Train Acc: 0.835897 | Val Loss: 0.124905, Val Acc: 0.731959\n",
      "Epoch 12184 - Train Loss: 0.105854, Train Acc: 0.835897 | Val Loss: 0.124901, Val Acc: 0.731959\n",
      "Epoch 12185 - Train Loss: 0.105849, Train Acc: 0.835897 | Val Loss: 0.124897, Val Acc: 0.731959\n",
      "Epoch 12186 - Train Loss: 0.105843, Train Acc: 0.835897 | Val Loss: 0.124892, Val Acc: 0.731959\n",
      "Epoch 12187 - Train Loss: 0.105838, Train Acc: 0.835897 | Val Loss: 0.124888, Val Acc: 0.731959\n",
      "Epoch 12188 - Train Loss: 0.105832, Train Acc: 0.835897 | Val Loss: 0.124884, Val Acc: 0.731959\n",
      "Epoch 12189 - Train Loss: 0.105827, Train Acc: 0.835897 | Val Loss: 0.124880, Val Acc: 0.731959\n",
      "Epoch 12190 - Train Loss: 0.105821, Train Acc: 0.835897 | Val Loss: 0.124875, Val Acc: 0.731959\n",
      "Epoch 12191 - Train Loss: 0.105816, Train Acc: 0.835897 | Val Loss: 0.124871, Val Acc: 0.731959\n",
      "Epoch 12192 - Train Loss: 0.105810, Train Acc: 0.835897 | Val Loss: 0.124867, Val Acc: 0.731959\n",
      "Epoch 12193 - Train Loss: 0.105805, Train Acc: 0.835897 | Val Loss: 0.124863, Val Acc: 0.731959\n",
      "Epoch 12194 - Train Loss: 0.105799, Train Acc: 0.835897 | Val Loss: 0.124858, Val Acc: 0.731959\n",
      "Epoch 12195 - Train Loss: 0.105794, Train Acc: 0.835897 | Val Loss: 0.124854, Val Acc: 0.731959\n",
      "Epoch 12196 - Train Loss: 0.105788, Train Acc: 0.835897 | Val Loss: 0.124850, Val Acc: 0.731959\n",
      "Epoch 12197 - Train Loss: 0.105783, Train Acc: 0.835897 | Val Loss: 0.124845, Val Acc: 0.731959\n",
      "Epoch 12198 - Train Loss: 0.105777, Train Acc: 0.835897 | Val Loss: 0.124841, Val Acc: 0.731959\n",
      "Epoch 12199 - Train Loss: 0.105772, Train Acc: 0.835897 | Val Loss: 0.124837, Val Acc: 0.731959\n",
      "Epoch 12200 - Train Loss: 0.105766, Train Acc: 0.835897 | Val Loss: 0.124833, Val Acc: 0.731959\n",
      "Epoch 12201 - Train Loss: 0.105761, Train Acc: 0.835897 | Val Loss: 0.124828, Val Acc: 0.731959\n",
      "Epoch 12202 - Train Loss: 0.105755, Train Acc: 0.835897 | Val Loss: 0.124824, Val Acc: 0.731959\n",
      "Epoch 12203 - Train Loss: 0.105750, Train Acc: 0.835897 | Val Loss: 0.124820, Val Acc: 0.731959\n",
      "Epoch 12204 - Train Loss: 0.105744, Train Acc: 0.835897 | Val Loss: 0.124816, Val Acc: 0.731959\n",
      "Epoch 12205 - Train Loss: 0.105739, Train Acc: 0.835897 | Val Loss: 0.124811, Val Acc: 0.731959\n",
      "Epoch 12206 - Train Loss: 0.105733, Train Acc: 0.835897 | Val Loss: 0.124807, Val Acc: 0.731959\n",
      "Epoch 12207 - Train Loss: 0.105728, Train Acc: 0.835897 | Val Loss: 0.124803, Val Acc: 0.731959\n",
      "Epoch 12208 - Train Loss: 0.105722, Train Acc: 0.835897 | Val Loss: 0.124799, Val Acc: 0.731959\n",
      "Epoch 12209 - Train Loss: 0.105717, Train Acc: 0.835897 | Val Loss: 0.124794, Val Acc: 0.731959\n",
      "Epoch 12210 - Train Loss: 0.105711, Train Acc: 0.835897 | Val Loss: 0.124790, Val Acc: 0.731959\n",
      "Epoch 12211 - Train Loss: 0.105706, Train Acc: 0.835897 | Val Loss: 0.124786, Val Acc: 0.731959\n",
      "Epoch 12212 - Train Loss: 0.105700, Train Acc: 0.835897 | Val Loss: 0.124782, Val Acc: 0.731959\n",
      "Epoch 12213 - Train Loss: 0.105695, Train Acc: 0.835897 | Val Loss: 0.124777, Val Acc: 0.731959\n",
      "Epoch 12214 - Train Loss: 0.105689, Train Acc: 0.835897 | Val Loss: 0.124773, Val Acc: 0.731959\n",
      "Epoch 12215 - Train Loss: 0.105684, Train Acc: 0.835897 | Val Loss: 0.124769, Val Acc: 0.731959\n",
      "Epoch 12216 - Train Loss: 0.105678, Train Acc: 0.835897 | Val Loss: 0.124765, Val Acc: 0.731959\n",
      "Epoch 12217 - Train Loss: 0.105673, Train Acc: 0.835897 | Val Loss: 0.124760, Val Acc: 0.731959\n",
      "Epoch 12218 - Train Loss: 0.105667, Train Acc: 0.835897 | Val Loss: 0.124756, Val Acc: 0.731959\n",
      "Epoch 12219 - Train Loss: 0.105662, Train Acc: 0.835897 | Val Loss: 0.124752, Val Acc: 0.731959\n",
      "Epoch 12220 - Train Loss: 0.105657, Train Acc: 0.835897 | Val Loss: 0.124748, Val Acc: 0.731959\n",
      "Epoch 12221 - Train Loss: 0.105651, Train Acc: 0.835897 | Val Loss: 0.124743, Val Acc: 0.731959\n",
      "Epoch 12222 - Train Loss: 0.105646, Train Acc: 0.835897 | Val Loss: 0.124739, Val Acc: 0.731959\n",
      "Epoch 12223 - Train Loss: 0.105640, Train Acc: 0.835897 | Val Loss: 0.124735, Val Acc: 0.731959\n",
      "Epoch 12224 - Train Loss: 0.105635, Train Acc: 0.835897 | Val Loss: 0.124731, Val Acc: 0.731959\n",
      "Epoch 12225 - Train Loss: 0.105629, Train Acc: 0.835897 | Val Loss: 0.124726, Val Acc: 0.731959\n",
      "Epoch 12226 - Train Loss: 0.105624, Train Acc: 0.835897 | Val Loss: 0.124722, Val Acc: 0.731959\n",
      "Epoch 12227 - Train Loss: 0.105618, Train Acc: 0.835897 | Val Loss: 0.124718, Val Acc: 0.731959\n",
      "Epoch 12228 - Train Loss: 0.105613, Train Acc: 0.835897 | Val Loss: 0.124714, Val Acc: 0.731959\n",
      "Epoch 12229 - Train Loss: 0.105607, Train Acc: 0.835897 | Val Loss: 0.124709, Val Acc: 0.731959\n",
      "Epoch 12230 - Train Loss: 0.105602, Train Acc: 0.835897 | Val Loss: 0.124705, Val Acc: 0.731959\n",
      "Epoch 12231 - Train Loss: 0.105596, Train Acc: 0.835897 | Val Loss: 0.124701, Val Acc: 0.731959\n",
      "Epoch 12232 - Train Loss: 0.105591, Train Acc: 0.835897 | Val Loss: 0.124697, Val Acc: 0.731959\n",
      "Epoch 12233 - Train Loss: 0.105585, Train Acc: 0.835897 | Val Loss: 0.124692, Val Acc: 0.731959\n",
      "Epoch 12234 - Train Loss: 0.105580, Train Acc: 0.835897 | Val Loss: 0.124688, Val Acc: 0.731959\n",
      "Epoch 12235 - Train Loss: 0.105574, Train Acc: 0.835897 | Val Loss: 0.124684, Val Acc: 0.731959\n",
      "Epoch 12236 - Train Loss: 0.105569, Train Acc: 0.835897 | Val Loss: 0.124680, Val Acc: 0.731959\n",
      "Epoch 12237 - Train Loss: 0.105563, Train Acc: 0.835897 | Val Loss: 0.124675, Val Acc: 0.731959\n",
      "Epoch 12238 - Train Loss: 0.105558, Train Acc: 0.837179 | Val Loss: 0.124671, Val Acc: 0.731959\n",
      "Epoch 12239 - Train Loss: 0.105553, Train Acc: 0.837179 | Val Loss: 0.124667, Val Acc: 0.731959\n",
      "Epoch 12240 - Train Loss: 0.105547, Train Acc: 0.837179 | Val Loss: 0.124663, Val Acc: 0.731959\n",
      "Epoch 12241 - Train Loss: 0.105542, Train Acc: 0.837179 | Val Loss: 0.124658, Val Acc: 0.731959\n",
      "Epoch 12242 - Train Loss: 0.105536, Train Acc: 0.837179 | Val Loss: 0.124654, Val Acc: 0.731959\n",
      "Epoch 12243 - Train Loss: 0.105531, Train Acc: 0.837179 | Val Loss: 0.124650, Val Acc: 0.731959\n",
      "Epoch 12244 - Train Loss: 0.105525, Train Acc: 0.837179 | Val Loss: 0.124646, Val Acc: 0.731959\n",
      "Epoch 12245 - Train Loss: 0.105520, Train Acc: 0.837179 | Val Loss: 0.124642, Val Acc: 0.731959\n",
      "Epoch 12246 - Train Loss: 0.105514, Train Acc: 0.837179 | Val Loss: 0.124637, Val Acc: 0.731959\n",
      "Epoch 12247 - Train Loss: 0.105509, Train Acc: 0.837179 | Val Loss: 0.124633, Val Acc: 0.731959\n",
      "Epoch 12248 - Train Loss: 0.105503, Train Acc: 0.837179 | Val Loss: 0.124629, Val Acc: 0.731959\n",
      "Epoch 12249 - Train Loss: 0.105498, Train Acc: 0.837179 | Val Loss: 0.124625, Val Acc: 0.731959\n",
      "Epoch 12250 - Train Loss: 0.105492, Train Acc: 0.837179 | Val Loss: 0.124620, Val Acc: 0.731959\n",
      "Epoch 12251 - Train Loss: 0.105487, Train Acc: 0.837179 | Val Loss: 0.124616, Val Acc: 0.731959\n",
      "Epoch 12252 - Train Loss: 0.105481, Train Acc: 0.837179 | Val Loss: 0.124612, Val Acc: 0.731959\n",
      "Epoch 12253 - Train Loss: 0.105476, Train Acc: 0.837179 | Val Loss: 0.124608, Val Acc: 0.731959\n",
      "Epoch 12254 - Train Loss: 0.105471, Train Acc: 0.837179 | Val Loss: 0.124604, Val Acc: 0.731959\n",
      "Epoch 12255 - Train Loss: 0.105465, Train Acc: 0.837179 | Val Loss: 0.124599, Val Acc: 0.731959\n",
      "Epoch 12256 - Train Loss: 0.105460, Train Acc: 0.837179 | Val Loss: 0.124595, Val Acc: 0.731959\n",
      "Epoch 12257 - Train Loss: 0.105454, Train Acc: 0.837179 | Val Loss: 0.124591, Val Acc: 0.731959\n",
      "Epoch 12258 - Train Loss: 0.105449, Train Acc: 0.837179 | Val Loss: 0.124587, Val Acc: 0.731959\n",
      "Epoch 12259 - Train Loss: 0.105443, Train Acc: 0.837179 | Val Loss: 0.124582, Val Acc: 0.731959\n",
      "Epoch 12260 - Train Loss: 0.105438, Train Acc: 0.837179 | Val Loss: 0.124578, Val Acc: 0.731959\n",
      "Epoch 12261 - Train Loss: 0.105432, Train Acc: 0.837179 | Val Loss: 0.124574, Val Acc: 0.731959\n",
      "Epoch 12262 - Train Loss: 0.105427, Train Acc: 0.837179 | Val Loss: 0.124570, Val Acc: 0.731959\n",
      "Epoch 12263 - Train Loss: 0.105422, Train Acc: 0.837179 | Val Loss: 0.124566, Val Acc: 0.731959\n",
      "Epoch 12264 - Train Loss: 0.105416, Train Acc: 0.837179 | Val Loss: 0.124561, Val Acc: 0.731959\n",
      "Epoch 12265 - Train Loss: 0.105411, Train Acc: 0.837179 | Val Loss: 0.124557, Val Acc: 0.731959\n",
      "Epoch 12266 - Train Loss: 0.105405, Train Acc: 0.837179 | Val Loss: 0.124553, Val Acc: 0.731959\n",
      "Epoch 12267 - Train Loss: 0.105400, Train Acc: 0.837179 | Val Loss: 0.124549, Val Acc: 0.731959\n",
      "Epoch 12268 - Train Loss: 0.105394, Train Acc: 0.837179 | Val Loss: 0.124544, Val Acc: 0.731959\n",
      "Epoch 12269 - Train Loss: 0.105389, Train Acc: 0.837179 | Val Loss: 0.124540, Val Acc: 0.731959\n",
      "Epoch 12270 - Train Loss: 0.105383, Train Acc: 0.837179 | Val Loss: 0.124536, Val Acc: 0.731959\n",
      "Epoch 12271 - Train Loss: 0.105378, Train Acc: 0.837179 | Val Loss: 0.124532, Val Acc: 0.731959\n",
      "Epoch 12272 - Train Loss: 0.105372, Train Acc: 0.837179 | Val Loss: 0.124528, Val Acc: 0.731959\n",
      "Epoch 12273 - Train Loss: 0.105367, Train Acc: 0.837179 | Val Loss: 0.124523, Val Acc: 0.731959\n",
      "Epoch 12274 - Train Loss: 0.105362, Train Acc: 0.837179 | Val Loss: 0.124519, Val Acc: 0.731959\n",
      "Epoch 12275 - Train Loss: 0.105356, Train Acc: 0.837179 | Val Loss: 0.124515, Val Acc: 0.731959\n",
      "Epoch 12276 - Train Loss: 0.105351, Train Acc: 0.837179 | Val Loss: 0.124511, Val Acc: 0.731959\n",
      "Epoch 12277 - Train Loss: 0.105345, Train Acc: 0.837179 | Val Loss: 0.124507, Val Acc: 0.731959\n",
      "Epoch 12278 - Train Loss: 0.105340, Train Acc: 0.837179 | Val Loss: 0.124502, Val Acc: 0.731959\n",
      "Epoch 12279 - Train Loss: 0.105334, Train Acc: 0.837179 | Val Loss: 0.124498, Val Acc: 0.731959\n",
      "Epoch 12280 - Train Loss: 0.105329, Train Acc: 0.837179 | Val Loss: 0.124494, Val Acc: 0.731959\n",
      "Epoch 12281 - Train Loss: 0.105324, Train Acc: 0.837179 | Val Loss: 0.124490, Val Acc: 0.731959\n",
      "Epoch 12282 - Train Loss: 0.105318, Train Acc: 0.835897 | Val Loss: 0.124486, Val Acc: 0.731959\n",
      "Epoch 12283 - Train Loss: 0.105313, Train Acc: 0.835897 | Val Loss: 0.124481, Val Acc: 0.731959\n",
      "Epoch 12284 - Train Loss: 0.105307, Train Acc: 0.835897 | Val Loss: 0.124477, Val Acc: 0.731959\n",
      "Epoch 12285 - Train Loss: 0.105302, Train Acc: 0.835897 | Val Loss: 0.124473, Val Acc: 0.731959\n",
      "Epoch 12286 - Train Loss: 0.105296, Train Acc: 0.835897 | Val Loss: 0.124469, Val Acc: 0.731959\n",
      "Epoch 12287 - Train Loss: 0.105291, Train Acc: 0.835897 | Val Loss: 0.124465, Val Acc: 0.731959\n",
      "Epoch 12288 - Train Loss: 0.105285, Train Acc: 0.835897 | Val Loss: 0.124460, Val Acc: 0.731959\n",
      "Epoch 12289 - Train Loss: 0.105280, Train Acc: 0.835897 | Val Loss: 0.124456, Val Acc: 0.731959\n",
      "Epoch 12290 - Train Loss: 0.105275, Train Acc: 0.835897 | Val Loss: 0.124452, Val Acc: 0.731959\n",
      "Epoch 12291 - Train Loss: 0.105269, Train Acc: 0.835897 | Val Loss: 0.124448, Val Acc: 0.731959\n",
      "Epoch 12292 - Train Loss: 0.105264, Train Acc: 0.835897 | Val Loss: 0.124444, Val Acc: 0.731959\n",
      "Epoch 12293 - Train Loss: 0.105258, Train Acc: 0.835897 | Val Loss: 0.124439, Val Acc: 0.731959\n",
      "Epoch 12294 - Train Loss: 0.105253, Train Acc: 0.835897 | Val Loss: 0.124435, Val Acc: 0.731959\n",
      "Epoch 12295 - Train Loss: 0.105247, Train Acc: 0.835897 | Val Loss: 0.124431, Val Acc: 0.731959\n",
      "Epoch 12296 - Train Loss: 0.105242, Train Acc: 0.835897 | Val Loss: 0.124427, Val Acc: 0.731959\n",
      "Epoch 12297 - Train Loss: 0.105237, Train Acc: 0.835897 | Val Loss: 0.124423, Val Acc: 0.731959\n",
      "Epoch 12298 - Train Loss: 0.105231, Train Acc: 0.835897 | Val Loss: 0.124419, Val Acc: 0.731959\n",
      "Epoch 12299 - Train Loss: 0.105226, Train Acc: 0.835897 | Val Loss: 0.124414, Val Acc: 0.731959\n",
      "Epoch 12300 - Train Loss: 0.105220, Train Acc: 0.835897 | Val Loss: 0.124410, Val Acc: 0.731959\n",
      "Epoch 12301 - Train Loss: 0.105215, Train Acc: 0.835897 | Val Loss: 0.124406, Val Acc: 0.731959\n",
      "Epoch 12302 - Train Loss: 0.105210, Train Acc: 0.835897 | Val Loss: 0.124402, Val Acc: 0.731959\n",
      "Epoch 12303 - Train Loss: 0.105204, Train Acc: 0.835897 | Val Loss: 0.124398, Val Acc: 0.731959\n",
      "Epoch 12304 - Train Loss: 0.105199, Train Acc: 0.835897 | Val Loss: 0.124393, Val Acc: 0.731959\n",
      "Epoch 12305 - Train Loss: 0.105193, Train Acc: 0.835897 | Val Loss: 0.124389, Val Acc: 0.731959\n",
      "Epoch 12306 - Train Loss: 0.105188, Train Acc: 0.835897 | Val Loss: 0.124385, Val Acc: 0.731959\n",
      "Epoch 12307 - Train Loss: 0.105182, Train Acc: 0.835897 | Val Loss: 0.124381, Val Acc: 0.731959\n",
      "Epoch 12308 - Train Loss: 0.105177, Train Acc: 0.835897 | Val Loss: 0.124377, Val Acc: 0.731959\n",
      "Epoch 12309 - Train Loss: 0.105172, Train Acc: 0.835897 | Val Loss: 0.124372, Val Acc: 0.731959\n",
      "Epoch 12310 - Train Loss: 0.105166, Train Acc: 0.835897 | Val Loss: 0.124368, Val Acc: 0.731959\n",
      "Epoch 12311 - Train Loss: 0.105161, Train Acc: 0.835897 | Val Loss: 0.124364, Val Acc: 0.731959\n",
      "Epoch 12312 - Train Loss: 0.105155, Train Acc: 0.835897 | Val Loss: 0.124360, Val Acc: 0.731959\n",
      "Epoch 12313 - Train Loss: 0.105150, Train Acc: 0.835897 | Val Loss: 0.124356, Val Acc: 0.731959\n",
      "Epoch 12314 - Train Loss: 0.105145, Train Acc: 0.835897 | Val Loss: 0.124352, Val Acc: 0.731959\n",
      "Epoch 12315 - Train Loss: 0.105139, Train Acc: 0.835897 | Val Loss: 0.124347, Val Acc: 0.731959\n",
      "Epoch 12316 - Train Loss: 0.105134, Train Acc: 0.835897 | Val Loss: 0.124343, Val Acc: 0.731959\n",
      "Epoch 12317 - Train Loss: 0.105128, Train Acc: 0.835897 | Val Loss: 0.124339, Val Acc: 0.731959\n",
      "Epoch 12318 - Train Loss: 0.105123, Train Acc: 0.835897 | Val Loss: 0.124335, Val Acc: 0.731959\n",
      "Epoch 12319 - Train Loss: 0.105117, Train Acc: 0.835897 | Val Loss: 0.124331, Val Acc: 0.731959\n",
      "Epoch 12320 - Train Loss: 0.105112, Train Acc: 0.835897 | Val Loss: 0.124327, Val Acc: 0.731959\n",
      "Epoch 12321 - Train Loss: 0.105107, Train Acc: 0.835897 | Val Loss: 0.124322, Val Acc: 0.731959\n",
      "Epoch 12322 - Train Loss: 0.105101, Train Acc: 0.835897 | Val Loss: 0.124318, Val Acc: 0.731959\n",
      "Epoch 12323 - Train Loss: 0.105096, Train Acc: 0.835897 | Val Loss: 0.124314, Val Acc: 0.731959\n",
      "Epoch 12324 - Train Loss: 0.105090, Train Acc: 0.835897 | Val Loss: 0.124310, Val Acc: 0.731959\n",
      "Epoch 12325 - Train Loss: 0.105085, Train Acc: 0.835897 | Val Loss: 0.124306, Val Acc: 0.731959\n",
      "Epoch 12326 - Train Loss: 0.105080, Train Acc: 0.835897 | Val Loss: 0.124302, Val Acc: 0.731959\n",
      "Epoch 12327 - Train Loss: 0.105074, Train Acc: 0.835897 | Val Loss: 0.124297, Val Acc: 0.731959\n",
      "Epoch 12328 - Train Loss: 0.105069, Train Acc: 0.835897 | Val Loss: 0.124293, Val Acc: 0.731959\n",
      "Epoch 12329 - Train Loss: 0.105063, Train Acc: 0.835897 | Val Loss: 0.124289, Val Acc: 0.731959\n",
      "Epoch 12330 - Train Loss: 0.105058, Train Acc: 0.835897 | Val Loss: 0.124285, Val Acc: 0.731959\n",
      "Epoch 12331 - Train Loss: 0.105053, Train Acc: 0.835897 | Val Loss: 0.124281, Val Acc: 0.731959\n",
      "Epoch 12332 - Train Loss: 0.105047, Train Acc: 0.835897 | Val Loss: 0.124277, Val Acc: 0.731959\n",
      "Epoch 12333 - Train Loss: 0.105042, Train Acc: 0.835897 | Val Loss: 0.124272, Val Acc: 0.731959\n",
      "Epoch 12334 - Train Loss: 0.105036, Train Acc: 0.835897 | Val Loss: 0.124268, Val Acc: 0.731959\n",
      "Epoch 12335 - Train Loss: 0.105031, Train Acc: 0.835897 | Val Loss: 0.124264, Val Acc: 0.731959\n",
      "Epoch 12336 - Train Loss: 0.105026, Train Acc: 0.835897 | Val Loss: 0.124260, Val Acc: 0.731959\n",
      "Epoch 12337 - Train Loss: 0.105020, Train Acc: 0.835897 | Val Loss: 0.124256, Val Acc: 0.731959\n",
      "Epoch 12338 - Train Loss: 0.105015, Train Acc: 0.835897 | Val Loss: 0.124252, Val Acc: 0.731959\n",
      "Epoch 12339 - Train Loss: 0.105009, Train Acc: 0.835897 | Val Loss: 0.124247, Val Acc: 0.731959\n",
      "Epoch 12340 - Train Loss: 0.105004, Train Acc: 0.835897 | Val Loss: 0.124243, Val Acc: 0.731959\n",
      "Epoch 12341 - Train Loss: 0.104999, Train Acc: 0.835897 | Val Loss: 0.124239, Val Acc: 0.731959\n",
      "Epoch 12342 - Train Loss: 0.104993, Train Acc: 0.835897 | Val Loss: 0.124235, Val Acc: 0.731959\n",
      "Epoch 12343 - Train Loss: 0.104988, Train Acc: 0.835897 | Val Loss: 0.124231, Val Acc: 0.731959\n",
      "Epoch 12344 - Train Loss: 0.104983, Train Acc: 0.835897 | Val Loss: 0.124227, Val Acc: 0.731959\n",
      "Epoch 12345 - Train Loss: 0.104977, Train Acc: 0.835897 | Val Loss: 0.124223, Val Acc: 0.731959\n",
      "Epoch 12346 - Train Loss: 0.104972, Train Acc: 0.835897 | Val Loss: 0.124218, Val Acc: 0.731959\n",
      "Epoch 12347 - Train Loss: 0.104966, Train Acc: 0.835897 | Val Loss: 0.124214, Val Acc: 0.731959\n",
      "Epoch 12348 - Train Loss: 0.104961, Train Acc: 0.835897 | Val Loss: 0.124210, Val Acc: 0.731959\n",
      "Epoch 12349 - Train Loss: 0.104956, Train Acc: 0.835897 | Val Loss: 0.124206, Val Acc: 0.731959\n",
      "Epoch 12350 - Train Loss: 0.104950, Train Acc: 0.835897 | Val Loss: 0.124202, Val Acc: 0.742268\n",
      "Epoch 12351 - Train Loss: 0.104945, Train Acc: 0.835897 | Val Loss: 0.124198, Val Acc: 0.742268\n",
      "Epoch 12352 - Train Loss: 0.104939, Train Acc: 0.835897 | Val Loss: 0.124193, Val Acc: 0.742268\n",
      "Epoch 12353 - Train Loss: 0.104934, Train Acc: 0.835897 | Val Loss: 0.124189, Val Acc: 0.742268\n",
      "Epoch 12354 - Train Loss: 0.104929, Train Acc: 0.835897 | Val Loss: 0.124185, Val Acc: 0.742268\n",
      "Epoch 12355 - Train Loss: 0.104923, Train Acc: 0.835897 | Val Loss: 0.124181, Val Acc: 0.742268\n",
      "Epoch 12356 - Train Loss: 0.104918, Train Acc: 0.835897 | Val Loss: 0.124177, Val Acc: 0.742268\n",
      "Epoch 12357 - Train Loss: 0.104912, Train Acc: 0.837179 | Val Loss: 0.124173, Val Acc: 0.742268\n",
      "Epoch 12358 - Train Loss: 0.104907, Train Acc: 0.837179 | Val Loss: 0.124169, Val Acc: 0.742268\n",
      "Epoch 12359 - Train Loss: 0.104902, Train Acc: 0.837179 | Val Loss: 0.124164, Val Acc: 0.742268\n",
      "Epoch 12360 - Train Loss: 0.104896, Train Acc: 0.837179 | Val Loss: 0.124160, Val Acc: 0.742268\n",
      "Epoch 12361 - Train Loss: 0.104891, Train Acc: 0.837179 | Val Loss: 0.124156, Val Acc: 0.742268\n",
      "Epoch 12362 - Train Loss: 0.104886, Train Acc: 0.837179 | Val Loss: 0.124152, Val Acc: 0.742268\n",
      "Epoch 12363 - Train Loss: 0.104880, Train Acc: 0.837179 | Val Loss: 0.124148, Val Acc: 0.742268\n",
      "Epoch 12364 - Train Loss: 0.104875, Train Acc: 0.837179 | Val Loss: 0.124144, Val Acc: 0.742268\n",
      "Epoch 12365 - Train Loss: 0.104869, Train Acc: 0.837179 | Val Loss: 0.124140, Val Acc: 0.742268\n",
      "Epoch 12366 - Train Loss: 0.104864, Train Acc: 0.837179 | Val Loss: 0.124136, Val Acc: 0.742268\n",
      "Epoch 12367 - Train Loss: 0.104859, Train Acc: 0.837179 | Val Loss: 0.124131, Val Acc: 0.742268\n",
      "Epoch 12368 - Train Loss: 0.104853, Train Acc: 0.837179 | Val Loss: 0.124127, Val Acc: 0.742268\n",
      "Epoch 12369 - Train Loss: 0.104848, Train Acc: 0.837179 | Val Loss: 0.124123, Val Acc: 0.742268\n",
      "Epoch 12370 - Train Loss: 0.104843, Train Acc: 0.837179 | Val Loss: 0.124119, Val Acc: 0.742268\n",
      "Epoch 12371 - Train Loss: 0.104837, Train Acc: 0.837179 | Val Loss: 0.124115, Val Acc: 0.742268\n",
      "Epoch 12372 - Train Loss: 0.104832, Train Acc: 0.837179 | Val Loss: 0.124111, Val Acc: 0.742268\n",
      "Epoch 12373 - Train Loss: 0.104826, Train Acc: 0.837179 | Val Loss: 0.124107, Val Acc: 0.742268\n",
      "Epoch 12374 - Train Loss: 0.104821, Train Acc: 0.837179 | Val Loss: 0.124102, Val Acc: 0.742268\n",
      "Epoch 12375 - Train Loss: 0.104816, Train Acc: 0.837179 | Val Loss: 0.124098, Val Acc: 0.742268\n",
      "Epoch 12376 - Train Loss: 0.104810, Train Acc: 0.837179 | Val Loss: 0.124094, Val Acc: 0.742268\n",
      "Epoch 12377 - Train Loss: 0.104805, Train Acc: 0.837179 | Val Loss: 0.124090, Val Acc: 0.742268\n",
      "Epoch 12378 - Train Loss: 0.104800, Train Acc: 0.837179 | Val Loss: 0.124086, Val Acc: 0.742268\n",
      "Epoch 12379 - Train Loss: 0.104794, Train Acc: 0.837179 | Val Loss: 0.124082, Val Acc: 0.742268\n",
      "Epoch 12380 - Train Loss: 0.104789, Train Acc: 0.837179 | Val Loss: 0.124078, Val Acc: 0.742268\n",
      "Epoch 12381 - Train Loss: 0.104784, Train Acc: 0.837179 | Val Loss: 0.124074, Val Acc: 0.742268\n",
      "Epoch 12382 - Train Loss: 0.104778, Train Acc: 0.837179 | Val Loss: 0.124069, Val Acc: 0.742268\n",
      "Epoch 12383 - Train Loss: 0.104773, Train Acc: 0.837179 | Val Loss: 0.124065, Val Acc: 0.742268\n",
      "Epoch 12384 - Train Loss: 0.104767, Train Acc: 0.837179 | Val Loss: 0.124061, Val Acc: 0.742268\n",
      "Epoch 12385 - Train Loss: 0.104762, Train Acc: 0.837179 | Val Loss: 0.124057, Val Acc: 0.742268\n",
      "Epoch 12386 - Train Loss: 0.104757, Train Acc: 0.837179 | Val Loss: 0.124053, Val Acc: 0.742268\n",
      "Epoch 12387 - Train Loss: 0.104751, Train Acc: 0.837179 | Val Loss: 0.124049, Val Acc: 0.742268\n",
      "Epoch 12388 - Train Loss: 0.104746, Train Acc: 0.837179 | Val Loss: 0.124045, Val Acc: 0.742268\n",
      "Epoch 12389 - Train Loss: 0.104741, Train Acc: 0.837179 | Val Loss: 0.124041, Val Acc: 0.742268\n",
      "Epoch 12390 - Train Loss: 0.104735, Train Acc: 0.837179 | Val Loss: 0.124037, Val Acc: 0.742268\n",
      "Epoch 12391 - Train Loss: 0.104730, Train Acc: 0.837179 | Val Loss: 0.124032, Val Acc: 0.742268\n",
      "Epoch 12392 - Train Loss: 0.104725, Train Acc: 0.837179 | Val Loss: 0.124028, Val Acc: 0.742268\n",
      "Epoch 12393 - Train Loss: 0.104719, Train Acc: 0.837179 | Val Loss: 0.124024, Val Acc: 0.742268\n",
      "Epoch 12394 - Train Loss: 0.104714, Train Acc: 0.837179 | Val Loss: 0.124020, Val Acc: 0.742268\n",
      "Epoch 12395 - Train Loss: 0.104709, Train Acc: 0.837179 | Val Loss: 0.124016, Val Acc: 0.742268\n",
      "Epoch 12396 - Train Loss: 0.104703, Train Acc: 0.837179 | Val Loss: 0.124012, Val Acc: 0.742268\n",
      "Epoch 12397 - Train Loss: 0.104698, Train Acc: 0.837179 | Val Loss: 0.124008, Val Acc: 0.742268\n",
      "Epoch 12398 - Train Loss: 0.104693, Train Acc: 0.837179 | Val Loss: 0.124004, Val Acc: 0.742268\n",
      "Epoch 12399 - Train Loss: 0.104687, Train Acc: 0.837179 | Val Loss: 0.123999, Val Acc: 0.742268\n",
      "Epoch 12400 - Train Loss: 0.104682, Train Acc: 0.837179 | Val Loss: 0.123995, Val Acc: 0.742268\n",
      "Epoch 12401 - Train Loss: 0.104676, Train Acc: 0.837179 | Val Loss: 0.123991, Val Acc: 0.742268\n",
      "Epoch 12402 - Train Loss: 0.104671, Train Acc: 0.837179 | Val Loss: 0.123987, Val Acc: 0.742268\n",
      "Epoch 12403 - Train Loss: 0.104666, Train Acc: 0.837179 | Val Loss: 0.123983, Val Acc: 0.742268\n",
      "Epoch 12404 - Train Loss: 0.104660, Train Acc: 0.837179 | Val Loss: 0.123979, Val Acc: 0.742268\n",
      "Epoch 12405 - Train Loss: 0.104655, Train Acc: 0.837179 | Val Loss: 0.123975, Val Acc: 0.742268\n",
      "Epoch 12406 - Train Loss: 0.104650, Train Acc: 0.837179 | Val Loss: 0.123971, Val Acc: 0.742268\n",
      "Epoch 12407 - Train Loss: 0.104644, Train Acc: 0.837179 | Val Loss: 0.123967, Val Acc: 0.742268\n",
      "Epoch 12408 - Train Loss: 0.104639, Train Acc: 0.837179 | Val Loss: 0.123963, Val Acc: 0.742268\n",
      "Epoch 12409 - Train Loss: 0.104634, Train Acc: 0.837179 | Val Loss: 0.123958, Val Acc: 0.742268\n",
      "Epoch 12410 - Train Loss: 0.104628, Train Acc: 0.837179 | Val Loss: 0.123954, Val Acc: 0.742268\n",
      "Epoch 12411 - Train Loss: 0.104623, Train Acc: 0.837179 | Val Loss: 0.123950, Val Acc: 0.742268\n",
      "Epoch 12412 - Train Loss: 0.104618, Train Acc: 0.837179 | Val Loss: 0.123946, Val Acc: 0.742268\n",
      "Epoch 12413 - Train Loss: 0.104612, Train Acc: 0.837179 | Val Loss: 0.123942, Val Acc: 0.742268\n",
      "Epoch 12414 - Train Loss: 0.104607, Train Acc: 0.837179 | Val Loss: 0.123938, Val Acc: 0.742268\n",
      "Epoch 12415 - Train Loss: 0.104602, Train Acc: 0.837179 | Val Loss: 0.123934, Val Acc: 0.742268\n",
      "Epoch 12416 - Train Loss: 0.104596, Train Acc: 0.837179 | Val Loss: 0.123930, Val Acc: 0.742268\n",
      "Epoch 12417 - Train Loss: 0.104591, Train Acc: 0.837179 | Val Loss: 0.123926, Val Acc: 0.742268\n",
      "Epoch 12418 - Train Loss: 0.104586, Train Acc: 0.837179 | Val Loss: 0.123922, Val Acc: 0.742268\n",
      "Epoch 12419 - Train Loss: 0.104580, Train Acc: 0.837179 | Val Loss: 0.123917, Val Acc: 0.742268\n",
      "Epoch 12420 - Train Loss: 0.104575, Train Acc: 0.837179 | Val Loss: 0.123913, Val Acc: 0.742268\n",
      "Epoch 12421 - Train Loss: 0.104570, Train Acc: 0.837179 | Val Loss: 0.123909, Val Acc: 0.742268\n",
      "Epoch 12422 - Train Loss: 0.104564, Train Acc: 0.837179 | Val Loss: 0.123905, Val Acc: 0.742268\n",
      "Epoch 12423 - Train Loss: 0.104559, Train Acc: 0.837179 | Val Loss: 0.123901, Val Acc: 0.742268\n",
      "Epoch 12424 - Train Loss: 0.104554, Train Acc: 0.837179 | Val Loss: 0.123897, Val Acc: 0.742268\n",
      "Epoch 12425 - Train Loss: 0.104548, Train Acc: 0.837179 | Val Loss: 0.123893, Val Acc: 0.742268\n",
      "Epoch 12426 - Train Loss: 0.104543, Train Acc: 0.837179 | Val Loss: 0.123889, Val Acc: 0.742268\n",
      "Epoch 12427 - Train Loss: 0.104538, Train Acc: 0.837179 | Val Loss: 0.123885, Val Acc: 0.742268\n",
      "Epoch 12428 - Train Loss: 0.104532, Train Acc: 0.837179 | Val Loss: 0.123881, Val Acc: 0.742268\n",
      "Epoch 12429 - Train Loss: 0.104527, Train Acc: 0.837179 | Val Loss: 0.123877, Val Acc: 0.742268\n",
      "Epoch 12430 - Train Loss: 0.104522, Train Acc: 0.837179 | Val Loss: 0.123872, Val Acc: 0.742268\n",
      "Epoch 12431 - Train Loss: 0.104516, Train Acc: 0.837179 | Val Loss: 0.123868, Val Acc: 0.742268\n",
      "Epoch 12432 - Train Loss: 0.104511, Train Acc: 0.837179 | Val Loss: 0.123864, Val Acc: 0.742268\n",
      "Epoch 12433 - Train Loss: 0.104506, Train Acc: 0.837179 | Val Loss: 0.123860, Val Acc: 0.742268\n",
      "Epoch 12434 - Train Loss: 0.104500, Train Acc: 0.837179 | Val Loss: 0.123856, Val Acc: 0.742268\n",
      "Epoch 12435 - Train Loss: 0.104495, Train Acc: 0.837179 | Val Loss: 0.123852, Val Acc: 0.742268\n",
      "Epoch 12436 - Train Loss: 0.104490, Train Acc: 0.837179 | Val Loss: 0.123848, Val Acc: 0.742268\n",
      "Epoch 12437 - Train Loss: 0.104484, Train Acc: 0.837179 | Val Loss: 0.123844, Val Acc: 0.742268\n",
      "Epoch 12438 - Train Loss: 0.104479, Train Acc: 0.837179 | Val Loss: 0.123840, Val Acc: 0.742268\n",
      "Epoch 12439 - Train Loss: 0.104474, Train Acc: 0.837179 | Val Loss: 0.123836, Val Acc: 0.742268\n",
      "Epoch 12440 - Train Loss: 0.104468, Train Acc: 0.837179 | Val Loss: 0.123832, Val Acc: 0.742268\n",
      "Epoch 12441 - Train Loss: 0.104463, Train Acc: 0.837179 | Val Loss: 0.123828, Val Acc: 0.742268\n",
      "Epoch 12442 - Train Loss: 0.104458, Train Acc: 0.837179 | Val Loss: 0.123823, Val Acc: 0.742268\n",
      "Epoch 12443 - Train Loss: 0.104452, Train Acc: 0.837179 | Val Loss: 0.123819, Val Acc: 0.742268\n",
      "Epoch 12444 - Train Loss: 0.104447, Train Acc: 0.837179 | Val Loss: 0.123815, Val Acc: 0.742268\n",
      "Epoch 12445 - Train Loss: 0.104442, Train Acc: 0.837179 | Val Loss: 0.123811, Val Acc: 0.742268\n",
      "Epoch 12446 - Train Loss: 0.104437, Train Acc: 0.837179 | Val Loss: 0.123807, Val Acc: 0.742268\n",
      "Epoch 12447 - Train Loss: 0.104431, Train Acc: 0.837179 | Val Loss: 0.123803, Val Acc: 0.742268\n",
      "Epoch 12448 - Train Loss: 0.104426, Train Acc: 0.837179 | Val Loss: 0.123799, Val Acc: 0.742268\n",
      "Epoch 12449 - Train Loss: 0.104421, Train Acc: 0.837179 | Val Loss: 0.123795, Val Acc: 0.742268\n",
      "Epoch 12450 - Train Loss: 0.104415, Train Acc: 0.837179 | Val Loss: 0.123791, Val Acc: 0.742268\n",
      "Epoch 12451 - Train Loss: 0.104410, Train Acc: 0.837179 | Val Loss: 0.123787, Val Acc: 0.742268\n",
      "Epoch 12452 - Train Loss: 0.104405, Train Acc: 0.837179 | Val Loss: 0.123783, Val Acc: 0.742268\n",
      "Epoch 12453 - Train Loss: 0.104399, Train Acc: 0.837179 | Val Loss: 0.123779, Val Acc: 0.742268\n",
      "Epoch 12454 - Train Loss: 0.104394, Train Acc: 0.837179 | Val Loss: 0.123775, Val Acc: 0.742268\n",
      "Epoch 12455 - Train Loss: 0.104389, Train Acc: 0.837179 | Val Loss: 0.123770, Val Acc: 0.742268\n",
      "Epoch 12456 - Train Loss: 0.104383, Train Acc: 0.837179 | Val Loss: 0.123766, Val Acc: 0.742268\n",
      "Epoch 12457 - Train Loss: 0.104378, Train Acc: 0.837179 | Val Loss: 0.123762, Val Acc: 0.742268\n",
      "Epoch 12458 - Train Loss: 0.104373, Train Acc: 0.837179 | Val Loss: 0.123758, Val Acc: 0.742268\n",
      "Epoch 12459 - Train Loss: 0.104367, Train Acc: 0.837179 | Val Loss: 0.123754, Val Acc: 0.742268\n",
      "Epoch 12460 - Train Loss: 0.104362, Train Acc: 0.837179 | Val Loss: 0.123750, Val Acc: 0.742268\n",
      "Epoch 12461 - Train Loss: 0.104357, Train Acc: 0.837179 | Val Loss: 0.123746, Val Acc: 0.742268\n",
      "Epoch 12462 - Train Loss: 0.104352, Train Acc: 0.837179 | Val Loss: 0.123742, Val Acc: 0.742268\n",
      "Epoch 12463 - Train Loss: 0.104346, Train Acc: 0.837179 | Val Loss: 0.123738, Val Acc: 0.742268\n",
      "Epoch 12464 - Train Loss: 0.104341, Train Acc: 0.837179 | Val Loss: 0.123734, Val Acc: 0.742268\n",
      "Epoch 12465 - Train Loss: 0.104336, Train Acc: 0.837179 | Val Loss: 0.123730, Val Acc: 0.742268\n",
      "Epoch 12466 - Train Loss: 0.104330, Train Acc: 0.837179 | Val Loss: 0.123726, Val Acc: 0.742268\n",
      "Epoch 12467 - Train Loss: 0.104325, Train Acc: 0.837179 | Val Loss: 0.123722, Val Acc: 0.742268\n",
      "Epoch 12468 - Train Loss: 0.104320, Train Acc: 0.837179 | Val Loss: 0.123718, Val Acc: 0.742268\n",
      "Epoch 12469 - Train Loss: 0.104314, Train Acc: 0.837179 | Val Loss: 0.123714, Val Acc: 0.742268\n",
      "Epoch 12470 - Train Loss: 0.104309, Train Acc: 0.837179 | Val Loss: 0.123709, Val Acc: 0.742268\n",
      "Epoch 12471 - Train Loss: 0.104304, Train Acc: 0.837179 | Val Loss: 0.123705, Val Acc: 0.742268\n",
      "Epoch 12472 - Train Loss: 0.104299, Train Acc: 0.837179 | Val Loss: 0.123701, Val Acc: 0.742268\n",
      "Epoch 12473 - Train Loss: 0.104293, Train Acc: 0.837179 | Val Loss: 0.123697, Val Acc: 0.742268\n",
      "Epoch 12474 - Train Loss: 0.104288, Train Acc: 0.837179 | Val Loss: 0.123693, Val Acc: 0.742268\n",
      "Epoch 12475 - Train Loss: 0.104283, Train Acc: 0.837179 | Val Loss: 0.123689, Val Acc: 0.742268\n",
      "Epoch 12476 - Train Loss: 0.104277, Train Acc: 0.837179 | Val Loss: 0.123685, Val Acc: 0.742268\n",
      "Epoch 12477 - Train Loss: 0.104272, Train Acc: 0.837179 | Val Loss: 0.123681, Val Acc: 0.742268\n",
      "Epoch 12478 - Train Loss: 0.104267, Train Acc: 0.837179 | Val Loss: 0.123677, Val Acc: 0.742268\n",
      "Epoch 12479 - Train Loss: 0.104262, Train Acc: 0.837179 | Val Loss: 0.123673, Val Acc: 0.742268\n",
      "Epoch 12480 - Train Loss: 0.104256, Train Acc: 0.837179 | Val Loss: 0.123669, Val Acc: 0.742268\n",
      "Epoch 12481 - Train Loss: 0.104251, Train Acc: 0.837179 | Val Loss: 0.123665, Val Acc: 0.742268\n",
      "Epoch 12482 - Train Loss: 0.104246, Train Acc: 0.837179 | Val Loss: 0.123661, Val Acc: 0.742268\n",
      "Epoch 12483 - Train Loss: 0.104240, Train Acc: 0.837179 | Val Loss: 0.123657, Val Acc: 0.742268\n",
      "Epoch 12484 - Train Loss: 0.104235, Train Acc: 0.837179 | Val Loss: 0.123653, Val Acc: 0.742268\n",
      "Epoch 12485 - Train Loss: 0.104230, Train Acc: 0.837179 | Val Loss: 0.123649, Val Acc: 0.742268\n",
      "Epoch 12486 - Train Loss: 0.104224, Train Acc: 0.837179 | Val Loss: 0.123645, Val Acc: 0.742268\n",
      "Epoch 12487 - Train Loss: 0.104219, Train Acc: 0.837179 | Val Loss: 0.123641, Val Acc: 0.742268\n",
      "Epoch 12488 - Train Loss: 0.104214, Train Acc: 0.837179 | Val Loss: 0.123637, Val Acc: 0.742268\n",
      "Epoch 12489 - Train Loss: 0.104209, Train Acc: 0.837179 | Val Loss: 0.123632, Val Acc: 0.742268\n",
      "Epoch 12490 - Train Loss: 0.104203, Train Acc: 0.837179 | Val Loss: 0.123628, Val Acc: 0.742268\n",
      "Epoch 12491 - Train Loss: 0.104198, Train Acc: 0.837179 | Val Loss: 0.123624, Val Acc: 0.742268\n",
      "Epoch 12492 - Train Loss: 0.104193, Train Acc: 0.837179 | Val Loss: 0.123620, Val Acc: 0.742268\n",
      "Epoch 12493 - Train Loss: 0.104187, Train Acc: 0.837179 | Val Loss: 0.123616, Val Acc: 0.742268\n",
      "Epoch 12494 - Train Loss: 0.104182, Train Acc: 0.837179 | Val Loss: 0.123612, Val Acc: 0.742268\n",
      "Epoch 12495 - Train Loss: 0.104177, Train Acc: 0.837179 | Val Loss: 0.123608, Val Acc: 0.742268\n",
      "Epoch 12496 - Train Loss: 0.104172, Train Acc: 0.837179 | Val Loss: 0.123604, Val Acc: 0.742268\n",
      "Epoch 12497 - Train Loss: 0.104166, Train Acc: 0.837179 | Val Loss: 0.123600, Val Acc: 0.742268\n",
      "Epoch 12498 - Train Loss: 0.104161, Train Acc: 0.837179 | Val Loss: 0.123596, Val Acc: 0.742268\n",
      "Epoch 12499 - Train Loss: 0.104156, Train Acc: 0.837179 | Val Loss: 0.123592, Val Acc: 0.742268\n",
      "Epoch 12500 - Train Loss: 0.104151, Train Acc: 0.837179 | Val Loss: 0.123588, Val Acc: 0.742268\n",
      "Epoch 12501 - Train Loss: 0.104145, Train Acc: 0.837179 | Val Loss: 0.123584, Val Acc: 0.742268\n",
      "Epoch 12502 - Train Loss: 0.104140, Train Acc: 0.837179 | Val Loss: 0.123580, Val Acc: 0.742268\n",
      "Epoch 12503 - Train Loss: 0.104135, Train Acc: 0.837179 | Val Loss: 0.123576, Val Acc: 0.742268\n",
      "Epoch 12504 - Train Loss: 0.104129, Train Acc: 0.837179 | Val Loss: 0.123572, Val Acc: 0.742268\n",
      "Epoch 12505 - Train Loss: 0.104124, Train Acc: 0.837179 | Val Loss: 0.123568, Val Acc: 0.742268\n",
      "Epoch 12506 - Train Loss: 0.104119, Train Acc: 0.837179 | Val Loss: 0.123564, Val Acc: 0.742268\n",
      "Epoch 12507 - Train Loss: 0.104114, Train Acc: 0.837179 | Val Loss: 0.123560, Val Acc: 0.742268\n",
      "Epoch 12508 - Train Loss: 0.104108, Train Acc: 0.837179 | Val Loss: 0.123556, Val Acc: 0.742268\n",
      "Epoch 12509 - Train Loss: 0.104103, Train Acc: 0.837179 | Val Loss: 0.123552, Val Acc: 0.742268\n",
      "Epoch 12510 - Train Loss: 0.104098, Train Acc: 0.837179 | Val Loss: 0.123548, Val Acc: 0.742268\n",
      "Epoch 12511 - Train Loss: 0.104093, Train Acc: 0.837179 | Val Loss: 0.123544, Val Acc: 0.742268\n",
      "Epoch 12512 - Train Loss: 0.104087, Train Acc: 0.837179 | Val Loss: 0.123540, Val Acc: 0.742268\n",
      "Epoch 12513 - Train Loss: 0.104082, Train Acc: 0.837179 | Val Loss: 0.123536, Val Acc: 0.742268\n",
      "Epoch 12514 - Train Loss: 0.104077, Train Acc: 0.837179 | Val Loss: 0.123532, Val Acc: 0.742268\n",
      "Epoch 12515 - Train Loss: 0.104071, Train Acc: 0.837179 | Val Loss: 0.123528, Val Acc: 0.742268\n",
      "Epoch 12516 - Train Loss: 0.104066, Train Acc: 0.837179 | Val Loss: 0.123524, Val Acc: 0.742268\n",
      "Epoch 12517 - Train Loss: 0.104061, Train Acc: 0.837179 | Val Loss: 0.123519, Val Acc: 0.742268\n",
      "Epoch 12518 - Train Loss: 0.104056, Train Acc: 0.837179 | Val Loss: 0.123515, Val Acc: 0.742268\n",
      "Epoch 12519 - Train Loss: 0.104050, Train Acc: 0.837179 | Val Loss: 0.123511, Val Acc: 0.742268\n",
      "Epoch 12520 - Train Loss: 0.104045, Train Acc: 0.837179 | Val Loss: 0.123507, Val Acc: 0.742268\n",
      "Epoch 12521 - Train Loss: 0.104040, Train Acc: 0.837179 | Val Loss: 0.123503, Val Acc: 0.742268\n",
      "Epoch 12522 - Train Loss: 0.104035, Train Acc: 0.837179 | Val Loss: 0.123499, Val Acc: 0.742268\n",
      "Epoch 12523 - Train Loss: 0.104029, Train Acc: 0.837179 | Val Loss: 0.123495, Val Acc: 0.742268\n",
      "Epoch 12524 - Train Loss: 0.104024, Train Acc: 0.837179 | Val Loss: 0.123491, Val Acc: 0.742268\n",
      "Epoch 12525 - Train Loss: 0.104019, Train Acc: 0.837179 | Val Loss: 0.123487, Val Acc: 0.742268\n",
      "Epoch 12526 - Train Loss: 0.104014, Train Acc: 0.837179 | Val Loss: 0.123483, Val Acc: 0.742268\n",
      "Epoch 12527 - Train Loss: 0.104008, Train Acc: 0.837179 | Val Loss: 0.123479, Val Acc: 0.742268\n",
      "Epoch 12528 - Train Loss: 0.104003, Train Acc: 0.837179 | Val Loss: 0.123475, Val Acc: 0.742268\n",
      "Epoch 12529 - Train Loss: 0.103998, Train Acc: 0.837179 | Val Loss: 0.123471, Val Acc: 0.742268\n",
      "Epoch 12530 - Train Loss: 0.103993, Train Acc: 0.837179 | Val Loss: 0.123467, Val Acc: 0.742268\n",
      "Epoch 12531 - Train Loss: 0.103987, Train Acc: 0.837179 | Val Loss: 0.123463, Val Acc: 0.742268\n",
      "Epoch 12532 - Train Loss: 0.103982, Train Acc: 0.837179 | Val Loss: 0.123459, Val Acc: 0.742268\n",
      "Epoch 12533 - Train Loss: 0.103977, Train Acc: 0.837179 | Val Loss: 0.123455, Val Acc: 0.742268\n",
      "Epoch 12534 - Train Loss: 0.103972, Train Acc: 0.837179 | Val Loss: 0.123451, Val Acc: 0.742268\n",
      "Epoch 12535 - Train Loss: 0.103966, Train Acc: 0.837179 | Val Loss: 0.123447, Val Acc: 0.742268\n",
      "Epoch 12536 - Train Loss: 0.103961, Train Acc: 0.837179 | Val Loss: 0.123443, Val Acc: 0.742268\n",
      "Epoch 12537 - Train Loss: 0.103956, Train Acc: 0.837179 | Val Loss: 0.123439, Val Acc: 0.742268\n",
      "Epoch 12538 - Train Loss: 0.103951, Train Acc: 0.837179 | Val Loss: 0.123435, Val Acc: 0.742268\n",
      "Epoch 12539 - Train Loss: 0.103945, Train Acc: 0.837179 | Val Loss: 0.123431, Val Acc: 0.742268\n",
      "Epoch 12540 - Train Loss: 0.103940, Train Acc: 0.837179 | Val Loss: 0.123427, Val Acc: 0.742268\n",
      "Epoch 12541 - Train Loss: 0.103935, Train Acc: 0.837179 | Val Loss: 0.123423, Val Acc: 0.742268\n",
      "Epoch 12542 - Train Loss: 0.103930, Train Acc: 0.837179 | Val Loss: 0.123419, Val Acc: 0.742268\n",
      "Epoch 12543 - Train Loss: 0.103924, Train Acc: 0.837179 | Val Loss: 0.123415, Val Acc: 0.742268\n",
      "Epoch 12544 - Train Loss: 0.103919, Train Acc: 0.837179 | Val Loss: 0.123411, Val Acc: 0.742268\n",
      "Epoch 12545 - Train Loss: 0.103914, Train Acc: 0.837179 | Val Loss: 0.123407, Val Acc: 0.742268\n",
      "Epoch 12546 - Train Loss: 0.103909, Train Acc: 0.837179 | Val Loss: 0.123403, Val Acc: 0.742268\n",
      "Epoch 12547 - Train Loss: 0.103903, Train Acc: 0.837179 | Val Loss: 0.123399, Val Acc: 0.742268\n",
      "Epoch 12548 - Train Loss: 0.103898, Train Acc: 0.837179 | Val Loss: 0.123395, Val Acc: 0.742268\n",
      "Epoch 12549 - Train Loss: 0.103893, Train Acc: 0.837179 | Val Loss: 0.123391, Val Acc: 0.742268\n",
      "Epoch 12550 - Train Loss: 0.103888, Train Acc: 0.837179 | Val Loss: 0.123387, Val Acc: 0.742268\n",
      "Epoch 12551 - Train Loss: 0.103882, Train Acc: 0.837179 | Val Loss: 0.123383, Val Acc: 0.742268\n",
      "Epoch 12552 - Train Loss: 0.103877, Train Acc: 0.837179 | Val Loss: 0.123379, Val Acc: 0.742268\n",
      "Epoch 12553 - Train Loss: 0.103872, Train Acc: 0.837179 | Val Loss: 0.123375, Val Acc: 0.742268\n",
      "Epoch 12554 - Train Loss: 0.103867, Train Acc: 0.837179 | Val Loss: 0.123371, Val Acc: 0.742268\n",
      "Epoch 12555 - Train Loss: 0.103861, Train Acc: 0.837179 | Val Loss: 0.123367, Val Acc: 0.742268\n",
      "Epoch 12556 - Train Loss: 0.103856, Train Acc: 0.837179 | Val Loss: 0.123363, Val Acc: 0.742268\n",
      "Epoch 12557 - Train Loss: 0.103851, Train Acc: 0.837179 | Val Loss: 0.123359, Val Acc: 0.742268\n",
      "Epoch 12558 - Train Loss: 0.103846, Train Acc: 0.837179 | Val Loss: 0.123355, Val Acc: 0.742268\n",
      "Epoch 12559 - Train Loss: 0.103840, Train Acc: 0.837179 | Val Loss: 0.123351, Val Acc: 0.742268\n",
      "Epoch 12560 - Train Loss: 0.103835, Train Acc: 0.837179 | Val Loss: 0.123347, Val Acc: 0.742268\n",
      "Epoch 12561 - Train Loss: 0.103830, Train Acc: 0.837179 | Val Loss: 0.123343, Val Acc: 0.742268\n",
      "Epoch 12562 - Train Loss: 0.103825, Train Acc: 0.837179 | Val Loss: 0.123339, Val Acc: 0.742268\n",
      "Epoch 12563 - Train Loss: 0.103820, Train Acc: 0.837179 | Val Loss: 0.123335, Val Acc: 0.742268\n",
      "Epoch 12564 - Train Loss: 0.103814, Train Acc: 0.837179 | Val Loss: 0.123331, Val Acc: 0.742268\n",
      "Epoch 12565 - Train Loss: 0.103809, Train Acc: 0.837179 | Val Loss: 0.123327, Val Acc: 0.742268\n",
      "Epoch 12566 - Train Loss: 0.103804, Train Acc: 0.837179 | Val Loss: 0.123323, Val Acc: 0.742268\n",
      "Epoch 12567 - Train Loss: 0.103799, Train Acc: 0.837179 | Val Loss: 0.123319, Val Acc: 0.742268\n",
      "Epoch 12568 - Train Loss: 0.103793, Train Acc: 0.837179 | Val Loss: 0.123315, Val Acc: 0.742268\n",
      "Epoch 12569 - Train Loss: 0.103788, Train Acc: 0.837179 | Val Loss: 0.123311, Val Acc: 0.742268\n",
      "Epoch 12570 - Train Loss: 0.103783, Train Acc: 0.837179 | Val Loss: 0.123307, Val Acc: 0.742268\n",
      "Epoch 12571 - Train Loss: 0.103778, Train Acc: 0.837179 | Val Loss: 0.123303, Val Acc: 0.742268\n",
      "Epoch 12572 - Train Loss: 0.103772, Train Acc: 0.837179 | Val Loss: 0.123299, Val Acc: 0.742268\n",
      "Epoch 12573 - Train Loss: 0.103767, Train Acc: 0.837179 | Val Loss: 0.123295, Val Acc: 0.742268\n",
      "Epoch 12574 - Train Loss: 0.103762, Train Acc: 0.837179 | Val Loss: 0.123291, Val Acc: 0.742268\n",
      "Epoch 12575 - Train Loss: 0.103757, Train Acc: 0.837179 | Val Loss: 0.123287, Val Acc: 0.742268\n",
      "Epoch 12576 - Train Loss: 0.103752, Train Acc: 0.837179 | Val Loss: 0.123283, Val Acc: 0.742268\n",
      "Epoch 12577 - Train Loss: 0.103746, Train Acc: 0.837179 | Val Loss: 0.123279, Val Acc: 0.742268\n",
      "Epoch 12578 - Train Loss: 0.103741, Train Acc: 0.837179 | Val Loss: 0.123275, Val Acc: 0.742268\n",
      "Epoch 12579 - Train Loss: 0.103736, Train Acc: 0.837179 | Val Loss: 0.123271, Val Acc: 0.742268\n",
      "Epoch 12580 - Train Loss: 0.103731, Train Acc: 0.837179 | Val Loss: 0.123267, Val Acc: 0.742268\n",
      "Epoch 12581 - Train Loss: 0.103725, Train Acc: 0.837179 | Val Loss: 0.123263, Val Acc: 0.742268\n",
      "Epoch 12582 - Train Loss: 0.103720, Train Acc: 0.837179 | Val Loss: 0.123259, Val Acc: 0.742268\n",
      "Epoch 12583 - Train Loss: 0.103715, Train Acc: 0.837179 | Val Loss: 0.123255, Val Acc: 0.742268\n",
      "Epoch 12584 - Train Loss: 0.103710, Train Acc: 0.837179 | Val Loss: 0.123251, Val Acc: 0.742268\n",
      "Epoch 12585 - Train Loss: 0.103705, Train Acc: 0.837179 | Val Loss: 0.123247, Val Acc: 0.742268\n",
      "Epoch 12586 - Train Loss: 0.103699, Train Acc: 0.837179 | Val Loss: 0.123244, Val Acc: 0.742268\n",
      "Epoch 12587 - Train Loss: 0.103694, Train Acc: 0.837179 | Val Loss: 0.123240, Val Acc: 0.742268\n",
      "Epoch 12588 - Train Loss: 0.103689, Train Acc: 0.837179 | Val Loss: 0.123236, Val Acc: 0.742268\n",
      "Epoch 12589 - Train Loss: 0.103684, Train Acc: 0.837179 | Val Loss: 0.123232, Val Acc: 0.742268\n",
      "Epoch 12590 - Train Loss: 0.103679, Train Acc: 0.837179 | Val Loss: 0.123228, Val Acc: 0.742268\n",
      "Epoch 12591 - Train Loss: 0.103673, Train Acc: 0.837179 | Val Loss: 0.123224, Val Acc: 0.742268\n",
      "Epoch 12592 - Train Loss: 0.103668, Train Acc: 0.837179 | Val Loss: 0.123220, Val Acc: 0.742268\n",
      "Epoch 12593 - Train Loss: 0.103663, Train Acc: 0.837179 | Val Loss: 0.123216, Val Acc: 0.742268\n",
      "Epoch 12594 - Train Loss: 0.103658, Train Acc: 0.837179 | Val Loss: 0.123212, Val Acc: 0.742268\n",
      "Epoch 12595 - Train Loss: 0.103652, Train Acc: 0.837179 | Val Loss: 0.123208, Val Acc: 0.742268\n",
      "Epoch 12596 - Train Loss: 0.103647, Train Acc: 0.837179 | Val Loss: 0.123204, Val Acc: 0.742268\n",
      "Epoch 12597 - Train Loss: 0.103642, Train Acc: 0.837179 | Val Loss: 0.123200, Val Acc: 0.742268\n",
      "Epoch 12598 - Train Loss: 0.103637, Train Acc: 0.837179 | Val Loss: 0.123196, Val Acc: 0.742268\n",
      "Epoch 12599 - Train Loss: 0.103632, Train Acc: 0.837179 | Val Loss: 0.123192, Val Acc: 0.742268\n",
      "Epoch 12600 - Train Loss: 0.103626, Train Acc: 0.837179 | Val Loss: 0.123188, Val Acc: 0.742268\n",
      "Epoch 12601 - Train Loss: 0.103621, Train Acc: 0.837179 | Val Loss: 0.123184, Val Acc: 0.742268\n",
      "Epoch 12602 - Train Loss: 0.103616, Train Acc: 0.837179 | Val Loss: 0.123180, Val Acc: 0.742268\n",
      "Epoch 12603 - Train Loss: 0.103611, Train Acc: 0.837179 | Val Loss: 0.123176, Val Acc: 0.742268\n",
      "Epoch 12604 - Train Loss: 0.103606, Train Acc: 0.837179 | Val Loss: 0.123172, Val Acc: 0.742268\n",
      "Epoch 12605 - Train Loss: 0.103600, Train Acc: 0.837179 | Val Loss: 0.123168, Val Acc: 0.742268\n",
      "Epoch 12606 - Train Loss: 0.103595, Train Acc: 0.837179 | Val Loss: 0.123164, Val Acc: 0.742268\n",
      "Epoch 12607 - Train Loss: 0.103590, Train Acc: 0.837179 | Val Loss: 0.123160, Val Acc: 0.742268\n",
      "Epoch 12608 - Train Loss: 0.103585, Train Acc: 0.837179 | Val Loss: 0.123156, Val Acc: 0.742268\n",
      "Epoch 12609 - Train Loss: 0.103580, Train Acc: 0.837179 | Val Loss: 0.123152, Val Acc: 0.742268\n",
      "Epoch 12610 - Train Loss: 0.103574, Train Acc: 0.837179 | Val Loss: 0.123148, Val Acc: 0.742268\n",
      "Epoch 12611 - Train Loss: 0.103569, Train Acc: 0.837179 | Val Loss: 0.123144, Val Acc: 0.742268\n",
      "Epoch 12612 - Train Loss: 0.103564, Train Acc: 0.837179 | Val Loss: 0.123140, Val Acc: 0.742268\n",
      "Epoch 12613 - Train Loss: 0.103559, Train Acc: 0.837179 | Val Loss: 0.123137, Val Acc: 0.742268\n",
      "Epoch 12614 - Train Loss: 0.103554, Train Acc: 0.837179 | Val Loss: 0.123133, Val Acc: 0.742268\n",
      "Epoch 12615 - Train Loss: 0.103548, Train Acc: 0.837179 | Val Loss: 0.123129, Val Acc: 0.742268\n",
      "Epoch 12616 - Train Loss: 0.103543, Train Acc: 0.837179 | Val Loss: 0.123125, Val Acc: 0.742268\n",
      "Epoch 12617 - Train Loss: 0.103538, Train Acc: 0.837179 | Val Loss: 0.123121, Val Acc: 0.742268\n",
      "Epoch 12618 - Train Loss: 0.103533, Train Acc: 0.837179 | Val Loss: 0.123117, Val Acc: 0.742268\n",
      "Epoch 12619 - Train Loss: 0.103528, Train Acc: 0.837179 | Val Loss: 0.123113, Val Acc: 0.742268\n",
      "Epoch 12620 - Train Loss: 0.103523, Train Acc: 0.837179 | Val Loss: 0.123109, Val Acc: 0.742268\n",
      "Epoch 12621 - Train Loss: 0.103517, Train Acc: 0.837179 | Val Loss: 0.123105, Val Acc: 0.742268\n",
      "Epoch 12622 - Train Loss: 0.103512, Train Acc: 0.837179 | Val Loss: 0.123101, Val Acc: 0.742268\n",
      "Epoch 12623 - Train Loss: 0.103507, Train Acc: 0.837179 | Val Loss: 0.123097, Val Acc: 0.742268\n",
      "Epoch 12624 - Train Loss: 0.103502, Train Acc: 0.837179 | Val Loss: 0.123093, Val Acc: 0.742268\n",
      "Epoch 12625 - Train Loss: 0.103497, Train Acc: 0.837179 | Val Loss: 0.123089, Val Acc: 0.742268\n",
      "Epoch 12626 - Train Loss: 0.103491, Train Acc: 0.837179 | Val Loss: 0.123085, Val Acc: 0.742268\n",
      "Epoch 12627 - Train Loss: 0.103486, Train Acc: 0.838462 | Val Loss: 0.123081, Val Acc: 0.742268\n",
      "Epoch 12628 - Train Loss: 0.103481, Train Acc: 0.838462 | Val Loss: 0.123077, Val Acc: 0.742268\n",
      "Epoch 12629 - Train Loss: 0.103476, Train Acc: 0.838462 | Val Loss: 0.123073, Val Acc: 0.742268\n",
      "Epoch 12630 - Train Loss: 0.103471, Train Acc: 0.838462 | Val Loss: 0.123069, Val Acc: 0.742268\n",
      "Epoch 12631 - Train Loss: 0.103465, Train Acc: 0.838462 | Val Loss: 0.123065, Val Acc: 0.742268\n",
      "Epoch 12632 - Train Loss: 0.103460, Train Acc: 0.838462 | Val Loss: 0.123062, Val Acc: 0.742268\n",
      "Epoch 12633 - Train Loss: 0.103455, Train Acc: 0.838462 | Val Loss: 0.123058, Val Acc: 0.742268\n",
      "Epoch 12634 - Train Loss: 0.103450, Train Acc: 0.838462 | Val Loss: 0.123054, Val Acc: 0.742268\n",
      "Epoch 12635 - Train Loss: 0.103445, Train Acc: 0.838462 | Val Loss: 0.123050, Val Acc: 0.742268\n",
      "Epoch 12636 - Train Loss: 0.103440, Train Acc: 0.838462 | Val Loss: 0.123046, Val Acc: 0.742268\n",
      "Epoch 12637 - Train Loss: 0.103434, Train Acc: 0.838462 | Val Loss: 0.123042, Val Acc: 0.742268\n",
      "Epoch 12638 - Train Loss: 0.103429, Train Acc: 0.838462 | Val Loss: 0.123038, Val Acc: 0.742268\n",
      "Epoch 12639 - Train Loss: 0.103424, Train Acc: 0.838462 | Val Loss: 0.123034, Val Acc: 0.742268\n",
      "Epoch 12640 - Train Loss: 0.103419, Train Acc: 0.838462 | Val Loss: 0.123030, Val Acc: 0.742268\n",
      "Epoch 12641 - Train Loss: 0.103414, Train Acc: 0.838462 | Val Loss: 0.123026, Val Acc: 0.742268\n",
      "Epoch 12642 - Train Loss: 0.103408, Train Acc: 0.838462 | Val Loss: 0.123022, Val Acc: 0.742268\n",
      "Epoch 12643 - Train Loss: 0.103403, Train Acc: 0.838462 | Val Loss: 0.123018, Val Acc: 0.742268\n",
      "Epoch 12644 - Train Loss: 0.103398, Train Acc: 0.838462 | Val Loss: 0.123014, Val Acc: 0.742268\n",
      "Epoch 12645 - Train Loss: 0.103393, Train Acc: 0.838462 | Val Loss: 0.123010, Val Acc: 0.742268\n",
      "Epoch 12646 - Train Loss: 0.103388, Train Acc: 0.838462 | Val Loss: 0.123006, Val Acc: 0.742268\n",
      "Epoch 12647 - Train Loss: 0.103383, Train Acc: 0.838462 | Val Loss: 0.123003, Val Acc: 0.742268\n",
      "Epoch 12648 - Train Loss: 0.103377, Train Acc: 0.838462 | Val Loss: 0.122999, Val Acc: 0.742268\n",
      "Epoch 12649 - Train Loss: 0.103372, Train Acc: 0.838462 | Val Loss: 0.122995, Val Acc: 0.742268\n",
      "Epoch 12650 - Train Loss: 0.103367, Train Acc: 0.838462 | Val Loss: 0.122991, Val Acc: 0.742268\n",
      "Epoch 12651 - Train Loss: 0.103362, Train Acc: 0.838462 | Val Loss: 0.122987, Val Acc: 0.742268\n",
      "Epoch 12652 - Train Loss: 0.103357, Train Acc: 0.838462 | Val Loss: 0.122983, Val Acc: 0.742268\n",
      "Epoch 12653 - Train Loss: 0.103352, Train Acc: 0.838462 | Val Loss: 0.122979, Val Acc: 0.742268\n",
      "Epoch 12654 - Train Loss: 0.103346, Train Acc: 0.838462 | Val Loss: 0.122975, Val Acc: 0.742268\n",
      "Epoch 12655 - Train Loss: 0.103341, Train Acc: 0.838462 | Val Loss: 0.122971, Val Acc: 0.742268\n",
      "Epoch 12656 - Train Loss: 0.103336, Train Acc: 0.838462 | Val Loss: 0.122967, Val Acc: 0.742268\n",
      "Epoch 12657 - Train Loss: 0.103331, Train Acc: 0.838462 | Val Loss: 0.122963, Val Acc: 0.742268\n",
      "Epoch 12658 - Train Loss: 0.103326, Train Acc: 0.838462 | Val Loss: 0.122959, Val Acc: 0.742268\n",
      "Epoch 12659 - Train Loss: 0.103321, Train Acc: 0.838462 | Val Loss: 0.122955, Val Acc: 0.742268\n",
      "Epoch 12660 - Train Loss: 0.103315, Train Acc: 0.838462 | Val Loss: 0.122952, Val Acc: 0.742268\n",
      "Epoch 12661 - Train Loss: 0.103310, Train Acc: 0.838462 | Val Loss: 0.122948, Val Acc: 0.742268\n",
      "Epoch 12662 - Train Loss: 0.103305, Train Acc: 0.838462 | Val Loss: 0.122944, Val Acc: 0.742268\n",
      "Epoch 12663 - Train Loss: 0.103300, Train Acc: 0.838462 | Val Loss: 0.122940, Val Acc: 0.742268\n",
      "Epoch 12664 - Train Loss: 0.103295, Train Acc: 0.838462 | Val Loss: 0.122936, Val Acc: 0.742268\n",
      "Epoch 12665 - Train Loss: 0.103290, Train Acc: 0.838462 | Val Loss: 0.122932, Val Acc: 0.742268\n",
      "Epoch 12666 - Train Loss: 0.103284, Train Acc: 0.838462 | Val Loss: 0.122928, Val Acc: 0.742268\n",
      "Epoch 12667 - Train Loss: 0.103279, Train Acc: 0.838462 | Val Loss: 0.122924, Val Acc: 0.742268\n",
      "Epoch 12668 - Train Loss: 0.103274, Train Acc: 0.838462 | Val Loss: 0.122920, Val Acc: 0.742268\n",
      "Epoch 12669 - Train Loss: 0.103269, Train Acc: 0.838462 | Val Loss: 0.122916, Val Acc: 0.742268\n",
      "Epoch 12670 - Train Loss: 0.103264, Train Acc: 0.838462 | Val Loss: 0.122912, Val Acc: 0.742268\n",
      "Epoch 12671 - Train Loss: 0.103259, Train Acc: 0.838462 | Val Loss: 0.122909, Val Acc: 0.742268\n",
      "Epoch 12672 - Train Loss: 0.103254, Train Acc: 0.838462 | Val Loss: 0.122905, Val Acc: 0.742268\n",
      "Epoch 12673 - Train Loss: 0.103248, Train Acc: 0.838462 | Val Loss: 0.122901, Val Acc: 0.742268\n",
      "Epoch 12674 - Train Loss: 0.103243, Train Acc: 0.838462 | Val Loss: 0.122897, Val Acc: 0.742268\n",
      "Epoch 12675 - Train Loss: 0.103238, Train Acc: 0.838462 | Val Loss: 0.122893, Val Acc: 0.742268\n",
      "Epoch 12676 - Train Loss: 0.103233, Train Acc: 0.838462 | Val Loss: 0.122889, Val Acc: 0.742268\n",
      "Epoch 12677 - Train Loss: 0.103228, Train Acc: 0.838462 | Val Loss: 0.122885, Val Acc: 0.742268\n",
      "Epoch 12678 - Train Loss: 0.103223, Train Acc: 0.838462 | Val Loss: 0.122881, Val Acc: 0.742268\n",
      "Epoch 12679 - Train Loss: 0.103217, Train Acc: 0.838462 | Val Loss: 0.122877, Val Acc: 0.742268\n",
      "Epoch 12680 - Train Loss: 0.103212, Train Acc: 0.838462 | Val Loss: 0.122873, Val Acc: 0.742268\n",
      "Epoch 12681 - Train Loss: 0.103207, Train Acc: 0.838462 | Val Loss: 0.122870, Val Acc: 0.742268\n",
      "Epoch 12682 - Train Loss: 0.103202, Train Acc: 0.838462 | Val Loss: 0.122866, Val Acc: 0.742268\n",
      "Epoch 12683 - Train Loss: 0.103197, Train Acc: 0.838462 | Val Loss: 0.122862, Val Acc: 0.742268\n",
      "Epoch 12684 - Train Loss: 0.103192, Train Acc: 0.838462 | Val Loss: 0.122858, Val Acc: 0.742268\n",
      "Epoch 12685 - Train Loss: 0.103187, Train Acc: 0.838462 | Val Loss: 0.122854, Val Acc: 0.742268\n",
      "Epoch 12686 - Train Loss: 0.103181, Train Acc: 0.838462 | Val Loss: 0.122850, Val Acc: 0.742268\n",
      "Epoch 12687 - Train Loss: 0.103176, Train Acc: 0.838462 | Val Loss: 0.122846, Val Acc: 0.742268\n",
      "Epoch 12688 - Train Loss: 0.103171, Train Acc: 0.838462 | Val Loss: 0.122842, Val Acc: 0.742268\n",
      "Epoch 12689 - Train Loss: 0.103166, Train Acc: 0.838462 | Val Loss: 0.122838, Val Acc: 0.742268\n",
      "Epoch 12690 - Train Loss: 0.103161, Train Acc: 0.838462 | Val Loss: 0.122834, Val Acc: 0.742268\n",
      "Epoch 12691 - Train Loss: 0.103156, Train Acc: 0.838462 | Val Loss: 0.122831, Val Acc: 0.742268\n",
      "Epoch 12692 - Train Loss: 0.103151, Train Acc: 0.838462 | Val Loss: 0.122827, Val Acc: 0.742268\n",
      "Epoch 12693 - Train Loss: 0.103145, Train Acc: 0.838462 | Val Loss: 0.122823, Val Acc: 0.742268\n",
      "Epoch 12694 - Train Loss: 0.103140, Train Acc: 0.838462 | Val Loss: 0.122819, Val Acc: 0.742268\n",
      "Epoch 12695 - Train Loss: 0.103135, Train Acc: 0.838462 | Val Loss: 0.122815, Val Acc: 0.742268\n",
      "Epoch 12696 - Train Loss: 0.103130, Train Acc: 0.838462 | Val Loss: 0.122811, Val Acc: 0.742268\n",
      "Epoch 12697 - Train Loss: 0.103125, Train Acc: 0.838462 | Val Loss: 0.122807, Val Acc: 0.742268\n",
      "Epoch 12698 - Train Loss: 0.103120, Train Acc: 0.838462 | Val Loss: 0.122803, Val Acc: 0.742268\n",
      "Epoch 12699 - Train Loss: 0.103115, Train Acc: 0.838462 | Val Loss: 0.122799, Val Acc: 0.742268\n",
      "Epoch 12700 - Train Loss: 0.103109, Train Acc: 0.838462 | Val Loss: 0.122796, Val Acc: 0.742268\n",
      "Epoch 12701 - Train Loss: 0.103104, Train Acc: 0.838462 | Val Loss: 0.122792, Val Acc: 0.742268\n",
      "Epoch 12702 - Train Loss: 0.103099, Train Acc: 0.838462 | Val Loss: 0.122788, Val Acc: 0.742268\n",
      "Epoch 12703 - Train Loss: 0.103094, Train Acc: 0.838462 | Val Loss: 0.122784, Val Acc: 0.742268\n",
      "Epoch 12704 - Train Loss: 0.103089, Train Acc: 0.838462 | Val Loss: 0.122780, Val Acc: 0.742268\n",
      "Epoch 12705 - Train Loss: 0.103084, Train Acc: 0.838462 | Val Loss: 0.122776, Val Acc: 0.742268\n",
      "Epoch 12706 - Train Loss: 0.103079, Train Acc: 0.838462 | Val Loss: 0.122772, Val Acc: 0.742268\n",
      "Epoch 12707 - Train Loss: 0.103074, Train Acc: 0.838462 | Val Loss: 0.122768, Val Acc: 0.742268\n",
      "Epoch 12708 - Train Loss: 0.103068, Train Acc: 0.838462 | Val Loss: 0.122765, Val Acc: 0.742268\n",
      "Epoch 12709 - Train Loss: 0.103063, Train Acc: 0.838462 | Val Loss: 0.122761, Val Acc: 0.742268\n",
      "Epoch 12710 - Train Loss: 0.103058, Train Acc: 0.838462 | Val Loss: 0.122757, Val Acc: 0.742268\n",
      "Epoch 12711 - Train Loss: 0.103053, Train Acc: 0.838462 | Val Loss: 0.122753, Val Acc: 0.742268\n",
      "Epoch 12712 - Train Loss: 0.103048, Train Acc: 0.838462 | Val Loss: 0.122749, Val Acc: 0.742268\n",
      "Epoch 12713 - Train Loss: 0.103043, Train Acc: 0.838462 | Val Loss: 0.122745, Val Acc: 0.742268\n",
      "Epoch 12714 - Train Loss: 0.103038, Train Acc: 0.838462 | Val Loss: 0.122741, Val Acc: 0.742268\n",
      "Epoch 12715 - Train Loss: 0.103033, Train Acc: 0.838462 | Val Loss: 0.122737, Val Acc: 0.742268\n",
      "Epoch 12716 - Train Loss: 0.103027, Train Acc: 0.838462 | Val Loss: 0.122734, Val Acc: 0.742268\n",
      "Epoch 12717 - Train Loss: 0.103022, Train Acc: 0.838462 | Val Loss: 0.122730, Val Acc: 0.742268\n",
      "Epoch 12718 - Train Loss: 0.103017, Train Acc: 0.838462 | Val Loss: 0.122726, Val Acc: 0.742268\n",
      "Epoch 12719 - Train Loss: 0.103012, Train Acc: 0.838462 | Val Loss: 0.122722, Val Acc: 0.742268\n",
      "Epoch 12720 - Train Loss: 0.103007, Train Acc: 0.838462 | Val Loss: 0.122718, Val Acc: 0.742268\n",
      "Epoch 12721 - Train Loss: 0.103002, Train Acc: 0.838462 | Val Loss: 0.122714, Val Acc: 0.742268\n",
      "Epoch 12722 - Train Loss: 0.102997, Train Acc: 0.838462 | Val Loss: 0.122710, Val Acc: 0.742268\n",
      "Epoch 12723 - Train Loss: 0.102992, Train Acc: 0.838462 | Val Loss: 0.122706, Val Acc: 0.742268\n",
      "Epoch 12724 - Train Loss: 0.102986, Train Acc: 0.838462 | Val Loss: 0.122703, Val Acc: 0.742268\n",
      "Epoch 12725 - Train Loss: 0.102981, Train Acc: 0.838462 | Val Loss: 0.122699, Val Acc: 0.742268\n",
      "Epoch 12726 - Train Loss: 0.102976, Train Acc: 0.838462 | Val Loss: 0.122695, Val Acc: 0.742268\n",
      "Epoch 12727 - Train Loss: 0.102971, Train Acc: 0.838462 | Val Loss: 0.122691, Val Acc: 0.742268\n",
      "Epoch 12728 - Train Loss: 0.102966, Train Acc: 0.838462 | Val Loss: 0.122687, Val Acc: 0.742268\n",
      "Epoch 12729 - Train Loss: 0.102961, Train Acc: 0.838462 | Val Loss: 0.122683, Val Acc: 0.742268\n",
      "Epoch 12730 - Train Loss: 0.102956, Train Acc: 0.838462 | Val Loss: 0.122679, Val Acc: 0.742268\n",
      "Epoch 12731 - Train Loss: 0.102951, Train Acc: 0.838462 | Val Loss: 0.122675, Val Acc: 0.742268\n",
      "Epoch 12732 - Train Loss: 0.102945, Train Acc: 0.838462 | Val Loss: 0.122672, Val Acc: 0.742268\n",
      "Epoch 12733 - Train Loss: 0.102940, Train Acc: 0.838462 | Val Loss: 0.122668, Val Acc: 0.742268\n",
      "Epoch 12734 - Train Loss: 0.102935, Train Acc: 0.838462 | Val Loss: 0.122664, Val Acc: 0.742268\n",
      "Epoch 12735 - Train Loss: 0.102930, Train Acc: 0.838462 | Val Loss: 0.122660, Val Acc: 0.742268\n",
      "Epoch 12736 - Train Loss: 0.102925, Train Acc: 0.838462 | Val Loss: 0.122656, Val Acc: 0.742268\n",
      "Epoch 12737 - Train Loss: 0.102920, Train Acc: 0.838462 | Val Loss: 0.122652, Val Acc: 0.742268\n",
      "Epoch 12738 - Train Loss: 0.102915, Train Acc: 0.838462 | Val Loss: 0.122648, Val Acc: 0.742268\n",
      "Epoch 12739 - Train Loss: 0.102910, Train Acc: 0.838462 | Val Loss: 0.122645, Val Acc: 0.742268\n",
      "Epoch 12740 - Train Loss: 0.102905, Train Acc: 0.838462 | Val Loss: 0.122641, Val Acc: 0.742268\n",
      "Epoch 12741 - Train Loss: 0.102899, Train Acc: 0.838462 | Val Loss: 0.122637, Val Acc: 0.742268\n",
      "Epoch 12742 - Train Loss: 0.102894, Train Acc: 0.838462 | Val Loss: 0.122633, Val Acc: 0.742268\n",
      "Epoch 12743 - Train Loss: 0.102889, Train Acc: 0.838462 | Val Loss: 0.122629, Val Acc: 0.742268\n",
      "Epoch 12744 - Train Loss: 0.102884, Train Acc: 0.838462 | Val Loss: 0.122625, Val Acc: 0.742268\n",
      "Epoch 12745 - Train Loss: 0.102879, Train Acc: 0.838462 | Val Loss: 0.122621, Val Acc: 0.742268\n",
      "Epoch 12746 - Train Loss: 0.102874, Train Acc: 0.838462 | Val Loss: 0.122618, Val Acc: 0.742268\n",
      "Epoch 12747 - Train Loss: 0.102869, Train Acc: 0.838462 | Val Loss: 0.122614, Val Acc: 0.742268\n",
      "Epoch 12748 - Train Loss: 0.102864, Train Acc: 0.838462 | Val Loss: 0.122610, Val Acc: 0.742268\n",
      "Epoch 12749 - Train Loss: 0.102859, Train Acc: 0.838462 | Val Loss: 0.122606, Val Acc: 0.742268\n",
      "Epoch 12750 - Train Loss: 0.102854, Train Acc: 0.838462 | Val Loss: 0.122602, Val Acc: 0.742268\n",
      "Epoch 12751 - Train Loss: 0.102848, Train Acc: 0.838462 | Val Loss: 0.122598, Val Acc: 0.742268\n",
      "Epoch 12752 - Train Loss: 0.102843, Train Acc: 0.838462 | Val Loss: 0.122594, Val Acc: 0.742268\n",
      "Epoch 12753 - Train Loss: 0.102838, Train Acc: 0.838462 | Val Loss: 0.122591, Val Acc: 0.742268\n",
      "Epoch 12754 - Train Loss: 0.102833, Train Acc: 0.838462 | Val Loss: 0.122587, Val Acc: 0.742268\n",
      "Epoch 12755 - Train Loss: 0.102828, Train Acc: 0.838462 | Val Loss: 0.122583, Val Acc: 0.742268\n",
      "Epoch 12756 - Train Loss: 0.102823, Train Acc: 0.838462 | Val Loss: 0.122579, Val Acc: 0.742268\n",
      "Epoch 12757 - Train Loss: 0.102818, Train Acc: 0.838462 | Val Loss: 0.122575, Val Acc: 0.742268\n",
      "Epoch 12758 - Train Loss: 0.102813, Train Acc: 0.838462 | Val Loss: 0.122571, Val Acc: 0.742268\n",
      "Epoch 12759 - Train Loss: 0.102808, Train Acc: 0.838462 | Val Loss: 0.122568, Val Acc: 0.742268\n",
      "Epoch 12760 - Train Loss: 0.102803, Train Acc: 0.838462 | Val Loss: 0.122564, Val Acc: 0.742268\n",
      "Epoch 12761 - Train Loss: 0.102797, Train Acc: 0.838462 | Val Loss: 0.122560, Val Acc: 0.742268\n",
      "Epoch 12762 - Train Loss: 0.102792, Train Acc: 0.838462 | Val Loss: 0.122556, Val Acc: 0.742268\n",
      "Epoch 12763 - Train Loss: 0.102787, Train Acc: 0.839744 | Val Loss: 0.122552, Val Acc: 0.742268\n",
      "Epoch 12764 - Train Loss: 0.102782, Train Acc: 0.839744 | Val Loss: 0.122548, Val Acc: 0.742268\n",
      "Epoch 12765 - Train Loss: 0.102777, Train Acc: 0.839744 | Val Loss: 0.122544, Val Acc: 0.742268\n",
      "Epoch 12766 - Train Loss: 0.102772, Train Acc: 0.839744 | Val Loss: 0.122541, Val Acc: 0.742268\n",
      "Epoch 12767 - Train Loss: 0.102767, Train Acc: 0.839744 | Val Loss: 0.122537, Val Acc: 0.742268\n",
      "Epoch 12768 - Train Loss: 0.102762, Train Acc: 0.839744 | Val Loss: 0.122533, Val Acc: 0.742268\n",
      "Epoch 12769 - Train Loss: 0.102757, Train Acc: 0.839744 | Val Loss: 0.122529, Val Acc: 0.742268\n",
      "Epoch 12770 - Train Loss: 0.102752, Train Acc: 0.839744 | Val Loss: 0.122525, Val Acc: 0.742268\n",
      "Epoch 12771 - Train Loss: 0.102747, Train Acc: 0.839744 | Val Loss: 0.122521, Val Acc: 0.742268\n",
      "Epoch 12772 - Train Loss: 0.102741, Train Acc: 0.839744 | Val Loss: 0.122518, Val Acc: 0.742268\n",
      "Epoch 12773 - Train Loss: 0.102736, Train Acc: 0.839744 | Val Loss: 0.122514, Val Acc: 0.742268\n",
      "Epoch 12774 - Train Loss: 0.102731, Train Acc: 0.839744 | Val Loss: 0.122510, Val Acc: 0.742268\n",
      "Epoch 12775 - Train Loss: 0.102726, Train Acc: 0.839744 | Val Loss: 0.122506, Val Acc: 0.742268\n",
      "Epoch 12776 - Train Loss: 0.102721, Train Acc: 0.839744 | Val Loss: 0.122502, Val Acc: 0.742268\n",
      "Epoch 12777 - Train Loss: 0.102716, Train Acc: 0.839744 | Val Loss: 0.122498, Val Acc: 0.742268\n",
      "Epoch 12778 - Train Loss: 0.102711, Train Acc: 0.839744 | Val Loss: 0.122495, Val Acc: 0.742268\n",
      "Epoch 12779 - Train Loss: 0.102706, Train Acc: 0.839744 | Val Loss: 0.122491, Val Acc: 0.742268\n",
      "Epoch 12780 - Train Loss: 0.102701, Train Acc: 0.839744 | Val Loss: 0.122487, Val Acc: 0.742268\n",
      "Epoch 12781 - Train Loss: 0.102696, Train Acc: 0.839744 | Val Loss: 0.122483, Val Acc: 0.742268\n",
      "Epoch 12782 - Train Loss: 0.102691, Train Acc: 0.839744 | Val Loss: 0.122479, Val Acc: 0.742268\n",
      "Epoch 12783 - Train Loss: 0.102686, Train Acc: 0.839744 | Val Loss: 0.122475, Val Acc: 0.742268\n",
      "Epoch 12784 - Train Loss: 0.102681, Train Acc: 0.839744 | Val Loss: 0.122472, Val Acc: 0.742268\n",
      "Epoch 12785 - Train Loss: 0.102675, Train Acc: 0.839744 | Val Loss: 0.122468, Val Acc: 0.742268\n",
      "Epoch 12786 - Train Loss: 0.102670, Train Acc: 0.839744 | Val Loss: 0.122464, Val Acc: 0.742268\n",
      "Epoch 12787 - Train Loss: 0.102665, Train Acc: 0.839744 | Val Loss: 0.122460, Val Acc: 0.742268\n",
      "Epoch 12788 - Train Loss: 0.102660, Train Acc: 0.839744 | Val Loss: 0.122456, Val Acc: 0.742268\n",
      "Epoch 12789 - Train Loss: 0.102655, Train Acc: 0.839744 | Val Loss: 0.122452, Val Acc: 0.742268\n",
      "Epoch 12790 - Train Loss: 0.102650, Train Acc: 0.839744 | Val Loss: 0.122449, Val Acc: 0.742268\n",
      "Epoch 12791 - Train Loss: 0.102645, Train Acc: 0.839744 | Val Loss: 0.122445, Val Acc: 0.742268\n",
      "Epoch 12792 - Train Loss: 0.102640, Train Acc: 0.839744 | Val Loss: 0.122441, Val Acc: 0.742268\n",
      "Epoch 12793 - Train Loss: 0.102635, Train Acc: 0.839744 | Val Loss: 0.122437, Val Acc: 0.742268\n",
      "Epoch 12794 - Train Loss: 0.102630, Train Acc: 0.839744 | Val Loss: 0.122433, Val Acc: 0.742268\n",
      "Epoch 12795 - Train Loss: 0.102625, Train Acc: 0.839744 | Val Loss: 0.122430, Val Acc: 0.742268\n",
      "Epoch 12796 - Train Loss: 0.102620, Train Acc: 0.839744 | Val Loss: 0.122426, Val Acc: 0.742268\n",
      "Epoch 12797 - Train Loss: 0.102615, Train Acc: 0.839744 | Val Loss: 0.122422, Val Acc: 0.742268\n",
      "Epoch 12798 - Train Loss: 0.102610, Train Acc: 0.839744 | Val Loss: 0.122418, Val Acc: 0.742268\n",
      "Epoch 12799 - Train Loss: 0.102604, Train Acc: 0.839744 | Val Loss: 0.122414, Val Acc: 0.742268\n",
      "Epoch 12800 - Train Loss: 0.102599, Train Acc: 0.839744 | Val Loss: 0.122410, Val Acc: 0.742268\n",
      "Epoch 12801 - Train Loss: 0.102594, Train Acc: 0.839744 | Val Loss: 0.122407, Val Acc: 0.742268\n",
      "Epoch 12802 - Train Loss: 0.102589, Train Acc: 0.839744 | Val Loss: 0.122403, Val Acc: 0.742268\n",
      "Epoch 12803 - Train Loss: 0.102584, Train Acc: 0.839744 | Val Loss: 0.122399, Val Acc: 0.742268\n",
      "Epoch 12804 - Train Loss: 0.102579, Train Acc: 0.839744 | Val Loss: 0.122395, Val Acc: 0.742268\n",
      "Epoch 12805 - Train Loss: 0.102574, Train Acc: 0.839744 | Val Loss: 0.122391, Val Acc: 0.742268\n",
      "Epoch 12806 - Train Loss: 0.102569, Train Acc: 0.839744 | Val Loss: 0.122388, Val Acc: 0.742268\n",
      "Epoch 12807 - Train Loss: 0.102564, Train Acc: 0.839744 | Val Loss: 0.122384, Val Acc: 0.742268\n",
      "Epoch 12808 - Train Loss: 0.102559, Train Acc: 0.839744 | Val Loss: 0.122380, Val Acc: 0.742268\n",
      "Epoch 12809 - Train Loss: 0.102554, Train Acc: 0.839744 | Val Loss: 0.122376, Val Acc: 0.742268\n",
      "Epoch 12810 - Train Loss: 0.102549, Train Acc: 0.839744 | Val Loss: 0.122372, Val Acc: 0.742268\n",
      "Epoch 12811 - Train Loss: 0.102544, Train Acc: 0.839744 | Val Loss: 0.122368, Val Acc: 0.742268\n",
      "Epoch 12812 - Train Loss: 0.102539, Train Acc: 0.839744 | Val Loss: 0.122365, Val Acc: 0.742268\n",
      "Epoch 12813 - Train Loss: 0.102534, Train Acc: 0.839744 | Val Loss: 0.122361, Val Acc: 0.742268\n",
      "Epoch 12814 - Train Loss: 0.102529, Train Acc: 0.839744 | Val Loss: 0.122357, Val Acc: 0.742268\n",
      "Epoch 12815 - Train Loss: 0.102523, Train Acc: 0.839744 | Val Loss: 0.122353, Val Acc: 0.742268\n",
      "Epoch 12816 - Train Loss: 0.102518, Train Acc: 0.839744 | Val Loss: 0.122349, Val Acc: 0.742268\n",
      "Epoch 12817 - Train Loss: 0.102513, Train Acc: 0.839744 | Val Loss: 0.122346, Val Acc: 0.742268\n",
      "Epoch 12818 - Train Loss: 0.102508, Train Acc: 0.839744 | Val Loss: 0.122342, Val Acc: 0.742268\n",
      "Epoch 12819 - Train Loss: 0.102503, Train Acc: 0.839744 | Val Loss: 0.122338, Val Acc: 0.742268\n",
      "Epoch 12820 - Train Loss: 0.102498, Train Acc: 0.839744 | Val Loss: 0.122334, Val Acc: 0.742268\n",
      "Epoch 12821 - Train Loss: 0.102493, Train Acc: 0.839744 | Val Loss: 0.122330, Val Acc: 0.742268\n",
      "Epoch 12822 - Train Loss: 0.102488, Train Acc: 0.839744 | Val Loss: 0.122327, Val Acc: 0.742268\n",
      "Epoch 12823 - Train Loss: 0.102483, Train Acc: 0.839744 | Val Loss: 0.122323, Val Acc: 0.742268\n",
      "Epoch 12824 - Train Loss: 0.102478, Train Acc: 0.839744 | Val Loss: 0.122319, Val Acc: 0.742268\n",
      "Epoch 12825 - Train Loss: 0.102473, Train Acc: 0.839744 | Val Loss: 0.122315, Val Acc: 0.742268\n",
      "Epoch 12826 - Train Loss: 0.102468, Train Acc: 0.839744 | Val Loss: 0.122311, Val Acc: 0.742268\n",
      "Epoch 12827 - Train Loss: 0.102463, Train Acc: 0.839744 | Val Loss: 0.122308, Val Acc: 0.742268\n",
      "Epoch 12828 - Train Loss: 0.102458, Train Acc: 0.839744 | Val Loss: 0.122304, Val Acc: 0.742268\n",
      "Epoch 12829 - Train Loss: 0.102453, Train Acc: 0.839744 | Val Loss: 0.122300, Val Acc: 0.742268\n",
      "Epoch 12830 - Train Loss: 0.102448, Train Acc: 0.839744 | Val Loss: 0.122296, Val Acc: 0.742268\n",
      "Epoch 12831 - Train Loss: 0.102443, Train Acc: 0.839744 | Val Loss: 0.122292, Val Acc: 0.742268\n",
      "Epoch 12832 - Train Loss: 0.102438, Train Acc: 0.839744 | Val Loss: 0.122289, Val Acc: 0.742268\n",
      "Epoch 12833 - Train Loss: 0.102433, Train Acc: 0.839744 | Val Loss: 0.122285, Val Acc: 0.742268\n",
      "Epoch 12834 - Train Loss: 0.102428, Train Acc: 0.839744 | Val Loss: 0.122281, Val Acc: 0.742268\n",
      "Epoch 12835 - Train Loss: 0.102422, Train Acc: 0.839744 | Val Loss: 0.122277, Val Acc: 0.742268\n",
      "Epoch 12836 - Train Loss: 0.102417, Train Acc: 0.839744 | Val Loss: 0.122273, Val Acc: 0.742268\n",
      "Epoch 12837 - Train Loss: 0.102412, Train Acc: 0.839744 | Val Loss: 0.122270, Val Acc: 0.742268\n",
      "Epoch 12838 - Train Loss: 0.102407, Train Acc: 0.839744 | Val Loss: 0.122266, Val Acc: 0.742268\n",
      "Epoch 12839 - Train Loss: 0.102402, Train Acc: 0.839744 | Val Loss: 0.122262, Val Acc: 0.742268\n",
      "Epoch 12840 - Train Loss: 0.102397, Train Acc: 0.839744 | Val Loss: 0.122258, Val Acc: 0.742268\n",
      "Epoch 12841 - Train Loss: 0.102392, Train Acc: 0.839744 | Val Loss: 0.122255, Val Acc: 0.742268\n",
      "Epoch 12842 - Train Loss: 0.102387, Train Acc: 0.839744 | Val Loss: 0.122251, Val Acc: 0.742268\n",
      "Epoch 12843 - Train Loss: 0.102382, Train Acc: 0.839744 | Val Loss: 0.122247, Val Acc: 0.742268\n",
      "Epoch 12844 - Train Loss: 0.102377, Train Acc: 0.839744 | Val Loss: 0.122243, Val Acc: 0.742268\n",
      "Epoch 12845 - Train Loss: 0.102372, Train Acc: 0.839744 | Val Loss: 0.122239, Val Acc: 0.742268\n",
      "Epoch 12846 - Train Loss: 0.102367, Train Acc: 0.839744 | Val Loss: 0.122236, Val Acc: 0.742268\n",
      "Epoch 12847 - Train Loss: 0.102362, Train Acc: 0.839744 | Val Loss: 0.122232, Val Acc: 0.742268\n",
      "Epoch 12848 - Train Loss: 0.102357, Train Acc: 0.839744 | Val Loss: 0.122228, Val Acc: 0.742268\n",
      "Epoch 12849 - Train Loss: 0.102352, Train Acc: 0.839744 | Val Loss: 0.122224, Val Acc: 0.742268\n",
      "Epoch 12850 - Train Loss: 0.102347, Train Acc: 0.839744 | Val Loss: 0.122220, Val Acc: 0.742268\n",
      "Epoch 12851 - Train Loss: 0.102342, Train Acc: 0.839744 | Val Loss: 0.122217, Val Acc: 0.742268\n",
      "Epoch 12852 - Train Loss: 0.102337, Train Acc: 0.839744 | Val Loss: 0.122213, Val Acc: 0.742268\n",
      "Epoch 12853 - Train Loss: 0.102332, Train Acc: 0.839744 | Val Loss: 0.122209, Val Acc: 0.742268\n",
      "Epoch 12854 - Train Loss: 0.102327, Train Acc: 0.839744 | Val Loss: 0.122205, Val Acc: 0.742268\n",
      "Epoch 12855 - Train Loss: 0.102322, Train Acc: 0.839744 | Val Loss: 0.122202, Val Acc: 0.742268\n",
      "Epoch 12856 - Train Loss: 0.102317, Train Acc: 0.839744 | Val Loss: 0.122198, Val Acc: 0.742268\n",
      "Epoch 12857 - Train Loss: 0.102312, Train Acc: 0.839744 | Val Loss: 0.122194, Val Acc: 0.742268\n",
      "Epoch 12858 - Train Loss: 0.102307, Train Acc: 0.839744 | Val Loss: 0.122190, Val Acc: 0.742268\n",
      "Epoch 12859 - Train Loss: 0.102302, Train Acc: 0.839744 | Val Loss: 0.122187, Val Acc: 0.742268\n",
      "Epoch 12860 - Train Loss: 0.102297, Train Acc: 0.839744 | Val Loss: 0.122183, Val Acc: 0.742268\n",
      "Epoch 12861 - Train Loss: 0.102292, Train Acc: 0.839744 | Val Loss: 0.122179, Val Acc: 0.742268\n",
      "Epoch 12862 - Train Loss: 0.102287, Train Acc: 0.839744 | Val Loss: 0.122175, Val Acc: 0.742268\n",
      "Epoch 12863 - Train Loss: 0.102282, Train Acc: 0.839744 | Val Loss: 0.122171, Val Acc: 0.742268\n",
      "Epoch 12864 - Train Loss: 0.102277, Train Acc: 0.839744 | Val Loss: 0.122168, Val Acc: 0.742268\n",
      "Epoch 12865 - Train Loss: 0.102272, Train Acc: 0.839744 | Val Loss: 0.122164, Val Acc: 0.742268\n",
      "Epoch 12866 - Train Loss: 0.102266, Train Acc: 0.839744 | Val Loss: 0.122160, Val Acc: 0.742268\n",
      "Epoch 12867 - Train Loss: 0.102261, Train Acc: 0.839744 | Val Loss: 0.122156, Val Acc: 0.742268\n",
      "Epoch 12868 - Train Loss: 0.102256, Train Acc: 0.839744 | Val Loss: 0.122153, Val Acc: 0.742268\n",
      "Epoch 12869 - Train Loss: 0.102251, Train Acc: 0.839744 | Val Loss: 0.122149, Val Acc: 0.742268\n",
      "Epoch 12870 - Train Loss: 0.102246, Train Acc: 0.839744 | Val Loss: 0.122145, Val Acc: 0.742268\n",
      "Epoch 12871 - Train Loss: 0.102241, Train Acc: 0.839744 | Val Loss: 0.122141, Val Acc: 0.742268\n",
      "Epoch 12872 - Train Loss: 0.102236, Train Acc: 0.839744 | Val Loss: 0.122138, Val Acc: 0.742268\n",
      "Epoch 12873 - Train Loss: 0.102231, Train Acc: 0.839744 | Val Loss: 0.122134, Val Acc: 0.742268\n",
      "Epoch 12874 - Train Loss: 0.102226, Train Acc: 0.839744 | Val Loss: 0.122130, Val Acc: 0.742268\n",
      "Epoch 12875 - Train Loss: 0.102221, Train Acc: 0.838462 | Val Loss: 0.122126, Val Acc: 0.742268\n",
      "Epoch 12876 - Train Loss: 0.102216, Train Acc: 0.838462 | Val Loss: 0.122122, Val Acc: 0.742268\n",
      "Epoch 12877 - Train Loss: 0.102211, Train Acc: 0.838462 | Val Loss: 0.122119, Val Acc: 0.742268\n",
      "Epoch 12878 - Train Loss: 0.102206, Train Acc: 0.838462 | Val Loss: 0.122115, Val Acc: 0.742268\n",
      "Epoch 12879 - Train Loss: 0.102201, Train Acc: 0.838462 | Val Loss: 0.122111, Val Acc: 0.742268\n",
      "Epoch 12880 - Train Loss: 0.102196, Train Acc: 0.838462 | Val Loss: 0.122107, Val Acc: 0.742268\n",
      "Epoch 12881 - Train Loss: 0.102191, Train Acc: 0.838462 | Val Loss: 0.122104, Val Acc: 0.742268\n",
      "Epoch 12882 - Train Loss: 0.102186, Train Acc: 0.838462 | Val Loss: 0.122100, Val Acc: 0.742268\n",
      "Epoch 12883 - Train Loss: 0.102181, Train Acc: 0.838462 | Val Loss: 0.122096, Val Acc: 0.742268\n",
      "Epoch 12884 - Train Loss: 0.102176, Train Acc: 0.838462 | Val Loss: 0.122092, Val Acc: 0.742268\n",
      "Epoch 12885 - Train Loss: 0.102171, Train Acc: 0.838462 | Val Loss: 0.122089, Val Acc: 0.742268\n",
      "Epoch 12886 - Train Loss: 0.102166, Train Acc: 0.838462 | Val Loss: 0.122085, Val Acc: 0.742268\n",
      "Epoch 12887 - Train Loss: 0.102161, Train Acc: 0.838462 | Val Loss: 0.122081, Val Acc: 0.742268\n",
      "Epoch 12888 - Train Loss: 0.102156, Train Acc: 0.838462 | Val Loss: 0.122077, Val Acc: 0.742268\n",
      "Epoch 12889 - Train Loss: 0.102151, Train Acc: 0.838462 | Val Loss: 0.122074, Val Acc: 0.742268\n",
      "Epoch 12890 - Train Loss: 0.102146, Train Acc: 0.838462 | Val Loss: 0.122070, Val Acc: 0.742268\n",
      "Epoch 12891 - Train Loss: 0.102141, Train Acc: 0.838462 | Val Loss: 0.122066, Val Acc: 0.742268\n",
      "Epoch 12892 - Train Loss: 0.102136, Train Acc: 0.838462 | Val Loss: 0.122062, Val Acc: 0.742268\n",
      "Epoch 12893 - Train Loss: 0.102131, Train Acc: 0.838462 | Val Loss: 0.122059, Val Acc: 0.742268\n",
      "Epoch 12894 - Train Loss: 0.102126, Train Acc: 0.838462 | Val Loss: 0.122055, Val Acc: 0.742268\n",
      "Epoch 12895 - Train Loss: 0.102121, Train Acc: 0.838462 | Val Loss: 0.122051, Val Acc: 0.742268\n",
      "Epoch 12896 - Train Loss: 0.102116, Train Acc: 0.838462 | Val Loss: 0.122047, Val Acc: 0.742268\n",
      "Epoch 12897 - Train Loss: 0.102111, Train Acc: 0.838462 | Val Loss: 0.122043, Val Acc: 0.742268\n",
      "Epoch 12898 - Train Loss: 0.102106, Train Acc: 0.838462 | Val Loss: 0.122040, Val Acc: 0.742268\n",
      "Epoch 12899 - Train Loss: 0.102101, Train Acc: 0.838462 | Val Loss: 0.122036, Val Acc: 0.742268\n",
      "Epoch 12900 - Train Loss: 0.102096, Train Acc: 0.838462 | Val Loss: 0.122032, Val Acc: 0.742268\n",
      "Epoch 12901 - Train Loss: 0.102091, Train Acc: 0.838462 | Val Loss: 0.122028, Val Acc: 0.742268\n",
      "Epoch 12902 - Train Loss: 0.102086, Train Acc: 0.838462 | Val Loss: 0.122025, Val Acc: 0.742268\n",
      "Epoch 12903 - Train Loss: 0.102081, Train Acc: 0.838462 | Val Loss: 0.122021, Val Acc: 0.742268\n",
      "Epoch 12904 - Train Loss: 0.102076, Train Acc: 0.838462 | Val Loss: 0.122017, Val Acc: 0.742268\n",
      "Epoch 12905 - Train Loss: 0.102071, Train Acc: 0.838462 | Val Loss: 0.122013, Val Acc: 0.742268\n",
      "Epoch 12906 - Train Loss: 0.102066, Train Acc: 0.838462 | Val Loss: 0.122010, Val Acc: 0.742268\n",
      "Epoch 12907 - Train Loss: 0.102061, Train Acc: 0.838462 | Val Loss: 0.122006, Val Acc: 0.742268\n",
      "Epoch 12908 - Train Loss: 0.102056, Train Acc: 0.838462 | Val Loss: 0.122002, Val Acc: 0.742268\n",
      "Epoch 12909 - Train Loss: 0.102051, Train Acc: 0.838462 | Val Loss: 0.121998, Val Acc: 0.742268\n",
      "Epoch 12910 - Train Loss: 0.102046, Train Acc: 0.838462 | Val Loss: 0.121995, Val Acc: 0.742268\n",
      "Epoch 12911 - Train Loss: 0.102041, Train Acc: 0.838462 | Val Loss: 0.121991, Val Acc: 0.742268\n",
      "Epoch 12912 - Train Loss: 0.102036, Train Acc: 0.838462 | Val Loss: 0.121987, Val Acc: 0.742268\n",
      "Epoch 12913 - Train Loss: 0.102031, Train Acc: 0.838462 | Val Loss: 0.121983, Val Acc: 0.742268\n",
      "Epoch 12914 - Train Loss: 0.102026, Train Acc: 0.838462 | Val Loss: 0.121980, Val Acc: 0.742268\n",
      "Epoch 12915 - Train Loss: 0.102021, Train Acc: 0.838462 | Val Loss: 0.121976, Val Acc: 0.742268\n",
      "Epoch 12916 - Train Loss: 0.102016, Train Acc: 0.838462 | Val Loss: 0.121972, Val Acc: 0.742268\n",
      "Epoch 12917 - Train Loss: 0.102011, Train Acc: 0.838462 | Val Loss: 0.121968, Val Acc: 0.742268\n",
      "Epoch 12918 - Train Loss: 0.102006, Train Acc: 0.838462 | Val Loss: 0.121965, Val Acc: 0.742268\n",
      "Epoch 12919 - Train Loss: 0.102001, Train Acc: 0.838462 | Val Loss: 0.121961, Val Acc: 0.742268\n",
      "Epoch 12920 - Train Loss: 0.101996, Train Acc: 0.838462 | Val Loss: 0.121957, Val Acc: 0.742268\n",
      "Epoch 12921 - Train Loss: 0.101991, Train Acc: 0.838462 | Val Loss: 0.121954, Val Acc: 0.742268\n",
      "Epoch 12922 - Train Loss: 0.101986, Train Acc: 0.838462 | Val Loss: 0.121950, Val Acc: 0.742268\n",
      "Epoch 12923 - Train Loss: 0.101981, Train Acc: 0.838462 | Val Loss: 0.121946, Val Acc: 0.742268\n",
      "Epoch 12924 - Train Loss: 0.101976, Train Acc: 0.838462 | Val Loss: 0.121942, Val Acc: 0.742268\n",
      "Epoch 12925 - Train Loss: 0.101971, Train Acc: 0.838462 | Val Loss: 0.121939, Val Acc: 0.742268\n",
      "Epoch 12926 - Train Loss: 0.101966, Train Acc: 0.838462 | Val Loss: 0.121935, Val Acc: 0.742268\n",
      "Epoch 12927 - Train Loss: 0.101961, Train Acc: 0.838462 | Val Loss: 0.121931, Val Acc: 0.742268\n",
      "Epoch 12928 - Train Loss: 0.101956, Train Acc: 0.838462 | Val Loss: 0.121927, Val Acc: 0.742268\n",
      "Epoch 12929 - Train Loss: 0.101952, Train Acc: 0.838462 | Val Loss: 0.121924, Val Acc: 0.742268\n",
      "Epoch 12930 - Train Loss: 0.101947, Train Acc: 0.838462 | Val Loss: 0.121920, Val Acc: 0.742268\n",
      "Epoch 12931 - Train Loss: 0.101942, Train Acc: 0.838462 | Val Loss: 0.121916, Val Acc: 0.742268\n",
      "Epoch 12932 - Train Loss: 0.101937, Train Acc: 0.838462 | Val Loss: 0.121912, Val Acc: 0.742268\n",
      "Epoch 12933 - Train Loss: 0.101932, Train Acc: 0.838462 | Val Loss: 0.121909, Val Acc: 0.742268\n",
      "Epoch 12934 - Train Loss: 0.101927, Train Acc: 0.838462 | Val Loss: 0.121905, Val Acc: 0.742268\n",
      "Epoch 12935 - Train Loss: 0.101922, Train Acc: 0.838462 | Val Loss: 0.121901, Val Acc: 0.742268\n",
      "Epoch 12936 - Train Loss: 0.101917, Train Acc: 0.838462 | Val Loss: 0.121897, Val Acc: 0.742268\n",
      "Epoch 12937 - Train Loss: 0.101912, Train Acc: 0.838462 | Val Loss: 0.121894, Val Acc: 0.742268\n",
      "Epoch 12938 - Train Loss: 0.101907, Train Acc: 0.838462 | Val Loss: 0.121890, Val Acc: 0.742268\n",
      "Epoch 12939 - Train Loss: 0.101902, Train Acc: 0.838462 | Val Loss: 0.121886, Val Acc: 0.742268\n",
      "Epoch 12940 - Train Loss: 0.101897, Train Acc: 0.838462 | Val Loss: 0.121883, Val Acc: 0.742268\n",
      "Epoch 12941 - Train Loss: 0.101892, Train Acc: 0.838462 | Val Loss: 0.121879, Val Acc: 0.742268\n",
      "Epoch 12942 - Train Loss: 0.101887, Train Acc: 0.838462 | Val Loss: 0.121875, Val Acc: 0.742268\n",
      "Epoch 12943 - Train Loss: 0.101882, Train Acc: 0.838462 | Val Loss: 0.121871, Val Acc: 0.742268\n",
      "Epoch 12944 - Train Loss: 0.101877, Train Acc: 0.838462 | Val Loss: 0.121868, Val Acc: 0.742268\n",
      "Epoch 12945 - Train Loss: 0.101872, Train Acc: 0.838462 | Val Loss: 0.121864, Val Acc: 0.742268\n",
      "Epoch 12946 - Train Loss: 0.101867, Train Acc: 0.838462 | Val Loss: 0.121860, Val Acc: 0.742268\n",
      "Epoch 12947 - Train Loss: 0.101862, Train Acc: 0.838462 | Val Loss: 0.121856, Val Acc: 0.742268\n",
      "Epoch 12948 - Train Loss: 0.101857, Train Acc: 0.838462 | Val Loss: 0.121853, Val Acc: 0.742268\n",
      "Epoch 12949 - Train Loss: 0.101852, Train Acc: 0.838462 | Val Loss: 0.121849, Val Acc: 0.742268\n",
      "Epoch 12950 - Train Loss: 0.101847, Train Acc: 0.838462 | Val Loss: 0.121845, Val Acc: 0.742268\n",
      "Epoch 12951 - Train Loss: 0.101842, Train Acc: 0.838462 | Val Loss: 0.121842, Val Acc: 0.742268\n",
      "Epoch 12952 - Train Loss: 0.101837, Train Acc: 0.838462 | Val Loss: 0.121838, Val Acc: 0.742268\n",
      "Epoch 12953 - Train Loss: 0.101832, Train Acc: 0.838462 | Val Loss: 0.121834, Val Acc: 0.742268\n",
      "Epoch 12954 - Train Loss: 0.101827, Train Acc: 0.838462 | Val Loss: 0.121830, Val Acc: 0.742268\n",
      "Epoch 12955 - Train Loss: 0.101822, Train Acc: 0.838462 | Val Loss: 0.121827, Val Acc: 0.742268\n",
      "Epoch 12956 - Train Loss: 0.101817, Train Acc: 0.838462 | Val Loss: 0.121823, Val Acc: 0.742268\n",
      "Epoch 12957 - Train Loss: 0.101812, Train Acc: 0.838462 | Val Loss: 0.121819, Val Acc: 0.742268\n",
      "Epoch 12958 - Train Loss: 0.101807, Train Acc: 0.838462 | Val Loss: 0.121816, Val Acc: 0.742268\n",
      "Epoch 12959 - Train Loss: 0.101802, Train Acc: 0.838462 | Val Loss: 0.121812, Val Acc: 0.742268\n",
      "Epoch 12960 - Train Loss: 0.101798, Train Acc: 0.838462 | Val Loss: 0.121808, Val Acc: 0.742268\n",
      "Epoch 12961 - Train Loss: 0.101793, Train Acc: 0.838462 | Val Loss: 0.121804, Val Acc: 0.742268\n",
      "Epoch 12962 - Train Loss: 0.101788, Train Acc: 0.838462 | Val Loss: 0.121801, Val Acc: 0.742268\n",
      "Epoch 12963 - Train Loss: 0.101783, Train Acc: 0.838462 | Val Loss: 0.121797, Val Acc: 0.742268\n",
      "Epoch 12964 - Train Loss: 0.101778, Train Acc: 0.838462 | Val Loss: 0.121793, Val Acc: 0.742268\n",
      "Epoch 12965 - Train Loss: 0.101773, Train Acc: 0.838462 | Val Loss: 0.121790, Val Acc: 0.742268\n",
      "Epoch 12966 - Train Loss: 0.101768, Train Acc: 0.838462 | Val Loss: 0.121786, Val Acc: 0.742268\n",
      "Epoch 12967 - Train Loss: 0.101763, Train Acc: 0.838462 | Val Loss: 0.121782, Val Acc: 0.742268\n",
      "Epoch 12968 - Train Loss: 0.101758, Train Acc: 0.838462 | Val Loss: 0.121778, Val Acc: 0.742268\n",
      "Epoch 12969 - Train Loss: 0.101753, Train Acc: 0.838462 | Val Loss: 0.121775, Val Acc: 0.742268\n",
      "Epoch 12970 - Train Loss: 0.101748, Train Acc: 0.838462 | Val Loss: 0.121771, Val Acc: 0.742268\n",
      "Epoch 12971 - Train Loss: 0.101743, Train Acc: 0.838462 | Val Loss: 0.121767, Val Acc: 0.742268\n",
      "Epoch 12972 - Train Loss: 0.101738, Train Acc: 0.838462 | Val Loss: 0.121764, Val Acc: 0.742268\n",
      "Epoch 12973 - Train Loss: 0.101733, Train Acc: 0.838462 | Val Loss: 0.121760, Val Acc: 0.742268\n",
      "Epoch 12974 - Train Loss: 0.101728, Train Acc: 0.838462 | Val Loss: 0.121756, Val Acc: 0.742268\n",
      "Epoch 12975 - Train Loss: 0.101723, Train Acc: 0.838462 | Val Loss: 0.121753, Val Acc: 0.742268\n",
      "Epoch 12976 - Train Loss: 0.101718, Train Acc: 0.838462 | Val Loss: 0.121749, Val Acc: 0.742268\n",
      "Epoch 12977 - Train Loss: 0.101713, Train Acc: 0.838462 | Val Loss: 0.121745, Val Acc: 0.742268\n",
      "Epoch 12978 - Train Loss: 0.101708, Train Acc: 0.838462 | Val Loss: 0.121741, Val Acc: 0.742268\n",
      "Epoch 12979 - Train Loss: 0.101703, Train Acc: 0.838462 | Val Loss: 0.121738, Val Acc: 0.742268\n",
      "Epoch 12980 - Train Loss: 0.101699, Train Acc: 0.838462 | Val Loss: 0.121734, Val Acc: 0.742268\n",
      "Epoch 12981 - Train Loss: 0.101694, Train Acc: 0.838462 | Val Loss: 0.121730, Val Acc: 0.742268\n",
      "Epoch 12982 - Train Loss: 0.101689, Train Acc: 0.838462 | Val Loss: 0.121727, Val Acc: 0.742268\n",
      "Epoch 12983 - Train Loss: 0.101684, Train Acc: 0.838462 | Val Loss: 0.121723, Val Acc: 0.742268\n",
      "Epoch 12984 - Train Loss: 0.101679, Train Acc: 0.838462 | Val Loss: 0.121719, Val Acc: 0.742268\n",
      "Epoch 12985 - Train Loss: 0.101674, Train Acc: 0.838462 | Val Loss: 0.121716, Val Acc: 0.742268\n",
      "Epoch 12986 - Train Loss: 0.101669, Train Acc: 0.838462 | Val Loss: 0.121712, Val Acc: 0.742268\n",
      "Epoch 12987 - Train Loss: 0.101664, Train Acc: 0.838462 | Val Loss: 0.121708, Val Acc: 0.742268\n",
      "Epoch 12988 - Train Loss: 0.101659, Train Acc: 0.838462 | Val Loss: 0.121704, Val Acc: 0.742268\n",
      "Epoch 12989 - Train Loss: 0.101654, Train Acc: 0.838462 | Val Loss: 0.121701, Val Acc: 0.742268\n",
      "Epoch 12990 - Train Loss: 0.101649, Train Acc: 0.838462 | Val Loss: 0.121697, Val Acc: 0.742268\n",
      "Epoch 12991 - Train Loss: 0.101644, Train Acc: 0.838462 | Val Loss: 0.121693, Val Acc: 0.742268\n",
      "Epoch 12992 - Train Loss: 0.101639, Train Acc: 0.838462 | Val Loss: 0.121690, Val Acc: 0.742268\n",
      "Epoch 12993 - Train Loss: 0.101634, Train Acc: 0.839744 | Val Loss: 0.121686, Val Acc: 0.742268\n",
      "Epoch 12994 - Train Loss: 0.101629, Train Acc: 0.839744 | Val Loss: 0.121682, Val Acc: 0.742268\n",
      "Epoch 12995 - Train Loss: 0.101624, Train Acc: 0.839744 | Val Loss: 0.121679, Val Acc: 0.742268\n",
      "Epoch 12996 - Train Loss: 0.101620, Train Acc: 0.839744 | Val Loss: 0.121675, Val Acc: 0.742268\n",
      "Epoch 12997 - Train Loss: 0.101615, Train Acc: 0.839744 | Val Loss: 0.121671, Val Acc: 0.742268\n",
      "Epoch 12998 - Train Loss: 0.101610, Train Acc: 0.839744 | Val Loss: 0.121668, Val Acc: 0.742268\n",
      "Epoch 12999 - Train Loss: 0.101605, Train Acc: 0.839744 | Val Loss: 0.121664, Val Acc: 0.742268\n",
      "Epoch 13000 - Train Loss: 0.101600, Train Acc: 0.839744 | Val Loss: 0.121660, Val Acc: 0.742268\n",
      "Epoch 13001 - Train Loss: 0.101595, Train Acc: 0.839744 | Val Loss: 0.121656, Val Acc: 0.742268\n",
      "Epoch 13002 - Train Loss: 0.101590, Train Acc: 0.839744 | Val Loss: 0.121653, Val Acc: 0.742268\n",
      "Epoch 13003 - Train Loss: 0.101585, Train Acc: 0.839744 | Val Loss: 0.121649, Val Acc: 0.742268\n",
      "Epoch 13004 - Train Loss: 0.101580, Train Acc: 0.839744 | Val Loss: 0.121645, Val Acc: 0.742268\n",
      "Epoch 13005 - Train Loss: 0.101575, Train Acc: 0.839744 | Val Loss: 0.121642, Val Acc: 0.742268\n",
      "Epoch 13006 - Train Loss: 0.101570, Train Acc: 0.839744 | Val Loss: 0.121638, Val Acc: 0.742268\n",
      "Epoch 13007 - Train Loss: 0.101565, Train Acc: 0.839744 | Val Loss: 0.121634, Val Acc: 0.742268\n",
      "Epoch 13008 - Train Loss: 0.101560, Train Acc: 0.839744 | Val Loss: 0.121631, Val Acc: 0.742268\n",
      "Epoch 13009 - Train Loss: 0.101555, Train Acc: 0.839744 | Val Loss: 0.121627, Val Acc: 0.742268\n",
      "Epoch 13010 - Train Loss: 0.101551, Train Acc: 0.839744 | Val Loss: 0.121623, Val Acc: 0.742268\n",
      "Epoch 13011 - Train Loss: 0.101546, Train Acc: 0.839744 | Val Loss: 0.121620, Val Acc: 0.742268\n",
      "Epoch 13012 - Train Loss: 0.101541, Train Acc: 0.839744 | Val Loss: 0.121616, Val Acc: 0.742268\n",
      "Epoch 13013 - Train Loss: 0.101536, Train Acc: 0.839744 | Val Loss: 0.121612, Val Acc: 0.742268\n",
      "Epoch 13014 - Train Loss: 0.101531, Train Acc: 0.839744 | Val Loss: 0.121609, Val Acc: 0.742268\n",
      "Epoch 13015 - Train Loss: 0.101526, Train Acc: 0.839744 | Val Loss: 0.121605, Val Acc: 0.742268\n",
      "Epoch 13016 - Train Loss: 0.101521, Train Acc: 0.839744 | Val Loss: 0.121601, Val Acc: 0.742268\n",
      "Epoch 13017 - Train Loss: 0.101516, Train Acc: 0.839744 | Val Loss: 0.121598, Val Acc: 0.742268\n",
      "Epoch 13018 - Train Loss: 0.101511, Train Acc: 0.839744 | Val Loss: 0.121594, Val Acc: 0.742268\n",
      "Epoch 13019 - Train Loss: 0.101506, Train Acc: 0.839744 | Val Loss: 0.121590, Val Acc: 0.742268\n",
      "Epoch 13020 - Train Loss: 0.101501, Train Acc: 0.839744 | Val Loss: 0.121587, Val Acc: 0.742268\n",
      "Epoch 13021 - Train Loss: 0.101496, Train Acc: 0.839744 | Val Loss: 0.121583, Val Acc: 0.742268\n",
      "Epoch 13022 - Train Loss: 0.101491, Train Acc: 0.839744 | Val Loss: 0.121579, Val Acc: 0.742268\n",
      "Epoch 13023 - Train Loss: 0.101487, Train Acc: 0.839744 | Val Loss: 0.121576, Val Acc: 0.742268\n",
      "Epoch 13024 - Train Loss: 0.101482, Train Acc: 0.839744 | Val Loss: 0.121572, Val Acc: 0.742268\n",
      "Epoch 13025 - Train Loss: 0.101477, Train Acc: 0.839744 | Val Loss: 0.121568, Val Acc: 0.742268\n",
      "Epoch 13026 - Train Loss: 0.101472, Train Acc: 0.839744 | Val Loss: 0.121565, Val Acc: 0.742268\n",
      "Epoch 13027 - Train Loss: 0.101467, Train Acc: 0.839744 | Val Loss: 0.121561, Val Acc: 0.742268\n",
      "Epoch 13028 - Train Loss: 0.101462, Train Acc: 0.839744 | Val Loss: 0.121557, Val Acc: 0.742268\n",
      "Epoch 13029 - Train Loss: 0.101457, Train Acc: 0.839744 | Val Loss: 0.121554, Val Acc: 0.742268\n",
      "Epoch 13030 - Train Loss: 0.101452, Train Acc: 0.839744 | Val Loss: 0.121550, Val Acc: 0.742268\n",
      "Epoch 13031 - Train Loss: 0.101447, Train Acc: 0.839744 | Val Loss: 0.121546, Val Acc: 0.742268\n",
      "Epoch 13032 - Train Loss: 0.101442, Train Acc: 0.839744 | Val Loss: 0.121543, Val Acc: 0.742268\n",
      "Epoch 13033 - Train Loss: 0.101437, Train Acc: 0.839744 | Val Loss: 0.121539, Val Acc: 0.742268\n",
      "Epoch 13034 - Train Loss: 0.101433, Train Acc: 0.841026 | Val Loss: 0.121535, Val Acc: 0.742268\n",
      "Epoch 13035 - Train Loss: 0.101428, Train Acc: 0.841026 | Val Loss: 0.121532, Val Acc: 0.742268\n",
      "Epoch 13036 - Train Loss: 0.101423, Train Acc: 0.841026 | Val Loss: 0.121528, Val Acc: 0.742268\n",
      "Epoch 13037 - Train Loss: 0.101418, Train Acc: 0.841026 | Val Loss: 0.121524, Val Acc: 0.742268\n",
      "Epoch 13038 - Train Loss: 0.101413, Train Acc: 0.841026 | Val Loss: 0.121521, Val Acc: 0.742268\n",
      "Epoch 13039 - Train Loss: 0.101408, Train Acc: 0.841026 | Val Loss: 0.121517, Val Acc: 0.742268\n",
      "Epoch 13040 - Train Loss: 0.101403, Train Acc: 0.841026 | Val Loss: 0.121513, Val Acc: 0.742268\n",
      "Epoch 13041 - Train Loss: 0.101398, Train Acc: 0.841026 | Val Loss: 0.121510, Val Acc: 0.742268\n",
      "Epoch 13042 - Train Loss: 0.101393, Train Acc: 0.841026 | Val Loss: 0.121506, Val Acc: 0.742268\n",
      "Epoch 13043 - Train Loss: 0.101388, Train Acc: 0.841026 | Val Loss: 0.121502, Val Acc: 0.742268\n",
      "Epoch 13044 - Train Loss: 0.101383, Train Acc: 0.841026 | Val Loss: 0.121499, Val Acc: 0.742268\n",
      "Epoch 13045 - Train Loss: 0.101379, Train Acc: 0.841026 | Val Loss: 0.121495, Val Acc: 0.742268\n",
      "Epoch 13046 - Train Loss: 0.101374, Train Acc: 0.841026 | Val Loss: 0.121491, Val Acc: 0.742268\n",
      "Epoch 13047 - Train Loss: 0.101369, Train Acc: 0.841026 | Val Loss: 0.121488, Val Acc: 0.742268\n",
      "Epoch 13048 - Train Loss: 0.101364, Train Acc: 0.841026 | Val Loss: 0.121484, Val Acc: 0.742268\n",
      "Epoch 13049 - Train Loss: 0.101359, Train Acc: 0.841026 | Val Loss: 0.121480, Val Acc: 0.742268\n",
      "Epoch 13050 - Train Loss: 0.101354, Train Acc: 0.841026 | Val Loss: 0.121477, Val Acc: 0.742268\n",
      "Epoch 13051 - Train Loss: 0.101349, Train Acc: 0.841026 | Val Loss: 0.121473, Val Acc: 0.742268\n",
      "Epoch 13052 - Train Loss: 0.101344, Train Acc: 0.841026 | Val Loss: 0.121469, Val Acc: 0.742268\n",
      "Epoch 13053 - Train Loss: 0.101339, Train Acc: 0.841026 | Val Loss: 0.121466, Val Acc: 0.742268\n",
      "Epoch 13054 - Train Loss: 0.101335, Train Acc: 0.841026 | Val Loss: 0.121462, Val Acc: 0.742268\n",
      "Epoch 13055 - Train Loss: 0.101330, Train Acc: 0.841026 | Val Loss: 0.121459, Val Acc: 0.742268\n",
      "Epoch 13056 - Train Loss: 0.101325, Train Acc: 0.841026 | Val Loss: 0.121455, Val Acc: 0.742268\n",
      "Epoch 13057 - Train Loss: 0.101320, Train Acc: 0.841026 | Val Loss: 0.121451, Val Acc: 0.742268\n",
      "Epoch 13058 - Train Loss: 0.101315, Train Acc: 0.841026 | Val Loss: 0.121448, Val Acc: 0.742268\n",
      "Epoch 13059 - Train Loss: 0.101310, Train Acc: 0.841026 | Val Loss: 0.121444, Val Acc: 0.742268\n",
      "Epoch 13060 - Train Loss: 0.101305, Train Acc: 0.841026 | Val Loss: 0.121440, Val Acc: 0.742268\n",
      "Epoch 13061 - Train Loss: 0.101300, Train Acc: 0.841026 | Val Loss: 0.121437, Val Acc: 0.742268\n",
      "Epoch 13062 - Train Loss: 0.101295, Train Acc: 0.841026 | Val Loss: 0.121433, Val Acc: 0.742268\n",
      "Epoch 13063 - Train Loss: 0.101290, Train Acc: 0.841026 | Val Loss: 0.121429, Val Acc: 0.742268\n",
      "Epoch 13064 - Train Loss: 0.101286, Train Acc: 0.841026 | Val Loss: 0.121426, Val Acc: 0.742268\n",
      "Epoch 13065 - Train Loss: 0.101281, Train Acc: 0.841026 | Val Loss: 0.121422, Val Acc: 0.742268\n",
      "Epoch 13066 - Train Loss: 0.101276, Train Acc: 0.842308 | Val Loss: 0.121418, Val Acc: 0.742268\n",
      "Epoch 13067 - Train Loss: 0.101271, Train Acc: 0.842308 | Val Loss: 0.121415, Val Acc: 0.742268\n",
      "Epoch 13068 - Train Loss: 0.101266, Train Acc: 0.842308 | Val Loss: 0.121411, Val Acc: 0.742268\n",
      "Epoch 13069 - Train Loss: 0.101261, Train Acc: 0.842308 | Val Loss: 0.121408, Val Acc: 0.742268\n",
      "Epoch 13070 - Train Loss: 0.101256, Train Acc: 0.842308 | Val Loss: 0.121404, Val Acc: 0.742268\n",
      "Epoch 13071 - Train Loss: 0.101251, Train Acc: 0.842308 | Val Loss: 0.121400, Val Acc: 0.742268\n",
      "Epoch 13072 - Train Loss: 0.101246, Train Acc: 0.842308 | Val Loss: 0.121397, Val Acc: 0.742268\n",
      "Epoch 13073 - Train Loss: 0.101242, Train Acc: 0.842308 | Val Loss: 0.121393, Val Acc: 0.742268\n",
      "Epoch 13074 - Train Loss: 0.101237, Train Acc: 0.842308 | Val Loss: 0.121389, Val Acc: 0.742268\n",
      "Epoch 13075 - Train Loss: 0.101232, Train Acc: 0.842308 | Val Loss: 0.121386, Val Acc: 0.742268\n",
      "Epoch 13076 - Train Loss: 0.101227, Train Acc: 0.842308 | Val Loss: 0.121382, Val Acc: 0.742268\n",
      "Epoch 13077 - Train Loss: 0.101222, Train Acc: 0.842308 | Val Loss: 0.121378, Val Acc: 0.742268\n",
      "Epoch 13078 - Train Loss: 0.101217, Train Acc: 0.842308 | Val Loss: 0.121375, Val Acc: 0.742268\n",
      "Epoch 13079 - Train Loss: 0.101212, Train Acc: 0.842308 | Val Loss: 0.121371, Val Acc: 0.742268\n",
      "Epoch 13080 - Train Loss: 0.101207, Train Acc: 0.842308 | Val Loss: 0.121368, Val Acc: 0.742268\n",
      "Epoch 13081 - Train Loss: 0.101203, Train Acc: 0.842308 | Val Loss: 0.121364, Val Acc: 0.742268\n",
      "Epoch 13082 - Train Loss: 0.101198, Train Acc: 0.842308 | Val Loss: 0.121360, Val Acc: 0.742268\n",
      "Epoch 13083 - Train Loss: 0.101193, Train Acc: 0.842308 | Val Loss: 0.121357, Val Acc: 0.742268\n",
      "Epoch 13084 - Train Loss: 0.101188, Train Acc: 0.842308 | Val Loss: 0.121353, Val Acc: 0.742268\n",
      "Epoch 13085 - Train Loss: 0.101183, Train Acc: 0.842308 | Val Loss: 0.121349, Val Acc: 0.742268\n",
      "Epoch 13086 - Train Loss: 0.101178, Train Acc: 0.842308 | Val Loss: 0.121346, Val Acc: 0.742268\n",
      "Epoch 13087 - Train Loss: 0.101173, Train Acc: 0.842308 | Val Loss: 0.121342, Val Acc: 0.742268\n",
      "Epoch 13088 - Train Loss: 0.101168, Train Acc: 0.842308 | Val Loss: 0.121339, Val Acc: 0.742268\n",
      "Epoch 13089 - Train Loss: 0.101164, Train Acc: 0.842308 | Val Loss: 0.121335, Val Acc: 0.742268\n",
      "Epoch 13090 - Train Loss: 0.101159, Train Acc: 0.842308 | Val Loss: 0.121331, Val Acc: 0.742268\n",
      "Epoch 13091 - Train Loss: 0.101154, Train Acc: 0.842308 | Val Loss: 0.121328, Val Acc: 0.742268\n",
      "Epoch 13092 - Train Loss: 0.101149, Train Acc: 0.842308 | Val Loss: 0.121324, Val Acc: 0.742268\n",
      "Epoch 13093 - Train Loss: 0.101144, Train Acc: 0.842308 | Val Loss: 0.121320, Val Acc: 0.742268\n",
      "Epoch 13094 - Train Loss: 0.101139, Train Acc: 0.842308 | Val Loss: 0.121317, Val Acc: 0.742268\n",
      "Epoch 13095 - Train Loss: 0.101134, Train Acc: 0.842308 | Val Loss: 0.121313, Val Acc: 0.742268\n",
      "Epoch 13096 - Train Loss: 0.101129, Train Acc: 0.842308 | Val Loss: 0.121310, Val Acc: 0.742268\n",
      "Epoch 13097 - Train Loss: 0.101125, Train Acc: 0.842308 | Val Loss: 0.121306, Val Acc: 0.742268\n",
      "Epoch 13098 - Train Loss: 0.101120, Train Acc: 0.842308 | Val Loss: 0.121302, Val Acc: 0.742268\n",
      "Epoch 13099 - Train Loss: 0.101115, Train Acc: 0.842308 | Val Loss: 0.121299, Val Acc: 0.742268\n",
      "Epoch 13100 - Train Loss: 0.101110, Train Acc: 0.842308 | Val Loss: 0.121295, Val Acc: 0.742268\n",
      "Epoch 13101 - Train Loss: 0.101105, Train Acc: 0.842308 | Val Loss: 0.121291, Val Acc: 0.742268\n",
      "Epoch 13102 - Train Loss: 0.101100, Train Acc: 0.842308 | Val Loss: 0.121288, Val Acc: 0.742268\n",
      "Epoch 13103 - Train Loss: 0.101095, Train Acc: 0.842308 | Val Loss: 0.121284, Val Acc: 0.742268\n",
      "Epoch 13104 - Train Loss: 0.101091, Train Acc: 0.842308 | Val Loss: 0.121281, Val Acc: 0.742268\n",
      "Epoch 13105 - Train Loss: 0.101086, Train Acc: 0.842308 | Val Loss: 0.121277, Val Acc: 0.742268\n",
      "Epoch 13106 - Train Loss: 0.101081, Train Acc: 0.842308 | Val Loss: 0.121273, Val Acc: 0.742268\n",
      "Epoch 13107 - Train Loss: 0.101076, Train Acc: 0.842308 | Val Loss: 0.121270, Val Acc: 0.742268\n",
      "Epoch 13108 - Train Loss: 0.101071, Train Acc: 0.842308 | Val Loss: 0.121266, Val Acc: 0.742268\n",
      "Epoch 13109 - Train Loss: 0.101066, Train Acc: 0.842308 | Val Loss: 0.121263, Val Acc: 0.742268\n",
      "Epoch 13110 - Train Loss: 0.101061, Train Acc: 0.842308 | Val Loss: 0.121259, Val Acc: 0.742268\n",
      "Epoch 13111 - Train Loss: 0.101057, Train Acc: 0.842308 | Val Loss: 0.121255, Val Acc: 0.742268\n",
      "Epoch 13112 - Train Loss: 0.101052, Train Acc: 0.842308 | Val Loss: 0.121252, Val Acc: 0.742268\n",
      "Epoch 13113 - Train Loss: 0.101047, Train Acc: 0.842308 | Val Loss: 0.121248, Val Acc: 0.742268\n",
      "Epoch 13114 - Train Loss: 0.101042, Train Acc: 0.842308 | Val Loss: 0.121245, Val Acc: 0.742268\n",
      "Epoch 13115 - Train Loss: 0.101037, Train Acc: 0.842308 | Val Loss: 0.121241, Val Acc: 0.742268\n",
      "Epoch 13116 - Train Loss: 0.101032, Train Acc: 0.842308 | Val Loss: 0.121237, Val Acc: 0.742268\n",
      "Epoch 13117 - Train Loss: 0.101027, Train Acc: 0.842308 | Val Loss: 0.121234, Val Acc: 0.742268\n",
      "Epoch 13118 - Train Loss: 0.101023, Train Acc: 0.843590 | Val Loss: 0.121230, Val Acc: 0.742268\n",
      "Epoch 13119 - Train Loss: 0.101018, Train Acc: 0.843590 | Val Loss: 0.121227, Val Acc: 0.742268\n",
      "Epoch 13120 - Train Loss: 0.101013, Train Acc: 0.843590 | Val Loss: 0.121223, Val Acc: 0.742268\n",
      "Epoch 13121 - Train Loss: 0.101008, Train Acc: 0.843590 | Val Loss: 0.121219, Val Acc: 0.742268\n",
      "Epoch 13122 - Train Loss: 0.101003, Train Acc: 0.843590 | Val Loss: 0.121216, Val Acc: 0.742268\n",
      "Epoch 13123 - Train Loss: 0.100998, Train Acc: 0.843590 | Val Loss: 0.121212, Val Acc: 0.742268\n",
      "Epoch 13124 - Train Loss: 0.100993, Train Acc: 0.843590 | Val Loss: 0.121209, Val Acc: 0.742268\n",
      "Epoch 13125 - Train Loss: 0.100989, Train Acc: 0.843590 | Val Loss: 0.121205, Val Acc: 0.742268\n",
      "Epoch 13126 - Train Loss: 0.100984, Train Acc: 0.843590 | Val Loss: 0.121202, Val Acc: 0.742268\n",
      "Epoch 13127 - Train Loss: 0.100979, Train Acc: 0.843590 | Val Loss: 0.121198, Val Acc: 0.742268\n",
      "Epoch 13128 - Train Loss: 0.100974, Train Acc: 0.843590 | Val Loss: 0.121194, Val Acc: 0.742268\n",
      "Epoch 13129 - Train Loss: 0.100969, Train Acc: 0.843590 | Val Loss: 0.121191, Val Acc: 0.742268\n",
      "Epoch 13130 - Train Loss: 0.100964, Train Acc: 0.843590 | Val Loss: 0.121187, Val Acc: 0.742268\n",
      "Epoch 13131 - Train Loss: 0.100960, Train Acc: 0.843590 | Val Loss: 0.121184, Val Acc: 0.742268\n",
      "Epoch 13132 - Train Loss: 0.100955, Train Acc: 0.843590 | Val Loss: 0.121180, Val Acc: 0.742268\n",
      "Epoch 13133 - Train Loss: 0.100950, Train Acc: 0.843590 | Val Loss: 0.121176, Val Acc: 0.742268\n",
      "Epoch 13134 - Train Loss: 0.100945, Train Acc: 0.843590 | Val Loss: 0.121173, Val Acc: 0.742268\n",
      "Epoch 13135 - Train Loss: 0.100940, Train Acc: 0.843590 | Val Loss: 0.121169, Val Acc: 0.742268\n",
      "Epoch 13136 - Train Loss: 0.100935, Train Acc: 0.843590 | Val Loss: 0.121166, Val Acc: 0.742268\n",
      "Epoch 13137 - Train Loss: 0.100930, Train Acc: 0.843590 | Val Loss: 0.121162, Val Acc: 0.742268\n",
      "Epoch 13138 - Train Loss: 0.100926, Train Acc: 0.843590 | Val Loss: 0.121158, Val Acc: 0.742268\n",
      "Epoch 13139 - Train Loss: 0.100921, Train Acc: 0.843590 | Val Loss: 0.121155, Val Acc: 0.742268\n",
      "Epoch 13140 - Train Loss: 0.100916, Train Acc: 0.843590 | Val Loss: 0.121151, Val Acc: 0.742268\n",
      "Epoch 13141 - Train Loss: 0.100911, Train Acc: 0.843590 | Val Loss: 0.121148, Val Acc: 0.742268\n",
      "Epoch 13142 - Train Loss: 0.100906, Train Acc: 0.843590 | Val Loss: 0.121144, Val Acc: 0.742268\n",
      "Epoch 13143 - Train Loss: 0.100901, Train Acc: 0.843590 | Val Loss: 0.121141, Val Acc: 0.742268\n",
      "Epoch 13144 - Train Loss: 0.100897, Train Acc: 0.843590 | Val Loss: 0.121137, Val Acc: 0.742268\n",
      "Epoch 13145 - Train Loss: 0.100892, Train Acc: 0.843590 | Val Loss: 0.121133, Val Acc: 0.742268\n",
      "Epoch 13146 - Train Loss: 0.100887, Train Acc: 0.843590 | Val Loss: 0.121130, Val Acc: 0.742268\n",
      "Epoch 13147 - Train Loss: 0.100882, Train Acc: 0.843590 | Val Loss: 0.121126, Val Acc: 0.742268\n",
      "Epoch 13148 - Train Loss: 0.100877, Train Acc: 0.843590 | Val Loss: 0.121123, Val Acc: 0.742268\n",
      "Epoch 13149 - Train Loss: 0.100872, Train Acc: 0.843590 | Val Loss: 0.121119, Val Acc: 0.742268\n",
      "Epoch 13150 - Train Loss: 0.100868, Train Acc: 0.843590 | Val Loss: 0.121115, Val Acc: 0.742268\n",
      "Epoch 13151 - Train Loss: 0.100863, Train Acc: 0.843590 | Val Loss: 0.121112, Val Acc: 0.742268\n",
      "Epoch 13152 - Train Loss: 0.100858, Train Acc: 0.843590 | Val Loss: 0.121108, Val Acc: 0.742268\n",
      "Epoch 13153 - Train Loss: 0.100853, Train Acc: 0.843590 | Val Loss: 0.121105, Val Acc: 0.742268\n",
      "Epoch 13154 - Train Loss: 0.100848, Train Acc: 0.843590 | Val Loss: 0.121101, Val Acc: 0.742268\n",
      "Epoch 13155 - Train Loss: 0.100843, Train Acc: 0.843590 | Val Loss: 0.121098, Val Acc: 0.742268\n",
      "Epoch 13156 - Train Loss: 0.100839, Train Acc: 0.843590 | Val Loss: 0.121094, Val Acc: 0.742268\n",
      "Epoch 13157 - Train Loss: 0.100834, Train Acc: 0.843590 | Val Loss: 0.121090, Val Acc: 0.742268\n",
      "Epoch 13158 - Train Loss: 0.100829, Train Acc: 0.843590 | Val Loss: 0.121087, Val Acc: 0.742268\n",
      "Epoch 13159 - Train Loss: 0.100824, Train Acc: 0.843590 | Val Loss: 0.121083, Val Acc: 0.742268\n",
      "Epoch 13160 - Train Loss: 0.100819, Train Acc: 0.843590 | Val Loss: 0.121080, Val Acc: 0.742268\n",
      "Epoch 13161 - Train Loss: 0.100814, Train Acc: 0.843590 | Val Loss: 0.121076, Val Acc: 0.742268\n",
      "Epoch 13162 - Train Loss: 0.100810, Train Acc: 0.843590 | Val Loss: 0.121073, Val Acc: 0.742268\n",
      "Epoch 13163 - Train Loss: 0.100805, Train Acc: 0.843590 | Val Loss: 0.121069, Val Acc: 0.742268\n",
      "Epoch 13164 - Train Loss: 0.100800, Train Acc: 0.843590 | Val Loss: 0.121065, Val Acc: 0.742268\n",
      "Epoch 13165 - Train Loss: 0.100795, Train Acc: 0.843590 | Val Loss: 0.121062, Val Acc: 0.742268\n",
      "Epoch 13166 - Train Loss: 0.100790, Train Acc: 0.843590 | Val Loss: 0.121058, Val Acc: 0.742268\n",
      "Epoch 13167 - Train Loss: 0.100786, Train Acc: 0.843590 | Val Loss: 0.121055, Val Acc: 0.742268\n",
      "Epoch 13168 - Train Loss: 0.100781, Train Acc: 0.843590 | Val Loss: 0.121051, Val Acc: 0.742268\n",
      "Epoch 13169 - Train Loss: 0.100776, Train Acc: 0.843590 | Val Loss: 0.121048, Val Acc: 0.742268\n",
      "Epoch 13170 - Train Loss: 0.100771, Train Acc: 0.843590 | Val Loss: 0.121044, Val Acc: 0.742268\n",
      "Epoch 13171 - Train Loss: 0.100766, Train Acc: 0.843590 | Val Loss: 0.121040, Val Acc: 0.742268\n",
      "Epoch 13172 - Train Loss: 0.100761, Train Acc: 0.843590 | Val Loss: 0.121037, Val Acc: 0.742268\n",
      "Epoch 13173 - Train Loss: 0.100757, Train Acc: 0.843590 | Val Loss: 0.121033, Val Acc: 0.742268\n",
      "Epoch 13174 - Train Loss: 0.100752, Train Acc: 0.843590 | Val Loss: 0.121030, Val Acc: 0.742268\n",
      "Epoch 13175 - Train Loss: 0.100747, Train Acc: 0.843590 | Val Loss: 0.121026, Val Acc: 0.742268\n",
      "Epoch 13176 - Train Loss: 0.100742, Train Acc: 0.843590 | Val Loss: 0.121023, Val Acc: 0.742268\n",
      "Epoch 13177 - Train Loss: 0.100737, Train Acc: 0.843590 | Val Loss: 0.121019, Val Acc: 0.742268\n",
      "Epoch 13178 - Train Loss: 0.100733, Train Acc: 0.843590 | Val Loss: 0.121016, Val Acc: 0.742268\n",
      "Epoch 13179 - Train Loss: 0.100728, Train Acc: 0.843590 | Val Loss: 0.121012, Val Acc: 0.742268\n",
      "Epoch 13180 - Train Loss: 0.100723, Train Acc: 0.843590 | Val Loss: 0.121008, Val Acc: 0.742268\n",
      "Epoch 13181 - Train Loss: 0.100718, Train Acc: 0.843590 | Val Loss: 0.121005, Val Acc: 0.742268\n",
      "Epoch 13182 - Train Loss: 0.100713, Train Acc: 0.844872 | Val Loss: 0.121001, Val Acc: 0.742268\n",
      "Epoch 13183 - Train Loss: 0.100708, Train Acc: 0.844872 | Val Loss: 0.120998, Val Acc: 0.742268\n",
      "Epoch 13184 - Train Loss: 0.100704, Train Acc: 0.844872 | Val Loss: 0.120994, Val Acc: 0.742268\n",
      "Epoch 13185 - Train Loss: 0.100699, Train Acc: 0.844872 | Val Loss: 0.120991, Val Acc: 0.742268\n",
      "Epoch 13186 - Train Loss: 0.100694, Train Acc: 0.844872 | Val Loss: 0.120987, Val Acc: 0.742268\n",
      "Epoch 13187 - Train Loss: 0.100689, Train Acc: 0.844872 | Val Loss: 0.120984, Val Acc: 0.742268\n",
      "Epoch 13188 - Train Loss: 0.100684, Train Acc: 0.844872 | Val Loss: 0.120980, Val Acc: 0.742268\n",
      "Epoch 13189 - Train Loss: 0.100680, Train Acc: 0.844872 | Val Loss: 0.120976, Val Acc: 0.742268\n",
      "Epoch 13190 - Train Loss: 0.100675, Train Acc: 0.844872 | Val Loss: 0.120973, Val Acc: 0.742268\n",
      "Epoch 13191 - Train Loss: 0.100670, Train Acc: 0.844872 | Val Loss: 0.120969, Val Acc: 0.742268\n",
      "Epoch 13192 - Train Loss: 0.100665, Train Acc: 0.844872 | Val Loss: 0.120966, Val Acc: 0.742268\n",
      "Epoch 13193 - Train Loss: 0.100660, Train Acc: 0.844872 | Val Loss: 0.120962, Val Acc: 0.742268\n",
      "Epoch 13194 - Train Loss: 0.100656, Train Acc: 0.844872 | Val Loss: 0.120959, Val Acc: 0.742268\n",
      "Epoch 13195 - Train Loss: 0.100651, Train Acc: 0.844872 | Val Loss: 0.120955, Val Acc: 0.742268\n",
      "Epoch 13196 - Train Loss: 0.100646, Train Acc: 0.844872 | Val Loss: 0.120952, Val Acc: 0.742268\n",
      "Epoch 13197 - Train Loss: 0.100641, Train Acc: 0.844872 | Val Loss: 0.120948, Val Acc: 0.742268\n",
      "Epoch 13198 - Train Loss: 0.100636, Train Acc: 0.844872 | Val Loss: 0.120945, Val Acc: 0.742268\n",
      "Epoch 13199 - Train Loss: 0.100632, Train Acc: 0.844872 | Val Loss: 0.120941, Val Acc: 0.742268\n",
      "Epoch 13200 - Train Loss: 0.100627, Train Acc: 0.844872 | Val Loss: 0.120937, Val Acc: 0.742268\n",
      "Epoch 13201 - Train Loss: 0.100622, Train Acc: 0.844872 | Val Loss: 0.120934, Val Acc: 0.742268\n",
      "Epoch 13202 - Train Loss: 0.100617, Train Acc: 0.844872 | Val Loss: 0.120930, Val Acc: 0.742268\n",
      "Epoch 13203 - Train Loss: 0.100612, Train Acc: 0.844872 | Val Loss: 0.120927, Val Acc: 0.742268\n",
      "Epoch 13204 - Train Loss: 0.100608, Train Acc: 0.844872 | Val Loss: 0.120923, Val Acc: 0.742268\n",
      "Epoch 13205 - Train Loss: 0.100603, Train Acc: 0.844872 | Val Loss: 0.120920, Val Acc: 0.742268\n",
      "Epoch 13206 - Train Loss: 0.100598, Train Acc: 0.844872 | Val Loss: 0.120916, Val Acc: 0.742268\n",
      "Epoch 13207 - Train Loss: 0.100593, Train Acc: 0.844872 | Val Loss: 0.120913, Val Acc: 0.742268\n",
      "Epoch 13208 - Train Loss: 0.100588, Train Acc: 0.844872 | Val Loss: 0.120909, Val Acc: 0.742268\n",
      "Epoch 13209 - Train Loss: 0.100584, Train Acc: 0.844872 | Val Loss: 0.120906, Val Acc: 0.742268\n",
      "Epoch 13210 - Train Loss: 0.100579, Train Acc: 0.844872 | Val Loss: 0.120902, Val Acc: 0.742268\n",
      "Epoch 13211 - Train Loss: 0.100574, Train Acc: 0.844872 | Val Loss: 0.120898, Val Acc: 0.742268\n",
      "Epoch 13212 - Train Loss: 0.100569, Train Acc: 0.844872 | Val Loss: 0.120895, Val Acc: 0.742268\n",
      "Epoch 13213 - Train Loss: 0.100564, Train Acc: 0.844872 | Val Loss: 0.120891, Val Acc: 0.742268\n",
      "Epoch 13214 - Train Loss: 0.100560, Train Acc: 0.844872 | Val Loss: 0.120888, Val Acc: 0.742268\n",
      "Epoch 13215 - Train Loss: 0.100555, Train Acc: 0.844872 | Val Loss: 0.120884, Val Acc: 0.742268\n",
      "Epoch 13216 - Train Loss: 0.100550, Train Acc: 0.844872 | Val Loss: 0.120881, Val Acc: 0.742268\n",
      "Epoch 13217 - Train Loss: 0.100545, Train Acc: 0.844872 | Val Loss: 0.120877, Val Acc: 0.742268\n",
      "Epoch 13218 - Train Loss: 0.100540, Train Acc: 0.844872 | Val Loss: 0.120874, Val Acc: 0.742268\n",
      "Epoch 13219 - Train Loss: 0.100536, Train Acc: 0.844872 | Val Loss: 0.120870, Val Acc: 0.742268\n",
      "Epoch 13220 - Train Loss: 0.100531, Train Acc: 0.844872 | Val Loss: 0.120867, Val Acc: 0.742268\n",
      "Epoch 13221 - Train Loss: 0.100526, Train Acc: 0.844872 | Val Loss: 0.120863, Val Acc: 0.742268\n",
      "Epoch 13222 - Train Loss: 0.100521, Train Acc: 0.844872 | Val Loss: 0.120860, Val Acc: 0.742268\n",
      "Epoch 13223 - Train Loss: 0.100517, Train Acc: 0.844872 | Val Loss: 0.120856, Val Acc: 0.742268\n",
      "Epoch 13224 - Train Loss: 0.100512, Train Acc: 0.844872 | Val Loss: 0.120852, Val Acc: 0.742268\n",
      "Epoch 13225 - Train Loss: 0.100507, Train Acc: 0.844872 | Val Loss: 0.120849, Val Acc: 0.742268\n",
      "Epoch 13226 - Train Loss: 0.100502, Train Acc: 0.844872 | Val Loss: 0.120845, Val Acc: 0.742268\n",
      "Epoch 13227 - Train Loss: 0.100497, Train Acc: 0.844872 | Val Loss: 0.120842, Val Acc: 0.742268\n",
      "Epoch 13228 - Train Loss: 0.100493, Train Acc: 0.844872 | Val Loss: 0.120838, Val Acc: 0.742268\n",
      "Epoch 13229 - Train Loss: 0.100488, Train Acc: 0.844872 | Val Loss: 0.120835, Val Acc: 0.742268\n",
      "Epoch 13230 - Train Loss: 0.100483, Train Acc: 0.844872 | Val Loss: 0.120831, Val Acc: 0.742268\n",
      "Epoch 13231 - Train Loss: 0.100478, Train Acc: 0.844872 | Val Loss: 0.120828, Val Acc: 0.742268\n",
      "Epoch 13232 - Train Loss: 0.100473, Train Acc: 0.844872 | Val Loss: 0.120824, Val Acc: 0.742268\n",
      "Epoch 13233 - Train Loss: 0.100469, Train Acc: 0.844872 | Val Loss: 0.120821, Val Acc: 0.742268\n",
      "Epoch 13234 - Train Loss: 0.100464, Train Acc: 0.844872 | Val Loss: 0.120817, Val Acc: 0.742268\n",
      "Epoch 13235 - Train Loss: 0.100459, Train Acc: 0.844872 | Val Loss: 0.120814, Val Acc: 0.742268\n",
      "Epoch 13236 - Train Loss: 0.100454, Train Acc: 0.844872 | Val Loss: 0.120810, Val Acc: 0.742268\n",
      "Epoch 13237 - Train Loss: 0.100450, Train Acc: 0.846154 | Val Loss: 0.120807, Val Acc: 0.742268\n",
      "Epoch 13238 - Train Loss: 0.100445, Train Acc: 0.846154 | Val Loss: 0.120803, Val Acc: 0.742268\n",
      "Epoch 13239 - Train Loss: 0.100440, Train Acc: 0.846154 | Val Loss: 0.120800, Val Acc: 0.742268\n",
      "Epoch 13240 - Train Loss: 0.100435, Train Acc: 0.846154 | Val Loss: 0.120796, Val Acc: 0.742268\n",
      "Epoch 13241 - Train Loss: 0.100430, Train Acc: 0.846154 | Val Loss: 0.120793, Val Acc: 0.742268\n",
      "Epoch 13242 - Train Loss: 0.100426, Train Acc: 0.846154 | Val Loss: 0.120789, Val Acc: 0.742268\n",
      "Epoch 13243 - Train Loss: 0.100421, Train Acc: 0.846154 | Val Loss: 0.120786, Val Acc: 0.742268\n",
      "Epoch 13244 - Train Loss: 0.100416, Train Acc: 0.846154 | Val Loss: 0.120782, Val Acc: 0.742268\n",
      "Epoch 13245 - Train Loss: 0.100411, Train Acc: 0.846154 | Val Loss: 0.120778, Val Acc: 0.742268\n",
      "Epoch 13246 - Train Loss: 0.100407, Train Acc: 0.846154 | Val Loss: 0.120775, Val Acc: 0.742268\n",
      "Epoch 13247 - Train Loss: 0.100402, Train Acc: 0.846154 | Val Loss: 0.120771, Val Acc: 0.742268\n",
      "Epoch 13248 - Train Loss: 0.100397, Train Acc: 0.846154 | Val Loss: 0.120768, Val Acc: 0.742268\n",
      "Epoch 13249 - Train Loss: 0.100392, Train Acc: 0.846154 | Val Loss: 0.120764, Val Acc: 0.742268\n",
      "Epoch 13250 - Train Loss: 0.100388, Train Acc: 0.846154 | Val Loss: 0.120761, Val Acc: 0.742268\n",
      "Epoch 13251 - Train Loss: 0.100383, Train Acc: 0.846154 | Val Loss: 0.120757, Val Acc: 0.742268\n",
      "Epoch 13252 - Train Loss: 0.100378, Train Acc: 0.846154 | Val Loss: 0.120754, Val Acc: 0.742268\n",
      "Epoch 13253 - Train Loss: 0.100373, Train Acc: 0.846154 | Val Loss: 0.120750, Val Acc: 0.742268\n",
      "Epoch 13254 - Train Loss: 0.100368, Train Acc: 0.846154 | Val Loss: 0.120747, Val Acc: 0.742268\n",
      "Epoch 13255 - Train Loss: 0.100364, Train Acc: 0.846154 | Val Loss: 0.120743, Val Acc: 0.742268\n",
      "Epoch 13256 - Train Loss: 0.100359, Train Acc: 0.846154 | Val Loss: 0.120740, Val Acc: 0.742268\n",
      "Epoch 13257 - Train Loss: 0.100354, Train Acc: 0.846154 | Val Loss: 0.120736, Val Acc: 0.742268\n",
      "Epoch 13258 - Train Loss: 0.100349, Train Acc: 0.846154 | Val Loss: 0.120733, Val Acc: 0.742268\n",
      "Epoch 13259 - Train Loss: 0.100345, Train Acc: 0.846154 | Val Loss: 0.120729, Val Acc: 0.742268\n",
      "Epoch 13260 - Train Loss: 0.100340, Train Acc: 0.846154 | Val Loss: 0.120726, Val Acc: 0.742268\n",
      "Epoch 13261 - Train Loss: 0.100335, Train Acc: 0.846154 | Val Loss: 0.120722, Val Acc: 0.742268\n",
      "Epoch 13262 - Train Loss: 0.100330, Train Acc: 0.846154 | Val Loss: 0.120719, Val Acc: 0.742268\n",
      "Epoch 13263 - Train Loss: 0.100326, Train Acc: 0.846154 | Val Loss: 0.120715, Val Acc: 0.742268\n",
      "Epoch 13264 - Train Loss: 0.100321, Train Acc: 0.846154 | Val Loss: 0.120712, Val Acc: 0.742268\n",
      "Epoch 13265 - Train Loss: 0.100316, Train Acc: 0.846154 | Val Loss: 0.120708, Val Acc: 0.742268\n",
      "Epoch 13266 - Train Loss: 0.100311, Train Acc: 0.846154 | Val Loss: 0.120705, Val Acc: 0.742268\n",
      "Epoch 13267 - Train Loss: 0.100307, Train Acc: 0.846154 | Val Loss: 0.120701, Val Acc: 0.742268\n",
      "Epoch 13268 - Train Loss: 0.100302, Train Acc: 0.846154 | Val Loss: 0.120698, Val Acc: 0.742268\n",
      "Epoch 13269 - Train Loss: 0.100297, Train Acc: 0.846154 | Val Loss: 0.120694, Val Acc: 0.742268\n",
      "Epoch 13270 - Train Loss: 0.100292, Train Acc: 0.846154 | Val Loss: 0.120691, Val Acc: 0.742268\n",
      "Epoch 13271 - Train Loss: 0.100288, Train Acc: 0.846154 | Val Loss: 0.120687, Val Acc: 0.742268\n",
      "Epoch 13272 - Train Loss: 0.100283, Train Acc: 0.846154 | Val Loss: 0.120684, Val Acc: 0.742268\n",
      "Epoch 13273 - Train Loss: 0.100278, Train Acc: 0.846154 | Val Loss: 0.120680, Val Acc: 0.742268\n",
      "Epoch 13274 - Train Loss: 0.100273, Train Acc: 0.846154 | Val Loss: 0.120677, Val Acc: 0.742268\n",
      "Epoch 13275 - Train Loss: 0.100268, Train Acc: 0.846154 | Val Loss: 0.120673, Val Acc: 0.742268\n",
      "Epoch 13276 - Train Loss: 0.100264, Train Acc: 0.846154 | Val Loss: 0.120670, Val Acc: 0.742268\n",
      "Epoch 13277 - Train Loss: 0.100259, Train Acc: 0.846154 | Val Loss: 0.120666, Val Acc: 0.742268\n",
      "Epoch 13278 - Train Loss: 0.100254, Train Acc: 0.846154 | Val Loss: 0.120663, Val Acc: 0.742268\n",
      "Epoch 13279 - Train Loss: 0.100249, Train Acc: 0.846154 | Val Loss: 0.120659, Val Acc: 0.742268\n",
      "Epoch 13280 - Train Loss: 0.100245, Train Acc: 0.846154 | Val Loss: 0.120656, Val Acc: 0.742268\n",
      "Epoch 13281 - Train Loss: 0.100240, Train Acc: 0.846154 | Val Loss: 0.120652, Val Acc: 0.742268\n",
      "Epoch 13282 - Train Loss: 0.100235, Train Acc: 0.846154 | Val Loss: 0.120649, Val Acc: 0.742268\n",
      "Epoch 13283 - Train Loss: 0.100230, Train Acc: 0.846154 | Val Loss: 0.120645, Val Acc: 0.742268\n",
      "Epoch 13284 - Train Loss: 0.100226, Train Acc: 0.846154 | Val Loss: 0.120642, Val Acc: 0.742268\n",
      "Epoch 13285 - Train Loss: 0.100221, Train Acc: 0.846154 | Val Loss: 0.120638, Val Acc: 0.742268\n",
      "Epoch 13286 - Train Loss: 0.100216, Train Acc: 0.846154 | Val Loss: 0.120635, Val Acc: 0.742268\n",
      "Epoch 13287 - Train Loss: 0.100211, Train Acc: 0.846154 | Val Loss: 0.120631, Val Acc: 0.742268\n",
      "Epoch 13288 - Train Loss: 0.100207, Train Acc: 0.846154 | Val Loss: 0.120628, Val Acc: 0.742268\n",
      "Epoch 13289 - Train Loss: 0.100202, Train Acc: 0.846154 | Val Loss: 0.120624, Val Acc: 0.742268\n",
      "Epoch 13290 - Train Loss: 0.100197, Train Acc: 0.846154 | Val Loss: 0.120621, Val Acc: 0.742268\n",
      "Epoch 13291 - Train Loss: 0.100193, Train Acc: 0.846154 | Val Loss: 0.120617, Val Acc: 0.742268\n",
      "Epoch 13292 - Train Loss: 0.100188, Train Acc: 0.846154 | Val Loss: 0.120614, Val Acc: 0.742268\n",
      "Epoch 13293 - Train Loss: 0.100183, Train Acc: 0.846154 | Val Loss: 0.120610, Val Acc: 0.742268\n",
      "Epoch 13294 - Train Loss: 0.100178, Train Acc: 0.846154 | Val Loss: 0.120607, Val Acc: 0.742268\n",
      "Epoch 13295 - Train Loss: 0.100174, Train Acc: 0.846154 | Val Loss: 0.120603, Val Acc: 0.742268\n",
      "Epoch 13296 - Train Loss: 0.100169, Train Acc: 0.846154 | Val Loss: 0.120600, Val Acc: 0.742268\n",
      "Epoch 13297 - Train Loss: 0.100164, Train Acc: 0.846154 | Val Loss: 0.120596, Val Acc: 0.742268\n",
      "Epoch 13298 - Train Loss: 0.100159, Train Acc: 0.846154 | Val Loss: 0.120593, Val Acc: 0.742268\n",
      "Epoch 13299 - Train Loss: 0.100155, Train Acc: 0.846154 | Val Loss: 0.120589, Val Acc: 0.742268\n",
      "Epoch 13300 - Train Loss: 0.100150, Train Acc: 0.846154 | Val Loss: 0.120586, Val Acc: 0.742268\n",
      "Epoch 13301 - Train Loss: 0.100145, Train Acc: 0.846154 | Val Loss: 0.120582, Val Acc: 0.742268\n",
      "Epoch 13302 - Train Loss: 0.100140, Train Acc: 0.846154 | Val Loss: 0.120579, Val Acc: 0.742268\n",
      "Epoch 13303 - Train Loss: 0.100136, Train Acc: 0.846154 | Val Loss: 0.120575, Val Acc: 0.742268\n",
      "Epoch 13304 - Train Loss: 0.100131, Train Acc: 0.846154 | Val Loss: 0.120572, Val Acc: 0.742268\n",
      "Epoch 13305 - Train Loss: 0.100126, Train Acc: 0.846154 | Val Loss: 0.120569, Val Acc: 0.742268\n",
      "Epoch 13306 - Train Loss: 0.100121, Train Acc: 0.846154 | Val Loss: 0.120565, Val Acc: 0.742268\n",
      "Epoch 13307 - Train Loss: 0.100117, Train Acc: 0.846154 | Val Loss: 0.120562, Val Acc: 0.742268\n",
      "Epoch 13308 - Train Loss: 0.100112, Train Acc: 0.846154 | Val Loss: 0.120558, Val Acc: 0.742268\n",
      "Epoch 13309 - Train Loss: 0.100107, Train Acc: 0.846154 | Val Loss: 0.120555, Val Acc: 0.742268\n",
      "Epoch 13310 - Train Loss: 0.100102, Train Acc: 0.846154 | Val Loss: 0.120551, Val Acc: 0.742268\n",
      "Epoch 13311 - Train Loss: 0.100098, Train Acc: 0.846154 | Val Loss: 0.120548, Val Acc: 0.742268\n",
      "Epoch 13312 - Train Loss: 0.100093, Train Acc: 0.846154 | Val Loss: 0.120544, Val Acc: 0.742268\n",
      "Epoch 13313 - Train Loss: 0.100088, Train Acc: 0.846154 | Val Loss: 0.120541, Val Acc: 0.742268\n",
      "Epoch 13314 - Train Loss: 0.100084, Train Acc: 0.846154 | Val Loss: 0.120537, Val Acc: 0.742268\n",
      "Epoch 13315 - Train Loss: 0.100079, Train Acc: 0.846154 | Val Loss: 0.120534, Val Acc: 0.742268\n",
      "Epoch 13316 - Train Loss: 0.100074, Train Acc: 0.846154 | Val Loss: 0.120530, Val Acc: 0.742268\n",
      "Epoch 13317 - Train Loss: 0.100069, Train Acc: 0.846154 | Val Loss: 0.120527, Val Acc: 0.742268\n",
      "Epoch 13318 - Train Loss: 0.100065, Train Acc: 0.846154 | Val Loss: 0.120523, Val Acc: 0.742268\n",
      "Epoch 13319 - Train Loss: 0.100060, Train Acc: 0.846154 | Val Loss: 0.120520, Val Acc: 0.742268\n",
      "Epoch 13320 - Train Loss: 0.100055, Train Acc: 0.846154 | Val Loss: 0.120516, Val Acc: 0.742268\n",
      "Epoch 13321 - Train Loss: 0.100050, Train Acc: 0.846154 | Val Loss: 0.120513, Val Acc: 0.742268\n",
      "Epoch 13322 - Train Loss: 0.100046, Train Acc: 0.846154 | Val Loss: 0.120509, Val Acc: 0.742268\n",
      "Epoch 13323 - Train Loss: 0.100041, Train Acc: 0.846154 | Val Loss: 0.120506, Val Acc: 0.742268\n",
      "Epoch 13324 - Train Loss: 0.100036, Train Acc: 0.846154 | Val Loss: 0.120502, Val Acc: 0.742268\n",
      "Epoch 13325 - Train Loss: 0.100032, Train Acc: 0.846154 | Val Loss: 0.120499, Val Acc: 0.742268\n",
      "Epoch 13326 - Train Loss: 0.100027, Train Acc: 0.846154 | Val Loss: 0.120496, Val Acc: 0.742268\n",
      "Epoch 13327 - Train Loss: 0.100022, Train Acc: 0.846154 | Val Loss: 0.120492, Val Acc: 0.742268\n",
      "Epoch 13328 - Train Loss: 0.100017, Train Acc: 0.846154 | Val Loss: 0.120489, Val Acc: 0.742268\n",
      "Epoch 13329 - Train Loss: 0.100013, Train Acc: 0.846154 | Val Loss: 0.120485, Val Acc: 0.742268\n",
      "Epoch 13330 - Train Loss: 0.100008, Train Acc: 0.846154 | Val Loss: 0.120482, Val Acc: 0.742268\n",
      "Epoch 13331 - Train Loss: 0.100003, Train Acc: 0.846154 | Val Loss: 0.120478, Val Acc: 0.742268\n",
      "Epoch 13332 - Train Loss: 0.099999, Train Acc: 0.846154 | Val Loss: 0.120475, Val Acc: 0.742268\n",
      "Epoch 13333 - Train Loss: 0.099994, Train Acc: 0.846154 | Val Loss: 0.120471, Val Acc: 0.742268\n",
      "Epoch 13334 - Train Loss: 0.099989, Train Acc: 0.846154 | Val Loss: 0.120468, Val Acc: 0.742268\n",
      "Epoch 13335 - Train Loss: 0.099984, Train Acc: 0.846154 | Val Loss: 0.120464, Val Acc: 0.742268\n",
      "Epoch 13336 - Train Loss: 0.099980, Train Acc: 0.846154 | Val Loss: 0.120461, Val Acc: 0.742268\n",
      "Epoch 13337 - Train Loss: 0.099975, Train Acc: 0.846154 | Val Loss: 0.120457, Val Acc: 0.742268\n",
      "Epoch 13338 - Train Loss: 0.099970, Train Acc: 0.846154 | Val Loss: 0.120454, Val Acc: 0.742268\n",
      "Epoch 13339 - Train Loss: 0.099966, Train Acc: 0.846154 | Val Loss: 0.120451, Val Acc: 0.742268\n",
      "Epoch 13340 - Train Loss: 0.099961, Train Acc: 0.846154 | Val Loss: 0.120447, Val Acc: 0.742268\n",
      "Epoch 13341 - Train Loss: 0.099956, Train Acc: 0.846154 | Val Loss: 0.120444, Val Acc: 0.742268\n",
      "Epoch 13342 - Train Loss: 0.099951, Train Acc: 0.846154 | Val Loss: 0.120440, Val Acc: 0.742268\n",
      "Epoch 13343 - Train Loss: 0.099947, Train Acc: 0.846154 | Val Loss: 0.120437, Val Acc: 0.742268\n",
      "Epoch 13344 - Train Loss: 0.099942, Train Acc: 0.846154 | Val Loss: 0.120433, Val Acc: 0.742268\n",
      "Epoch 13345 - Train Loss: 0.099937, Train Acc: 0.846154 | Val Loss: 0.120430, Val Acc: 0.742268\n",
      "Epoch 13346 - Train Loss: 0.099933, Train Acc: 0.846154 | Val Loss: 0.120426, Val Acc: 0.742268\n",
      "Epoch 13347 - Train Loss: 0.099928, Train Acc: 0.846154 | Val Loss: 0.120423, Val Acc: 0.742268\n",
      "Epoch 13348 - Train Loss: 0.099923, Train Acc: 0.846154 | Val Loss: 0.120419, Val Acc: 0.742268\n",
      "Epoch 13349 - Train Loss: 0.099918, Train Acc: 0.846154 | Val Loss: 0.120416, Val Acc: 0.742268\n",
      "Epoch 13350 - Train Loss: 0.099914, Train Acc: 0.846154 | Val Loss: 0.120412, Val Acc: 0.742268\n",
      "Epoch 13351 - Train Loss: 0.099909, Train Acc: 0.846154 | Val Loss: 0.120409, Val Acc: 0.742268\n",
      "Epoch 13352 - Train Loss: 0.099904, Train Acc: 0.846154 | Val Loss: 0.120406, Val Acc: 0.742268\n",
      "Epoch 13353 - Train Loss: 0.099900, Train Acc: 0.846154 | Val Loss: 0.120402, Val Acc: 0.742268\n",
      "Epoch 13354 - Train Loss: 0.099895, Train Acc: 0.846154 | Val Loss: 0.120399, Val Acc: 0.742268\n",
      "Epoch 13355 - Train Loss: 0.099890, Train Acc: 0.846154 | Val Loss: 0.120395, Val Acc: 0.742268\n",
      "Epoch 13356 - Train Loss: 0.099885, Train Acc: 0.846154 | Val Loss: 0.120392, Val Acc: 0.742268\n",
      "Epoch 13357 - Train Loss: 0.099881, Train Acc: 0.846154 | Val Loss: 0.120388, Val Acc: 0.742268\n",
      "Epoch 13358 - Train Loss: 0.099876, Train Acc: 0.846154 | Val Loss: 0.120385, Val Acc: 0.742268\n",
      "Epoch 13359 - Train Loss: 0.099871, Train Acc: 0.846154 | Val Loss: 0.120381, Val Acc: 0.742268\n",
      "Epoch 13360 - Train Loss: 0.099867, Train Acc: 0.846154 | Val Loss: 0.120378, Val Acc: 0.742268\n",
      "Epoch 13361 - Train Loss: 0.099862, Train Acc: 0.846154 | Val Loss: 0.120375, Val Acc: 0.742268\n",
      "Epoch 13362 - Train Loss: 0.099857, Train Acc: 0.846154 | Val Loss: 0.120371, Val Acc: 0.742268\n",
      "Epoch 13363 - Train Loss: 0.099853, Train Acc: 0.846154 | Val Loss: 0.120368, Val Acc: 0.742268\n",
      "Epoch 13364 - Train Loss: 0.099848, Train Acc: 0.846154 | Val Loss: 0.120364, Val Acc: 0.742268\n",
      "Epoch 13365 - Train Loss: 0.099843, Train Acc: 0.846154 | Val Loss: 0.120361, Val Acc: 0.742268\n",
      "Epoch 13366 - Train Loss: 0.099838, Train Acc: 0.846154 | Val Loss: 0.120357, Val Acc: 0.742268\n",
      "Epoch 13367 - Train Loss: 0.099834, Train Acc: 0.846154 | Val Loss: 0.120354, Val Acc: 0.742268\n",
      "Epoch 13368 - Train Loss: 0.099829, Train Acc: 0.846154 | Val Loss: 0.120350, Val Acc: 0.742268\n",
      "Epoch 13369 - Train Loss: 0.099824, Train Acc: 0.846154 | Val Loss: 0.120347, Val Acc: 0.742268\n",
      "Epoch 13370 - Train Loss: 0.099820, Train Acc: 0.846154 | Val Loss: 0.120344, Val Acc: 0.742268\n",
      "Epoch 13371 - Train Loss: 0.099815, Train Acc: 0.846154 | Val Loss: 0.120340, Val Acc: 0.742268\n",
      "Epoch 13372 - Train Loss: 0.099810, Train Acc: 0.846154 | Val Loss: 0.120337, Val Acc: 0.742268\n",
      "Epoch 13373 - Train Loss: 0.099806, Train Acc: 0.846154 | Val Loss: 0.120333, Val Acc: 0.742268\n",
      "Epoch 13374 - Train Loss: 0.099801, Train Acc: 0.846154 | Val Loss: 0.120330, Val Acc: 0.742268\n",
      "Epoch 13375 - Train Loss: 0.099796, Train Acc: 0.846154 | Val Loss: 0.120326, Val Acc: 0.742268\n",
      "Epoch 13376 - Train Loss: 0.099792, Train Acc: 0.846154 | Val Loss: 0.120323, Val Acc: 0.742268\n",
      "Epoch 13377 - Train Loss: 0.099787, Train Acc: 0.846154 | Val Loss: 0.120319, Val Acc: 0.742268\n",
      "Epoch 13378 - Train Loss: 0.099782, Train Acc: 0.846154 | Val Loss: 0.120316, Val Acc: 0.742268\n",
      "Epoch 13379 - Train Loss: 0.099777, Train Acc: 0.846154 | Val Loss: 0.120313, Val Acc: 0.742268\n",
      "Epoch 13380 - Train Loss: 0.099773, Train Acc: 0.846154 | Val Loss: 0.120309, Val Acc: 0.742268\n",
      "Epoch 13381 - Train Loss: 0.099768, Train Acc: 0.846154 | Val Loss: 0.120306, Val Acc: 0.742268\n",
      "Epoch 13382 - Train Loss: 0.099763, Train Acc: 0.846154 | Val Loss: 0.120302, Val Acc: 0.742268\n",
      "Epoch 13383 - Train Loss: 0.099759, Train Acc: 0.846154 | Val Loss: 0.120299, Val Acc: 0.742268\n",
      "Epoch 13384 - Train Loss: 0.099754, Train Acc: 0.846154 | Val Loss: 0.120295, Val Acc: 0.742268\n",
      "Epoch 13385 - Train Loss: 0.099749, Train Acc: 0.846154 | Val Loss: 0.120292, Val Acc: 0.742268\n",
      "Epoch 13386 - Train Loss: 0.099745, Train Acc: 0.846154 | Val Loss: 0.120289, Val Acc: 0.742268\n",
      "Epoch 13387 - Train Loss: 0.099740, Train Acc: 0.846154 | Val Loss: 0.120285, Val Acc: 0.742268\n",
      "Epoch 13388 - Train Loss: 0.099735, Train Acc: 0.846154 | Val Loss: 0.120282, Val Acc: 0.742268\n",
      "Epoch 13389 - Train Loss: 0.099731, Train Acc: 0.846154 | Val Loss: 0.120278, Val Acc: 0.742268\n",
      "Epoch 13390 - Train Loss: 0.099726, Train Acc: 0.846154 | Val Loss: 0.120275, Val Acc: 0.742268\n",
      "Epoch 13391 - Train Loss: 0.099721, Train Acc: 0.846154 | Val Loss: 0.120271, Val Acc: 0.742268\n",
      "Epoch 13392 - Train Loss: 0.099717, Train Acc: 0.846154 | Val Loss: 0.120268, Val Acc: 0.742268\n",
      "Epoch 13393 - Train Loss: 0.099712, Train Acc: 0.846154 | Val Loss: 0.120265, Val Acc: 0.742268\n",
      "Epoch 13394 - Train Loss: 0.099707, Train Acc: 0.846154 | Val Loss: 0.120261, Val Acc: 0.742268\n",
      "Epoch 13395 - Train Loss: 0.099703, Train Acc: 0.846154 | Val Loss: 0.120258, Val Acc: 0.742268\n",
      "Epoch 13396 - Train Loss: 0.099698, Train Acc: 0.846154 | Val Loss: 0.120254, Val Acc: 0.742268\n",
      "Epoch 13397 - Train Loss: 0.099693, Train Acc: 0.846154 | Val Loss: 0.120251, Val Acc: 0.742268\n",
      "Epoch 13398 - Train Loss: 0.099689, Train Acc: 0.846154 | Val Loss: 0.120247, Val Acc: 0.742268\n",
      "Epoch 13399 - Train Loss: 0.099684, Train Acc: 0.846154 | Val Loss: 0.120244, Val Acc: 0.742268\n",
      "Epoch 13400 - Train Loss: 0.099679, Train Acc: 0.846154 | Val Loss: 0.120241, Val Acc: 0.742268\n",
      "Epoch 13401 - Train Loss: 0.099674, Train Acc: 0.846154 | Val Loss: 0.120237, Val Acc: 0.742268\n",
      "Epoch 13402 - Train Loss: 0.099670, Train Acc: 0.846154 | Val Loss: 0.120234, Val Acc: 0.742268\n",
      "Epoch 13403 - Train Loss: 0.099665, Train Acc: 0.846154 | Val Loss: 0.120230, Val Acc: 0.742268\n",
      "Epoch 13404 - Train Loss: 0.099660, Train Acc: 0.846154 | Val Loss: 0.120227, Val Acc: 0.742268\n",
      "Epoch 13405 - Train Loss: 0.099656, Train Acc: 0.846154 | Val Loss: 0.120224, Val Acc: 0.742268\n",
      "Epoch 13406 - Train Loss: 0.099651, Train Acc: 0.846154 | Val Loss: 0.120220, Val Acc: 0.742268\n",
      "Epoch 13407 - Train Loss: 0.099646, Train Acc: 0.846154 | Val Loss: 0.120217, Val Acc: 0.742268\n",
      "Epoch 13408 - Train Loss: 0.099642, Train Acc: 0.846154 | Val Loss: 0.120213, Val Acc: 0.742268\n",
      "Epoch 13409 - Train Loss: 0.099637, Train Acc: 0.846154 | Val Loss: 0.120210, Val Acc: 0.742268\n",
      "Epoch 13410 - Train Loss: 0.099632, Train Acc: 0.846154 | Val Loss: 0.120206, Val Acc: 0.742268\n",
      "Epoch 13411 - Train Loss: 0.099628, Train Acc: 0.846154 | Val Loss: 0.120203, Val Acc: 0.742268\n",
      "Epoch 13412 - Train Loss: 0.099623, Train Acc: 0.846154 | Val Loss: 0.120200, Val Acc: 0.742268\n",
      "Epoch 13413 - Train Loss: 0.099618, Train Acc: 0.846154 | Val Loss: 0.120196, Val Acc: 0.742268\n",
      "Epoch 13414 - Train Loss: 0.099614, Train Acc: 0.846154 | Val Loss: 0.120193, Val Acc: 0.742268\n",
      "Epoch 13415 - Train Loss: 0.099609, Train Acc: 0.846154 | Val Loss: 0.120189, Val Acc: 0.742268\n",
      "Epoch 13416 - Train Loss: 0.099604, Train Acc: 0.846154 | Val Loss: 0.120186, Val Acc: 0.742268\n",
      "Epoch 13417 - Train Loss: 0.099600, Train Acc: 0.846154 | Val Loss: 0.120183, Val Acc: 0.742268\n",
      "Epoch 13418 - Train Loss: 0.099595, Train Acc: 0.846154 | Val Loss: 0.120179, Val Acc: 0.742268\n",
      "Epoch 13419 - Train Loss: 0.099590, Train Acc: 0.846154 | Val Loss: 0.120176, Val Acc: 0.742268\n",
      "Epoch 13420 - Train Loss: 0.099586, Train Acc: 0.846154 | Val Loss: 0.120172, Val Acc: 0.742268\n",
      "Epoch 13421 - Train Loss: 0.099581, Train Acc: 0.846154 | Val Loss: 0.120169, Val Acc: 0.742268\n",
      "Epoch 13422 - Train Loss: 0.099576, Train Acc: 0.846154 | Val Loss: 0.120166, Val Acc: 0.742268\n",
      "Epoch 13423 - Train Loss: 0.099572, Train Acc: 0.846154 | Val Loss: 0.120162, Val Acc: 0.742268\n",
      "Epoch 13424 - Train Loss: 0.099567, Train Acc: 0.846154 | Val Loss: 0.120159, Val Acc: 0.742268\n",
      "Epoch 13425 - Train Loss: 0.099562, Train Acc: 0.846154 | Val Loss: 0.120155, Val Acc: 0.742268\n",
      "Epoch 13426 - Train Loss: 0.099558, Train Acc: 0.846154 | Val Loss: 0.120152, Val Acc: 0.742268\n",
      "Epoch 13427 - Train Loss: 0.099553, Train Acc: 0.846154 | Val Loss: 0.120149, Val Acc: 0.742268\n",
      "Epoch 13428 - Train Loss: 0.099549, Train Acc: 0.846154 | Val Loss: 0.120145, Val Acc: 0.742268\n",
      "Epoch 13429 - Train Loss: 0.099544, Train Acc: 0.846154 | Val Loss: 0.120142, Val Acc: 0.742268\n",
      "Epoch 13430 - Train Loss: 0.099539, Train Acc: 0.846154 | Val Loss: 0.120138, Val Acc: 0.742268\n",
      "Epoch 13431 - Train Loss: 0.099535, Train Acc: 0.846154 | Val Loss: 0.120135, Val Acc: 0.742268\n",
      "Epoch 13432 - Train Loss: 0.099530, Train Acc: 0.846154 | Val Loss: 0.120132, Val Acc: 0.742268\n",
      "Epoch 13433 - Train Loss: 0.099525, Train Acc: 0.846154 | Val Loss: 0.120128, Val Acc: 0.742268\n",
      "Epoch 13434 - Train Loss: 0.099521, Train Acc: 0.846154 | Val Loss: 0.120125, Val Acc: 0.742268\n",
      "Epoch 13435 - Train Loss: 0.099516, Train Acc: 0.846154 | Val Loss: 0.120121, Val Acc: 0.742268\n",
      "Epoch 13436 - Train Loss: 0.099511, Train Acc: 0.846154 | Val Loss: 0.120118, Val Acc: 0.742268\n",
      "Epoch 13437 - Train Loss: 0.099507, Train Acc: 0.846154 | Val Loss: 0.120114, Val Acc: 0.742268\n",
      "Epoch 13438 - Train Loss: 0.099502, Train Acc: 0.846154 | Val Loss: 0.120111, Val Acc: 0.742268\n",
      "Epoch 13439 - Train Loss: 0.099497, Train Acc: 0.846154 | Val Loss: 0.120108, Val Acc: 0.742268\n",
      "Epoch 13440 - Train Loss: 0.099493, Train Acc: 0.846154 | Val Loss: 0.120104, Val Acc: 0.731959\n",
      "Epoch 13441 - Train Loss: 0.099488, Train Acc: 0.846154 | Val Loss: 0.120101, Val Acc: 0.731959\n",
      "Epoch 13442 - Train Loss: 0.099483, Train Acc: 0.846154 | Val Loss: 0.120098, Val Acc: 0.731959\n",
      "Epoch 13443 - Train Loss: 0.099479, Train Acc: 0.846154 | Val Loss: 0.120094, Val Acc: 0.731959\n",
      "Epoch 13444 - Train Loss: 0.099474, Train Acc: 0.846154 | Val Loss: 0.120091, Val Acc: 0.731959\n",
      "Epoch 13445 - Train Loss: 0.099469, Train Acc: 0.846154 | Val Loss: 0.120087, Val Acc: 0.731959\n",
      "Epoch 13446 - Train Loss: 0.099465, Train Acc: 0.846154 | Val Loss: 0.120084, Val Acc: 0.731959\n",
      "Epoch 13447 - Train Loss: 0.099460, Train Acc: 0.846154 | Val Loss: 0.120081, Val Acc: 0.731959\n",
      "Epoch 13448 - Train Loss: 0.099455, Train Acc: 0.846154 | Val Loss: 0.120077, Val Acc: 0.731959\n",
      "Epoch 13449 - Train Loss: 0.099451, Train Acc: 0.846154 | Val Loss: 0.120074, Val Acc: 0.731959\n",
      "Epoch 13450 - Train Loss: 0.099446, Train Acc: 0.846154 | Val Loss: 0.120070, Val Acc: 0.731959\n",
      "Epoch 13451 - Train Loss: 0.099442, Train Acc: 0.846154 | Val Loss: 0.120067, Val Acc: 0.731959\n",
      "Epoch 13452 - Train Loss: 0.099437, Train Acc: 0.846154 | Val Loss: 0.120064, Val Acc: 0.731959\n",
      "Epoch 13453 - Train Loss: 0.099432, Train Acc: 0.846154 | Val Loss: 0.120060, Val Acc: 0.731959\n",
      "Epoch 13454 - Train Loss: 0.099428, Train Acc: 0.846154 | Val Loss: 0.120057, Val Acc: 0.731959\n",
      "Epoch 13455 - Train Loss: 0.099423, Train Acc: 0.846154 | Val Loss: 0.120053, Val Acc: 0.731959\n",
      "Epoch 13456 - Train Loss: 0.099418, Train Acc: 0.846154 | Val Loss: 0.120050, Val Acc: 0.731959\n",
      "Epoch 13457 - Train Loss: 0.099414, Train Acc: 0.846154 | Val Loss: 0.120047, Val Acc: 0.731959\n",
      "Epoch 13458 - Train Loss: 0.099409, Train Acc: 0.846154 | Val Loss: 0.120043, Val Acc: 0.731959\n",
      "Epoch 13459 - Train Loss: 0.099404, Train Acc: 0.846154 | Val Loss: 0.120040, Val Acc: 0.731959\n",
      "Epoch 13460 - Train Loss: 0.099400, Train Acc: 0.846154 | Val Loss: 0.120037, Val Acc: 0.731959\n",
      "Epoch 13461 - Train Loss: 0.099395, Train Acc: 0.846154 | Val Loss: 0.120033, Val Acc: 0.731959\n",
      "Epoch 13462 - Train Loss: 0.099391, Train Acc: 0.846154 | Val Loss: 0.120030, Val Acc: 0.731959\n",
      "Epoch 13463 - Train Loss: 0.099386, Train Acc: 0.846154 | Val Loss: 0.120026, Val Acc: 0.731959\n",
      "Epoch 13464 - Train Loss: 0.099381, Train Acc: 0.846154 | Val Loss: 0.120023, Val Acc: 0.731959\n",
      "Epoch 13465 - Train Loss: 0.099377, Train Acc: 0.846154 | Val Loss: 0.120020, Val Acc: 0.731959\n",
      "Epoch 13466 - Train Loss: 0.099372, Train Acc: 0.846154 | Val Loss: 0.120016, Val Acc: 0.731959\n",
      "Epoch 13467 - Train Loss: 0.099367, Train Acc: 0.846154 | Val Loss: 0.120013, Val Acc: 0.731959\n",
      "Epoch 13468 - Train Loss: 0.099363, Train Acc: 0.846154 | Val Loss: 0.120009, Val Acc: 0.731959\n",
      "Epoch 13469 - Train Loss: 0.099358, Train Acc: 0.846154 | Val Loss: 0.120006, Val Acc: 0.731959\n",
      "Epoch 13470 - Train Loss: 0.099353, Train Acc: 0.846154 | Val Loss: 0.120003, Val Acc: 0.742268\n",
      "Epoch 13471 - Train Loss: 0.099349, Train Acc: 0.846154 | Val Loss: 0.119999, Val Acc: 0.742268\n",
      "Epoch 13472 - Train Loss: 0.099344, Train Acc: 0.846154 | Val Loss: 0.119996, Val Acc: 0.742268\n",
      "Epoch 13473 - Train Loss: 0.099340, Train Acc: 0.846154 | Val Loss: 0.119993, Val Acc: 0.742268\n",
      "Epoch 13474 - Train Loss: 0.099335, Train Acc: 0.846154 | Val Loss: 0.119989, Val Acc: 0.742268\n",
      "Epoch 13475 - Train Loss: 0.099330, Train Acc: 0.846154 | Val Loss: 0.119986, Val Acc: 0.742268\n",
      "Epoch 13476 - Train Loss: 0.099326, Train Acc: 0.846154 | Val Loss: 0.119982, Val Acc: 0.742268\n",
      "Epoch 13477 - Train Loss: 0.099321, Train Acc: 0.846154 | Val Loss: 0.119979, Val Acc: 0.742268\n",
      "Epoch 13478 - Train Loss: 0.099316, Train Acc: 0.846154 | Val Loss: 0.119976, Val Acc: 0.742268\n",
      "Epoch 13479 - Train Loss: 0.099312, Train Acc: 0.846154 | Val Loss: 0.119972, Val Acc: 0.742268\n",
      "Epoch 13480 - Train Loss: 0.099307, Train Acc: 0.846154 | Val Loss: 0.119969, Val Acc: 0.742268\n",
      "Epoch 13481 - Train Loss: 0.099303, Train Acc: 0.846154 | Val Loss: 0.119966, Val Acc: 0.742268\n",
      "Epoch 13482 - Train Loss: 0.099298, Train Acc: 0.846154 | Val Loss: 0.119962, Val Acc: 0.742268\n",
      "Epoch 13483 - Train Loss: 0.099293, Train Acc: 0.846154 | Val Loss: 0.119959, Val Acc: 0.742268\n",
      "Epoch 13484 - Train Loss: 0.099289, Train Acc: 0.846154 | Val Loss: 0.119955, Val Acc: 0.742268\n",
      "Epoch 13485 - Train Loss: 0.099284, Train Acc: 0.846154 | Val Loss: 0.119952, Val Acc: 0.742268\n",
      "Epoch 13486 - Train Loss: 0.099279, Train Acc: 0.846154 | Val Loss: 0.119949, Val Acc: 0.742268\n",
      "Epoch 13487 - Train Loss: 0.099275, Train Acc: 0.846154 | Val Loss: 0.119945, Val Acc: 0.742268\n",
      "Epoch 13488 - Train Loss: 0.099270, Train Acc: 0.846154 | Val Loss: 0.119942, Val Acc: 0.742268\n",
      "Epoch 13489 - Train Loss: 0.099266, Train Acc: 0.846154 | Val Loss: 0.119939, Val Acc: 0.742268\n",
      "Epoch 13490 - Train Loss: 0.099261, Train Acc: 0.846154 | Val Loss: 0.119935, Val Acc: 0.742268\n",
      "Epoch 13491 - Train Loss: 0.099256, Train Acc: 0.846154 | Val Loss: 0.119932, Val Acc: 0.742268\n",
      "Epoch 13492 - Train Loss: 0.099252, Train Acc: 0.846154 | Val Loss: 0.119929, Val Acc: 0.742268\n",
      "Epoch 13493 - Train Loss: 0.099247, Train Acc: 0.846154 | Val Loss: 0.119925, Val Acc: 0.742268\n",
      "Epoch 13494 - Train Loss: 0.099242, Train Acc: 0.846154 | Val Loss: 0.119922, Val Acc: 0.742268\n",
      "Epoch 13495 - Train Loss: 0.099238, Train Acc: 0.846154 | Val Loss: 0.119918, Val Acc: 0.742268\n",
      "Epoch 13496 - Train Loss: 0.099233, Train Acc: 0.846154 | Val Loss: 0.119915, Val Acc: 0.742268\n",
      "Epoch 13497 - Train Loss: 0.099229, Train Acc: 0.846154 | Val Loss: 0.119912, Val Acc: 0.742268\n",
      "Epoch 13498 - Train Loss: 0.099224, Train Acc: 0.846154 | Val Loss: 0.119908, Val Acc: 0.742268\n",
      "Epoch 13499 - Train Loss: 0.099219, Train Acc: 0.846154 | Val Loss: 0.119905, Val Acc: 0.742268\n",
      "Epoch 13500 - Train Loss: 0.099215, Train Acc: 0.846154 | Val Loss: 0.119902, Val Acc: 0.742268\n",
      "Epoch 13501 - Train Loss: 0.099210, Train Acc: 0.846154 | Val Loss: 0.119898, Val Acc: 0.742268\n",
      "Epoch 13502 - Train Loss: 0.099206, Train Acc: 0.846154 | Val Loss: 0.119895, Val Acc: 0.742268\n",
      "Epoch 13503 - Train Loss: 0.099201, Train Acc: 0.846154 | Val Loss: 0.119892, Val Acc: 0.742268\n",
      "Epoch 13504 - Train Loss: 0.099196, Train Acc: 0.846154 | Val Loss: 0.119888, Val Acc: 0.742268\n",
      "Epoch 13505 - Train Loss: 0.099192, Train Acc: 0.846154 | Val Loss: 0.119885, Val Acc: 0.742268\n",
      "Epoch 13506 - Train Loss: 0.099187, Train Acc: 0.846154 | Val Loss: 0.119882, Val Acc: 0.742268\n",
      "Epoch 13507 - Train Loss: 0.099183, Train Acc: 0.846154 | Val Loss: 0.119878, Val Acc: 0.742268\n",
      "Epoch 13508 - Train Loss: 0.099178, Train Acc: 0.846154 | Val Loss: 0.119875, Val Acc: 0.742268\n",
      "Epoch 13509 - Train Loss: 0.099173, Train Acc: 0.846154 | Val Loss: 0.119871, Val Acc: 0.742268\n",
      "Epoch 13510 - Train Loss: 0.099169, Train Acc: 0.846154 | Val Loss: 0.119868, Val Acc: 0.742268\n",
      "Epoch 13511 - Train Loss: 0.099164, Train Acc: 0.846154 | Val Loss: 0.119865, Val Acc: 0.742268\n",
      "Epoch 13512 - Train Loss: 0.099159, Train Acc: 0.846154 | Val Loss: 0.119861, Val Acc: 0.742268\n",
      "Epoch 13513 - Train Loss: 0.099155, Train Acc: 0.846154 | Val Loss: 0.119858, Val Acc: 0.742268\n",
      "Epoch 13514 - Train Loss: 0.099150, Train Acc: 0.846154 | Val Loss: 0.119855, Val Acc: 0.742268\n",
      "Epoch 13515 - Train Loss: 0.099146, Train Acc: 0.846154 | Val Loss: 0.119851, Val Acc: 0.742268\n",
      "Epoch 13516 - Train Loss: 0.099141, Train Acc: 0.846154 | Val Loss: 0.119848, Val Acc: 0.742268\n",
      "Epoch 13517 - Train Loss: 0.099136, Train Acc: 0.846154 | Val Loss: 0.119845, Val Acc: 0.742268\n",
      "Epoch 13518 - Train Loss: 0.099132, Train Acc: 0.846154 | Val Loss: 0.119841, Val Acc: 0.742268\n",
      "Epoch 13519 - Train Loss: 0.099127, Train Acc: 0.846154 | Val Loss: 0.119838, Val Acc: 0.742268\n",
      "Epoch 13520 - Train Loss: 0.099123, Train Acc: 0.846154 | Val Loss: 0.119835, Val Acc: 0.742268\n",
      "Epoch 13521 - Train Loss: 0.099118, Train Acc: 0.846154 | Val Loss: 0.119831, Val Acc: 0.742268\n",
      "Epoch 13522 - Train Loss: 0.099113, Train Acc: 0.846154 | Val Loss: 0.119828, Val Acc: 0.742268\n",
      "Epoch 13523 - Train Loss: 0.099109, Train Acc: 0.846154 | Val Loss: 0.119825, Val Acc: 0.742268\n",
      "Epoch 13524 - Train Loss: 0.099104, Train Acc: 0.846154 | Val Loss: 0.119821, Val Acc: 0.742268\n",
      "Epoch 13525 - Train Loss: 0.099100, Train Acc: 0.846154 | Val Loss: 0.119818, Val Acc: 0.742268\n",
      "Epoch 13526 - Train Loss: 0.099095, Train Acc: 0.846154 | Val Loss: 0.119815, Val Acc: 0.742268\n",
      "Epoch 13527 - Train Loss: 0.099090, Train Acc: 0.846154 | Val Loss: 0.119811, Val Acc: 0.742268\n",
      "Epoch 13528 - Train Loss: 0.099086, Train Acc: 0.846154 | Val Loss: 0.119808, Val Acc: 0.742268\n",
      "Epoch 13529 - Train Loss: 0.099081, Train Acc: 0.846154 | Val Loss: 0.119805, Val Acc: 0.742268\n",
      "Epoch 13530 - Train Loss: 0.099077, Train Acc: 0.846154 | Val Loss: 0.119801, Val Acc: 0.742268\n",
      "Epoch 13531 - Train Loss: 0.099072, Train Acc: 0.846154 | Val Loss: 0.119798, Val Acc: 0.742268\n",
      "Epoch 13532 - Train Loss: 0.099067, Train Acc: 0.846154 | Val Loss: 0.119795, Val Acc: 0.742268\n",
      "Epoch 13533 - Train Loss: 0.099063, Train Acc: 0.846154 | Val Loss: 0.119791, Val Acc: 0.742268\n",
      "Epoch 13534 - Train Loss: 0.099058, Train Acc: 0.846154 | Val Loss: 0.119788, Val Acc: 0.742268\n",
      "Epoch 13535 - Train Loss: 0.099054, Train Acc: 0.846154 | Val Loss: 0.119785, Val Acc: 0.742268\n",
      "Epoch 13536 - Train Loss: 0.099049, Train Acc: 0.846154 | Val Loss: 0.119781, Val Acc: 0.742268\n",
      "Epoch 13537 - Train Loss: 0.099045, Train Acc: 0.846154 | Val Loss: 0.119778, Val Acc: 0.742268\n",
      "Epoch 13538 - Train Loss: 0.099040, Train Acc: 0.846154 | Val Loss: 0.119775, Val Acc: 0.742268\n",
      "Epoch 13539 - Train Loss: 0.099035, Train Acc: 0.846154 | Val Loss: 0.119771, Val Acc: 0.742268\n",
      "Epoch 13540 - Train Loss: 0.099031, Train Acc: 0.846154 | Val Loss: 0.119768, Val Acc: 0.742268\n",
      "Epoch 13541 - Train Loss: 0.099026, Train Acc: 0.846154 | Val Loss: 0.119765, Val Acc: 0.742268\n",
      "Epoch 13542 - Train Loss: 0.099022, Train Acc: 0.846154 | Val Loss: 0.119761, Val Acc: 0.742268\n",
      "Epoch 13543 - Train Loss: 0.099017, Train Acc: 0.846154 | Val Loss: 0.119758, Val Acc: 0.742268\n",
      "Epoch 13544 - Train Loss: 0.099012, Train Acc: 0.846154 | Val Loss: 0.119755, Val Acc: 0.742268\n",
      "Epoch 13545 - Train Loss: 0.099008, Train Acc: 0.846154 | Val Loss: 0.119751, Val Acc: 0.742268\n",
      "Epoch 13546 - Train Loss: 0.099003, Train Acc: 0.846154 | Val Loss: 0.119748, Val Acc: 0.742268\n",
      "Epoch 13547 - Train Loss: 0.098999, Train Acc: 0.846154 | Val Loss: 0.119745, Val Acc: 0.742268\n",
      "Epoch 13548 - Train Loss: 0.098994, Train Acc: 0.846154 | Val Loss: 0.119741, Val Acc: 0.742268\n",
      "Epoch 13549 - Train Loss: 0.098989, Train Acc: 0.846154 | Val Loss: 0.119738, Val Acc: 0.742268\n",
      "Epoch 13550 - Train Loss: 0.098985, Train Acc: 0.846154 | Val Loss: 0.119735, Val Acc: 0.742268\n",
      "Epoch 13551 - Train Loss: 0.098980, Train Acc: 0.846154 | Val Loss: 0.119731, Val Acc: 0.742268\n",
      "Epoch 13552 - Train Loss: 0.098976, Train Acc: 0.846154 | Val Loss: 0.119728, Val Acc: 0.742268\n",
      "Epoch 13553 - Train Loss: 0.098971, Train Acc: 0.846154 | Val Loss: 0.119725, Val Acc: 0.742268\n",
      "Epoch 13554 - Train Loss: 0.098967, Train Acc: 0.846154 | Val Loss: 0.119721, Val Acc: 0.742268\n",
      "Epoch 13555 - Train Loss: 0.098962, Train Acc: 0.846154 | Val Loss: 0.119718, Val Acc: 0.742268\n",
      "Epoch 13556 - Train Loss: 0.098957, Train Acc: 0.846154 | Val Loss: 0.119715, Val Acc: 0.742268\n",
      "Epoch 13557 - Train Loss: 0.098953, Train Acc: 0.846154 | Val Loss: 0.119712, Val Acc: 0.742268\n",
      "Epoch 13558 - Train Loss: 0.098948, Train Acc: 0.846154 | Val Loss: 0.119708, Val Acc: 0.742268\n",
      "Epoch 13559 - Train Loss: 0.098944, Train Acc: 0.846154 | Val Loss: 0.119705, Val Acc: 0.742268\n",
      "Epoch 13560 - Train Loss: 0.098939, Train Acc: 0.846154 | Val Loss: 0.119702, Val Acc: 0.742268\n",
      "Epoch 13561 - Train Loss: 0.098935, Train Acc: 0.846154 | Val Loss: 0.119698, Val Acc: 0.742268\n",
      "Epoch 13562 - Train Loss: 0.098930, Train Acc: 0.846154 | Val Loss: 0.119695, Val Acc: 0.742268\n",
      "Epoch 13563 - Train Loss: 0.098925, Train Acc: 0.846154 | Val Loss: 0.119692, Val Acc: 0.742268\n",
      "Epoch 13564 - Train Loss: 0.098921, Train Acc: 0.846154 | Val Loss: 0.119688, Val Acc: 0.742268\n",
      "Epoch 13565 - Train Loss: 0.098916, Train Acc: 0.846154 | Val Loss: 0.119685, Val Acc: 0.742268\n",
      "Epoch 13566 - Train Loss: 0.098912, Train Acc: 0.846154 | Val Loss: 0.119682, Val Acc: 0.742268\n",
      "Epoch 13567 - Train Loss: 0.098907, Train Acc: 0.846154 | Val Loss: 0.119678, Val Acc: 0.742268\n",
      "Epoch 13568 - Train Loss: 0.098902, Train Acc: 0.846154 | Val Loss: 0.119675, Val Acc: 0.742268\n",
      "Epoch 13569 - Train Loss: 0.098898, Train Acc: 0.846154 | Val Loss: 0.119672, Val Acc: 0.742268\n",
      "Epoch 13570 - Train Loss: 0.098893, Train Acc: 0.846154 | Val Loss: 0.119668, Val Acc: 0.742268\n",
      "Epoch 13571 - Train Loss: 0.098889, Train Acc: 0.846154 | Val Loss: 0.119665, Val Acc: 0.742268\n",
      "Epoch 13572 - Train Loss: 0.098884, Train Acc: 0.846154 | Val Loss: 0.119662, Val Acc: 0.742268\n",
      "Epoch 13573 - Train Loss: 0.098880, Train Acc: 0.846154 | Val Loss: 0.119659, Val Acc: 0.742268\n",
      "Epoch 13574 - Train Loss: 0.098875, Train Acc: 0.846154 | Val Loss: 0.119655, Val Acc: 0.742268\n",
      "Epoch 13575 - Train Loss: 0.098871, Train Acc: 0.846154 | Val Loss: 0.119652, Val Acc: 0.742268\n",
      "Epoch 13576 - Train Loss: 0.098866, Train Acc: 0.846154 | Val Loss: 0.119649, Val Acc: 0.742268\n",
      "Epoch 13577 - Train Loss: 0.098861, Train Acc: 0.846154 | Val Loss: 0.119645, Val Acc: 0.742268\n",
      "Epoch 13578 - Train Loss: 0.098857, Train Acc: 0.846154 | Val Loss: 0.119642, Val Acc: 0.742268\n",
      "Epoch 13579 - Train Loss: 0.098852, Train Acc: 0.846154 | Val Loss: 0.119639, Val Acc: 0.742268\n",
      "Epoch 13580 - Train Loss: 0.098848, Train Acc: 0.846154 | Val Loss: 0.119636, Val Acc: 0.742268\n",
      "Epoch 13581 - Train Loss: 0.098843, Train Acc: 0.846154 | Val Loss: 0.119632, Val Acc: 0.742268\n",
      "Epoch 13582 - Train Loss: 0.098839, Train Acc: 0.846154 | Val Loss: 0.119629, Val Acc: 0.742268\n",
      "Epoch 13583 - Train Loss: 0.098834, Train Acc: 0.846154 | Val Loss: 0.119626, Val Acc: 0.742268\n",
      "Epoch 13584 - Train Loss: 0.098829, Train Acc: 0.846154 | Val Loss: 0.119622, Val Acc: 0.742268\n",
      "Epoch 13585 - Train Loss: 0.098825, Train Acc: 0.846154 | Val Loss: 0.119619, Val Acc: 0.742268\n",
      "Epoch 13586 - Train Loss: 0.098820, Train Acc: 0.846154 | Val Loss: 0.119616, Val Acc: 0.742268\n",
      "Epoch 13587 - Train Loss: 0.098816, Train Acc: 0.846154 | Val Loss: 0.119612, Val Acc: 0.742268\n",
      "Epoch 13588 - Train Loss: 0.098811, Train Acc: 0.846154 | Val Loss: 0.119609, Val Acc: 0.742268\n",
      "Epoch 13589 - Train Loss: 0.098807, Train Acc: 0.846154 | Val Loss: 0.119606, Val Acc: 0.742268\n",
      "Epoch 13590 - Train Loss: 0.098802, Train Acc: 0.846154 | Val Loss: 0.119603, Val Acc: 0.742268\n",
      "Epoch 13591 - Train Loss: 0.098797, Train Acc: 0.846154 | Val Loss: 0.119599, Val Acc: 0.742268\n",
      "Epoch 13592 - Train Loss: 0.098793, Train Acc: 0.846154 | Val Loss: 0.119596, Val Acc: 0.742268\n",
      "Epoch 13593 - Train Loss: 0.098788, Train Acc: 0.846154 | Val Loss: 0.119593, Val Acc: 0.742268\n",
      "Epoch 13594 - Train Loss: 0.098784, Train Acc: 0.846154 | Val Loss: 0.119589, Val Acc: 0.742268\n",
      "Epoch 13595 - Train Loss: 0.098779, Train Acc: 0.846154 | Val Loss: 0.119586, Val Acc: 0.742268\n",
      "Epoch 13596 - Train Loss: 0.098775, Train Acc: 0.846154 | Val Loss: 0.119583, Val Acc: 0.742268\n",
      "Epoch 13597 - Train Loss: 0.098770, Train Acc: 0.846154 | Val Loss: 0.119580, Val Acc: 0.742268\n",
      "Epoch 13598 - Train Loss: 0.098766, Train Acc: 0.846154 | Val Loss: 0.119576, Val Acc: 0.742268\n",
      "Epoch 13599 - Train Loss: 0.098761, Train Acc: 0.846154 | Val Loss: 0.119573, Val Acc: 0.742268\n",
      "Epoch 13600 - Train Loss: 0.098756, Train Acc: 0.846154 | Val Loss: 0.119570, Val Acc: 0.742268\n",
      "Epoch 13601 - Train Loss: 0.098752, Train Acc: 0.846154 | Val Loss: 0.119566, Val Acc: 0.742268\n",
      "Epoch 13602 - Train Loss: 0.098747, Train Acc: 0.846154 | Val Loss: 0.119563, Val Acc: 0.742268\n",
      "Epoch 13603 - Train Loss: 0.098743, Train Acc: 0.846154 | Val Loss: 0.119560, Val Acc: 0.742268\n",
      "Epoch 13604 - Train Loss: 0.098738, Train Acc: 0.846154 | Val Loss: 0.119557, Val Acc: 0.742268\n",
      "Epoch 13605 - Train Loss: 0.098734, Train Acc: 0.846154 | Val Loss: 0.119553, Val Acc: 0.742268\n",
      "Epoch 13606 - Train Loss: 0.098729, Train Acc: 0.846154 | Val Loss: 0.119550, Val Acc: 0.742268\n",
      "Epoch 13607 - Train Loss: 0.098725, Train Acc: 0.846154 | Val Loss: 0.119547, Val Acc: 0.742268\n",
      "Epoch 13608 - Train Loss: 0.098720, Train Acc: 0.846154 | Val Loss: 0.119544, Val Acc: 0.742268\n",
      "Epoch 13609 - Train Loss: 0.098716, Train Acc: 0.846154 | Val Loss: 0.119540, Val Acc: 0.742268\n",
      "Epoch 13610 - Train Loss: 0.098711, Train Acc: 0.846154 | Val Loss: 0.119537, Val Acc: 0.742268\n",
      "Epoch 13611 - Train Loss: 0.098706, Train Acc: 0.846154 | Val Loss: 0.119534, Val Acc: 0.742268\n",
      "Epoch 13612 - Train Loss: 0.098702, Train Acc: 0.846154 | Val Loss: 0.119530, Val Acc: 0.742268\n",
      "Epoch 13613 - Train Loss: 0.098697, Train Acc: 0.846154 | Val Loss: 0.119527, Val Acc: 0.742268\n",
      "Epoch 13614 - Train Loss: 0.098693, Train Acc: 0.846154 | Val Loss: 0.119524, Val Acc: 0.742268\n",
      "Epoch 13615 - Train Loss: 0.098688, Train Acc: 0.846154 | Val Loss: 0.119521, Val Acc: 0.742268\n",
      "Epoch 13616 - Train Loss: 0.098684, Train Acc: 0.846154 | Val Loss: 0.119517, Val Acc: 0.742268\n",
      "Epoch 13617 - Train Loss: 0.098679, Train Acc: 0.846154 | Val Loss: 0.119514, Val Acc: 0.742268\n",
      "Epoch 13618 - Train Loss: 0.098675, Train Acc: 0.846154 | Val Loss: 0.119511, Val Acc: 0.742268\n",
      "Epoch 13619 - Train Loss: 0.098670, Train Acc: 0.846154 | Val Loss: 0.119508, Val Acc: 0.742268\n",
      "Epoch 13620 - Train Loss: 0.098666, Train Acc: 0.846154 | Val Loss: 0.119504, Val Acc: 0.742268\n",
      "Epoch 13621 - Train Loss: 0.098661, Train Acc: 0.846154 | Val Loss: 0.119501, Val Acc: 0.742268\n",
      "Epoch 13622 - Train Loss: 0.098656, Train Acc: 0.846154 | Val Loss: 0.119498, Val Acc: 0.742268\n",
      "Epoch 13623 - Train Loss: 0.098652, Train Acc: 0.846154 | Val Loss: 0.119494, Val Acc: 0.742268\n",
      "Epoch 13624 - Train Loss: 0.098647, Train Acc: 0.846154 | Val Loss: 0.119491, Val Acc: 0.742268\n",
      "Epoch 13625 - Train Loss: 0.098643, Train Acc: 0.846154 | Val Loss: 0.119488, Val Acc: 0.742268\n",
      "Epoch 13626 - Train Loss: 0.098638, Train Acc: 0.846154 | Val Loss: 0.119485, Val Acc: 0.742268\n",
      "Epoch 13627 - Train Loss: 0.098634, Train Acc: 0.846154 | Val Loss: 0.119481, Val Acc: 0.742268\n",
      "Epoch 13628 - Train Loss: 0.098629, Train Acc: 0.846154 | Val Loss: 0.119478, Val Acc: 0.742268\n",
      "Epoch 13629 - Train Loss: 0.098625, Train Acc: 0.846154 | Val Loss: 0.119475, Val Acc: 0.742268\n",
      "Epoch 13630 - Train Loss: 0.098620, Train Acc: 0.846154 | Val Loss: 0.119472, Val Acc: 0.742268\n",
      "Epoch 13631 - Train Loss: 0.098616, Train Acc: 0.846154 | Val Loss: 0.119468, Val Acc: 0.742268\n",
      "Epoch 13632 - Train Loss: 0.098611, Train Acc: 0.846154 | Val Loss: 0.119465, Val Acc: 0.742268\n",
      "Epoch 13633 - Train Loss: 0.098607, Train Acc: 0.846154 | Val Loss: 0.119462, Val Acc: 0.742268\n",
      "Epoch 13634 - Train Loss: 0.098602, Train Acc: 0.846154 | Val Loss: 0.119459, Val Acc: 0.742268\n",
      "Epoch 13635 - Train Loss: 0.098598, Train Acc: 0.846154 | Val Loss: 0.119455, Val Acc: 0.742268\n",
      "Epoch 13636 - Train Loss: 0.098593, Train Acc: 0.846154 | Val Loss: 0.119452, Val Acc: 0.742268\n",
      "Epoch 13637 - Train Loss: 0.098588, Train Acc: 0.846154 | Val Loss: 0.119449, Val Acc: 0.742268\n",
      "Epoch 13638 - Train Loss: 0.098584, Train Acc: 0.846154 | Val Loss: 0.119446, Val Acc: 0.742268\n",
      "Epoch 13639 - Train Loss: 0.098579, Train Acc: 0.846154 | Val Loss: 0.119442, Val Acc: 0.742268\n",
      "Epoch 13640 - Train Loss: 0.098575, Train Acc: 0.846154 | Val Loss: 0.119439, Val Acc: 0.742268\n",
      "Epoch 13641 - Train Loss: 0.098570, Train Acc: 0.846154 | Val Loss: 0.119436, Val Acc: 0.742268\n",
      "Epoch 13642 - Train Loss: 0.098566, Train Acc: 0.847436 | Val Loss: 0.119433, Val Acc: 0.742268\n",
      "Epoch 13643 - Train Loss: 0.098561, Train Acc: 0.847436 | Val Loss: 0.119429, Val Acc: 0.742268\n",
      "Epoch 13644 - Train Loss: 0.098557, Train Acc: 0.847436 | Val Loss: 0.119426, Val Acc: 0.742268\n",
      "Epoch 13645 - Train Loss: 0.098552, Train Acc: 0.847436 | Val Loss: 0.119423, Val Acc: 0.742268\n",
      "Epoch 13646 - Train Loss: 0.098548, Train Acc: 0.847436 | Val Loss: 0.119419, Val Acc: 0.742268\n",
      "Epoch 13647 - Train Loss: 0.098543, Train Acc: 0.847436 | Val Loss: 0.119416, Val Acc: 0.742268\n",
      "Epoch 13648 - Train Loss: 0.098539, Train Acc: 0.847436 | Val Loss: 0.119413, Val Acc: 0.742268\n",
      "Epoch 13649 - Train Loss: 0.098534, Train Acc: 0.847436 | Val Loss: 0.119410, Val Acc: 0.742268\n",
      "Epoch 13650 - Train Loss: 0.098530, Train Acc: 0.847436 | Val Loss: 0.119407, Val Acc: 0.742268\n",
      "Epoch 13651 - Train Loss: 0.098525, Train Acc: 0.847436 | Val Loss: 0.119403, Val Acc: 0.742268\n",
      "Epoch 13652 - Train Loss: 0.098521, Train Acc: 0.847436 | Val Loss: 0.119400, Val Acc: 0.742268\n",
      "Epoch 13653 - Train Loss: 0.098516, Train Acc: 0.847436 | Val Loss: 0.119397, Val Acc: 0.742268\n",
      "Epoch 13654 - Train Loss: 0.098512, Train Acc: 0.847436 | Val Loss: 0.119394, Val Acc: 0.742268\n",
      "Epoch 13655 - Train Loss: 0.098507, Train Acc: 0.847436 | Val Loss: 0.119390, Val Acc: 0.742268\n",
      "Epoch 13656 - Train Loss: 0.098502, Train Acc: 0.847436 | Val Loss: 0.119387, Val Acc: 0.742268\n",
      "Epoch 13657 - Train Loss: 0.098498, Train Acc: 0.847436 | Val Loss: 0.119384, Val Acc: 0.742268\n",
      "Epoch 13658 - Train Loss: 0.098493, Train Acc: 0.847436 | Val Loss: 0.119381, Val Acc: 0.742268\n",
      "Epoch 13659 - Train Loss: 0.098489, Train Acc: 0.847436 | Val Loss: 0.119377, Val Acc: 0.742268\n",
      "Epoch 13660 - Train Loss: 0.098484, Train Acc: 0.847436 | Val Loss: 0.119374, Val Acc: 0.742268\n",
      "Epoch 13661 - Train Loss: 0.098480, Train Acc: 0.847436 | Val Loss: 0.119371, Val Acc: 0.742268\n",
      "Epoch 13662 - Train Loss: 0.098475, Train Acc: 0.847436 | Val Loss: 0.119368, Val Acc: 0.742268\n",
      "Epoch 13663 - Train Loss: 0.098471, Train Acc: 0.847436 | Val Loss: 0.119364, Val Acc: 0.742268\n",
      "Epoch 13664 - Train Loss: 0.098466, Train Acc: 0.847436 | Val Loss: 0.119361, Val Acc: 0.742268\n",
      "Epoch 13665 - Train Loss: 0.098462, Train Acc: 0.847436 | Val Loss: 0.119358, Val Acc: 0.742268\n",
      "Epoch 13666 - Train Loss: 0.098457, Train Acc: 0.847436 | Val Loss: 0.119355, Val Acc: 0.742268\n",
      "Epoch 13667 - Train Loss: 0.098453, Train Acc: 0.847436 | Val Loss: 0.119351, Val Acc: 0.742268\n",
      "Epoch 13668 - Train Loss: 0.098448, Train Acc: 0.847436 | Val Loss: 0.119348, Val Acc: 0.742268\n",
      "Epoch 13669 - Train Loss: 0.098444, Train Acc: 0.847436 | Val Loss: 0.119345, Val Acc: 0.742268\n",
      "Epoch 13670 - Train Loss: 0.098439, Train Acc: 0.847436 | Val Loss: 0.119342, Val Acc: 0.742268\n",
      "Epoch 13671 - Train Loss: 0.098435, Train Acc: 0.847436 | Val Loss: 0.119338, Val Acc: 0.742268\n",
      "Epoch 13672 - Train Loss: 0.098430, Train Acc: 0.847436 | Val Loss: 0.119335, Val Acc: 0.742268\n",
      "Epoch 13673 - Train Loss: 0.098426, Train Acc: 0.847436 | Val Loss: 0.119332, Val Acc: 0.742268\n",
      "Epoch 13674 - Train Loss: 0.098421, Train Acc: 0.847436 | Val Loss: 0.119329, Val Acc: 0.742268\n",
      "Epoch 13675 - Train Loss: 0.098417, Train Acc: 0.847436 | Val Loss: 0.119326, Val Acc: 0.742268\n",
      "Epoch 13676 - Train Loss: 0.098412, Train Acc: 0.847436 | Val Loss: 0.119322, Val Acc: 0.742268\n",
      "Epoch 13677 - Train Loss: 0.098408, Train Acc: 0.847436 | Val Loss: 0.119319, Val Acc: 0.742268\n",
      "Epoch 13678 - Train Loss: 0.098403, Train Acc: 0.847436 | Val Loss: 0.119316, Val Acc: 0.742268\n",
      "Epoch 13679 - Train Loss: 0.098399, Train Acc: 0.847436 | Val Loss: 0.119313, Val Acc: 0.742268\n",
      "Epoch 13680 - Train Loss: 0.098394, Train Acc: 0.847436 | Val Loss: 0.119309, Val Acc: 0.742268\n",
      "Epoch 13681 - Train Loss: 0.098390, Train Acc: 0.847436 | Val Loss: 0.119306, Val Acc: 0.742268\n",
      "Epoch 13682 - Train Loss: 0.098385, Train Acc: 0.847436 | Val Loss: 0.119303, Val Acc: 0.742268\n",
      "Epoch 13683 - Train Loss: 0.098381, Train Acc: 0.847436 | Val Loss: 0.119300, Val Acc: 0.742268\n",
      "Epoch 13684 - Train Loss: 0.098376, Train Acc: 0.847436 | Val Loss: 0.119296, Val Acc: 0.742268\n",
      "Epoch 13685 - Train Loss: 0.098372, Train Acc: 0.847436 | Val Loss: 0.119293, Val Acc: 0.742268\n",
      "Epoch 13686 - Train Loss: 0.098367, Train Acc: 0.847436 | Val Loss: 0.119290, Val Acc: 0.742268\n",
      "Epoch 13687 - Train Loss: 0.098363, Train Acc: 0.847436 | Val Loss: 0.119287, Val Acc: 0.742268\n",
      "Epoch 13688 - Train Loss: 0.098358, Train Acc: 0.847436 | Val Loss: 0.119283, Val Acc: 0.742268\n",
      "Epoch 13689 - Train Loss: 0.098354, Train Acc: 0.847436 | Val Loss: 0.119280, Val Acc: 0.742268\n",
      "Epoch 13690 - Train Loss: 0.098349, Train Acc: 0.847436 | Val Loss: 0.119277, Val Acc: 0.742268\n",
      "Epoch 13691 - Train Loss: 0.098345, Train Acc: 0.847436 | Val Loss: 0.119274, Val Acc: 0.742268\n",
      "Epoch 13692 - Train Loss: 0.098340, Train Acc: 0.847436 | Val Loss: 0.119270, Val Acc: 0.742268\n",
      "Epoch 13693 - Train Loss: 0.098336, Train Acc: 0.847436 | Val Loss: 0.119267, Val Acc: 0.742268\n",
      "Epoch 13694 - Train Loss: 0.098331, Train Acc: 0.847436 | Val Loss: 0.119264, Val Acc: 0.742268\n",
      "Epoch 13695 - Train Loss: 0.098327, Train Acc: 0.847436 | Val Loss: 0.119261, Val Acc: 0.742268\n",
      "Epoch 13696 - Train Loss: 0.098322, Train Acc: 0.847436 | Val Loss: 0.119258, Val Acc: 0.742268\n",
      "Epoch 13697 - Train Loss: 0.098318, Train Acc: 0.847436 | Val Loss: 0.119254, Val Acc: 0.742268\n",
      "Epoch 13698 - Train Loss: 0.098313, Train Acc: 0.848718 | Val Loss: 0.119251, Val Acc: 0.742268\n",
      "Epoch 13699 - Train Loss: 0.098309, Train Acc: 0.848718 | Val Loss: 0.119248, Val Acc: 0.742268\n",
      "Epoch 13700 - Train Loss: 0.098304, Train Acc: 0.848718 | Val Loss: 0.119245, Val Acc: 0.742268\n",
      "Epoch 13701 - Train Loss: 0.098300, Train Acc: 0.848718 | Val Loss: 0.119241, Val Acc: 0.742268\n",
      "Epoch 13702 - Train Loss: 0.098295, Train Acc: 0.848718 | Val Loss: 0.119238, Val Acc: 0.742268\n",
      "Epoch 13703 - Train Loss: 0.098291, Train Acc: 0.848718 | Val Loss: 0.119235, Val Acc: 0.742268\n",
      "Epoch 13704 - Train Loss: 0.098286, Train Acc: 0.848718 | Val Loss: 0.119232, Val Acc: 0.742268\n",
      "Epoch 13705 - Train Loss: 0.098282, Train Acc: 0.848718 | Val Loss: 0.119228, Val Acc: 0.742268\n",
      "Epoch 13706 - Train Loss: 0.098277, Train Acc: 0.848718 | Val Loss: 0.119225, Val Acc: 0.742268\n",
      "Epoch 13707 - Train Loss: 0.098273, Train Acc: 0.848718 | Val Loss: 0.119222, Val Acc: 0.742268\n",
      "Epoch 13708 - Train Loss: 0.098268, Train Acc: 0.848718 | Val Loss: 0.119219, Val Acc: 0.742268\n",
      "Epoch 13709 - Train Loss: 0.098264, Train Acc: 0.848718 | Val Loss: 0.119215, Val Acc: 0.742268\n",
      "Epoch 13710 - Train Loss: 0.098259, Train Acc: 0.848718 | Val Loss: 0.119212, Val Acc: 0.742268\n",
      "Epoch 13711 - Train Loss: 0.098255, Train Acc: 0.848718 | Val Loss: 0.119209, Val Acc: 0.742268\n",
      "Epoch 13712 - Train Loss: 0.098250, Train Acc: 0.848718 | Val Loss: 0.119206, Val Acc: 0.742268\n",
      "Epoch 13713 - Train Loss: 0.098246, Train Acc: 0.848718 | Val Loss: 0.119203, Val Acc: 0.742268\n",
      "Epoch 13714 - Train Loss: 0.098241, Train Acc: 0.848718 | Val Loss: 0.119199, Val Acc: 0.742268\n",
      "Epoch 13715 - Train Loss: 0.098237, Train Acc: 0.848718 | Val Loss: 0.119196, Val Acc: 0.742268\n",
      "Epoch 13716 - Train Loss: 0.098232, Train Acc: 0.848718 | Val Loss: 0.119193, Val Acc: 0.742268\n",
      "Epoch 13717 - Train Loss: 0.098228, Train Acc: 0.848718 | Val Loss: 0.119190, Val Acc: 0.742268\n",
      "Epoch 13718 - Train Loss: 0.098224, Train Acc: 0.848718 | Val Loss: 0.119186, Val Acc: 0.742268\n",
      "Epoch 13719 - Train Loss: 0.098219, Train Acc: 0.848718 | Val Loss: 0.119183, Val Acc: 0.742268\n",
      "Epoch 13720 - Train Loss: 0.098215, Train Acc: 0.848718 | Val Loss: 0.119180, Val Acc: 0.742268\n",
      "Epoch 13721 - Train Loss: 0.098210, Train Acc: 0.848718 | Val Loss: 0.119177, Val Acc: 0.742268\n",
      "Epoch 13722 - Train Loss: 0.098206, Train Acc: 0.848718 | Val Loss: 0.119174, Val Acc: 0.742268\n",
      "Epoch 13723 - Train Loss: 0.098201, Train Acc: 0.848718 | Val Loss: 0.119170, Val Acc: 0.742268\n",
      "Epoch 13724 - Train Loss: 0.098197, Train Acc: 0.848718 | Val Loss: 0.119167, Val Acc: 0.742268\n",
      "Epoch 13725 - Train Loss: 0.098192, Train Acc: 0.848718 | Val Loss: 0.119164, Val Acc: 0.742268\n",
      "Epoch 13726 - Train Loss: 0.098188, Train Acc: 0.848718 | Val Loss: 0.119161, Val Acc: 0.742268\n",
      "Epoch 13727 - Train Loss: 0.098183, Train Acc: 0.848718 | Val Loss: 0.119157, Val Acc: 0.742268\n",
      "Epoch 13728 - Train Loss: 0.098179, Train Acc: 0.848718 | Val Loss: 0.119154, Val Acc: 0.742268\n",
      "Epoch 13729 - Train Loss: 0.098174, Train Acc: 0.848718 | Val Loss: 0.119151, Val Acc: 0.742268\n",
      "Epoch 13730 - Train Loss: 0.098170, Train Acc: 0.848718 | Val Loss: 0.119148, Val Acc: 0.742268\n",
      "Epoch 13731 - Train Loss: 0.098165, Train Acc: 0.848718 | Val Loss: 0.119145, Val Acc: 0.742268\n",
      "Epoch 13732 - Train Loss: 0.098161, Train Acc: 0.848718 | Val Loss: 0.119141, Val Acc: 0.742268\n",
      "Epoch 13733 - Train Loss: 0.098156, Train Acc: 0.848718 | Val Loss: 0.119138, Val Acc: 0.742268\n",
      "Epoch 13734 - Train Loss: 0.098152, Train Acc: 0.848718 | Val Loss: 0.119135, Val Acc: 0.742268\n",
      "Epoch 13735 - Train Loss: 0.098147, Train Acc: 0.848718 | Val Loss: 0.119132, Val Acc: 0.742268\n",
      "Epoch 13736 - Train Loss: 0.098143, Train Acc: 0.848718 | Val Loss: 0.119128, Val Acc: 0.742268\n",
      "Epoch 13737 - Train Loss: 0.098138, Train Acc: 0.848718 | Val Loss: 0.119125, Val Acc: 0.742268\n",
      "Epoch 13738 - Train Loss: 0.098134, Train Acc: 0.848718 | Val Loss: 0.119122, Val Acc: 0.742268\n",
      "Epoch 13739 - Train Loss: 0.098130, Train Acc: 0.848718 | Val Loss: 0.119119, Val Acc: 0.752577\n",
      "Epoch 13740 - Train Loss: 0.098125, Train Acc: 0.848718 | Val Loss: 0.119116, Val Acc: 0.752577\n",
      "Epoch 13741 - Train Loss: 0.098121, Train Acc: 0.848718 | Val Loss: 0.119112, Val Acc: 0.752577\n",
      "Epoch 13742 - Train Loss: 0.098116, Train Acc: 0.848718 | Val Loss: 0.119109, Val Acc: 0.752577\n",
      "Epoch 13743 - Train Loss: 0.098112, Train Acc: 0.848718 | Val Loss: 0.119106, Val Acc: 0.752577\n",
      "Epoch 13744 - Train Loss: 0.098107, Train Acc: 0.848718 | Val Loss: 0.119103, Val Acc: 0.752577\n",
      "Epoch 13745 - Train Loss: 0.098103, Train Acc: 0.848718 | Val Loss: 0.119100, Val Acc: 0.752577\n",
      "Epoch 13746 - Train Loss: 0.098098, Train Acc: 0.848718 | Val Loss: 0.119096, Val Acc: 0.752577\n",
      "Epoch 13747 - Train Loss: 0.098094, Train Acc: 0.848718 | Val Loss: 0.119093, Val Acc: 0.752577\n",
      "Epoch 13748 - Train Loss: 0.098089, Train Acc: 0.848718 | Val Loss: 0.119090, Val Acc: 0.752577\n",
      "Epoch 13749 - Train Loss: 0.098085, Train Acc: 0.848718 | Val Loss: 0.119087, Val Acc: 0.752577\n",
      "Epoch 13750 - Train Loss: 0.098080, Train Acc: 0.848718 | Val Loss: 0.119084, Val Acc: 0.752577\n",
      "Epoch 13751 - Train Loss: 0.098076, Train Acc: 0.848718 | Val Loss: 0.119080, Val Acc: 0.752577\n",
      "Epoch 13752 - Train Loss: 0.098071, Train Acc: 0.848718 | Val Loss: 0.119077, Val Acc: 0.752577\n",
      "Epoch 13753 - Train Loss: 0.098067, Train Acc: 0.848718 | Val Loss: 0.119074, Val Acc: 0.752577\n",
      "Epoch 13754 - Train Loss: 0.098063, Train Acc: 0.848718 | Val Loss: 0.119071, Val Acc: 0.752577\n",
      "Epoch 13755 - Train Loss: 0.098058, Train Acc: 0.848718 | Val Loss: 0.119068, Val Acc: 0.752577\n",
      "Epoch 13756 - Train Loss: 0.098054, Train Acc: 0.848718 | Val Loss: 0.119064, Val Acc: 0.752577\n",
      "Epoch 13757 - Train Loss: 0.098049, Train Acc: 0.848718 | Val Loss: 0.119061, Val Acc: 0.752577\n",
      "Epoch 13758 - Train Loss: 0.098045, Train Acc: 0.848718 | Val Loss: 0.119058, Val Acc: 0.752577\n",
      "Epoch 13759 - Train Loss: 0.098040, Train Acc: 0.848718 | Val Loss: 0.119055, Val Acc: 0.752577\n",
      "Epoch 13760 - Train Loss: 0.098036, Train Acc: 0.848718 | Val Loss: 0.119052, Val Acc: 0.752577\n",
      "Epoch 13761 - Train Loss: 0.098031, Train Acc: 0.848718 | Val Loss: 0.119048, Val Acc: 0.752577\n",
      "Epoch 13762 - Train Loss: 0.098027, Train Acc: 0.848718 | Val Loss: 0.119045, Val Acc: 0.752577\n",
      "Epoch 13763 - Train Loss: 0.098022, Train Acc: 0.848718 | Val Loss: 0.119042, Val Acc: 0.752577\n",
      "Epoch 13764 - Train Loss: 0.098018, Train Acc: 0.848718 | Val Loss: 0.119039, Val Acc: 0.752577\n",
      "Epoch 13765 - Train Loss: 0.098014, Train Acc: 0.848718 | Val Loss: 0.119036, Val Acc: 0.752577\n",
      "Epoch 13766 - Train Loss: 0.098009, Train Acc: 0.848718 | Val Loss: 0.119032, Val Acc: 0.752577\n",
      "Epoch 13767 - Train Loss: 0.098005, Train Acc: 0.848718 | Val Loss: 0.119029, Val Acc: 0.752577\n",
      "Epoch 13768 - Train Loss: 0.098000, Train Acc: 0.848718 | Val Loss: 0.119026, Val Acc: 0.752577\n",
      "Epoch 13769 - Train Loss: 0.097996, Train Acc: 0.848718 | Val Loss: 0.119023, Val Acc: 0.752577\n",
      "Epoch 13770 - Train Loss: 0.097991, Train Acc: 0.848718 | Val Loss: 0.119020, Val Acc: 0.752577\n",
      "Epoch 13771 - Train Loss: 0.097987, Train Acc: 0.848718 | Val Loss: 0.119016, Val Acc: 0.752577\n",
      "Epoch 13772 - Train Loss: 0.097982, Train Acc: 0.848718 | Val Loss: 0.119013, Val Acc: 0.752577\n",
      "Epoch 13773 - Train Loss: 0.097978, Train Acc: 0.848718 | Val Loss: 0.119010, Val Acc: 0.752577\n",
      "Epoch 13774 - Train Loss: 0.097973, Train Acc: 0.848718 | Val Loss: 0.119007, Val Acc: 0.752577\n",
      "Epoch 13775 - Train Loss: 0.097969, Train Acc: 0.848718 | Val Loss: 0.119004, Val Acc: 0.752577\n",
      "Epoch 13776 - Train Loss: 0.097965, Train Acc: 0.848718 | Val Loss: 0.119000, Val Acc: 0.752577\n",
      "Epoch 13777 - Train Loss: 0.097960, Train Acc: 0.848718 | Val Loss: 0.118997, Val Acc: 0.752577\n",
      "Epoch 13778 - Train Loss: 0.097956, Train Acc: 0.848718 | Val Loss: 0.118994, Val Acc: 0.752577\n",
      "Epoch 13779 - Train Loss: 0.097951, Train Acc: 0.848718 | Val Loss: 0.118991, Val Acc: 0.752577\n",
      "Epoch 13780 - Train Loss: 0.097947, Train Acc: 0.848718 | Val Loss: 0.118988, Val Acc: 0.752577\n",
      "Epoch 13781 - Train Loss: 0.097942, Train Acc: 0.848718 | Val Loss: 0.118985, Val Acc: 0.752577\n",
      "Epoch 13782 - Train Loss: 0.097938, Train Acc: 0.848718 | Val Loss: 0.118981, Val Acc: 0.752577\n",
      "Epoch 13783 - Train Loss: 0.097933, Train Acc: 0.848718 | Val Loss: 0.118978, Val Acc: 0.752577\n",
      "Epoch 13784 - Train Loss: 0.097929, Train Acc: 0.848718 | Val Loss: 0.118975, Val Acc: 0.752577\n",
      "Epoch 13785 - Train Loss: 0.097925, Train Acc: 0.848718 | Val Loss: 0.118972, Val Acc: 0.752577\n",
      "Epoch 13786 - Train Loss: 0.097920, Train Acc: 0.848718 | Val Loss: 0.118969, Val Acc: 0.752577\n",
      "Epoch 13787 - Train Loss: 0.097916, Train Acc: 0.848718 | Val Loss: 0.118965, Val Acc: 0.752577\n",
      "Epoch 13788 - Train Loss: 0.097911, Train Acc: 0.848718 | Val Loss: 0.118962, Val Acc: 0.752577\n",
      "Epoch 13789 - Train Loss: 0.097907, Train Acc: 0.848718 | Val Loss: 0.118959, Val Acc: 0.752577\n",
      "Epoch 13790 - Train Loss: 0.097902, Train Acc: 0.848718 | Val Loss: 0.118956, Val Acc: 0.752577\n",
      "Epoch 13791 - Train Loss: 0.097898, Train Acc: 0.848718 | Val Loss: 0.118953, Val Acc: 0.752577\n",
      "Epoch 13792 - Train Loss: 0.097894, Train Acc: 0.848718 | Val Loss: 0.118949, Val Acc: 0.752577\n",
      "Epoch 13793 - Train Loss: 0.097889, Train Acc: 0.848718 | Val Loss: 0.118946, Val Acc: 0.752577\n",
      "Epoch 13794 - Train Loss: 0.097885, Train Acc: 0.848718 | Val Loss: 0.118943, Val Acc: 0.752577\n",
      "Epoch 13795 - Train Loss: 0.097880, Train Acc: 0.848718 | Val Loss: 0.118940, Val Acc: 0.752577\n",
      "Epoch 13796 - Train Loss: 0.097876, Train Acc: 0.848718 | Val Loss: 0.118937, Val Acc: 0.752577\n",
      "Epoch 13797 - Train Loss: 0.097871, Train Acc: 0.848718 | Val Loss: 0.118934, Val Acc: 0.752577\n",
      "Epoch 13798 - Train Loss: 0.097867, Train Acc: 0.848718 | Val Loss: 0.118930, Val Acc: 0.752577\n",
      "Epoch 13799 - Train Loss: 0.097862, Train Acc: 0.848718 | Val Loss: 0.118927, Val Acc: 0.752577\n",
      "Epoch 13800 - Train Loss: 0.097858, Train Acc: 0.848718 | Val Loss: 0.118924, Val Acc: 0.752577\n",
      "Epoch 13801 - Train Loss: 0.097854, Train Acc: 0.848718 | Val Loss: 0.118921, Val Acc: 0.752577\n",
      "Epoch 13802 - Train Loss: 0.097849, Train Acc: 0.848718 | Val Loss: 0.118918, Val Acc: 0.752577\n",
      "Epoch 13803 - Train Loss: 0.097845, Train Acc: 0.848718 | Val Loss: 0.118915, Val Acc: 0.752577\n",
      "Epoch 13804 - Train Loss: 0.097840, Train Acc: 0.848718 | Val Loss: 0.118911, Val Acc: 0.752577\n",
      "Epoch 13805 - Train Loss: 0.097836, Train Acc: 0.848718 | Val Loss: 0.118908, Val Acc: 0.752577\n",
      "Epoch 13806 - Train Loss: 0.097831, Train Acc: 0.848718 | Val Loss: 0.118905, Val Acc: 0.752577\n",
      "Epoch 13807 - Train Loss: 0.097827, Train Acc: 0.848718 | Val Loss: 0.118902, Val Acc: 0.752577\n",
      "Epoch 13808 - Train Loss: 0.097823, Train Acc: 0.848718 | Val Loss: 0.118899, Val Acc: 0.752577\n",
      "Epoch 13809 - Train Loss: 0.097818, Train Acc: 0.848718 | Val Loss: 0.118896, Val Acc: 0.752577\n",
      "Epoch 13810 - Train Loss: 0.097814, Train Acc: 0.848718 | Val Loss: 0.118892, Val Acc: 0.752577\n",
      "Epoch 13811 - Train Loss: 0.097809, Train Acc: 0.848718 | Val Loss: 0.118889, Val Acc: 0.752577\n",
      "Epoch 13812 - Train Loss: 0.097805, Train Acc: 0.848718 | Val Loss: 0.118886, Val Acc: 0.752577\n",
      "Epoch 13813 - Train Loss: 0.097800, Train Acc: 0.848718 | Val Loss: 0.118883, Val Acc: 0.752577\n",
      "Epoch 13814 - Train Loss: 0.097796, Train Acc: 0.848718 | Val Loss: 0.118880, Val Acc: 0.752577\n",
      "Epoch 13815 - Train Loss: 0.097792, Train Acc: 0.848718 | Val Loss: 0.118877, Val Acc: 0.752577\n",
      "Epoch 13816 - Train Loss: 0.097787, Train Acc: 0.848718 | Val Loss: 0.118873, Val Acc: 0.752577\n",
      "Epoch 13817 - Train Loss: 0.097783, Train Acc: 0.848718 | Val Loss: 0.118870, Val Acc: 0.752577\n",
      "Epoch 13818 - Train Loss: 0.097778, Train Acc: 0.848718 | Val Loss: 0.118867, Val Acc: 0.752577\n",
      "Epoch 13819 - Train Loss: 0.097774, Train Acc: 0.848718 | Val Loss: 0.118864, Val Acc: 0.752577\n",
      "Epoch 13820 - Train Loss: 0.097769, Train Acc: 0.848718 | Val Loss: 0.118861, Val Acc: 0.752577\n",
      "Epoch 13821 - Train Loss: 0.097765, Train Acc: 0.848718 | Val Loss: 0.118858, Val Acc: 0.752577\n",
      "Epoch 13822 - Train Loss: 0.097761, Train Acc: 0.848718 | Val Loss: 0.118854, Val Acc: 0.752577\n",
      "Epoch 13823 - Train Loss: 0.097756, Train Acc: 0.848718 | Val Loss: 0.118851, Val Acc: 0.752577\n",
      "Epoch 13824 - Train Loss: 0.097752, Train Acc: 0.848718 | Val Loss: 0.118848, Val Acc: 0.752577\n",
      "Epoch 13825 - Train Loss: 0.097747, Train Acc: 0.848718 | Val Loss: 0.118845, Val Acc: 0.752577\n",
      "Epoch 13826 - Train Loss: 0.097743, Train Acc: 0.848718 | Val Loss: 0.118842, Val Acc: 0.752577\n",
      "Epoch 13827 - Train Loss: 0.097739, Train Acc: 0.848718 | Val Loss: 0.118839, Val Acc: 0.752577\n",
      "Epoch 13828 - Train Loss: 0.097734, Train Acc: 0.848718 | Val Loss: 0.118836, Val Acc: 0.752577\n",
      "Epoch 13829 - Train Loss: 0.097730, Train Acc: 0.848718 | Val Loss: 0.118832, Val Acc: 0.752577\n",
      "Epoch 13830 - Train Loss: 0.097725, Train Acc: 0.848718 | Val Loss: 0.118829, Val Acc: 0.752577\n",
      "Epoch 13831 - Train Loss: 0.097721, Train Acc: 0.848718 | Val Loss: 0.118826, Val Acc: 0.752577\n",
      "Epoch 13832 - Train Loss: 0.097716, Train Acc: 0.848718 | Val Loss: 0.118823, Val Acc: 0.752577\n",
      "Epoch 13833 - Train Loss: 0.097712, Train Acc: 0.848718 | Val Loss: 0.118820, Val Acc: 0.752577\n",
      "Epoch 13834 - Train Loss: 0.097708, Train Acc: 0.848718 | Val Loss: 0.118817, Val Acc: 0.752577\n",
      "Epoch 13835 - Train Loss: 0.097703, Train Acc: 0.848718 | Val Loss: 0.118813, Val Acc: 0.752577\n",
      "Epoch 13836 - Train Loss: 0.097699, Train Acc: 0.848718 | Val Loss: 0.118810, Val Acc: 0.752577\n",
      "Epoch 13837 - Train Loss: 0.097694, Train Acc: 0.848718 | Val Loss: 0.118807, Val Acc: 0.752577\n",
      "Epoch 13838 - Train Loss: 0.097690, Train Acc: 0.848718 | Val Loss: 0.118804, Val Acc: 0.752577\n",
      "Epoch 13839 - Train Loss: 0.097686, Train Acc: 0.848718 | Val Loss: 0.118801, Val Acc: 0.752577\n",
      "Epoch 13840 - Train Loss: 0.097681, Train Acc: 0.848718 | Val Loss: 0.118798, Val Acc: 0.752577\n",
      "Epoch 13841 - Train Loss: 0.097677, Train Acc: 0.848718 | Val Loss: 0.118795, Val Acc: 0.752577\n",
      "Epoch 13842 - Train Loss: 0.097672, Train Acc: 0.848718 | Val Loss: 0.118791, Val Acc: 0.752577\n",
      "Epoch 13843 - Train Loss: 0.097668, Train Acc: 0.848718 | Val Loss: 0.118788, Val Acc: 0.752577\n",
      "Epoch 13844 - Train Loss: 0.097664, Train Acc: 0.848718 | Val Loss: 0.118785, Val Acc: 0.752577\n",
      "Epoch 13845 - Train Loss: 0.097659, Train Acc: 0.848718 | Val Loss: 0.118782, Val Acc: 0.752577\n",
      "Epoch 13846 - Train Loss: 0.097655, Train Acc: 0.848718 | Val Loss: 0.118779, Val Acc: 0.752577\n",
      "Epoch 13847 - Train Loss: 0.097650, Train Acc: 0.848718 | Val Loss: 0.118776, Val Acc: 0.752577\n",
      "Epoch 13848 - Train Loss: 0.097646, Train Acc: 0.848718 | Val Loss: 0.118773, Val Acc: 0.752577\n",
      "Epoch 13849 - Train Loss: 0.097641, Train Acc: 0.848718 | Val Loss: 0.118769, Val Acc: 0.752577\n",
      "Epoch 13850 - Train Loss: 0.097637, Train Acc: 0.848718 | Val Loss: 0.118766, Val Acc: 0.752577\n",
      "Epoch 13851 - Train Loss: 0.097633, Train Acc: 0.848718 | Val Loss: 0.118763, Val Acc: 0.752577\n",
      "Epoch 13852 - Train Loss: 0.097628, Train Acc: 0.848718 | Val Loss: 0.118760, Val Acc: 0.752577\n",
      "Epoch 13853 - Train Loss: 0.097624, Train Acc: 0.848718 | Val Loss: 0.118757, Val Acc: 0.752577\n",
      "Epoch 13854 - Train Loss: 0.097619, Train Acc: 0.848718 | Val Loss: 0.118754, Val Acc: 0.752577\n",
      "Epoch 13855 - Train Loss: 0.097615, Train Acc: 0.848718 | Val Loss: 0.118751, Val Acc: 0.752577\n",
      "Epoch 13856 - Train Loss: 0.097611, Train Acc: 0.848718 | Val Loss: 0.118747, Val Acc: 0.752577\n",
      "Epoch 13857 - Train Loss: 0.097606, Train Acc: 0.848718 | Val Loss: 0.118744, Val Acc: 0.752577\n",
      "Epoch 13858 - Train Loss: 0.097602, Train Acc: 0.848718 | Val Loss: 0.118741, Val Acc: 0.752577\n",
      "Epoch 13859 - Train Loss: 0.097597, Train Acc: 0.848718 | Val Loss: 0.118738, Val Acc: 0.752577\n",
      "Epoch 13860 - Train Loss: 0.097593, Train Acc: 0.848718 | Val Loss: 0.118735, Val Acc: 0.752577\n",
      "Epoch 13861 - Train Loss: 0.097589, Train Acc: 0.848718 | Val Loss: 0.118732, Val Acc: 0.752577\n",
      "Epoch 13862 - Train Loss: 0.097584, Train Acc: 0.848718 | Val Loss: 0.118729, Val Acc: 0.752577\n",
      "Epoch 13863 - Train Loss: 0.097580, Train Acc: 0.848718 | Val Loss: 0.118725, Val Acc: 0.752577\n",
      "Epoch 13864 - Train Loss: 0.097575, Train Acc: 0.848718 | Val Loss: 0.118722, Val Acc: 0.752577\n",
      "Epoch 13865 - Train Loss: 0.097571, Train Acc: 0.848718 | Val Loss: 0.118719, Val Acc: 0.752577\n",
      "Epoch 13866 - Train Loss: 0.097567, Train Acc: 0.848718 | Val Loss: 0.118716, Val Acc: 0.752577\n",
      "Epoch 13867 - Train Loss: 0.097562, Train Acc: 0.848718 | Val Loss: 0.118713, Val Acc: 0.752577\n",
      "Epoch 13868 - Train Loss: 0.097558, Train Acc: 0.848718 | Val Loss: 0.118710, Val Acc: 0.752577\n",
      "Epoch 13869 - Train Loss: 0.097553, Train Acc: 0.848718 | Val Loss: 0.118707, Val Acc: 0.752577\n",
      "Epoch 13870 - Train Loss: 0.097549, Train Acc: 0.848718 | Val Loss: 0.118704, Val Acc: 0.752577\n",
      "Epoch 13871 - Train Loss: 0.097545, Train Acc: 0.848718 | Val Loss: 0.118700, Val Acc: 0.752577\n",
      "Epoch 13872 - Train Loss: 0.097540, Train Acc: 0.848718 | Val Loss: 0.118697, Val Acc: 0.752577\n",
      "Epoch 13873 - Train Loss: 0.097536, Train Acc: 0.848718 | Val Loss: 0.118694, Val Acc: 0.752577\n",
      "Epoch 13874 - Train Loss: 0.097532, Train Acc: 0.848718 | Val Loss: 0.118691, Val Acc: 0.752577\n",
      "Epoch 13875 - Train Loss: 0.097527, Train Acc: 0.848718 | Val Loss: 0.118688, Val Acc: 0.752577\n",
      "Epoch 13876 - Train Loss: 0.097523, Train Acc: 0.848718 | Val Loss: 0.118685, Val Acc: 0.752577\n",
      "Epoch 13877 - Train Loss: 0.097518, Train Acc: 0.848718 | Val Loss: 0.118682, Val Acc: 0.752577\n",
      "Epoch 13878 - Train Loss: 0.097514, Train Acc: 0.848718 | Val Loss: 0.118678, Val Acc: 0.752577\n",
      "Epoch 13879 - Train Loss: 0.097510, Train Acc: 0.848718 | Val Loss: 0.118675, Val Acc: 0.752577\n",
      "Epoch 13880 - Train Loss: 0.097505, Train Acc: 0.848718 | Val Loss: 0.118672, Val Acc: 0.752577\n",
      "Epoch 13881 - Train Loss: 0.097501, Train Acc: 0.848718 | Val Loss: 0.118669, Val Acc: 0.752577\n",
      "Epoch 13882 - Train Loss: 0.097496, Train Acc: 0.848718 | Val Loss: 0.118666, Val Acc: 0.752577\n",
      "Epoch 13883 - Train Loss: 0.097492, Train Acc: 0.848718 | Val Loss: 0.118663, Val Acc: 0.752577\n",
      "Epoch 13884 - Train Loss: 0.097488, Train Acc: 0.848718 | Val Loss: 0.118660, Val Acc: 0.752577\n",
      "Epoch 13885 - Train Loss: 0.097483, Train Acc: 0.848718 | Val Loss: 0.118657, Val Acc: 0.752577\n",
      "Epoch 13886 - Train Loss: 0.097479, Train Acc: 0.848718 | Val Loss: 0.118653, Val Acc: 0.752577\n",
      "Epoch 13887 - Train Loss: 0.097474, Train Acc: 0.848718 | Val Loss: 0.118650, Val Acc: 0.752577\n",
      "Epoch 13888 - Train Loss: 0.097470, Train Acc: 0.848718 | Val Loss: 0.118647, Val Acc: 0.752577\n",
      "Epoch 13889 - Train Loss: 0.097466, Train Acc: 0.848718 | Val Loss: 0.118644, Val Acc: 0.752577\n",
      "Epoch 13890 - Train Loss: 0.097461, Train Acc: 0.848718 | Val Loss: 0.118641, Val Acc: 0.752577\n",
      "Epoch 13891 - Train Loss: 0.097457, Train Acc: 0.848718 | Val Loss: 0.118638, Val Acc: 0.752577\n",
      "Epoch 13892 - Train Loss: 0.097453, Train Acc: 0.848718 | Val Loss: 0.118635, Val Acc: 0.752577\n",
      "Epoch 13893 - Train Loss: 0.097448, Train Acc: 0.848718 | Val Loss: 0.118632, Val Acc: 0.752577\n",
      "Epoch 13894 - Train Loss: 0.097444, Train Acc: 0.848718 | Val Loss: 0.118628, Val Acc: 0.752577\n",
      "Epoch 13895 - Train Loss: 0.097439, Train Acc: 0.848718 | Val Loss: 0.118625, Val Acc: 0.752577\n",
      "Epoch 13896 - Train Loss: 0.097435, Train Acc: 0.848718 | Val Loss: 0.118622, Val Acc: 0.752577\n",
      "Epoch 13897 - Train Loss: 0.097431, Train Acc: 0.848718 | Val Loss: 0.118619, Val Acc: 0.752577\n",
      "Epoch 13898 - Train Loss: 0.097426, Train Acc: 0.848718 | Val Loss: 0.118616, Val Acc: 0.752577\n",
      "Epoch 13899 - Train Loss: 0.097422, Train Acc: 0.848718 | Val Loss: 0.118613, Val Acc: 0.752577\n",
      "Epoch 13900 - Train Loss: 0.097418, Train Acc: 0.848718 | Val Loss: 0.118610, Val Acc: 0.752577\n",
      "Epoch 13901 - Train Loss: 0.097413, Train Acc: 0.848718 | Val Loss: 0.118607, Val Acc: 0.752577\n",
      "Epoch 13902 - Train Loss: 0.097409, Train Acc: 0.848718 | Val Loss: 0.118604, Val Acc: 0.752577\n",
      "Epoch 13903 - Train Loss: 0.097404, Train Acc: 0.848718 | Val Loss: 0.118600, Val Acc: 0.752577\n",
      "Epoch 13904 - Train Loss: 0.097400, Train Acc: 0.848718 | Val Loss: 0.118597, Val Acc: 0.752577\n",
      "Epoch 13905 - Train Loss: 0.097396, Train Acc: 0.848718 | Val Loss: 0.118594, Val Acc: 0.752577\n",
      "Epoch 13906 - Train Loss: 0.097391, Train Acc: 0.848718 | Val Loss: 0.118591, Val Acc: 0.752577\n",
      "Epoch 13907 - Train Loss: 0.097387, Train Acc: 0.850000 | Val Loss: 0.118588, Val Acc: 0.752577\n",
      "Epoch 13908 - Train Loss: 0.097383, Train Acc: 0.850000 | Val Loss: 0.118585, Val Acc: 0.752577\n",
      "Epoch 13909 - Train Loss: 0.097378, Train Acc: 0.850000 | Val Loss: 0.118582, Val Acc: 0.752577\n",
      "Epoch 13910 - Train Loss: 0.097374, Train Acc: 0.850000 | Val Loss: 0.118579, Val Acc: 0.752577\n",
      "Epoch 13911 - Train Loss: 0.097369, Train Acc: 0.850000 | Val Loss: 0.118576, Val Acc: 0.752577\n",
      "Epoch 13912 - Train Loss: 0.097365, Train Acc: 0.850000 | Val Loss: 0.118572, Val Acc: 0.752577\n",
      "Epoch 13913 - Train Loss: 0.097361, Train Acc: 0.850000 | Val Loss: 0.118569, Val Acc: 0.752577\n",
      "Epoch 13914 - Train Loss: 0.097356, Train Acc: 0.850000 | Val Loss: 0.118566, Val Acc: 0.752577\n",
      "Epoch 13915 - Train Loss: 0.097352, Train Acc: 0.850000 | Val Loss: 0.118563, Val Acc: 0.752577\n",
      "Epoch 13916 - Train Loss: 0.097348, Train Acc: 0.850000 | Val Loss: 0.118560, Val Acc: 0.752577\n",
      "Epoch 13917 - Train Loss: 0.097343, Train Acc: 0.850000 | Val Loss: 0.118557, Val Acc: 0.752577\n",
      "Epoch 13918 - Train Loss: 0.097339, Train Acc: 0.850000 | Val Loss: 0.118554, Val Acc: 0.752577\n",
      "Epoch 13919 - Train Loss: 0.097334, Train Acc: 0.851282 | Val Loss: 0.118551, Val Acc: 0.752577\n",
      "Epoch 13920 - Train Loss: 0.097330, Train Acc: 0.851282 | Val Loss: 0.118548, Val Acc: 0.752577\n",
      "Epoch 13921 - Train Loss: 0.097326, Train Acc: 0.851282 | Val Loss: 0.118545, Val Acc: 0.752577\n",
      "Epoch 13922 - Train Loss: 0.097321, Train Acc: 0.851282 | Val Loss: 0.118541, Val Acc: 0.752577\n",
      "Epoch 13923 - Train Loss: 0.097317, Train Acc: 0.851282 | Val Loss: 0.118538, Val Acc: 0.752577\n",
      "Epoch 13924 - Train Loss: 0.097313, Train Acc: 0.851282 | Val Loss: 0.118535, Val Acc: 0.752577\n",
      "Epoch 13925 - Train Loss: 0.097308, Train Acc: 0.851282 | Val Loss: 0.118532, Val Acc: 0.752577\n",
      "Epoch 13926 - Train Loss: 0.097304, Train Acc: 0.851282 | Val Loss: 0.118529, Val Acc: 0.752577\n",
      "Epoch 13927 - Train Loss: 0.097300, Train Acc: 0.851282 | Val Loss: 0.118526, Val Acc: 0.752577\n",
      "Epoch 13928 - Train Loss: 0.097295, Train Acc: 0.851282 | Val Loss: 0.118523, Val Acc: 0.752577\n",
      "Epoch 13929 - Train Loss: 0.097291, Train Acc: 0.851282 | Val Loss: 0.118520, Val Acc: 0.752577\n",
      "Epoch 13930 - Train Loss: 0.097286, Train Acc: 0.851282 | Val Loss: 0.118517, Val Acc: 0.752577\n",
      "Epoch 13931 - Train Loss: 0.097282, Train Acc: 0.851282 | Val Loss: 0.118514, Val Acc: 0.752577\n",
      "Epoch 13932 - Train Loss: 0.097278, Train Acc: 0.851282 | Val Loss: 0.118510, Val Acc: 0.752577\n",
      "Epoch 13933 - Train Loss: 0.097273, Train Acc: 0.851282 | Val Loss: 0.118507, Val Acc: 0.752577\n",
      "Epoch 13934 - Train Loss: 0.097269, Train Acc: 0.851282 | Val Loss: 0.118504, Val Acc: 0.752577\n",
      "Epoch 13935 - Train Loss: 0.097265, Train Acc: 0.851282 | Val Loss: 0.118501, Val Acc: 0.752577\n",
      "Epoch 13936 - Train Loss: 0.097260, Train Acc: 0.851282 | Val Loss: 0.118498, Val Acc: 0.752577\n",
      "Epoch 13937 - Train Loss: 0.097256, Train Acc: 0.851282 | Val Loss: 0.118495, Val Acc: 0.752577\n",
      "Epoch 13938 - Train Loss: 0.097252, Train Acc: 0.851282 | Val Loss: 0.118492, Val Acc: 0.752577\n",
      "Epoch 13939 - Train Loss: 0.097247, Train Acc: 0.851282 | Val Loss: 0.118489, Val Acc: 0.752577\n",
      "Epoch 13940 - Train Loss: 0.097243, Train Acc: 0.851282 | Val Loss: 0.118486, Val Acc: 0.752577\n",
      "Epoch 13941 - Train Loss: 0.097239, Train Acc: 0.851282 | Val Loss: 0.118483, Val Acc: 0.752577\n",
      "Epoch 13942 - Train Loss: 0.097234, Train Acc: 0.851282 | Val Loss: 0.118480, Val Acc: 0.752577\n",
      "Epoch 13943 - Train Loss: 0.097230, Train Acc: 0.851282 | Val Loss: 0.118476, Val Acc: 0.752577\n",
      "Epoch 13944 - Train Loss: 0.097226, Train Acc: 0.851282 | Val Loss: 0.118473, Val Acc: 0.752577\n",
      "Epoch 13945 - Train Loss: 0.097221, Train Acc: 0.851282 | Val Loss: 0.118470, Val Acc: 0.752577\n",
      "Epoch 13946 - Train Loss: 0.097217, Train Acc: 0.851282 | Val Loss: 0.118467, Val Acc: 0.752577\n",
      "Epoch 13947 - Train Loss: 0.097212, Train Acc: 0.851282 | Val Loss: 0.118464, Val Acc: 0.752577\n",
      "Epoch 13948 - Train Loss: 0.097208, Train Acc: 0.851282 | Val Loss: 0.118461, Val Acc: 0.752577\n",
      "Epoch 13949 - Train Loss: 0.097204, Train Acc: 0.851282 | Val Loss: 0.118458, Val Acc: 0.752577\n",
      "Epoch 13950 - Train Loss: 0.097199, Train Acc: 0.851282 | Val Loss: 0.118455, Val Acc: 0.752577\n",
      "Epoch 13951 - Train Loss: 0.097195, Train Acc: 0.851282 | Val Loss: 0.118452, Val Acc: 0.752577\n",
      "Epoch 13952 - Train Loss: 0.097191, Train Acc: 0.851282 | Val Loss: 0.118449, Val Acc: 0.752577\n",
      "Epoch 13953 - Train Loss: 0.097186, Train Acc: 0.851282 | Val Loss: 0.118446, Val Acc: 0.752577\n",
      "Epoch 13954 - Train Loss: 0.097182, Train Acc: 0.851282 | Val Loss: 0.118443, Val Acc: 0.752577\n",
      "Epoch 13955 - Train Loss: 0.097178, Train Acc: 0.851282 | Val Loss: 0.118439, Val Acc: 0.752577\n",
      "Epoch 13956 - Train Loss: 0.097173, Train Acc: 0.851282 | Val Loss: 0.118436, Val Acc: 0.752577\n",
      "Epoch 13957 - Train Loss: 0.097169, Train Acc: 0.851282 | Val Loss: 0.118433, Val Acc: 0.752577\n",
      "Epoch 13958 - Train Loss: 0.097165, Train Acc: 0.851282 | Val Loss: 0.118430, Val Acc: 0.752577\n",
      "Epoch 13959 - Train Loss: 0.097160, Train Acc: 0.851282 | Val Loss: 0.118427, Val Acc: 0.752577\n",
      "Epoch 13960 - Train Loss: 0.097156, Train Acc: 0.851282 | Val Loss: 0.118424, Val Acc: 0.752577\n",
      "Epoch 13961 - Train Loss: 0.097152, Train Acc: 0.851282 | Val Loss: 0.118421, Val Acc: 0.752577\n",
      "Epoch 13962 - Train Loss: 0.097147, Train Acc: 0.851282 | Val Loss: 0.118418, Val Acc: 0.752577\n",
      "Epoch 13963 - Train Loss: 0.097143, Train Acc: 0.851282 | Val Loss: 0.118415, Val Acc: 0.752577\n",
      "Epoch 13964 - Train Loss: 0.097139, Train Acc: 0.851282 | Val Loss: 0.118412, Val Acc: 0.752577\n",
      "Epoch 13965 - Train Loss: 0.097134, Train Acc: 0.851282 | Val Loss: 0.118409, Val Acc: 0.752577\n",
      "Epoch 13966 - Train Loss: 0.097130, Train Acc: 0.851282 | Val Loss: 0.118406, Val Acc: 0.752577\n",
      "Epoch 13967 - Train Loss: 0.097126, Train Acc: 0.851282 | Val Loss: 0.118403, Val Acc: 0.752577\n",
      "Epoch 13968 - Train Loss: 0.097121, Train Acc: 0.851282 | Val Loss: 0.118399, Val Acc: 0.752577\n",
      "Epoch 13969 - Train Loss: 0.097117, Train Acc: 0.851282 | Val Loss: 0.118396, Val Acc: 0.752577\n",
      "Epoch 13970 - Train Loss: 0.097113, Train Acc: 0.851282 | Val Loss: 0.118393, Val Acc: 0.752577\n",
      "Epoch 13971 - Train Loss: 0.097108, Train Acc: 0.851282 | Val Loss: 0.118390, Val Acc: 0.752577\n",
      "Epoch 13972 - Train Loss: 0.097104, Train Acc: 0.851282 | Val Loss: 0.118387, Val Acc: 0.752577\n",
      "Epoch 13973 - Train Loss: 0.097099, Train Acc: 0.851282 | Val Loss: 0.118384, Val Acc: 0.752577\n",
      "Epoch 13974 - Train Loss: 0.097095, Train Acc: 0.851282 | Val Loss: 0.118381, Val Acc: 0.752577\n",
      "Epoch 13975 - Train Loss: 0.097091, Train Acc: 0.851282 | Val Loss: 0.118378, Val Acc: 0.752577\n",
      "Epoch 13976 - Train Loss: 0.097086, Train Acc: 0.851282 | Val Loss: 0.118375, Val Acc: 0.752577\n",
      "Epoch 13977 - Train Loss: 0.097082, Train Acc: 0.851282 | Val Loss: 0.118372, Val Acc: 0.752577\n",
      "Epoch 13978 - Train Loss: 0.097078, Train Acc: 0.851282 | Val Loss: 0.118369, Val Acc: 0.752577\n",
      "Epoch 13979 - Train Loss: 0.097073, Train Acc: 0.851282 | Val Loss: 0.118366, Val Acc: 0.752577\n",
      "Epoch 13980 - Train Loss: 0.097069, Train Acc: 0.851282 | Val Loss: 0.118363, Val Acc: 0.752577\n",
      "Epoch 13981 - Train Loss: 0.097065, Train Acc: 0.851282 | Val Loss: 0.118360, Val Acc: 0.752577\n",
      "Epoch 13982 - Train Loss: 0.097060, Train Acc: 0.851282 | Val Loss: 0.118356, Val Acc: 0.752577\n",
      "Epoch 13983 - Train Loss: 0.097056, Train Acc: 0.851282 | Val Loss: 0.118353, Val Acc: 0.752577\n",
      "Epoch 13984 - Train Loss: 0.097052, Train Acc: 0.851282 | Val Loss: 0.118350, Val Acc: 0.752577\n",
      "Epoch 13985 - Train Loss: 0.097047, Train Acc: 0.851282 | Val Loss: 0.118347, Val Acc: 0.752577\n",
      "Epoch 13986 - Train Loss: 0.097043, Train Acc: 0.851282 | Val Loss: 0.118344, Val Acc: 0.752577\n",
      "Epoch 13987 - Train Loss: 0.097039, Train Acc: 0.851282 | Val Loss: 0.118341, Val Acc: 0.752577\n",
      "Epoch 13988 - Train Loss: 0.097035, Train Acc: 0.851282 | Val Loss: 0.118338, Val Acc: 0.752577\n",
      "Epoch 13989 - Train Loss: 0.097030, Train Acc: 0.851282 | Val Loss: 0.118335, Val Acc: 0.752577\n",
      "Epoch 13990 - Train Loss: 0.097026, Train Acc: 0.851282 | Val Loss: 0.118332, Val Acc: 0.752577\n",
      "Epoch 13991 - Train Loss: 0.097022, Train Acc: 0.851282 | Val Loss: 0.118329, Val Acc: 0.752577\n",
      "Epoch 13992 - Train Loss: 0.097017, Train Acc: 0.851282 | Val Loss: 0.118326, Val Acc: 0.752577\n",
      "Epoch 13993 - Train Loss: 0.097013, Train Acc: 0.851282 | Val Loss: 0.118323, Val Acc: 0.752577\n",
      "Epoch 13994 - Train Loss: 0.097009, Train Acc: 0.851282 | Val Loss: 0.118320, Val Acc: 0.752577\n",
      "Epoch 13995 - Train Loss: 0.097004, Train Acc: 0.851282 | Val Loss: 0.118317, Val Acc: 0.752577\n",
      "Epoch 13996 - Train Loss: 0.097000, Train Acc: 0.851282 | Val Loss: 0.118314, Val Acc: 0.752577\n",
      "Epoch 13997 - Train Loss: 0.096996, Train Acc: 0.851282 | Val Loss: 0.118311, Val Acc: 0.752577\n",
      "Epoch 13998 - Train Loss: 0.096991, Train Acc: 0.851282 | Val Loss: 0.118307, Val Acc: 0.752577\n",
      "Epoch 13999 - Train Loss: 0.096987, Train Acc: 0.851282 | Val Loss: 0.118304, Val Acc: 0.752577\n",
      "Epoch 14000 - Train Loss: 0.096983, Train Acc: 0.851282 | Val Loss: 0.118301, Val Acc: 0.752577\n",
      "Epoch 14001 - Train Loss: 0.096978, Train Acc: 0.851282 | Val Loss: 0.118298, Val Acc: 0.752577\n",
      "Epoch 14002 - Train Loss: 0.096974, Train Acc: 0.851282 | Val Loss: 0.118295, Val Acc: 0.752577\n",
      "Epoch 14003 - Train Loss: 0.096970, Train Acc: 0.851282 | Val Loss: 0.118292, Val Acc: 0.752577\n",
      "Epoch 14004 - Train Loss: 0.096965, Train Acc: 0.851282 | Val Loss: 0.118289, Val Acc: 0.752577\n",
      "Epoch 14005 - Train Loss: 0.096961, Train Acc: 0.851282 | Val Loss: 0.118286, Val Acc: 0.752577\n",
      "Epoch 14006 - Train Loss: 0.096957, Train Acc: 0.851282 | Val Loss: 0.118283, Val Acc: 0.752577\n",
      "Epoch 14007 - Train Loss: 0.096952, Train Acc: 0.851282 | Val Loss: 0.118280, Val Acc: 0.752577\n",
      "Epoch 14008 - Train Loss: 0.096948, Train Acc: 0.851282 | Val Loss: 0.118277, Val Acc: 0.752577\n",
      "Epoch 14009 - Train Loss: 0.096944, Train Acc: 0.851282 | Val Loss: 0.118274, Val Acc: 0.752577\n",
      "Epoch 14010 - Train Loss: 0.096939, Train Acc: 0.851282 | Val Loss: 0.118271, Val Acc: 0.752577\n",
      "Epoch 14011 - Train Loss: 0.096935, Train Acc: 0.851282 | Val Loss: 0.118268, Val Acc: 0.752577\n",
      "Epoch 14012 - Train Loss: 0.096931, Train Acc: 0.851282 | Val Loss: 0.118265, Val Acc: 0.752577\n",
      "Epoch 14013 - Train Loss: 0.096926, Train Acc: 0.851282 | Val Loss: 0.118262, Val Acc: 0.752577\n",
      "Epoch 14014 - Train Loss: 0.096922, Train Acc: 0.851282 | Val Loss: 0.118259, Val Acc: 0.752577\n",
      "Epoch 14015 - Train Loss: 0.096918, Train Acc: 0.851282 | Val Loss: 0.118256, Val Acc: 0.752577\n",
      "Epoch 14016 - Train Loss: 0.096914, Train Acc: 0.851282 | Val Loss: 0.118253, Val Acc: 0.752577\n",
      "Epoch 14017 - Train Loss: 0.096909, Train Acc: 0.851282 | Val Loss: 0.118250, Val Acc: 0.752577\n",
      "Epoch 14018 - Train Loss: 0.096905, Train Acc: 0.851282 | Val Loss: 0.118246, Val Acc: 0.752577\n",
      "Epoch 14019 - Train Loss: 0.096901, Train Acc: 0.851282 | Val Loss: 0.118243, Val Acc: 0.752577\n",
      "Epoch 14020 - Train Loss: 0.096896, Train Acc: 0.851282 | Val Loss: 0.118240, Val Acc: 0.752577\n",
      "Epoch 14021 - Train Loss: 0.096892, Train Acc: 0.851282 | Val Loss: 0.118237, Val Acc: 0.752577\n",
      "Epoch 14022 - Train Loss: 0.096888, Train Acc: 0.851282 | Val Loss: 0.118234, Val Acc: 0.752577\n",
      "Epoch 14023 - Train Loss: 0.096883, Train Acc: 0.851282 | Val Loss: 0.118231, Val Acc: 0.752577\n",
      "Epoch 14024 - Train Loss: 0.096879, Train Acc: 0.851282 | Val Loss: 0.118228, Val Acc: 0.752577\n",
      "Epoch 14025 - Train Loss: 0.096875, Train Acc: 0.851282 | Val Loss: 0.118225, Val Acc: 0.752577\n",
      "Epoch 14026 - Train Loss: 0.096870, Train Acc: 0.851282 | Val Loss: 0.118222, Val Acc: 0.752577\n",
      "Epoch 14027 - Train Loss: 0.096866, Train Acc: 0.851282 | Val Loss: 0.118219, Val Acc: 0.752577\n",
      "Epoch 14028 - Train Loss: 0.096862, Train Acc: 0.851282 | Val Loss: 0.118216, Val Acc: 0.752577\n",
      "Epoch 14029 - Train Loss: 0.096858, Train Acc: 0.851282 | Val Loss: 0.118213, Val Acc: 0.752577\n",
      "Epoch 14030 - Train Loss: 0.096853, Train Acc: 0.851282 | Val Loss: 0.118210, Val Acc: 0.752577\n",
      "Epoch 14031 - Train Loss: 0.096849, Train Acc: 0.851282 | Val Loss: 0.118207, Val Acc: 0.752577\n",
      "Epoch 14032 - Train Loss: 0.096845, Train Acc: 0.851282 | Val Loss: 0.118204, Val Acc: 0.752577\n",
      "Epoch 14033 - Train Loss: 0.096840, Train Acc: 0.851282 | Val Loss: 0.118201, Val Acc: 0.752577\n",
      "Epoch 14034 - Train Loss: 0.096836, Train Acc: 0.851282 | Val Loss: 0.118198, Val Acc: 0.752577\n",
      "Epoch 14035 - Train Loss: 0.096832, Train Acc: 0.851282 | Val Loss: 0.118195, Val Acc: 0.752577\n",
      "Epoch 14036 - Train Loss: 0.096827, Train Acc: 0.851282 | Val Loss: 0.118192, Val Acc: 0.752577\n",
      "Epoch 14037 - Train Loss: 0.096823, Train Acc: 0.851282 | Val Loss: 0.118189, Val Acc: 0.752577\n",
      "Epoch 14038 - Train Loss: 0.096819, Train Acc: 0.851282 | Val Loss: 0.118186, Val Acc: 0.752577\n",
      "Epoch 14039 - Train Loss: 0.096814, Train Acc: 0.851282 | Val Loss: 0.118183, Val Acc: 0.752577\n",
      "Epoch 14040 - Train Loss: 0.096810, Train Acc: 0.851282 | Val Loss: 0.118180, Val Acc: 0.752577\n",
      "Epoch 14041 - Train Loss: 0.096806, Train Acc: 0.851282 | Val Loss: 0.118177, Val Acc: 0.752577\n",
      "Epoch 14042 - Train Loss: 0.096802, Train Acc: 0.851282 | Val Loss: 0.118174, Val Acc: 0.752577\n",
      "Epoch 14043 - Train Loss: 0.096797, Train Acc: 0.851282 | Val Loss: 0.118171, Val Acc: 0.752577\n",
      "Epoch 14044 - Train Loss: 0.096793, Train Acc: 0.851282 | Val Loss: 0.118167, Val Acc: 0.752577\n",
      "Epoch 14045 - Train Loss: 0.096789, Train Acc: 0.851282 | Val Loss: 0.118164, Val Acc: 0.752577\n",
      "Epoch 14046 - Train Loss: 0.096784, Train Acc: 0.851282 | Val Loss: 0.118161, Val Acc: 0.752577\n",
      "Epoch 14047 - Train Loss: 0.096780, Train Acc: 0.851282 | Val Loss: 0.118158, Val Acc: 0.752577\n",
      "Epoch 14048 - Train Loss: 0.096776, Train Acc: 0.851282 | Val Loss: 0.118155, Val Acc: 0.752577\n",
      "Epoch 14049 - Train Loss: 0.096772, Train Acc: 0.851282 | Val Loss: 0.118152, Val Acc: 0.752577\n",
      "Epoch 14050 - Train Loss: 0.096767, Train Acc: 0.851282 | Val Loss: 0.118149, Val Acc: 0.752577\n",
      "Epoch 14051 - Train Loss: 0.096763, Train Acc: 0.851282 | Val Loss: 0.118146, Val Acc: 0.752577\n",
      "Epoch 14052 - Train Loss: 0.096759, Train Acc: 0.851282 | Val Loss: 0.118143, Val Acc: 0.752577\n",
      "Epoch 14053 - Train Loss: 0.096754, Train Acc: 0.851282 | Val Loss: 0.118140, Val Acc: 0.752577\n",
      "Epoch 14054 - Train Loss: 0.096750, Train Acc: 0.851282 | Val Loss: 0.118137, Val Acc: 0.752577\n",
      "Epoch 14055 - Train Loss: 0.096746, Train Acc: 0.851282 | Val Loss: 0.118134, Val Acc: 0.752577\n",
      "Epoch 14056 - Train Loss: 0.096741, Train Acc: 0.851282 | Val Loss: 0.118131, Val Acc: 0.752577\n",
      "Epoch 14057 - Train Loss: 0.096737, Train Acc: 0.851282 | Val Loss: 0.118128, Val Acc: 0.752577\n",
      "Epoch 14058 - Train Loss: 0.096733, Train Acc: 0.851282 | Val Loss: 0.118125, Val Acc: 0.752577\n",
      "Epoch 14059 - Train Loss: 0.096729, Train Acc: 0.851282 | Val Loss: 0.118122, Val Acc: 0.752577\n",
      "Epoch 14060 - Train Loss: 0.096724, Train Acc: 0.851282 | Val Loss: 0.118119, Val Acc: 0.752577\n",
      "Epoch 14061 - Train Loss: 0.096720, Train Acc: 0.851282 | Val Loss: 0.118116, Val Acc: 0.752577\n",
      "Epoch 14062 - Train Loss: 0.096716, Train Acc: 0.851282 | Val Loss: 0.118113, Val Acc: 0.752577\n",
      "Epoch 14063 - Train Loss: 0.096711, Train Acc: 0.851282 | Val Loss: 0.118110, Val Acc: 0.752577\n",
      "Epoch 14064 - Train Loss: 0.096707, Train Acc: 0.851282 | Val Loss: 0.118107, Val Acc: 0.752577\n",
      "Epoch 14065 - Train Loss: 0.096703, Train Acc: 0.851282 | Val Loss: 0.118104, Val Acc: 0.752577\n",
      "Epoch 14066 - Train Loss: 0.096699, Train Acc: 0.851282 | Val Loss: 0.118101, Val Acc: 0.752577\n",
      "Epoch 14067 - Train Loss: 0.096694, Train Acc: 0.851282 | Val Loss: 0.118098, Val Acc: 0.752577\n",
      "Epoch 14068 - Train Loss: 0.096690, Train Acc: 0.851282 | Val Loss: 0.118095, Val Acc: 0.752577\n",
      "Epoch 14069 - Train Loss: 0.096686, Train Acc: 0.851282 | Val Loss: 0.118092, Val Acc: 0.752577\n",
      "Epoch 14070 - Train Loss: 0.096681, Train Acc: 0.851282 | Val Loss: 0.118089, Val Acc: 0.752577\n",
      "Epoch 14071 - Train Loss: 0.096677, Train Acc: 0.851282 | Val Loss: 0.118086, Val Acc: 0.752577\n",
      "Epoch 14072 - Train Loss: 0.096673, Train Acc: 0.851282 | Val Loss: 0.118083, Val Acc: 0.752577\n",
      "Epoch 14073 - Train Loss: 0.096669, Train Acc: 0.851282 | Val Loss: 0.118080, Val Acc: 0.752577\n",
      "Epoch 14074 - Train Loss: 0.096664, Train Acc: 0.851282 | Val Loss: 0.118077, Val Acc: 0.752577\n",
      "Epoch 14075 - Train Loss: 0.096660, Train Acc: 0.851282 | Val Loss: 0.118074, Val Acc: 0.752577\n",
      "Epoch 14076 - Train Loss: 0.096656, Train Acc: 0.851282 | Val Loss: 0.118071, Val Acc: 0.752577\n",
      "Epoch 14077 - Train Loss: 0.096651, Train Acc: 0.851282 | Val Loss: 0.118068, Val Acc: 0.752577\n",
      "Epoch 14078 - Train Loss: 0.096647, Train Acc: 0.851282 | Val Loss: 0.118065, Val Acc: 0.752577\n",
      "Epoch 14079 - Train Loss: 0.096643, Train Acc: 0.851282 | Val Loss: 0.118062, Val Acc: 0.752577\n",
      "Epoch 14080 - Train Loss: 0.096639, Train Acc: 0.851282 | Val Loss: 0.118059, Val Acc: 0.752577\n",
      "Epoch 14081 - Train Loss: 0.096634, Train Acc: 0.851282 | Val Loss: 0.118056, Val Acc: 0.752577\n",
      "Epoch 14082 - Train Loss: 0.096630, Train Acc: 0.851282 | Val Loss: 0.118053, Val Acc: 0.752577\n",
      "Epoch 14083 - Train Loss: 0.096626, Train Acc: 0.851282 | Val Loss: 0.118050, Val Acc: 0.752577\n",
      "Epoch 14084 - Train Loss: 0.096622, Train Acc: 0.851282 | Val Loss: 0.118047, Val Acc: 0.752577\n",
      "Epoch 14085 - Train Loss: 0.096617, Train Acc: 0.851282 | Val Loss: 0.118044, Val Acc: 0.752577\n",
      "Epoch 14086 - Train Loss: 0.096613, Train Acc: 0.851282 | Val Loss: 0.118041, Val Acc: 0.752577\n",
      "Epoch 14087 - Train Loss: 0.096609, Train Acc: 0.851282 | Val Loss: 0.118038, Val Acc: 0.752577\n",
      "Epoch 14088 - Train Loss: 0.096604, Train Acc: 0.851282 | Val Loss: 0.118035, Val Acc: 0.752577\n",
      "Epoch 14089 - Train Loss: 0.096600, Train Acc: 0.851282 | Val Loss: 0.118032, Val Acc: 0.752577\n",
      "Epoch 14090 - Train Loss: 0.096596, Train Acc: 0.851282 | Val Loss: 0.118029, Val Acc: 0.752577\n",
      "Epoch 14091 - Train Loss: 0.096592, Train Acc: 0.851282 | Val Loss: 0.118026, Val Acc: 0.752577\n",
      "Epoch 14092 - Train Loss: 0.096587, Train Acc: 0.851282 | Val Loss: 0.118023, Val Acc: 0.752577\n",
      "Epoch 14093 - Train Loss: 0.096583, Train Acc: 0.851282 | Val Loss: 0.118020, Val Acc: 0.752577\n",
      "Epoch 14094 - Train Loss: 0.096579, Train Acc: 0.851282 | Val Loss: 0.118017, Val Acc: 0.752577\n",
      "Epoch 14095 - Train Loss: 0.096575, Train Acc: 0.851282 | Val Loss: 0.118014, Val Acc: 0.752577\n",
      "Epoch 14096 - Train Loss: 0.096570, Train Acc: 0.851282 | Val Loss: 0.118011, Val Acc: 0.752577\n",
      "Epoch 14097 - Train Loss: 0.096566, Train Acc: 0.851282 | Val Loss: 0.118008, Val Acc: 0.752577\n",
      "Epoch 14098 - Train Loss: 0.096562, Train Acc: 0.852564 | Val Loss: 0.118005, Val Acc: 0.752577\n",
      "Epoch 14099 - Train Loss: 0.096557, Train Acc: 0.852564 | Val Loss: 0.118002, Val Acc: 0.752577\n",
      "Epoch 14100 - Train Loss: 0.096553, Train Acc: 0.852564 | Val Loss: 0.117999, Val Acc: 0.752577\n",
      "Epoch 14101 - Train Loss: 0.096549, Train Acc: 0.852564 | Val Loss: 0.117996, Val Acc: 0.752577\n",
      "Epoch 14102 - Train Loss: 0.096545, Train Acc: 0.852564 | Val Loss: 0.117993, Val Acc: 0.752577\n",
      "Epoch 14103 - Train Loss: 0.096540, Train Acc: 0.852564 | Val Loss: 0.117990, Val Acc: 0.752577\n",
      "Epoch 14104 - Train Loss: 0.096536, Train Acc: 0.852564 | Val Loss: 0.117987, Val Acc: 0.752577\n",
      "Epoch 14105 - Train Loss: 0.096532, Train Acc: 0.852564 | Val Loss: 0.117984, Val Acc: 0.752577\n",
      "Epoch 14106 - Train Loss: 0.096528, Train Acc: 0.852564 | Val Loss: 0.117981, Val Acc: 0.752577\n",
      "Epoch 14107 - Train Loss: 0.096523, Train Acc: 0.852564 | Val Loss: 0.117978, Val Acc: 0.752577\n",
      "Epoch 14108 - Train Loss: 0.096519, Train Acc: 0.852564 | Val Loss: 0.117975, Val Acc: 0.752577\n",
      "Epoch 14109 - Train Loss: 0.096515, Train Acc: 0.852564 | Val Loss: 0.117972, Val Acc: 0.752577\n",
      "Epoch 14110 - Train Loss: 0.096511, Train Acc: 0.852564 | Val Loss: 0.117969, Val Acc: 0.752577\n",
      "Epoch 14111 - Train Loss: 0.096506, Train Acc: 0.852564 | Val Loss: 0.117966, Val Acc: 0.752577\n",
      "Epoch 14112 - Train Loss: 0.096502, Train Acc: 0.852564 | Val Loss: 0.117963, Val Acc: 0.752577\n",
      "Epoch 14113 - Train Loss: 0.096498, Train Acc: 0.852564 | Val Loss: 0.117960, Val Acc: 0.752577\n",
      "Epoch 14114 - Train Loss: 0.096494, Train Acc: 0.852564 | Val Loss: 0.117957, Val Acc: 0.752577\n",
      "Epoch 14115 - Train Loss: 0.096489, Train Acc: 0.852564 | Val Loss: 0.117954, Val Acc: 0.752577\n",
      "Epoch 14116 - Train Loss: 0.096485, Train Acc: 0.852564 | Val Loss: 0.117951, Val Acc: 0.752577\n",
      "Epoch 14117 - Train Loss: 0.096481, Train Acc: 0.852564 | Val Loss: 0.117948, Val Acc: 0.752577\n",
      "Epoch 14118 - Train Loss: 0.096476, Train Acc: 0.852564 | Val Loss: 0.117945, Val Acc: 0.752577\n",
      "Epoch 14119 - Train Loss: 0.096472, Train Acc: 0.852564 | Val Loss: 0.117942, Val Acc: 0.752577\n",
      "Epoch 14120 - Train Loss: 0.096468, Train Acc: 0.852564 | Val Loss: 0.117939, Val Acc: 0.752577\n",
      "Epoch 14121 - Train Loss: 0.096464, Train Acc: 0.852564 | Val Loss: 0.117936, Val Acc: 0.752577\n",
      "Epoch 14122 - Train Loss: 0.096459, Train Acc: 0.852564 | Val Loss: 0.117933, Val Acc: 0.752577\n",
      "Epoch 14123 - Train Loss: 0.096455, Train Acc: 0.852564 | Val Loss: 0.117930, Val Acc: 0.752577\n",
      "Epoch 14124 - Train Loss: 0.096451, Train Acc: 0.852564 | Val Loss: 0.117927, Val Acc: 0.752577\n",
      "Epoch 14125 - Train Loss: 0.096447, Train Acc: 0.852564 | Val Loss: 0.117924, Val Acc: 0.752577\n",
      "Epoch 14126 - Train Loss: 0.096442, Train Acc: 0.852564 | Val Loss: 0.117921, Val Acc: 0.752577\n",
      "Epoch 14127 - Train Loss: 0.096438, Train Acc: 0.853846 | Val Loss: 0.117918, Val Acc: 0.752577\n",
      "Epoch 14128 - Train Loss: 0.096434, Train Acc: 0.853846 | Val Loss: 0.117915, Val Acc: 0.752577\n",
      "Epoch 14129 - Train Loss: 0.096430, Train Acc: 0.853846 | Val Loss: 0.117912, Val Acc: 0.752577\n",
      "Epoch 14130 - Train Loss: 0.096425, Train Acc: 0.853846 | Val Loss: 0.117909, Val Acc: 0.752577\n",
      "Epoch 14131 - Train Loss: 0.096421, Train Acc: 0.853846 | Val Loss: 0.117906, Val Acc: 0.752577\n",
      "Epoch 14132 - Train Loss: 0.096417, Train Acc: 0.853846 | Val Loss: 0.117903, Val Acc: 0.752577\n",
      "Epoch 14133 - Train Loss: 0.096413, Train Acc: 0.853846 | Val Loss: 0.117900, Val Acc: 0.752577\n",
      "Epoch 14134 - Train Loss: 0.096408, Train Acc: 0.853846 | Val Loss: 0.117897, Val Acc: 0.752577\n",
      "Epoch 14135 - Train Loss: 0.096404, Train Acc: 0.853846 | Val Loss: 0.117894, Val Acc: 0.752577\n",
      "Epoch 14136 - Train Loss: 0.096400, Train Acc: 0.853846 | Val Loss: 0.117891, Val Acc: 0.752577\n",
      "Epoch 14137 - Train Loss: 0.096396, Train Acc: 0.853846 | Val Loss: 0.117888, Val Acc: 0.752577\n",
      "Epoch 14138 - Train Loss: 0.096391, Train Acc: 0.853846 | Val Loss: 0.117885, Val Acc: 0.752577\n",
      "Epoch 14139 - Train Loss: 0.096387, Train Acc: 0.853846 | Val Loss: 0.117882, Val Acc: 0.752577\n",
      "Epoch 14140 - Train Loss: 0.096383, Train Acc: 0.853846 | Val Loss: 0.117879, Val Acc: 0.752577\n",
      "Epoch 14141 - Train Loss: 0.096379, Train Acc: 0.853846 | Val Loss: 0.117876, Val Acc: 0.752577\n",
      "Epoch 14142 - Train Loss: 0.096375, Train Acc: 0.853846 | Val Loss: 0.117873, Val Acc: 0.752577\n",
      "Epoch 14143 - Train Loss: 0.096370, Train Acc: 0.853846 | Val Loss: 0.117870, Val Acc: 0.752577\n",
      "Epoch 14144 - Train Loss: 0.096366, Train Acc: 0.853846 | Val Loss: 0.117867, Val Acc: 0.752577\n",
      "Epoch 14145 - Train Loss: 0.096362, Train Acc: 0.853846 | Val Loss: 0.117864, Val Acc: 0.752577\n",
      "Epoch 14146 - Train Loss: 0.096358, Train Acc: 0.853846 | Val Loss: 0.117861, Val Acc: 0.752577\n",
      "Epoch 14147 - Train Loss: 0.096353, Train Acc: 0.853846 | Val Loss: 0.117858, Val Acc: 0.752577\n",
      "Epoch 14148 - Train Loss: 0.096349, Train Acc: 0.853846 | Val Loss: 0.117855, Val Acc: 0.752577\n",
      "Epoch 14149 - Train Loss: 0.096345, Train Acc: 0.853846 | Val Loss: 0.117852, Val Acc: 0.752577\n",
      "Epoch 14150 - Train Loss: 0.096341, Train Acc: 0.853846 | Val Loss: 0.117849, Val Acc: 0.752577\n",
      "Epoch 14151 - Train Loss: 0.096336, Train Acc: 0.853846 | Val Loss: 0.117847, Val Acc: 0.752577\n",
      "Epoch 14152 - Train Loss: 0.096332, Train Acc: 0.853846 | Val Loss: 0.117844, Val Acc: 0.752577\n",
      "Epoch 14153 - Train Loss: 0.096328, Train Acc: 0.853846 | Val Loss: 0.117841, Val Acc: 0.752577\n",
      "Epoch 14154 - Train Loss: 0.096324, Train Acc: 0.853846 | Val Loss: 0.117838, Val Acc: 0.752577\n",
      "Epoch 14155 - Train Loss: 0.096319, Train Acc: 0.853846 | Val Loss: 0.117835, Val Acc: 0.752577\n",
      "Epoch 14156 - Train Loss: 0.096315, Train Acc: 0.853846 | Val Loss: 0.117832, Val Acc: 0.752577\n",
      "Epoch 14157 - Train Loss: 0.096311, Train Acc: 0.853846 | Val Loss: 0.117829, Val Acc: 0.752577\n",
      "Epoch 14158 - Train Loss: 0.096307, Train Acc: 0.853846 | Val Loss: 0.117826, Val Acc: 0.752577\n",
      "Epoch 14159 - Train Loss: 0.096302, Train Acc: 0.853846 | Val Loss: 0.117823, Val Acc: 0.752577\n",
      "Epoch 14160 - Train Loss: 0.096298, Train Acc: 0.853846 | Val Loss: 0.117820, Val Acc: 0.752577\n",
      "Epoch 14161 - Train Loss: 0.096294, Train Acc: 0.853846 | Val Loss: 0.117817, Val Acc: 0.752577\n",
      "Epoch 14162 - Train Loss: 0.096290, Train Acc: 0.853846 | Val Loss: 0.117814, Val Acc: 0.752577\n",
      "Epoch 14163 - Train Loss: 0.096286, Train Acc: 0.853846 | Val Loss: 0.117811, Val Acc: 0.752577\n",
      "Epoch 14164 - Train Loss: 0.096281, Train Acc: 0.853846 | Val Loss: 0.117808, Val Acc: 0.752577\n",
      "Epoch 14165 - Train Loss: 0.096277, Train Acc: 0.853846 | Val Loss: 0.117805, Val Acc: 0.752577\n",
      "Epoch 14166 - Train Loss: 0.096273, Train Acc: 0.853846 | Val Loss: 0.117802, Val Acc: 0.752577\n",
      "Epoch 14167 - Train Loss: 0.096269, Train Acc: 0.853846 | Val Loss: 0.117799, Val Acc: 0.752577\n",
      "Epoch 14168 - Train Loss: 0.096264, Train Acc: 0.853846 | Val Loss: 0.117796, Val Acc: 0.752577\n",
      "Epoch 14169 - Train Loss: 0.096260, Train Acc: 0.853846 | Val Loss: 0.117793, Val Acc: 0.752577\n",
      "Epoch 14170 - Train Loss: 0.096256, Train Acc: 0.853846 | Val Loss: 0.117790, Val Acc: 0.752577\n",
      "Epoch 14171 - Train Loss: 0.096252, Train Acc: 0.853846 | Val Loss: 0.117787, Val Acc: 0.752577\n",
      "Epoch 14172 - Train Loss: 0.096247, Train Acc: 0.853846 | Val Loss: 0.117784, Val Acc: 0.752577\n",
      "Epoch 14173 - Train Loss: 0.096243, Train Acc: 0.853846 | Val Loss: 0.117781, Val Acc: 0.752577\n",
      "Epoch 14174 - Train Loss: 0.096239, Train Acc: 0.853846 | Val Loss: 0.117778, Val Acc: 0.752577\n",
      "Epoch 14175 - Train Loss: 0.096235, Train Acc: 0.853846 | Val Loss: 0.117775, Val Acc: 0.752577\n",
      "Epoch 14176 - Train Loss: 0.096231, Train Acc: 0.853846 | Val Loss: 0.117772, Val Acc: 0.752577\n",
      "Epoch 14177 - Train Loss: 0.096226, Train Acc: 0.853846 | Val Loss: 0.117769, Val Acc: 0.752577\n",
      "Epoch 14178 - Train Loss: 0.096222, Train Acc: 0.853846 | Val Loss: 0.117767, Val Acc: 0.752577\n",
      "Epoch 14179 - Train Loss: 0.096218, Train Acc: 0.853846 | Val Loss: 0.117764, Val Acc: 0.752577\n",
      "Epoch 14180 - Train Loss: 0.096214, Train Acc: 0.853846 | Val Loss: 0.117761, Val Acc: 0.752577\n",
      "Epoch 14181 - Train Loss: 0.096209, Train Acc: 0.853846 | Val Loss: 0.117758, Val Acc: 0.752577\n",
      "Epoch 14182 - Train Loss: 0.096205, Train Acc: 0.853846 | Val Loss: 0.117755, Val Acc: 0.752577\n",
      "Epoch 14183 - Train Loss: 0.096201, Train Acc: 0.853846 | Val Loss: 0.117752, Val Acc: 0.752577\n",
      "Epoch 14184 - Train Loss: 0.096197, Train Acc: 0.853846 | Val Loss: 0.117749, Val Acc: 0.752577\n",
      "Epoch 14185 - Train Loss: 0.096193, Train Acc: 0.853846 | Val Loss: 0.117746, Val Acc: 0.752577\n",
      "Epoch 14186 - Train Loss: 0.096188, Train Acc: 0.853846 | Val Loss: 0.117743, Val Acc: 0.752577\n",
      "Epoch 14187 - Train Loss: 0.096184, Train Acc: 0.853846 | Val Loss: 0.117740, Val Acc: 0.752577\n",
      "Epoch 14188 - Train Loss: 0.096180, Train Acc: 0.853846 | Val Loss: 0.117737, Val Acc: 0.752577\n",
      "Epoch 14189 - Train Loss: 0.096176, Train Acc: 0.853846 | Val Loss: 0.117734, Val Acc: 0.752577\n",
      "Epoch 14190 - Train Loss: 0.096172, Train Acc: 0.853846 | Val Loss: 0.117731, Val Acc: 0.752577\n",
      "Epoch 14191 - Train Loss: 0.096167, Train Acc: 0.853846 | Val Loss: 0.117728, Val Acc: 0.752577\n",
      "Epoch 14192 - Train Loss: 0.096163, Train Acc: 0.853846 | Val Loss: 0.117725, Val Acc: 0.752577\n",
      "Epoch 14193 - Train Loss: 0.096159, Train Acc: 0.853846 | Val Loss: 0.117722, Val Acc: 0.752577\n",
      "Epoch 14194 - Train Loss: 0.096155, Train Acc: 0.853846 | Val Loss: 0.117719, Val Acc: 0.752577\n",
      "Epoch 14195 - Train Loss: 0.096150, Train Acc: 0.853846 | Val Loss: 0.117716, Val Acc: 0.752577\n",
      "Epoch 14196 - Train Loss: 0.096146, Train Acc: 0.853846 | Val Loss: 0.117713, Val Acc: 0.752577\n",
      "Epoch 14197 - Train Loss: 0.096142, Train Acc: 0.853846 | Val Loss: 0.117711, Val Acc: 0.752577\n",
      "Epoch 14198 - Train Loss: 0.096138, Train Acc: 0.853846 | Val Loss: 0.117708, Val Acc: 0.752577\n",
      "Epoch 14199 - Train Loss: 0.096134, Train Acc: 0.853846 | Val Loss: 0.117705, Val Acc: 0.752577\n",
      "Epoch 14200 - Train Loss: 0.096129, Train Acc: 0.853846 | Val Loss: 0.117702, Val Acc: 0.752577\n",
      "Epoch 14201 - Train Loss: 0.096125, Train Acc: 0.853846 | Val Loss: 0.117699, Val Acc: 0.752577\n",
      "Epoch 14202 - Train Loss: 0.096121, Train Acc: 0.853846 | Val Loss: 0.117696, Val Acc: 0.752577\n",
      "Epoch 14203 - Train Loss: 0.096117, Train Acc: 0.853846 | Val Loss: 0.117693, Val Acc: 0.752577\n",
      "Epoch 14204 - Train Loss: 0.096113, Train Acc: 0.853846 | Val Loss: 0.117690, Val Acc: 0.752577\n",
      "Epoch 14205 - Train Loss: 0.096108, Train Acc: 0.853846 | Val Loss: 0.117687, Val Acc: 0.752577\n",
      "Epoch 14206 - Train Loss: 0.096104, Train Acc: 0.853846 | Val Loss: 0.117684, Val Acc: 0.752577\n",
      "Epoch 14207 - Train Loss: 0.096100, Train Acc: 0.853846 | Val Loss: 0.117681, Val Acc: 0.752577\n",
      "Epoch 14208 - Train Loss: 0.096096, Train Acc: 0.853846 | Val Loss: 0.117678, Val Acc: 0.752577\n",
      "Epoch 14209 - Train Loss: 0.096092, Train Acc: 0.853846 | Val Loss: 0.117675, Val Acc: 0.752577\n",
      "Epoch 14210 - Train Loss: 0.096087, Train Acc: 0.853846 | Val Loss: 0.117672, Val Acc: 0.752577\n",
      "Epoch 14211 - Train Loss: 0.096083, Train Acc: 0.853846 | Val Loss: 0.117669, Val Acc: 0.752577\n",
      "Epoch 14212 - Train Loss: 0.096079, Train Acc: 0.853846 | Val Loss: 0.117667, Val Acc: 0.752577\n",
      "Epoch 14213 - Train Loss: 0.096075, Train Acc: 0.853846 | Val Loss: 0.117664, Val Acc: 0.752577\n",
      "Epoch 14214 - Train Loss: 0.096071, Train Acc: 0.853846 | Val Loss: 0.117661, Val Acc: 0.752577\n",
      "Epoch 14215 - Train Loss: 0.096066, Train Acc: 0.853846 | Val Loss: 0.117658, Val Acc: 0.752577\n",
      "Epoch 14216 - Train Loss: 0.096062, Train Acc: 0.853846 | Val Loss: 0.117655, Val Acc: 0.752577\n",
      "Epoch 14217 - Train Loss: 0.096058, Train Acc: 0.853846 | Val Loss: 0.117652, Val Acc: 0.752577\n",
      "Epoch 14218 - Train Loss: 0.096054, Train Acc: 0.853846 | Val Loss: 0.117649, Val Acc: 0.752577\n",
      "Epoch 14219 - Train Loss: 0.096050, Train Acc: 0.853846 | Val Loss: 0.117646, Val Acc: 0.752577\n",
      "Epoch 14220 - Train Loss: 0.096045, Train Acc: 0.853846 | Val Loss: 0.117643, Val Acc: 0.752577\n",
      "Epoch 14221 - Train Loss: 0.096041, Train Acc: 0.853846 | Val Loss: 0.117640, Val Acc: 0.752577\n",
      "Epoch 14222 - Train Loss: 0.096037, Train Acc: 0.853846 | Val Loss: 0.117637, Val Acc: 0.752577\n",
      "Epoch 14223 - Train Loss: 0.096033, Train Acc: 0.853846 | Val Loss: 0.117634, Val Acc: 0.752577\n",
      "Epoch 14224 - Train Loss: 0.096029, Train Acc: 0.853846 | Val Loss: 0.117631, Val Acc: 0.752577\n",
      "Epoch 14225 - Train Loss: 0.096024, Train Acc: 0.853846 | Val Loss: 0.117628, Val Acc: 0.752577\n",
      "Epoch 14226 - Train Loss: 0.096020, Train Acc: 0.853846 | Val Loss: 0.117626, Val Acc: 0.752577\n",
      "Epoch 14227 - Train Loss: 0.096016, Train Acc: 0.853846 | Val Loss: 0.117623, Val Acc: 0.752577\n",
      "Epoch 14228 - Train Loss: 0.096012, Train Acc: 0.853846 | Val Loss: 0.117620, Val Acc: 0.752577\n",
      "Epoch 14229 - Train Loss: 0.096008, Train Acc: 0.853846 | Val Loss: 0.117617, Val Acc: 0.752577\n",
      "Epoch 14230 - Train Loss: 0.096003, Train Acc: 0.853846 | Val Loss: 0.117614, Val Acc: 0.752577\n",
      "Epoch 14231 - Train Loss: 0.095999, Train Acc: 0.853846 | Val Loss: 0.117611, Val Acc: 0.752577\n",
      "Epoch 14232 - Train Loss: 0.095995, Train Acc: 0.853846 | Val Loss: 0.117608, Val Acc: 0.752577\n",
      "Epoch 14233 - Train Loss: 0.095991, Train Acc: 0.853846 | Val Loss: 0.117605, Val Acc: 0.752577\n",
      "Epoch 14234 - Train Loss: 0.095987, Train Acc: 0.853846 | Val Loss: 0.117602, Val Acc: 0.752577\n",
      "Epoch 14235 - Train Loss: 0.095982, Train Acc: 0.853846 | Val Loss: 0.117599, Val Acc: 0.752577\n",
      "Epoch 14236 - Train Loss: 0.095978, Train Acc: 0.853846 | Val Loss: 0.117596, Val Acc: 0.752577\n",
      "Epoch 14237 - Train Loss: 0.095974, Train Acc: 0.853846 | Val Loss: 0.117593, Val Acc: 0.752577\n",
      "Epoch 14238 - Train Loss: 0.095970, Train Acc: 0.853846 | Val Loss: 0.117591, Val Acc: 0.752577\n",
      "Epoch 14239 - Train Loss: 0.095966, Train Acc: 0.853846 | Val Loss: 0.117588, Val Acc: 0.752577\n",
      "Epoch 14240 - Train Loss: 0.095961, Train Acc: 0.853846 | Val Loss: 0.117585, Val Acc: 0.752577\n",
      "Epoch 14241 - Train Loss: 0.095957, Train Acc: 0.853846 | Val Loss: 0.117582, Val Acc: 0.752577\n",
      "Epoch 14242 - Train Loss: 0.095953, Train Acc: 0.853846 | Val Loss: 0.117579, Val Acc: 0.752577\n",
      "Epoch 14243 - Train Loss: 0.095949, Train Acc: 0.853846 | Val Loss: 0.117576, Val Acc: 0.752577\n",
      "Epoch 14244 - Train Loss: 0.095945, Train Acc: 0.853846 | Val Loss: 0.117573, Val Acc: 0.752577\n",
      "Epoch 14245 - Train Loss: 0.095941, Train Acc: 0.853846 | Val Loss: 0.117570, Val Acc: 0.752577\n",
      "Epoch 14246 - Train Loss: 0.095936, Train Acc: 0.853846 | Val Loss: 0.117567, Val Acc: 0.752577\n",
      "Epoch 14247 - Train Loss: 0.095932, Train Acc: 0.853846 | Val Loss: 0.117564, Val Acc: 0.752577\n",
      "Epoch 14248 - Train Loss: 0.095928, Train Acc: 0.853846 | Val Loss: 0.117561, Val Acc: 0.752577\n",
      "Epoch 14249 - Train Loss: 0.095924, Train Acc: 0.853846 | Val Loss: 0.117559, Val Acc: 0.752577\n",
      "Epoch 14250 - Train Loss: 0.095920, Train Acc: 0.853846 | Val Loss: 0.117556, Val Acc: 0.752577\n",
      "Epoch 14251 - Train Loss: 0.095915, Train Acc: 0.853846 | Val Loss: 0.117553, Val Acc: 0.752577\n",
      "Epoch 14252 - Train Loss: 0.095911, Train Acc: 0.853846 | Val Loss: 0.117550, Val Acc: 0.752577\n",
      "Epoch 14253 - Train Loss: 0.095907, Train Acc: 0.853846 | Val Loss: 0.117547, Val Acc: 0.752577\n",
      "Epoch 14254 - Train Loss: 0.095903, Train Acc: 0.853846 | Val Loss: 0.117544, Val Acc: 0.752577\n",
      "Epoch 14255 - Train Loss: 0.095899, Train Acc: 0.853846 | Val Loss: 0.117541, Val Acc: 0.752577\n",
      "Epoch 14256 - Train Loss: 0.095895, Train Acc: 0.853846 | Val Loss: 0.117538, Val Acc: 0.752577\n",
      "Epoch 14257 - Train Loss: 0.095890, Train Acc: 0.853846 | Val Loss: 0.117535, Val Acc: 0.752577\n",
      "Epoch 14258 - Train Loss: 0.095886, Train Acc: 0.853846 | Val Loss: 0.117532, Val Acc: 0.752577\n",
      "Epoch 14259 - Train Loss: 0.095882, Train Acc: 0.853846 | Val Loss: 0.117529, Val Acc: 0.752577\n",
      "Epoch 14260 - Train Loss: 0.095878, Train Acc: 0.853846 | Val Loss: 0.117527, Val Acc: 0.752577\n",
      "Epoch 14261 - Train Loss: 0.095874, Train Acc: 0.853846 | Val Loss: 0.117524, Val Acc: 0.752577\n",
      "Epoch 14262 - Train Loss: 0.095869, Train Acc: 0.853846 | Val Loss: 0.117521, Val Acc: 0.752577\n",
      "Epoch 14263 - Train Loss: 0.095865, Train Acc: 0.853846 | Val Loss: 0.117518, Val Acc: 0.752577\n",
      "Epoch 14264 - Train Loss: 0.095861, Train Acc: 0.853846 | Val Loss: 0.117515, Val Acc: 0.752577\n",
      "Epoch 14265 - Train Loss: 0.095857, Train Acc: 0.853846 | Val Loss: 0.117512, Val Acc: 0.752577\n",
      "Epoch 14266 - Train Loss: 0.095853, Train Acc: 0.853846 | Val Loss: 0.117509, Val Acc: 0.752577\n",
      "Epoch 14267 - Train Loss: 0.095849, Train Acc: 0.853846 | Val Loss: 0.117506, Val Acc: 0.752577\n",
      "Epoch 14268 - Train Loss: 0.095844, Train Acc: 0.853846 | Val Loss: 0.117503, Val Acc: 0.752577\n",
      "Epoch 14269 - Train Loss: 0.095840, Train Acc: 0.853846 | Val Loss: 0.117500, Val Acc: 0.752577\n",
      "Epoch 14270 - Train Loss: 0.095836, Train Acc: 0.853846 | Val Loss: 0.117498, Val Acc: 0.752577\n",
      "Epoch 14271 - Train Loss: 0.095832, Train Acc: 0.853846 | Val Loss: 0.117495, Val Acc: 0.752577\n",
      "Epoch 14272 - Train Loss: 0.095828, Train Acc: 0.853846 | Val Loss: 0.117492, Val Acc: 0.752577\n",
      "Epoch 14273 - Train Loss: 0.095824, Train Acc: 0.853846 | Val Loss: 0.117489, Val Acc: 0.752577\n",
      "Epoch 14274 - Train Loss: 0.095819, Train Acc: 0.853846 | Val Loss: 0.117486, Val Acc: 0.752577\n",
      "Epoch 14275 - Train Loss: 0.095815, Train Acc: 0.853846 | Val Loss: 0.117483, Val Acc: 0.752577\n",
      "Epoch 14276 - Train Loss: 0.095811, Train Acc: 0.853846 | Val Loss: 0.117480, Val Acc: 0.752577\n",
      "Epoch 14277 - Train Loss: 0.095807, Train Acc: 0.853846 | Val Loss: 0.117477, Val Acc: 0.752577\n",
      "Epoch 14278 - Train Loss: 0.095803, Train Acc: 0.853846 | Val Loss: 0.117474, Val Acc: 0.752577\n",
      "Epoch 14279 - Train Loss: 0.095799, Train Acc: 0.853846 | Val Loss: 0.117472, Val Acc: 0.752577\n",
      "Epoch 14280 - Train Loss: 0.095794, Train Acc: 0.853846 | Val Loss: 0.117469, Val Acc: 0.752577\n",
      "Epoch 14281 - Train Loss: 0.095790, Train Acc: 0.853846 | Val Loss: 0.117466, Val Acc: 0.752577\n",
      "Epoch 14282 - Train Loss: 0.095786, Train Acc: 0.853846 | Val Loss: 0.117463, Val Acc: 0.752577\n",
      "Epoch 14283 - Train Loss: 0.095782, Train Acc: 0.853846 | Val Loss: 0.117460, Val Acc: 0.752577\n",
      "Epoch 14284 - Train Loss: 0.095778, Train Acc: 0.853846 | Val Loss: 0.117457, Val Acc: 0.752577\n",
      "Epoch 14285 - Train Loss: 0.095774, Train Acc: 0.853846 | Val Loss: 0.117454, Val Acc: 0.752577\n",
      "Epoch 14286 - Train Loss: 0.095769, Train Acc: 0.853846 | Val Loss: 0.117451, Val Acc: 0.752577\n",
      "Epoch 14287 - Train Loss: 0.095765, Train Acc: 0.853846 | Val Loss: 0.117448, Val Acc: 0.752577\n",
      "Epoch 14288 - Train Loss: 0.095761, Train Acc: 0.853846 | Val Loss: 0.117446, Val Acc: 0.752577\n",
      "Epoch 14289 - Train Loss: 0.095757, Train Acc: 0.853846 | Val Loss: 0.117443, Val Acc: 0.752577\n",
      "Epoch 14290 - Train Loss: 0.095753, Train Acc: 0.853846 | Val Loss: 0.117440, Val Acc: 0.752577\n",
      "Epoch 14291 - Train Loss: 0.095749, Train Acc: 0.853846 | Val Loss: 0.117437, Val Acc: 0.752577\n",
      "Epoch 14292 - Train Loss: 0.095744, Train Acc: 0.855128 | Val Loss: 0.117434, Val Acc: 0.752577\n",
      "Epoch 14293 - Train Loss: 0.095740, Train Acc: 0.855128 | Val Loss: 0.117431, Val Acc: 0.752577\n",
      "Epoch 14294 - Train Loss: 0.095736, Train Acc: 0.855128 | Val Loss: 0.117428, Val Acc: 0.752577\n",
      "Epoch 14295 - Train Loss: 0.095732, Train Acc: 0.855128 | Val Loss: 0.117425, Val Acc: 0.752577\n",
      "Epoch 14296 - Train Loss: 0.095728, Train Acc: 0.855128 | Val Loss: 0.117422, Val Acc: 0.752577\n",
      "Epoch 14297 - Train Loss: 0.095724, Train Acc: 0.855128 | Val Loss: 0.117420, Val Acc: 0.752577\n",
      "Epoch 14298 - Train Loss: 0.095720, Train Acc: 0.855128 | Val Loss: 0.117417, Val Acc: 0.752577\n",
      "Epoch 14299 - Train Loss: 0.095715, Train Acc: 0.855128 | Val Loss: 0.117414, Val Acc: 0.752577\n",
      "Epoch 14300 - Train Loss: 0.095711, Train Acc: 0.855128 | Val Loss: 0.117411, Val Acc: 0.752577\n",
      "Epoch 14301 - Train Loss: 0.095707, Train Acc: 0.855128 | Val Loss: 0.117408, Val Acc: 0.752577\n",
      "Epoch 14302 - Train Loss: 0.095703, Train Acc: 0.855128 | Val Loss: 0.117405, Val Acc: 0.752577\n",
      "Epoch 14303 - Train Loss: 0.095699, Train Acc: 0.855128 | Val Loss: 0.117402, Val Acc: 0.752577\n",
      "Epoch 14304 - Train Loss: 0.095695, Train Acc: 0.855128 | Val Loss: 0.117399, Val Acc: 0.752577\n",
      "Epoch 14305 - Train Loss: 0.095690, Train Acc: 0.855128 | Val Loss: 0.117396, Val Acc: 0.752577\n",
      "Epoch 14306 - Train Loss: 0.095686, Train Acc: 0.855128 | Val Loss: 0.117394, Val Acc: 0.752577\n",
      "Epoch 14307 - Train Loss: 0.095682, Train Acc: 0.855128 | Val Loss: 0.117391, Val Acc: 0.752577\n",
      "Epoch 14308 - Train Loss: 0.095678, Train Acc: 0.855128 | Val Loss: 0.117388, Val Acc: 0.752577\n",
      "Epoch 14309 - Train Loss: 0.095674, Train Acc: 0.855128 | Val Loss: 0.117385, Val Acc: 0.752577\n",
      "Epoch 14310 - Train Loss: 0.095670, Train Acc: 0.855128 | Val Loss: 0.117382, Val Acc: 0.752577\n",
      "Epoch 14311 - Train Loss: 0.095666, Train Acc: 0.855128 | Val Loss: 0.117379, Val Acc: 0.752577\n",
      "Epoch 14312 - Train Loss: 0.095661, Train Acc: 0.855128 | Val Loss: 0.117376, Val Acc: 0.752577\n",
      "Epoch 14313 - Train Loss: 0.095657, Train Acc: 0.855128 | Val Loss: 0.117373, Val Acc: 0.752577\n",
      "Epoch 14314 - Train Loss: 0.095653, Train Acc: 0.855128 | Val Loss: 0.117370, Val Acc: 0.752577\n",
      "Epoch 14315 - Train Loss: 0.095649, Train Acc: 0.855128 | Val Loss: 0.117368, Val Acc: 0.752577\n",
      "Epoch 14316 - Train Loss: 0.095645, Train Acc: 0.855128 | Val Loss: 0.117365, Val Acc: 0.752577\n",
      "Epoch 14317 - Train Loss: 0.095641, Train Acc: 0.855128 | Val Loss: 0.117362, Val Acc: 0.752577\n",
      "Epoch 14318 - Train Loss: 0.095637, Train Acc: 0.855128 | Val Loss: 0.117359, Val Acc: 0.752577\n",
      "Epoch 14319 - Train Loss: 0.095632, Train Acc: 0.855128 | Val Loss: 0.117356, Val Acc: 0.752577\n",
      "Epoch 14320 - Train Loss: 0.095628, Train Acc: 0.855128 | Val Loss: 0.117353, Val Acc: 0.752577\n",
      "Epoch 14321 - Train Loss: 0.095624, Train Acc: 0.855128 | Val Loss: 0.117350, Val Acc: 0.752577\n",
      "Epoch 14322 - Train Loss: 0.095620, Train Acc: 0.855128 | Val Loss: 0.117347, Val Acc: 0.752577\n",
      "Epoch 14323 - Train Loss: 0.095616, Train Acc: 0.855128 | Val Loss: 0.117345, Val Acc: 0.752577\n",
      "Epoch 14324 - Train Loss: 0.095612, Train Acc: 0.855128 | Val Loss: 0.117342, Val Acc: 0.752577\n",
      "Epoch 14325 - Train Loss: 0.095608, Train Acc: 0.855128 | Val Loss: 0.117339, Val Acc: 0.752577\n",
      "Epoch 14326 - Train Loss: 0.095603, Train Acc: 0.855128 | Val Loss: 0.117336, Val Acc: 0.752577\n",
      "Epoch 14327 - Train Loss: 0.095599, Train Acc: 0.855128 | Val Loss: 0.117333, Val Acc: 0.752577\n",
      "Epoch 14328 - Train Loss: 0.095595, Train Acc: 0.855128 | Val Loss: 0.117330, Val Acc: 0.752577\n",
      "Epoch 14329 - Train Loss: 0.095591, Train Acc: 0.855128 | Val Loss: 0.117327, Val Acc: 0.752577\n",
      "Epoch 14330 - Train Loss: 0.095587, Train Acc: 0.855128 | Val Loss: 0.117325, Val Acc: 0.752577\n",
      "Epoch 14331 - Train Loss: 0.095583, Train Acc: 0.855128 | Val Loss: 0.117322, Val Acc: 0.752577\n",
      "Epoch 14332 - Train Loss: 0.095579, Train Acc: 0.855128 | Val Loss: 0.117319, Val Acc: 0.752577\n",
      "Epoch 14333 - Train Loss: 0.095574, Train Acc: 0.855128 | Val Loss: 0.117316, Val Acc: 0.752577\n",
      "Epoch 14334 - Train Loss: 0.095570, Train Acc: 0.855128 | Val Loss: 0.117313, Val Acc: 0.752577\n",
      "Epoch 14335 - Train Loss: 0.095566, Train Acc: 0.855128 | Val Loss: 0.117310, Val Acc: 0.752577\n",
      "Epoch 14336 - Train Loss: 0.095562, Train Acc: 0.855128 | Val Loss: 0.117307, Val Acc: 0.752577\n",
      "Epoch 14337 - Train Loss: 0.095558, Train Acc: 0.855128 | Val Loss: 0.117304, Val Acc: 0.752577\n",
      "Epoch 14338 - Train Loss: 0.095554, Train Acc: 0.855128 | Val Loss: 0.117302, Val Acc: 0.752577\n",
      "Epoch 14339 - Train Loss: 0.095550, Train Acc: 0.855128 | Val Loss: 0.117299, Val Acc: 0.752577\n",
      "Epoch 14340 - Train Loss: 0.095546, Train Acc: 0.855128 | Val Loss: 0.117296, Val Acc: 0.752577\n",
      "Epoch 14341 - Train Loss: 0.095541, Train Acc: 0.855128 | Val Loss: 0.117293, Val Acc: 0.752577\n",
      "Epoch 14342 - Train Loss: 0.095537, Train Acc: 0.855128 | Val Loss: 0.117290, Val Acc: 0.752577\n",
      "Epoch 14343 - Train Loss: 0.095533, Train Acc: 0.855128 | Val Loss: 0.117287, Val Acc: 0.752577\n",
      "Epoch 14344 - Train Loss: 0.095529, Train Acc: 0.855128 | Val Loss: 0.117284, Val Acc: 0.752577\n",
      "Epoch 14345 - Train Loss: 0.095525, Train Acc: 0.855128 | Val Loss: 0.117282, Val Acc: 0.752577\n",
      "Epoch 14346 - Train Loss: 0.095521, Train Acc: 0.855128 | Val Loss: 0.117279, Val Acc: 0.752577\n",
      "Epoch 14347 - Train Loss: 0.095517, Train Acc: 0.855128 | Val Loss: 0.117276, Val Acc: 0.752577\n",
      "Epoch 14348 - Train Loss: 0.095512, Train Acc: 0.855128 | Val Loss: 0.117273, Val Acc: 0.752577\n",
      "Epoch 14349 - Train Loss: 0.095508, Train Acc: 0.855128 | Val Loss: 0.117270, Val Acc: 0.752577\n",
      "Epoch 14350 - Train Loss: 0.095504, Train Acc: 0.855128 | Val Loss: 0.117267, Val Acc: 0.752577\n",
      "Epoch 14351 - Train Loss: 0.095500, Train Acc: 0.855128 | Val Loss: 0.117264, Val Acc: 0.752577\n",
      "Epoch 14352 - Train Loss: 0.095496, Train Acc: 0.855128 | Val Loss: 0.117262, Val Acc: 0.752577\n",
      "Epoch 14353 - Train Loss: 0.095492, Train Acc: 0.855128 | Val Loss: 0.117259, Val Acc: 0.752577\n",
      "Epoch 14354 - Train Loss: 0.095488, Train Acc: 0.855128 | Val Loss: 0.117256, Val Acc: 0.752577\n",
      "Epoch 14355 - Train Loss: 0.095484, Train Acc: 0.855128 | Val Loss: 0.117253, Val Acc: 0.752577\n",
      "Epoch 14356 - Train Loss: 0.095479, Train Acc: 0.855128 | Val Loss: 0.117250, Val Acc: 0.752577\n",
      "Epoch 14357 - Train Loss: 0.095475, Train Acc: 0.855128 | Val Loss: 0.117247, Val Acc: 0.752577\n",
      "Epoch 14358 - Train Loss: 0.095471, Train Acc: 0.855128 | Val Loss: 0.117244, Val Acc: 0.752577\n",
      "Epoch 14359 - Train Loss: 0.095467, Train Acc: 0.855128 | Val Loss: 0.117242, Val Acc: 0.752577\n",
      "Epoch 14360 - Train Loss: 0.095463, Train Acc: 0.855128 | Val Loss: 0.117239, Val Acc: 0.752577\n",
      "Epoch 14361 - Train Loss: 0.095459, Train Acc: 0.855128 | Val Loss: 0.117236, Val Acc: 0.752577\n",
      "Epoch 14362 - Train Loss: 0.095455, Train Acc: 0.855128 | Val Loss: 0.117233, Val Acc: 0.752577\n",
      "Epoch 14363 - Train Loss: 0.095451, Train Acc: 0.855128 | Val Loss: 0.117230, Val Acc: 0.752577\n",
      "Epoch 14364 - Train Loss: 0.095446, Train Acc: 0.855128 | Val Loss: 0.117227, Val Acc: 0.752577\n",
      "Epoch 14365 - Train Loss: 0.095442, Train Acc: 0.855128 | Val Loss: 0.117224, Val Acc: 0.752577\n",
      "Epoch 14366 - Train Loss: 0.095438, Train Acc: 0.855128 | Val Loss: 0.117222, Val Acc: 0.752577\n",
      "Epoch 14367 - Train Loss: 0.095434, Train Acc: 0.855128 | Val Loss: 0.117219, Val Acc: 0.752577\n",
      "Epoch 14368 - Train Loss: 0.095430, Train Acc: 0.855128 | Val Loss: 0.117216, Val Acc: 0.752577\n",
      "Epoch 14369 - Train Loss: 0.095426, Train Acc: 0.855128 | Val Loss: 0.117213, Val Acc: 0.752577\n",
      "Epoch 14370 - Train Loss: 0.095422, Train Acc: 0.855128 | Val Loss: 0.117210, Val Acc: 0.752577\n",
      "Epoch 14371 - Train Loss: 0.095418, Train Acc: 0.855128 | Val Loss: 0.117207, Val Acc: 0.752577\n",
      "Epoch 14372 - Train Loss: 0.095414, Train Acc: 0.855128 | Val Loss: 0.117205, Val Acc: 0.752577\n",
      "Epoch 14373 - Train Loss: 0.095409, Train Acc: 0.855128 | Val Loss: 0.117202, Val Acc: 0.752577\n",
      "Epoch 14374 - Train Loss: 0.095405, Train Acc: 0.855128 | Val Loss: 0.117199, Val Acc: 0.752577\n",
      "Epoch 14375 - Train Loss: 0.095401, Train Acc: 0.855128 | Val Loss: 0.117196, Val Acc: 0.752577\n",
      "Epoch 14376 - Train Loss: 0.095397, Train Acc: 0.855128 | Val Loss: 0.117193, Val Acc: 0.752577\n",
      "Epoch 14377 - Train Loss: 0.095393, Train Acc: 0.855128 | Val Loss: 0.117190, Val Acc: 0.752577\n",
      "Epoch 14378 - Train Loss: 0.095389, Train Acc: 0.855128 | Val Loss: 0.117188, Val Acc: 0.752577\n",
      "Epoch 14379 - Train Loss: 0.095385, Train Acc: 0.855128 | Val Loss: 0.117185, Val Acc: 0.752577\n",
      "Epoch 14380 - Train Loss: 0.095381, Train Acc: 0.855128 | Val Loss: 0.117182, Val Acc: 0.752577\n",
      "Epoch 14381 - Train Loss: 0.095377, Train Acc: 0.855128 | Val Loss: 0.117179, Val Acc: 0.752577\n",
      "Epoch 14382 - Train Loss: 0.095372, Train Acc: 0.855128 | Val Loss: 0.117176, Val Acc: 0.752577\n",
      "Epoch 14383 - Train Loss: 0.095368, Train Acc: 0.855128 | Val Loss: 0.117173, Val Acc: 0.752577\n",
      "Epoch 14384 - Train Loss: 0.095364, Train Acc: 0.855128 | Val Loss: 0.117170, Val Acc: 0.752577\n",
      "Epoch 14385 - Train Loss: 0.095360, Train Acc: 0.855128 | Val Loss: 0.117168, Val Acc: 0.752577\n",
      "Epoch 14386 - Train Loss: 0.095356, Train Acc: 0.855128 | Val Loss: 0.117165, Val Acc: 0.752577\n",
      "Epoch 14387 - Train Loss: 0.095352, Train Acc: 0.855128 | Val Loss: 0.117162, Val Acc: 0.752577\n",
      "Epoch 14388 - Train Loss: 0.095348, Train Acc: 0.855128 | Val Loss: 0.117159, Val Acc: 0.752577\n",
      "Epoch 14389 - Train Loss: 0.095344, Train Acc: 0.855128 | Val Loss: 0.117156, Val Acc: 0.752577\n",
      "Epoch 14390 - Train Loss: 0.095340, Train Acc: 0.855128 | Val Loss: 0.117153, Val Acc: 0.752577\n",
      "Epoch 14391 - Train Loss: 0.095336, Train Acc: 0.855128 | Val Loss: 0.117151, Val Acc: 0.752577\n",
      "Epoch 14392 - Train Loss: 0.095331, Train Acc: 0.855128 | Val Loss: 0.117148, Val Acc: 0.752577\n",
      "Epoch 14393 - Train Loss: 0.095327, Train Acc: 0.855128 | Val Loss: 0.117145, Val Acc: 0.752577\n",
      "Epoch 14394 - Train Loss: 0.095323, Train Acc: 0.855128 | Val Loss: 0.117142, Val Acc: 0.752577\n",
      "Epoch 14395 - Train Loss: 0.095319, Train Acc: 0.855128 | Val Loss: 0.117139, Val Acc: 0.752577\n",
      "Epoch 14396 - Train Loss: 0.095315, Train Acc: 0.855128 | Val Loss: 0.117136, Val Acc: 0.752577\n",
      "Epoch 14397 - Train Loss: 0.095311, Train Acc: 0.855128 | Val Loss: 0.117134, Val Acc: 0.752577\n",
      "Epoch 14398 - Train Loss: 0.095307, Train Acc: 0.855128 | Val Loss: 0.117131, Val Acc: 0.752577\n",
      "Epoch 14399 - Train Loss: 0.095303, Train Acc: 0.855128 | Val Loss: 0.117128, Val Acc: 0.752577\n",
      "Epoch 14400 - Train Loss: 0.095299, Train Acc: 0.855128 | Val Loss: 0.117125, Val Acc: 0.752577\n",
      "Epoch 14401 - Train Loss: 0.095295, Train Acc: 0.855128 | Val Loss: 0.117122, Val Acc: 0.752577\n",
      "Epoch 14402 - Train Loss: 0.095290, Train Acc: 0.855128 | Val Loss: 0.117119, Val Acc: 0.752577\n",
      "Epoch 14403 - Train Loss: 0.095286, Train Acc: 0.855128 | Val Loss: 0.117117, Val Acc: 0.752577\n",
      "Epoch 14404 - Train Loss: 0.095282, Train Acc: 0.855128 | Val Loss: 0.117114, Val Acc: 0.752577\n",
      "Epoch 14405 - Train Loss: 0.095278, Train Acc: 0.855128 | Val Loss: 0.117111, Val Acc: 0.752577\n",
      "Epoch 14406 - Train Loss: 0.095274, Train Acc: 0.855128 | Val Loss: 0.117108, Val Acc: 0.752577\n",
      "Epoch 14407 - Train Loss: 0.095270, Train Acc: 0.855128 | Val Loss: 0.117105, Val Acc: 0.752577\n",
      "Epoch 14408 - Train Loss: 0.095266, Train Acc: 0.855128 | Val Loss: 0.117102, Val Acc: 0.752577\n",
      "Epoch 14409 - Train Loss: 0.095262, Train Acc: 0.855128 | Val Loss: 0.117100, Val Acc: 0.752577\n",
      "Epoch 14410 - Train Loss: 0.095258, Train Acc: 0.855128 | Val Loss: 0.117097, Val Acc: 0.752577\n",
      "Epoch 14411 - Train Loss: 0.095254, Train Acc: 0.855128 | Val Loss: 0.117094, Val Acc: 0.752577\n",
      "Epoch 14412 - Train Loss: 0.095249, Train Acc: 0.855128 | Val Loss: 0.117091, Val Acc: 0.752577\n",
      "Epoch 14413 - Train Loss: 0.095245, Train Acc: 0.855128 | Val Loss: 0.117088, Val Acc: 0.752577\n",
      "Epoch 14414 - Train Loss: 0.095241, Train Acc: 0.855128 | Val Loss: 0.117085, Val Acc: 0.752577\n",
      "Epoch 14415 - Train Loss: 0.095237, Train Acc: 0.855128 | Val Loss: 0.117083, Val Acc: 0.752577\n",
      "Epoch 14416 - Train Loss: 0.095233, Train Acc: 0.855128 | Val Loss: 0.117080, Val Acc: 0.752577\n",
      "Epoch 14417 - Train Loss: 0.095229, Train Acc: 0.855128 | Val Loss: 0.117077, Val Acc: 0.752577\n",
      "Epoch 14418 - Train Loss: 0.095225, Train Acc: 0.855128 | Val Loss: 0.117074, Val Acc: 0.752577\n",
      "Epoch 14419 - Train Loss: 0.095221, Train Acc: 0.855128 | Val Loss: 0.117071, Val Acc: 0.752577\n",
      "Epoch 14420 - Train Loss: 0.095217, Train Acc: 0.855128 | Val Loss: 0.117069, Val Acc: 0.752577\n",
      "Epoch 14421 - Train Loss: 0.095213, Train Acc: 0.855128 | Val Loss: 0.117066, Val Acc: 0.752577\n",
      "Epoch 14422 - Train Loss: 0.095209, Train Acc: 0.855128 | Val Loss: 0.117063, Val Acc: 0.752577\n",
      "Epoch 14423 - Train Loss: 0.095204, Train Acc: 0.855128 | Val Loss: 0.117060, Val Acc: 0.752577\n",
      "Epoch 14424 - Train Loss: 0.095200, Train Acc: 0.855128 | Val Loss: 0.117057, Val Acc: 0.752577\n",
      "Epoch 14425 - Train Loss: 0.095196, Train Acc: 0.855128 | Val Loss: 0.117055, Val Acc: 0.752577\n",
      "Epoch 14426 - Train Loss: 0.095192, Train Acc: 0.855128 | Val Loss: 0.117052, Val Acc: 0.752577\n",
      "Epoch 14427 - Train Loss: 0.095188, Train Acc: 0.855128 | Val Loss: 0.117049, Val Acc: 0.752577\n",
      "Epoch 14428 - Train Loss: 0.095184, Train Acc: 0.855128 | Val Loss: 0.117046, Val Acc: 0.752577\n",
      "Epoch 14429 - Train Loss: 0.095180, Train Acc: 0.855128 | Val Loss: 0.117043, Val Acc: 0.752577\n",
      "Epoch 14430 - Train Loss: 0.095176, Train Acc: 0.855128 | Val Loss: 0.117040, Val Acc: 0.752577\n",
      "Epoch 14431 - Train Loss: 0.095172, Train Acc: 0.855128 | Val Loss: 0.117038, Val Acc: 0.752577\n",
      "Epoch 14432 - Train Loss: 0.095168, Train Acc: 0.855128 | Val Loss: 0.117035, Val Acc: 0.752577\n",
      "Epoch 14433 - Train Loss: 0.095164, Train Acc: 0.855128 | Val Loss: 0.117032, Val Acc: 0.752577\n",
      "Epoch 14434 - Train Loss: 0.095160, Train Acc: 0.855128 | Val Loss: 0.117029, Val Acc: 0.752577\n",
      "Epoch 14435 - Train Loss: 0.095156, Train Acc: 0.855128 | Val Loss: 0.117026, Val Acc: 0.752577\n",
      "Epoch 14436 - Train Loss: 0.095151, Train Acc: 0.855128 | Val Loss: 0.117024, Val Acc: 0.752577\n",
      "Epoch 14437 - Train Loss: 0.095147, Train Acc: 0.855128 | Val Loss: 0.117021, Val Acc: 0.752577\n",
      "Epoch 14438 - Train Loss: 0.095143, Train Acc: 0.855128 | Val Loss: 0.117018, Val Acc: 0.752577\n",
      "Epoch 14439 - Train Loss: 0.095139, Train Acc: 0.855128 | Val Loss: 0.117015, Val Acc: 0.752577\n",
      "Epoch 14440 - Train Loss: 0.095135, Train Acc: 0.855128 | Val Loss: 0.117012, Val Acc: 0.752577\n",
      "Epoch 14441 - Train Loss: 0.095131, Train Acc: 0.855128 | Val Loss: 0.117010, Val Acc: 0.752577\n",
      "Epoch 14442 - Train Loss: 0.095127, Train Acc: 0.855128 | Val Loss: 0.117007, Val Acc: 0.752577\n",
      "Epoch 14443 - Train Loss: 0.095123, Train Acc: 0.855128 | Val Loss: 0.117004, Val Acc: 0.752577\n",
      "Epoch 14444 - Train Loss: 0.095119, Train Acc: 0.855128 | Val Loss: 0.117001, Val Acc: 0.752577\n",
      "Epoch 14445 - Train Loss: 0.095115, Train Acc: 0.855128 | Val Loss: 0.116999, Val Acc: 0.752577\n",
      "Epoch 14446 - Train Loss: 0.095111, Train Acc: 0.855128 | Val Loss: 0.116996, Val Acc: 0.752577\n",
      "Epoch 14447 - Train Loss: 0.095107, Train Acc: 0.855128 | Val Loss: 0.116993, Val Acc: 0.752577\n",
      "Epoch 14448 - Train Loss: 0.095103, Train Acc: 0.855128 | Val Loss: 0.116990, Val Acc: 0.752577\n",
      "Epoch 14449 - Train Loss: 0.095098, Train Acc: 0.855128 | Val Loss: 0.116987, Val Acc: 0.752577\n",
      "Epoch 14450 - Train Loss: 0.095094, Train Acc: 0.855128 | Val Loss: 0.116985, Val Acc: 0.752577\n",
      "Epoch 14451 - Train Loss: 0.095090, Train Acc: 0.855128 | Val Loss: 0.116982, Val Acc: 0.752577\n",
      "Epoch 14452 - Train Loss: 0.095086, Train Acc: 0.855128 | Val Loss: 0.116979, Val Acc: 0.752577\n",
      "Epoch 14453 - Train Loss: 0.095082, Train Acc: 0.855128 | Val Loss: 0.116976, Val Acc: 0.752577\n",
      "Epoch 14454 - Train Loss: 0.095078, Train Acc: 0.855128 | Val Loss: 0.116973, Val Acc: 0.752577\n",
      "Epoch 14455 - Train Loss: 0.095074, Train Acc: 0.855128 | Val Loss: 0.116971, Val Acc: 0.752577\n",
      "Epoch 14456 - Train Loss: 0.095070, Train Acc: 0.855128 | Val Loss: 0.116968, Val Acc: 0.752577\n",
      "Epoch 14457 - Train Loss: 0.095066, Train Acc: 0.855128 | Val Loss: 0.116965, Val Acc: 0.752577\n",
      "Epoch 14458 - Train Loss: 0.095062, Train Acc: 0.855128 | Val Loss: 0.116962, Val Acc: 0.752577\n",
      "Epoch 14459 - Train Loss: 0.095058, Train Acc: 0.855128 | Val Loss: 0.116959, Val Acc: 0.752577\n",
      "Epoch 14460 - Train Loss: 0.095054, Train Acc: 0.855128 | Val Loss: 0.116957, Val Acc: 0.752577\n",
      "Epoch 14461 - Train Loss: 0.095050, Train Acc: 0.855128 | Val Loss: 0.116954, Val Acc: 0.752577\n",
      "Epoch 14462 - Train Loss: 0.095046, Train Acc: 0.855128 | Val Loss: 0.116951, Val Acc: 0.752577\n",
      "Epoch 14463 - Train Loss: 0.095042, Train Acc: 0.855128 | Val Loss: 0.116948, Val Acc: 0.752577\n",
      "Epoch 14464 - Train Loss: 0.095037, Train Acc: 0.855128 | Val Loss: 0.116945, Val Acc: 0.752577\n",
      "Epoch 14465 - Train Loss: 0.095033, Train Acc: 0.855128 | Val Loss: 0.116943, Val Acc: 0.752577\n",
      "Epoch 14466 - Train Loss: 0.095029, Train Acc: 0.855128 | Val Loss: 0.116940, Val Acc: 0.752577\n",
      "Epoch 14467 - Train Loss: 0.095025, Train Acc: 0.855128 | Val Loss: 0.116937, Val Acc: 0.752577\n",
      "Epoch 14468 - Train Loss: 0.095021, Train Acc: 0.855128 | Val Loss: 0.116934, Val Acc: 0.752577\n",
      "Epoch 14469 - Train Loss: 0.095017, Train Acc: 0.855128 | Val Loss: 0.116932, Val Acc: 0.752577\n",
      "Epoch 14470 - Train Loss: 0.095013, Train Acc: 0.855128 | Val Loss: 0.116929, Val Acc: 0.752577\n",
      "Epoch 14471 - Train Loss: 0.095009, Train Acc: 0.855128 | Val Loss: 0.116926, Val Acc: 0.752577\n",
      "Epoch 14472 - Train Loss: 0.095005, Train Acc: 0.855128 | Val Loss: 0.116923, Val Acc: 0.752577\n",
      "Epoch 14473 - Train Loss: 0.095001, Train Acc: 0.855128 | Val Loss: 0.116920, Val Acc: 0.752577\n",
      "Epoch 14474 - Train Loss: 0.094997, Train Acc: 0.855128 | Val Loss: 0.116918, Val Acc: 0.752577\n",
      "Epoch 14475 - Train Loss: 0.094993, Train Acc: 0.855128 | Val Loss: 0.116915, Val Acc: 0.752577\n",
      "Epoch 14476 - Train Loss: 0.094989, Train Acc: 0.855128 | Val Loss: 0.116912, Val Acc: 0.752577\n",
      "Epoch 14477 - Train Loss: 0.094985, Train Acc: 0.855128 | Val Loss: 0.116909, Val Acc: 0.752577\n",
      "Epoch 14478 - Train Loss: 0.094981, Train Acc: 0.855128 | Val Loss: 0.116907, Val Acc: 0.752577\n",
      "Epoch 14479 - Train Loss: 0.094977, Train Acc: 0.855128 | Val Loss: 0.116904, Val Acc: 0.752577\n",
      "Epoch 14480 - Train Loss: 0.094973, Train Acc: 0.855128 | Val Loss: 0.116901, Val Acc: 0.752577\n",
      "Epoch 14481 - Train Loss: 0.094968, Train Acc: 0.855128 | Val Loss: 0.116898, Val Acc: 0.752577\n",
      "Epoch 14482 - Train Loss: 0.094964, Train Acc: 0.855128 | Val Loss: 0.116895, Val Acc: 0.752577\n",
      "Epoch 14483 - Train Loss: 0.094960, Train Acc: 0.855128 | Val Loss: 0.116893, Val Acc: 0.752577\n",
      "Epoch 14484 - Train Loss: 0.094956, Train Acc: 0.855128 | Val Loss: 0.116890, Val Acc: 0.752577\n",
      "Epoch 14485 - Train Loss: 0.094952, Train Acc: 0.855128 | Val Loss: 0.116887, Val Acc: 0.752577\n",
      "Epoch 14486 - Train Loss: 0.094948, Train Acc: 0.855128 | Val Loss: 0.116884, Val Acc: 0.752577\n",
      "Epoch 14487 - Train Loss: 0.094944, Train Acc: 0.855128 | Val Loss: 0.116882, Val Acc: 0.752577\n",
      "Epoch 14488 - Train Loss: 0.094940, Train Acc: 0.855128 | Val Loss: 0.116879, Val Acc: 0.752577\n",
      "Epoch 14489 - Train Loss: 0.094936, Train Acc: 0.855128 | Val Loss: 0.116876, Val Acc: 0.752577\n",
      "Epoch 14490 - Train Loss: 0.094932, Train Acc: 0.855128 | Val Loss: 0.116873, Val Acc: 0.752577\n",
      "Epoch 14491 - Train Loss: 0.094928, Train Acc: 0.855128 | Val Loss: 0.116870, Val Acc: 0.752577\n",
      "Epoch 14492 - Train Loss: 0.094924, Train Acc: 0.855128 | Val Loss: 0.116868, Val Acc: 0.752577\n",
      "Epoch 14493 - Train Loss: 0.094920, Train Acc: 0.855128 | Val Loss: 0.116865, Val Acc: 0.752577\n",
      "Epoch 14494 - Train Loss: 0.094916, Train Acc: 0.855128 | Val Loss: 0.116862, Val Acc: 0.752577\n",
      "Epoch 14495 - Train Loss: 0.094912, Train Acc: 0.855128 | Val Loss: 0.116859, Val Acc: 0.752577\n",
      "Epoch 14496 - Train Loss: 0.094908, Train Acc: 0.855128 | Val Loss: 0.116857, Val Acc: 0.752577\n",
      "Epoch 14497 - Train Loss: 0.094904, Train Acc: 0.855128 | Val Loss: 0.116854, Val Acc: 0.752577\n",
      "Epoch 14498 - Train Loss: 0.094900, Train Acc: 0.855128 | Val Loss: 0.116851, Val Acc: 0.752577\n",
      "Epoch 14499 - Train Loss: 0.094896, Train Acc: 0.855128 | Val Loss: 0.116848, Val Acc: 0.752577\n",
      "Epoch 14500 - Train Loss: 0.094892, Train Acc: 0.855128 | Val Loss: 0.116846, Val Acc: 0.752577\n",
      "Epoch 14501 - Train Loss: 0.094888, Train Acc: 0.855128 | Val Loss: 0.116843, Val Acc: 0.752577\n",
      "Epoch 14502 - Train Loss: 0.094883, Train Acc: 0.855128 | Val Loss: 0.116840, Val Acc: 0.752577\n",
      "Epoch 14503 - Train Loss: 0.094879, Train Acc: 0.855128 | Val Loss: 0.116837, Val Acc: 0.752577\n",
      "Epoch 14504 - Train Loss: 0.094875, Train Acc: 0.855128 | Val Loss: 0.116834, Val Acc: 0.752577\n",
      "Epoch 14505 - Train Loss: 0.094871, Train Acc: 0.855128 | Val Loss: 0.116832, Val Acc: 0.752577\n",
      "Epoch 14506 - Train Loss: 0.094867, Train Acc: 0.855128 | Val Loss: 0.116829, Val Acc: 0.752577\n",
      "Epoch 14507 - Train Loss: 0.094863, Train Acc: 0.855128 | Val Loss: 0.116826, Val Acc: 0.752577\n",
      "Epoch 14508 - Train Loss: 0.094859, Train Acc: 0.855128 | Val Loss: 0.116823, Val Acc: 0.752577\n",
      "Epoch 14509 - Train Loss: 0.094855, Train Acc: 0.855128 | Val Loss: 0.116821, Val Acc: 0.752577\n",
      "Epoch 14510 - Train Loss: 0.094851, Train Acc: 0.855128 | Val Loss: 0.116818, Val Acc: 0.752577\n",
      "Epoch 14511 - Train Loss: 0.094847, Train Acc: 0.855128 | Val Loss: 0.116815, Val Acc: 0.752577\n",
      "Epoch 14512 - Train Loss: 0.094843, Train Acc: 0.855128 | Val Loss: 0.116812, Val Acc: 0.752577\n",
      "Epoch 14513 - Train Loss: 0.094839, Train Acc: 0.855128 | Val Loss: 0.116810, Val Acc: 0.752577\n",
      "Epoch 14514 - Train Loss: 0.094835, Train Acc: 0.855128 | Val Loss: 0.116807, Val Acc: 0.752577\n",
      "Epoch 14515 - Train Loss: 0.094831, Train Acc: 0.855128 | Val Loss: 0.116804, Val Acc: 0.752577\n",
      "Epoch 14516 - Train Loss: 0.094827, Train Acc: 0.855128 | Val Loss: 0.116801, Val Acc: 0.752577\n",
      "Epoch 14517 - Train Loss: 0.094823, Train Acc: 0.855128 | Val Loss: 0.116799, Val Acc: 0.752577\n",
      "Epoch 14518 - Train Loss: 0.094819, Train Acc: 0.855128 | Val Loss: 0.116796, Val Acc: 0.752577\n",
      "Epoch 14519 - Train Loss: 0.094815, Train Acc: 0.855128 | Val Loss: 0.116793, Val Acc: 0.752577\n",
      "Epoch 14520 - Train Loss: 0.094811, Train Acc: 0.855128 | Val Loss: 0.116790, Val Acc: 0.752577\n",
      "Epoch 14521 - Train Loss: 0.094807, Train Acc: 0.855128 | Val Loss: 0.116787, Val Acc: 0.752577\n",
      "Epoch 14522 - Train Loss: 0.094803, Train Acc: 0.855128 | Val Loss: 0.116785, Val Acc: 0.752577\n",
      "Epoch 14523 - Train Loss: 0.094799, Train Acc: 0.855128 | Val Loss: 0.116782, Val Acc: 0.752577\n",
      "Epoch 14524 - Train Loss: 0.094795, Train Acc: 0.855128 | Val Loss: 0.116779, Val Acc: 0.752577\n",
      "Epoch 14525 - Train Loss: 0.094791, Train Acc: 0.855128 | Val Loss: 0.116776, Val Acc: 0.752577\n",
      "Epoch 14526 - Train Loss: 0.094787, Train Acc: 0.855128 | Val Loss: 0.116774, Val Acc: 0.752577\n",
      "Epoch 14527 - Train Loss: 0.094783, Train Acc: 0.855128 | Val Loss: 0.116771, Val Acc: 0.752577\n",
      "Epoch 14528 - Train Loss: 0.094779, Train Acc: 0.855128 | Val Loss: 0.116768, Val Acc: 0.752577\n",
      "Epoch 14529 - Train Loss: 0.094774, Train Acc: 0.855128 | Val Loss: 0.116765, Val Acc: 0.752577\n",
      "Epoch 14530 - Train Loss: 0.094770, Train Acc: 0.855128 | Val Loss: 0.116763, Val Acc: 0.752577\n",
      "Epoch 14531 - Train Loss: 0.094766, Train Acc: 0.855128 | Val Loss: 0.116760, Val Acc: 0.752577\n",
      "Epoch 14532 - Train Loss: 0.094762, Train Acc: 0.855128 | Val Loss: 0.116757, Val Acc: 0.752577\n",
      "Epoch 14533 - Train Loss: 0.094758, Train Acc: 0.855128 | Val Loss: 0.116754, Val Acc: 0.752577\n",
      "Epoch 14534 - Train Loss: 0.094754, Train Acc: 0.855128 | Val Loss: 0.116752, Val Acc: 0.752577\n",
      "Epoch 14535 - Train Loss: 0.094750, Train Acc: 0.855128 | Val Loss: 0.116749, Val Acc: 0.752577\n",
      "Epoch 14536 - Train Loss: 0.094746, Train Acc: 0.855128 | Val Loss: 0.116746, Val Acc: 0.752577\n",
      "Epoch 14537 - Train Loss: 0.094742, Train Acc: 0.855128 | Val Loss: 0.116743, Val Acc: 0.752577\n",
      "Epoch 14538 - Train Loss: 0.094738, Train Acc: 0.855128 | Val Loss: 0.116741, Val Acc: 0.752577\n",
      "Epoch 14539 - Train Loss: 0.094734, Train Acc: 0.855128 | Val Loss: 0.116738, Val Acc: 0.752577\n",
      "Epoch 14540 - Train Loss: 0.094730, Train Acc: 0.855128 | Val Loss: 0.116735, Val Acc: 0.752577\n",
      "Epoch 14541 - Train Loss: 0.094726, Train Acc: 0.855128 | Val Loss: 0.116732, Val Acc: 0.752577\n",
      "Epoch 14542 - Train Loss: 0.094722, Train Acc: 0.855128 | Val Loss: 0.116730, Val Acc: 0.752577\n",
      "Epoch 14543 - Train Loss: 0.094718, Train Acc: 0.855128 | Val Loss: 0.116727, Val Acc: 0.752577\n",
      "Epoch 14544 - Train Loss: 0.094714, Train Acc: 0.855128 | Val Loss: 0.116724, Val Acc: 0.752577\n",
      "Epoch 14545 - Train Loss: 0.094710, Train Acc: 0.855128 | Val Loss: 0.116721, Val Acc: 0.752577\n",
      "Epoch 14546 - Train Loss: 0.094706, Train Acc: 0.855128 | Val Loss: 0.116719, Val Acc: 0.752577\n",
      "Epoch 14547 - Train Loss: 0.094702, Train Acc: 0.855128 | Val Loss: 0.116716, Val Acc: 0.752577\n",
      "Epoch 14548 - Train Loss: 0.094698, Train Acc: 0.855128 | Val Loss: 0.116713, Val Acc: 0.752577\n",
      "Epoch 14549 - Train Loss: 0.094694, Train Acc: 0.855128 | Val Loss: 0.116710, Val Acc: 0.752577\n",
      "Epoch 14550 - Train Loss: 0.094690, Train Acc: 0.855128 | Val Loss: 0.116708, Val Acc: 0.752577\n",
      "Epoch 14551 - Train Loss: 0.094686, Train Acc: 0.855128 | Val Loss: 0.116705, Val Acc: 0.752577\n",
      "Epoch 14552 - Train Loss: 0.094682, Train Acc: 0.855128 | Val Loss: 0.116702, Val Acc: 0.752577\n",
      "Epoch 14553 - Train Loss: 0.094678, Train Acc: 0.855128 | Val Loss: 0.116699, Val Acc: 0.752577\n",
      "Epoch 14554 - Train Loss: 0.094674, Train Acc: 0.855128 | Val Loss: 0.116697, Val Acc: 0.752577\n",
      "Epoch 14555 - Train Loss: 0.094670, Train Acc: 0.855128 | Val Loss: 0.116694, Val Acc: 0.752577\n",
      "Epoch 14556 - Train Loss: 0.094666, Train Acc: 0.855128 | Val Loss: 0.116691, Val Acc: 0.752577\n",
      "Epoch 14557 - Train Loss: 0.094662, Train Acc: 0.855128 | Val Loss: 0.116689, Val Acc: 0.752577\n",
      "Epoch 14558 - Train Loss: 0.094658, Train Acc: 0.855128 | Val Loss: 0.116686, Val Acc: 0.752577\n",
      "Epoch 14559 - Train Loss: 0.094654, Train Acc: 0.855128 | Val Loss: 0.116683, Val Acc: 0.752577\n",
      "Epoch 14560 - Train Loss: 0.094650, Train Acc: 0.855128 | Val Loss: 0.116680, Val Acc: 0.752577\n",
      "Epoch 14561 - Train Loss: 0.094646, Train Acc: 0.855128 | Val Loss: 0.116678, Val Acc: 0.752577\n",
      "Epoch 14562 - Train Loss: 0.094642, Train Acc: 0.855128 | Val Loss: 0.116675, Val Acc: 0.752577\n",
      "Epoch 14563 - Train Loss: 0.094638, Train Acc: 0.855128 | Val Loss: 0.116672, Val Acc: 0.752577\n",
      "Epoch 14564 - Train Loss: 0.094634, Train Acc: 0.855128 | Val Loss: 0.116669, Val Acc: 0.752577\n",
      "Epoch 14565 - Train Loss: 0.094630, Train Acc: 0.855128 | Val Loss: 0.116667, Val Acc: 0.752577\n",
      "Epoch 14566 - Train Loss: 0.094626, Train Acc: 0.855128 | Val Loss: 0.116664, Val Acc: 0.752577\n",
      "Epoch 14567 - Train Loss: 0.094622, Train Acc: 0.855128 | Val Loss: 0.116661, Val Acc: 0.752577\n",
      "Epoch 14568 - Train Loss: 0.094618, Train Acc: 0.855128 | Val Loss: 0.116658, Val Acc: 0.752577\n",
      "Epoch 14569 - Train Loss: 0.094614, Train Acc: 0.855128 | Val Loss: 0.116656, Val Acc: 0.752577\n",
      "Epoch 14570 - Train Loss: 0.094610, Train Acc: 0.855128 | Val Loss: 0.116653, Val Acc: 0.752577\n",
      "Epoch 14571 - Train Loss: 0.094606, Train Acc: 0.855128 | Val Loss: 0.116650, Val Acc: 0.752577\n",
      "Epoch 14572 - Train Loss: 0.094602, Train Acc: 0.855128 | Val Loss: 0.116647, Val Acc: 0.752577\n",
      "Epoch 14573 - Train Loss: 0.094598, Train Acc: 0.855128 | Val Loss: 0.116645, Val Acc: 0.752577\n",
      "Epoch 14574 - Train Loss: 0.094594, Train Acc: 0.855128 | Val Loss: 0.116642, Val Acc: 0.752577\n",
      "Epoch 14575 - Train Loss: 0.094590, Train Acc: 0.855128 | Val Loss: 0.116639, Val Acc: 0.752577\n",
      "Epoch 14576 - Train Loss: 0.094586, Train Acc: 0.855128 | Val Loss: 0.116637, Val Acc: 0.752577\n",
      "Epoch 14577 - Train Loss: 0.094582, Train Acc: 0.855128 | Val Loss: 0.116634, Val Acc: 0.752577\n",
      "Epoch 14578 - Train Loss: 0.094578, Train Acc: 0.855128 | Val Loss: 0.116631, Val Acc: 0.752577\n",
      "Epoch 14579 - Train Loss: 0.094574, Train Acc: 0.855128 | Val Loss: 0.116628, Val Acc: 0.752577\n",
      "Epoch 14580 - Train Loss: 0.094570, Train Acc: 0.855128 | Val Loss: 0.116626, Val Acc: 0.752577\n",
      "Epoch 14581 - Train Loss: 0.094566, Train Acc: 0.855128 | Val Loss: 0.116623, Val Acc: 0.752577\n",
      "Epoch 14582 - Train Loss: 0.094562, Train Acc: 0.855128 | Val Loss: 0.116620, Val Acc: 0.752577\n",
      "Epoch 14583 - Train Loss: 0.094558, Train Acc: 0.855128 | Val Loss: 0.116617, Val Acc: 0.752577\n",
      "Epoch 14584 - Train Loss: 0.094554, Train Acc: 0.855128 | Val Loss: 0.116615, Val Acc: 0.752577\n",
      "Epoch 14585 - Train Loss: 0.094550, Train Acc: 0.855128 | Val Loss: 0.116612, Val Acc: 0.752577\n",
      "Epoch 14586 - Train Loss: 0.094546, Train Acc: 0.855128 | Val Loss: 0.116609, Val Acc: 0.752577\n",
      "Epoch 14587 - Train Loss: 0.094542, Train Acc: 0.855128 | Val Loss: 0.116607, Val Acc: 0.752577\n",
      "Epoch 14588 - Train Loss: 0.094538, Train Acc: 0.855128 | Val Loss: 0.116604, Val Acc: 0.752577\n",
      "Epoch 14589 - Train Loss: 0.094534, Train Acc: 0.855128 | Val Loss: 0.116601, Val Acc: 0.752577\n",
      "Epoch 14590 - Train Loss: 0.094530, Train Acc: 0.855128 | Val Loss: 0.116598, Val Acc: 0.752577\n",
      "Epoch 14591 - Train Loss: 0.094526, Train Acc: 0.855128 | Val Loss: 0.116596, Val Acc: 0.752577\n",
      "Epoch 14592 - Train Loss: 0.094522, Train Acc: 0.855128 | Val Loss: 0.116593, Val Acc: 0.752577\n",
      "Epoch 14593 - Train Loss: 0.094518, Train Acc: 0.855128 | Val Loss: 0.116590, Val Acc: 0.752577\n",
      "Epoch 14594 - Train Loss: 0.094514, Train Acc: 0.855128 | Val Loss: 0.116588, Val Acc: 0.752577\n",
      "Epoch 14595 - Train Loss: 0.094510, Train Acc: 0.855128 | Val Loss: 0.116585, Val Acc: 0.752577\n",
      "Epoch 14596 - Train Loss: 0.094506, Train Acc: 0.855128 | Val Loss: 0.116582, Val Acc: 0.752577\n",
      "Epoch 14597 - Train Loss: 0.094502, Train Acc: 0.855128 | Val Loss: 0.116579, Val Acc: 0.752577\n",
      "Epoch 14598 - Train Loss: 0.094498, Train Acc: 0.855128 | Val Loss: 0.116577, Val Acc: 0.752577\n",
      "Epoch 14599 - Train Loss: 0.094494, Train Acc: 0.855128 | Val Loss: 0.116574, Val Acc: 0.752577\n",
      "Epoch 14600 - Train Loss: 0.094490, Train Acc: 0.855128 | Val Loss: 0.116571, Val Acc: 0.752577\n",
      "Epoch 14601 - Train Loss: 0.094486, Train Acc: 0.855128 | Val Loss: 0.116569, Val Acc: 0.752577\n",
      "Epoch 14602 - Train Loss: 0.094482, Train Acc: 0.856410 | Val Loss: 0.116566, Val Acc: 0.752577\n",
      "Epoch 14603 - Train Loss: 0.094478, Train Acc: 0.856410 | Val Loss: 0.116563, Val Acc: 0.752577\n",
      "Epoch 14604 - Train Loss: 0.094474, Train Acc: 0.856410 | Val Loss: 0.116560, Val Acc: 0.752577\n",
      "Epoch 14605 - Train Loss: 0.094470, Train Acc: 0.856410 | Val Loss: 0.116558, Val Acc: 0.752577\n",
      "Epoch 14606 - Train Loss: 0.094466, Train Acc: 0.856410 | Val Loss: 0.116555, Val Acc: 0.752577\n",
      "Epoch 14607 - Train Loss: 0.094462, Train Acc: 0.856410 | Val Loss: 0.116552, Val Acc: 0.752577\n",
      "Epoch 14608 - Train Loss: 0.094458, Train Acc: 0.856410 | Val Loss: 0.116550, Val Acc: 0.752577\n",
      "Epoch 14609 - Train Loss: 0.094454, Train Acc: 0.856410 | Val Loss: 0.116547, Val Acc: 0.752577\n",
      "Epoch 14610 - Train Loss: 0.094450, Train Acc: 0.856410 | Val Loss: 0.116544, Val Acc: 0.752577\n",
      "Epoch 14611 - Train Loss: 0.094446, Train Acc: 0.856410 | Val Loss: 0.116541, Val Acc: 0.752577\n",
      "Epoch 14612 - Train Loss: 0.094442, Train Acc: 0.856410 | Val Loss: 0.116539, Val Acc: 0.752577\n",
      "Epoch 14613 - Train Loss: 0.094438, Train Acc: 0.856410 | Val Loss: 0.116536, Val Acc: 0.752577\n",
      "Epoch 14614 - Train Loss: 0.094434, Train Acc: 0.856410 | Val Loss: 0.116533, Val Acc: 0.752577\n",
      "Epoch 14615 - Train Loss: 0.094430, Train Acc: 0.856410 | Val Loss: 0.116531, Val Acc: 0.752577\n",
      "Epoch 14616 - Train Loss: 0.094426, Train Acc: 0.856410 | Val Loss: 0.116528, Val Acc: 0.752577\n",
      "Epoch 14617 - Train Loss: 0.094422, Train Acc: 0.856410 | Val Loss: 0.116525, Val Acc: 0.752577\n",
      "Epoch 14618 - Train Loss: 0.094418, Train Acc: 0.856410 | Val Loss: 0.116522, Val Acc: 0.752577\n",
      "Epoch 14619 - Train Loss: 0.094414, Train Acc: 0.856410 | Val Loss: 0.116520, Val Acc: 0.752577\n",
      "Epoch 14620 - Train Loss: 0.094410, Train Acc: 0.856410 | Val Loss: 0.116517, Val Acc: 0.752577\n",
      "Epoch 14621 - Train Loss: 0.094406, Train Acc: 0.856410 | Val Loss: 0.116514, Val Acc: 0.752577\n",
      "Epoch 14622 - Train Loss: 0.094402, Train Acc: 0.856410 | Val Loss: 0.116512, Val Acc: 0.752577\n",
      "Epoch 14623 - Train Loss: 0.094398, Train Acc: 0.856410 | Val Loss: 0.116509, Val Acc: 0.752577\n",
      "Epoch 14624 - Train Loss: 0.094394, Train Acc: 0.856410 | Val Loss: 0.116506, Val Acc: 0.752577\n",
      "Epoch 14625 - Train Loss: 0.094390, Train Acc: 0.856410 | Val Loss: 0.116504, Val Acc: 0.752577\n",
      "Epoch 14626 - Train Loss: 0.094386, Train Acc: 0.856410 | Val Loss: 0.116501, Val Acc: 0.752577\n",
      "Epoch 14627 - Train Loss: 0.094382, Train Acc: 0.856410 | Val Loss: 0.116498, Val Acc: 0.752577\n",
      "Epoch 14628 - Train Loss: 0.094378, Train Acc: 0.856410 | Val Loss: 0.116495, Val Acc: 0.752577\n",
      "Epoch 14629 - Train Loss: 0.094374, Train Acc: 0.856410 | Val Loss: 0.116493, Val Acc: 0.752577\n",
      "Epoch 14630 - Train Loss: 0.094370, Train Acc: 0.856410 | Val Loss: 0.116490, Val Acc: 0.752577\n",
      "Epoch 14631 - Train Loss: 0.094366, Train Acc: 0.856410 | Val Loss: 0.116487, Val Acc: 0.752577\n",
      "Epoch 14632 - Train Loss: 0.094362, Train Acc: 0.856410 | Val Loss: 0.116485, Val Acc: 0.752577\n",
      "Epoch 14633 - Train Loss: 0.094358, Train Acc: 0.856410 | Val Loss: 0.116482, Val Acc: 0.752577\n",
      "Epoch 14634 - Train Loss: 0.094354, Train Acc: 0.856410 | Val Loss: 0.116479, Val Acc: 0.752577\n",
      "Epoch 14635 - Train Loss: 0.094350, Train Acc: 0.856410 | Val Loss: 0.116477, Val Acc: 0.752577\n",
      "Epoch 14636 - Train Loss: 0.094346, Train Acc: 0.856410 | Val Loss: 0.116474, Val Acc: 0.752577\n",
      "Epoch 14637 - Train Loss: 0.094342, Train Acc: 0.856410 | Val Loss: 0.116471, Val Acc: 0.752577\n",
      "Epoch 14638 - Train Loss: 0.094338, Train Acc: 0.856410 | Val Loss: 0.116469, Val Acc: 0.752577\n",
      "Epoch 14639 - Train Loss: 0.094335, Train Acc: 0.856410 | Val Loss: 0.116466, Val Acc: 0.752577\n",
      "Epoch 14640 - Train Loss: 0.094331, Train Acc: 0.856410 | Val Loss: 0.116463, Val Acc: 0.752577\n",
      "Epoch 14641 - Train Loss: 0.094327, Train Acc: 0.856410 | Val Loss: 0.116460, Val Acc: 0.752577\n",
      "Epoch 14642 - Train Loss: 0.094323, Train Acc: 0.856410 | Val Loss: 0.116458, Val Acc: 0.752577\n",
      "Epoch 14643 - Train Loss: 0.094319, Train Acc: 0.856410 | Val Loss: 0.116455, Val Acc: 0.752577\n",
      "Epoch 14644 - Train Loss: 0.094315, Train Acc: 0.856410 | Val Loss: 0.116452, Val Acc: 0.752577\n",
      "Epoch 14645 - Train Loss: 0.094311, Train Acc: 0.856410 | Val Loss: 0.116450, Val Acc: 0.752577\n",
      "Epoch 14646 - Train Loss: 0.094307, Train Acc: 0.856410 | Val Loss: 0.116447, Val Acc: 0.752577\n",
      "Epoch 14647 - Train Loss: 0.094303, Train Acc: 0.856410 | Val Loss: 0.116444, Val Acc: 0.752577\n",
      "Epoch 14648 - Train Loss: 0.094299, Train Acc: 0.856410 | Val Loss: 0.116442, Val Acc: 0.752577\n",
      "Epoch 14649 - Train Loss: 0.094295, Train Acc: 0.856410 | Val Loss: 0.116439, Val Acc: 0.752577\n",
      "Epoch 14650 - Train Loss: 0.094291, Train Acc: 0.856410 | Val Loss: 0.116436, Val Acc: 0.752577\n",
      "Epoch 14651 - Train Loss: 0.094287, Train Acc: 0.856410 | Val Loss: 0.116434, Val Acc: 0.752577\n",
      "Epoch 14652 - Train Loss: 0.094283, Train Acc: 0.856410 | Val Loss: 0.116431, Val Acc: 0.752577\n",
      "Epoch 14653 - Train Loss: 0.094279, Train Acc: 0.856410 | Val Loss: 0.116428, Val Acc: 0.752577\n",
      "Epoch 14654 - Train Loss: 0.094275, Train Acc: 0.856410 | Val Loss: 0.116426, Val Acc: 0.752577\n",
      "Epoch 14655 - Train Loss: 0.094271, Train Acc: 0.856410 | Val Loss: 0.116423, Val Acc: 0.752577\n",
      "Epoch 14656 - Train Loss: 0.094267, Train Acc: 0.856410 | Val Loss: 0.116420, Val Acc: 0.752577\n",
      "Epoch 14657 - Train Loss: 0.094263, Train Acc: 0.856410 | Val Loss: 0.116417, Val Acc: 0.752577\n",
      "Epoch 14658 - Train Loss: 0.094259, Train Acc: 0.856410 | Val Loss: 0.116415, Val Acc: 0.752577\n",
      "Epoch 14659 - Train Loss: 0.094255, Train Acc: 0.856410 | Val Loss: 0.116412, Val Acc: 0.752577\n",
      "Epoch 14660 - Train Loss: 0.094251, Train Acc: 0.856410 | Val Loss: 0.116409, Val Acc: 0.752577\n",
      "Epoch 14661 - Train Loss: 0.094247, Train Acc: 0.856410 | Val Loss: 0.116407, Val Acc: 0.752577\n",
      "Epoch 14662 - Train Loss: 0.094243, Train Acc: 0.856410 | Val Loss: 0.116404, Val Acc: 0.752577\n",
      "Epoch 14663 - Train Loss: 0.094239, Train Acc: 0.856410 | Val Loss: 0.116401, Val Acc: 0.752577\n",
      "Epoch 14664 - Train Loss: 0.094235, Train Acc: 0.856410 | Val Loss: 0.116399, Val Acc: 0.752577\n",
      "Epoch 14665 - Train Loss: 0.094231, Train Acc: 0.856410 | Val Loss: 0.116396, Val Acc: 0.752577\n",
      "Epoch 14666 - Train Loss: 0.094227, Train Acc: 0.856410 | Val Loss: 0.116393, Val Acc: 0.752577\n",
      "Epoch 14667 - Train Loss: 0.094224, Train Acc: 0.856410 | Val Loss: 0.116391, Val Acc: 0.752577\n",
      "Epoch 14668 - Train Loss: 0.094220, Train Acc: 0.856410 | Val Loss: 0.116388, Val Acc: 0.752577\n",
      "Epoch 14669 - Train Loss: 0.094216, Train Acc: 0.856410 | Val Loss: 0.116385, Val Acc: 0.752577\n",
      "Epoch 14670 - Train Loss: 0.094212, Train Acc: 0.856410 | Val Loss: 0.116383, Val Acc: 0.752577\n",
      "Epoch 14671 - Train Loss: 0.094208, Train Acc: 0.856410 | Val Loss: 0.116380, Val Acc: 0.752577\n",
      "Epoch 14672 - Train Loss: 0.094204, Train Acc: 0.856410 | Val Loss: 0.116377, Val Acc: 0.752577\n",
      "Epoch 14673 - Train Loss: 0.094200, Train Acc: 0.856410 | Val Loss: 0.116375, Val Acc: 0.752577\n",
      "Epoch 14674 - Train Loss: 0.094196, Train Acc: 0.856410 | Val Loss: 0.116372, Val Acc: 0.752577\n",
      "Epoch 14675 - Train Loss: 0.094192, Train Acc: 0.856410 | Val Loss: 0.116369, Val Acc: 0.752577\n",
      "Epoch 14676 - Train Loss: 0.094188, Train Acc: 0.856410 | Val Loss: 0.116367, Val Acc: 0.752577\n",
      "Epoch 14677 - Train Loss: 0.094184, Train Acc: 0.856410 | Val Loss: 0.116364, Val Acc: 0.752577\n",
      "Epoch 14678 - Train Loss: 0.094180, Train Acc: 0.856410 | Val Loss: 0.116361, Val Acc: 0.752577\n",
      "Epoch 14679 - Train Loss: 0.094176, Train Acc: 0.856410 | Val Loss: 0.116359, Val Acc: 0.752577\n",
      "Epoch 14680 - Train Loss: 0.094172, Train Acc: 0.856410 | Val Loss: 0.116356, Val Acc: 0.752577\n",
      "Epoch 14681 - Train Loss: 0.094168, Train Acc: 0.856410 | Val Loss: 0.116353, Val Acc: 0.752577\n",
      "Epoch 14682 - Train Loss: 0.094164, Train Acc: 0.856410 | Val Loss: 0.116351, Val Acc: 0.752577\n",
      "Epoch 14683 - Train Loss: 0.094160, Train Acc: 0.856410 | Val Loss: 0.116348, Val Acc: 0.752577\n",
      "Epoch 14684 - Train Loss: 0.094156, Train Acc: 0.856410 | Val Loss: 0.116345, Val Acc: 0.752577\n",
      "Epoch 14685 - Train Loss: 0.094152, Train Acc: 0.856410 | Val Loss: 0.116343, Val Acc: 0.752577\n",
      "Epoch 14686 - Train Loss: 0.094148, Train Acc: 0.856410 | Val Loss: 0.116340, Val Acc: 0.752577\n",
      "Epoch 14687 - Train Loss: 0.094144, Train Acc: 0.856410 | Val Loss: 0.116337, Val Acc: 0.752577\n",
      "Epoch 14688 - Train Loss: 0.094141, Train Acc: 0.856410 | Val Loss: 0.116335, Val Acc: 0.752577\n",
      "Epoch 14689 - Train Loss: 0.094137, Train Acc: 0.856410 | Val Loss: 0.116332, Val Acc: 0.752577\n",
      "Epoch 14690 - Train Loss: 0.094133, Train Acc: 0.856410 | Val Loss: 0.116329, Val Acc: 0.752577\n",
      "Epoch 14691 - Train Loss: 0.094129, Train Acc: 0.856410 | Val Loss: 0.116327, Val Acc: 0.752577\n",
      "Epoch 14692 - Train Loss: 0.094125, Train Acc: 0.856410 | Val Loss: 0.116324, Val Acc: 0.752577\n",
      "Epoch 14693 - Train Loss: 0.094121, Train Acc: 0.856410 | Val Loss: 0.116321, Val Acc: 0.752577\n",
      "Epoch 14694 - Train Loss: 0.094117, Train Acc: 0.856410 | Val Loss: 0.116319, Val Acc: 0.752577\n",
      "Epoch 14695 - Train Loss: 0.094113, Train Acc: 0.856410 | Val Loss: 0.116316, Val Acc: 0.752577\n",
      "Epoch 14696 - Train Loss: 0.094109, Train Acc: 0.856410 | Val Loss: 0.116313, Val Acc: 0.752577\n",
      "Epoch 14697 - Train Loss: 0.094105, Train Acc: 0.856410 | Val Loss: 0.116311, Val Acc: 0.752577\n",
      "Epoch 14698 - Train Loss: 0.094101, Train Acc: 0.856410 | Val Loss: 0.116308, Val Acc: 0.752577\n",
      "Epoch 14699 - Train Loss: 0.094097, Train Acc: 0.856410 | Val Loss: 0.116305, Val Acc: 0.752577\n",
      "Epoch 14700 - Train Loss: 0.094093, Train Acc: 0.856410 | Val Loss: 0.116303, Val Acc: 0.752577\n",
      "Epoch 14701 - Train Loss: 0.094089, Train Acc: 0.856410 | Val Loss: 0.116300, Val Acc: 0.752577\n",
      "Epoch 14702 - Train Loss: 0.094085, Train Acc: 0.856410 | Val Loss: 0.116297, Val Acc: 0.752577\n",
      "Epoch 14703 - Train Loss: 0.094081, Train Acc: 0.856410 | Val Loss: 0.116295, Val Acc: 0.752577\n",
      "Epoch 14704 - Train Loss: 0.094077, Train Acc: 0.856410 | Val Loss: 0.116292, Val Acc: 0.752577\n",
      "Epoch 14705 - Train Loss: 0.094074, Train Acc: 0.856410 | Val Loss: 0.116289, Val Acc: 0.752577\n",
      "Epoch 14706 - Train Loss: 0.094070, Train Acc: 0.856410 | Val Loss: 0.116287, Val Acc: 0.752577\n",
      "Epoch 14707 - Train Loss: 0.094066, Train Acc: 0.856410 | Val Loss: 0.116284, Val Acc: 0.752577\n",
      "Epoch 14708 - Train Loss: 0.094062, Train Acc: 0.856410 | Val Loss: 0.116281, Val Acc: 0.752577\n",
      "Epoch 14709 - Train Loss: 0.094058, Train Acc: 0.856410 | Val Loss: 0.116279, Val Acc: 0.752577\n",
      "Epoch 14710 - Train Loss: 0.094054, Train Acc: 0.856410 | Val Loss: 0.116276, Val Acc: 0.752577\n",
      "Epoch 14711 - Train Loss: 0.094050, Train Acc: 0.856410 | Val Loss: 0.116273, Val Acc: 0.752577\n",
      "Epoch 14712 - Train Loss: 0.094046, Train Acc: 0.856410 | Val Loss: 0.116271, Val Acc: 0.752577\n",
      "Epoch 14713 - Train Loss: 0.094042, Train Acc: 0.856410 | Val Loss: 0.116268, Val Acc: 0.752577\n",
      "Epoch 14714 - Train Loss: 0.094038, Train Acc: 0.856410 | Val Loss: 0.116265, Val Acc: 0.752577\n",
      "Epoch 14715 - Train Loss: 0.094034, Train Acc: 0.856410 | Val Loss: 0.116263, Val Acc: 0.752577\n",
      "Epoch 14716 - Train Loss: 0.094030, Train Acc: 0.856410 | Val Loss: 0.116260, Val Acc: 0.752577\n",
      "Epoch 14717 - Train Loss: 0.094026, Train Acc: 0.856410 | Val Loss: 0.116257, Val Acc: 0.752577\n",
      "Epoch 14718 - Train Loss: 0.094022, Train Acc: 0.856410 | Val Loss: 0.116255, Val Acc: 0.752577\n",
      "Epoch 14719 - Train Loss: 0.094018, Train Acc: 0.856410 | Val Loss: 0.116252, Val Acc: 0.752577\n",
      "Epoch 14720 - Train Loss: 0.094014, Train Acc: 0.856410 | Val Loss: 0.116250, Val Acc: 0.752577\n",
      "Epoch 14721 - Train Loss: 0.094011, Train Acc: 0.856410 | Val Loss: 0.116247, Val Acc: 0.752577\n",
      "Epoch 14722 - Train Loss: 0.094007, Train Acc: 0.856410 | Val Loss: 0.116244, Val Acc: 0.752577\n",
      "Epoch 14723 - Train Loss: 0.094003, Train Acc: 0.856410 | Val Loss: 0.116242, Val Acc: 0.752577\n",
      "Epoch 14724 - Train Loss: 0.093999, Train Acc: 0.856410 | Val Loss: 0.116239, Val Acc: 0.752577\n",
      "Epoch 14725 - Train Loss: 0.093995, Train Acc: 0.856410 | Val Loss: 0.116236, Val Acc: 0.752577\n",
      "Epoch 14726 - Train Loss: 0.093991, Train Acc: 0.856410 | Val Loss: 0.116234, Val Acc: 0.752577\n",
      "Epoch 14727 - Train Loss: 0.093987, Train Acc: 0.856410 | Val Loss: 0.116231, Val Acc: 0.752577\n",
      "Epoch 14728 - Train Loss: 0.093983, Train Acc: 0.856410 | Val Loss: 0.116228, Val Acc: 0.752577\n",
      "Epoch 14729 - Train Loss: 0.093979, Train Acc: 0.856410 | Val Loss: 0.116226, Val Acc: 0.752577\n",
      "Epoch 14730 - Train Loss: 0.093975, Train Acc: 0.856410 | Val Loss: 0.116223, Val Acc: 0.752577\n",
      "Epoch 14731 - Train Loss: 0.093971, Train Acc: 0.856410 | Val Loss: 0.116220, Val Acc: 0.752577\n",
      "Epoch 14732 - Train Loss: 0.093967, Train Acc: 0.856410 | Val Loss: 0.116218, Val Acc: 0.752577\n",
      "Epoch 14733 - Train Loss: 0.093963, Train Acc: 0.856410 | Val Loss: 0.116215, Val Acc: 0.752577\n",
      "Epoch 14734 - Train Loss: 0.093960, Train Acc: 0.856410 | Val Loss: 0.116213, Val Acc: 0.752577\n",
      "Epoch 14735 - Train Loss: 0.093956, Train Acc: 0.856410 | Val Loss: 0.116210, Val Acc: 0.752577\n",
      "Epoch 14736 - Train Loss: 0.093952, Train Acc: 0.856410 | Val Loss: 0.116207, Val Acc: 0.752577\n",
      "Epoch 14737 - Train Loss: 0.093948, Train Acc: 0.856410 | Val Loss: 0.116205, Val Acc: 0.752577\n",
      "Epoch 14738 - Train Loss: 0.093944, Train Acc: 0.856410 | Val Loss: 0.116202, Val Acc: 0.752577\n",
      "Epoch 14739 - Train Loss: 0.093940, Train Acc: 0.856410 | Val Loss: 0.116199, Val Acc: 0.752577\n",
      "Epoch 14740 - Train Loss: 0.093936, Train Acc: 0.856410 | Val Loss: 0.116197, Val Acc: 0.752577\n",
      "Epoch 14741 - Train Loss: 0.093932, Train Acc: 0.856410 | Val Loss: 0.116194, Val Acc: 0.752577\n",
      "Epoch 14742 - Train Loss: 0.093928, Train Acc: 0.856410 | Val Loss: 0.116191, Val Acc: 0.752577\n",
      "Epoch 14743 - Train Loss: 0.093924, Train Acc: 0.856410 | Val Loss: 0.116189, Val Acc: 0.752577\n",
      "Epoch 14744 - Train Loss: 0.093920, Train Acc: 0.856410 | Val Loss: 0.116186, Val Acc: 0.752577\n",
      "Epoch 14745 - Train Loss: 0.093916, Train Acc: 0.856410 | Val Loss: 0.116183, Val Acc: 0.752577\n",
      "Epoch 14746 - Train Loss: 0.093912, Train Acc: 0.856410 | Val Loss: 0.116181, Val Acc: 0.752577\n",
      "Epoch 14747 - Train Loss: 0.093909, Train Acc: 0.856410 | Val Loss: 0.116178, Val Acc: 0.752577\n",
      "Epoch 14748 - Train Loss: 0.093905, Train Acc: 0.856410 | Val Loss: 0.116176, Val Acc: 0.752577\n",
      "Epoch 14749 - Train Loss: 0.093901, Train Acc: 0.856410 | Val Loss: 0.116173, Val Acc: 0.752577\n",
      "Epoch 14750 - Train Loss: 0.093897, Train Acc: 0.856410 | Val Loss: 0.116170, Val Acc: 0.752577\n",
      "Epoch 14751 - Train Loss: 0.093893, Train Acc: 0.856410 | Val Loss: 0.116168, Val Acc: 0.752577\n",
      "Epoch 14752 - Train Loss: 0.093889, Train Acc: 0.856410 | Val Loss: 0.116165, Val Acc: 0.752577\n",
      "Epoch 14753 - Train Loss: 0.093885, Train Acc: 0.856410 | Val Loss: 0.116162, Val Acc: 0.752577\n",
      "Epoch 14754 - Train Loss: 0.093881, Train Acc: 0.856410 | Val Loss: 0.116160, Val Acc: 0.752577\n",
      "Epoch 14755 - Train Loss: 0.093877, Train Acc: 0.856410 | Val Loss: 0.116157, Val Acc: 0.752577\n",
      "Epoch 14756 - Train Loss: 0.093873, Train Acc: 0.856410 | Val Loss: 0.116155, Val Acc: 0.752577\n",
      "Epoch 14757 - Train Loss: 0.093869, Train Acc: 0.856410 | Val Loss: 0.116152, Val Acc: 0.752577\n",
      "Epoch 14758 - Train Loss: 0.093866, Train Acc: 0.856410 | Val Loss: 0.116149, Val Acc: 0.752577\n",
      "Epoch 14759 - Train Loss: 0.093862, Train Acc: 0.856410 | Val Loss: 0.116147, Val Acc: 0.752577\n",
      "Epoch 14760 - Train Loss: 0.093858, Train Acc: 0.856410 | Val Loss: 0.116144, Val Acc: 0.752577\n",
      "Epoch 14761 - Train Loss: 0.093854, Train Acc: 0.856410 | Val Loss: 0.116141, Val Acc: 0.752577\n",
      "Epoch 14762 - Train Loss: 0.093850, Train Acc: 0.856410 | Val Loss: 0.116139, Val Acc: 0.752577\n",
      "Epoch 14763 - Train Loss: 0.093846, Train Acc: 0.856410 | Val Loss: 0.116136, Val Acc: 0.752577\n",
      "Epoch 14764 - Train Loss: 0.093842, Train Acc: 0.856410 | Val Loss: 0.116133, Val Acc: 0.752577\n",
      "Epoch 14765 - Train Loss: 0.093838, Train Acc: 0.856410 | Val Loss: 0.116131, Val Acc: 0.752577\n",
      "Epoch 14766 - Train Loss: 0.093834, Train Acc: 0.856410 | Val Loss: 0.116128, Val Acc: 0.752577\n",
      "Epoch 14767 - Train Loss: 0.093830, Train Acc: 0.856410 | Val Loss: 0.116126, Val Acc: 0.752577\n",
      "Epoch 14768 - Train Loss: 0.093826, Train Acc: 0.856410 | Val Loss: 0.116123, Val Acc: 0.752577\n",
      "Epoch 14769 - Train Loss: 0.093823, Train Acc: 0.856410 | Val Loss: 0.116120, Val Acc: 0.752577\n",
      "Epoch 14770 - Train Loss: 0.093819, Train Acc: 0.856410 | Val Loss: 0.116118, Val Acc: 0.752577\n",
      "Epoch 14771 - Train Loss: 0.093815, Train Acc: 0.856410 | Val Loss: 0.116115, Val Acc: 0.752577\n",
      "Epoch 14772 - Train Loss: 0.093811, Train Acc: 0.856410 | Val Loss: 0.116113, Val Acc: 0.752577\n",
      "Epoch 14773 - Train Loss: 0.093807, Train Acc: 0.856410 | Val Loss: 0.116110, Val Acc: 0.752577\n",
      "Epoch 14774 - Train Loss: 0.093803, Train Acc: 0.856410 | Val Loss: 0.116107, Val Acc: 0.752577\n",
      "Epoch 14775 - Train Loss: 0.093799, Train Acc: 0.856410 | Val Loss: 0.116105, Val Acc: 0.752577\n",
      "Epoch 14776 - Train Loss: 0.093795, Train Acc: 0.856410 | Val Loss: 0.116102, Val Acc: 0.752577\n",
      "Epoch 14777 - Train Loss: 0.093791, Train Acc: 0.856410 | Val Loss: 0.116099, Val Acc: 0.752577\n",
      "Epoch 14778 - Train Loss: 0.093787, Train Acc: 0.856410 | Val Loss: 0.116097, Val Acc: 0.752577\n",
      "Epoch 14779 - Train Loss: 0.093783, Train Acc: 0.856410 | Val Loss: 0.116094, Val Acc: 0.752577\n",
      "Epoch 14780 - Train Loss: 0.093780, Train Acc: 0.856410 | Val Loss: 0.116092, Val Acc: 0.752577\n",
      "Epoch 14781 - Train Loss: 0.093776, Train Acc: 0.856410 | Val Loss: 0.116089, Val Acc: 0.752577\n",
      "Epoch 14782 - Train Loss: 0.093772, Train Acc: 0.857692 | Val Loss: 0.116086, Val Acc: 0.752577\n",
      "Epoch 14783 - Train Loss: 0.093768, Train Acc: 0.857692 | Val Loss: 0.116084, Val Acc: 0.752577\n",
      "Epoch 14784 - Train Loss: 0.093764, Train Acc: 0.857692 | Val Loss: 0.116081, Val Acc: 0.752577\n",
      "Epoch 14785 - Train Loss: 0.093760, Train Acc: 0.857692 | Val Loss: 0.116078, Val Acc: 0.752577\n",
      "Epoch 14786 - Train Loss: 0.093756, Train Acc: 0.857692 | Val Loss: 0.116076, Val Acc: 0.752577\n",
      "Epoch 14787 - Train Loss: 0.093752, Train Acc: 0.857692 | Val Loss: 0.116073, Val Acc: 0.752577\n",
      "Epoch 14788 - Train Loss: 0.093748, Train Acc: 0.857692 | Val Loss: 0.116071, Val Acc: 0.752577\n",
      "Epoch 14789 - Train Loss: 0.093745, Train Acc: 0.857692 | Val Loss: 0.116068, Val Acc: 0.752577\n",
      "Epoch 14790 - Train Loss: 0.093741, Train Acc: 0.857692 | Val Loss: 0.116065, Val Acc: 0.752577\n",
      "Epoch 14791 - Train Loss: 0.093737, Train Acc: 0.857692 | Val Loss: 0.116063, Val Acc: 0.752577\n",
      "Epoch 14792 - Train Loss: 0.093733, Train Acc: 0.857692 | Val Loss: 0.116060, Val Acc: 0.752577\n",
      "Epoch 14793 - Train Loss: 0.093729, Train Acc: 0.857692 | Val Loss: 0.116058, Val Acc: 0.752577\n",
      "Epoch 14794 - Train Loss: 0.093725, Train Acc: 0.857692 | Val Loss: 0.116055, Val Acc: 0.752577\n",
      "Epoch 14795 - Train Loss: 0.093721, Train Acc: 0.857692 | Val Loss: 0.116052, Val Acc: 0.752577\n",
      "Epoch 14796 - Train Loss: 0.093717, Train Acc: 0.857692 | Val Loss: 0.116050, Val Acc: 0.752577\n",
      "Epoch 14797 - Train Loss: 0.093713, Train Acc: 0.857692 | Val Loss: 0.116047, Val Acc: 0.752577\n",
      "Epoch 14798 - Train Loss: 0.093709, Train Acc: 0.857692 | Val Loss: 0.116044, Val Acc: 0.752577\n",
      "Epoch 14799 - Train Loss: 0.093706, Train Acc: 0.857692 | Val Loss: 0.116042, Val Acc: 0.752577\n",
      "Epoch 14800 - Train Loss: 0.093702, Train Acc: 0.857692 | Val Loss: 0.116039, Val Acc: 0.752577\n",
      "Epoch 14801 - Train Loss: 0.093698, Train Acc: 0.857692 | Val Loss: 0.116037, Val Acc: 0.752577\n",
      "Epoch 14802 - Train Loss: 0.093694, Train Acc: 0.857692 | Val Loss: 0.116034, Val Acc: 0.752577\n",
      "Epoch 14803 - Train Loss: 0.093690, Train Acc: 0.857692 | Val Loss: 0.116031, Val Acc: 0.752577\n",
      "Epoch 14804 - Train Loss: 0.093686, Train Acc: 0.857692 | Val Loss: 0.116029, Val Acc: 0.752577\n",
      "Epoch 14805 - Train Loss: 0.093682, Train Acc: 0.857692 | Val Loss: 0.116026, Val Acc: 0.752577\n",
      "Epoch 14806 - Train Loss: 0.093678, Train Acc: 0.857692 | Val Loss: 0.116024, Val Acc: 0.752577\n",
      "Epoch 14807 - Train Loss: 0.093674, Train Acc: 0.857692 | Val Loss: 0.116021, Val Acc: 0.752577\n",
      "Epoch 14808 - Train Loss: 0.093671, Train Acc: 0.857692 | Val Loss: 0.116018, Val Acc: 0.752577\n",
      "Epoch 14809 - Train Loss: 0.093667, Train Acc: 0.857692 | Val Loss: 0.116016, Val Acc: 0.752577\n",
      "Epoch 14810 - Train Loss: 0.093663, Train Acc: 0.857692 | Val Loss: 0.116013, Val Acc: 0.752577\n",
      "Epoch 14811 - Train Loss: 0.093659, Train Acc: 0.857692 | Val Loss: 0.116011, Val Acc: 0.752577\n",
      "Epoch 14812 - Train Loss: 0.093655, Train Acc: 0.857692 | Val Loss: 0.116008, Val Acc: 0.752577\n",
      "Epoch 14813 - Train Loss: 0.093651, Train Acc: 0.857692 | Val Loss: 0.116005, Val Acc: 0.752577\n",
      "Epoch 14814 - Train Loss: 0.093647, Train Acc: 0.857692 | Val Loss: 0.116003, Val Acc: 0.752577\n",
      "Epoch 14815 - Train Loss: 0.093643, Train Acc: 0.857692 | Val Loss: 0.116000, Val Acc: 0.752577\n",
      "Epoch 14816 - Train Loss: 0.093640, Train Acc: 0.857692 | Val Loss: 0.115998, Val Acc: 0.752577\n",
      "Epoch 14817 - Train Loss: 0.093636, Train Acc: 0.857692 | Val Loss: 0.115995, Val Acc: 0.752577\n",
      "Epoch 14818 - Train Loss: 0.093632, Train Acc: 0.857692 | Val Loss: 0.115992, Val Acc: 0.752577\n",
      "Epoch 14819 - Train Loss: 0.093628, Train Acc: 0.857692 | Val Loss: 0.115990, Val Acc: 0.752577\n",
      "Epoch 14820 - Train Loss: 0.093624, Train Acc: 0.857692 | Val Loss: 0.115987, Val Acc: 0.752577\n",
      "Epoch 14821 - Train Loss: 0.093620, Train Acc: 0.857692 | Val Loss: 0.115985, Val Acc: 0.752577\n",
      "Epoch 14822 - Train Loss: 0.093616, Train Acc: 0.857692 | Val Loss: 0.115982, Val Acc: 0.752577\n",
      "Epoch 14823 - Train Loss: 0.093612, Train Acc: 0.857692 | Val Loss: 0.115979, Val Acc: 0.752577\n",
      "Epoch 14824 - Train Loss: 0.093608, Train Acc: 0.857692 | Val Loss: 0.115977, Val Acc: 0.752577\n",
      "Epoch 14825 - Train Loss: 0.093605, Train Acc: 0.858974 | Val Loss: 0.115974, Val Acc: 0.752577\n",
      "Epoch 14826 - Train Loss: 0.093601, Train Acc: 0.858974 | Val Loss: 0.115972, Val Acc: 0.752577\n",
      "Epoch 14827 - Train Loss: 0.093597, Train Acc: 0.858974 | Val Loss: 0.115969, Val Acc: 0.752577\n",
      "Epoch 14828 - Train Loss: 0.093593, Train Acc: 0.858974 | Val Loss: 0.115966, Val Acc: 0.752577\n",
      "Epoch 14829 - Train Loss: 0.093589, Train Acc: 0.858974 | Val Loss: 0.115964, Val Acc: 0.752577\n",
      "Epoch 14830 - Train Loss: 0.093585, Train Acc: 0.858974 | Val Loss: 0.115961, Val Acc: 0.752577\n",
      "Epoch 14831 - Train Loss: 0.093581, Train Acc: 0.858974 | Val Loss: 0.115959, Val Acc: 0.752577\n",
      "Epoch 14832 - Train Loss: 0.093577, Train Acc: 0.858974 | Val Loss: 0.115956, Val Acc: 0.752577\n",
      "Epoch 14833 - Train Loss: 0.093574, Train Acc: 0.858974 | Val Loss: 0.115954, Val Acc: 0.752577\n",
      "Epoch 14834 - Train Loss: 0.093570, Train Acc: 0.858974 | Val Loss: 0.115951, Val Acc: 0.752577\n",
      "Epoch 14835 - Train Loss: 0.093566, Train Acc: 0.858974 | Val Loss: 0.115948, Val Acc: 0.752577\n",
      "Epoch 14836 - Train Loss: 0.093562, Train Acc: 0.858974 | Val Loss: 0.115946, Val Acc: 0.752577\n",
      "Epoch 14837 - Train Loss: 0.093558, Train Acc: 0.858974 | Val Loss: 0.115943, Val Acc: 0.752577\n",
      "Epoch 14838 - Train Loss: 0.093554, Train Acc: 0.858974 | Val Loss: 0.115941, Val Acc: 0.752577\n",
      "Epoch 14839 - Train Loss: 0.093550, Train Acc: 0.858974 | Val Loss: 0.115938, Val Acc: 0.752577\n",
      "Epoch 14840 - Train Loss: 0.093546, Train Acc: 0.858974 | Val Loss: 0.115935, Val Acc: 0.752577\n",
      "Epoch 14841 - Train Loss: 0.093543, Train Acc: 0.858974 | Val Loss: 0.115933, Val Acc: 0.752577\n",
      "Epoch 14842 - Train Loss: 0.093539, Train Acc: 0.858974 | Val Loss: 0.115930, Val Acc: 0.752577\n",
      "Epoch 14843 - Train Loss: 0.093535, Train Acc: 0.858974 | Val Loss: 0.115928, Val Acc: 0.752577\n",
      "Epoch 14844 - Train Loss: 0.093531, Train Acc: 0.858974 | Val Loss: 0.115925, Val Acc: 0.752577\n",
      "Epoch 14845 - Train Loss: 0.093527, Train Acc: 0.858974 | Val Loss: 0.115922, Val Acc: 0.752577\n",
      "Epoch 14846 - Train Loss: 0.093523, Train Acc: 0.858974 | Val Loss: 0.115920, Val Acc: 0.752577\n",
      "Epoch 14847 - Train Loss: 0.093519, Train Acc: 0.858974 | Val Loss: 0.115917, Val Acc: 0.752577\n",
      "Epoch 14848 - Train Loss: 0.093516, Train Acc: 0.858974 | Val Loss: 0.115915, Val Acc: 0.752577\n",
      "Epoch 14849 - Train Loss: 0.093512, Train Acc: 0.858974 | Val Loss: 0.115912, Val Acc: 0.752577\n",
      "Epoch 14850 - Train Loss: 0.093508, Train Acc: 0.858974 | Val Loss: 0.115910, Val Acc: 0.752577\n",
      "Epoch 14851 - Train Loss: 0.093504, Train Acc: 0.858974 | Val Loss: 0.115907, Val Acc: 0.752577\n",
      "Epoch 14852 - Train Loss: 0.093500, Train Acc: 0.858974 | Val Loss: 0.115904, Val Acc: 0.752577\n",
      "Epoch 14853 - Train Loss: 0.093496, Train Acc: 0.858974 | Val Loss: 0.115902, Val Acc: 0.752577\n",
      "Epoch 14854 - Train Loss: 0.093492, Train Acc: 0.858974 | Val Loss: 0.115899, Val Acc: 0.752577\n",
      "Epoch 14855 - Train Loss: 0.093488, Train Acc: 0.858974 | Val Loss: 0.115897, Val Acc: 0.752577\n",
      "Epoch 14856 - Train Loss: 0.093485, Train Acc: 0.858974 | Val Loss: 0.115894, Val Acc: 0.752577\n",
      "Epoch 14857 - Train Loss: 0.093481, Train Acc: 0.858974 | Val Loss: 0.115891, Val Acc: 0.752577\n",
      "Epoch 14858 - Train Loss: 0.093477, Train Acc: 0.858974 | Val Loss: 0.115889, Val Acc: 0.752577\n",
      "Epoch 14859 - Train Loss: 0.093473, Train Acc: 0.858974 | Val Loss: 0.115886, Val Acc: 0.752577\n",
      "Epoch 14860 - Train Loss: 0.093469, Train Acc: 0.858974 | Val Loss: 0.115884, Val Acc: 0.752577\n",
      "Epoch 14861 - Train Loss: 0.093465, Train Acc: 0.858974 | Val Loss: 0.115881, Val Acc: 0.752577\n",
      "Epoch 14862 - Train Loss: 0.093461, Train Acc: 0.858974 | Val Loss: 0.115879, Val Acc: 0.752577\n",
      "Epoch 14863 - Train Loss: 0.093458, Train Acc: 0.858974 | Val Loss: 0.115876, Val Acc: 0.752577\n",
      "Epoch 14864 - Train Loss: 0.093454, Train Acc: 0.858974 | Val Loss: 0.115873, Val Acc: 0.752577\n",
      "Epoch 14865 - Train Loss: 0.093450, Train Acc: 0.858974 | Val Loss: 0.115871, Val Acc: 0.752577\n",
      "Epoch 14866 - Train Loss: 0.093446, Train Acc: 0.858974 | Val Loss: 0.115868, Val Acc: 0.752577\n",
      "Epoch 14867 - Train Loss: 0.093442, Train Acc: 0.858974 | Val Loss: 0.115866, Val Acc: 0.752577\n",
      "Epoch 14868 - Train Loss: 0.093438, Train Acc: 0.858974 | Val Loss: 0.115863, Val Acc: 0.752577\n",
      "Epoch 14869 - Train Loss: 0.093434, Train Acc: 0.858974 | Val Loss: 0.115861, Val Acc: 0.752577\n",
      "Epoch 14870 - Train Loss: 0.093431, Train Acc: 0.858974 | Val Loss: 0.115858, Val Acc: 0.752577\n",
      "Epoch 14871 - Train Loss: 0.093427, Train Acc: 0.858974 | Val Loss: 0.115855, Val Acc: 0.752577\n",
      "Epoch 14872 - Train Loss: 0.093423, Train Acc: 0.858974 | Val Loss: 0.115853, Val Acc: 0.752577\n",
      "Epoch 14873 - Train Loss: 0.093419, Train Acc: 0.858974 | Val Loss: 0.115850, Val Acc: 0.752577\n",
      "Epoch 14874 - Train Loss: 0.093415, Train Acc: 0.858974 | Val Loss: 0.115848, Val Acc: 0.752577\n",
      "Epoch 14875 - Train Loss: 0.093411, Train Acc: 0.858974 | Val Loss: 0.115845, Val Acc: 0.752577\n",
      "Epoch 14876 - Train Loss: 0.093407, Train Acc: 0.858974 | Val Loss: 0.115843, Val Acc: 0.752577\n",
      "Epoch 14877 - Train Loss: 0.093404, Train Acc: 0.858974 | Val Loss: 0.115840, Val Acc: 0.752577\n",
      "Epoch 14878 - Train Loss: 0.093400, Train Acc: 0.858974 | Val Loss: 0.115837, Val Acc: 0.752577\n",
      "Epoch 14879 - Train Loss: 0.093396, Train Acc: 0.858974 | Val Loss: 0.115835, Val Acc: 0.752577\n",
      "Epoch 14880 - Train Loss: 0.093392, Train Acc: 0.858974 | Val Loss: 0.115832, Val Acc: 0.752577\n",
      "Epoch 14881 - Train Loss: 0.093388, Train Acc: 0.858974 | Val Loss: 0.115830, Val Acc: 0.752577\n",
      "Epoch 14882 - Train Loss: 0.093384, Train Acc: 0.858974 | Val Loss: 0.115827, Val Acc: 0.752577\n",
      "Epoch 14883 - Train Loss: 0.093381, Train Acc: 0.858974 | Val Loss: 0.115825, Val Acc: 0.752577\n",
      "Epoch 14884 - Train Loss: 0.093377, Train Acc: 0.858974 | Val Loss: 0.115822, Val Acc: 0.752577\n",
      "Epoch 14885 - Train Loss: 0.093373, Train Acc: 0.858974 | Val Loss: 0.115819, Val Acc: 0.752577\n",
      "Epoch 14886 - Train Loss: 0.093369, Train Acc: 0.858974 | Val Loss: 0.115817, Val Acc: 0.752577\n",
      "Epoch 14887 - Train Loss: 0.093365, Train Acc: 0.858974 | Val Loss: 0.115814, Val Acc: 0.752577\n",
      "Epoch 14888 - Train Loss: 0.093361, Train Acc: 0.858974 | Val Loss: 0.115812, Val Acc: 0.752577\n",
      "Epoch 14889 - Train Loss: 0.093357, Train Acc: 0.858974 | Val Loss: 0.115809, Val Acc: 0.752577\n",
      "Epoch 14890 - Train Loss: 0.093354, Train Acc: 0.858974 | Val Loss: 0.115807, Val Acc: 0.752577\n",
      "Epoch 14891 - Train Loss: 0.093350, Train Acc: 0.858974 | Val Loss: 0.115804, Val Acc: 0.752577\n",
      "Epoch 14892 - Train Loss: 0.093346, Train Acc: 0.858974 | Val Loss: 0.115802, Val Acc: 0.752577\n",
      "Epoch 14893 - Train Loss: 0.093342, Train Acc: 0.858974 | Val Loss: 0.115799, Val Acc: 0.752577\n",
      "Epoch 14894 - Train Loss: 0.093338, Train Acc: 0.858974 | Val Loss: 0.115796, Val Acc: 0.752577\n",
      "Epoch 14895 - Train Loss: 0.093334, Train Acc: 0.858974 | Val Loss: 0.115794, Val Acc: 0.752577\n",
      "Epoch 14896 - Train Loss: 0.093331, Train Acc: 0.858974 | Val Loss: 0.115791, Val Acc: 0.752577\n",
      "Epoch 14897 - Train Loss: 0.093327, Train Acc: 0.858974 | Val Loss: 0.115789, Val Acc: 0.752577\n",
      "Epoch 14898 - Train Loss: 0.093323, Train Acc: 0.858974 | Val Loss: 0.115786, Val Acc: 0.752577\n",
      "Epoch 14899 - Train Loss: 0.093319, Train Acc: 0.858974 | Val Loss: 0.115784, Val Acc: 0.752577\n",
      "Epoch 14900 - Train Loss: 0.093315, Train Acc: 0.858974 | Val Loss: 0.115781, Val Acc: 0.752577\n",
      "Epoch 14901 - Train Loss: 0.093311, Train Acc: 0.858974 | Val Loss: 0.115779, Val Acc: 0.752577\n",
      "Epoch 14902 - Train Loss: 0.093308, Train Acc: 0.858974 | Val Loss: 0.115776, Val Acc: 0.752577\n",
      "Epoch 14903 - Train Loss: 0.093304, Train Acc: 0.858974 | Val Loss: 0.115773, Val Acc: 0.752577\n",
      "Epoch 14904 - Train Loss: 0.093300, Train Acc: 0.858974 | Val Loss: 0.115771, Val Acc: 0.752577\n",
      "Epoch 14905 - Train Loss: 0.093296, Train Acc: 0.858974 | Val Loss: 0.115768, Val Acc: 0.752577\n",
      "Epoch 14906 - Train Loss: 0.093292, Train Acc: 0.858974 | Val Loss: 0.115766, Val Acc: 0.752577\n",
      "Epoch 14907 - Train Loss: 0.093288, Train Acc: 0.858974 | Val Loss: 0.115763, Val Acc: 0.752577\n",
      "Epoch 14908 - Train Loss: 0.093284, Train Acc: 0.858974 | Val Loss: 0.115761, Val Acc: 0.752577\n",
      "Epoch 14909 - Train Loss: 0.093281, Train Acc: 0.858974 | Val Loss: 0.115758, Val Acc: 0.752577\n",
      "Epoch 14910 - Train Loss: 0.093277, Train Acc: 0.858974 | Val Loss: 0.115756, Val Acc: 0.752577\n",
      "Epoch 14911 - Train Loss: 0.093273, Train Acc: 0.858974 | Val Loss: 0.115753, Val Acc: 0.752577\n",
      "Epoch 14912 - Train Loss: 0.093269, Train Acc: 0.858974 | Val Loss: 0.115751, Val Acc: 0.752577\n",
      "Epoch 14913 - Train Loss: 0.093265, Train Acc: 0.858974 | Val Loss: 0.115748, Val Acc: 0.752577\n",
      "Epoch 14914 - Train Loss: 0.093261, Train Acc: 0.858974 | Val Loss: 0.115746, Val Acc: 0.752577\n",
      "Epoch 14915 - Train Loss: 0.093258, Train Acc: 0.858974 | Val Loss: 0.115743, Val Acc: 0.752577\n",
      "Epoch 14916 - Train Loss: 0.093254, Train Acc: 0.858974 | Val Loss: 0.115741, Val Acc: 0.752577\n",
      "Epoch 14917 - Train Loss: 0.093250, Train Acc: 0.858974 | Val Loss: 0.115738, Val Acc: 0.752577\n",
      "Epoch 14918 - Train Loss: 0.093246, Train Acc: 0.858974 | Val Loss: 0.115736, Val Acc: 0.752577\n",
      "Epoch 14919 - Train Loss: 0.093242, Train Acc: 0.858974 | Val Loss: 0.115733, Val Acc: 0.752577\n",
      "Epoch 14920 - Train Loss: 0.093238, Train Acc: 0.858974 | Val Loss: 0.115731, Val Acc: 0.752577\n",
      "Epoch 14921 - Train Loss: 0.093235, Train Acc: 0.858974 | Val Loss: 0.115728, Val Acc: 0.752577\n",
      "Epoch 14922 - Train Loss: 0.093231, Train Acc: 0.858974 | Val Loss: 0.115726, Val Acc: 0.752577\n",
      "Epoch 14923 - Train Loss: 0.093227, Train Acc: 0.858974 | Val Loss: 0.115723, Val Acc: 0.752577\n",
      "Epoch 14924 - Train Loss: 0.093223, Train Acc: 0.858974 | Val Loss: 0.115721, Val Acc: 0.752577\n",
      "Epoch 14925 - Train Loss: 0.093219, Train Acc: 0.858974 | Val Loss: 0.115718, Val Acc: 0.752577\n",
      "Epoch 14926 - Train Loss: 0.093215, Train Acc: 0.858974 | Val Loss: 0.115716, Val Acc: 0.752577\n",
      "Epoch 14927 - Train Loss: 0.093212, Train Acc: 0.858974 | Val Loss: 0.115713, Val Acc: 0.752577\n",
      "Epoch 14928 - Train Loss: 0.093208, Train Acc: 0.858974 | Val Loss: 0.115711, Val Acc: 0.752577\n",
      "Epoch 14929 - Train Loss: 0.093204, Train Acc: 0.858974 | Val Loss: 0.115708, Val Acc: 0.752577\n",
      "Epoch 14930 - Train Loss: 0.093200, Train Acc: 0.858974 | Val Loss: 0.115706, Val Acc: 0.752577\n",
      "Epoch 14931 - Train Loss: 0.093196, Train Acc: 0.858974 | Val Loss: 0.115703, Val Acc: 0.752577\n",
      "Epoch 14932 - Train Loss: 0.093192, Train Acc: 0.858974 | Val Loss: 0.115701, Val Acc: 0.752577\n",
      "Epoch 14933 - Train Loss: 0.093189, Train Acc: 0.858974 | Val Loss: 0.115698, Val Acc: 0.752577\n",
      "Epoch 14934 - Train Loss: 0.093185, Train Acc: 0.860256 | Val Loss: 0.115696, Val Acc: 0.752577\n",
      "Epoch 14935 - Train Loss: 0.093181, Train Acc: 0.860256 | Val Loss: 0.115693, Val Acc: 0.752577\n",
      "Epoch 14936 - Train Loss: 0.093177, Train Acc: 0.860256 | Val Loss: 0.115691, Val Acc: 0.752577\n",
      "Epoch 14937 - Train Loss: 0.093173, Train Acc: 0.860256 | Val Loss: 0.115688, Val Acc: 0.752577\n",
      "Epoch 14938 - Train Loss: 0.093169, Train Acc: 0.860256 | Val Loss: 0.115686, Val Acc: 0.752577\n",
      "Epoch 14939 - Train Loss: 0.093166, Train Acc: 0.860256 | Val Loss: 0.115683, Val Acc: 0.752577\n",
      "Epoch 14940 - Train Loss: 0.093162, Train Acc: 0.860256 | Val Loss: 0.115681, Val Acc: 0.752577\n",
      "Epoch 14941 - Train Loss: 0.093158, Train Acc: 0.860256 | Val Loss: 0.115678, Val Acc: 0.752577\n",
      "Epoch 14942 - Train Loss: 0.093154, Train Acc: 0.860256 | Val Loss: 0.115675, Val Acc: 0.752577\n",
      "Epoch 14943 - Train Loss: 0.093150, Train Acc: 0.860256 | Val Loss: 0.115673, Val Acc: 0.752577\n",
      "Epoch 14944 - Train Loss: 0.093147, Train Acc: 0.860256 | Val Loss: 0.115670, Val Acc: 0.752577\n",
      "Epoch 14945 - Train Loss: 0.093143, Train Acc: 0.860256 | Val Loss: 0.115668, Val Acc: 0.752577\n",
      "Epoch 14946 - Train Loss: 0.093139, Train Acc: 0.860256 | Val Loss: 0.115665, Val Acc: 0.752577\n",
      "Epoch 14947 - Train Loss: 0.093135, Train Acc: 0.860256 | Val Loss: 0.115663, Val Acc: 0.752577\n",
      "Epoch 14948 - Train Loss: 0.093131, Train Acc: 0.860256 | Val Loss: 0.115660, Val Acc: 0.752577\n",
      "Epoch 14949 - Train Loss: 0.093127, Train Acc: 0.860256 | Val Loss: 0.115658, Val Acc: 0.752577\n",
      "Epoch 14950 - Train Loss: 0.093124, Train Acc: 0.860256 | Val Loss: 0.115655, Val Acc: 0.752577\n",
      "Epoch 14951 - Train Loss: 0.093120, Train Acc: 0.860256 | Val Loss: 0.115653, Val Acc: 0.752577\n",
      "Epoch 14952 - Train Loss: 0.093116, Train Acc: 0.860256 | Val Loss: 0.115650, Val Acc: 0.752577\n",
      "Epoch 14953 - Train Loss: 0.093112, Train Acc: 0.861538 | Val Loss: 0.115648, Val Acc: 0.752577\n",
      "Epoch 14954 - Train Loss: 0.093108, Train Acc: 0.861538 | Val Loss: 0.115645, Val Acc: 0.752577\n",
      "Epoch 14955 - Train Loss: 0.093105, Train Acc: 0.861538 | Val Loss: 0.115643, Val Acc: 0.752577\n",
      "Epoch 14956 - Train Loss: 0.093101, Train Acc: 0.861538 | Val Loss: 0.115640, Val Acc: 0.752577\n",
      "Epoch 14957 - Train Loss: 0.093097, Train Acc: 0.861538 | Val Loss: 0.115638, Val Acc: 0.752577\n",
      "Epoch 14958 - Train Loss: 0.093093, Train Acc: 0.861538 | Val Loss: 0.115635, Val Acc: 0.752577\n",
      "Epoch 14959 - Train Loss: 0.093089, Train Acc: 0.861538 | Val Loss: 0.115633, Val Acc: 0.752577\n",
      "Epoch 14960 - Train Loss: 0.093085, Train Acc: 0.861538 | Val Loss: 0.115630, Val Acc: 0.752577\n",
      "Epoch 14961 - Train Loss: 0.093082, Train Acc: 0.861538 | Val Loss: 0.115628, Val Acc: 0.752577\n",
      "Epoch 14962 - Train Loss: 0.093078, Train Acc: 0.861538 | Val Loss: 0.115625, Val Acc: 0.752577\n",
      "Epoch 14963 - Train Loss: 0.093074, Train Acc: 0.861538 | Val Loss: 0.115623, Val Acc: 0.752577\n",
      "Epoch 14964 - Train Loss: 0.093070, Train Acc: 0.861538 | Val Loss: 0.115620, Val Acc: 0.752577\n",
      "Epoch 14965 - Train Loss: 0.093066, Train Acc: 0.861538 | Val Loss: 0.115618, Val Acc: 0.752577\n",
      "Epoch 14966 - Train Loss: 0.093063, Train Acc: 0.861538 | Val Loss: 0.115615, Val Acc: 0.752577\n",
      "Epoch 14967 - Train Loss: 0.093059, Train Acc: 0.861538 | Val Loss: 0.115613, Val Acc: 0.752577\n",
      "Epoch 14968 - Train Loss: 0.093055, Train Acc: 0.861538 | Val Loss: 0.115610, Val Acc: 0.752577\n",
      "Epoch 14969 - Train Loss: 0.093051, Train Acc: 0.861538 | Val Loss: 0.115608, Val Acc: 0.752577\n",
      "Epoch 14970 - Train Loss: 0.093047, Train Acc: 0.861538 | Val Loss: 0.115606, Val Acc: 0.752577\n",
      "Epoch 14971 - Train Loss: 0.093043, Train Acc: 0.861538 | Val Loss: 0.115603, Val Acc: 0.752577\n",
      "Epoch 14972 - Train Loss: 0.093040, Train Acc: 0.861538 | Val Loss: 0.115601, Val Acc: 0.752577\n",
      "Epoch 14973 - Train Loss: 0.093036, Train Acc: 0.861538 | Val Loss: 0.115598, Val Acc: 0.752577\n",
      "Epoch 14974 - Train Loss: 0.093032, Train Acc: 0.861538 | Val Loss: 0.115596, Val Acc: 0.752577\n",
      "Epoch 14975 - Train Loss: 0.093028, Train Acc: 0.861538 | Val Loss: 0.115593, Val Acc: 0.752577\n",
      "Epoch 14976 - Train Loss: 0.093024, Train Acc: 0.861538 | Val Loss: 0.115591, Val Acc: 0.752577\n",
      "Epoch 14977 - Train Loss: 0.093021, Train Acc: 0.861538 | Val Loss: 0.115588, Val Acc: 0.752577\n",
      "Epoch 14978 - Train Loss: 0.093017, Train Acc: 0.861538 | Val Loss: 0.115586, Val Acc: 0.752577\n",
      "Epoch 14979 - Train Loss: 0.093013, Train Acc: 0.861538 | Val Loss: 0.115583, Val Acc: 0.752577\n",
      "Epoch 14980 - Train Loss: 0.093009, Train Acc: 0.861538 | Val Loss: 0.115581, Val Acc: 0.752577\n",
      "Epoch 14981 - Train Loss: 0.093005, Train Acc: 0.861538 | Val Loss: 0.115578, Val Acc: 0.752577\n",
      "Epoch 14982 - Train Loss: 0.093002, Train Acc: 0.861538 | Val Loss: 0.115576, Val Acc: 0.752577\n",
      "Epoch 14983 - Train Loss: 0.092998, Train Acc: 0.861538 | Val Loss: 0.115573, Val Acc: 0.752577\n",
      "Epoch 14984 - Train Loss: 0.092994, Train Acc: 0.861538 | Val Loss: 0.115571, Val Acc: 0.752577\n",
      "Epoch 14985 - Train Loss: 0.092990, Train Acc: 0.861538 | Val Loss: 0.115568, Val Acc: 0.752577\n",
      "Epoch 14986 - Train Loss: 0.092986, Train Acc: 0.861538 | Val Loss: 0.115566, Val Acc: 0.752577\n",
      "Epoch 14987 - Train Loss: 0.092983, Train Acc: 0.861538 | Val Loss: 0.115563, Val Acc: 0.752577\n",
      "Epoch 14988 - Train Loss: 0.092979, Train Acc: 0.861538 | Val Loss: 0.115561, Val Acc: 0.752577\n",
      "Epoch 14989 - Train Loss: 0.092975, Train Acc: 0.861538 | Val Loss: 0.115558, Val Acc: 0.752577\n",
      "Epoch 14990 - Train Loss: 0.092971, Train Acc: 0.861538 | Val Loss: 0.115556, Val Acc: 0.752577\n",
      "Epoch 14991 - Train Loss: 0.092967, Train Acc: 0.861538 | Val Loss: 0.115553, Val Acc: 0.752577\n",
      "Epoch 14992 - Train Loss: 0.092964, Train Acc: 0.861538 | Val Loss: 0.115551, Val Acc: 0.752577\n",
      "Epoch 14993 - Train Loss: 0.092960, Train Acc: 0.861538 | Val Loss: 0.115548, Val Acc: 0.752577\n",
      "Epoch 14994 - Train Loss: 0.092956, Train Acc: 0.861538 | Val Loss: 0.115546, Val Acc: 0.752577\n",
      "Epoch 14995 - Train Loss: 0.092952, Train Acc: 0.861538 | Val Loss: 0.115543, Val Acc: 0.752577\n",
      "Epoch 14996 - Train Loss: 0.092948, Train Acc: 0.861538 | Val Loss: 0.115541, Val Acc: 0.752577\n",
      "Epoch 14997 - Train Loss: 0.092945, Train Acc: 0.861538 | Val Loss: 0.115538, Val Acc: 0.752577\n",
      "Epoch 14998 - Train Loss: 0.092941, Train Acc: 0.861538 | Val Loss: 0.115536, Val Acc: 0.752577\n",
      "Epoch 14999 - Train Loss: 0.092937, Train Acc: 0.861538 | Val Loss: 0.115533, Val Acc: 0.752577\n",
      "Epoch 15000 - Train Loss: 0.092933, Train Acc: 0.861538 | Val Loss: 0.115531, Val Acc: 0.752577\n",
      "Epoch 15001 - Train Loss: 0.092929, Train Acc: 0.861538 | Val Loss: 0.115528, Val Acc: 0.752577\n",
      "Epoch 15002 - Train Loss: 0.092926, Train Acc: 0.861538 | Val Loss: 0.115526, Val Acc: 0.752577\n",
      "Epoch 15003 - Train Loss: 0.092922, Train Acc: 0.862821 | Val Loss: 0.115524, Val Acc: 0.752577\n",
      "Epoch 15004 - Train Loss: 0.092918, Train Acc: 0.862821 | Val Loss: 0.115521, Val Acc: 0.752577\n",
      "Epoch 15005 - Train Loss: 0.092914, Train Acc: 0.862821 | Val Loss: 0.115519, Val Acc: 0.752577\n",
      "Epoch 15006 - Train Loss: 0.092910, Train Acc: 0.862821 | Val Loss: 0.115516, Val Acc: 0.752577\n",
      "Epoch 15007 - Train Loss: 0.092907, Train Acc: 0.862821 | Val Loss: 0.115514, Val Acc: 0.752577\n",
      "Epoch 15008 - Train Loss: 0.092903, Train Acc: 0.862821 | Val Loss: 0.115511, Val Acc: 0.752577\n",
      "Epoch 15009 - Train Loss: 0.092899, Train Acc: 0.862821 | Val Loss: 0.115509, Val Acc: 0.752577\n",
      "Epoch 15010 - Train Loss: 0.092895, Train Acc: 0.862821 | Val Loss: 0.115506, Val Acc: 0.752577\n",
      "Epoch 15011 - Train Loss: 0.092891, Train Acc: 0.862821 | Val Loss: 0.115504, Val Acc: 0.752577\n",
      "Epoch 15012 - Train Loss: 0.092888, Train Acc: 0.862821 | Val Loss: 0.115501, Val Acc: 0.752577\n",
      "Epoch 15013 - Train Loss: 0.092884, Train Acc: 0.862821 | Val Loss: 0.115499, Val Acc: 0.752577\n",
      "Epoch 15014 - Train Loss: 0.092880, Train Acc: 0.862821 | Val Loss: 0.115496, Val Acc: 0.752577\n",
      "Epoch 15015 - Train Loss: 0.092876, Train Acc: 0.862821 | Val Loss: 0.115494, Val Acc: 0.752577\n",
      "Epoch 15016 - Train Loss: 0.092873, Train Acc: 0.862821 | Val Loss: 0.115491, Val Acc: 0.752577\n",
      "Epoch 15017 - Train Loss: 0.092869, Train Acc: 0.862821 | Val Loss: 0.115489, Val Acc: 0.752577\n",
      "Epoch 15018 - Train Loss: 0.092865, Train Acc: 0.862821 | Val Loss: 0.115486, Val Acc: 0.752577\n",
      "Epoch 15019 - Train Loss: 0.092861, Train Acc: 0.862821 | Val Loss: 0.115484, Val Acc: 0.752577\n",
      "Epoch 15020 - Train Loss: 0.092857, Train Acc: 0.862821 | Val Loss: 0.115482, Val Acc: 0.752577\n",
      "Epoch 15021 - Train Loss: 0.092854, Train Acc: 0.862821 | Val Loss: 0.115479, Val Acc: 0.752577\n",
      "Epoch 15022 - Train Loss: 0.092850, Train Acc: 0.862821 | Val Loss: 0.115477, Val Acc: 0.752577\n",
      "Epoch 15023 - Train Loss: 0.092846, Train Acc: 0.862821 | Val Loss: 0.115474, Val Acc: 0.752577\n",
      "Epoch 15024 - Train Loss: 0.092842, Train Acc: 0.862821 | Val Loss: 0.115472, Val Acc: 0.752577\n",
      "Epoch 15025 - Train Loss: 0.092838, Train Acc: 0.862821 | Val Loss: 0.115469, Val Acc: 0.752577\n",
      "Epoch 15026 - Train Loss: 0.092835, Train Acc: 0.862821 | Val Loss: 0.115467, Val Acc: 0.752577\n",
      "Epoch 15027 - Train Loss: 0.092831, Train Acc: 0.862821 | Val Loss: 0.115464, Val Acc: 0.752577\n",
      "Epoch 15028 - Train Loss: 0.092827, Train Acc: 0.862821 | Val Loss: 0.115462, Val Acc: 0.752577\n",
      "Epoch 15029 - Train Loss: 0.092823, Train Acc: 0.862821 | Val Loss: 0.115459, Val Acc: 0.752577\n",
      "Epoch 15030 - Train Loss: 0.092820, Train Acc: 0.862821 | Val Loss: 0.115457, Val Acc: 0.752577\n",
      "Epoch 15031 - Train Loss: 0.092816, Train Acc: 0.862821 | Val Loss: 0.115454, Val Acc: 0.752577\n",
      "Epoch 15032 - Train Loss: 0.092812, Train Acc: 0.862821 | Val Loss: 0.115452, Val Acc: 0.752577\n",
      "Epoch 15033 - Train Loss: 0.092808, Train Acc: 0.862821 | Val Loss: 0.115449, Val Acc: 0.752577\n",
      "Epoch 15034 - Train Loss: 0.092804, Train Acc: 0.862821 | Val Loss: 0.115447, Val Acc: 0.752577\n",
      "Epoch 15035 - Train Loss: 0.092801, Train Acc: 0.862821 | Val Loss: 0.115445, Val Acc: 0.752577\n",
      "Epoch 15036 - Train Loss: 0.092797, Train Acc: 0.861538 | Val Loss: 0.115442, Val Acc: 0.752577\n",
      "Epoch 15037 - Train Loss: 0.092793, Train Acc: 0.861538 | Val Loss: 0.115440, Val Acc: 0.752577\n",
      "Epoch 15038 - Train Loss: 0.092789, Train Acc: 0.861538 | Val Loss: 0.115437, Val Acc: 0.752577\n",
      "Epoch 15039 - Train Loss: 0.092786, Train Acc: 0.861538 | Val Loss: 0.115435, Val Acc: 0.752577\n",
      "Epoch 15040 - Train Loss: 0.092782, Train Acc: 0.861538 | Val Loss: 0.115432, Val Acc: 0.752577\n",
      "Epoch 15041 - Train Loss: 0.092778, Train Acc: 0.861538 | Val Loss: 0.115430, Val Acc: 0.752577\n",
      "Epoch 15042 - Train Loss: 0.092774, Train Acc: 0.861538 | Val Loss: 0.115427, Val Acc: 0.752577\n",
      "Epoch 15043 - Train Loss: 0.092770, Train Acc: 0.861538 | Val Loss: 0.115425, Val Acc: 0.752577\n",
      "Epoch 15044 - Train Loss: 0.092767, Train Acc: 0.861538 | Val Loss: 0.115422, Val Acc: 0.752577\n",
      "Epoch 15045 - Train Loss: 0.092763, Train Acc: 0.861538 | Val Loss: 0.115420, Val Acc: 0.752577\n",
      "Epoch 15046 - Train Loss: 0.092759, Train Acc: 0.861538 | Val Loss: 0.115417, Val Acc: 0.752577\n",
      "Epoch 15047 - Train Loss: 0.092755, Train Acc: 0.861538 | Val Loss: 0.115415, Val Acc: 0.752577\n",
      "Epoch 15048 - Train Loss: 0.092752, Train Acc: 0.861538 | Val Loss: 0.115413, Val Acc: 0.752577\n",
      "Epoch 15049 - Train Loss: 0.092748, Train Acc: 0.861538 | Val Loss: 0.115410, Val Acc: 0.752577\n",
      "Epoch 15050 - Train Loss: 0.092744, Train Acc: 0.861538 | Val Loss: 0.115408, Val Acc: 0.752577\n",
      "Epoch 15051 - Train Loss: 0.092740, Train Acc: 0.861538 | Val Loss: 0.115405, Val Acc: 0.752577\n",
      "Epoch 15052 - Train Loss: 0.092736, Train Acc: 0.861538 | Val Loss: 0.115403, Val Acc: 0.752577\n",
      "Epoch 15053 - Train Loss: 0.092733, Train Acc: 0.861538 | Val Loss: 0.115400, Val Acc: 0.752577\n",
      "Epoch 15054 - Train Loss: 0.092729, Train Acc: 0.861538 | Val Loss: 0.115398, Val Acc: 0.752577\n",
      "Epoch 15055 - Train Loss: 0.092725, Train Acc: 0.861538 | Val Loss: 0.115395, Val Acc: 0.752577\n",
      "Epoch 15056 - Train Loss: 0.092721, Train Acc: 0.861538 | Val Loss: 0.115393, Val Acc: 0.752577\n",
      "Epoch 15057 - Train Loss: 0.092718, Train Acc: 0.861538 | Val Loss: 0.115390, Val Acc: 0.752577\n",
      "Epoch 15058 - Train Loss: 0.092714, Train Acc: 0.861538 | Val Loss: 0.115388, Val Acc: 0.752577\n",
      "Epoch 15059 - Train Loss: 0.092710, Train Acc: 0.861538 | Val Loss: 0.115386, Val Acc: 0.752577\n",
      "Epoch 15060 - Train Loss: 0.092706, Train Acc: 0.861538 | Val Loss: 0.115383, Val Acc: 0.752577\n",
      "Epoch 15061 - Train Loss: 0.092703, Train Acc: 0.861538 | Val Loss: 0.115381, Val Acc: 0.752577\n",
      "Epoch 15062 - Train Loss: 0.092699, Train Acc: 0.861538 | Val Loss: 0.115378, Val Acc: 0.752577\n",
      "Epoch 15063 - Train Loss: 0.092695, Train Acc: 0.861538 | Val Loss: 0.115376, Val Acc: 0.752577\n",
      "Epoch 15064 - Train Loss: 0.092691, Train Acc: 0.861538 | Val Loss: 0.115373, Val Acc: 0.752577\n",
      "Epoch 15065 - Train Loss: 0.092688, Train Acc: 0.861538 | Val Loss: 0.115371, Val Acc: 0.752577\n",
      "Epoch 15066 - Train Loss: 0.092684, Train Acc: 0.861538 | Val Loss: 0.115368, Val Acc: 0.752577\n",
      "Epoch 15067 - Train Loss: 0.092680, Train Acc: 0.861538 | Val Loss: 0.115366, Val Acc: 0.752577\n",
      "Epoch 15068 - Train Loss: 0.092676, Train Acc: 0.861538 | Val Loss: 0.115364, Val Acc: 0.752577\n",
      "Epoch 15069 - Train Loss: 0.092672, Train Acc: 0.861538 | Val Loss: 0.115361, Val Acc: 0.752577\n",
      "Epoch 15070 - Train Loss: 0.092669, Train Acc: 0.861538 | Val Loss: 0.115359, Val Acc: 0.752577\n",
      "Epoch 15071 - Train Loss: 0.092665, Train Acc: 0.861538 | Val Loss: 0.115356, Val Acc: 0.752577\n",
      "Epoch 15072 - Train Loss: 0.092661, Train Acc: 0.861538 | Val Loss: 0.115354, Val Acc: 0.752577\n",
      "Epoch 15073 - Train Loss: 0.092657, Train Acc: 0.861538 | Val Loss: 0.115351, Val Acc: 0.752577\n",
      "Epoch 15074 - Train Loss: 0.092654, Train Acc: 0.861538 | Val Loss: 0.115349, Val Acc: 0.752577\n",
      "Epoch 15075 - Train Loss: 0.092650, Train Acc: 0.861538 | Val Loss: 0.115346, Val Acc: 0.752577\n",
      "Epoch 15076 - Train Loss: 0.092646, Train Acc: 0.861538 | Val Loss: 0.115344, Val Acc: 0.752577\n",
      "Epoch 15077 - Train Loss: 0.092642, Train Acc: 0.861538 | Val Loss: 0.115342, Val Acc: 0.752577\n",
      "Epoch 15078 - Train Loss: 0.092639, Train Acc: 0.861538 | Val Loss: 0.115339, Val Acc: 0.752577\n",
      "Epoch 15079 - Train Loss: 0.092635, Train Acc: 0.861538 | Val Loss: 0.115337, Val Acc: 0.752577\n",
      "Epoch 15080 - Train Loss: 0.092631, Train Acc: 0.861538 | Val Loss: 0.115334, Val Acc: 0.752577\n",
      "Epoch 15081 - Train Loss: 0.092627, Train Acc: 0.861538 | Val Loss: 0.115332, Val Acc: 0.752577\n",
      "Epoch 15082 - Train Loss: 0.092624, Train Acc: 0.861538 | Val Loss: 0.115329, Val Acc: 0.752577\n",
      "Epoch 15083 - Train Loss: 0.092620, Train Acc: 0.861538 | Val Loss: 0.115327, Val Acc: 0.752577\n",
      "Epoch 15084 - Train Loss: 0.092616, Train Acc: 0.861538 | Val Loss: 0.115325, Val Acc: 0.752577\n",
      "Epoch 15085 - Train Loss: 0.092612, Train Acc: 0.861538 | Val Loss: 0.115322, Val Acc: 0.752577\n",
      "Epoch 15086 - Train Loss: 0.092609, Train Acc: 0.861538 | Val Loss: 0.115320, Val Acc: 0.752577\n",
      "Epoch 15087 - Train Loss: 0.092605, Train Acc: 0.861538 | Val Loss: 0.115317, Val Acc: 0.752577\n",
      "Epoch 15088 - Train Loss: 0.092601, Train Acc: 0.861538 | Val Loss: 0.115315, Val Acc: 0.752577\n",
      "Epoch 15089 - Train Loss: 0.092597, Train Acc: 0.861538 | Val Loss: 0.115312, Val Acc: 0.752577\n",
      "Epoch 15090 - Train Loss: 0.092594, Train Acc: 0.861538 | Val Loss: 0.115310, Val Acc: 0.752577\n",
      "Epoch 15091 - Train Loss: 0.092590, Train Acc: 0.861538 | Val Loss: 0.115307, Val Acc: 0.752577\n",
      "Epoch 15092 - Train Loss: 0.092586, Train Acc: 0.861538 | Val Loss: 0.115305, Val Acc: 0.752577\n",
      "Epoch 15093 - Train Loss: 0.092582, Train Acc: 0.861538 | Val Loss: 0.115303, Val Acc: 0.752577\n",
      "Epoch 15094 - Train Loss: 0.092579, Train Acc: 0.861538 | Val Loss: 0.115300, Val Acc: 0.752577\n",
      "Epoch 15095 - Train Loss: 0.092575, Train Acc: 0.861538 | Val Loss: 0.115298, Val Acc: 0.752577\n",
      "Epoch 15096 - Train Loss: 0.092571, Train Acc: 0.861538 | Val Loss: 0.115295, Val Acc: 0.752577\n",
      "Epoch 15097 - Train Loss: 0.092567, Train Acc: 0.861538 | Val Loss: 0.115293, Val Acc: 0.752577\n",
      "Epoch 15098 - Train Loss: 0.092564, Train Acc: 0.861538 | Val Loss: 0.115290, Val Acc: 0.752577\n",
      "Epoch 15099 - Train Loss: 0.092560, Train Acc: 0.861538 | Val Loss: 0.115288, Val Acc: 0.752577\n",
      "Epoch 15100 - Train Loss: 0.092556, Train Acc: 0.861538 | Val Loss: 0.115286, Val Acc: 0.762887\n",
      "Epoch 15101 - Train Loss: 0.092552, Train Acc: 0.861538 | Val Loss: 0.115283, Val Acc: 0.762887\n",
      "Epoch 15102 - Train Loss: 0.092549, Train Acc: 0.861538 | Val Loss: 0.115281, Val Acc: 0.762887\n",
      "Epoch 15103 - Train Loss: 0.092545, Train Acc: 0.861538 | Val Loss: 0.115278, Val Acc: 0.762887\n",
      "Epoch 15104 - Train Loss: 0.092541, Train Acc: 0.861538 | Val Loss: 0.115276, Val Acc: 0.762887\n",
      "Epoch 15105 - Train Loss: 0.092537, Train Acc: 0.861538 | Val Loss: 0.115274, Val Acc: 0.762887\n",
      "Epoch 15106 - Train Loss: 0.092534, Train Acc: 0.861538 | Val Loss: 0.115271, Val Acc: 0.762887\n",
      "Epoch 15107 - Train Loss: 0.092530, Train Acc: 0.861538 | Val Loss: 0.115269, Val Acc: 0.762887\n",
      "Epoch 15108 - Train Loss: 0.092526, Train Acc: 0.861538 | Val Loss: 0.115266, Val Acc: 0.762887\n",
      "Epoch 15109 - Train Loss: 0.092522, Train Acc: 0.861538 | Val Loss: 0.115264, Val Acc: 0.762887\n",
      "Epoch 15110 - Train Loss: 0.092519, Train Acc: 0.861538 | Val Loss: 0.115261, Val Acc: 0.762887\n",
      "Epoch 15111 - Train Loss: 0.092515, Train Acc: 0.861538 | Val Loss: 0.115259, Val Acc: 0.762887\n",
      "Epoch 15112 - Train Loss: 0.092511, Train Acc: 0.861538 | Val Loss: 0.115257, Val Acc: 0.762887\n",
      "Epoch 15113 - Train Loss: 0.092507, Train Acc: 0.861538 | Val Loss: 0.115254, Val Acc: 0.762887\n",
      "Epoch 15114 - Train Loss: 0.092504, Train Acc: 0.861538 | Val Loss: 0.115252, Val Acc: 0.762887\n",
      "Epoch 15115 - Train Loss: 0.092500, Train Acc: 0.861538 | Val Loss: 0.115249, Val Acc: 0.762887\n",
      "Epoch 15116 - Train Loss: 0.092496, Train Acc: 0.861538 | Val Loss: 0.115247, Val Acc: 0.762887\n",
      "Epoch 15117 - Train Loss: 0.092492, Train Acc: 0.861538 | Val Loss: 0.115245, Val Acc: 0.762887\n",
      "Epoch 15118 - Train Loss: 0.092489, Train Acc: 0.861538 | Val Loss: 0.115242, Val Acc: 0.762887\n",
      "Epoch 15119 - Train Loss: 0.092485, Train Acc: 0.861538 | Val Loss: 0.115240, Val Acc: 0.762887\n",
      "Epoch 15120 - Train Loss: 0.092481, Train Acc: 0.861538 | Val Loss: 0.115237, Val Acc: 0.762887\n",
      "Epoch 15121 - Train Loss: 0.092477, Train Acc: 0.861538 | Val Loss: 0.115235, Val Acc: 0.762887\n",
      "Epoch 15122 - Train Loss: 0.092474, Train Acc: 0.861538 | Val Loss: 0.115232, Val Acc: 0.762887\n",
      "Epoch 15123 - Train Loss: 0.092470, Train Acc: 0.861538 | Val Loss: 0.115230, Val Acc: 0.762887\n",
      "Epoch 15124 - Train Loss: 0.092466, Train Acc: 0.861538 | Val Loss: 0.115228, Val Acc: 0.762887\n",
      "Epoch 15125 - Train Loss: 0.092463, Train Acc: 0.861538 | Val Loss: 0.115225, Val Acc: 0.762887\n",
      "Epoch 15126 - Train Loss: 0.092459, Train Acc: 0.861538 | Val Loss: 0.115223, Val Acc: 0.762887\n",
      "Epoch 15127 - Train Loss: 0.092455, Train Acc: 0.861538 | Val Loss: 0.115220, Val Acc: 0.762887\n",
      "Epoch 15128 - Train Loss: 0.092451, Train Acc: 0.861538 | Val Loss: 0.115218, Val Acc: 0.762887\n",
      "Epoch 15129 - Train Loss: 0.092448, Train Acc: 0.861538 | Val Loss: 0.115216, Val Acc: 0.762887\n",
      "Epoch 15130 - Train Loss: 0.092444, Train Acc: 0.861538 | Val Loss: 0.115213, Val Acc: 0.762887\n",
      "Epoch 15131 - Train Loss: 0.092440, Train Acc: 0.861538 | Val Loss: 0.115211, Val Acc: 0.762887\n",
      "Epoch 15132 - Train Loss: 0.092436, Train Acc: 0.861538 | Val Loss: 0.115208, Val Acc: 0.762887\n",
      "Epoch 15133 - Train Loss: 0.092433, Train Acc: 0.861538 | Val Loss: 0.115206, Val Acc: 0.762887\n",
      "Epoch 15134 - Train Loss: 0.092429, Train Acc: 0.861538 | Val Loss: 0.115204, Val Acc: 0.762887\n",
      "Epoch 15135 - Train Loss: 0.092425, Train Acc: 0.861538 | Val Loss: 0.115201, Val Acc: 0.762887\n",
      "Epoch 15136 - Train Loss: 0.092421, Train Acc: 0.861538 | Val Loss: 0.115199, Val Acc: 0.762887\n",
      "Epoch 15137 - Train Loss: 0.092418, Train Acc: 0.861538 | Val Loss: 0.115196, Val Acc: 0.762887\n",
      "Epoch 15138 - Train Loss: 0.092414, Train Acc: 0.861538 | Val Loss: 0.115194, Val Acc: 0.762887\n",
      "Epoch 15139 - Train Loss: 0.092410, Train Acc: 0.861538 | Val Loss: 0.115191, Val Acc: 0.762887\n",
      "Epoch 15140 - Train Loss: 0.092407, Train Acc: 0.861538 | Val Loss: 0.115189, Val Acc: 0.762887\n",
      "Epoch 15141 - Train Loss: 0.092403, Train Acc: 0.861538 | Val Loss: 0.115187, Val Acc: 0.762887\n",
      "Epoch 15142 - Train Loss: 0.092399, Train Acc: 0.861538 | Val Loss: 0.115184, Val Acc: 0.762887\n",
      "Epoch 15143 - Train Loss: 0.092395, Train Acc: 0.861538 | Val Loss: 0.115182, Val Acc: 0.762887\n",
      "Epoch 15144 - Train Loss: 0.092392, Train Acc: 0.861538 | Val Loss: 0.115179, Val Acc: 0.762887\n",
      "Epoch 15145 - Train Loss: 0.092388, Train Acc: 0.861538 | Val Loss: 0.115177, Val Acc: 0.762887\n",
      "Epoch 15146 - Train Loss: 0.092384, Train Acc: 0.861538 | Val Loss: 0.115175, Val Acc: 0.762887\n",
      "Epoch 15147 - Train Loss: 0.092380, Train Acc: 0.861538 | Val Loss: 0.115172, Val Acc: 0.762887\n",
      "Epoch 15148 - Train Loss: 0.092377, Train Acc: 0.861538 | Val Loss: 0.115170, Val Acc: 0.762887\n",
      "Epoch 15149 - Train Loss: 0.092373, Train Acc: 0.861538 | Val Loss: 0.115167, Val Acc: 0.762887\n",
      "Epoch 15150 - Train Loss: 0.092369, Train Acc: 0.861538 | Val Loss: 0.115165, Val Acc: 0.762887\n",
      "Epoch 15151 - Train Loss: 0.092366, Train Acc: 0.861538 | Val Loss: 0.115163, Val Acc: 0.762887\n",
      "Epoch 15152 - Train Loss: 0.092362, Train Acc: 0.861538 | Val Loss: 0.115160, Val Acc: 0.762887\n",
      "Epoch 15153 - Train Loss: 0.092358, Train Acc: 0.862821 | Val Loss: 0.115158, Val Acc: 0.762887\n",
      "Epoch 15154 - Train Loss: 0.092354, Train Acc: 0.862821 | Val Loss: 0.115155, Val Acc: 0.762887\n",
      "Epoch 15155 - Train Loss: 0.092351, Train Acc: 0.862821 | Val Loss: 0.115153, Val Acc: 0.762887\n",
      "Epoch 15156 - Train Loss: 0.092347, Train Acc: 0.862821 | Val Loss: 0.115151, Val Acc: 0.762887\n",
      "Epoch 15157 - Train Loss: 0.092343, Train Acc: 0.862821 | Val Loss: 0.115148, Val Acc: 0.762887\n",
      "Epoch 15158 - Train Loss: 0.092339, Train Acc: 0.862821 | Val Loss: 0.115146, Val Acc: 0.762887\n",
      "Epoch 15159 - Train Loss: 0.092336, Train Acc: 0.862821 | Val Loss: 0.115143, Val Acc: 0.762887\n",
      "Epoch 15160 - Train Loss: 0.092332, Train Acc: 0.862821 | Val Loss: 0.115141, Val Acc: 0.762887\n",
      "Epoch 15161 - Train Loss: 0.092328, Train Acc: 0.862821 | Val Loss: 0.115139, Val Acc: 0.762887\n",
      "Epoch 15162 - Train Loss: 0.092325, Train Acc: 0.862821 | Val Loss: 0.115136, Val Acc: 0.762887\n",
      "Epoch 15163 - Train Loss: 0.092321, Train Acc: 0.862821 | Val Loss: 0.115134, Val Acc: 0.762887\n",
      "Epoch 15164 - Train Loss: 0.092317, Train Acc: 0.862821 | Val Loss: 0.115131, Val Acc: 0.762887\n",
      "Epoch 15165 - Train Loss: 0.092313, Train Acc: 0.862821 | Val Loss: 0.115129, Val Acc: 0.762887\n",
      "Epoch 15166 - Train Loss: 0.092310, Train Acc: 0.862821 | Val Loss: 0.115127, Val Acc: 0.762887\n",
      "Epoch 15167 - Train Loss: 0.092306, Train Acc: 0.862821 | Val Loss: 0.115124, Val Acc: 0.762887\n",
      "Epoch 15168 - Train Loss: 0.092302, Train Acc: 0.862821 | Val Loss: 0.115122, Val Acc: 0.762887\n",
      "Epoch 15169 - Train Loss: 0.092299, Train Acc: 0.862821 | Val Loss: 0.115119, Val Acc: 0.762887\n",
      "Epoch 15170 - Train Loss: 0.092295, Train Acc: 0.862821 | Val Loss: 0.115117, Val Acc: 0.762887\n",
      "Epoch 15171 - Train Loss: 0.092291, Train Acc: 0.862821 | Val Loss: 0.115115, Val Acc: 0.762887\n",
      "Epoch 15172 - Train Loss: 0.092287, Train Acc: 0.862821 | Val Loss: 0.115112, Val Acc: 0.762887\n",
      "Epoch 15173 - Train Loss: 0.092284, Train Acc: 0.862821 | Val Loss: 0.115110, Val Acc: 0.762887\n",
      "Epoch 15174 - Train Loss: 0.092280, Train Acc: 0.862821 | Val Loss: 0.115108, Val Acc: 0.762887\n",
      "Epoch 15175 - Train Loss: 0.092276, Train Acc: 0.862821 | Val Loss: 0.115105, Val Acc: 0.762887\n",
      "Epoch 15176 - Train Loss: 0.092273, Train Acc: 0.862821 | Val Loss: 0.115103, Val Acc: 0.762887\n",
      "Epoch 15177 - Train Loss: 0.092269, Train Acc: 0.862821 | Val Loss: 0.115100, Val Acc: 0.762887\n",
      "Epoch 15178 - Train Loss: 0.092265, Train Acc: 0.862821 | Val Loss: 0.115098, Val Acc: 0.762887\n",
      "Epoch 15179 - Train Loss: 0.092261, Train Acc: 0.862821 | Val Loss: 0.115096, Val Acc: 0.762887\n",
      "Epoch 15180 - Train Loss: 0.092258, Train Acc: 0.862821 | Val Loss: 0.115093, Val Acc: 0.762887\n",
      "Epoch 15181 - Train Loss: 0.092254, Train Acc: 0.862821 | Val Loss: 0.115091, Val Acc: 0.762887\n",
      "Epoch 15182 - Train Loss: 0.092250, Train Acc: 0.862821 | Val Loss: 0.115088, Val Acc: 0.762887\n",
      "Epoch 15183 - Train Loss: 0.092247, Train Acc: 0.862821 | Val Loss: 0.115086, Val Acc: 0.762887\n",
      "Epoch 15184 - Train Loss: 0.092243, Train Acc: 0.862821 | Val Loss: 0.115084, Val Acc: 0.762887\n",
      "Epoch 15185 - Train Loss: 0.092239, Train Acc: 0.862821 | Val Loss: 0.115081, Val Acc: 0.762887\n",
      "Epoch 15186 - Train Loss: 0.092235, Train Acc: 0.862821 | Val Loss: 0.115079, Val Acc: 0.762887\n",
      "Epoch 15187 - Train Loss: 0.092232, Train Acc: 0.862821 | Val Loss: 0.115076, Val Acc: 0.762887\n",
      "Epoch 15188 - Train Loss: 0.092228, Train Acc: 0.862821 | Val Loss: 0.115074, Val Acc: 0.762887\n",
      "Epoch 15189 - Train Loss: 0.092224, Train Acc: 0.862821 | Val Loss: 0.115072, Val Acc: 0.762887\n",
      "Epoch 15190 - Train Loss: 0.092221, Train Acc: 0.862821 | Val Loss: 0.115069, Val Acc: 0.762887\n",
      "Epoch 15191 - Train Loss: 0.092217, Train Acc: 0.862821 | Val Loss: 0.115067, Val Acc: 0.762887\n",
      "Epoch 15192 - Train Loss: 0.092213, Train Acc: 0.862821 | Val Loss: 0.115065, Val Acc: 0.762887\n",
      "Epoch 15193 - Train Loss: 0.092210, Train Acc: 0.862821 | Val Loss: 0.115062, Val Acc: 0.762887\n",
      "Epoch 15194 - Train Loss: 0.092206, Train Acc: 0.862821 | Val Loss: 0.115060, Val Acc: 0.762887\n",
      "Epoch 15195 - Train Loss: 0.092202, Train Acc: 0.862821 | Val Loss: 0.115057, Val Acc: 0.762887\n",
      "Epoch 15196 - Train Loss: 0.092198, Train Acc: 0.862821 | Val Loss: 0.115055, Val Acc: 0.762887\n",
      "Epoch 15197 - Train Loss: 0.092195, Train Acc: 0.862821 | Val Loss: 0.115053, Val Acc: 0.762887\n",
      "Epoch 15198 - Train Loss: 0.092191, Train Acc: 0.862821 | Val Loss: 0.115050, Val Acc: 0.762887\n",
      "Epoch 15199 - Train Loss: 0.092187, Train Acc: 0.862821 | Val Loss: 0.115048, Val Acc: 0.762887\n",
      "Epoch 15200 - Train Loss: 0.092184, Train Acc: 0.862821 | Val Loss: 0.115046, Val Acc: 0.762887\n",
      "Epoch 15201 - Train Loss: 0.092180, Train Acc: 0.862821 | Val Loss: 0.115043, Val Acc: 0.762887\n",
      "Epoch 15202 - Train Loss: 0.092176, Train Acc: 0.862821 | Val Loss: 0.115041, Val Acc: 0.762887\n",
      "Epoch 15203 - Train Loss: 0.092173, Train Acc: 0.862821 | Val Loss: 0.115038, Val Acc: 0.762887\n",
      "Epoch 15204 - Train Loss: 0.092169, Train Acc: 0.862821 | Val Loss: 0.115036, Val Acc: 0.762887\n",
      "Epoch 15205 - Train Loss: 0.092165, Train Acc: 0.862821 | Val Loss: 0.115034, Val Acc: 0.762887\n",
      "Epoch 15206 - Train Loss: 0.092161, Train Acc: 0.862821 | Val Loss: 0.115031, Val Acc: 0.762887\n",
      "Epoch 15207 - Train Loss: 0.092158, Train Acc: 0.862821 | Val Loss: 0.115029, Val Acc: 0.762887\n",
      "Epoch 15208 - Train Loss: 0.092154, Train Acc: 0.862821 | Val Loss: 0.115027, Val Acc: 0.762887\n",
      "Epoch 15209 - Train Loss: 0.092150, Train Acc: 0.862821 | Val Loss: 0.115024, Val Acc: 0.762887\n",
      "Epoch 15210 - Train Loss: 0.092147, Train Acc: 0.862821 | Val Loss: 0.115022, Val Acc: 0.762887\n",
      "Epoch 15211 - Train Loss: 0.092143, Train Acc: 0.862821 | Val Loss: 0.115019, Val Acc: 0.762887\n",
      "Epoch 15212 - Train Loss: 0.092139, Train Acc: 0.862821 | Val Loss: 0.115017, Val Acc: 0.762887\n",
      "Epoch 15213 - Train Loss: 0.092136, Train Acc: 0.862821 | Val Loss: 0.115015, Val Acc: 0.762887\n",
      "Epoch 15214 - Train Loss: 0.092132, Train Acc: 0.862821 | Val Loss: 0.115012, Val Acc: 0.762887\n",
      "Epoch 15215 - Train Loss: 0.092128, Train Acc: 0.862821 | Val Loss: 0.115010, Val Acc: 0.762887\n",
      "Epoch 15216 - Train Loss: 0.092124, Train Acc: 0.862821 | Val Loss: 0.115007, Val Acc: 0.762887\n",
      "Epoch 15217 - Train Loss: 0.092121, Train Acc: 0.862821 | Val Loss: 0.115005, Val Acc: 0.762887\n",
      "Epoch 15218 - Train Loss: 0.092117, Train Acc: 0.862821 | Val Loss: 0.115003, Val Acc: 0.762887\n",
      "Epoch 15219 - Train Loss: 0.092113, Train Acc: 0.862821 | Val Loss: 0.115000, Val Acc: 0.762887\n",
      "Epoch 15220 - Train Loss: 0.092110, Train Acc: 0.862821 | Val Loss: 0.114998, Val Acc: 0.762887\n",
      "Epoch 15221 - Train Loss: 0.092106, Train Acc: 0.862821 | Val Loss: 0.114996, Val Acc: 0.762887\n",
      "Epoch 15222 - Train Loss: 0.092102, Train Acc: 0.862821 | Val Loss: 0.114993, Val Acc: 0.762887\n",
      "Epoch 15223 - Train Loss: 0.092099, Train Acc: 0.862821 | Val Loss: 0.114991, Val Acc: 0.762887\n",
      "Epoch 15224 - Train Loss: 0.092095, Train Acc: 0.862821 | Val Loss: 0.114988, Val Acc: 0.762887\n",
      "Epoch 15225 - Train Loss: 0.092091, Train Acc: 0.862821 | Val Loss: 0.114986, Val Acc: 0.762887\n",
      "Epoch 15226 - Train Loss: 0.092088, Train Acc: 0.862821 | Val Loss: 0.114984, Val Acc: 0.762887\n",
      "Epoch 15227 - Train Loss: 0.092084, Train Acc: 0.862821 | Val Loss: 0.114981, Val Acc: 0.762887\n",
      "Epoch 15228 - Train Loss: 0.092080, Train Acc: 0.862821 | Val Loss: 0.114979, Val Acc: 0.762887\n",
      "Epoch 15229 - Train Loss: 0.092076, Train Acc: 0.862821 | Val Loss: 0.114977, Val Acc: 0.762887\n",
      "Epoch 15230 - Train Loss: 0.092073, Train Acc: 0.862821 | Val Loss: 0.114974, Val Acc: 0.762887\n",
      "Epoch 15231 - Train Loss: 0.092069, Train Acc: 0.862821 | Val Loss: 0.114972, Val Acc: 0.762887\n",
      "Epoch 15232 - Train Loss: 0.092065, Train Acc: 0.862821 | Val Loss: 0.114970, Val Acc: 0.762887\n",
      "Epoch 15233 - Train Loss: 0.092062, Train Acc: 0.862821 | Val Loss: 0.114967, Val Acc: 0.762887\n",
      "Epoch 15234 - Train Loss: 0.092058, Train Acc: 0.862821 | Val Loss: 0.114965, Val Acc: 0.762887\n",
      "Epoch 15235 - Train Loss: 0.092054, Train Acc: 0.862821 | Val Loss: 0.114962, Val Acc: 0.762887\n",
      "Epoch 15236 - Train Loss: 0.092051, Train Acc: 0.862821 | Val Loss: 0.114960, Val Acc: 0.762887\n",
      "Epoch 15237 - Train Loss: 0.092047, Train Acc: 0.862821 | Val Loss: 0.114958, Val Acc: 0.762887\n",
      "Epoch 15238 - Train Loss: 0.092043, Train Acc: 0.862821 | Val Loss: 0.114955, Val Acc: 0.762887\n",
      "Epoch 15239 - Train Loss: 0.092040, Train Acc: 0.862821 | Val Loss: 0.114953, Val Acc: 0.762887\n",
      "Epoch 15240 - Train Loss: 0.092036, Train Acc: 0.862821 | Val Loss: 0.114951, Val Acc: 0.762887\n",
      "Epoch 15241 - Train Loss: 0.092032, Train Acc: 0.862821 | Val Loss: 0.114948, Val Acc: 0.762887\n",
      "Epoch 15242 - Train Loss: 0.092029, Train Acc: 0.862821 | Val Loss: 0.114946, Val Acc: 0.762887\n",
      "Epoch 15243 - Train Loss: 0.092025, Train Acc: 0.862821 | Val Loss: 0.114943, Val Acc: 0.762887\n",
      "Epoch 15244 - Train Loss: 0.092021, Train Acc: 0.862821 | Val Loss: 0.114941, Val Acc: 0.762887\n",
      "Epoch 15245 - Train Loss: 0.092018, Train Acc: 0.862821 | Val Loss: 0.114939, Val Acc: 0.762887\n",
      "Epoch 15246 - Train Loss: 0.092014, Train Acc: 0.862821 | Val Loss: 0.114936, Val Acc: 0.762887\n",
      "Epoch 15247 - Train Loss: 0.092010, Train Acc: 0.862821 | Val Loss: 0.114934, Val Acc: 0.762887\n",
      "Epoch 15248 - Train Loss: 0.092007, Train Acc: 0.862821 | Val Loss: 0.114932, Val Acc: 0.762887\n",
      "Epoch 15249 - Train Loss: 0.092003, Train Acc: 0.862821 | Val Loss: 0.114929, Val Acc: 0.762887\n",
      "Epoch 15250 - Train Loss: 0.091999, Train Acc: 0.862821 | Val Loss: 0.114927, Val Acc: 0.762887\n",
      "Epoch 15251 - Train Loss: 0.091995, Train Acc: 0.862821 | Val Loss: 0.114925, Val Acc: 0.762887\n",
      "Epoch 15252 - Train Loss: 0.091992, Train Acc: 0.862821 | Val Loss: 0.114922, Val Acc: 0.762887\n",
      "Epoch 15253 - Train Loss: 0.091988, Train Acc: 0.862821 | Val Loss: 0.114920, Val Acc: 0.762887\n",
      "Epoch 15254 - Train Loss: 0.091984, Train Acc: 0.862821 | Val Loss: 0.114918, Val Acc: 0.762887\n",
      "Epoch 15255 - Train Loss: 0.091981, Train Acc: 0.862821 | Val Loss: 0.114915, Val Acc: 0.762887\n",
      "Epoch 15256 - Train Loss: 0.091977, Train Acc: 0.862821 | Val Loss: 0.114913, Val Acc: 0.762887\n",
      "Epoch 15257 - Train Loss: 0.091973, Train Acc: 0.862821 | Val Loss: 0.114910, Val Acc: 0.762887\n",
      "Epoch 15258 - Train Loss: 0.091970, Train Acc: 0.862821 | Val Loss: 0.114908, Val Acc: 0.762887\n",
      "Epoch 15259 - Train Loss: 0.091966, Train Acc: 0.862821 | Val Loss: 0.114906, Val Acc: 0.762887\n",
      "Epoch 15260 - Train Loss: 0.091962, Train Acc: 0.862821 | Val Loss: 0.114903, Val Acc: 0.762887\n",
      "Epoch 15261 - Train Loss: 0.091959, Train Acc: 0.862821 | Val Loss: 0.114901, Val Acc: 0.762887\n",
      "Epoch 15262 - Train Loss: 0.091955, Train Acc: 0.862821 | Val Loss: 0.114899, Val Acc: 0.762887\n",
      "Epoch 15263 - Train Loss: 0.091951, Train Acc: 0.862821 | Val Loss: 0.114896, Val Acc: 0.762887\n",
      "Epoch 15264 - Train Loss: 0.091948, Train Acc: 0.862821 | Val Loss: 0.114894, Val Acc: 0.762887\n",
      "Epoch 15265 - Train Loss: 0.091944, Train Acc: 0.862821 | Val Loss: 0.114892, Val Acc: 0.762887\n",
      "Epoch 15266 - Train Loss: 0.091940, Train Acc: 0.862821 | Val Loss: 0.114889, Val Acc: 0.762887\n",
      "Epoch 15267 - Train Loss: 0.091937, Train Acc: 0.862821 | Val Loss: 0.114887, Val Acc: 0.762887\n",
      "Epoch 15268 - Train Loss: 0.091933, Train Acc: 0.862821 | Val Loss: 0.114885, Val Acc: 0.762887\n",
      "Epoch 15269 - Train Loss: 0.091929, Train Acc: 0.862821 | Val Loss: 0.114882, Val Acc: 0.762887\n",
      "Epoch 15270 - Train Loss: 0.091926, Train Acc: 0.862821 | Val Loss: 0.114880, Val Acc: 0.762887\n",
      "Epoch 15271 - Train Loss: 0.091922, Train Acc: 0.862821 | Val Loss: 0.114877, Val Acc: 0.762887\n",
      "Epoch 15272 - Train Loss: 0.091918, Train Acc: 0.862821 | Val Loss: 0.114875, Val Acc: 0.762887\n",
      "Epoch 15273 - Train Loss: 0.091915, Train Acc: 0.862821 | Val Loss: 0.114873, Val Acc: 0.762887\n",
      "Epoch 15274 - Train Loss: 0.091911, Train Acc: 0.862821 | Val Loss: 0.114870, Val Acc: 0.762887\n",
      "Epoch 15275 - Train Loss: 0.091907, Train Acc: 0.862821 | Val Loss: 0.114868, Val Acc: 0.762887\n",
      "Epoch 15276 - Train Loss: 0.091904, Train Acc: 0.862821 | Val Loss: 0.114866, Val Acc: 0.762887\n",
      "Epoch 15277 - Train Loss: 0.091900, Train Acc: 0.862821 | Val Loss: 0.114863, Val Acc: 0.762887\n",
      "Epoch 15278 - Train Loss: 0.091896, Train Acc: 0.862821 | Val Loss: 0.114861, Val Acc: 0.762887\n",
      "Epoch 15279 - Train Loss: 0.091893, Train Acc: 0.862821 | Val Loss: 0.114859, Val Acc: 0.762887\n",
      "Epoch 15280 - Train Loss: 0.091889, Train Acc: 0.862821 | Val Loss: 0.114856, Val Acc: 0.762887\n",
      "Epoch 15281 - Train Loss: 0.091885, Train Acc: 0.862821 | Val Loss: 0.114854, Val Acc: 0.762887\n",
      "Epoch 15282 - Train Loss: 0.091882, Train Acc: 0.862821 | Val Loss: 0.114852, Val Acc: 0.762887\n",
      "Epoch 15283 - Train Loss: 0.091878, Train Acc: 0.862821 | Val Loss: 0.114849, Val Acc: 0.762887\n",
      "Epoch 15284 - Train Loss: 0.091874, Train Acc: 0.862821 | Val Loss: 0.114847, Val Acc: 0.762887\n",
      "Epoch 15285 - Train Loss: 0.091871, Train Acc: 0.862821 | Val Loss: 0.114845, Val Acc: 0.762887\n",
      "Epoch 15286 - Train Loss: 0.091867, Train Acc: 0.862821 | Val Loss: 0.114842, Val Acc: 0.762887\n",
      "Epoch 15287 - Train Loss: 0.091863, Train Acc: 0.862821 | Val Loss: 0.114840, Val Acc: 0.762887\n",
      "Epoch 15288 - Train Loss: 0.091860, Train Acc: 0.862821 | Val Loss: 0.114838, Val Acc: 0.762887\n",
      "Epoch 15289 - Train Loss: 0.091856, Train Acc: 0.862821 | Val Loss: 0.114835, Val Acc: 0.762887\n",
      "Epoch 15290 - Train Loss: 0.091852, Train Acc: 0.862821 | Val Loss: 0.114833, Val Acc: 0.762887\n",
      "Epoch 15291 - Train Loss: 0.091849, Train Acc: 0.862821 | Val Loss: 0.114830, Val Acc: 0.762887\n",
      "Epoch 15292 - Train Loss: 0.091845, Train Acc: 0.862821 | Val Loss: 0.114828, Val Acc: 0.762887\n",
      "Epoch 15293 - Train Loss: 0.091841, Train Acc: 0.862821 | Val Loss: 0.114826, Val Acc: 0.762887\n",
      "Epoch 15294 - Train Loss: 0.091838, Train Acc: 0.862821 | Val Loss: 0.114823, Val Acc: 0.762887\n",
      "Epoch 15295 - Train Loss: 0.091834, Train Acc: 0.862821 | Val Loss: 0.114821, Val Acc: 0.762887\n",
      "Epoch 15296 - Train Loss: 0.091831, Train Acc: 0.862821 | Val Loss: 0.114819, Val Acc: 0.762887\n",
      "Epoch 15297 - Train Loss: 0.091827, Train Acc: 0.862821 | Val Loss: 0.114816, Val Acc: 0.762887\n",
      "Epoch 15298 - Train Loss: 0.091823, Train Acc: 0.862821 | Val Loss: 0.114814, Val Acc: 0.762887\n",
      "Epoch 15299 - Train Loss: 0.091820, Train Acc: 0.862821 | Val Loss: 0.114811, Val Acc: 0.762887\n",
      "Epoch 15300 - Train Loss: 0.091816, Train Acc: 0.862821 | Val Loss: 0.114809, Val Acc: 0.762887\n",
      "Epoch 15301 - Train Loss: 0.091812, Train Acc: 0.862821 | Val Loss: 0.114807, Val Acc: 0.762887\n",
      "Epoch 15302 - Train Loss: 0.091809, Train Acc: 0.862821 | Val Loss: 0.114804, Val Acc: 0.762887\n",
      "Epoch 15303 - Train Loss: 0.091805, Train Acc: 0.862821 | Val Loss: 0.114802, Val Acc: 0.762887\n",
      "Epoch 15304 - Train Loss: 0.091801, Train Acc: 0.862821 | Val Loss: 0.114799, Val Acc: 0.762887\n",
      "Epoch 15305 - Train Loss: 0.091798, Train Acc: 0.862821 | Val Loss: 0.114797, Val Acc: 0.762887\n",
      "Epoch 15306 - Train Loss: 0.091794, Train Acc: 0.862821 | Val Loss: 0.114795, Val Acc: 0.762887\n",
      "Epoch 15307 - Train Loss: 0.091790, Train Acc: 0.862821 | Val Loss: 0.114792, Val Acc: 0.762887\n",
      "Epoch 15308 - Train Loss: 0.091787, Train Acc: 0.862821 | Val Loss: 0.114790, Val Acc: 0.762887\n",
      "Epoch 15309 - Train Loss: 0.091783, Train Acc: 0.862821 | Val Loss: 0.114788, Val Acc: 0.762887\n",
      "Epoch 15310 - Train Loss: 0.091779, Train Acc: 0.862821 | Val Loss: 0.114785, Val Acc: 0.762887\n",
      "Epoch 15311 - Train Loss: 0.091776, Train Acc: 0.862821 | Val Loss: 0.114783, Val Acc: 0.762887\n",
      "Epoch 15312 - Train Loss: 0.091772, Train Acc: 0.862821 | Val Loss: 0.114780, Val Acc: 0.762887\n",
      "Epoch 15313 - Train Loss: 0.091768, Train Acc: 0.862821 | Val Loss: 0.114778, Val Acc: 0.762887\n",
      "Epoch 15314 - Train Loss: 0.091765, Train Acc: 0.862821 | Val Loss: 0.114776, Val Acc: 0.762887\n",
      "Epoch 15315 - Train Loss: 0.091761, Train Acc: 0.862821 | Val Loss: 0.114773, Val Acc: 0.762887\n",
      "Epoch 15316 - Train Loss: 0.091757, Train Acc: 0.862821 | Val Loss: 0.114771, Val Acc: 0.762887\n",
      "Epoch 15317 - Train Loss: 0.091754, Train Acc: 0.862821 | Val Loss: 0.114768, Val Acc: 0.762887\n",
      "Epoch 15318 - Train Loss: 0.091750, Train Acc: 0.862821 | Val Loss: 0.114766, Val Acc: 0.762887\n",
      "Epoch 15319 - Train Loss: 0.091747, Train Acc: 0.862821 | Val Loss: 0.114764, Val Acc: 0.762887\n",
      "Epoch 15320 - Train Loss: 0.091743, Train Acc: 0.862821 | Val Loss: 0.114761, Val Acc: 0.762887\n",
      "Epoch 15321 - Train Loss: 0.091739, Train Acc: 0.862821 | Val Loss: 0.114759, Val Acc: 0.762887\n",
      "Epoch 15322 - Train Loss: 0.091736, Train Acc: 0.862821 | Val Loss: 0.114757, Val Acc: 0.762887\n",
      "Epoch 15323 - Train Loss: 0.091732, Train Acc: 0.862821 | Val Loss: 0.114754, Val Acc: 0.762887\n",
      "Epoch 15324 - Train Loss: 0.091728, Train Acc: 0.862821 | Val Loss: 0.114752, Val Acc: 0.762887\n",
      "Epoch 15325 - Train Loss: 0.091725, Train Acc: 0.862821 | Val Loss: 0.114749, Val Acc: 0.762887\n",
      "Epoch 15326 - Train Loss: 0.091721, Train Acc: 0.862821 | Val Loss: 0.114747, Val Acc: 0.762887\n",
      "Epoch 15327 - Train Loss: 0.091717, Train Acc: 0.862821 | Val Loss: 0.114745, Val Acc: 0.762887\n",
      "Epoch 15328 - Train Loss: 0.091714, Train Acc: 0.862821 | Val Loss: 0.114742, Val Acc: 0.762887\n",
      "Epoch 15329 - Train Loss: 0.091710, Train Acc: 0.862821 | Val Loss: 0.114740, Val Acc: 0.762887\n",
      "Epoch 15330 - Train Loss: 0.091706, Train Acc: 0.862821 | Val Loss: 0.114738, Val Acc: 0.762887\n",
      "Epoch 15331 - Train Loss: 0.091703, Train Acc: 0.862821 | Val Loss: 0.114735, Val Acc: 0.762887\n",
      "Epoch 15332 - Train Loss: 0.091699, Train Acc: 0.862821 | Val Loss: 0.114733, Val Acc: 0.762887\n",
      "Epoch 15333 - Train Loss: 0.091696, Train Acc: 0.862821 | Val Loss: 0.114730, Val Acc: 0.762887\n",
      "Epoch 15334 - Train Loss: 0.091692, Train Acc: 0.862821 | Val Loss: 0.114728, Val Acc: 0.762887\n",
      "Epoch 15335 - Train Loss: 0.091688, Train Acc: 0.862821 | Val Loss: 0.114726, Val Acc: 0.762887\n",
      "Epoch 15336 - Train Loss: 0.091685, Train Acc: 0.862821 | Val Loss: 0.114723, Val Acc: 0.762887\n",
      "Epoch 15337 - Train Loss: 0.091681, Train Acc: 0.862821 | Val Loss: 0.114721, Val Acc: 0.762887\n",
      "Epoch 15338 - Train Loss: 0.091677, Train Acc: 0.862821 | Val Loss: 0.114719, Val Acc: 0.762887\n",
      "Epoch 15339 - Train Loss: 0.091674, Train Acc: 0.862821 | Val Loss: 0.114716, Val Acc: 0.762887\n",
      "Epoch 15340 - Train Loss: 0.091670, Train Acc: 0.862821 | Val Loss: 0.114714, Val Acc: 0.762887\n",
      "Epoch 15341 - Train Loss: 0.091666, Train Acc: 0.862821 | Val Loss: 0.114712, Val Acc: 0.762887\n",
      "Epoch 15342 - Train Loss: 0.091663, Train Acc: 0.862821 | Val Loss: 0.114709, Val Acc: 0.762887\n",
      "Epoch 15343 - Train Loss: 0.091659, Train Acc: 0.862821 | Val Loss: 0.114707, Val Acc: 0.762887\n",
      "Epoch 15344 - Train Loss: 0.091656, Train Acc: 0.862821 | Val Loss: 0.114704, Val Acc: 0.762887\n",
      "Epoch 15345 - Train Loss: 0.091652, Train Acc: 0.862821 | Val Loss: 0.114702, Val Acc: 0.762887\n",
      "Epoch 15346 - Train Loss: 0.091648, Train Acc: 0.862821 | Val Loss: 0.114700, Val Acc: 0.762887\n",
      "Epoch 15347 - Train Loss: 0.091645, Train Acc: 0.862821 | Val Loss: 0.114697, Val Acc: 0.762887\n",
      "Epoch 15348 - Train Loss: 0.091641, Train Acc: 0.862821 | Val Loss: 0.114695, Val Acc: 0.762887\n",
      "Epoch 15349 - Train Loss: 0.091637, Train Acc: 0.862821 | Val Loss: 0.114693, Val Acc: 0.762887\n",
      "Epoch 15350 - Train Loss: 0.091634, Train Acc: 0.862821 | Val Loss: 0.114690, Val Acc: 0.762887\n",
      "Epoch 15351 - Train Loss: 0.091630, Train Acc: 0.862821 | Val Loss: 0.114688, Val Acc: 0.762887\n",
      "Epoch 15352 - Train Loss: 0.091627, Train Acc: 0.862821 | Val Loss: 0.114685, Val Acc: 0.762887\n",
      "Epoch 15353 - Train Loss: 0.091623, Train Acc: 0.862821 | Val Loss: 0.114683, Val Acc: 0.762887\n",
      "Epoch 15354 - Train Loss: 0.091619, Train Acc: 0.862821 | Val Loss: 0.114681, Val Acc: 0.762887\n",
      "Epoch 15355 - Train Loss: 0.091616, Train Acc: 0.862821 | Val Loss: 0.114678, Val Acc: 0.762887\n",
      "Epoch 15356 - Train Loss: 0.091612, Train Acc: 0.862821 | Val Loss: 0.114676, Val Acc: 0.762887\n",
      "Epoch 15357 - Train Loss: 0.091608, Train Acc: 0.862821 | Val Loss: 0.114674, Val Acc: 0.762887\n",
      "Epoch 15358 - Train Loss: 0.091605, Train Acc: 0.862821 | Val Loss: 0.114671, Val Acc: 0.762887\n",
      "Epoch 15359 - Train Loss: 0.091601, Train Acc: 0.862821 | Val Loss: 0.114669, Val Acc: 0.762887\n",
      "Epoch 15360 - Train Loss: 0.091597, Train Acc: 0.862821 | Val Loss: 0.114667, Val Acc: 0.762887\n",
      "Epoch 15361 - Train Loss: 0.091594, Train Acc: 0.862821 | Val Loss: 0.114664, Val Acc: 0.762887\n",
      "Epoch 15362 - Train Loss: 0.091590, Train Acc: 0.862821 | Val Loss: 0.114662, Val Acc: 0.762887\n",
      "Epoch 15363 - Train Loss: 0.091587, Train Acc: 0.862821 | Val Loss: 0.114660, Val Acc: 0.762887\n",
      "Epoch 15364 - Train Loss: 0.091583, Train Acc: 0.862821 | Val Loss: 0.114657, Val Acc: 0.762887\n",
      "Epoch 15365 - Train Loss: 0.091579, Train Acc: 0.862821 | Val Loss: 0.114655, Val Acc: 0.762887\n",
      "Epoch 15366 - Train Loss: 0.091576, Train Acc: 0.862821 | Val Loss: 0.114652, Val Acc: 0.762887\n",
      "Epoch 15367 - Train Loss: 0.091572, Train Acc: 0.862821 | Val Loss: 0.114650, Val Acc: 0.762887\n",
      "Epoch 15368 - Train Loss: 0.091568, Train Acc: 0.862821 | Val Loss: 0.114648, Val Acc: 0.762887\n",
      "Epoch 15369 - Train Loss: 0.091565, Train Acc: 0.862821 | Val Loss: 0.114645, Val Acc: 0.762887\n",
      "Epoch 15370 - Train Loss: 0.091561, Train Acc: 0.862821 | Val Loss: 0.114643, Val Acc: 0.762887\n",
      "Epoch 15371 - Train Loss: 0.091558, Train Acc: 0.862821 | Val Loss: 0.114641, Val Acc: 0.762887\n",
      "Epoch 15372 - Train Loss: 0.091554, Train Acc: 0.862821 | Val Loss: 0.114638, Val Acc: 0.762887\n",
      "Epoch 15373 - Train Loss: 0.091550, Train Acc: 0.862821 | Val Loss: 0.114636, Val Acc: 0.762887\n",
      "Epoch 15374 - Train Loss: 0.091547, Train Acc: 0.862821 | Val Loss: 0.114634, Val Acc: 0.762887\n",
      "Epoch 15375 - Train Loss: 0.091543, Train Acc: 0.862821 | Val Loss: 0.114631, Val Acc: 0.762887\n",
      "Epoch 15376 - Train Loss: 0.091540, Train Acc: 0.862821 | Val Loss: 0.114629, Val Acc: 0.762887\n",
      "Epoch 15377 - Train Loss: 0.091536, Train Acc: 0.862821 | Val Loss: 0.114627, Val Acc: 0.762887\n",
      "Epoch 15378 - Train Loss: 0.091532, Train Acc: 0.862821 | Val Loss: 0.114624, Val Acc: 0.762887\n",
      "Epoch 15379 - Train Loss: 0.091529, Train Acc: 0.862821 | Val Loss: 0.114622, Val Acc: 0.762887\n",
      "Epoch 15380 - Train Loss: 0.091525, Train Acc: 0.862821 | Val Loss: 0.114619, Val Acc: 0.762887\n",
      "Epoch 15381 - Train Loss: 0.091521, Train Acc: 0.862821 | Val Loss: 0.114617, Val Acc: 0.762887\n",
      "Epoch 15382 - Train Loss: 0.091518, Train Acc: 0.862821 | Val Loss: 0.114615, Val Acc: 0.762887\n",
      "Epoch 15383 - Train Loss: 0.091514, Train Acc: 0.862821 | Val Loss: 0.114612, Val Acc: 0.762887\n",
      "Epoch 15384 - Train Loss: 0.091511, Train Acc: 0.862821 | Val Loss: 0.114610, Val Acc: 0.762887\n",
      "Epoch 15385 - Train Loss: 0.091507, Train Acc: 0.862821 | Val Loss: 0.114608, Val Acc: 0.762887\n",
      "Epoch 15386 - Train Loss: 0.091503, Train Acc: 0.862821 | Val Loss: 0.114605, Val Acc: 0.762887\n",
      "Epoch 15387 - Train Loss: 0.091500, Train Acc: 0.862821 | Val Loss: 0.114603, Val Acc: 0.762887\n",
      "Epoch 15388 - Train Loss: 0.091496, Train Acc: 0.862821 | Val Loss: 0.114601, Val Acc: 0.762887\n",
      "Epoch 15389 - Train Loss: 0.091493, Train Acc: 0.862821 | Val Loss: 0.114598, Val Acc: 0.762887\n",
      "Epoch 15390 - Train Loss: 0.091489, Train Acc: 0.862821 | Val Loss: 0.114596, Val Acc: 0.762887\n",
      "Epoch 15391 - Train Loss: 0.091485, Train Acc: 0.862821 | Val Loss: 0.114594, Val Acc: 0.762887\n",
      "Epoch 15392 - Train Loss: 0.091482, Train Acc: 0.862821 | Val Loss: 0.114591, Val Acc: 0.762887\n",
      "Epoch 15393 - Train Loss: 0.091478, Train Acc: 0.862821 | Val Loss: 0.114589, Val Acc: 0.762887\n",
      "Epoch 15394 - Train Loss: 0.091474, Train Acc: 0.862821 | Val Loss: 0.114587, Val Acc: 0.762887\n",
      "Epoch 15395 - Train Loss: 0.091471, Train Acc: 0.862821 | Val Loss: 0.114584, Val Acc: 0.762887\n",
      "Epoch 15396 - Train Loss: 0.091467, Train Acc: 0.862821 | Val Loss: 0.114582, Val Acc: 0.762887\n",
      "Epoch 15397 - Train Loss: 0.091464, Train Acc: 0.862821 | Val Loss: 0.114579, Val Acc: 0.762887\n",
      "Epoch 15398 - Train Loss: 0.091460, Train Acc: 0.862821 | Val Loss: 0.114577, Val Acc: 0.762887\n",
      "Epoch 15399 - Train Loss: 0.091456, Train Acc: 0.862821 | Val Loss: 0.114575, Val Acc: 0.762887\n",
      "Epoch 15400 - Train Loss: 0.091453, Train Acc: 0.862821 | Val Loss: 0.114572, Val Acc: 0.762887\n",
      "Epoch 15401 - Train Loss: 0.091449, Train Acc: 0.862821 | Val Loss: 0.114570, Val Acc: 0.762887\n",
      "Epoch 15402 - Train Loss: 0.091446, Train Acc: 0.862821 | Val Loss: 0.114568, Val Acc: 0.762887\n",
      "Epoch 15403 - Train Loss: 0.091442, Train Acc: 0.862821 | Val Loss: 0.114565, Val Acc: 0.762887\n",
      "Epoch 15404 - Train Loss: 0.091438, Train Acc: 0.862821 | Val Loss: 0.114563, Val Acc: 0.762887\n",
      "Epoch 15405 - Train Loss: 0.091435, Train Acc: 0.862821 | Val Loss: 0.114561, Val Acc: 0.762887\n",
      "Epoch 15406 - Train Loss: 0.091431, Train Acc: 0.862821 | Val Loss: 0.114558, Val Acc: 0.762887\n",
      "Epoch 15407 - Train Loss: 0.091428, Train Acc: 0.862821 | Val Loss: 0.114556, Val Acc: 0.762887\n",
      "Epoch 15408 - Train Loss: 0.091424, Train Acc: 0.862821 | Val Loss: 0.114554, Val Acc: 0.762887\n",
      "Epoch 15409 - Train Loss: 0.091420, Train Acc: 0.862821 | Val Loss: 0.114551, Val Acc: 0.762887\n",
      "Epoch 15410 - Train Loss: 0.091417, Train Acc: 0.862821 | Val Loss: 0.114549, Val Acc: 0.762887\n",
      "Epoch 15411 - Train Loss: 0.091413, Train Acc: 0.862821 | Val Loss: 0.114547, Val Acc: 0.762887\n",
      "Epoch 15412 - Train Loss: 0.091410, Train Acc: 0.862821 | Val Loss: 0.114544, Val Acc: 0.762887\n",
      "Epoch 15413 - Train Loss: 0.091406, Train Acc: 0.862821 | Val Loss: 0.114542, Val Acc: 0.762887\n",
      "Epoch 15414 - Train Loss: 0.091402, Train Acc: 0.862821 | Val Loss: 0.114540, Val Acc: 0.762887\n",
      "Epoch 15415 - Train Loss: 0.091399, Train Acc: 0.862821 | Val Loss: 0.114537, Val Acc: 0.762887\n",
      "Epoch 15416 - Train Loss: 0.091395, Train Acc: 0.862821 | Val Loss: 0.114535, Val Acc: 0.762887\n",
      "Epoch 15417 - Train Loss: 0.091392, Train Acc: 0.862821 | Val Loss: 0.114533, Val Acc: 0.762887\n",
      "Epoch 15418 - Train Loss: 0.091388, Train Acc: 0.862821 | Val Loss: 0.114530, Val Acc: 0.762887\n",
      "Epoch 15419 - Train Loss: 0.091384, Train Acc: 0.862821 | Val Loss: 0.114528, Val Acc: 0.762887\n",
      "Epoch 15420 - Train Loss: 0.091381, Train Acc: 0.862821 | Val Loss: 0.114526, Val Acc: 0.762887\n",
      "Epoch 15421 - Train Loss: 0.091377, Train Acc: 0.862821 | Val Loss: 0.114523, Val Acc: 0.762887\n",
      "Epoch 15422 - Train Loss: 0.091374, Train Acc: 0.862821 | Val Loss: 0.114521, Val Acc: 0.762887\n",
      "Epoch 15423 - Train Loss: 0.091370, Train Acc: 0.862821 | Val Loss: 0.114519, Val Acc: 0.762887\n",
      "Epoch 15424 - Train Loss: 0.091366, Train Acc: 0.862821 | Val Loss: 0.114516, Val Acc: 0.762887\n",
      "Epoch 15425 - Train Loss: 0.091363, Train Acc: 0.862821 | Val Loss: 0.114514, Val Acc: 0.762887\n",
      "Epoch 15426 - Train Loss: 0.091359, Train Acc: 0.862821 | Val Loss: 0.114512, Val Acc: 0.762887\n",
      "Epoch 15427 - Train Loss: 0.091356, Train Acc: 0.862821 | Val Loss: 0.114509, Val Acc: 0.762887\n",
      "Epoch 15428 - Train Loss: 0.091352, Train Acc: 0.862821 | Val Loss: 0.114507, Val Acc: 0.762887\n",
      "Epoch 15429 - Train Loss: 0.091348, Train Acc: 0.862821 | Val Loss: 0.114505, Val Acc: 0.762887\n",
      "Epoch 15430 - Train Loss: 0.091345, Train Acc: 0.862821 | Val Loss: 0.114502, Val Acc: 0.762887\n",
      "Epoch 15431 - Train Loss: 0.091341, Train Acc: 0.862821 | Val Loss: 0.114500, Val Acc: 0.762887\n",
      "Epoch 15432 - Train Loss: 0.091338, Train Acc: 0.862821 | Val Loss: 0.114498, Val Acc: 0.762887\n",
      "Epoch 15433 - Train Loss: 0.091334, Train Acc: 0.862821 | Val Loss: 0.114495, Val Acc: 0.762887\n",
      "Epoch 15434 - Train Loss: 0.091330, Train Acc: 0.862821 | Val Loss: 0.114493, Val Acc: 0.762887\n",
      "Epoch 15435 - Train Loss: 0.091327, Train Acc: 0.862821 | Val Loss: 0.114491, Val Acc: 0.762887\n",
      "Epoch 15436 - Train Loss: 0.091323, Train Acc: 0.862821 | Val Loss: 0.114488, Val Acc: 0.762887\n",
      "Epoch 15437 - Train Loss: 0.091320, Train Acc: 0.862821 | Val Loss: 0.114486, Val Acc: 0.762887\n",
      "Epoch 15438 - Train Loss: 0.091316, Train Acc: 0.862821 | Val Loss: 0.114484, Val Acc: 0.762887\n",
      "Epoch 15439 - Train Loss: 0.091313, Train Acc: 0.862821 | Val Loss: 0.114481, Val Acc: 0.762887\n",
      "Epoch 15440 - Train Loss: 0.091309, Train Acc: 0.862821 | Val Loss: 0.114479, Val Acc: 0.762887\n",
      "Epoch 15441 - Train Loss: 0.091305, Train Acc: 0.862821 | Val Loss: 0.114477, Val Acc: 0.762887\n",
      "Epoch 15442 - Train Loss: 0.091302, Train Acc: 0.862821 | Val Loss: 0.114474, Val Acc: 0.762887\n",
      "Epoch 15443 - Train Loss: 0.091298, Train Acc: 0.862821 | Val Loss: 0.114472, Val Acc: 0.762887\n",
      "Epoch 15444 - Train Loss: 0.091295, Train Acc: 0.862821 | Val Loss: 0.114470, Val Acc: 0.762887\n",
      "Epoch 15445 - Train Loss: 0.091291, Train Acc: 0.862821 | Val Loss: 0.114467, Val Acc: 0.762887\n",
      "Epoch 15446 - Train Loss: 0.091287, Train Acc: 0.862821 | Val Loss: 0.114465, Val Acc: 0.762887\n",
      "Epoch 15447 - Train Loss: 0.091284, Train Acc: 0.862821 | Val Loss: 0.114463, Val Acc: 0.762887\n",
      "Epoch 15448 - Train Loss: 0.091280, Train Acc: 0.862821 | Val Loss: 0.114460, Val Acc: 0.762887\n",
      "Epoch 15449 - Train Loss: 0.091277, Train Acc: 0.862821 | Val Loss: 0.114458, Val Acc: 0.762887\n",
      "Epoch 15450 - Train Loss: 0.091273, Train Acc: 0.862821 | Val Loss: 0.114456, Val Acc: 0.762887\n",
      "Epoch 15451 - Train Loss: 0.091269, Train Acc: 0.862821 | Val Loss: 0.114453, Val Acc: 0.762887\n",
      "Epoch 15452 - Train Loss: 0.091266, Train Acc: 0.862821 | Val Loss: 0.114451, Val Acc: 0.762887\n",
      "Epoch 15453 - Train Loss: 0.091262, Train Acc: 0.862821 | Val Loss: 0.114449, Val Acc: 0.762887\n",
      "Epoch 15454 - Train Loss: 0.091259, Train Acc: 0.862821 | Val Loss: 0.114446, Val Acc: 0.762887\n",
      "Epoch 15455 - Train Loss: 0.091255, Train Acc: 0.862821 | Val Loss: 0.114444, Val Acc: 0.762887\n",
      "Epoch 15456 - Train Loss: 0.091252, Train Acc: 0.862821 | Val Loss: 0.114442, Val Acc: 0.762887\n",
      "Epoch 15457 - Train Loss: 0.091248, Train Acc: 0.862821 | Val Loss: 0.114439, Val Acc: 0.762887\n",
      "Epoch 15458 - Train Loss: 0.091244, Train Acc: 0.862821 | Val Loss: 0.114437, Val Acc: 0.762887\n",
      "Epoch 15459 - Train Loss: 0.091241, Train Acc: 0.862821 | Val Loss: 0.114435, Val Acc: 0.762887\n",
      "Epoch 15460 - Train Loss: 0.091237, Train Acc: 0.862821 | Val Loss: 0.114433, Val Acc: 0.762887\n",
      "Epoch 15461 - Train Loss: 0.091234, Train Acc: 0.862821 | Val Loss: 0.114430, Val Acc: 0.762887\n",
      "Epoch 15462 - Train Loss: 0.091230, Train Acc: 0.862821 | Val Loss: 0.114428, Val Acc: 0.762887\n",
      "Epoch 15463 - Train Loss: 0.091226, Train Acc: 0.862821 | Val Loss: 0.114426, Val Acc: 0.762887\n",
      "Epoch 15464 - Train Loss: 0.091223, Train Acc: 0.862821 | Val Loss: 0.114423, Val Acc: 0.762887\n",
      "Epoch 15465 - Train Loss: 0.091219, Train Acc: 0.862821 | Val Loss: 0.114421, Val Acc: 0.762887\n",
      "Epoch 15466 - Train Loss: 0.091216, Train Acc: 0.862821 | Val Loss: 0.114419, Val Acc: 0.762887\n",
      "Epoch 15467 - Train Loss: 0.091212, Train Acc: 0.862821 | Val Loss: 0.114416, Val Acc: 0.762887\n",
      "Epoch 15468 - Train Loss: 0.091209, Train Acc: 0.862821 | Val Loss: 0.114414, Val Acc: 0.762887\n",
      "Epoch 15469 - Train Loss: 0.091205, Train Acc: 0.862821 | Val Loss: 0.114412, Val Acc: 0.762887\n",
      "Epoch 15470 - Train Loss: 0.091201, Train Acc: 0.862821 | Val Loss: 0.114409, Val Acc: 0.762887\n",
      "Epoch 15471 - Train Loss: 0.091198, Train Acc: 0.862821 | Val Loss: 0.114407, Val Acc: 0.762887\n",
      "Epoch 15472 - Train Loss: 0.091194, Train Acc: 0.862821 | Val Loss: 0.114405, Val Acc: 0.762887\n",
      "Epoch 15473 - Train Loss: 0.091191, Train Acc: 0.862821 | Val Loss: 0.114402, Val Acc: 0.762887\n",
      "Epoch 15474 - Train Loss: 0.091187, Train Acc: 0.862821 | Val Loss: 0.114400, Val Acc: 0.762887\n",
      "Epoch 15475 - Train Loss: 0.091184, Train Acc: 0.862821 | Val Loss: 0.114398, Val Acc: 0.762887\n",
      "Epoch 15476 - Train Loss: 0.091180, Train Acc: 0.862821 | Val Loss: 0.114395, Val Acc: 0.762887\n",
      "Epoch 15477 - Train Loss: 0.091176, Train Acc: 0.862821 | Val Loss: 0.114393, Val Acc: 0.762887\n",
      "Epoch 15478 - Train Loss: 0.091173, Train Acc: 0.862821 | Val Loss: 0.114391, Val Acc: 0.762887\n",
      "Epoch 15479 - Train Loss: 0.091169, Train Acc: 0.862821 | Val Loss: 0.114389, Val Acc: 0.762887\n",
      "Epoch 15480 - Train Loss: 0.091166, Train Acc: 0.862821 | Val Loss: 0.114386, Val Acc: 0.762887\n",
      "Epoch 15481 - Train Loss: 0.091162, Train Acc: 0.862821 | Val Loss: 0.114384, Val Acc: 0.762887\n",
      "Epoch 15482 - Train Loss: 0.091159, Train Acc: 0.862821 | Val Loss: 0.114382, Val Acc: 0.762887\n",
      "Epoch 15483 - Train Loss: 0.091155, Train Acc: 0.862821 | Val Loss: 0.114379, Val Acc: 0.762887\n",
      "Epoch 15484 - Train Loss: 0.091151, Train Acc: 0.862821 | Val Loss: 0.114377, Val Acc: 0.762887\n",
      "Epoch 15485 - Train Loss: 0.091148, Train Acc: 0.862821 | Val Loss: 0.114375, Val Acc: 0.762887\n",
      "Epoch 15486 - Train Loss: 0.091144, Train Acc: 0.862821 | Val Loss: 0.114372, Val Acc: 0.762887\n",
      "Epoch 15487 - Train Loss: 0.091141, Train Acc: 0.862821 | Val Loss: 0.114370, Val Acc: 0.762887\n",
      "Epoch 15488 - Train Loss: 0.091137, Train Acc: 0.862821 | Val Loss: 0.114368, Val Acc: 0.762887\n",
      "Epoch 15489 - Train Loss: 0.091134, Train Acc: 0.862821 | Val Loss: 0.114365, Val Acc: 0.762887\n",
      "Epoch 15490 - Train Loss: 0.091130, Train Acc: 0.862821 | Val Loss: 0.114363, Val Acc: 0.762887\n",
      "Epoch 15491 - Train Loss: 0.091126, Train Acc: 0.862821 | Val Loss: 0.114361, Val Acc: 0.762887\n",
      "Epoch 15492 - Train Loss: 0.091123, Train Acc: 0.862821 | Val Loss: 0.114359, Val Acc: 0.762887\n",
      "Epoch 15493 - Train Loss: 0.091119, Train Acc: 0.862821 | Val Loss: 0.114356, Val Acc: 0.762887\n",
      "Epoch 15494 - Train Loss: 0.091116, Train Acc: 0.862821 | Val Loss: 0.114354, Val Acc: 0.762887\n",
      "Epoch 15495 - Train Loss: 0.091112, Train Acc: 0.862821 | Val Loss: 0.114352, Val Acc: 0.762887\n",
      "Epoch 15496 - Train Loss: 0.091109, Train Acc: 0.862821 | Val Loss: 0.114349, Val Acc: 0.762887\n",
      "Epoch 15497 - Train Loss: 0.091105, Train Acc: 0.862821 | Val Loss: 0.114347, Val Acc: 0.762887\n",
      "Epoch 15498 - Train Loss: 0.091102, Train Acc: 0.862821 | Val Loss: 0.114345, Val Acc: 0.762887\n",
      "Epoch 15499 - Train Loss: 0.091098, Train Acc: 0.862821 | Val Loss: 0.114342, Val Acc: 0.762887\n",
      "Epoch 15500 - Train Loss: 0.091094, Train Acc: 0.862821 | Val Loss: 0.114340, Val Acc: 0.762887\n",
      "Epoch 15501 - Train Loss: 0.091091, Train Acc: 0.862821 | Val Loss: 0.114338, Val Acc: 0.762887\n",
      "Epoch 15502 - Train Loss: 0.091087, Train Acc: 0.862821 | Val Loss: 0.114336, Val Acc: 0.762887\n",
      "Epoch 15503 - Train Loss: 0.091084, Train Acc: 0.862821 | Val Loss: 0.114333, Val Acc: 0.762887\n",
      "Epoch 15504 - Train Loss: 0.091080, Train Acc: 0.862821 | Val Loss: 0.114331, Val Acc: 0.762887\n",
      "Epoch 15505 - Train Loss: 0.091077, Train Acc: 0.862821 | Val Loss: 0.114329, Val Acc: 0.762887\n",
      "Epoch 15506 - Train Loss: 0.091073, Train Acc: 0.862821 | Val Loss: 0.114326, Val Acc: 0.762887\n",
      "Epoch 15507 - Train Loss: 0.091069, Train Acc: 0.862821 | Val Loss: 0.114324, Val Acc: 0.762887\n",
      "Epoch 15508 - Train Loss: 0.091066, Train Acc: 0.862821 | Val Loss: 0.114322, Val Acc: 0.762887\n",
      "Epoch 15509 - Train Loss: 0.091062, Train Acc: 0.862821 | Val Loss: 0.114319, Val Acc: 0.762887\n",
      "Epoch 15510 - Train Loss: 0.091059, Train Acc: 0.862821 | Val Loss: 0.114317, Val Acc: 0.762887\n",
      "Epoch 15511 - Train Loss: 0.091055, Train Acc: 0.862821 | Val Loss: 0.114315, Val Acc: 0.762887\n",
      "Epoch 15512 - Train Loss: 0.091052, Train Acc: 0.862821 | Val Loss: 0.114313, Val Acc: 0.762887\n",
      "Epoch 15513 - Train Loss: 0.091048, Train Acc: 0.862821 | Val Loss: 0.114310, Val Acc: 0.762887\n",
      "Epoch 15514 - Train Loss: 0.091045, Train Acc: 0.862821 | Val Loss: 0.114308, Val Acc: 0.762887\n",
      "Epoch 15515 - Train Loss: 0.091041, Train Acc: 0.862821 | Val Loss: 0.114306, Val Acc: 0.762887\n",
      "Epoch 15516 - Train Loss: 0.091037, Train Acc: 0.862821 | Val Loss: 0.114303, Val Acc: 0.762887\n",
      "Epoch 15517 - Train Loss: 0.091034, Train Acc: 0.862821 | Val Loss: 0.114301, Val Acc: 0.762887\n",
      "Epoch 15518 - Train Loss: 0.091030, Train Acc: 0.862821 | Val Loss: 0.114299, Val Acc: 0.762887\n",
      "Epoch 15519 - Train Loss: 0.091027, Train Acc: 0.862821 | Val Loss: 0.114297, Val Acc: 0.762887\n",
      "Epoch 15520 - Train Loss: 0.091023, Train Acc: 0.862821 | Val Loss: 0.114294, Val Acc: 0.762887\n",
      "Epoch 15521 - Train Loss: 0.091020, Train Acc: 0.862821 | Val Loss: 0.114292, Val Acc: 0.762887\n",
      "Epoch 15522 - Train Loss: 0.091016, Train Acc: 0.862821 | Val Loss: 0.114290, Val Acc: 0.762887\n",
      "Epoch 15523 - Train Loss: 0.091013, Train Acc: 0.862821 | Val Loss: 0.114287, Val Acc: 0.762887\n",
      "Epoch 15524 - Train Loss: 0.091009, Train Acc: 0.862821 | Val Loss: 0.114285, Val Acc: 0.762887\n",
      "Epoch 15525 - Train Loss: 0.091005, Train Acc: 0.862821 | Val Loss: 0.114283, Val Acc: 0.762887\n",
      "Epoch 15526 - Train Loss: 0.091002, Train Acc: 0.862821 | Val Loss: 0.114281, Val Acc: 0.762887\n",
      "Epoch 15527 - Train Loss: 0.090998, Train Acc: 0.862821 | Val Loss: 0.114278, Val Acc: 0.762887\n",
      "Epoch 15528 - Train Loss: 0.090995, Train Acc: 0.862821 | Val Loss: 0.114276, Val Acc: 0.762887\n",
      "Epoch 15529 - Train Loss: 0.090991, Train Acc: 0.862821 | Val Loss: 0.114274, Val Acc: 0.762887\n",
      "Epoch 15530 - Train Loss: 0.090988, Train Acc: 0.862821 | Val Loss: 0.114271, Val Acc: 0.762887\n",
      "Epoch 15531 - Train Loss: 0.090984, Train Acc: 0.862821 | Val Loss: 0.114269, Val Acc: 0.762887\n",
      "Epoch 15532 - Train Loss: 0.090981, Train Acc: 0.862821 | Val Loss: 0.114267, Val Acc: 0.762887\n",
      "Epoch 15533 - Train Loss: 0.090977, Train Acc: 0.862821 | Val Loss: 0.114265, Val Acc: 0.762887\n",
      "Epoch 15534 - Train Loss: 0.090974, Train Acc: 0.862821 | Val Loss: 0.114262, Val Acc: 0.762887\n",
      "Epoch 15535 - Train Loss: 0.090970, Train Acc: 0.862821 | Val Loss: 0.114260, Val Acc: 0.762887\n",
      "Epoch 15536 - Train Loss: 0.090966, Train Acc: 0.862821 | Val Loss: 0.114258, Val Acc: 0.762887\n",
      "Epoch 15537 - Train Loss: 0.090963, Train Acc: 0.862821 | Val Loss: 0.114255, Val Acc: 0.762887\n",
      "Epoch 15538 - Train Loss: 0.090959, Train Acc: 0.862821 | Val Loss: 0.114253, Val Acc: 0.762887\n",
      "Epoch 15539 - Train Loss: 0.090956, Train Acc: 0.862821 | Val Loss: 0.114251, Val Acc: 0.762887\n",
      "Epoch 15540 - Train Loss: 0.090952, Train Acc: 0.862821 | Val Loss: 0.114249, Val Acc: 0.762887\n",
      "Epoch 15541 - Train Loss: 0.090949, Train Acc: 0.862821 | Val Loss: 0.114246, Val Acc: 0.762887\n",
      "Epoch 15542 - Train Loss: 0.090945, Train Acc: 0.862821 | Val Loss: 0.114244, Val Acc: 0.762887\n",
      "Epoch 15543 - Train Loss: 0.090942, Train Acc: 0.862821 | Val Loss: 0.114242, Val Acc: 0.762887\n",
      "Epoch 15544 - Train Loss: 0.090938, Train Acc: 0.862821 | Val Loss: 0.114239, Val Acc: 0.762887\n",
      "Epoch 15545 - Train Loss: 0.090935, Train Acc: 0.862821 | Val Loss: 0.114237, Val Acc: 0.762887\n",
      "Epoch 15546 - Train Loss: 0.090931, Train Acc: 0.862821 | Val Loss: 0.114235, Val Acc: 0.762887\n",
      "Epoch 15547 - Train Loss: 0.090927, Train Acc: 0.862821 | Val Loss: 0.114233, Val Acc: 0.762887\n",
      "Epoch 15548 - Train Loss: 0.090924, Train Acc: 0.862821 | Val Loss: 0.114230, Val Acc: 0.762887\n",
      "Epoch 15549 - Train Loss: 0.090920, Train Acc: 0.862821 | Val Loss: 0.114228, Val Acc: 0.762887\n",
      "Epoch 15550 - Train Loss: 0.090917, Train Acc: 0.862821 | Val Loss: 0.114226, Val Acc: 0.762887\n",
      "Epoch 15551 - Train Loss: 0.090913, Train Acc: 0.862821 | Val Loss: 0.114223, Val Acc: 0.762887\n",
      "Epoch 15552 - Train Loss: 0.090910, Train Acc: 0.862821 | Val Loss: 0.114221, Val Acc: 0.762887\n",
      "Epoch 15553 - Train Loss: 0.090906, Train Acc: 0.862821 | Val Loss: 0.114219, Val Acc: 0.762887\n",
      "Epoch 15554 - Train Loss: 0.090903, Train Acc: 0.862821 | Val Loss: 0.114217, Val Acc: 0.762887\n",
      "Epoch 15555 - Train Loss: 0.090899, Train Acc: 0.862821 | Val Loss: 0.114214, Val Acc: 0.762887\n",
      "Epoch 15556 - Train Loss: 0.090896, Train Acc: 0.862821 | Val Loss: 0.114212, Val Acc: 0.762887\n",
      "Epoch 15557 - Train Loss: 0.090892, Train Acc: 0.862821 | Val Loss: 0.114210, Val Acc: 0.762887\n",
      "Epoch 15558 - Train Loss: 0.090889, Train Acc: 0.862821 | Val Loss: 0.114208, Val Acc: 0.762887\n",
      "Epoch 15559 - Train Loss: 0.090885, Train Acc: 0.862821 | Val Loss: 0.114205, Val Acc: 0.762887\n",
      "Epoch 15560 - Train Loss: 0.090881, Train Acc: 0.862821 | Val Loss: 0.114203, Val Acc: 0.762887\n",
      "Epoch 15561 - Train Loss: 0.090878, Train Acc: 0.862821 | Val Loss: 0.114201, Val Acc: 0.762887\n",
      "Epoch 15562 - Train Loss: 0.090874, Train Acc: 0.862821 | Val Loss: 0.114198, Val Acc: 0.762887\n",
      "Epoch 15563 - Train Loss: 0.090871, Train Acc: 0.862821 | Val Loss: 0.114196, Val Acc: 0.762887\n",
      "Epoch 15564 - Train Loss: 0.090867, Train Acc: 0.862821 | Val Loss: 0.114194, Val Acc: 0.762887\n",
      "Epoch 15565 - Train Loss: 0.090864, Train Acc: 0.862821 | Val Loss: 0.114192, Val Acc: 0.762887\n",
      "Epoch 15566 - Train Loss: 0.090860, Train Acc: 0.862821 | Val Loss: 0.114189, Val Acc: 0.762887\n",
      "Epoch 15567 - Train Loss: 0.090857, Train Acc: 0.862821 | Val Loss: 0.114187, Val Acc: 0.762887\n",
      "Epoch 15568 - Train Loss: 0.090853, Train Acc: 0.862821 | Val Loss: 0.114185, Val Acc: 0.762887\n",
      "Epoch 15569 - Train Loss: 0.090850, Train Acc: 0.862821 | Val Loss: 0.114183, Val Acc: 0.762887\n",
      "Epoch 15570 - Train Loss: 0.090846, Train Acc: 0.862821 | Val Loss: 0.114180, Val Acc: 0.762887\n",
      "Epoch 15571 - Train Loss: 0.090843, Train Acc: 0.862821 | Val Loss: 0.114178, Val Acc: 0.762887\n",
      "Epoch 15572 - Train Loss: 0.090839, Train Acc: 0.862821 | Val Loss: 0.114176, Val Acc: 0.762887\n",
      "Epoch 15573 - Train Loss: 0.090836, Train Acc: 0.862821 | Val Loss: 0.114173, Val Acc: 0.762887\n",
      "Epoch 15574 - Train Loss: 0.090832, Train Acc: 0.862821 | Val Loss: 0.114171, Val Acc: 0.762887\n",
      "Epoch 15575 - Train Loss: 0.090829, Train Acc: 0.862821 | Val Loss: 0.114169, Val Acc: 0.762887\n",
      "Epoch 15576 - Train Loss: 0.090825, Train Acc: 0.862821 | Val Loss: 0.114167, Val Acc: 0.762887\n",
      "Epoch 15577 - Train Loss: 0.090821, Train Acc: 0.862821 | Val Loss: 0.114164, Val Acc: 0.762887\n",
      "Epoch 15578 - Train Loss: 0.090818, Train Acc: 0.862821 | Val Loss: 0.114162, Val Acc: 0.762887\n",
      "Epoch 15579 - Train Loss: 0.090814, Train Acc: 0.862821 | Val Loss: 0.114160, Val Acc: 0.762887\n",
      "Epoch 15580 - Train Loss: 0.090811, Train Acc: 0.862821 | Val Loss: 0.114158, Val Acc: 0.762887\n",
      "Epoch 15581 - Train Loss: 0.090807, Train Acc: 0.862821 | Val Loss: 0.114155, Val Acc: 0.762887\n",
      "Epoch 15582 - Train Loss: 0.090804, Train Acc: 0.862821 | Val Loss: 0.114153, Val Acc: 0.762887\n",
      "Epoch 15583 - Train Loss: 0.090800, Train Acc: 0.862821 | Val Loss: 0.114151, Val Acc: 0.762887\n",
      "Epoch 15584 - Train Loss: 0.090797, Train Acc: 0.862821 | Val Loss: 0.114149, Val Acc: 0.762887\n",
      "Epoch 15585 - Train Loss: 0.090793, Train Acc: 0.862821 | Val Loss: 0.114146, Val Acc: 0.773196\n",
      "Epoch 15586 - Train Loss: 0.090790, Train Acc: 0.862821 | Val Loss: 0.114144, Val Acc: 0.773196\n",
      "Epoch 15587 - Train Loss: 0.090786, Train Acc: 0.862821 | Val Loss: 0.114142, Val Acc: 0.773196\n",
      "Epoch 15588 - Train Loss: 0.090783, Train Acc: 0.862821 | Val Loss: 0.114140, Val Acc: 0.773196\n",
      "Epoch 15589 - Train Loss: 0.090779, Train Acc: 0.862821 | Val Loss: 0.114137, Val Acc: 0.773196\n",
      "Epoch 15590 - Train Loss: 0.090776, Train Acc: 0.862821 | Val Loss: 0.114135, Val Acc: 0.773196\n",
      "Epoch 15591 - Train Loss: 0.090772, Train Acc: 0.862821 | Val Loss: 0.114133, Val Acc: 0.773196\n",
      "Epoch 15592 - Train Loss: 0.090769, Train Acc: 0.862821 | Val Loss: 0.114130, Val Acc: 0.773196\n",
      "Epoch 15593 - Train Loss: 0.090765, Train Acc: 0.862821 | Val Loss: 0.114128, Val Acc: 0.773196\n",
      "Epoch 15594 - Train Loss: 0.090762, Train Acc: 0.862821 | Val Loss: 0.114126, Val Acc: 0.773196\n",
      "Epoch 15595 - Train Loss: 0.090758, Train Acc: 0.862821 | Val Loss: 0.114124, Val Acc: 0.773196\n",
      "Epoch 15596 - Train Loss: 0.090754, Train Acc: 0.862821 | Val Loss: 0.114121, Val Acc: 0.773196\n",
      "Epoch 15597 - Train Loss: 0.090751, Train Acc: 0.862821 | Val Loss: 0.114119, Val Acc: 0.773196\n",
      "Epoch 15598 - Train Loss: 0.090747, Train Acc: 0.862821 | Val Loss: 0.114117, Val Acc: 0.773196\n",
      "Epoch 15599 - Train Loss: 0.090744, Train Acc: 0.862821 | Val Loss: 0.114115, Val Acc: 0.773196\n",
      "Epoch 15600 - Train Loss: 0.090740, Train Acc: 0.862821 | Val Loss: 0.114112, Val Acc: 0.773196\n",
      "Epoch 15601 - Train Loss: 0.090737, Train Acc: 0.862821 | Val Loss: 0.114110, Val Acc: 0.773196\n",
      "Epoch 15602 - Train Loss: 0.090733, Train Acc: 0.862821 | Val Loss: 0.114108, Val Acc: 0.773196\n",
      "Epoch 15603 - Train Loss: 0.090730, Train Acc: 0.862821 | Val Loss: 0.114106, Val Acc: 0.773196\n",
      "Epoch 15604 - Train Loss: 0.090726, Train Acc: 0.862821 | Val Loss: 0.114103, Val Acc: 0.773196\n",
      "Epoch 15605 - Train Loss: 0.090723, Train Acc: 0.864103 | Val Loss: 0.114101, Val Acc: 0.773196\n",
      "Epoch 15606 - Train Loss: 0.090719, Train Acc: 0.864103 | Val Loss: 0.114099, Val Acc: 0.773196\n",
      "Epoch 15607 - Train Loss: 0.090716, Train Acc: 0.864103 | Val Loss: 0.114097, Val Acc: 0.773196\n",
      "Epoch 15608 - Train Loss: 0.090712, Train Acc: 0.864103 | Val Loss: 0.114094, Val Acc: 0.773196\n",
      "Epoch 15609 - Train Loss: 0.090709, Train Acc: 0.864103 | Val Loss: 0.114092, Val Acc: 0.773196\n",
      "Epoch 15610 - Train Loss: 0.090705, Train Acc: 0.864103 | Val Loss: 0.114090, Val Acc: 0.773196\n",
      "Epoch 15611 - Train Loss: 0.090702, Train Acc: 0.864103 | Val Loss: 0.114088, Val Acc: 0.773196\n",
      "Epoch 15612 - Train Loss: 0.090698, Train Acc: 0.864103 | Val Loss: 0.114085, Val Acc: 0.773196\n",
      "Epoch 15613 - Train Loss: 0.090695, Train Acc: 0.864103 | Val Loss: 0.114083, Val Acc: 0.773196\n",
      "Epoch 15614 - Train Loss: 0.090691, Train Acc: 0.864103 | Val Loss: 0.114081, Val Acc: 0.773196\n",
      "Epoch 15615 - Train Loss: 0.090688, Train Acc: 0.864103 | Val Loss: 0.114079, Val Acc: 0.773196\n",
      "Epoch 15616 - Train Loss: 0.090684, Train Acc: 0.864103 | Val Loss: 0.114076, Val Acc: 0.773196\n",
      "Epoch 15617 - Train Loss: 0.090681, Train Acc: 0.864103 | Val Loss: 0.114074, Val Acc: 0.773196\n",
      "Epoch 15618 - Train Loss: 0.090677, Train Acc: 0.864103 | Val Loss: 0.114072, Val Acc: 0.773196\n",
      "Epoch 15619 - Train Loss: 0.090674, Train Acc: 0.864103 | Val Loss: 0.114070, Val Acc: 0.773196\n",
      "Epoch 15620 - Train Loss: 0.090670, Train Acc: 0.864103 | Val Loss: 0.114067, Val Acc: 0.773196\n",
      "Epoch 15621 - Train Loss: 0.090667, Train Acc: 0.864103 | Val Loss: 0.114065, Val Acc: 0.773196\n",
      "Epoch 15622 - Train Loss: 0.090663, Train Acc: 0.864103 | Val Loss: 0.114063, Val Acc: 0.773196\n",
      "Epoch 15623 - Train Loss: 0.090660, Train Acc: 0.864103 | Val Loss: 0.114061, Val Acc: 0.773196\n",
      "Epoch 15624 - Train Loss: 0.090656, Train Acc: 0.864103 | Val Loss: 0.114058, Val Acc: 0.773196\n",
      "Epoch 15625 - Train Loss: 0.090653, Train Acc: 0.864103 | Val Loss: 0.114056, Val Acc: 0.773196\n",
      "Epoch 15626 - Train Loss: 0.090649, Train Acc: 0.864103 | Val Loss: 0.114054, Val Acc: 0.773196\n",
      "Epoch 15627 - Train Loss: 0.090646, Train Acc: 0.864103 | Val Loss: 0.114052, Val Acc: 0.773196\n",
      "Epoch 15628 - Train Loss: 0.090642, Train Acc: 0.864103 | Val Loss: 0.114049, Val Acc: 0.773196\n",
      "Epoch 15629 - Train Loss: 0.090639, Train Acc: 0.864103 | Val Loss: 0.114047, Val Acc: 0.773196\n",
      "Epoch 15630 - Train Loss: 0.090635, Train Acc: 0.864103 | Val Loss: 0.114045, Val Acc: 0.773196\n",
      "Epoch 15631 - Train Loss: 0.090632, Train Acc: 0.864103 | Val Loss: 0.114043, Val Acc: 0.773196\n",
      "Epoch 15632 - Train Loss: 0.090628, Train Acc: 0.864103 | Val Loss: 0.114040, Val Acc: 0.773196\n",
      "Epoch 15633 - Train Loss: 0.090625, Train Acc: 0.864103 | Val Loss: 0.114038, Val Acc: 0.773196\n",
      "Epoch 15634 - Train Loss: 0.090621, Train Acc: 0.864103 | Val Loss: 0.114036, Val Acc: 0.773196\n",
      "Epoch 15635 - Train Loss: 0.090618, Train Acc: 0.864103 | Val Loss: 0.114034, Val Acc: 0.773196\n",
      "Epoch 15636 - Train Loss: 0.090614, Train Acc: 0.864103 | Val Loss: 0.114032, Val Acc: 0.773196\n",
      "Epoch 15637 - Train Loss: 0.090611, Train Acc: 0.864103 | Val Loss: 0.114029, Val Acc: 0.773196\n",
      "Epoch 15638 - Train Loss: 0.090607, Train Acc: 0.864103 | Val Loss: 0.114027, Val Acc: 0.773196\n",
      "Epoch 15639 - Train Loss: 0.090604, Train Acc: 0.864103 | Val Loss: 0.114025, Val Acc: 0.773196\n",
      "Epoch 15640 - Train Loss: 0.090600, Train Acc: 0.864103 | Val Loss: 0.114023, Val Acc: 0.773196\n",
      "Epoch 15641 - Train Loss: 0.090597, Train Acc: 0.864103 | Val Loss: 0.114020, Val Acc: 0.773196\n",
      "Epoch 15642 - Train Loss: 0.090593, Train Acc: 0.864103 | Val Loss: 0.114018, Val Acc: 0.773196\n",
      "Epoch 15643 - Train Loss: 0.090590, Train Acc: 0.864103 | Val Loss: 0.114016, Val Acc: 0.773196\n",
      "Epoch 15644 - Train Loss: 0.090586, Train Acc: 0.864103 | Val Loss: 0.114014, Val Acc: 0.773196\n",
      "Epoch 15645 - Train Loss: 0.090583, Train Acc: 0.864103 | Val Loss: 0.114011, Val Acc: 0.773196\n",
      "Epoch 15646 - Train Loss: 0.090579, Train Acc: 0.864103 | Val Loss: 0.114009, Val Acc: 0.773196\n",
      "Epoch 15647 - Train Loss: 0.090576, Train Acc: 0.864103 | Val Loss: 0.114007, Val Acc: 0.773196\n",
      "Epoch 15648 - Train Loss: 0.090572, Train Acc: 0.864103 | Val Loss: 0.114005, Val Acc: 0.773196\n",
      "Epoch 15649 - Train Loss: 0.090569, Train Acc: 0.864103 | Val Loss: 0.114002, Val Acc: 0.773196\n",
      "Epoch 15650 - Train Loss: 0.090565, Train Acc: 0.864103 | Val Loss: 0.114000, Val Acc: 0.773196\n",
      "Epoch 15651 - Train Loss: 0.090562, Train Acc: 0.864103 | Val Loss: 0.113998, Val Acc: 0.773196\n",
      "Epoch 15652 - Train Loss: 0.090558, Train Acc: 0.864103 | Val Loss: 0.113996, Val Acc: 0.773196\n",
      "Epoch 15653 - Train Loss: 0.090555, Train Acc: 0.864103 | Val Loss: 0.113994, Val Acc: 0.773196\n",
      "Epoch 15654 - Train Loss: 0.090551, Train Acc: 0.864103 | Val Loss: 0.113991, Val Acc: 0.773196\n",
      "Epoch 15655 - Train Loss: 0.090548, Train Acc: 0.864103 | Val Loss: 0.113989, Val Acc: 0.773196\n",
      "Epoch 15656 - Train Loss: 0.090544, Train Acc: 0.864103 | Val Loss: 0.113987, Val Acc: 0.773196\n",
      "Epoch 15657 - Train Loss: 0.090541, Train Acc: 0.864103 | Val Loss: 0.113985, Val Acc: 0.773196\n",
      "Epoch 15658 - Train Loss: 0.090537, Train Acc: 0.864103 | Val Loss: 0.113982, Val Acc: 0.773196\n",
      "Epoch 15659 - Train Loss: 0.090534, Train Acc: 0.864103 | Val Loss: 0.113980, Val Acc: 0.773196\n",
      "Epoch 15660 - Train Loss: 0.090530, Train Acc: 0.864103 | Val Loss: 0.113978, Val Acc: 0.773196\n",
      "Epoch 15661 - Train Loss: 0.090527, Train Acc: 0.864103 | Val Loss: 0.113976, Val Acc: 0.773196\n",
      "Epoch 15662 - Train Loss: 0.090523, Train Acc: 0.864103 | Val Loss: 0.113973, Val Acc: 0.773196\n",
      "Epoch 15663 - Train Loss: 0.090520, Train Acc: 0.864103 | Val Loss: 0.113971, Val Acc: 0.773196\n",
      "Epoch 15664 - Train Loss: 0.090516, Train Acc: 0.864103 | Val Loss: 0.113969, Val Acc: 0.773196\n",
      "Epoch 15665 - Train Loss: 0.090513, Train Acc: 0.864103 | Val Loss: 0.113967, Val Acc: 0.773196\n",
      "Epoch 15666 - Train Loss: 0.090509, Train Acc: 0.864103 | Val Loss: 0.113965, Val Acc: 0.773196\n",
      "Epoch 15667 - Train Loss: 0.090506, Train Acc: 0.864103 | Val Loss: 0.113962, Val Acc: 0.773196\n",
      "Epoch 15668 - Train Loss: 0.090502, Train Acc: 0.864103 | Val Loss: 0.113960, Val Acc: 0.773196\n",
      "Epoch 15669 - Train Loss: 0.090499, Train Acc: 0.864103 | Val Loss: 0.113958, Val Acc: 0.773196\n",
      "Epoch 15670 - Train Loss: 0.090495, Train Acc: 0.864103 | Val Loss: 0.113956, Val Acc: 0.773196\n",
      "Epoch 15671 - Train Loss: 0.090492, Train Acc: 0.864103 | Val Loss: 0.113953, Val Acc: 0.773196\n",
      "Epoch 15672 - Train Loss: 0.090488, Train Acc: 0.864103 | Val Loss: 0.113951, Val Acc: 0.773196\n",
      "Epoch 15673 - Train Loss: 0.090485, Train Acc: 0.864103 | Val Loss: 0.113949, Val Acc: 0.773196\n",
      "Epoch 15674 - Train Loss: 0.090481, Train Acc: 0.864103 | Val Loss: 0.113947, Val Acc: 0.773196\n",
      "Epoch 15675 - Train Loss: 0.090478, Train Acc: 0.864103 | Val Loss: 0.113945, Val Acc: 0.773196\n",
      "Epoch 15676 - Train Loss: 0.090474, Train Acc: 0.864103 | Val Loss: 0.113942, Val Acc: 0.773196\n",
      "Epoch 15677 - Train Loss: 0.090471, Train Acc: 0.864103 | Val Loss: 0.113940, Val Acc: 0.773196\n",
      "Epoch 15678 - Train Loss: 0.090467, Train Acc: 0.864103 | Val Loss: 0.113938, Val Acc: 0.773196\n",
      "Epoch 15679 - Train Loss: 0.090464, Train Acc: 0.864103 | Val Loss: 0.113936, Val Acc: 0.773196\n",
      "Epoch 15680 - Train Loss: 0.090460, Train Acc: 0.864103 | Val Loss: 0.113933, Val Acc: 0.773196\n",
      "Epoch 15681 - Train Loss: 0.090457, Train Acc: 0.864103 | Val Loss: 0.113931, Val Acc: 0.773196\n",
      "Epoch 15682 - Train Loss: 0.090453, Train Acc: 0.864103 | Val Loss: 0.113929, Val Acc: 0.773196\n",
      "Epoch 15683 - Train Loss: 0.090450, Train Acc: 0.864103 | Val Loss: 0.113927, Val Acc: 0.773196\n",
      "Epoch 15684 - Train Loss: 0.090446, Train Acc: 0.864103 | Val Loss: 0.113925, Val Acc: 0.773196\n",
      "Epoch 15685 - Train Loss: 0.090443, Train Acc: 0.864103 | Val Loss: 0.113922, Val Acc: 0.773196\n",
      "Epoch 15686 - Train Loss: 0.090440, Train Acc: 0.864103 | Val Loss: 0.113920, Val Acc: 0.773196\n",
      "Epoch 15687 - Train Loss: 0.090436, Train Acc: 0.864103 | Val Loss: 0.113918, Val Acc: 0.773196\n",
      "Epoch 15688 - Train Loss: 0.090433, Train Acc: 0.864103 | Val Loss: 0.113916, Val Acc: 0.773196\n",
      "Epoch 15689 - Train Loss: 0.090429, Train Acc: 0.864103 | Val Loss: 0.113914, Val Acc: 0.773196\n",
      "Epoch 15690 - Train Loss: 0.090426, Train Acc: 0.864103 | Val Loss: 0.113911, Val Acc: 0.773196\n",
      "Epoch 15691 - Train Loss: 0.090422, Train Acc: 0.864103 | Val Loss: 0.113909, Val Acc: 0.773196\n",
      "Epoch 15692 - Train Loss: 0.090419, Train Acc: 0.864103 | Val Loss: 0.113907, Val Acc: 0.773196\n",
      "Epoch 15693 - Train Loss: 0.090415, Train Acc: 0.864103 | Val Loss: 0.113905, Val Acc: 0.773196\n",
      "Epoch 15694 - Train Loss: 0.090412, Train Acc: 0.864103 | Val Loss: 0.113903, Val Acc: 0.773196\n",
      "Epoch 15695 - Train Loss: 0.090408, Train Acc: 0.864103 | Val Loss: 0.113900, Val Acc: 0.773196\n",
      "Epoch 15696 - Train Loss: 0.090405, Train Acc: 0.864103 | Val Loss: 0.113898, Val Acc: 0.773196\n",
      "Epoch 15697 - Train Loss: 0.090401, Train Acc: 0.864103 | Val Loss: 0.113896, Val Acc: 0.773196\n",
      "Epoch 15698 - Train Loss: 0.090398, Train Acc: 0.864103 | Val Loss: 0.113894, Val Acc: 0.773196\n",
      "Epoch 15699 - Train Loss: 0.090394, Train Acc: 0.864103 | Val Loss: 0.113891, Val Acc: 0.773196\n",
      "Epoch 15700 - Train Loss: 0.090391, Train Acc: 0.864103 | Val Loss: 0.113889, Val Acc: 0.773196\n",
      "Epoch 15701 - Train Loss: 0.090387, Train Acc: 0.864103 | Val Loss: 0.113887, Val Acc: 0.773196\n",
      "Epoch 15702 - Train Loss: 0.090384, Train Acc: 0.864103 | Val Loss: 0.113885, Val Acc: 0.773196\n",
      "Epoch 15703 - Train Loss: 0.090380, Train Acc: 0.864103 | Val Loss: 0.113883, Val Acc: 0.773196\n",
      "Epoch 15704 - Train Loss: 0.090377, Train Acc: 0.864103 | Val Loss: 0.113880, Val Acc: 0.773196\n",
      "Epoch 15705 - Train Loss: 0.090373, Train Acc: 0.864103 | Val Loss: 0.113878, Val Acc: 0.773196\n",
      "Epoch 15706 - Train Loss: 0.090370, Train Acc: 0.864103 | Val Loss: 0.113876, Val Acc: 0.773196\n",
      "Epoch 15707 - Train Loss: 0.090367, Train Acc: 0.864103 | Val Loss: 0.113874, Val Acc: 0.773196\n",
      "Epoch 15708 - Train Loss: 0.090363, Train Acc: 0.864103 | Val Loss: 0.113872, Val Acc: 0.773196\n",
      "Epoch 15709 - Train Loss: 0.090360, Train Acc: 0.864103 | Val Loss: 0.113869, Val Acc: 0.773196\n",
      "Epoch 15710 - Train Loss: 0.090356, Train Acc: 0.864103 | Val Loss: 0.113867, Val Acc: 0.773196\n",
      "Epoch 15711 - Train Loss: 0.090353, Train Acc: 0.864103 | Val Loss: 0.113865, Val Acc: 0.773196\n",
      "Epoch 15712 - Train Loss: 0.090349, Train Acc: 0.864103 | Val Loss: 0.113863, Val Acc: 0.773196\n",
      "Epoch 15713 - Train Loss: 0.090346, Train Acc: 0.864103 | Val Loss: 0.113861, Val Acc: 0.773196\n",
      "Epoch 15714 - Train Loss: 0.090342, Train Acc: 0.864103 | Val Loss: 0.113858, Val Acc: 0.773196\n",
      "Epoch 15715 - Train Loss: 0.090339, Train Acc: 0.864103 | Val Loss: 0.113856, Val Acc: 0.773196\n",
      "Epoch 15716 - Train Loss: 0.090335, Train Acc: 0.864103 | Val Loss: 0.113854, Val Acc: 0.773196\n",
      "Epoch 15717 - Train Loss: 0.090332, Train Acc: 0.864103 | Val Loss: 0.113852, Val Acc: 0.773196\n",
      "Epoch 15718 - Train Loss: 0.090328, Train Acc: 0.864103 | Val Loss: 0.113850, Val Acc: 0.773196\n",
      "Epoch 15719 - Train Loss: 0.090325, Train Acc: 0.864103 | Val Loss: 0.113847, Val Acc: 0.773196\n",
      "Epoch 15720 - Train Loss: 0.090321, Train Acc: 0.864103 | Val Loss: 0.113845, Val Acc: 0.773196\n",
      "Epoch 15721 - Train Loss: 0.090318, Train Acc: 0.864103 | Val Loss: 0.113843, Val Acc: 0.773196\n",
      "Epoch 15722 - Train Loss: 0.090314, Train Acc: 0.864103 | Val Loss: 0.113841, Val Acc: 0.773196\n",
      "Epoch 15723 - Train Loss: 0.090311, Train Acc: 0.864103 | Val Loss: 0.113839, Val Acc: 0.773196\n",
      "Epoch 15724 - Train Loss: 0.090308, Train Acc: 0.864103 | Val Loss: 0.113836, Val Acc: 0.773196\n",
      "Epoch 15725 - Train Loss: 0.090304, Train Acc: 0.864103 | Val Loss: 0.113834, Val Acc: 0.773196\n",
      "Epoch 15726 - Train Loss: 0.090301, Train Acc: 0.864103 | Val Loss: 0.113832, Val Acc: 0.773196\n",
      "Epoch 15727 - Train Loss: 0.090297, Train Acc: 0.864103 | Val Loss: 0.113830, Val Acc: 0.773196\n",
      "Epoch 15728 - Train Loss: 0.090294, Train Acc: 0.864103 | Val Loss: 0.113828, Val Acc: 0.773196\n",
      "Epoch 15729 - Train Loss: 0.090290, Train Acc: 0.864103 | Val Loss: 0.113825, Val Acc: 0.773196\n",
      "Epoch 15730 - Train Loss: 0.090287, Train Acc: 0.864103 | Val Loss: 0.113823, Val Acc: 0.773196\n",
      "Epoch 15731 - Train Loss: 0.090283, Train Acc: 0.864103 | Val Loss: 0.113821, Val Acc: 0.773196\n",
      "Epoch 15732 - Train Loss: 0.090280, Train Acc: 0.864103 | Val Loss: 0.113819, Val Acc: 0.773196\n",
      "Epoch 15733 - Train Loss: 0.090276, Train Acc: 0.864103 | Val Loss: 0.113817, Val Acc: 0.773196\n",
      "Epoch 15734 - Train Loss: 0.090273, Train Acc: 0.864103 | Val Loss: 0.113815, Val Acc: 0.773196\n",
      "Epoch 15735 - Train Loss: 0.090269, Train Acc: 0.864103 | Val Loss: 0.113812, Val Acc: 0.773196\n",
      "Epoch 15736 - Train Loss: 0.090266, Train Acc: 0.864103 | Val Loss: 0.113810, Val Acc: 0.773196\n",
      "Epoch 15737 - Train Loss: 0.090263, Train Acc: 0.864103 | Val Loss: 0.113808, Val Acc: 0.773196\n",
      "Epoch 15738 - Train Loss: 0.090259, Train Acc: 0.864103 | Val Loss: 0.113806, Val Acc: 0.773196\n",
      "Epoch 15739 - Train Loss: 0.090256, Train Acc: 0.864103 | Val Loss: 0.113804, Val Acc: 0.773196\n",
      "Epoch 15740 - Train Loss: 0.090252, Train Acc: 0.864103 | Val Loss: 0.113801, Val Acc: 0.773196\n",
      "Epoch 15741 - Train Loss: 0.090249, Train Acc: 0.864103 | Val Loss: 0.113799, Val Acc: 0.773196\n",
      "Epoch 15742 - Train Loss: 0.090245, Train Acc: 0.864103 | Val Loss: 0.113797, Val Acc: 0.773196\n",
      "Epoch 15743 - Train Loss: 0.090242, Train Acc: 0.864103 | Val Loss: 0.113795, Val Acc: 0.773196\n",
      "Epoch 15744 - Train Loss: 0.090238, Train Acc: 0.864103 | Val Loss: 0.113793, Val Acc: 0.773196\n",
      "Epoch 15745 - Train Loss: 0.090235, Train Acc: 0.864103 | Val Loss: 0.113790, Val Acc: 0.773196\n",
      "Epoch 15746 - Train Loss: 0.090231, Train Acc: 0.864103 | Val Loss: 0.113788, Val Acc: 0.773196\n",
      "Epoch 15747 - Train Loss: 0.090228, Train Acc: 0.864103 | Val Loss: 0.113786, Val Acc: 0.773196\n",
      "Epoch 15748 - Train Loss: 0.090225, Train Acc: 0.864103 | Val Loss: 0.113784, Val Acc: 0.773196\n",
      "Epoch 15749 - Train Loss: 0.090221, Train Acc: 0.864103 | Val Loss: 0.113782, Val Acc: 0.773196\n",
      "Epoch 15750 - Train Loss: 0.090218, Train Acc: 0.864103 | Val Loss: 0.113780, Val Acc: 0.773196\n",
      "Epoch 15751 - Train Loss: 0.090214, Train Acc: 0.864103 | Val Loss: 0.113777, Val Acc: 0.773196\n",
      "Epoch 15752 - Train Loss: 0.090211, Train Acc: 0.864103 | Val Loss: 0.113775, Val Acc: 0.773196\n",
      "Epoch 15753 - Train Loss: 0.090207, Train Acc: 0.864103 | Val Loss: 0.113773, Val Acc: 0.773196\n",
      "Epoch 15754 - Train Loss: 0.090204, Train Acc: 0.864103 | Val Loss: 0.113771, Val Acc: 0.773196\n",
      "Epoch 15755 - Train Loss: 0.090200, Train Acc: 0.864103 | Val Loss: 0.113769, Val Acc: 0.773196\n",
      "Epoch 15756 - Train Loss: 0.090197, Train Acc: 0.864103 | Val Loss: 0.113766, Val Acc: 0.773196\n",
      "Epoch 15757 - Train Loss: 0.090193, Train Acc: 0.864103 | Val Loss: 0.113764, Val Acc: 0.773196\n",
      "Epoch 15758 - Train Loss: 0.090190, Train Acc: 0.864103 | Val Loss: 0.113762, Val Acc: 0.773196\n",
      "Epoch 15759 - Train Loss: 0.090187, Train Acc: 0.864103 | Val Loss: 0.113760, Val Acc: 0.773196\n",
      "Epoch 15760 - Train Loss: 0.090183, Train Acc: 0.864103 | Val Loss: 0.113758, Val Acc: 0.773196\n",
      "Epoch 15761 - Train Loss: 0.090180, Train Acc: 0.864103 | Val Loss: 0.113756, Val Acc: 0.773196\n",
      "Epoch 15762 - Train Loss: 0.090176, Train Acc: 0.864103 | Val Loss: 0.113753, Val Acc: 0.773196\n",
      "Epoch 15763 - Train Loss: 0.090173, Train Acc: 0.864103 | Val Loss: 0.113751, Val Acc: 0.773196\n",
      "Epoch 15764 - Train Loss: 0.090169, Train Acc: 0.864103 | Val Loss: 0.113749, Val Acc: 0.773196\n",
      "Epoch 15765 - Train Loss: 0.090166, Train Acc: 0.864103 | Val Loss: 0.113747, Val Acc: 0.773196\n",
      "Epoch 15766 - Train Loss: 0.090162, Train Acc: 0.864103 | Val Loss: 0.113745, Val Acc: 0.773196\n",
      "Epoch 15767 - Train Loss: 0.090159, Train Acc: 0.864103 | Val Loss: 0.113742, Val Acc: 0.773196\n",
      "Epoch 15768 - Train Loss: 0.090156, Train Acc: 0.864103 | Val Loss: 0.113740, Val Acc: 0.773196\n",
      "Epoch 15769 - Train Loss: 0.090152, Train Acc: 0.864103 | Val Loss: 0.113738, Val Acc: 0.773196\n",
      "Epoch 15770 - Train Loss: 0.090149, Train Acc: 0.864103 | Val Loss: 0.113736, Val Acc: 0.773196\n",
      "Epoch 15771 - Train Loss: 0.090145, Train Acc: 0.864103 | Val Loss: 0.113734, Val Acc: 0.773196\n",
      "Epoch 15772 - Train Loss: 0.090142, Train Acc: 0.864103 | Val Loss: 0.113732, Val Acc: 0.773196\n",
      "Epoch 15773 - Train Loss: 0.090138, Train Acc: 0.864103 | Val Loss: 0.113729, Val Acc: 0.773196\n",
      "Epoch 15774 - Train Loss: 0.090135, Train Acc: 0.864103 | Val Loss: 0.113727, Val Acc: 0.773196\n",
      "Epoch 15775 - Train Loss: 0.090131, Train Acc: 0.864103 | Val Loss: 0.113725, Val Acc: 0.773196\n",
      "Epoch 15776 - Train Loss: 0.090128, Train Acc: 0.864103 | Val Loss: 0.113723, Val Acc: 0.773196\n",
      "Epoch 15777 - Train Loss: 0.090125, Train Acc: 0.864103 | Val Loss: 0.113721, Val Acc: 0.773196\n",
      "Epoch 15778 - Train Loss: 0.090121, Train Acc: 0.864103 | Val Loss: 0.113718, Val Acc: 0.773196\n",
      "Epoch 15779 - Train Loss: 0.090118, Train Acc: 0.864103 | Val Loss: 0.113716, Val Acc: 0.773196\n",
      "Epoch 15780 - Train Loss: 0.090114, Train Acc: 0.864103 | Val Loss: 0.113714, Val Acc: 0.773196\n",
      "Epoch 15781 - Train Loss: 0.090111, Train Acc: 0.864103 | Val Loss: 0.113712, Val Acc: 0.773196\n",
      "Epoch 15782 - Train Loss: 0.090107, Train Acc: 0.864103 | Val Loss: 0.113710, Val Acc: 0.773196\n",
      "Epoch 15783 - Train Loss: 0.090104, Train Acc: 0.864103 | Val Loss: 0.113708, Val Acc: 0.773196\n",
      "Epoch 15784 - Train Loss: 0.090101, Train Acc: 0.864103 | Val Loss: 0.113705, Val Acc: 0.773196\n",
      "Epoch 15785 - Train Loss: 0.090097, Train Acc: 0.865385 | Val Loss: 0.113703, Val Acc: 0.773196\n",
      "Epoch 15786 - Train Loss: 0.090094, Train Acc: 0.865385 | Val Loss: 0.113701, Val Acc: 0.773196\n",
      "Epoch 15787 - Train Loss: 0.090090, Train Acc: 0.865385 | Val Loss: 0.113699, Val Acc: 0.773196\n",
      "Epoch 15788 - Train Loss: 0.090087, Train Acc: 0.865385 | Val Loss: 0.113697, Val Acc: 0.773196\n",
      "Epoch 15789 - Train Loss: 0.090083, Train Acc: 0.865385 | Val Loss: 0.113695, Val Acc: 0.773196\n",
      "Epoch 15790 - Train Loss: 0.090080, Train Acc: 0.865385 | Val Loss: 0.113692, Val Acc: 0.773196\n",
      "Epoch 15791 - Train Loss: 0.090076, Train Acc: 0.865385 | Val Loss: 0.113690, Val Acc: 0.773196\n",
      "Epoch 15792 - Train Loss: 0.090073, Train Acc: 0.865385 | Val Loss: 0.113688, Val Acc: 0.773196\n",
      "Epoch 15793 - Train Loss: 0.090070, Train Acc: 0.865385 | Val Loss: 0.113686, Val Acc: 0.773196\n",
      "Epoch 15794 - Train Loss: 0.090066, Train Acc: 0.865385 | Val Loss: 0.113684, Val Acc: 0.773196\n",
      "Epoch 15795 - Train Loss: 0.090063, Train Acc: 0.865385 | Val Loss: 0.113682, Val Acc: 0.773196\n",
      "Epoch 15796 - Train Loss: 0.090059, Train Acc: 0.865385 | Val Loss: 0.113679, Val Acc: 0.773196\n",
      "Epoch 15797 - Train Loss: 0.090056, Train Acc: 0.865385 | Val Loss: 0.113677, Val Acc: 0.773196\n",
      "Epoch 15798 - Train Loss: 0.090052, Train Acc: 0.865385 | Val Loss: 0.113675, Val Acc: 0.773196\n",
      "Epoch 15799 - Train Loss: 0.090049, Train Acc: 0.865385 | Val Loss: 0.113673, Val Acc: 0.773196\n",
      "Epoch 15800 - Train Loss: 0.090046, Train Acc: 0.865385 | Val Loss: 0.113671, Val Acc: 0.773196\n",
      "Epoch 15801 - Train Loss: 0.090042, Train Acc: 0.865385 | Val Loss: 0.113669, Val Acc: 0.773196\n",
      "Epoch 15802 - Train Loss: 0.090039, Train Acc: 0.865385 | Val Loss: 0.113666, Val Acc: 0.773196\n",
      "Epoch 15803 - Train Loss: 0.090035, Train Acc: 0.865385 | Val Loss: 0.113664, Val Acc: 0.773196\n",
      "Epoch 15804 - Train Loss: 0.090032, Train Acc: 0.865385 | Val Loss: 0.113662, Val Acc: 0.773196\n",
      "Epoch 15805 - Train Loss: 0.090028, Train Acc: 0.865385 | Val Loss: 0.113660, Val Acc: 0.773196\n",
      "Epoch 15806 - Train Loss: 0.090025, Train Acc: 0.865385 | Val Loss: 0.113658, Val Acc: 0.773196\n",
      "Epoch 15807 - Train Loss: 0.090022, Train Acc: 0.865385 | Val Loss: 0.113656, Val Acc: 0.773196\n",
      "Epoch 15808 - Train Loss: 0.090018, Train Acc: 0.865385 | Val Loss: 0.113653, Val Acc: 0.773196\n",
      "Epoch 15809 - Train Loss: 0.090015, Train Acc: 0.865385 | Val Loss: 0.113651, Val Acc: 0.773196\n",
      "Epoch 15810 - Train Loss: 0.090011, Train Acc: 0.865385 | Val Loss: 0.113649, Val Acc: 0.773196\n",
      "Epoch 15811 - Train Loss: 0.090008, Train Acc: 0.865385 | Val Loss: 0.113647, Val Acc: 0.773196\n",
      "Epoch 15812 - Train Loss: 0.090004, Train Acc: 0.865385 | Val Loss: 0.113645, Val Acc: 0.773196\n",
      "Epoch 15813 - Train Loss: 0.090001, Train Acc: 0.865385 | Val Loss: 0.113643, Val Acc: 0.773196\n",
      "Epoch 15814 - Train Loss: 0.089998, Train Acc: 0.865385 | Val Loss: 0.113641, Val Acc: 0.773196\n",
      "Epoch 15815 - Train Loss: 0.089994, Train Acc: 0.865385 | Val Loss: 0.113638, Val Acc: 0.773196\n",
      "Epoch 15816 - Train Loss: 0.089991, Train Acc: 0.865385 | Val Loss: 0.113636, Val Acc: 0.773196\n",
      "Epoch 15817 - Train Loss: 0.089987, Train Acc: 0.865385 | Val Loss: 0.113634, Val Acc: 0.773196\n",
      "Epoch 15818 - Train Loss: 0.089984, Train Acc: 0.865385 | Val Loss: 0.113632, Val Acc: 0.773196\n",
      "Epoch 15819 - Train Loss: 0.089980, Train Acc: 0.865385 | Val Loss: 0.113630, Val Acc: 0.773196\n",
      "Epoch 15820 - Train Loss: 0.089977, Train Acc: 0.865385 | Val Loss: 0.113628, Val Acc: 0.773196\n",
      "Epoch 15821 - Train Loss: 0.089974, Train Acc: 0.865385 | Val Loss: 0.113625, Val Acc: 0.773196\n",
      "Epoch 15822 - Train Loss: 0.089970, Train Acc: 0.865385 | Val Loss: 0.113623, Val Acc: 0.773196\n",
      "Epoch 15823 - Train Loss: 0.089967, Train Acc: 0.865385 | Val Loss: 0.113621, Val Acc: 0.773196\n",
      "Epoch 15824 - Train Loss: 0.089963, Train Acc: 0.865385 | Val Loss: 0.113619, Val Acc: 0.773196\n",
      "Epoch 15825 - Train Loss: 0.089960, Train Acc: 0.865385 | Val Loss: 0.113617, Val Acc: 0.773196\n",
      "Epoch 15826 - Train Loss: 0.089957, Train Acc: 0.865385 | Val Loss: 0.113615, Val Acc: 0.773196\n",
      "Epoch 15827 - Train Loss: 0.089953, Train Acc: 0.865385 | Val Loss: 0.113613, Val Acc: 0.773196\n",
      "Epoch 15828 - Train Loss: 0.089950, Train Acc: 0.865385 | Val Loss: 0.113610, Val Acc: 0.773196\n",
      "Epoch 15829 - Train Loss: 0.089946, Train Acc: 0.865385 | Val Loss: 0.113608, Val Acc: 0.773196\n",
      "Epoch 15830 - Train Loss: 0.089943, Train Acc: 0.865385 | Val Loss: 0.113606, Val Acc: 0.773196\n",
      "Epoch 15831 - Train Loss: 0.089939, Train Acc: 0.865385 | Val Loss: 0.113604, Val Acc: 0.773196\n",
      "Epoch 15832 - Train Loss: 0.089936, Train Acc: 0.865385 | Val Loss: 0.113602, Val Acc: 0.773196\n",
      "Epoch 15833 - Train Loss: 0.089933, Train Acc: 0.865385 | Val Loss: 0.113600, Val Acc: 0.773196\n",
      "Epoch 15834 - Train Loss: 0.089929, Train Acc: 0.865385 | Val Loss: 0.113597, Val Acc: 0.773196\n",
      "Epoch 15835 - Train Loss: 0.089926, Train Acc: 0.865385 | Val Loss: 0.113595, Val Acc: 0.773196\n",
      "Epoch 15836 - Train Loss: 0.089922, Train Acc: 0.865385 | Val Loss: 0.113593, Val Acc: 0.773196\n",
      "Epoch 15837 - Train Loss: 0.089919, Train Acc: 0.865385 | Val Loss: 0.113591, Val Acc: 0.773196\n",
      "Epoch 15838 - Train Loss: 0.089916, Train Acc: 0.865385 | Val Loss: 0.113589, Val Acc: 0.773196\n",
      "Epoch 15839 - Train Loss: 0.089912, Train Acc: 0.865385 | Val Loss: 0.113587, Val Acc: 0.773196\n",
      "Epoch 15840 - Train Loss: 0.089909, Train Acc: 0.865385 | Val Loss: 0.113585, Val Acc: 0.773196\n",
      "Epoch 15841 - Train Loss: 0.089905, Train Acc: 0.865385 | Val Loss: 0.113582, Val Acc: 0.773196\n",
      "Epoch 15842 - Train Loss: 0.089902, Train Acc: 0.865385 | Val Loss: 0.113580, Val Acc: 0.773196\n",
      "Epoch 15843 - Train Loss: 0.089898, Train Acc: 0.865385 | Val Loss: 0.113578, Val Acc: 0.773196\n",
      "Epoch 15844 - Train Loss: 0.089895, Train Acc: 0.865385 | Val Loss: 0.113576, Val Acc: 0.773196\n",
      "Epoch 15845 - Train Loss: 0.089892, Train Acc: 0.865385 | Val Loss: 0.113574, Val Acc: 0.773196\n",
      "Epoch 15846 - Train Loss: 0.089888, Train Acc: 0.865385 | Val Loss: 0.113572, Val Acc: 0.773196\n",
      "Epoch 15847 - Train Loss: 0.089885, Train Acc: 0.865385 | Val Loss: 0.113570, Val Acc: 0.773196\n",
      "Epoch 15848 - Train Loss: 0.089881, Train Acc: 0.865385 | Val Loss: 0.113567, Val Acc: 0.773196\n",
      "Epoch 15849 - Train Loss: 0.089878, Train Acc: 0.865385 | Val Loss: 0.113565, Val Acc: 0.773196\n",
      "Epoch 15850 - Train Loss: 0.089875, Train Acc: 0.865385 | Val Loss: 0.113563, Val Acc: 0.773196\n",
      "Epoch 15851 - Train Loss: 0.089871, Train Acc: 0.865385 | Val Loss: 0.113561, Val Acc: 0.773196\n",
      "Epoch 15852 - Train Loss: 0.089868, Train Acc: 0.865385 | Val Loss: 0.113559, Val Acc: 0.773196\n",
      "Epoch 15853 - Train Loss: 0.089864, Train Acc: 0.865385 | Val Loss: 0.113557, Val Acc: 0.773196\n",
      "Epoch 15854 - Train Loss: 0.089861, Train Acc: 0.865385 | Val Loss: 0.113555, Val Acc: 0.773196\n",
      "Epoch 15855 - Train Loss: 0.089858, Train Acc: 0.865385 | Val Loss: 0.113552, Val Acc: 0.773196\n",
      "Epoch 15856 - Train Loss: 0.089854, Train Acc: 0.865385 | Val Loss: 0.113550, Val Acc: 0.773196\n",
      "Epoch 15857 - Train Loss: 0.089851, Train Acc: 0.865385 | Val Loss: 0.113548, Val Acc: 0.773196\n",
      "Epoch 15858 - Train Loss: 0.089847, Train Acc: 0.865385 | Val Loss: 0.113546, Val Acc: 0.773196\n",
      "Epoch 15859 - Train Loss: 0.089844, Train Acc: 0.865385 | Val Loss: 0.113544, Val Acc: 0.773196\n",
      "Epoch 15860 - Train Loss: 0.089840, Train Acc: 0.865385 | Val Loss: 0.113542, Val Acc: 0.773196\n",
      "Epoch 15861 - Train Loss: 0.089837, Train Acc: 0.865385 | Val Loss: 0.113540, Val Acc: 0.773196\n",
      "Epoch 15862 - Train Loss: 0.089834, Train Acc: 0.865385 | Val Loss: 0.113537, Val Acc: 0.773196\n",
      "Epoch 15863 - Train Loss: 0.089830, Train Acc: 0.865385 | Val Loss: 0.113535, Val Acc: 0.773196\n",
      "Epoch 15864 - Train Loss: 0.089827, Train Acc: 0.866667 | Val Loss: 0.113533, Val Acc: 0.773196\n",
      "Epoch 15865 - Train Loss: 0.089823, Train Acc: 0.866667 | Val Loss: 0.113531, Val Acc: 0.773196\n",
      "Epoch 15866 - Train Loss: 0.089820, Train Acc: 0.866667 | Val Loss: 0.113529, Val Acc: 0.773196\n",
      "Epoch 15867 - Train Loss: 0.089817, Train Acc: 0.866667 | Val Loss: 0.113527, Val Acc: 0.773196\n",
      "Epoch 15868 - Train Loss: 0.089813, Train Acc: 0.866667 | Val Loss: 0.113525, Val Acc: 0.773196\n",
      "Epoch 15869 - Train Loss: 0.089810, Train Acc: 0.866667 | Val Loss: 0.113522, Val Acc: 0.773196\n",
      "Epoch 15870 - Train Loss: 0.089806, Train Acc: 0.866667 | Val Loss: 0.113520, Val Acc: 0.773196\n",
      "Epoch 15871 - Train Loss: 0.089803, Train Acc: 0.866667 | Val Loss: 0.113518, Val Acc: 0.773196\n",
      "Epoch 15872 - Train Loss: 0.089800, Train Acc: 0.866667 | Val Loss: 0.113516, Val Acc: 0.773196\n",
      "Epoch 15873 - Train Loss: 0.089796, Train Acc: 0.866667 | Val Loss: 0.113514, Val Acc: 0.773196\n",
      "Epoch 15874 - Train Loss: 0.089793, Train Acc: 0.866667 | Val Loss: 0.113512, Val Acc: 0.773196\n",
      "Epoch 15875 - Train Loss: 0.089789, Train Acc: 0.866667 | Val Loss: 0.113510, Val Acc: 0.773196\n",
      "Epoch 15876 - Train Loss: 0.089786, Train Acc: 0.866667 | Val Loss: 0.113508, Val Acc: 0.773196\n",
      "Epoch 15877 - Train Loss: 0.089783, Train Acc: 0.866667 | Val Loss: 0.113505, Val Acc: 0.773196\n",
      "Epoch 15878 - Train Loss: 0.089779, Train Acc: 0.866667 | Val Loss: 0.113503, Val Acc: 0.773196\n",
      "Epoch 15879 - Train Loss: 0.089776, Train Acc: 0.866667 | Val Loss: 0.113501, Val Acc: 0.773196\n",
      "Epoch 15880 - Train Loss: 0.089772, Train Acc: 0.866667 | Val Loss: 0.113499, Val Acc: 0.773196\n",
      "Epoch 15881 - Train Loss: 0.089769, Train Acc: 0.866667 | Val Loss: 0.113497, Val Acc: 0.773196\n",
      "Epoch 15882 - Train Loss: 0.089766, Train Acc: 0.866667 | Val Loss: 0.113495, Val Acc: 0.773196\n",
      "Epoch 15883 - Train Loss: 0.089762, Train Acc: 0.866667 | Val Loss: 0.113493, Val Acc: 0.773196\n",
      "Epoch 15884 - Train Loss: 0.089759, Train Acc: 0.866667 | Val Loss: 0.113491, Val Acc: 0.773196\n",
      "Epoch 15885 - Train Loss: 0.089755, Train Acc: 0.866667 | Val Loss: 0.113488, Val Acc: 0.773196\n",
      "Epoch 15886 - Train Loss: 0.089752, Train Acc: 0.866667 | Val Loss: 0.113486, Val Acc: 0.773196\n",
      "Epoch 15887 - Train Loss: 0.089749, Train Acc: 0.866667 | Val Loss: 0.113484, Val Acc: 0.773196\n",
      "Epoch 15888 - Train Loss: 0.089745, Train Acc: 0.866667 | Val Loss: 0.113482, Val Acc: 0.773196\n",
      "Epoch 15889 - Train Loss: 0.089742, Train Acc: 0.866667 | Val Loss: 0.113480, Val Acc: 0.773196\n",
      "Epoch 15890 - Train Loss: 0.089739, Train Acc: 0.866667 | Val Loss: 0.113478, Val Acc: 0.773196\n",
      "Epoch 15891 - Train Loss: 0.089735, Train Acc: 0.866667 | Val Loss: 0.113476, Val Acc: 0.773196\n",
      "Epoch 15892 - Train Loss: 0.089732, Train Acc: 0.866667 | Val Loss: 0.113474, Val Acc: 0.773196\n",
      "Epoch 15893 - Train Loss: 0.089728, Train Acc: 0.866667 | Val Loss: 0.113471, Val Acc: 0.773196\n",
      "Epoch 15894 - Train Loss: 0.089725, Train Acc: 0.866667 | Val Loss: 0.113469, Val Acc: 0.773196\n",
      "Epoch 15895 - Train Loss: 0.089722, Train Acc: 0.866667 | Val Loss: 0.113467, Val Acc: 0.773196\n",
      "Epoch 15896 - Train Loss: 0.089718, Train Acc: 0.866667 | Val Loss: 0.113465, Val Acc: 0.773196\n",
      "Epoch 15897 - Train Loss: 0.089715, Train Acc: 0.867949 | Val Loss: 0.113463, Val Acc: 0.773196\n",
      "Epoch 15898 - Train Loss: 0.089711, Train Acc: 0.867949 | Val Loss: 0.113461, Val Acc: 0.773196\n",
      "Epoch 15899 - Train Loss: 0.089708, Train Acc: 0.869231 | Val Loss: 0.113459, Val Acc: 0.773196\n",
      "Epoch 15900 - Train Loss: 0.089705, Train Acc: 0.869231 | Val Loss: 0.113457, Val Acc: 0.773196\n",
      "Epoch 15901 - Train Loss: 0.089701, Train Acc: 0.869231 | Val Loss: 0.113454, Val Acc: 0.773196\n",
      "Epoch 15902 - Train Loss: 0.089698, Train Acc: 0.869231 | Val Loss: 0.113452, Val Acc: 0.773196\n",
      "Epoch 15903 - Train Loss: 0.089694, Train Acc: 0.869231 | Val Loss: 0.113450, Val Acc: 0.773196\n",
      "Epoch 15904 - Train Loss: 0.089691, Train Acc: 0.869231 | Val Loss: 0.113448, Val Acc: 0.773196\n",
      "Epoch 15905 - Train Loss: 0.089688, Train Acc: 0.869231 | Val Loss: 0.113446, Val Acc: 0.773196\n",
      "Epoch 15906 - Train Loss: 0.089684, Train Acc: 0.869231 | Val Loss: 0.113444, Val Acc: 0.773196\n",
      "Epoch 15907 - Train Loss: 0.089681, Train Acc: 0.869231 | Val Loss: 0.113442, Val Acc: 0.773196\n",
      "Epoch 15908 - Train Loss: 0.089678, Train Acc: 0.869231 | Val Loss: 0.113440, Val Acc: 0.773196\n",
      "Epoch 15909 - Train Loss: 0.089674, Train Acc: 0.869231 | Val Loss: 0.113437, Val Acc: 0.773196\n",
      "Epoch 15910 - Train Loss: 0.089671, Train Acc: 0.869231 | Val Loss: 0.113435, Val Acc: 0.773196\n",
      "Epoch 15911 - Train Loss: 0.089667, Train Acc: 0.869231 | Val Loss: 0.113433, Val Acc: 0.773196\n",
      "Epoch 15912 - Train Loss: 0.089664, Train Acc: 0.869231 | Val Loss: 0.113431, Val Acc: 0.773196\n",
      "Epoch 15913 - Train Loss: 0.089661, Train Acc: 0.869231 | Val Loss: 0.113429, Val Acc: 0.773196\n",
      "Epoch 15914 - Train Loss: 0.089657, Train Acc: 0.869231 | Val Loss: 0.113427, Val Acc: 0.773196\n",
      "Epoch 15915 - Train Loss: 0.089654, Train Acc: 0.869231 | Val Loss: 0.113425, Val Acc: 0.773196\n",
      "Epoch 15916 - Train Loss: 0.089650, Train Acc: 0.869231 | Val Loss: 0.113423, Val Acc: 0.773196\n",
      "Epoch 15917 - Train Loss: 0.089647, Train Acc: 0.869231 | Val Loss: 0.113421, Val Acc: 0.773196\n",
      "Epoch 15918 - Train Loss: 0.089644, Train Acc: 0.869231 | Val Loss: 0.113418, Val Acc: 0.773196\n",
      "Epoch 15919 - Train Loss: 0.089640, Train Acc: 0.869231 | Val Loss: 0.113416, Val Acc: 0.773196\n",
      "Epoch 15920 - Train Loss: 0.089637, Train Acc: 0.869231 | Val Loss: 0.113414, Val Acc: 0.773196\n",
      "Epoch 15921 - Train Loss: 0.089634, Train Acc: 0.869231 | Val Loss: 0.113412, Val Acc: 0.773196\n",
      "Epoch 15922 - Train Loss: 0.089630, Train Acc: 0.869231 | Val Loss: 0.113410, Val Acc: 0.773196\n",
      "Epoch 15923 - Train Loss: 0.089627, Train Acc: 0.869231 | Val Loss: 0.113408, Val Acc: 0.773196\n",
      "Epoch 15924 - Train Loss: 0.089623, Train Acc: 0.869231 | Val Loss: 0.113406, Val Acc: 0.773196\n",
      "Epoch 15925 - Train Loss: 0.089620, Train Acc: 0.869231 | Val Loss: 0.113404, Val Acc: 0.773196\n",
      "Epoch 15926 - Train Loss: 0.089617, Train Acc: 0.869231 | Val Loss: 0.113402, Val Acc: 0.773196\n",
      "Epoch 15927 - Train Loss: 0.089613, Train Acc: 0.869231 | Val Loss: 0.113399, Val Acc: 0.773196\n",
      "Epoch 15928 - Train Loss: 0.089610, Train Acc: 0.869231 | Val Loss: 0.113397, Val Acc: 0.773196\n",
      "Epoch 15929 - Train Loss: 0.089607, Train Acc: 0.869231 | Val Loss: 0.113395, Val Acc: 0.773196\n",
      "Epoch 15930 - Train Loss: 0.089603, Train Acc: 0.869231 | Val Loss: 0.113393, Val Acc: 0.773196\n",
      "Epoch 15931 - Train Loss: 0.089600, Train Acc: 0.869231 | Val Loss: 0.113391, Val Acc: 0.773196\n",
      "Epoch 15932 - Train Loss: 0.089596, Train Acc: 0.869231 | Val Loss: 0.113389, Val Acc: 0.773196\n",
      "Epoch 15933 - Train Loss: 0.089593, Train Acc: 0.869231 | Val Loss: 0.113387, Val Acc: 0.773196\n",
      "Epoch 15934 - Train Loss: 0.089590, Train Acc: 0.869231 | Val Loss: 0.113385, Val Acc: 0.773196\n",
      "Epoch 15935 - Train Loss: 0.089586, Train Acc: 0.869231 | Val Loss: 0.113383, Val Acc: 0.773196\n",
      "Epoch 15936 - Train Loss: 0.089583, Train Acc: 0.869231 | Val Loss: 0.113380, Val Acc: 0.773196\n",
      "Epoch 15937 - Train Loss: 0.089580, Train Acc: 0.869231 | Val Loss: 0.113378, Val Acc: 0.773196\n",
      "Epoch 15938 - Train Loss: 0.089576, Train Acc: 0.869231 | Val Loss: 0.113376, Val Acc: 0.773196\n",
      "Epoch 15939 - Train Loss: 0.089573, Train Acc: 0.869231 | Val Loss: 0.113374, Val Acc: 0.773196\n",
      "Epoch 15940 - Train Loss: 0.089569, Train Acc: 0.869231 | Val Loss: 0.113372, Val Acc: 0.773196\n",
      "Epoch 15941 - Train Loss: 0.089566, Train Acc: 0.869231 | Val Loss: 0.113370, Val Acc: 0.773196\n",
      "Epoch 15942 - Train Loss: 0.089563, Train Acc: 0.869231 | Val Loss: 0.113368, Val Acc: 0.773196\n",
      "Epoch 15943 - Train Loss: 0.089559, Train Acc: 0.869231 | Val Loss: 0.113366, Val Acc: 0.773196\n",
      "Epoch 15944 - Train Loss: 0.089556, Train Acc: 0.869231 | Val Loss: 0.113364, Val Acc: 0.773196\n",
      "Epoch 15945 - Train Loss: 0.089553, Train Acc: 0.869231 | Val Loss: 0.113361, Val Acc: 0.773196\n",
      "Epoch 15946 - Train Loss: 0.089549, Train Acc: 0.869231 | Val Loss: 0.113359, Val Acc: 0.773196\n",
      "Epoch 15947 - Train Loss: 0.089546, Train Acc: 0.869231 | Val Loss: 0.113357, Val Acc: 0.773196\n",
      "Epoch 15948 - Train Loss: 0.089542, Train Acc: 0.869231 | Val Loss: 0.113355, Val Acc: 0.773196\n",
      "Epoch 15949 - Train Loss: 0.089539, Train Acc: 0.869231 | Val Loss: 0.113353, Val Acc: 0.773196\n",
      "Epoch 15950 - Train Loss: 0.089536, Train Acc: 0.869231 | Val Loss: 0.113351, Val Acc: 0.773196\n",
      "Epoch 15951 - Train Loss: 0.089532, Train Acc: 0.869231 | Val Loss: 0.113349, Val Acc: 0.773196\n",
      "Epoch 15952 - Train Loss: 0.089529, Train Acc: 0.869231 | Val Loss: 0.113347, Val Acc: 0.773196\n",
      "Epoch 15953 - Train Loss: 0.089526, Train Acc: 0.869231 | Val Loss: 0.113345, Val Acc: 0.773196\n",
      "Epoch 15954 - Train Loss: 0.089522, Train Acc: 0.869231 | Val Loss: 0.113343, Val Acc: 0.773196\n",
      "Epoch 15955 - Train Loss: 0.089519, Train Acc: 0.869231 | Val Loss: 0.113340, Val Acc: 0.773196\n",
      "Epoch 15956 - Train Loss: 0.089516, Train Acc: 0.869231 | Val Loss: 0.113338, Val Acc: 0.773196\n",
      "Epoch 15957 - Train Loss: 0.089512, Train Acc: 0.869231 | Val Loss: 0.113336, Val Acc: 0.773196\n",
      "Epoch 15958 - Train Loss: 0.089509, Train Acc: 0.869231 | Val Loss: 0.113334, Val Acc: 0.773196\n",
      "Epoch 15959 - Train Loss: 0.089505, Train Acc: 0.869231 | Val Loss: 0.113332, Val Acc: 0.773196\n",
      "Epoch 15960 - Train Loss: 0.089502, Train Acc: 0.869231 | Val Loss: 0.113330, Val Acc: 0.773196\n",
      "Epoch 15961 - Train Loss: 0.089499, Train Acc: 0.869231 | Val Loss: 0.113328, Val Acc: 0.773196\n",
      "Epoch 15962 - Train Loss: 0.089495, Train Acc: 0.869231 | Val Loss: 0.113326, Val Acc: 0.773196\n",
      "Epoch 15963 - Train Loss: 0.089492, Train Acc: 0.869231 | Val Loss: 0.113324, Val Acc: 0.773196\n",
      "Epoch 15964 - Train Loss: 0.089489, Train Acc: 0.869231 | Val Loss: 0.113322, Val Acc: 0.773196\n",
      "Epoch 15965 - Train Loss: 0.089485, Train Acc: 0.869231 | Val Loss: 0.113319, Val Acc: 0.773196\n",
      "Epoch 15966 - Train Loss: 0.089482, Train Acc: 0.869231 | Val Loss: 0.113317, Val Acc: 0.773196\n",
      "Epoch 15967 - Train Loss: 0.089479, Train Acc: 0.869231 | Val Loss: 0.113315, Val Acc: 0.773196\n",
      "Epoch 15968 - Train Loss: 0.089475, Train Acc: 0.869231 | Val Loss: 0.113313, Val Acc: 0.773196\n",
      "Epoch 15969 - Train Loss: 0.089472, Train Acc: 0.869231 | Val Loss: 0.113311, Val Acc: 0.773196\n",
      "Epoch 15970 - Train Loss: 0.089468, Train Acc: 0.869231 | Val Loss: 0.113309, Val Acc: 0.773196\n",
      "Epoch 15971 - Train Loss: 0.089465, Train Acc: 0.869231 | Val Loss: 0.113307, Val Acc: 0.773196\n",
      "Epoch 15972 - Train Loss: 0.089462, Train Acc: 0.869231 | Val Loss: 0.113305, Val Acc: 0.773196\n",
      "Epoch 15973 - Train Loss: 0.089458, Train Acc: 0.869231 | Val Loss: 0.113303, Val Acc: 0.773196\n",
      "Epoch 15974 - Train Loss: 0.089455, Train Acc: 0.869231 | Val Loss: 0.113301, Val Acc: 0.773196\n",
      "Epoch 15975 - Train Loss: 0.089452, Train Acc: 0.869231 | Val Loss: 0.113299, Val Acc: 0.773196\n",
      "Epoch 15976 - Train Loss: 0.089448, Train Acc: 0.869231 | Val Loss: 0.113296, Val Acc: 0.773196\n",
      "Epoch 15977 - Train Loss: 0.089445, Train Acc: 0.869231 | Val Loss: 0.113294, Val Acc: 0.773196\n",
      "Epoch 15978 - Train Loss: 0.089442, Train Acc: 0.869231 | Val Loss: 0.113292, Val Acc: 0.773196\n",
      "Epoch 15979 - Train Loss: 0.089438, Train Acc: 0.869231 | Val Loss: 0.113290, Val Acc: 0.773196\n",
      "Epoch 15980 - Train Loss: 0.089435, Train Acc: 0.869231 | Val Loss: 0.113288, Val Acc: 0.773196\n",
      "Epoch 15981 - Train Loss: 0.089432, Train Acc: 0.869231 | Val Loss: 0.113286, Val Acc: 0.773196\n",
      "Epoch 15982 - Train Loss: 0.089428, Train Acc: 0.869231 | Val Loss: 0.113284, Val Acc: 0.773196\n",
      "Epoch 15983 - Train Loss: 0.089425, Train Acc: 0.869231 | Val Loss: 0.113282, Val Acc: 0.773196\n",
      "Epoch 15984 - Train Loss: 0.089421, Train Acc: 0.869231 | Val Loss: 0.113280, Val Acc: 0.773196\n",
      "Epoch 15985 - Train Loss: 0.089418, Train Acc: 0.869231 | Val Loss: 0.113278, Val Acc: 0.773196\n",
      "Epoch 15986 - Train Loss: 0.089415, Train Acc: 0.869231 | Val Loss: 0.113276, Val Acc: 0.773196\n",
      "Epoch 15987 - Train Loss: 0.089411, Train Acc: 0.869231 | Val Loss: 0.113274, Val Acc: 0.773196\n",
      "Epoch 15988 - Train Loss: 0.089408, Train Acc: 0.869231 | Val Loss: 0.113272, Val Acc: 0.773196\n",
      "Epoch 15989 - Train Loss: 0.089405, Train Acc: 0.869231 | Val Loss: 0.113269, Val Acc: 0.773196\n",
      "Epoch 15990 - Train Loss: 0.089401, Train Acc: 0.869231 | Val Loss: 0.113267, Val Acc: 0.773196\n",
      "Epoch 15991 - Train Loss: 0.089398, Train Acc: 0.869231 | Val Loss: 0.113265, Val Acc: 0.773196\n",
      "Epoch 15992 - Train Loss: 0.089395, Train Acc: 0.869231 | Val Loss: 0.113263, Val Acc: 0.773196\n",
      "Epoch 15993 - Train Loss: 0.089391, Train Acc: 0.870513 | Val Loss: 0.113261, Val Acc: 0.773196\n",
      "Epoch 15994 - Train Loss: 0.089388, Train Acc: 0.870513 | Val Loss: 0.113259, Val Acc: 0.773196\n",
      "Epoch 15995 - Train Loss: 0.089385, Train Acc: 0.870513 | Val Loss: 0.113257, Val Acc: 0.773196\n",
      "Epoch 15996 - Train Loss: 0.089381, Train Acc: 0.870513 | Val Loss: 0.113255, Val Acc: 0.773196\n",
      "Epoch 15997 - Train Loss: 0.089378, Train Acc: 0.870513 | Val Loss: 0.113253, Val Acc: 0.773196\n",
      "Epoch 15998 - Train Loss: 0.089375, Train Acc: 0.870513 | Val Loss: 0.113251, Val Acc: 0.773196\n",
      "Epoch 15999 - Train Loss: 0.089371, Train Acc: 0.870513 | Val Loss: 0.113249, Val Acc: 0.773196\n",
      "Epoch 16000 - Train Loss: 0.089368, Train Acc: 0.870513 | Val Loss: 0.113247, Val Acc: 0.773196\n",
      "Epoch 16001 - Train Loss: 0.089365, Train Acc: 0.870513 | Val Loss: 0.113245, Val Acc: 0.773196\n",
      "Epoch 16002 - Train Loss: 0.089361, Train Acc: 0.870513 | Val Loss: 0.113242, Val Acc: 0.773196\n",
      "Epoch 16003 - Train Loss: 0.089358, Train Acc: 0.870513 | Val Loss: 0.113240, Val Acc: 0.773196\n",
      "Epoch 16004 - Train Loss: 0.089355, Train Acc: 0.870513 | Val Loss: 0.113238, Val Acc: 0.773196\n",
      "Epoch 16005 - Train Loss: 0.089351, Train Acc: 0.870513 | Val Loss: 0.113236, Val Acc: 0.773196\n",
      "Epoch 16006 - Train Loss: 0.089348, Train Acc: 0.870513 | Val Loss: 0.113234, Val Acc: 0.773196\n",
      "Epoch 16007 - Train Loss: 0.089344, Train Acc: 0.870513 | Val Loss: 0.113232, Val Acc: 0.773196\n",
      "Epoch 16008 - Train Loss: 0.089341, Train Acc: 0.870513 | Val Loss: 0.113230, Val Acc: 0.773196\n",
      "Epoch 16009 - Train Loss: 0.089338, Train Acc: 0.870513 | Val Loss: 0.113228, Val Acc: 0.773196\n",
      "Epoch 16010 - Train Loss: 0.089334, Train Acc: 0.870513 | Val Loss: 0.113226, Val Acc: 0.773196\n",
      "Epoch 16011 - Train Loss: 0.089331, Train Acc: 0.870513 | Val Loss: 0.113224, Val Acc: 0.773196\n",
      "Epoch 16012 - Train Loss: 0.089328, Train Acc: 0.870513 | Val Loss: 0.113222, Val Acc: 0.773196\n",
      "Epoch 16013 - Train Loss: 0.089324, Train Acc: 0.870513 | Val Loss: 0.113220, Val Acc: 0.773196\n",
      "Epoch 16014 - Train Loss: 0.089321, Train Acc: 0.870513 | Val Loss: 0.113218, Val Acc: 0.773196\n",
      "Epoch 16015 - Train Loss: 0.089318, Train Acc: 0.870513 | Val Loss: 0.113216, Val Acc: 0.773196\n",
      "Epoch 16016 - Train Loss: 0.089314, Train Acc: 0.870513 | Val Loss: 0.113214, Val Acc: 0.773196\n",
      "Epoch 16017 - Train Loss: 0.089311, Train Acc: 0.870513 | Val Loss: 0.113211, Val Acc: 0.773196\n",
      "Epoch 16018 - Train Loss: 0.089308, Train Acc: 0.870513 | Val Loss: 0.113209, Val Acc: 0.773196\n",
      "Epoch 16019 - Train Loss: 0.089304, Train Acc: 0.870513 | Val Loss: 0.113207, Val Acc: 0.773196\n",
      "Epoch 16020 - Train Loss: 0.089301, Train Acc: 0.870513 | Val Loss: 0.113205, Val Acc: 0.773196\n",
      "Epoch 16021 - Train Loss: 0.089298, Train Acc: 0.870513 | Val Loss: 0.113203, Val Acc: 0.773196\n",
      "Epoch 16022 - Train Loss: 0.089294, Train Acc: 0.870513 | Val Loss: 0.113201, Val Acc: 0.773196\n",
      "Epoch 16023 - Train Loss: 0.089291, Train Acc: 0.870513 | Val Loss: 0.113199, Val Acc: 0.773196\n",
      "Epoch 16024 - Train Loss: 0.089288, Train Acc: 0.870513 | Val Loss: 0.113197, Val Acc: 0.773196\n",
      "Epoch 16025 - Train Loss: 0.089284, Train Acc: 0.870513 | Val Loss: 0.113195, Val Acc: 0.773196\n",
      "Epoch 16026 - Train Loss: 0.089281, Train Acc: 0.870513 | Val Loss: 0.113193, Val Acc: 0.773196\n",
      "Epoch 16027 - Train Loss: 0.089278, Train Acc: 0.870513 | Val Loss: 0.113191, Val Acc: 0.773196\n",
      "Epoch 16028 - Train Loss: 0.089274, Train Acc: 0.870513 | Val Loss: 0.113189, Val Acc: 0.773196\n",
      "Epoch 16029 - Train Loss: 0.089271, Train Acc: 0.870513 | Val Loss: 0.113187, Val Acc: 0.773196\n",
      "Epoch 16030 - Train Loss: 0.089268, Train Acc: 0.870513 | Val Loss: 0.113185, Val Acc: 0.773196\n",
      "Epoch 16031 - Train Loss: 0.089264, Train Acc: 0.870513 | Val Loss: 0.113183, Val Acc: 0.773196\n",
      "Epoch 16032 - Train Loss: 0.089261, Train Acc: 0.870513 | Val Loss: 0.113181, Val Acc: 0.773196\n",
      "Epoch 16033 - Train Loss: 0.089258, Train Acc: 0.870513 | Val Loss: 0.113178, Val Acc: 0.773196\n",
      "Epoch 16034 - Train Loss: 0.089254, Train Acc: 0.870513 | Val Loss: 0.113176, Val Acc: 0.773196\n",
      "Epoch 16035 - Train Loss: 0.089251, Train Acc: 0.870513 | Val Loss: 0.113174, Val Acc: 0.773196\n",
      "Epoch 16036 - Train Loss: 0.089248, Train Acc: 0.870513 | Val Loss: 0.113172, Val Acc: 0.773196\n",
      "Epoch 16037 - Train Loss: 0.089244, Train Acc: 0.870513 | Val Loss: 0.113170, Val Acc: 0.773196\n",
      "Epoch 16038 - Train Loss: 0.089241, Train Acc: 0.870513 | Val Loss: 0.113168, Val Acc: 0.773196\n",
      "Epoch 16039 - Train Loss: 0.089238, Train Acc: 0.870513 | Val Loss: 0.113166, Val Acc: 0.773196\n",
      "Epoch 16040 - Train Loss: 0.089234, Train Acc: 0.870513 | Val Loss: 0.113164, Val Acc: 0.773196\n",
      "Epoch 16041 - Train Loss: 0.089231, Train Acc: 0.870513 | Val Loss: 0.113162, Val Acc: 0.773196\n",
      "Epoch 16042 - Train Loss: 0.089228, Train Acc: 0.871795 | Val Loss: 0.113160, Val Acc: 0.773196\n",
      "Epoch 16043 - Train Loss: 0.089224, Train Acc: 0.871795 | Val Loss: 0.113158, Val Acc: 0.773196\n",
      "Epoch 16044 - Train Loss: 0.089221, Train Acc: 0.871795 | Val Loss: 0.113156, Val Acc: 0.773196\n",
      "Epoch 16045 - Train Loss: 0.089218, Train Acc: 0.871795 | Val Loss: 0.113154, Val Acc: 0.773196\n",
      "Epoch 16046 - Train Loss: 0.089214, Train Acc: 0.871795 | Val Loss: 0.113152, Val Acc: 0.773196\n",
      "Epoch 16047 - Train Loss: 0.089211, Train Acc: 0.871795 | Val Loss: 0.113150, Val Acc: 0.773196\n",
      "Epoch 16048 - Train Loss: 0.089208, Train Acc: 0.871795 | Val Loss: 0.113148, Val Acc: 0.773196\n",
      "Epoch 16049 - Train Loss: 0.089204, Train Acc: 0.871795 | Val Loss: 0.113146, Val Acc: 0.773196\n",
      "Epoch 16050 - Train Loss: 0.089201, Train Acc: 0.873077 | Val Loss: 0.113143, Val Acc: 0.773196\n",
      "Epoch 16051 - Train Loss: 0.089198, Train Acc: 0.873077 | Val Loss: 0.113141, Val Acc: 0.773196\n",
      "Epoch 16052 - Train Loss: 0.089194, Train Acc: 0.873077 | Val Loss: 0.113139, Val Acc: 0.773196\n",
      "Epoch 16053 - Train Loss: 0.089191, Train Acc: 0.873077 | Val Loss: 0.113137, Val Acc: 0.773196\n",
      "Epoch 16054 - Train Loss: 0.089188, Train Acc: 0.873077 | Val Loss: 0.113135, Val Acc: 0.773196\n",
      "Epoch 16055 - Train Loss: 0.089185, Train Acc: 0.873077 | Val Loss: 0.113133, Val Acc: 0.773196\n",
      "Epoch 16056 - Train Loss: 0.089181, Train Acc: 0.873077 | Val Loss: 0.113131, Val Acc: 0.773196\n",
      "Epoch 16057 - Train Loss: 0.089178, Train Acc: 0.873077 | Val Loss: 0.113129, Val Acc: 0.773196\n",
      "Epoch 16058 - Train Loss: 0.089175, Train Acc: 0.873077 | Val Loss: 0.113127, Val Acc: 0.773196\n",
      "Epoch 16059 - Train Loss: 0.089171, Train Acc: 0.873077 | Val Loss: 0.113125, Val Acc: 0.773196\n",
      "Epoch 16060 - Train Loss: 0.089168, Train Acc: 0.873077 | Val Loss: 0.113123, Val Acc: 0.773196\n",
      "Epoch 16061 - Train Loss: 0.089165, Train Acc: 0.873077 | Val Loss: 0.113121, Val Acc: 0.773196\n",
      "Epoch 16062 - Train Loss: 0.089161, Train Acc: 0.873077 | Val Loss: 0.113119, Val Acc: 0.773196\n",
      "Epoch 16063 - Train Loss: 0.089158, Train Acc: 0.873077 | Val Loss: 0.113117, Val Acc: 0.773196\n",
      "Epoch 16064 - Train Loss: 0.089155, Train Acc: 0.873077 | Val Loss: 0.113115, Val Acc: 0.773196\n",
      "Epoch 16065 - Train Loss: 0.089151, Train Acc: 0.873077 | Val Loss: 0.113113, Val Acc: 0.773196\n",
      "Epoch 16066 - Train Loss: 0.089148, Train Acc: 0.873077 | Val Loss: 0.113111, Val Acc: 0.773196\n",
      "Epoch 16067 - Train Loss: 0.089145, Train Acc: 0.873077 | Val Loss: 0.113109, Val Acc: 0.773196\n",
      "Epoch 16068 - Train Loss: 0.089141, Train Acc: 0.873077 | Val Loss: 0.113107, Val Acc: 0.773196\n",
      "Epoch 16069 - Train Loss: 0.089138, Train Acc: 0.873077 | Val Loss: 0.113105, Val Acc: 0.773196\n",
      "Epoch 16070 - Train Loss: 0.089135, Train Acc: 0.873077 | Val Loss: 0.113103, Val Acc: 0.773196\n",
      "Epoch 16071 - Train Loss: 0.089131, Train Acc: 0.873077 | Val Loss: 0.113100, Val Acc: 0.773196\n",
      "Epoch 16072 - Train Loss: 0.089128, Train Acc: 0.873077 | Val Loss: 0.113098, Val Acc: 0.773196\n",
      "Epoch 16073 - Train Loss: 0.089125, Train Acc: 0.873077 | Val Loss: 0.113096, Val Acc: 0.773196\n",
      "Epoch 16074 - Train Loss: 0.089121, Train Acc: 0.873077 | Val Loss: 0.113094, Val Acc: 0.773196\n",
      "Epoch 16075 - Train Loss: 0.089118, Train Acc: 0.873077 | Val Loss: 0.113092, Val Acc: 0.773196\n",
      "Epoch 16076 - Train Loss: 0.089115, Train Acc: 0.873077 | Val Loss: 0.113090, Val Acc: 0.773196\n",
      "Epoch 16077 - Train Loss: 0.089112, Train Acc: 0.873077 | Val Loss: 0.113088, Val Acc: 0.773196\n",
      "Epoch 16078 - Train Loss: 0.089108, Train Acc: 0.873077 | Val Loss: 0.113086, Val Acc: 0.773196\n",
      "Epoch 16079 - Train Loss: 0.089105, Train Acc: 0.873077 | Val Loss: 0.113084, Val Acc: 0.773196\n",
      "Epoch 16080 - Train Loss: 0.089102, Train Acc: 0.873077 | Val Loss: 0.113082, Val Acc: 0.773196\n",
      "Epoch 16081 - Train Loss: 0.089098, Train Acc: 0.873077 | Val Loss: 0.113080, Val Acc: 0.773196\n",
      "Epoch 16082 - Train Loss: 0.089095, Train Acc: 0.873077 | Val Loss: 0.113078, Val Acc: 0.773196\n",
      "Epoch 16083 - Train Loss: 0.089092, Train Acc: 0.873077 | Val Loss: 0.113076, Val Acc: 0.773196\n",
      "Epoch 16084 - Train Loss: 0.089088, Train Acc: 0.873077 | Val Loss: 0.113074, Val Acc: 0.773196\n",
      "Epoch 16085 - Train Loss: 0.089085, Train Acc: 0.873077 | Val Loss: 0.113072, Val Acc: 0.773196\n",
      "Epoch 16086 - Train Loss: 0.089082, Train Acc: 0.873077 | Val Loss: 0.113070, Val Acc: 0.773196\n",
      "Epoch 16087 - Train Loss: 0.089078, Train Acc: 0.873077 | Val Loss: 0.113068, Val Acc: 0.773196\n",
      "Epoch 16088 - Train Loss: 0.089075, Train Acc: 0.873077 | Val Loss: 0.113066, Val Acc: 0.773196\n",
      "Epoch 16089 - Train Loss: 0.089072, Train Acc: 0.873077 | Val Loss: 0.113064, Val Acc: 0.773196\n",
      "Epoch 16090 - Train Loss: 0.089068, Train Acc: 0.873077 | Val Loss: 0.113062, Val Acc: 0.773196\n",
      "Epoch 16091 - Train Loss: 0.089065, Train Acc: 0.873077 | Val Loss: 0.113060, Val Acc: 0.773196\n",
      "Epoch 16092 - Train Loss: 0.089062, Train Acc: 0.873077 | Val Loss: 0.113058, Val Acc: 0.773196\n",
      "Epoch 16093 - Train Loss: 0.089059, Train Acc: 0.873077 | Val Loss: 0.113056, Val Acc: 0.773196\n",
      "Epoch 16094 - Train Loss: 0.089055, Train Acc: 0.873077 | Val Loss: 0.113054, Val Acc: 0.773196\n",
      "Epoch 16095 - Train Loss: 0.089052, Train Acc: 0.873077 | Val Loss: 0.113052, Val Acc: 0.773196\n",
      "Epoch 16096 - Train Loss: 0.089049, Train Acc: 0.873077 | Val Loss: 0.113050, Val Acc: 0.773196\n",
      "Epoch 16097 - Train Loss: 0.089045, Train Acc: 0.873077 | Val Loss: 0.113047, Val Acc: 0.773196\n",
      "Epoch 16098 - Train Loss: 0.089042, Train Acc: 0.873077 | Val Loss: 0.113045, Val Acc: 0.773196\n",
      "Epoch 16099 - Train Loss: 0.089039, Train Acc: 0.873077 | Val Loss: 0.113043, Val Acc: 0.773196\n",
      "Epoch 16100 - Train Loss: 0.089035, Train Acc: 0.873077 | Val Loss: 0.113041, Val Acc: 0.773196\n",
      "Epoch 16101 - Train Loss: 0.089032, Train Acc: 0.873077 | Val Loss: 0.113039, Val Acc: 0.773196\n",
      "Epoch 16102 - Train Loss: 0.089029, Train Acc: 0.873077 | Val Loss: 0.113037, Val Acc: 0.773196\n",
      "Epoch 16103 - Train Loss: 0.089025, Train Acc: 0.873077 | Val Loss: 0.113035, Val Acc: 0.773196\n",
      "Epoch 16104 - Train Loss: 0.089022, Train Acc: 0.873077 | Val Loss: 0.113033, Val Acc: 0.773196\n",
      "Epoch 16105 - Train Loss: 0.089019, Train Acc: 0.873077 | Val Loss: 0.113031, Val Acc: 0.773196\n",
      "Epoch 16106 - Train Loss: 0.089016, Train Acc: 0.873077 | Val Loss: 0.113029, Val Acc: 0.773196\n",
      "Epoch 16107 - Train Loss: 0.089012, Train Acc: 0.873077 | Val Loss: 0.113027, Val Acc: 0.773196\n",
      "Epoch 16108 - Train Loss: 0.089009, Train Acc: 0.873077 | Val Loss: 0.113025, Val Acc: 0.773196\n",
      "Epoch 16109 - Train Loss: 0.089006, Train Acc: 0.873077 | Val Loss: 0.113023, Val Acc: 0.773196\n",
      "Epoch 16110 - Train Loss: 0.089002, Train Acc: 0.873077 | Val Loss: 0.113021, Val Acc: 0.773196\n",
      "Epoch 16111 - Train Loss: 0.088999, Train Acc: 0.873077 | Val Loss: 0.113019, Val Acc: 0.773196\n",
      "Epoch 16112 - Train Loss: 0.088996, Train Acc: 0.873077 | Val Loss: 0.113017, Val Acc: 0.773196\n",
      "Epoch 16113 - Train Loss: 0.088992, Train Acc: 0.873077 | Val Loss: 0.113015, Val Acc: 0.773196\n",
      "Epoch 16114 - Train Loss: 0.088989, Train Acc: 0.873077 | Val Loss: 0.113013, Val Acc: 0.773196\n",
      "Epoch 16115 - Train Loss: 0.088986, Train Acc: 0.873077 | Val Loss: 0.113011, Val Acc: 0.773196\n",
      "Epoch 16116 - Train Loss: 0.088983, Train Acc: 0.873077 | Val Loss: 0.113009, Val Acc: 0.773196\n",
      "Epoch 16117 - Train Loss: 0.088979, Train Acc: 0.873077 | Val Loss: 0.113007, Val Acc: 0.773196\n",
      "Epoch 16118 - Train Loss: 0.088976, Train Acc: 0.873077 | Val Loss: 0.113005, Val Acc: 0.773196\n",
      "Epoch 16119 - Train Loss: 0.088973, Train Acc: 0.873077 | Val Loss: 0.113003, Val Acc: 0.773196\n",
      "Epoch 16120 - Train Loss: 0.088969, Train Acc: 0.873077 | Val Loss: 0.113001, Val Acc: 0.773196\n",
      "Epoch 16121 - Train Loss: 0.088966, Train Acc: 0.873077 | Val Loss: 0.112999, Val Acc: 0.773196\n",
      "Epoch 16122 - Train Loss: 0.088963, Train Acc: 0.873077 | Val Loss: 0.112997, Val Acc: 0.773196\n",
      "Epoch 16123 - Train Loss: 0.088959, Train Acc: 0.873077 | Val Loss: 0.112995, Val Acc: 0.773196\n",
      "Epoch 16124 - Train Loss: 0.088956, Train Acc: 0.873077 | Val Loss: 0.112993, Val Acc: 0.773196\n",
      "Epoch 16125 - Train Loss: 0.088953, Train Acc: 0.873077 | Val Loss: 0.112991, Val Acc: 0.773196\n",
      "Epoch 16126 - Train Loss: 0.088950, Train Acc: 0.873077 | Val Loss: 0.112989, Val Acc: 0.773196\n",
      "Epoch 16127 - Train Loss: 0.088946, Train Acc: 0.873077 | Val Loss: 0.112987, Val Acc: 0.773196\n",
      "Epoch 16128 - Train Loss: 0.088943, Train Acc: 0.873077 | Val Loss: 0.112985, Val Acc: 0.773196\n",
      "Epoch 16129 - Train Loss: 0.088940, Train Acc: 0.873077 | Val Loss: 0.112983, Val Acc: 0.773196\n",
      "Epoch 16130 - Train Loss: 0.088936, Train Acc: 0.873077 | Val Loss: 0.112981, Val Acc: 0.773196\n",
      "Epoch 16131 - Train Loss: 0.088933, Train Acc: 0.873077 | Val Loss: 0.112979, Val Acc: 0.773196\n",
      "Epoch 16132 - Train Loss: 0.088930, Train Acc: 0.873077 | Val Loss: 0.112977, Val Acc: 0.773196\n",
      "Epoch 16133 - Train Loss: 0.088927, Train Acc: 0.873077 | Val Loss: 0.112975, Val Acc: 0.773196\n",
      "Epoch 16134 - Train Loss: 0.088923, Train Acc: 0.873077 | Val Loss: 0.112972, Val Acc: 0.773196\n",
      "Epoch 16135 - Train Loss: 0.088920, Train Acc: 0.873077 | Val Loss: 0.112970, Val Acc: 0.773196\n",
      "Epoch 16136 - Train Loss: 0.088917, Train Acc: 0.873077 | Val Loss: 0.112968, Val Acc: 0.773196\n",
      "Epoch 16137 - Train Loss: 0.088913, Train Acc: 0.873077 | Val Loss: 0.112966, Val Acc: 0.773196\n",
      "Epoch 16138 - Train Loss: 0.088910, Train Acc: 0.873077 | Val Loss: 0.112964, Val Acc: 0.773196\n",
      "Epoch 16139 - Train Loss: 0.088907, Train Acc: 0.873077 | Val Loss: 0.112962, Val Acc: 0.773196\n",
      "Epoch 16140 - Train Loss: 0.088904, Train Acc: 0.873077 | Val Loss: 0.112960, Val Acc: 0.773196\n",
      "Epoch 16141 - Train Loss: 0.088900, Train Acc: 0.874359 | Val Loss: 0.112958, Val Acc: 0.773196\n",
      "Epoch 16142 - Train Loss: 0.088897, Train Acc: 0.874359 | Val Loss: 0.112956, Val Acc: 0.773196\n",
      "Epoch 16143 - Train Loss: 0.088894, Train Acc: 0.874359 | Val Loss: 0.112954, Val Acc: 0.773196\n",
      "Epoch 16144 - Train Loss: 0.088890, Train Acc: 0.874359 | Val Loss: 0.112952, Val Acc: 0.773196\n",
      "Epoch 16145 - Train Loss: 0.088887, Train Acc: 0.874359 | Val Loss: 0.112950, Val Acc: 0.773196\n",
      "Epoch 16146 - Train Loss: 0.088884, Train Acc: 0.874359 | Val Loss: 0.112948, Val Acc: 0.773196\n",
      "Epoch 16147 - Train Loss: 0.088881, Train Acc: 0.874359 | Val Loss: 0.112946, Val Acc: 0.773196\n",
      "Epoch 16148 - Train Loss: 0.088877, Train Acc: 0.874359 | Val Loss: 0.112944, Val Acc: 0.773196\n",
      "Epoch 16149 - Train Loss: 0.088874, Train Acc: 0.874359 | Val Loss: 0.112942, Val Acc: 0.773196\n",
      "Epoch 16150 - Train Loss: 0.088871, Train Acc: 0.874359 | Val Loss: 0.112940, Val Acc: 0.773196\n",
      "Epoch 16151 - Train Loss: 0.088867, Train Acc: 0.874359 | Val Loss: 0.112938, Val Acc: 0.773196\n",
      "Epoch 16152 - Train Loss: 0.088864, Train Acc: 0.874359 | Val Loss: 0.112936, Val Acc: 0.773196\n",
      "Epoch 16153 - Train Loss: 0.088861, Train Acc: 0.874359 | Val Loss: 0.112934, Val Acc: 0.773196\n",
      "Epoch 16154 - Train Loss: 0.088858, Train Acc: 0.874359 | Val Loss: 0.112932, Val Acc: 0.773196\n",
      "Epoch 16155 - Train Loss: 0.088854, Train Acc: 0.874359 | Val Loss: 0.112930, Val Acc: 0.773196\n",
      "Epoch 16156 - Train Loss: 0.088851, Train Acc: 0.874359 | Val Loss: 0.112928, Val Acc: 0.773196\n",
      "Epoch 16157 - Train Loss: 0.088848, Train Acc: 0.874359 | Val Loss: 0.112926, Val Acc: 0.773196\n",
      "Epoch 16158 - Train Loss: 0.088844, Train Acc: 0.874359 | Val Loss: 0.112924, Val Acc: 0.773196\n",
      "Epoch 16159 - Train Loss: 0.088841, Train Acc: 0.875641 | Val Loss: 0.112922, Val Acc: 0.773196\n",
      "Epoch 16160 - Train Loss: 0.088838, Train Acc: 0.875641 | Val Loss: 0.112920, Val Acc: 0.773196\n",
      "Epoch 16161 - Train Loss: 0.088835, Train Acc: 0.875641 | Val Loss: 0.112918, Val Acc: 0.773196\n",
      "Epoch 16162 - Train Loss: 0.088831, Train Acc: 0.875641 | Val Loss: 0.112916, Val Acc: 0.773196\n",
      "Epoch 16163 - Train Loss: 0.088828, Train Acc: 0.875641 | Val Loss: 0.112914, Val Acc: 0.773196\n",
      "Epoch 16164 - Train Loss: 0.088825, Train Acc: 0.875641 | Val Loss: 0.112912, Val Acc: 0.773196\n",
      "Epoch 16165 - Train Loss: 0.088821, Train Acc: 0.875641 | Val Loss: 0.112910, Val Acc: 0.773196\n",
      "Epoch 16166 - Train Loss: 0.088818, Train Acc: 0.875641 | Val Loss: 0.112908, Val Acc: 0.773196\n",
      "Epoch 16167 - Train Loss: 0.088815, Train Acc: 0.875641 | Val Loss: 0.112906, Val Acc: 0.773196\n",
      "Epoch 16168 - Train Loss: 0.088812, Train Acc: 0.875641 | Val Loss: 0.112904, Val Acc: 0.773196\n",
      "Epoch 16169 - Train Loss: 0.088808, Train Acc: 0.875641 | Val Loss: 0.112902, Val Acc: 0.773196\n",
      "Epoch 16170 - Train Loss: 0.088805, Train Acc: 0.875641 | Val Loss: 0.112900, Val Acc: 0.773196\n",
      "Epoch 16171 - Train Loss: 0.088802, Train Acc: 0.875641 | Val Loss: 0.112898, Val Acc: 0.773196\n",
      "Epoch 16172 - Train Loss: 0.088798, Train Acc: 0.875641 | Val Loss: 0.112896, Val Acc: 0.773196\n",
      "Epoch 16173 - Train Loss: 0.088795, Train Acc: 0.875641 | Val Loss: 0.112894, Val Acc: 0.773196\n",
      "Epoch 16174 - Train Loss: 0.088792, Train Acc: 0.875641 | Val Loss: 0.112892, Val Acc: 0.773196\n",
      "Epoch 16175 - Train Loss: 0.088789, Train Acc: 0.875641 | Val Loss: 0.112890, Val Acc: 0.773196\n",
      "Epoch 16176 - Train Loss: 0.088785, Train Acc: 0.875641 | Val Loss: 0.112888, Val Acc: 0.773196\n",
      "Epoch 16177 - Train Loss: 0.088782, Train Acc: 0.875641 | Val Loss: 0.112886, Val Acc: 0.773196\n",
      "Epoch 16178 - Train Loss: 0.088779, Train Acc: 0.875641 | Val Loss: 0.112884, Val Acc: 0.773196\n",
      "Epoch 16179 - Train Loss: 0.088776, Train Acc: 0.875641 | Val Loss: 0.112882, Val Acc: 0.773196\n",
      "Epoch 16180 - Train Loss: 0.088772, Train Acc: 0.875641 | Val Loss: 0.112880, Val Acc: 0.773196\n",
      "Epoch 16181 - Train Loss: 0.088769, Train Acc: 0.875641 | Val Loss: 0.112878, Val Acc: 0.773196\n",
      "Epoch 16182 - Train Loss: 0.088766, Train Acc: 0.875641 | Val Loss: 0.112876, Val Acc: 0.773196\n",
      "Epoch 16183 - Train Loss: 0.088762, Train Acc: 0.875641 | Val Loss: 0.112874, Val Acc: 0.773196\n",
      "Epoch 16184 - Train Loss: 0.088759, Train Acc: 0.875641 | Val Loss: 0.112872, Val Acc: 0.773196\n",
      "Epoch 16185 - Train Loss: 0.088756, Train Acc: 0.875641 | Val Loss: 0.112870, Val Acc: 0.773196\n",
      "Epoch 16186 - Train Loss: 0.088753, Train Acc: 0.875641 | Val Loss: 0.112868, Val Acc: 0.773196\n",
      "Epoch 16187 - Train Loss: 0.088749, Train Acc: 0.875641 | Val Loss: 0.112866, Val Acc: 0.773196\n",
      "Epoch 16188 - Train Loss: 0.088746, Train Acc: 0.875641 | Val Loss: 0.112864, Val Acc: 0.773196\n",
      "Epoch 16189 - Train Loss: 0.088743, Train Acc: 0.875641 | Val Loss: 0.112862, Val Acc: 0.773196\n",
      "Epoch 16190 - Train Loss: 0.088740, Train Acc: 0.875641 | Val Loss: 0.112860, Val Acc: 0.773196\n",
      "Epoch 16191 - Train Loss: 0.088736, Train Acc: 0.875641 | Val Loss: 0.112858, Val Acc: 0.773196\n",
      "Epoch 16192 - Train Loss: 0.088733, Train Acc: 0.875641 | Val Loss: 0.112856, Val Acc: 0.773196\n",
      "Epoch 16193 - Train Loss: 0.088730, Train Acc: 0.875641 | Val Loss: 0.112854, Val Acc: 0.773196\n",
      "Epoch 16194 - Train Loss: 0.088727, Train Acc: 0.875641 | Val Loss: 0.112852, Val Acc: 0.773196\n",
      "Epoch 16195 - Train Loss: 0.088723, Train Acc: 0.875641 | Val Loss: 0.112850, Val Acc: 0.773196\n",
      "Epoch 16196 - Train Loss: 0.088720, Train Acc: 0.875641 | Val Loss: 0.112848, Val Acc: 0.773196\n",
      "Epoch 16197 - Train Loss: 0.088717, Train Acc: 0.875641 | Val Loss: 0.112846, Val Acc: 0.773196\n",
      "Epoch 16198 - Train Loss: 0.088713, Train Acc: 0.875641 | Val Loss: 0.112844, Val Acc: 0.773196\n",
      "Epoch 16199 - Train Loss: 0.088710, Train Acc: 0.875641 | Val Loss: 0.112842, Val Acc: 0.773196\n",
      "Epoch 16200 - Train Loss: 0.088707, Train Acc: 0.875641 | Val Loss: 0.112840, Val Acc: 0.773196\n",
      "Epoch 16201 - Train Loss: 0.088704, Train Acc: 0.875641 | Val Loss: 0.112838, Val Acc: 0.773196\n",
      "Epoch 16202 - Train Loss: 0.088700, Train Acc: 0.875641 | Val Loss: 0.112836, Val Acc: 0.773196\n",
      "Epoch 16203 - Train Loss: 0.088697, Train Acc: 0.875641 | Val Loss: 0.112834, Val Acc: 0.773196\n",
      "Epoch 16204 - Train Loss: 0.088694, Train Acc: 0.875641 | Val Loss: 0.112832, Val Acc: 0.773196\n",
      "Epoch 16205 - Train Loss: 0.088691, Train Acc: 0.875641 | Val Loss: 0.112830, Val Acc: 0.773196\n",
      "Epoch 16206 - Train Loss: 0.088687, Train Acc: 0.875641 | Val Loss: 0.112828, Val Acc: 0.773196\n",
      "Epoch 16207 - Train Loss: 0.088684, Train Acc: 0.875641 | Val Loss: 0.112826, Val Acc: 0.773196\n",
      "Epoch 16208 - Train Loss: 0.088681, Train Acc: 0.875641 | Val Loss: 0.112824, Val Acc: 0.773196\n",
      "Epoch 16209 - Train Loss: 0.088678, Train Acc: 0.875641 | Val Loss: 0.112822, Val Acc: 0.773196\n",
      "Epoch 16210 - Train Loss: 0.088674, Train Acc: 0.875641 | Val Loss: 0.112820, Val Acc: 0.773196\n",
      "Epoch 16211 - Train Loss: 0.088671, Train Acc: 0.875641 | Val Loss: 0.112818, Val Acc: 0.773196\n",
      "Epoch 16212 - Train Loss: 0.088668, Train Acc: 0.875641 | Val Loss: 0.112816, Val Acc: 0.773196\n",
      "Epoch 16213 - Train Loss: 0.088665, Train Acc: 0.875641 | Val Loss: 0.112814, Val Acc: 0.773196\n",
      "Epoch 16214 - Train Loss: 0.088661, Train Acc: 0.875641 | Val Loss: 0.112812, Val Acc: 0.773196\n",
      "Epoch 16215 - Train Loss: 0.088658, Train Acc: 0.875641 | Val Loss: 0.112810, Val Acc: 0.773196\n",
      "Epoch 16216 - Train Loss: 0.088655, Train Acc: 0.875641 | Val Loss: 0.112808, Val Acc: 0.773196\n",
      "Epoch 16217 - Train Loss: 0.088651, Train Acc: 0.875641 | Val Loss: 0.112806, Val Acc: 0.773196\n",
      "Epoch 16218 - Train Loss: 0.088648, Train Acc: 0.875641 | Val Loss: 0.112804, Val Acc: 0.773196\n",
      "Epoch 16219 - Train Loss: 0.088645, Train Acc: 0.875641 | Val Loss: 0.112802, Val Acc: 0.773196\n",
      "Epoch 16220 - Train Loss: 0.088642, Train Acc: 0.875641 | Val Loss: 0.112800, Val Acc: 0.773196\n",
      "Epoch 16221 - Train Loss: 0.088638, Train Acc: 0.875641 | Val Loss: 0.112798, Val Acc: 0.773196\n",
      "Epoch 16222 - Train Loss: 0.088635, Train Acc: 0.875641 | Val Loss: 0.112796, Val Acc: 0.773196\n",
      "Epoch 16223 - Train Loss: 0.088632, Train Acc: 0.875641 | Val Loss: 0.112794, Val Acc: 0.773196\n",
      "Epoch 16224 - Train Loss: 0.088629, Train Acc: 0.875641 | Val Loss: 0.112792, Val Acc: 0.773196\n",
      "Epoch 16225 - Train Loss: 0.088625, Train Acc: 0.875641 | Val Loss: 0.112790, Val Acc: 0.773196\n",
      "Epoch 16226 - Train Loss: 0.088622, Train Acc: 0.875641 | Val Loss: 0.112788, Val Acc: 0.773196\n",
      "Epoch 16227 - Train Loss: 0.088619, Train Acc: 0.875641 | Val Loss: 0.112786, Val Acc: 0.773196\n",
      "Epoch 16228 - Train Loss: 0.088616, Train Acc: 0.875641 | Val Loss: 0.112784, Val Acc: 0.773196\n",
      "Epoch 16229 - Train Loss: 0.088612, Train Acc: 0.875641 | Val Loss: 0.112782, Val Acc: 0.773196\n",
      "Epoch 16230 - Train Loss: 0.088609, Train Acc: 0.875641 | Val Loss: 0.112780, Val Acc: 0.773196\n",
      "Epoch 16231 - Train Loss: 0.088606, Train Acc: 0.875641 | Val Loss: 0.112779, Val Acc: 0.773196\n",
      "Epoch 16232 - Train Loss: 0.088603, Train Acc: 0.875641 | Val Loss: 0.112777, Val Acc: 0.773196\n",
      "Epoch 16233 - Train Loss: 0.088599, Train Acc: 0.875641 | Val Loss: 0.112775, Val Acc: 0.773196\n",
      "Epoch 16234 - Train Loss: 0.088596, Train Acc: 0.875641 | Val Loss: 0.112773, Val Acc: 0.773196\n",
      "Epoch 16235 - Train Loss: 0.088593, Train Acc: 0.875641 | Val Loss: 0.112771, Val Acc: 0.773196\n",
      "Epoch 16236 - Train Loss: 0.088590, Train Acc: 0.875641 | Val Loss: 0.112769, Val Acc: 0.773196\n",
      "Epoch 16237 - Train Loss: 0.088586, Train Acc: 0.875641 | Val Loss: 0.112767, Val Acc: 0.773196\n",
      "Epoch 16238 - Train Loss: 0.088583, Train Acc: 0.875641 | Val Loss: 0.112765, Val Acc: 0.773196\n",
      "Epoch 16239 - Train Loss: 0.088580, Train Acc: 0.875641 | Val Loss: 0.112763, Val Acc: 0.773196\n",
      "Epoch 16240 - Train Loss: 0.088577, Train Acc: 0.875641 | Val Loss: 0.112761, Val Acc: 0.773196\n",
      "Epoch 16241 - Train Loss: 0.088573, Train Acc: 0.875641 | Val Loss: 0.112759, Val Acc: 0.773196\n",
      "Epoch 16242 - Train Loss: 0.088570, Train Acc: 0.875641 | Val Loss: 0.112757, Val Acc: 0.773196\n",
      "Epoch 16243 - Train Loss: 0.088567, Train Acc: 0.875641 | Val Loss: 0.112755, Val Acc: 0.773196\n",
      "Epoch 16244 - Train Loss: 0.088564, Train Acc: 0.875641 | Val Loss: 0.112753, Val Acc: 0.773196\n",
      "Epoch 16245 - Train Loss: 0.088560, Train Acc: 0.875641 | Val Loss: 0.112751, Val Acc: 0.773196\n",
      "Epoch 16246 - Train Loss: 0.088557, Train Acc: 0.875641 | Val Loss: 0.112749, Val Acc: 0.773196\n",
      "Epoch 16247 - Train Loss: 0.088554, Train Acc: 0.875641 | Val Loss: 0.112747, Val Acc: 0.773196\n",
      "Epoch 16248 - Train Loss: 0.088551, Train Acc: 0.875641 | Val Loss: 0.112745, Val Acc: 0.773196\n",
      "Epoch 16249 - Train Loss: 0.088547, Train Acc: 0.875641 | Val Loss: 0.112743, Val Acc: 0.773196\n",
      "Epoch 16250 - Train Loss: 0.088544, Train Acc: 0.875641 | Val Loss: 0.112741, Val Acc: 0.773196\n",
      "Epoch 16251 - Train Loss: 0.088541, Train Acc: 0.875641 | Val Loss: 0.112739, Val Acc: 0.773196\n",
      "Epoch 16252 - Train Loss: 0.088538, Train Acc: 0.875641 | Val Loss: 0.112737, Val Acc: 0.773196\n",
      "Epoch 16253 - Train Loss: 0.088534, Train Acc: 0.875641 | Val Loss: 0.112735, Val Acc: 0.773196\n",
      "Epoch 16254 - Train Loss: 0.088531, Train Acc: 0.875641 | Val Loss: 0.112733, Val Acc: 0.773196\n",
      "Epoch 16255 - Train Loss: 0.088528, Train Acc: 0.875641 | Val Loss: 0.112731, Val Acc: 0.773196\n",
      "Epoch 16256 - Train Loss: 0.088525, Train Acc: 0.875641 | Val Loss: 0.112729, Val Acc: 0.773196\n",
      "Epoch 16257 - Train Loss: 0.088522, Train Acc: 0.875641 | Val Loss: 0.112727, Val Acc: 0.773196\n",
      "Epoch 16258 - Train Loss: 0.088518, Train Acc: 0.875641 | Val Loss: 0.112725, Val Acc: 0.773196\n",
      "Epoch 16259 - Train Loss: 0.088515, Train Acc: 0.875641 | Val Loss: 0.112723, Val Acc: 0.773196\n",
      "Epoch 16260 - Train Loss: 0.088512, Train Acc: 0.875641 | Val Loss: 0.112721, Val Acc: 0.773196\n",
      "Epoch 16261 - Train Loss: 0.088509, Train Acc: 0.875641 | Val Loss: 0.112719, Val Acc: 0.773196\n",
      "Epoch 16262 - Train Loss: 0.088505, Train Acc: 0.875641 | Val Loss: 0.112717, Val Acc: 0.773196\n",
      "Epoch 16263 - Train Loss: 0.088502, Train Acc: 0.875641 | Val Loss: 0.112715, Val Acc: 0.773196\n",
      "Epoch 16264 - Train Loss: 0.088499, Train Acc: 0.875641 | Val Loss: 0.112713, Val Acc: 0.773196\n",
      "Epoch 16265 - Train Loss: 0.088496, Train Acc: 0.875641 | Val Loss: 0.112711, Val Acc: 0.773196\n",
      "Epoch 16266 - Train Loss: 0.088492, Train Acc: 0.875641 | Val Loss: 0.112709, Val Acc: 0.773196\n",
      "Epoch 16267 - Train Loss: 0.088489, Train Acc: 0.875641 | Val Loss: 0.112707, Val Acc: 0.773196\n",
      "Epoch 16268 - Train Loss: 0.088486, Train Acc: 0.875641 | Val Loss: 0.112706, Val Acc: 0.773196\n",
      "Epoch 16269 - Train Loss: 0.088483, Train Acc: 0.875641 | Val Loss: 0.112704, Val Acc: 0.773196\n",
      "Epoch 16270 - Train Loss: 0.088479, Train Acc: 0.875641 | Val Loss: 0.112702, Val Acc: 0.773196\n",
      "Epoch 16271 - Train Loss: 0.088476, Train Acc: 0.875641 | Val Loss: 0.112700, Val Acc: 0.773196\n",
      "Epoch 16272 - Train Loss: 0.088473, Train Acc: 0.875641 | Val Loss: 0.112698, Val Acc: 0.773196\n",
      "Epoch 16273 - Train Loss: 0.088470, Train Acc: 0.875641 | Val Loss: 0.112696, Val Acc: 0.773196\n",
      "Epoch 16274 - Train Loss: 0.088466, Train Acc: 0.875641 | Val Loss: 0.112694, Val Acc: 0.773196\n",
      "Epoch 16275 - Train Loss: 0.088463, Train Acc: 0.875641 | Val Loss: 0.112692, Val Acc: 0.773196\n",
      "Epoch 16276 - Train Loss: 0.088460, Train Acc: 0.875641 | Val Loss: 0.112690, Val Acc: 0.773196\n",
      "Epoch 16277 - Train Loss: 0.088457, Train Acc: 0.875641 | Val Loss: 0.112688, Val Acc: 0.773196\n",
      "Epoch 16278 - Train Loss: 0.088454, Train Acc: 0.875641 | Val Loss: 0.112686, Val Acc: 0.773196\n",
      "Epoch 16279 - Train Loss: 0.088450, Train Acc: 0.875641 | Val Loss: 0.112684, Val Acc: 0.773196\n",
      "Epoch 16280 - Train Loss: 0.088447, Train Acc: 0.875641 | Val Loss: 0.112682, Val Acc: 0.773196\n",
      "Epoch 16281 - Train Loss: 0.088444, Train Acc: 0.875641 | Val Loss: 0.112680, Val Acc: 0.773196\n",
      "Epoch 16282 - Train Loss: 0.088441, Train Acc: 0.875641 | Val Loss: 0.112678, Val Acc: 0.773196\n",
      "Epoch 16283 - Train Loss: 0.088437, Train Acc: 0.875641 | Val Loss: 0.112676, Val Acc: 0.773196\n",
      "Epoch 16284 - Train Loss: 0.088434, Train Acc: 0.875641 | Val Loss: 0.112674, Val Acc: 0.773196\n",
      "Epoch 16285 - Train Loss: 0.088431, Train Acc: 0.875641 | Val Loss: 0.112672, Val Acc: 0.773196\n",
      "Epoch 16286 - Train Loss: 0.088428, Train Acc: 0.875641 | Val Loss: 0.112670, Val Acc: 0.773196\n",
      "Epoch 16287 - Train Loss: 0.088424, Train Acc: 0.875641 | Val Loss: 0.112668, Val Acc: 0.773196\n",
      "Epoch 16288 - Train Loss: 0.088421, Train Acc: 0.875641 | Val Loss: 0.112666, Val Acc: 0.773196\n",
      "Epoch 16289 - Train Loss: 0.088418, Train Acc: 0.875641 | Val Loss: 0.112664, Val Acc: 0.773196\n",
      "Epoch 16290 - Train Loss: 0.088415, Train Acc: 0.875641 | Val Loss: 0.112662, Val Acc: 0.773196\n",
      "Epoch 16291 - Train Loss: 0.088412, Train Acc: 0.875641 | Val Loss: 0.112660, Val Acc: 0.773196\n",
      "Epoch 16292 - Train Loss: 0.088408, Train Acc: 0.875641 | Val Loss: 0.112658, Val Acc: 0.773196\n",
      "Epoch 16293 - Train Loss: 0.088405, Train Acc: 0.875641 | Val Loss: 0.112657, Val Acc: 0.773196\n",
      "Epoch 16294 - Train Loss: 0.088402, Train Acc: 0.875641 | Val Loss: 0.112655, Val Acc: 0.773196\n",
      "Epoch 16295 - Train Loss: 0.088399, Train Acc: 0.875641 | Val Loss: 0.112653, Val Acc: 0.773196\n",
      "Epoch 16296 - Train Loss: 0.088395, Train Acc: 0.875641 | Val Loss: 0.112651, Val Acc: 0.773196\n",
      "Epoch 16297 - Train Loss: 0.088392, Train Acc: 0.875641 | Val Loss: 0.112649, Val Acc: 0.773196\n",
      "Epoch 16298 - Train Loss: 0.088389, Train Acc: 0.875641 | Val Loss: 0.112647, Val Acc: 0.773196\n",
      "Epoch 16299 - Train Loss: 0.088386, Train Acc: 0.875641 | Val Loss: 0.112645, Val Acc: 0.773196\n",
      "Epoch 16300 - Train Loss: 0.088383, Train Acc: 0.875641 | Val Loss: 0.112643, Val Acc: 0.773196\n",
      "Epoch 16301 - Train Loss: 0.088379, Train Acc: 0.875641 | Val Loss: 0.112641, Val Acc: 0.773196\n",
      "Epoch 16302 - Train Loss: 0.088376, Train Acc: 0.875641 | Val Loss: 0.112639, Val Acc: 0.773196\n",
      "Epoch 16303 - Train Loss: 0.088373, Train Acc: 0.875641 | Val Loss: 0.112637, Val Acc: 0.773196\n",
      "Epoch 16304 - Train Loss: 0.088370, Train Acc: 0.875641 | Val Loss: 0.112635, Val Acc: 0.773196\n",
      "Epoch 16305 - Train Loss: 0.088366, Train Acc: 0.875641 | Val Loss: 0.112633, Val Acc: 0.773196\n",
      "Epoch 16306 - Train Loss: 0.088363, Train Acc: 0.875641 | Val Loss: 0.112631, Val Acc: 0.773196\n",
      "Epoch 16307 - Train Loss: 0.088360, Train Acc: 0.875641 | Val Loss: 0.112629, Val Acc: 0.773196\n",
      "Epoch 16308 - Train Loss: 0.088357, Train Acc: 0.875641 | Val Loss: 0.112627, Val Acc: 0.773196\n",
      "Epoch 16309 - Train Loss: 0.088354, Train Acc: 0.875641 | Val Loss: 0.112625, Val Acc: 0.773196\n",
      "Epoch 16310 - Train Loss: 0.088350, Train Acc: 0.875641 | Val Loss: 0.112623, Val Acc: 0.773196\n",
      "Epoch 16311 - Train Loss: 0.088347, Train Acc: 0.875641 | Val Loss: 0.112621, Val Acc: 0.773196\n",
      "Epoch 16312 - Train Loss: 0.088344, Train Acc: 0.875641 | Val Loss: 0.112619, Val Acc: 0.773196\n",
      "Epoch 16313 - Train Loss: 0.088341, Train Acc: 0.875641 | Val Loss: 0.112618, Val Acc: 0.773196\n",
      "Epoch 16314 - Train Loss: 0.088337, Train Acc: 0.875641 | Val Loss: 0.112616, Val Acc: 0.773196\n",
      "Epoch 16315 - Train Loss: 0.088334, Train Acc: 0.875641 | Val Loss: 0.112614, Val Acc: 0.773196\n",
      "Epoch 16316 - Train Loss: 0.088331, Train Acc: 0.875641 | Val Loss: 0.112612, Val Acc: 0.773196\n",
      "Epoch 16317 - Train Loss: 0.088328, Train Acc: 0.875641 | Val Loss: 0.112610, Val Acc: 0.773196\n",
      "Epoch 16318 - Train Loss: 0.088325, Train Acc: 0.875641 | Val Loss: 0.112608, Val Acc: 0.773196\n",
      "Epoch 16319 - Train Loss: 0.088321, Train Acc: 0.875641 | Val Loss: 0.112606, Val Acc: 0.773196\n",
      "Epoch 16320 - Train Loss: 0.088318, Train Acc: 0.875641 | Val Loss: 0.112604, Val Acc: 0.773196\n",
      "Epoch 16321 - Train Loss: 0.088315, Train Acc: 0.875641 | Val Loss: 0.112602, Val Acc: 0.773196\n",
      "Epoch 16322 - Train Loss: 0.088312, Train Acc: 0.875641 | Val Loss: 0.112600, Val Acc: 0.773196\n",
      "Epoch 16323 - Train Loss: 0.088308, Train Acc: 0.875641 | Val Loss: 0.112598, Val Acc: 0.773196\n",
      "Epoch 16324 - Train Loss: 0.088305, Train Acc: 0.875641 | Val Loss: 0.112596, Val Acc: 0.773196\n",
      "Epoch 16325 - Train Loss: 0.088302, Train Acc: 0.875641 | Val Loss: 0.112594, Val Acc: 0.773196\n",
      "Epoch 16326 - Train Loss: 0.088299, Train Acc: 0.875641 | Val Loss: 0.112592, Val Acc: 0.773196\n",
      "Epoch 16327 - Train Loss: 0.088296, Train Acc: 0.875641 | Val Loss: 0.112590, Val Acc: 0.773196\n",
      "Epoch 16328 - Train Loss: 0.088292, Train Acc: 0.875641 | Val Loss: 0.112588, Val Acc: 0.773196\n",
      "Epoch 16329 - Train Loss: 0.088289, Train Acc: 0.875641 | Val Loss: 0.112586, Val Acc: 0.773196\n",
      "Epoch 16330 - Train Loss: 0.088286, Train Acc: 0.875641 | Val Loss: 0.112585, Val Acc: 0.773196\n",
      "Epoch 16331 - Train Loss: 0.088283, Train Acc: 0.875641 | Val Loss: 0.112583, Val Acc: 0.773196\n",
      "Epoch 16332 - Train Loss: 0.088280, Train Acc: 0.875641 | Val Loss: 0.112581, Val Acc: 0.773196\n",
      "Epoch 16333 - Train Loss: 0.088276, Train Acc: 0.875641 | Val Loss: 0.112579, Val Acc: 0.773196\n",
      "Epoch 16334 - Train Loss: 0.088273, Train Acc: 0.875641 | Val Loss: 0.112577, Val Acc: 0.773196\n",
      "Epoch 16335 - Train Loss: 0.088270, Train Acc: 0.875641 | Val Loss: 0.112575, Val Acc: 0.773196\n",
      "Epoch 16336 - Train Loss: 0.088267, Train Acc: 0.875641 | Val Loss: 0.112573, Val Acc: 0.773196\n",
      "Epoch 16337 - Train Loss: 0.088263, Train Acc: 0.875641 | Val Loss: 0.112571, Val Acc: 0.773196\n",
      "Epoch 16338 - Train Loss: 0.088260, Train Acc: 0.875641 | Val Loss: 0.112569, Val Acc: 0.773196\n",
      "Epoch 16339 - Train Loss: 0.088257, Train Acc: 0.875641 | Val Loss: 0.112567, Val Acc: 0.773196\n",
      "Epoch 16340 - Train Loss: 0.088254, Train Acc: 0.875641 | Val Loss: 0.112565, Val Acc: 0.773196\n",
      "Epoch 16341 - Train Loss: 0.088251, Train Acc: 0.875641 | Val Loss: 0.112563, Val Acc: 0.773196\n",
      "Epoch 16342 - Train Loss: 0.088247, Train Acc: 0.875641 | Val Loss: 0.112561, Val Acc: 0.773196\n",
      "Epoch 16343 - Train Loss: 0.088244, Train Acc: 0.875641 | Val Loss: 0.112559, Val Acc: 0.773196\n",
      "Epoch 16344 - Train Loss: 0.088241, Train Acc: 0.875641 | Val Loss: 0.112557, Val Acc: 0.773196\n",
      "Epoch 16345 - Train Loss: 0.088238, Train Acc: 0.875641 | Val Loss: 0.112555, Val Acc: 0.773196\n",
      "Epoch 16346 - Train Loss: 0.088235, Train Acc: 0.875641 | Val Loss: 0.112553, Val Acc: 0.773196\n",
      "Epoch 16347 - Train Loss: 0.088231, Train Acc: 0.875641 | Val Loss: 0.112552, Val Acc: 0.773196\n",
      "Epoch 16348 - Train Loss: 0.088228, Train Acc: 0.875641 | Val Loss: 0.112550, Val Acc: 0.773196\n",
      "Epoch 16349 - Train Loss: 0.088225, Train Acc: 0.875641 | Val Loss: 0.112548, Val Acc: 0.773196\n",
      "Epoch 16350 - Train Loss: 0.088222, Train Acc: 0.875641 | Val Loss: 0.112546, Val Acc: 0.773196\n",
      "Epoch 16351 - Train Loss: 0.088219, Train Acc: 0.875641 | Val Loss: 0.112544, Val Acc: 0.773196\n",
      "Epoch 16352 - Train Loss: 0.088215, Train Acc: 0.875641 | Val Loss: 0.112542, Val Acc: 0.773196\n",
      "Epoch 16353 - Train Loss: 0.088212, Train Acc: 0.875641 | Val Loss: 0.112540, Val Acc: 0.773196\n",
      "Epoch 16354 - Train Loss: 0.088209, Train Acc: 0.875641 | Val Loss: 0.112538, Val Acc: 0.773196\n",
      "Epoch 16355 - Train Loss: 0.088206, Train Acc: 0.875641 | Val Loss: 0.112536, Val Acc: 0.773196\n",
      "Epoch 16356 - Train Loss: 0.088203, Train Acc: 0.875641 | Val Loss: 0.112534, Val Acc: 0.773196\n",
      "Epoch 16357 - Train Loss: 0.088199, Train Acc: 0.875641 | Val Loss: 0.112532, Val Acc: 0.773196\n",
      "Epoch 16358 - Train Loss: 0.088196, Train Acc: 0.875641 | Val Loss: 0.112530, Val Acc: 0.773196\n",
      "Epoch 16359 - Train Loss: 0.088193, Train Acc: 0.875641 | Val Loss: 0.112528, Val Acc: 0.773196\n",
      "Epoch 16360 - Train Loss: 0.088190, Train Acc: 0.875641 | Val Loss: 0.112526, Val Acc: 0.773196\n",
      "Epoch 16361 - Train Loss: 0.088187, Train Acc: 0.875641 | Val Loss: 0.112525, Val Acc: 0.773196\n",
      "Epoch 16362 - Train Loss: 0.088183, Train Acc: 0.875641 | Val Loss: 0.112523, Val Acc: 0.773196\n",
      "Epoch 16363 - Train Loss: 0.088180, Train Acc: 0.875641 | Val Loss: 0.112521, Val Acc: 0.773196\n",
      "Epoch 16364 - Train Loss: 0.088177, Train Acc: 0.875641 | Val Loss: 0.112519, Val Acc: 0.773196\n",
      "Epoch 16365 - Train Loss: 0.088174, Train Acc: 0.875641 | Val Loss: 0.112517, Val Acc: 0.773196\n",
      "Epoch 16366 - Train Loss: 0.088171, Train Acc: 0.875641 | Val Loss: 0.112515, Val Acc: 0.773196\n",
      "Epoch 16367 - Train Loss: 0.088167, Train Acc: 0.875641 | Val Loss: 0.112513, Val Acc: 0.773196\n",
      "Epoch 16368 - Train Loss: 0.088164, Train Acc: 0.875641 | Val Loss: 0.112511, Val Acc: 0.773196\n",
      "Epoch 16369 - Train Loss: 0.088161, Train Acc: 0.875641 | Val Loss: 0.112509, Val Acc: 0.773196\n",
      "Epoch 16370 - Train Loss: 0.088158, Train Acc: 0.875641 | Val Loss: 0.112507, Val Acc: 0.773196\n",
      "Epoch 16371 - Train Loss: 0.088155, Train Acc: 0.875641 | Val Loss: 0.112505, Val Acc: 0.773196\n",
      "Epoch 16372 - Train Loss: 0.088151, Train Acc: 0.875641 | Val Loss: 0.112503, Val Acc: 0.773196\n",
      "Epoch 16373 - Train Loss: 0.088148, Train Acc: 0.875641 | Val Loss: 0.112501, Val Acc: 0.773196\n",
      "Epoch 16374 - Train Loss: 0.088145, Train Acc: 0.875641 | Val Loss: 0.112500, Val Acc: 0.773196\n",
      "Epoch 16375 - Train Loss: 0.088142, Train Acc: 0.875641 | Val Loss: 0.112498, Val Acc: 0.773196\n",
      "Epoch 16376 - Train Loss: 0.088139, Train Acc: 0.875641 | Val Loss: 0.112496, Val Acc: 0.773196\n",
      "Epoch 16377 - Train Loss: 0.088135, Train Acc: 0.875641 | Val Loss: 0.112494, Val Acc: 0.773196\n",
      "Epoch 16378 - Train Loss: 0.088132, Train Acc: 0.875641 | Val Loss: 0.112492, Val Acc: 0.773196\n",
      "Epoch 16379 - Train Loss: 0.088129, Train Acc: 0.875641 | Val Loss: 0.112490, Val Acc: 0.773196\n",
      "Epoch 16380 - Train Loss: 0.088126, Train Acc: 0.875641 | Val Loss: 0.112488, Val Acc: 0.773196\n",
      "Epoch 16381 - Train Loss: 0.088123, Train Acc: 0.875641 | Val Loss: 0.112486, Val Acc: 0.773196\n",
      "Epoch 16382 - Train Loss: 0.088119, Train Acc: 0.875641 | Val Loss: 0.112484, Val Acc: 0.773196\n",
      "Epoch 16383 - Train Loss: 0.088116, Train Acc: 0.875641 | Val Loss: 0.112482, Val Acc: 0.773196\n",
      "Epoch 16384 - Train Loss: 0.088113, Train Acc: 0.875641 | Val Loss: 0.112480, Val Acc: 0.773196\n",
      "Epoch 16385 - Train Loss: 0.088110, Train Acc: 0.875641 | Val Loss: 0.112478, Val Acc: 0.773196\n",
      "Epoch 16386 - Train Loss: 0.088107, Train Acc: 0.875641 | Val Loss: 0.112476, Val Acc: 0.773196\n",
      "Epoch 16387 - Train Loss: 0.088103, Train Acc: 0.875641 | Val Loss: 0.112475, Val Acc: 0.773196\n",
      "Epoch 16388 - Train Loss: 0.088100, Train Acc: 0.875641 | Val Loss: 0.112473, Val Acc: 0.773196\n",
      "Epoch 16389 - Train Loss: 0.088097, Train Acc: 0.875641 | Val Loss: 0.112471, Val Acc: 0.773196\n",
      "Epoch 16390 - Train Loss: 0.088094, Train Acc: 0.875641 | Val Loss: 0.112469, Val Acc: 0.773196\n",
      "Epoch 16391 - Train Loss: 0.088091, Train Acc: 0.875641 | Val Loss: 0.112467, Val Acc: 0.773196\n",
      "Epoch 16392 - Train Loss: 0.088088, Train Acc: 0.875641 | Val Loss: 0.112465, Val Acc: 0.773196\n",
      "Epoch 16393 - Train Loss: 0.088084, Train Acc: 0.875641 | Val Loss: 0.112463, Val Acc: 0.773196\n",
      "Epoch 16394 - Train Loss: 0.088081, Train Acc: 0.875641 | Val Loss: 0.112461, Val Acc: 0.773196\n",
      "Epoch 16395 - Train Loss: 0.088078, Train Acc: 0.875641 | Val Loss: 0.112459, Val Acc: 0.773196\n",
      "Epoch 16396 - Train Loss: 0.088075, Train Acc: 0.875641 | Val Loss: 0.112457, Val Acc: 0.773196\n",
      "Epoch 16397 - Train Loss: 0.088072, Train Acc: 0.875641 | Val Loss: 0.112455, Val Acc: 0.773196\n",
      "Epoch 16398 - Train Loss: 0.088068, Train Acc: 0.875641 | Val Loss: 0.112453, Val Acc: 0.773196\n",
      "Epoch 16399 - Train Loss: 0.088065, Train Acc: 0.875641 | Val Loss: 0.112452, Val Acc: 0.773196\n",
      "Epoch 16400 - Train Loss: 0.088062, Train Acc: 0.875641 | Val Loss: 0.112450, Val Acc: 0.773196\n",
      "Epoch 16401 - Train Loss: 0.088059, Train Acc: 0.875641 | Val Loss: 0.112448, Val Acc: 0.773196\n",
      "Epoch 16402 - Train Loss: 0.088056, Train Acc: 0.875641 | Val Loss: 0.112446, Val Acc: 0.773196\n",
      "Epoch 16403 - Train Loss: 0.088052, Train Acc: 0.875641 | Val Loss: 0.112444, Val Acc: 0.773196\n",
      "Epoch 16404 - Train Loss: 0.088049, Train Acc: 0.875641 | Val Loss: 0.112442, Val Acc: 0.773196\n",
      "Epoch 16405 - Train Loss: 0.088046, Train Acc: 0.875641 | Val Loss: 0.112440, Val Acc: 0.773196\n",
      "Epoch 16406 - Train Loss: 0.088043, Train Acc: 0.875641 | Val Loss: 0.112438, Val Acc: 0.773196\n",
      "Epoch 16407 - Train Loss: 0.088040, Train Acc: 0.875641 | Val Loss: 0.112436, Val Acc: 0.773196\n",
      "Epoch 16408 - Train Loss: 0.088037, Train Acc: 0.875641 | Val Loss: 0.112434, Val Acc: 0.773196\n",
      "Epoch 16409 - Train Loss: 0.088033, Train Acc: 0.875641 | Val Loss: 0.112432, Val Acc: 0.773196\n",
      "Epoch 16410 - Train Loss: 0.088030, Train Acc: 0.875641 | Val Loss: 0.112431, Val Acc: 0.773196\n",
      "Epoch 16411 - Train Loss: 0.088027, Train Acc: 0.875641 | Val Loss: 0.112429, Val Acc: 0.773196\n",
      "Epoch 16412 - Train Loss: 0.088024, Train Acc: 0.875641 | Val Loss: 0.112427, Val Acc: 0.773196\n",
      "Epoch 16413 - Train Loss: 0.088021, Train Acc: 0.875641 | Val Loss: 0.112425, Val Acc: 0.773196\n",
      "Epoch 16414 - Train Loss: 0.088017, Train Acc: 0.875641 | Val Loss: 0.112423, Val Acc: 0.773196\n",
      "Epoch 16415 - Train Loss: 0.088014, Train Acc: 0.875641 | Val Loss: 0.112421, Val Acc: 0.773196\n",
      "Epoch 16416 - Train Loss: 0.088011, Train Acc: 0.875641 | Val Loss: 0.112419, Val Acc: 0.773196\n",
      "Epoch 16417 - Train Loss: 0.088008, Train Acc: 0.875641 | Val Loss: 0.112417, Val Acc: 0.773196\n",
      "Epoch 16418 - Train Loss: 0.088005, Train Acc: 0.875641 | Val Loss: 0.112415, Val Acc: 0.773196\n",
      "Epoch 16419 - Train Loss: 0.088002, Train Acc: 0.875641 | Val Loss: 0.112413, Val Acc: 0.773196\n",
      "Epoch 16420 - Train Loss: 0.087998, Train Acc: 0.875641 | Val Loss: 0.112412, Val Acc: 0.773196\n",
      "Epoch 16421 - Train Loss: 0.087995, Train Acc: 0.875641 | Val Loss: 0.112410, Val Acc: 0.773196\n",
      "Epoch 16422 - Train Loss: 0.087992, Train Acc: 0.875641 | Val Loss: 0.112408, Val Acc: 0.773196\n",
      "Epoch 16423 - Train Loss: 0.087989, Train Acc: 0.875641 | Val Loss: 0.112406, Val Acc: 0.773196\n",
      "Epoch 16424 - Train Loss: 0.087986, Train Acc: 0.875641 | Val Loss: 0.112404, Val Acc: 0.773196\n",
      "Epoch 16425 - Train Loss: 0.087982, Train Acc: 0.875641 | Val Loss: 0.112402, Val Acc: 0.773196\n",
      "Epoch 16426 - Train Loss: 0.087979, Train Acc: 0.875641 | Val Loss: 0.112400, Val Acc: 0.773196\n",
      "Epoch 16427 - Train Loss: 0.087976, Train Acc: 0.875641 | Val Loss: 0.112398, Val Acc: 0.773196\n",
      "Epoch 16428 - Train Loss: 0.087973, Train Acc: 0.875641 | Val Loss: 0.112396, Val Acc: 0.773196\n",
      "Epoch 16429 - Train Loss: 0.087970, Train Acc: 0.875641 | Val Loss: 0.112394, Val Acc: 0.773196\n",
      "Epoch 16430 - Train Loss: 0.087967, Train Acc: 0.875641 | Val Loss: 0.112392, Val Acc: 0.773196\n",
      "Epoch 16431 - Train Loss: 0.087963, Train Acc: 0.875641 | Val Loss: 0.112391, Val Acc: 0.773196\n",
      "Epoch 16432 - Train Loss: 0.087960, Train Acc: 0.875641 | Val Loss: 0.112389, Val Acc: 0.773196\n",
      "Epoch 16433 - Train Loss: 0.087957, Train Acc: 0.875641 | Val Loss: 0.112387, Val Acc: 0.773196\n",
      "Epoch 16434 - Train Loss: 0.087954, Train Acc: 0.875641 | Val Loss: 0.112385, Val Acc: 0.773196\n",
      "Epoch 16435 - Train Loss: 0.087951, Train Acc: 0.875641 | Val Loss: 0.112383, Val Acc: 0.773196\n",
      "Epoch 16436 - Train Loss: 0.087948, Train Acc: 0.875641 | Val Loss: 0.112381, Val Acc: 0.773196\n",
      "Epoch 16437 - Train Loss: 0.087944, Train Acc: 0.875641 | Val Loss: 0.112379, Val Acc: 0.773196\n",
      "Epoch 16438 - Train Loss: 0.087941, Train Acc: 0.875641 | Val Loss: 0.112377, Val Acc: 0.773196\n",
      "Epoch 16439 - Train Loss: 0.087938, Train Acc: 0.875641 | Val Loss: 0.112375, Val Acc: 0.773196\n",
      "Epoch 16440 - Train Loss: 0.087935, Train Acc: 0.875641 | Val Loss: 0.112373, Val Acc: 0.773196\n",
      "Epoch 16441 - Train Loss: 0.087932, Train Acc: 0.875641 | Val Loss: 0.112372, Val Acc: 0.773196\n",
      "Epoch 16442 - Train Loss: 0.087929, Train Acc: 0.875641 | Val Loss: 0.112370, Val Acc: 0.773196\n",
      "Epoch 16443 - Train Loss: 0.087925, Train Acc: 0.875641 | Val Loss: 0.112368, Val Acc: 0.773196\n",
      "Epoch 16444 - Train Loss: 0.087922, Train Acc: 0.875641 | Val Loss: 0.112366, Val Acc: 0.773196\n",
      "Epoch 16445 - Train Loss: 0.087919, Train Acc: 0.875641 | Val Loss: 0.112364, Val Acc: 0.773196\n",
      "Epoch 16446 - Train Loss: 0.087916, Train Acc: 0.875641 | Val Loss: 0.112362, Val Acc: 0.773196\n",
      "Epoch 16447 - Train Loss: 0.087913, Train Acc: 0.875641 | Val Loss: 0.112360, Val Acc: 0.773196\n",
      "Epoch 16448 - Train Loss: 0.087910, Train Acc: 0.875641 | Val Loss: 0.112358, Val Acc: 0.773196\n",
      "Epoch 16449 - Train Loss: 0.087906, Train Acc: 0.875641 | Val Loss: 0.112356, Val Acc: 0.773196\n",
      "Epoch 16450 - Train Loss: 0.087903, Train Acc: 0.875641 | Val Loss: 0.112355, Val Acc: 0.773196\n",
      "Epoch 16451 - Train Loss: 0.087900, Train Acc: 0.875641 | Val Loss: 0.112353, Val Acc: 0.773196\n",
      "Epoch 16452 - Train Loss: 0.087897, Train Acc: 0.875641 | Val Loss: 0.112351, Val Acc: 0.773196\n",
      "Epoch 16453 - Train Loss: 0.087894, Train Acc: 0.875641 | Val Loss: 0.112349, Val Acc: 0.773196\n",
      "Epoch 16454 - Train Loss: 0.087891, Train Acc: 0.875641 | Val Loss: 0.112347, Val Acc: 0.773196\n",
      "Epoch 16455 - Train Loss: 0.087887, Train Acc: 0.875641 | Val Loss: 0.112345, Val Acc: 0.773196\n",
      "Epoch 16456 - Train Loss: 0.087884, Train Acc: 0.876923 | Val Loss: 0.112343, Val Acc: 0.773196\n",
      "Epoch 16457 - Train Loss: 0.087881, Train Acc: 0.876923 | Val Loss: 0.112341, Val Acc: 0.773196\n",
      "Epoch 16458 - Train Loss: 0.087878, Train Acc: 0.876923 | Val Loss: 0.112339, Val Acc: 0.773196\n",
      "Epoch 16459 - Train Loss: 0.087875, Train Acc: 0.876923 | Val Loss: 0.112337, Val Acc: 0.773196\n",
      "Epoch 16460 - Train Loss: 0.087872, Train Acc: 0.876923 | Val Loss: 0.112336, Val Acc: 0.773196\n",
      "Epoch 16461 - Train Loss: 0.087868, Train Acc: 0.876923 | Val Loss: 0.112334, Val Acc: 0.773196\n",
      "Epoch 16462 - Train Loss: 0.087865, Train Acc: 0.876923 | Val Loss: 0.112332, Val Acc: 0.773196\n",
      "Epoch 16463 - Train Loss: 0.087862, Train Acc: 0.876923 | Val Loss: 0.112330, Val Acc: 0.773196\n",
      "Epoch 16464 - Train Loss: 0.087859, Train Acc: 0.876923 | Val Loss: 0.112328, Val Acc: 0.773196\n",
      "Epoch 16465 - Train Loss: 0.087856, Train Acc: 0.876923 | Val Loss: 0.112326, Val Acc: 0.773196\n",
      "Epoch 16466 - Train Loss: 0.087853, Train Acc: 0.876923 | Val Loss: 0.112324, Val Acc: 0.773196\n",
      "Epoch 16467 - Train Loss: 0.087849, Train Acc: 0.876923 | Val Loss: 0.112322, Val Acc: 0.773196\n",
      "Epoch 16468 - Train Loss: 0.087846, Train Acc: 0.876923 | Val Loss: 0.112320, Val Acc: 0.773196\n",
      "Epoch 16469 - Train Loss: 0.087843, Train Acc: 0.876923 | Val Loss: 0.112319, Val Acc: 0.773196\n",
      "Epoch 16470 - Train Loss: 0.087840, Train Acc: 0.876923 | Val Loss: 0.112317, Val Acc: 0.773196\n",
      "Epoch 16471 - Train Loss: 0.087837, Train Acc: 0.876923 | Val Loss: 0.112315, Val Acc: 0.773196\n",
      "Epoch 16472 - Train Loss: 0.087834, Train Acc: 0.876923 | Val Loss: 0.112313, Val Acc: 0.773196\n",
      "Epoch 16473 - Train Loss: 0.087831, Train Acc: 0.876923 | Val Loss: 0.112311, Val Acc: 0.773196\n",
      "Epoch 16474 - Train Loss: 0.087827, Train Acc: 0.876923 | Val Loss: 0.112309, Val Acc: 0.773196\n",
      "Epoch 16475 - Train Loss: 0.087824, Train Acc: 0.876923 | Val Loss: 0.112307, Val Acc: 0.773196\n",
      "Epoch 16476 - Train Loss: 0.087821, Train Acc: 0.876923 | Val Loss: 0.112305, Val Acc: 0.773196\n",
      "Epoch 16477 - Train Loss: 0.087818, Train Acc: 0.876923 | Val Loss: 0.112303, Val Acc: 0.773196\n",
      "Epoch 16478 - Train Loss: 0.087815, Train Acc: 0.876923 | Val Loss: 0.112302, Val Acc: 0.773196\n",
      "Epoch 16479 - Train Loss: 0.087812, Train Acc: 0.876923 | Val Loss: 0.112300, Val Acc: 0.773196\n",
      "Epoch 16480 - Train Loss: 0.087808, Train Acc: 0.876923 | Val Loss: 0.112298, Val Acc: 0.773196\n",
      "Epoch 16481 - Train Loss: 0.087805, Train Acc: 0.876923 | Val Loss: 0.112296, Val Acc: 0.773196\n",
      "Epoch 16482 - Train Loss: 0.087802, Train Acc: 0.878205 | Val Loss: 0.112294, Val Acc: 0.773196\n",
      "Epoch 16483 - Train Loss: 0.087799, Train Acc: 0.878205 | Val Loss: 0.112292, Val Acc: 0.773196\n",
      "Epoch 16484 - Train Loss: 0.087796, Train Acc: 0.878205 | Val Loss: 0.112290, Val Acc: 0.773196\n",
      "Epoch 16485 - Train Loss: 0.087793, Train Acc: 0.878205 | Val Loss: 0.112288, Val Acc: 0.773196\n",
      "Epoch 16486 - Train Loss: 0.087790, Train Acc: 0.878205 | Val Loss: 0.112287, Val Acc: 0.773196\n",
      "Epoch 16487 - Train Loss: 0.087786, Train Acc: 0.878205 | Val Loss: 0.112285, Val Acc: 0.773196\n",
      "Epoch 16488 - Train Loss: 0.087783, Train Acc: 0.878205 | Val Loss: 0.112283, Val Acc: 0.773196\n",
      "Epoch 16489 - Train Loss: 0.087780, Train Acc: 0.878205 | Val Loss: 0.112281, Val Acc: 0.773196\n",
      "Epoch 16490 - Train Loss: 0.087777, Train Acc: 0.878205 | Val Loss: 0.112279, Val Acc: 0.773196\n",
      "Epoch 16491 - Train Loss: 0.087774, Train Acc: 0.878205 | Val Loss: 0.112277, Val Acc: 0.773196\n",
      "Epoch 16492 - Train Loss: 0.087771, Train Acc: 0.878205 | Val Loss: 0.112275, Val Acc: 0.773196\n",
      "Epoch 16493 - Train Loss: 0.087767, Train Acc: 0.878205 | Val Loss: 0.112273, Val Acc: 0.773196\n",
      "Epoch 16494 - Train Loss: 0.087764, Train Acc: 0.878205 | Val Loss: 0.112272, Val Acc: 0.773196\n",
      "Epoch 16495 - Train Loss: 0.087761, Train Acc: 0.878205 | Val Loss: 0.112270, Val Acc: 0.773196\n",
      "Epoch 16496 - Train Loss: 0.087758, Train Acc: 0.878205 | Val Loss: 0.112268, Val Acc: 0.773196\n",
      "Epoch 16497 - Train Loss: 0.087755, Train Acc: 0.878205 | Val Loss: 0.112266, Val Acc: 0.773196\n",
      "Epoch 16498 - Train Loss: 0.087752, Train Acc: 0.878205 | Val Loss: 0.112264, Val Acc: 0.773196\n",
      "Epoch 16499 - Train Loss: 0.087749, Train Acc: 0.878205 | Val Loss: 0.112262, Val Acc: 0.773196\n",
      "Epoch 16500 - Train Loss: 0.087745, Train Acc: 0.878205 | Val Loss: 0.112260, Val Acc: 0.773196\n",
      "Epoch 16501 - Train Loss: 0.087742, Train Acc: 0.878205 | Val Loss: 0.112258, Val Acc: 0.773196\n",
      "Epoch 16502 - Train Loss: 0.087739, Train Acc: 0.878205 | Val Loss: 0.112256, Val Acc: 0.773196\n",
      "Epoch 16503 - Train Loss: 0.087736, Train Acc: 0.878205 | Val Loss: 0.112255, Val Acc: 0.773196\n",
      "Epoch 16504 - Train Loss: 0.087733, Train Acc: 0.878205 | Val Loss: 0.112253, Val Acc: 0.773196\n",
      "Epoch 16505 - Train Loss: 0.087730, Train Acc: 0.878205 | Val Loss: 0.112251, Val Acc: 0.773196\n",
      "Epoch 16506 - Train Loss: 0.087727, Train Acc: 0.878205 | Val Loss: 0.112249, Val Acc: 0.773196\n",
      "Epoch 16507 - Train Loss: 0.087723, Train Acc: 0.878205 | Val Loss: 0.112247, Val Acc: 0.773196\n",
      "Epoch 16508 - Train Loss: 0.087720, Train Acc: 0.878205 | Val Loss: 0.112245, Val Acc: 0.773196\n",
      "Epoch 16509 - Train Loss: 0.087717, Train Acc: 0.878205 | Val Loss: 0.112243, Val Acc: 0.773196\n",
      "Epoch 16510 - Train Loss: 0.087714, Train Acc: 0.878205 | Val Loss: 0.112241, Val Acc: 0.773196\n",
      "Epoch 16511 - Train Loss: 0.087711, Train Acc: 0.878205 | Val Loss: 0.112240, Val Acc: 0.773196\n",
      "Epoch 16512 - Train Loss: 0.087708, Train Acc: 0.878205 | Val Loss: 0.112238, Val Acc: 0.773196\n",
      "Epoch 16513 - Train Loss: 0.087705, Train Acc: 0.878205 | Val Loss: 0.112236, Val Acc: 0.773196\n",
      "Epoch 16514 - Train Loss: 0.087701, Train Acc: 0.878205 | Val Loss: 0.112234, Val Acc: 0.773196\n",
      "Epoch 16515 - Train Loss: 0.087698, Train Acc: 0.878205 | Val Loss: 0.112232, Val Acc: 0.773196\n",
      "Epoch 16516 - Train Loss: 0.087695, Train Acc: 0.878205 | Val Loss: 0.112230, Val Acc: 0.773196\n",
      "Epoch 16517 - Train Loss: 0.087692, Train Acc: 0.878205 | Val Loss: 0.112228, Val Acc: 0.773196\n",
      "Epoch 16518 - Train Loss: 0.087689, Train Acc: 0.878205 | Val Loss: 0.112227, Val Acc: 0.773196\n",
      "Epoch 16519 - Train Loss: 0.087686, Train Acc: 0.878205 | Val Loss: 0.112225, Val Acc: 0.773196\n",
      "Epoch 16520 - Train Loss: 0.087683, Train Acc: 0.878205 | Val Loss: 0.112223, Val Acc: 0.773196\n",
      "Epoch 16521 - Train Loss: 0.087679, Train Acc: 0.878205 | Val Loss: 0.112221, Val Acc: 0.773196\n",
      "Epoch 16522 - Train Loss: 0.087676, Train Acc: 0.878205 | Val Loss: 0.112219, Val Acc: 0.773196\n",
      "Epoch 16523 - Train Loss: 0.087673, Train Acc: 0.878205 | Val Loss: 0.112217, Val Acc: 0.773196\n",
      "Epoch 16524 - Train Loss: 0.087670, Train Acc: 0.878205 | Val Loss: 0.112215, Val Acc: 0.773196\n",
      "Epoch 16525 - Train Loss: 0.087667, Train Acc: 0.878205 | Val Loss: 0.112213, Val Acc: 0.773196\n",
      "Epoch 16526 - Train Loss: 0.087664, Train Acc: 0.878205 | Val Loss: 0.112212, Val Acc: 0.773196\n",
      "Epoch 16527 - Train Loss: 0.087661, Train Acc: 0.878205 | Val Loss: 0.112210, Val Acc: 0.773196\n",
      "Epoch 16528 - Train Loss: 0.087657, Train Acc: 0.878205 | Val Loss: 0.112208, Val Acc: 0.773196\n",
      "Epoch 16529 - Train Loss: 0.087654, Train Acc: 0.878205 | Val Loss: 0.112206, Val Acc: 0.773196\n",
      "Epoch 16530 - Train Loss: 0.087651, Train Acc: 0.878205 | Val Loss: 0.112204, Val Acc: 0.773196\n",
      "Epoch 16531 - Train Loss: 0.087648, Train Acc: 0.878205 | Val Loss: 0.112202, Val Acc: 0.773196\n",
      "Epoch 16532 - Train Loss: 0.087645, Train Acc: 0.878205 | Val Loss: 0.112200, Val Acc: 0.773196\n",
      "Epoch 16533 - Train Loss: 0.087642, Train Acc: 0.878205 | Val Loss: 0.112199, Val Acc: 0.773196\n",
      "Epoch 16534 - Train Loss: 0.087639, Train Acc: 0.878205 | Val Loss: 0.112197, Val Acc: 0.773196\n",
      "Epoch 16535 - Train Loss: 0.087636, Train Acc: 0.878205 | Val Loss: 0.112195, Val Acc: 0.773196\n",
      "Epoch 16536 - Train Loss: 0.087632, Train Acc: 0.878205 | Val Loss: 0.112193, Val Acc: 0.773196\n",
      "Epoch 16537 - Train Loss: 0.087629, Train Acc: 0.878205 | Val Loss: 0.112191, Val Acc: 0.773196\n",
      "Epoch 16538 - Train Loss: 0.087626, Train Acc: 0.878205 | Val Loss: 0.112189, Val Acc: 0.773196\n",
      "Epoch 16539 - Train Loss: 0.087623, Train Acc: 0.878205 | Val Loss: 0.112187, Val Acc: 0.773196\n",
      "Epoch 16540 - Train Loss: 0.087620, Train Acc: 0.878205 | Val Loss: 0.112186, Val Acc: 0.773196\n",
      "Epoch 16541 - Train Loss: 0.087617, Train Acc: 0.878205 | Val Loss: 0.112184, Val Acc: 0.773196\n",
      "Epoch 16542 - Train Loss: 0.087614, Train Acc: 0.878205 | Val Loss: 0.112182, Val Acc: 0.773196\n",
      "Epoch 16543 - Train Loss: 0.087610, Train Acc: 0.878205 | Val Loss: 0.112180, Val Acc: 0.773196\n",
      "Epoch 16544 - Train Loss: 0.087607, Train Acc: 0.878205 | Val Loss: 0.112178, Val Acc: 0.773196\n",
      "Epoch 16545 - Train Loss: 0.087604, Train Acc: 0.878205 | Val Loss: 0.112176, Val Acc: 0.773196\n",
      "Epoch 16546 - Train Loss: 0.087601, Train Acc: 0.878205 | Val Loss: 0.112174, Val Acc: 0.773196\n",
      "Epoch 16547 - Train Loss: 0.087598, Train Acc: 0.878205 | Val Loss: 0.112173, Val Acc: 0.773196\n",
      "Epoch 16548 - Train Loss: 0.087595, Train Acc: 0.878205 | Val Loss: 0.112171, Val Acc: 0.773196\n",
      "Epoch 16549 - Train Loss: 0.087592, Train Acc: 0.878205 | Val Loss: 0.112169, Val Acc: 0.773196\n",
      "Epoch 16550 - Train Loss: 0.087589, Train Acc: 0.878205 | Val Loss: 0.112167, Val Acc: 0.773196\n",
      "Epoch 16551 - Train Loss: 0.087585, Train Acc: 0.878205 | Val Loss: 0.112165, Val Acc: 0.773196\n",
      "Epoch 16552 - Train Loss: 0.087582, Train Acc: 0.878205 | Val Loss: 0.112163, Val Acc: 0.773196\n",
      "Epoch 16553 - Train Loss: 0.087579, Train Acc: 0.878205 | Val Loss: 0.112161, Val Acc: 0.773196\n",
      "Epoch 16554 - Train Loss: 0.087576, Train Acc: 0.878205 | Val Loss: 0.112159, Val Acc: 0.773196\n",
      "Epoch 16555 - Train Loss: 0.087573, Train Acc: 0.878205 | Val Loss: 0.112158, Val Acc: 0.773196\n",
      "Epoch 16556 - Train Loss: 0.087570, Train Acc: 0.878205 | Val Loss: 0.112156, Val Acc: 0.773196\n",
      "Epoch 16557 - Train Loss: 0.087567, Train Acc: 0.878205 | Val Loss: 0.112154, Val Acc: 0.773196\n",
      "Epoch 16558 - Train Loss: 0.087564, Train Acc: 0.878205 | Val Loss: 0.112152, Val Acc: 0.773196\n",
      "Epoch 16559 - Train Loss: 0.087560, Train Acc: 0.878205 | Val Loss: 0.112150, Val Acc: 0.773196\n",
      "Epoch 16560 - Train Loss: 0.087557, Train Acc: 0.878205 | Val Loss: 0.112148, Val Acc: 0.773196\n",
      "Epoch 16561 - Train Loss: 0.087554, Train Acc: 0.878205 | Val Loss: 0.112147, Val Acc: 0.773196\n",
      "Epoch 16562 - Train Loss: 0.087551, Train Acc: 0.878205 | Val Loss: 0.112145, Val Acc: 0.773196\n",
      "Epoch 16563 - Train Loss: 0.087548, Train Acc: 0.878205 | Val Loss: 0.112143, Val Acc: 0.773196\n",
      "Epoch 16564 - Train Loss: 0.087545, Train Acc: 0.878205 | Val Loss: 0.112141, Val Acc: 0.773196\n",
      "Epoch 16565 - Train Loss: 0.087542, Train Acc: 0.878205 | Val Loss: 0.112139, Val Acc: 0.773196\n",
      "Epoch 16566 - Train Loss: 0.087539, Train Acc: 0.878205 | Val Loss: 0.112137, Val Acc: 0.773196\n",
      "Epoch 16567 - Train Loss: 0.087535, Train Acc: 0.878205 | Val Loss: 0.112135, Val Acc: 0.773196\n",
      "Epoch 16568 - Train Loss: 0.087532, Train Acc: 0.878205 | Val Loss: 0.112134, Val Acc: 0.773196\n",
      "Epoch 16569 - Train Loss: 0.087529, Train Acc: 0.878205 | Val Loss: 0.112132, Val Acc: 0.773196\n",
      "Epoch 16570 - Train Loss: 0.087526, Train Acc: 0.878205 | Val Loss: 0.112130, Val Acc: 0.773196\n",
      "Epoch 16571 - Train Loss: 0.087523, Train Acc: 0.878205 | Val Loss: 0.112128, Val Acc: 0.773196\n",
      "Epoch 16572 - Train Loss: 0.087520, Train Acc: 0.878205 | Val Loss: 0.112126, Val Acc: 0.773196\n",
      "Epoch 16573 - Train Loss: 0.087517, Train Acc: 0.878205 | Val Loss: 0.112124, Val Acc: 0.773196\n",
      "Epoch 16574 - Train Loss: 0.087514, Train Acc: 0.878205 | Val Loss: 0.112122, Val Acc: 0.773196\n",
      "Epoch 16575 - Train Loss: 0.087511, Train Acc: 0.878205 | Val Loss: 0.112121, Val Acc: 0.773196\n",
      "Epoch 16576 - Train Loss: 0.087507, Train Acc: 0.878205 | Val Loss: 0.112119, Val Acc: 0.773196\n",
      "Epoch 16577 - Train Loss: 0.087504, Train Acc: 0.878205 | Val Loss: 0.112117, Val Acc: 0.773196\n",
      "Epoch 16578 - Train Loss: 0.087501, Train Acc: 0.878205 | Val Loss: 0.112115, Val Acc: 0.773196\n",
      "Epoch 16579 - Train Loss: 0.087498, Train Acc: 0.878205 | Val Loss: 0.112113, Val Acc: 0.773196\n",
      "Epoch 16580 - Train Loss: 0.087495, Train Acc: 0.878205 | Val Loss: 0.112111, Val Acc: 0.773196\n",
      "Epoch 16581 - Train Loss: 0.087492, Train Acc: 0.878205 | Val Loss: 0.112110, Val Acc: 0.773196\n",
      "Epoch 16582 - Train Loss: 0.087489, Train Acc: 0.878205 | Val Loss: 0.112108, Val Acc: 0.773196\n",
      "Epoch 16583 - Train Loss: 0.087486, Train Acc: 0.878205 | Val Loss: 0.112106, Val Acc: 0.773196\n",
      "Epoch 16584 - Train Loss: 0.087482, Train Acc: 0.878205 | Val Loss: 0.112104, Val Acc: 0.773196\n",
      "Epoch 16585 - Train Loss: 0.087479, Train Acc: 0.878205 | Val Loss: 0.112102, Val Acc: 0.773196\n",
      "Epoch 16586 - Train Loss: 0.087476, Train Acc: 0.878205 | Val Loss: 0.112100, Val Acc: 0.773196\n",
      "Epoch 16587 - Train Loss: 0.087473, Train Acc: 0.878205 | Val Loss: 0.112098, Val Acc: 0.773196\n",
      "Epoch 16588 - Train Loss: 0.087470, Train Acc: 0.878205 | Val Loss: 0.112097, Val Acc: 0.773196\n",
      "Epoch 16589 - Train Loss: 0.087467, Train Acc: 0.878205 | Val Loss: 0.112095, Val Acc: 0.773196\n",
      "Epoch 16590 - Train Loss: 0.087464, Train Acc: 0.878205 | Val Loss: 0.112093, Val Acc: 0.773196\n",
      "Epoch 16591 - Train Loss: 0.087461, Train Acc: 0.878205 | Val Loss: 0.112091, Val Acc: 0.773196\n",
      "Epoch 16592 - Train Loss: 0.087458, Train Acc: 0.878205 | Val Loss: 0.112089, Val Acc: 0.773196\n",
      "Epoch 16593 - Train Loss: 0.087454, Train Acc: 0.878205 | Val Loss: 0.112087, Val Acc: 0.773196\n",
      "Epoch 16594 - Train Loss: 0.087451, Train Acc: 0.878205 | Val Loss: 0.112086, Val Acc: 0.773196\n",
      "Epoch 16595 - Train Loss: 0.087448, Train Acc: 0.878205 | Val Loss: 0.112084, Val Acc: 0.773196\n",
      "Epoch 16596 - Train Loss: 0.087445, Train Acc: 0.878205 | Val Loss: 0.112082, Val Acc: 0.773196\n",
      "Epoch 16597 - Train Loss: 0.087442, Train Acc: 0.878205 | Val Loss: 0.112080, Val Acc: 0.773196\n",
      "Epoch 16598 - Train Loss: 0.087439, Train Acc: 0.878205 | Val Loss: 0.112078, Val Acc: 0.773196\n",
      "Epoch 16599 - Train Loss: 0.087436, Train Acc: 0.878205 | Val Loss: 0.112076, Val Acc: 0.773196\n",
      "Epoch 16600 - Train Loss: 0.087433, Train Acc: 0.878205 | Val Loss: 0.112075, Val Acc: 0.773196\n",
      "Epoch 16601 - Train Loss: 0.087430, Train Acc: 0.878205 | Val Loss: 0.112073, Val Acc: 0.773196\n",
      "Epoch 16602 - Train Loss: 0.087426, Train Acc: 0.878205 | Val Loss: 0.112071, Val Acc: 0.773196\n",
      "Epoch 16603 - Train Loss: 0.087423, Train Acc: 0.878205 | Val Loss: 0.112069, Val Acc: 0.773196\n",
      "Epoch 16604 - Train Loss: 0.087420, Train Acc: 0.878205 | Val Loss: 0.112067, Val Acc: 0.773196\n",
      "Epoch 16605 - Train Loss: 0.087417, Train Acc: 0.878205 | Val Loss: 0.112065, Val Acc: 0.773196\n",
      "Epoch 16606 - Train Loss: 0.087414, Train Acc: 0.878205 | Val Loss: 0.112063, Val Acc: 0.773196\n",
      "Epoch 16607 - Train Loss: 0.087411, Train Acc: 0.878205 | Val Loss: 0.112062, Val Acc: 0.773196\n",
      "Epoch 16608 - Train Loss: 0.087408, Train Acc: 0.878205 | Val Loss: 0.112060, Val Acc: 0.773196\n",
      "Epoch 16609 - Train Loss: 0.087405, Train Acc: 0.878205 | Val Loss: 0.112058, Val Acc: 0.773196\n",
      "Epoch 16610 - Train Loss: 0.087402, Train Acc: 0.878205 | Val Loss: 0.112056, Val Acc: 0.773196\n",
      "Epoch 16611 - Train Loss: 0.087399, Train Acc: 0.878205 | Val Loss: 0.112054, Val Acc: 0.773196\n",
      "Epoch 16612 - Train Loss: 0.087395, Train Acc: 0.878205 | Val Loss: 0.112053, Val Acc: 0.773196\n",
      "Epoch 16613 - Train Loss: 0.087392, Train Acc: 0.878205 | Val Loss: 0.112051, Val Acc: 0.773196\n",
      "Epoch 16614 - Train Loss: 0.087389, Train Acc: 0.878205 | Val Loss: 0.112049, Val Acc: 0.773196\n",
      "Epoch 16615 - Train Loss: 0.087386, Train Acc: 0.878205 | Val Loss: 0.112047, Val Acc: 0.773196\n",
      "Epoch 16616 - Train Loss: 0.087383, Train Acc: 0.878205 | Val Loss: 0.112045, Val Acc: 0.773196\n",
      "Epoch 16617 - Train Loss: 0.087380, Train Acc: 0.878205 | Val Loss: 0.112043, Val Acc: 0.773196\n",
      "Epoch 16618 - Train Loss: 0.087377, Train Acc: 0.878205 | Val Loss: 0.112041, Val Acc: 0.773196\n",
      "Epoch 16619 - Train Loss: 0.087374, Train Acc: 0.878205 | Val Loss: 0.112040, Val Acc: 0.773196\n",
      "Epoch 16620 - Train Loss: 0.087371, Train Acc: 0.878205 | Val Loss: 0.112038, Val Acc: 0.773196\n",
      "Epoch 16621 - Train Loss: 0.087367, Train Acc: 0.878205 | Val Loss: 0.112036, Val Acc: 0.773196\n",
      "Epoch 16622 - Train Loss: 0.087364, Train Acc: 0.878205 | Val Loss: 0.112034, Val Acc: 0.773196\n",
      "Epoch 16623 - Train Loss: 0.087361, Train Acc: 0.878205 | Val Loss: 0.112032, Val Acc: 0.773196\n",
      "Epoch 16624 - Train Loss: 0.087358, Train Acc: 0.878205 | Val Loss: 0.112031, Val Acc: 0.773196\n",
      "Epoch 16625 - Train Loss: 0.087355, Train Acc: 0.878205 | Val Loss: 0.112029, Val Acc: 0.773196\n",
      "Epoch 16626 - Train Loss: 0.087352, Train Acc: 0.878205 | Val Loss: 0.112027, Val Acc: 0.773196\n",
      "Epoch 16627 - Train Loss: 0.087349, Train Acc: 0.878205 | Val Loss: 0.112025, Val Acc: 0.773196\n",
      "Epoch 16628 - Train Loss: 0.087346, Train Acc: 0.878205 | Val Loss: 0.112023, Val Acc: 0.773196\n",
      "Epoch 16629 - Train Loss: 0.087343, Train Acc: 0.878205 | Val Loss: 0.112021, Val Acc: 0.773196\n",
      "Epoch 16630 - Train Loss: 0.087340, Train Acc: 0.878205 | Val Loss: 0.112020, Val Acc: 0.773196\n",
      "Epoch 16631 - Train Loss: 0.087336, Train Acc: 0.878205 | Val Loss: 0.112018, Val Acc: 0.773196\n",
      "Epoch 16632 - Train Loss: 0.087333, Train Acc: 0.878205 | Val Loss: 0.112016, Val Acc: 0.773196\n",
      "Epoch 16633 - Train Loss: 0.087330, Train Acc: 0.878205 | Val Loss: 0.112014, Val Acc: 0.773196\n",
      "Epoch 16634 - Train Loss: 0.087327, Train Acc: 0.878205 | Val Loss: 0.112012, Val Acc: 0.773196\n",
      "Epoch 16635 - Train Loss: 0.087324, Train Acc: 0.878205 | Val Loss: 0.112010, Val Acc: 0.773196\n",
      "Epoch 16636 - Train Loss: 0.087321, Train Acc: 0.878205 | Val Loss: 0.112009, Val Acc: 0.773196\n",
      "Epoch 16637 - Train Loss: 0.087318, Train Acc: 0.878205 | Val Loss: 0.112007, Val Acc: 0.773196\n",
      "Epoch 16638 - Train Loss: 0.087315, Train Acc: 0.878205 | Val Loss: 0.112005, Val Acc: 0.773196\n",
      "Epoch 16639 - Train Loss: 0.087312, Train Acc: 0.878205 | Val Loss: 0.112003, Val Acc: 0.773196\n",
      "Epoch 16640 - Train Loss: 0.087309, Train Acc: 0.878205 | Val Loss: 0.112001, Val Acc: 0.773196\n",
      "Epoch 16641 - Train Loss: 0.087306, Train Acc: 0.878205 | Val Loss: 0.111999, Val Acc: 0.773196\n",
      "Epoch 16642 - Train Loss: 0.087302, Train Acc: 0.878205 | Val Loss: 0.111998, Val Acc: 0.773196\n",
      "Epoch 16643 - Train Loss: 0.087299, Train Acc: 0.878205 | Val Loss: 0.111996, Val Acc: 0.773196\n",
      "Epoch 16644 - Train Loss: 0.087296, Train Acc: 0.878205 | Val Loss: 0.111994, Val Acc: 0.773196\n",
      "Epoch 16645 - Train Loss: 0.087293, Train Acc: 0.878205 | Val Loss: 0.111992, Val Acc: 0.773196\n",
      "Epoch 16646 - Train Loss: 0.087290, Train Acc: 0.878205 | Val Loss: 0.111990, Val Acc: 0.773196\n",
      "Epoch 16647 - Train Loss: 0.087287, Train Acc: 0.878205 | Val Loss: 0.111989, Val Acc: 0.773196\n",
      "Epoch 16648 - Train Loss: 0.087284, Train Acc: 0.878205 | Val Loss: 0.111987, Val Acc: 0.773196\n",
      "Epoch 16649 - Train Loss: 0.087281, Train Acc: 0.878205 | Val Loss: 0.111985, Val Acc: 0.773196\n",
      "Epoch 16650 - Train Loss: 0.087278, Train Acc: 0.878205 | Val Loss: 0.111983, Val Acc: 0.773196\n",
      "Epoch 16651 - Train Loss: 0.087275, Train Acc: 0.878205 | Val Loss: 0.111981, Val Acc: 0.773196\n",
      "Epoch 16652 - Train Loss: 0.087272, Train Acc: 0.878205 | Val Loss: 0.111979, Val Acc: 0.773196\n",
      "Epoch 16653 - Train Loss: 0.087268, Train Acc: 0.878205 | Val Loss: 0.111978, Val Acc: 0.773196\n",
      "Epoch 16654 - Train Loss: 0.087265, Train Acc: 0.878205 | Val Loss: 0.111976, Val Acc: 0.773196\n",
      "Epoch 16655 - Train Loss: 0.087262, Train Acc: 0.878205 | Val Loss: 0.111974, Val Acc: 0.773196\n",
      "Epoch 16656 - Train Loss: 0.087259, Train Acc: 0.878205 | Val Loss: 0.111972, Val Acc: 0.773196\n",
      "Epoch 16657 - Train Loss: 0.087256, Train Acc: 0.878205 | Val Loss: 0.111970, Val Acc: 0.773196\n",
      "Epoch 16658 - Train Loss: 0.087253, Train Acc: 0.878205 | Val Loss: 0.111969, Val Acc: 0.773196\n",
      "Epoch 16659 - Train Loss: 0.087250, Train Acc: 0.878205 | Val Loss: 0.111967, Val Acc: 0.773196\n",
      "Epoch 16660 - Train Loss: 0.087247, Train Acc: 0.878205 | Val Loss: 0.111965, Val Acc: 0.773196\n",
      "Epoch 16661 - Train Loss: 0.087244, Train Acc: 0.878205 | Val Loss: 0.111963, Val Acc: 0.773196\n",
      "Epoch 16662 - Train Loss: 0.087241, Train Acc: 0.878205 | Val Loss: 0.111961, Val Acc: 0.773196\n",
      "Epoch 16663 - Train Loss: 0.087238, Train Acc: 0.878205 | Val Loss: 0.111959, Val Acc: 0.773196\n",
      "Epoch 16664 - Train Loss: 0.087234, Train Acc: 0.878205 | Val Loss: 0.111958, Val Acc: 0.773196\n",
      "Epoch 16665 - Train Loss: 0.087231, Train Acc: 0.878205 | Val Loss: 0.111956, Val Acc: 0.773196\n",
      "Epoch 16666 - Train Loss: 0.087228, Train Acc: 0.878205 | Val Loss: 0.111954, Val Acc: 0.773196\n",
      "Epoch 16667 - Train Loss: 0.087225, Train Acc: 0.878205 | Val Loss: 0.111952, Val Acc: 0.773196\n",
      "Epoch 16668 - Train Loss: 0.087222, Train Acc: 0.878205 | Val Loss: 0.111950, Val Acc: 0.773196\n",
      "Epoch 16669 - Train Loss: 0.087219, Train Acc: 0.878205 | Val Loss: 0.111949, Val Acc: 0.773196\n",
      "Epoch 16670 - Train Loss: 0.087216, Train Acc: 0.878205 | Val Loss: 0.111947, Val Acc: 0.773196\n",
      "Epoch 16671 - Train Loss: 0.087213, Train Acc: 0.878205 | Val Loss: 0.111945, Val Acc: 0.773196\n",
      "Epoch 16672 - Train Loss: 0.087210, Train Acc: 0.878205 | Val Loss: 0.111943, Val Acc: 0.773196\n",
      "Epoch 16673 - Train Loss: 0.087207, Train Acc: 0.878205 | Val Loss: 0.111941, Val Acc: 0.773196\n",
      "Epoch 16674 - Train Loss: 0.087204, Train Acc: 0.878205 | Val Loss: 0.111940, Val Acc: 0.773196\n",
      "Epoch 16675 - Train Loss: 0.087201, Train Acc: 0.878205 | Val Loss: 0.111938, Val Acc: 0.773196\n",
      "Epoch 16676 - Train Loss: 0.087198, Train Acc: 0.878205 | Val Loss: 0.111936, Val Acc: 0.773196\n",
      "Epoch 16677 - Train Loss: 0.087194, Train Acc: 0.878205 | Val Loss: 0.111934, Val Acc: 0.773196\n",
      "Epoch 16678 - Train Loss: 0.087191, Train Acc: 0.878205 | Val Loss: 0.111932, Val Acc: 0.773196\n",
      "Epoch 16679 - Train Loss: 0.087188, Train Acc: 0.878205 | Val Loss: 0.111931, Val Acc: 0.773196\n",
      "Epoch 16680 - Train Loss: 0.087185, Train Acc: 0.878205 | Val Loss: 0.111929, Val Acc: 0.773196\n",
      "Epoch 16681 - Train Loss: 0.087182, Train Acc: 0.878205 | Val Loss: 0.111927, Val Acc: 0.773196\n",
      "Epoch 16682 - Train Loss: 0.087179, Train Acc: 0.878205 | Val Loss: 0.111925, Val Acc: 0.773196\n",
      "Epoch 16683 - Train Loss: 0.087176, Train Acc: 0.878205 | Val Loss: 0.111923, Val Acc: 0.773196\n",
      "Epoch 16684 - Train Loss: 0.087173, Train Acc: 0.878205 | Val Loss: 0.111921, Val Acc: 0.773196\n",
      "Epoch 16685 - Train Loss: 0.087170, Train Acc: 0.878205 | Val Loss: 0.111920, Val Acc: 0.773196\n",
      "Epoch 16686 - Train Loss: 0.087167, Train Acc: 0.878205 | Val Loss: 0.111918, Val Acc: 0.773196\n",
      "Epoch 16687 - Train Loss: 0.087164, Train Acc: 0.878205 | Val Loss: 0.111916, Val Acc: 0.773196\n",
      "Epoch 16688 - Train Loss: 0.087161, Train Acc: 0.878205 | Val Loss: 0.111914, Val Acc: 0.773196\n",
      "Epoch 16689 - Train Loss: 0.087157, Train Acc: 0.878205 | Val Loss: 0.111912, Val Acc: 0.773196\n",
      "Epoch 16690 - Train Loss: 0.087154, Train Acc: 0.878205 | Val Loss: 0.111911, Val Acc: 0.773196\n",
      "Epoch 16691 - Train Loss: 0.087151, Train Acc: 0.878205 | Val Loss: 0.111909, Val Acc: 0.773196\n",
      "Epoch 16692 - Train Loss: 0.087148, Train Acc: 0.878205 | Val Loss: 0.111907, Val Acc: 0.773196\n",
      "Epoch 16693 - Train Loss: 0.087145, Train Acc: 0.878205 | Val Loss: 0.111905, Val Acc: 0.773196\n",
      "Epoch 16694 - Train Loss: 0.087142, Train Acc: 0.878205 | Val Loss: 0.111903, Val Acc: 0.773196\n",
      "Epoch 16695 - Train Loss: 0.087139, Train Acc: 0.878205 | Val Loss: 0.111902, Val Acc: 0.773196\n",
      "Epoch 16696 - Train Loss: 0.087136, Train Acc: 0.878205 | Val Loss: 0.111900, Val Acc: 0.773196\n",
      "Epoch 16697 - Train Loss: 0.087133, Train Acc: 0.878205 | Val Loss: 0.111898, Val Acc: 0.773196\n",
      "Epoch 16698 - Train Loss: 0.087130, Train Acc: 0.878205 | Val Loss: 0.111896, Val Acc: 0.773196\n",
      "Epoch 16699 - Train Loss: 0.087127, Train Acc: 0.878205 | Val Loss: 0.111894, Val Acc: 0.773196\n",
      "Epoch 16700 - Train Loss: 0.087124, Train Acc: 0.878205 | Val Loss: 0.111893, Val Acc: 0.773196\n",
      "Epoch 16701 - Train Loss: 0.087121, Train Acc: 0.878205 | Val Loss: 0.111891, Val Acc: 0.773196\n",
      "Epoch 16702 - Train Loss: 0.087118, Train Acc: 0.878205 | Val Loss: 0.111889, Val Acc: 0.773196\n",
      "Epoch 16703 - Train Loss: 0.087114, Train Acc: 0.878205 | Val Loss: 0.111887, Val Acc: 0.773196\n",
      "Epoch 16704 - Train Loss: 0.087111, Train Acc: 0.878205 | Val Loss: 0.111885, Val Acc: 0.773196\n",
      "Epoch 16705 - Train Loss: 0.087108, Train Acc: 0.878205 | Val Loss: 0.111884, Val Acc: 0.773196\n",
      "Epoch 16706 - Train Loss: 0.087105, Train Acc: 0.878205 | Val Loss: 0.111882, Val Acc: 0.773196\n",
      "Epoch 16707 - Train Loss: 0.087102, Train Acc: 0.878205 | Val Loss: 0.111880, Val Acc: 0.773196\n",
      "Epoch 16708 - Train Loss: 0.087099, Train Acc: 0.878205 | Val Loss: 0.111878, Val Acc: 0.773196\n",
      "Epoch 16709 - Train Loss: 0.087096, Train Acc: 0.878205 | Val Loss: 0.111876, Val Acc: 0.773196\n",
      "Epoch 16710 - Train Loss: 0.087093, Train Acc: 0.878205 | Val Loss: 0.111875, Val Acc: 0.773196\n",
      "Epoch 16711 - Train Loss: 0.087090, Train Acc: 0.878205 | Val Loss: 0.111873, Val Acc: 0.773196\n",
      "Epoch 16712 - Train Loss: 0.087087, Train Acc: 0.878205 | Val Loss: 0.111871, Val Acc: 0.773196\n",
      "Epoch 16713 - Train Loss: 0.087084, Train Acc: 0.878205 | Val Loss: 0.111869, Val Acc: 0.773196\n",
      "Epoch 16714 - Train Loss: 0.087081, Train Acc: 0.878205 | Val Loss: 0.111867, Val Acc: 0.773196\n",
      "Epoch 16715 - Train Loss: 0.087078, Train Acc: 0.878205 | Val Loss: 0.111866, Val Acc: 0.773196\n",
      "Epoch 16716 - Train Loss: 0.087075, Train Acc: 0.878205 | Val Loss: 0.111864, Val Acc: 0.773196\n",
      "Epoch 16717 - Train Loss: 0.087072, Train Acc: 0.878205 | Val Loss: 0.111862, Val Acc: 0.773196\n",
      "Epoch 16718 - Train Loss: 0.087068, Train Acc: 0.878205 | Val Loss: 0.111860, Val Acc: 0.773196\n",
      "Epoch 16719 - Train Loss: 0.087065, Train Acc: 0.878205 | Val Loss: 0.111858, Val Acc: 0.773196\n",
      "Epoch 16720 - Train Loss: 0.087062, Train Acc: 0.878205 | Val Loss: 0.111857, Val Acc: 0.773196\n",
      "Epoch 16721 - Train Loss: 0.087059, Train Acc: 0.878205 | Val Loss: 0.111855, Val Acc: 0.773196\n",
      "Epoch 16722 - Train Loss: 0.087056, Train Acc: 0.878205 | Val Loss: 0.111853, Val Acc: 0.773196\n",
      "Epoch 16723 - Train Loss: 0.087053, Train Acc: 0.878205 | Val Loss: 0.111851, Val Acc: 0.773196\n",
      "Epoch 16724 - Train Loss: 0.087050, Train Acc: 0.878205 | Val Loss: 0.111850, Val Acc: 0.773196\n",
      "Epoch 16725 - Train Loss: 0.087047, Train Acc: 0.878205 | Val Loss: 0.111848, Val Acc: 0.773196\n",
      "Epoch 16726 - Train Loss: 0.087044, Train Acc: 0.878205 | Val Loss: 0.111846, Val Acc: 0.773196\n",
      "Epoch 16727 - Train Loss: 0.087041, Train Acc: 0.878205 | Val Loss: 0.111844, Val Acc: 0.773196\n",
      "Epoch 16728 - Train Loss: 0.087038, Train Acc: 0.878205 | Val Loss: 0.111842, Val Acc: 0.773196\n",
      "Epoch 16729 - Train Loss: 0.087035, Train Acc: 0.878205 | Val Loss: 0.111841, Val Acc: 0.773196\n",
      "Epoch 16730 - Train Loss: 0.087032, Train Acc: 0.878205 | Val Loss: 0.111839, Val Acc: 0.773196\n",
      "Epoch 16731 - Train Loss: 0.087029, Train Acc: 0.878205 | Val Loss: 0.111837, Val Acc: 0.773196\n",
      "Epoch 16732 - Train Loss: 0.087026, Train Acc: 0.878205 | Val Loss: 0.111835, Val Acc: 0.773196\n",
      "Epoch 16733 - Train Loss: 0.087023, Train Acc: 0.878205 | Val Loss: 0.111833, Val Acc: 0.773196\n",
      "Epoch 16734 - Train Loss: 0.087019, Train Acc: 0.878205 | Val Loss: 0.111832, Val Acc: 0.773196\n",
      "Epoch 16735 - Train Loss: 0.087016, Train Acc: 0.878205 | Val Loss: 0.111830, Val Acc: 0.773196\n",
      "Epoch 16736 - Train Loss: 0.087013, Train Acc: 0.878205 | Val Loss: 0.111828, Val Acc: 0.773196\n",
      "Epoch 16737 - Train Loss: 0.087010, Train Acc: 0.878205 | Val Loss: 0.111826, Val Acc: 0.773196\n",
      "Epoch 16738 - Train Loss: 0.087007, Train Acc: 0.878205 | Val Loss: 0.111824, Val Acc: 0.773196\n",
      "Epoch 16739 - Train Loss: 0.087004, Train Acc: 0.878205 | Val Loss: 0.111823, Val Acc: 0.773196\n",
      "Epoch 16740 - Train Loss: 0.087001, Train Acc: 0.878205 | Val Loss: 0.111821, Val Acc: 0.773196\n",
      "Epoch 16741 - Train Loss: 0.086998, Train Acc: 0.878205 | Val Loss: 0.111819, Val Acc: 0.773196\n",
      "Epoch 16742 - Train Loss: 0.086995, Train Acc: 0.878205 | Val Loss: 0.111817, Val Acc: 0.773196\n",
      "Epoch 16743 - Train Loss: 0.086992, Train Acc: 0.878205 | Val Loss: 0.111816, Val Acc: 0.773196\n",
      "Epoch 16744 - Train Loss: 0.086989, Train Acc: 0.878205 | Val Loss: 0.111814, Val Acc: 0.773196\n",
      "Epoch 16745 - Train Loss: 0.086986, Train Acc: 0.878205 | Val Loss: 0.111812, Val Acc: 0.773196\n",
      "Epoch 16746 - Train Loss: 0.086983, Train Acc: 0.878205 | Val Loss: 0.111810, Val Acc: 0.773196\n",
      "Epoch 16747 - Train Loss: 0.086980, Train Acc: 0.878205 | Val Loss: 0.111808, Val Acc: 0.773196\n",
      "Epoch 16748 - Train Loss: 0.086977, Train Acc: 0.878205 | Val Loss: 0.111807, Val Acc: 0.773196\n",
      "Epoch 16749 - Train Loss: 0.086974, Train Acc: 0.878205 | Val Loss: 0.111805, Val Acc: 0.773196\n",
      "Epoch 16750 - Train Loss: 0.086971, Train Acc: 0.878205 | Val Loss: 0.111803, Val Acc: 0.773196\n",
      "Epoch 16751 - Train Loss: 0.086968, Train Acc: 0.878205 | Val Loss: 0.111801, Val Acc: 0.773196\n",
      "Epoch 16752 - Train Loss: 0.086964, Train Acc: 0.878205 | Val Loss: 0.111799, Val Acc: 0.773196\n",
      "Epoch 16753 - Train Loss: 0.086961, Train Acc: 0.878205 | Val Loss: 0.111798, Val Acc: 0.773196\n",
      "Epoch 16754 - Train Loss: 0.086958, Train Acc: 0.878205 | Val Loss: 0.111796, Val Acc: 0.773196\n",
      "Epoch 16755 - Train Loss: 0.086955, Train Acc: 0.878205 | Val Loss: 0.111794, Val Acc: 0.773196\n",
      "Epoch 16756 - Train Loss: 0.086952, Train Acc: 0.878205 | Val Loss: 0.111792, Val Acc: 0.773196\n",
      "Epoch 16757 - Train Loss: 0.086949, Train Acc: 0.878205 | Val Loss: 0.111791, Val Acc: 0.773196\n",
      "Epoch 16758 - Train Loss: 0.086946, Train Acc: 0.878205 | Val Loss: 0.111789, Val Acc: 0.773196\n",
      "Epoch 16759 - Train Loss: 0.086943, Train Acc: 0.878205 | Val Loss: 0.111787, Val Acc: 0.773196\n",
      "Epoch 16760 - Train Loss: 0.086940, Train Acc: 0.878205 | Val Loss: 0.111785, Val Acc: 0.773196\n",
      "Epoch 16761 - Train Loss: 0.086937, Train Acc: 0.878205 | Val Loss: 0.111783, Val Acc: 0.773196\n",
      "Epoch 16762 - Train Loss: 0.086934, Train Acc: 0.878205 | Val Loss: 0.111782, Val Acc: 0.773196\n",
      "Epoch 16763 - Train Loss: 0.086931, Train Acc: 0.878205 | Val Loss: 0.111780, Val Acc: 0.773196\n",
      "Epoch 16764 - Train Loss: 0.086928, Train Acc: 0.878205 | Val Loss: 0.111778, Val Acc: 0.773196\n",
      "Epoch 16765 - Train Loss: 0.086925, Train Acc: 0.878205 | Val Loss: 0.111776, Val Acc: 0.773196\n",
      "Epoch 16766 - Train Loss: 0.086922, Train Acc: 0.878205 | Val Loss: 0.111775, Val Acc: 0.773196\n",
      "Epoch 16767 - Train Loss: 0.086919, Train Acc: 0.878205 | Val Loss: 0.111773, Val Acc: 0.773196\n",
      "Epoch 16768 - Train Loss: 0.086916, Train Acc: 0.878205 | Val Loss: 0.111771, Val Acc: 0.773196\n",
      "Epoch 16769 - Train Loss: 0.086913, Train Acc: 0.878205 | Val Loss: 0.111769, Val Acc: 0.773196\n",
      "Epoch 16770 - Train Loss: 0.086910, Train Acc: 0.878205 | Val Loss: 0.111767, Val Acc: 0.773196\n",
      "Epoch 16771 - Train Loss: 0.086907, Train Acc: 0.878205 | Val Loss: 0.111766, Val Acc: 0.773196\n",
      "Epoch 16772 - Train Loss: 0.086903, Train Acc: 0.878205 | Val Loss: 0.111764, Val Acc: 0.773196\n",
      "Epoch 16773 - Train Loss: 0.086900, Train Acc: 0.878205 | Val Loss: 0.111762, Val Acc: 0.773196\n",
      "Epoch 16774 - Train Loss: 0.086897, Train Acc: 0.878205 | Val Loss: 0.111760, Val Acc: 0.773196\n",
      "Epoch 16775 - Train Loss: 0.086894, Train Acc: 0.878205 | Val Loss: 0.111759, Val Acc: 0.773196\n",
      "Epoch 16776 - Train Loss: 0.086891, Train Acc: 0.878205 | Val Loss: 0.111757, Val Acc: 0.773196\n",
      "Epoch 16777 - Train Loss: 0.086888, Train Acc: 0.878205 | Val Loss: 0.111755, Val Acc: 0.773196\n",
      "Epoch 16778 - Train Loss: 0.086885, Train Acc: 0.878205 | Val Loss: 0.111753, Val Acc: 0.773196\n",
      "Epoch 16779 - Train Loss: 0.086882, Train Acc: 0.878205 | Val Loss: 0.111752, Val Acc: 0.773196\n",
      "Epoch 16780 - Train Loss: 0.086879, Train Acc: 0.878205 | Val Loss: 0.111750, Val Acc: 0.773196\n",
      "Epoch 16781 - Train Loss: 0.086876, Train Acc: 0.878205 | Val Loss: 0.111748, Val Acc: 0.773196\n",
      "Epoch 16782 - Train Loss: 0.086873, Train Acc: 0.878205 | Val Loss: 0.111746, Val Acc: 0.773196\n",
      "Epoch 16783 - Train Loss: 0.086870, Train Acc: 0.878205 | Val Loss: 0.111744, Val Acc: 0.773196\n",
      "Epoch 16784 - Train Loss: 0.086867, Train Acc: 0.878205 | Val Loss: 0.111743, Val Acc: 0.773196\n",
      "Epoch 16785 - Train Loss: 0.086864, Train Acc: 0.878205 | Val Loss: 0.111741, Val Acc: 0.773196\n",
      "Epoch 16786 - Train Loss: 0.086861, Train Acc: 0.878205 | Val Loss: 0.111739, Val Acc: 0.773196\n",
      "Epoch 16787 - Train Loss: 0.086858, Train Acc: 0.878205 | Val Loss: 0.111737, Val Acc: 0.773196\n",
      "Epoch 16788 - Train Loss: 0.086855, Train Acc: 0.878205 | Val Loss: 0.111736, Val Acc: 0.773196\n",
      "Epoch 16789 - Train Loss: 0.086852, Train Acc: 0.878205 | Val Loss: 0.111734, Val Acc: 0.773196\n",
      "Epoch 16790 - Train Loss: 0.086849, Train Acc: 0.878205 | Val Loss: 0.111732, Val Acc: 0.773196\n",
      "Epoch 16791 - Train Loss: 0.086846, Train Acc: 0.878205 | Val Loss: 0.111730, Val Acc: 0.773196\n",
      "Epoch 16792 - Train Loss: 0.086843, Train Acc: 0.878205 | Val Loss: 0.111729, Val Acc: 0.773196\n",
      "Epoch 16793 - Train Loss: 0.086840, Train Acc: 0.878205 | Val Loss: 0.111727, Val Acc: 0.773196\n",
      "Epoch 16794 - Train Loss: 0.086837, Train Acc: 0.878205 | Val Loss: 0.111725, Val Acc: 0.773196\n",
      "Epoch 16795 - Train Loss: 0.086834, Train Acc: 0.878205 | Val Loss: 0.111723, Val Acc: 0.773196\n",
      "Epoch 16796 - Train Loss: 0.086830, Train Acc: 0.878205 | Val Loss: 0.111721, Val Acc: 0.773196\n",
      "Epoch 16797 - Train Loss: 0.086827, Train Acc: 0.878205 | Val Loss: 0.111720, Val Acc: 0.773196\n",
      "Epoch 16798 - Train Loss: 0.086824, Train Acc: 0.878205 | Val Loss: 0.111718, Val Acc: 0.773196\n",
      "Epoch 16799 - Train Loss: 0.086821, Train Acc: 0.878205 | Val Loss: 0.111716, Val Acc: 0.773196\n",
      "Epoch 16800 - Train Loss: 0.086818, Train Acc: 0.878205 | Val Loss: 0.111714, Val Acc: 0.773196\n",
      "Epoch 16801 - Train Loss: 0.086815, Train Acc: 0.878205 | Val Loss: 0.111713, Val Acc: 0.773196\n",
      "Epoch 16802 - Train Loss: 0.086812, Train Acc: 0.878205 | Val Loss: 0.111711, Val Acc: 0.773196\n",
      "Epoch 16803 - Train Loss: 0.086809, Train Acc: 0.878205 | Val Loss: 0.111709, Val Acc: 0.773196\n",
      "Epoch 16804 - Train Loss: 0.086806, Train Acc: 0.878205 | Val Loss: 0.111707, Val Acc: 0.773196\n",
      "Epoch 16805 - Train Loss: 0.086803, Train Acc: 0.878205 | Val Loss: 0.111706, Val Acc: 0.773196\n",
      "Epoch 16806 - Train Loss: 0.086800, Train Acc: 0.878205 | Val Loss: 0.111704, Val Acc: 0.773196\n",
      "Epoch 16807 - Train Loss: 0.086797, Train Acc: 0.878205 | Val Loss: 0.111702, Val Acc: 0.773196\n",
      "Epoch 16808 - Train Loss: 0.086794, Train Acc: 0.878205 | Val Loss: 0.111700, Val Acc: 0.773196\n",
      "Epoch 16809 - Train Loss: 0.086791, Train Acc: 0.878205 | Val Loss: 0.111699, Val Acc: 0.773196\n",
      "Epoch 16810 - Train Loss: 0.086788, Train Acc: 0.878205 | Val Loss: 0.111697, Val Acc: 0.773196\n",
      "Epoch 16811 - Train Loss: 0.086785, Train Acc: 0.878205 | Val Loss: 0.111695, Val Acc: 0.773196\n",
      "Epoch 16812 - Train Loss: 0.086782, Train Acc: 0.878205 | Val Loss: 0.111693, Val Acc: 0.773196\n",
      "Epoch 16813 - Train Loss: 0.086779, Train Acc: 0.878205 | Val Loss: 0.111691, Val Acc: 0.773196\n",
      "Epoch 16814 - Train Loss: 0.086776, Train Acc: 0.878205 | Val Loss: 0.111690, Val Acc: 0.773196\n",
      "Epoch 16815 - Train Loss: 0.086773, Train Acc: 0.878205 | Val Loss: 0.111688, Val Acc: 0.773196\n",
      "Epoch 16816 - Train Loss: 0.086770, Train Acc: 0.878205 | Val Loss: 0.111686, Val Acc: 0.773196\n",
      "Epoch 16817 - Train Loss: 0.086767, Train Acc: 0.878205 | Val Loss: 0.111684, Val Acc: 0.773196\n",
      "Epoch 16818 - Train Loss: 0.086764, Train Acc: 0.878205 | Val Loss: 0.111683, Val Acc: 0.773196\n",
      "Epoch 16819 - Train Loss: 0.086761, Train Acc: 0.878205 | Val Loss: 0.111681, Val Acc: 0.773196\n",
      "Epoch 16820 - Train Loss: 0.086758, Train Acc: 0.878205 | Val Loss: 0.111679, Val Acc: 0.773196\n",
      "Epoch 16821 - Train Loss: 0.086755, Train Acc: 0.878205 | Val Loss: 0.111677, Val Acc: 0.773196\n",
      "Epoch 16822 - Train Loss: 0.086752, Train Acc: 0.878205 | Val Loss: 0.111676, Val Acc: 0.773196\n",
      "Epoch 16823 - Train Loss: 0.086749, Train Acc: 0.878205 | Val Loss: 0.111674, Val Acc: 0.773196\n",
      "Epoch 16824 - Train Loss: 0.086746, Train Acc: 0.878205 | Val Loss: 0.111672, Val Acc: 0.773196\n",
      "Epoch 16825 - Train Loss: 0.086743, Train Acc: 0.878205 | Val Loss: 0.111670, Val Acc: 0.773196\n",
      "Epoch 16826 - Train Loss: 0.086740, Train Acc: 0.878205 | Val Loss: 0.111669, Val Acc: 0.773196\n",
      "Epoch 16827 - Train Loss: 0.086737, Train Acc: 0.878205 | Val Loss: 0.111667, Val Acc: 0.773196\n",
      "Epoch 16828 - Train Loss: 0.086734, Train Acc: 0.878205 | Val Loss: 0.111665, Val Acc: 0.773196\n",
      "Epoch 16829 - Train Loss: 0.086730, Train Acc: 0.878205 | Val Loss: 0.111663, Val Acc: 0.773196\n",
      "Epoch 16830 - Train Loss: 0.086727, Train Acc: 0.878205 | Val Loss: 0.111662, Val Acc: 0.773196\n",
      "Epoch 16831 - Train Loss: 0.086724, Train Acc: 0.878205 | Val Loss: 0.111660, Val Acc: 0.773196\n",
      "Epoch 16832 - Train Loss: 0.086721, Train Acc: 0.878205 | Val Loss: 0.111658, Val Acc: 0.773196\n",
      "Epoch 16833 - Train Loss: 0.086718, Train Acc: 0.878205 | Val Loss: 0.111656, Val Acc: 0.773196\n",
      "Epoch 16834 - Train Loss: 0.086715, Train Acc: 0.878205 | Val Loss: 0.111655, Val Acc: 0.773196\n",
      "Epoch 16835 - Train Loss: 0.086712, Train Acc: 0.878205 | Val Loss: 0.111653, Val Acc: 0.773196\n",
      "Epoch 16836 - Train Loss: 0.086709, Train Acc: 0.878205 | Val Loss: 0.111651, Val Acc: 0.773196\n",
      "Epoch 16837 - Train Loss: 0.086706, Train Acc: 0.878205 | Val Loss: 0.111649, Val Acc: 0.773196\n",
      "Epoch 16838 - Train Loss: 0.086703, Train Acc: 0.878205 | Val Loss: 0.111648, Val Acc: 0.773196\n",
      "Epoch 16839 - Train Loss: 0.086700, Train Acc: 0.878205 | Val Loss: 0.111646, Val Acc: 0.773196\n",
      "Epoch 16840 - Train Loss: 0.086697, Train Acc: 0.878205 | Val Loss: 0.111644, Val Acc: 0.773196\n",
      "Epoch 16841 - Train Loss: 0.086694, Train Acc: 0.878205 | Val Loss: 0.111642, Val Acc: 0.773196\n",
      "Epoch 16842 - Train Loss: 0.086691, Train Acc: 0.878205 | Val Loss: 0.111641, Val Acc: 0.773196\n",
      "Epoch 16843 - Train Loss: 0.086688, Train Acc: 0.878205 | Val Loss: 0.111639, Val Acc: 0.773196\n",
      "Epoch 16844 - Train Loss: 0.086685, Train Acc: 0.878205 | Val Loss: 0.111637, Val Acc: 0.773196\n",
      "Epoch 16845 - Train Loss: 0.086682, Train Acc: 0.878205 | Val Loss: 0.111635, Val Acc: 0.773196\n",
      "Epoch 16846 - Train Loss: 0.086679, Train Acc: 0.878205 | Val Loss: 0.111634, Val Acc: 0.773196\n",
      "Epoch 16847 - Train Loss: 0.086676, Train Acc: 0.878205 | Val Loss: 0.111632, Val Acc: 0.773196\n",
      "Epoch 16848 - Train Loss: 0.086673, Train Acc: 0.878205 | Val Loss: 0.111630, Val Acc: 0.773196\n",
      "Epoch 16849 - Train Loss: 0.086670, Train Acc: 0.878205 | Val Loss: 0.111628, Val Acc: 0.773196\n",
      "Epoch 16850 - Train Loss: 0.086667, Train Acc: 0.878205 | Val Loss: 0.111627, Val Acc: 0.773196\n",
      "Epoch 16851 - Train Loss: 0.086664, Train Acc: 0.878205 | Val Loss: 0.111625, Val Acc: 0.773196\n",
      "Epoch 16852 - Train Loss: 0.086661, Train Acc: 0.878205 | Val Loss: 0.111623, Val Acc: 0.773196\n",
      "Epoch 16853 - Train Loss: 0.086658, Train Acc: 0.878205 | Val Loss: 0.111621, Val Acc: 0.773196\n",
      "Epoch 16854 - Train Loss: 0.086655, Train Acc: 0.878205 | Val Loss: 0.111620, Val Acc: 0.773196\n",
      "Epoch 16855 - Train Loss: 0.086652, Train Acc: 0.878205 | Val Loss: 0.111618, Val Acc: 0.773196\n",
      "Epoch 16856 - Train Loss: 0.086649, Train Acc: 0.878205 | Val Loss: 0.111616, Val Acc: 0.773196\n",
      "Epoch 16857 - Train Loss: 0.086646, Train Acc: 0.878205 | Val Loss: 0.111614, Val Acc: 0.773196\n",
      "Epoch 16858 - Train Loss: 0.086643, Train Acc: 0.878205 | Val Loss: 0.111613, Val Acc: 0.773196\n",
      "Epoch 16859 - Train Loss: 0.086640, Train Acc: 0.878205 | Val Loss: 0.111611, Val Acc: 0.773196\n",
      "Epoch 16860 - Train Loss: 0.086637, Train Acc: 0.878205 | Val Loss: 0.111609, Val Acc: 0.773196\n",
      "Epoch 16861 - Train Loss: 0.086634, Train Acc: 0.878205 | Val Loss: 0.111607, Val Acc: 0.773196\n",
      "Epoch 16862 - Train Loss: 0.086631, Train Acc: 0.878205 | Val Loss: 0.111606, Val Acc: 0.773196\n",
      "Epoch 16863 - Train Loss: 0.086628, Train Acc: 0.878205 | Val Loss: 0.111604, Val Acc: 0.773196\n",
      "Epoch 16864 - Train Loss: 0.086625, Train Acc: 0.878205 | Val Loss: 0.111602, Val Acc: 0.773196\n",
      "Epoch 16865 - Train Loss: 0.086622, Train Acc: 0.878205 | Val Loss: 0.111600, Val Acc: 0.773196\n",
      "Epoch 16866 - Train Loss: 0.086619, Train Acc: 0.878205 | Val Loss: 0.111599, Val Acc: 0.773196\n",
      "Epoch 16867 - Train Loss: 0.086616, Train Acc: 0.878205 | Val Loss: 0.111597, Val Acc: 0.773196\n",
      "Epoch 16868 - Train Loss: 0.086613, Train Acc: 0.878205 | Val Loss: 0.111595, Val Acc: 0.773196\n",
      "Epoch 16869 - Train Loss: 0.086610, Train Acc: 0.878205 | Val Loss: 0.111593, Val Acc: 0.773196\n",
      "Epoch 16870 - Train Loss: 0.086607, Train Acc: 0.878205 | Val Loss: 0.111592, Val Acc: 0.773196\n",
      "Epoch 16871 - Train Loss: 0.086604, Train Acc: 0.878205 | Val Loss: 0.111590, Val Acc: 0.773196\n",
      "Epoch 16872 - Train Loss: 0.086601, Train Acc: 0.878205 | Val Loss: 0.111588, Val Acc: 0.773196\n",
      "Epoch 16873 - Train Loss: 0.086598, Train Acc: 0.878205 | Val Loss: 0.111586, Val Acc: 0.773196\n",
      "Epoch 16874 - Train Loss: 0.086595, Train Acc: 0.878205 | Val Loss: 0.111585, Val Acc: 0.773196\n",
      "Epoch 16875 - Train Loss: 0.086592, Train Acc: 0.878205 | Val Loss: 0.111583, Val Acc: 0.773196\n",
      "Epoch 16876 - Train Loss: 0.086589, Train Acc: 0.878205 | Val Loss: 0.111581, Val Acc: 0.773196\n",
      "Epoch 16877 - Train Loss: 0.086586, Train Acc: 0.878205 | Val Loss: 0.111580, Val Acc: 0.773196\n",
      "Epoch 16878 - Train Loss: 0.086583, Train Acc: 0.878205 | Val Loss: 0.111578, Val Acc: 0.773196\n",
      "Epoch 16879 - Train Loss: 0.086580, Train Acc: 0.878205 | Val Loss: 0.111576, Val Acc: 0.773196\n",
      "Epoch 16880 - Train Loss: 0.086577, Train Acc: 0.878205 | Val Loss: 0.111574, Val Acc: 0.773196\n",
      "Epoch 16881 - Train Loss: 0.086574, Train Acc: 0.878205 | Val Loss: 0.111573, Val Acc: 0.773196\n",
      "Epoch 16882 - Train Loss: 0.086571, Train Acc: 0.878205 | Val Loss: 0.111571, Val Acc: 0.773196\n",
      "Epoch 16883 - Train Loss: 0.086568, Train Acc: 0.878205 | Val Loss: 0.111569, Val Acc: 0.773196\n",
      "Epoch 16884 - Train Loss: 0.086565, Train Acc: 0.878205 | Val Loss: 0.111567, Val Acc: 0.773196\n",
      "Epoch 16885 - Train Loss: 0.086562, Train Acc: 0.878205 | Val Loss: 0.111566, Val Acc: 0.773196\n",
      "Epoch 16886 - Train Loss: 0.086559, Train Acc: 0.878205 | Val Loss: 0.111564, Val Acc: 0.773196\n",
      "Epoch 16887 - Train Loss: 0.086556, Train Acc: 0.878205 | Val Loss: 0.111562, Val Acc: 0.773196\n",
      "Epoch 16888 - Train Loss: 0.086553, Train Acc: 0.878205 | Val Loss: 0.111561, Val Acc: 0.773196\n",
      "Epoch 16889 - Train Loss: 0.086550, Train Acc: 0.878205 | Val Loss: 0.111559, Val Acc: 0.773196\n",
      "Epoch 16890 - Train Loss: 0.086547, Train Acc: 0.878205 | Val Loss: 0.111557, Val Acc: 0.773196\n",
      "Epoch 16891 - Train Loss: 0.086544, Train Acc: 0.878205 | Val Loss: 0.111555, Val Acc: 0.773196\n",
      "Epoch 16892 - Train Loss: 0.086541, Train Acc: 0.878205 | Val Loss: 0.111554, Val Acc: 0.773196\n",
      "Epoch 16893 - Train Loss: 0.086538, Train Acc: 0.878205 | Val Loss: 0.111552, Val Acc: 0.773196\n",
      "Epoch 16894 - Train Loss: 0.086535, Train Acc: 0.878205 | Val Loss: 0.111550, Val Acc: 0.773196\n",
      "Epoch 16895 - Train Loss: 0.086532, Train Acc: 0.878205 | Val Loss: 0.111548, Val Acc: 0.773196\n",
      "Epoch 16896 - Train Loss: 0.086529, Train Acc: 0.878205 | Val Loss: 0.111547, Val Acc: 0.773196\n",
      "Epoch 16897 - Train Loss: 0.086526, Train Acc: 0.878205 | Val Loss: 0.111545, Val Acc: 0.773196\n",
      "Epoch 16898 - Train Loss: 0.086523, Train Acc: 0.878205 | Val Loss: 0.111543, Val Acc: 0.773196\n",
      "Epoch 16899 - Train Loss: 0.086520, Train Acc: 0.878205 | Val Loss: 0.111541, Val Acc: 0.773196\n",
      "Epoch 16900 - Train Loss: 0.086517, Train Acc: 0.878205 | Val Loss: 0.111540, Val Acc: 0.773196\n",
      "Epoch 16901 - Train Loss: 0.086514, Train Acc: 0.878205 | Val Loss: 0.111538, Val Acc: 0.773196\n",
      "Epoch 16902 - Train Loss: 0.086511, Train Acc: 0.878205 | Val Loss: 0.111536, Val Acc: 0.773196\n",
      "Epoch 16903 - Train Loss: 0.086508, Train Acc: 0.878205 | Val Loss: 0.111535, Val Acc: 0.773196\n",
      "Epoch 16904 - Train Loss: 0.086505, Train Acc: 0.878205 | Val Loss: 0.111533, Val Acc: 0.773196\n",
      "Epoch 16905 - Train Loss: 0.086502, Train Acc: 0.878205 | Val Loss: 0.111531, Val Acc: 0.773196\n",
      "Epoch 16906 - Train Loss: 0.086499, Train Acc: 0.878205 | Val Loss: 0.111529, Val Acc: 0.773196\n",
      "Epoch 16907 - Train Loss: 0.086496, Train Acc: 0.878205 | Val Loss: 0.111528, Val Acc: 0.773196\n",
      "Epoch 16908 - Train Loss: 0.086493, Train Acc: 0.878205 | Val Loss: 0.111526, Val Acc: 0.773196\n",
      "Epoch 16909 - Train Loss: 0.086490, Train Acc: 0.878205 | Val Loss: 0.111524, Val Acc: 0.773196\n",
      "Epoch 16910 - Train Loss: 0.086487, Train Acc: 0.878205 | Val Loss: 0.111523, Val Acc: 0.773196\n",
      "Epoch 16911 - Train Loss: 0.086484, Train Acc: 0.878205 | Val Loss: 0.111521, Val Acc: 0.773196\n",
      "Epoch 16912 - Train Loss: 0.086481, Train Acc: 0.878205 | Val Loss: 0.111519, Val Acc: 0.773196\n",
      "Epoch 16913 - Train Loss: 0.086478, Train Acc: 0.878205 | Val Loss: 0.111517, Val Acc: 0.773196\n",
      "Epoch 16914 - Train Loss: 0.086475, Train Acc: 0.878205 | Val Loss: 0.111516, Val Acc: 0.773196\n",
      "Epoch 16915 - Train Loss: 0.086472, Train Acc: 0.878205 | Val Loss: 0.111514, Val Acc: 0.773196\n",
      "Epoch 16916 - Train Loss: 0.086469, Train Acc: 0.878205 | Val Loss: 0.111512, Val Acc: 0.773196\n",
      "Epoch 16917 - Train Loss: 0.086466, Train Acc: 0.878205 | Val Loss: 0.111510, Val Acc: 0.773196\n",
      "Epoch 16918 - Train Loss: 0.086463, Train Acc: 0.878205 | Val Loss: 0.111509, Val Acc: 0.773196\n",
      "Epoch 16919 - Train Loss: 0.086460, Train Acc: 0.878205 | Val Loss: 0.111507, Val Acc: 0.773196\n",
      "Epoch 16920 - Train Loss: 0.086457, Train Acc: 0.878205 | Val Loss: 0.111505, Val Acc: 0.773196\n",
      "Epoch 16921 - Train Loss: 0.086454, Train Acc: 0.878205 | Val Loss: 0.111504, Val Acc: 0.773196\n",
      "Epoch 16922 - Train Loss: 0.086451, Train Acc: 0.878205 | Val Loss: 0.111502, Val Acc: 0.773196\n",
      "Epoch 16923 - Train Loss: 0.086448, Train Acc: 0.878205 | Val Loss: 0.111500, Val Acc: 0.773196\n",
      "Epoch 16924 - Train Loss: 0.086445, Train Acc: 0.878205 | Val Loss: 0.111498, Val Acc: 0.773196\n",
      "Epoch 16925 - Train Loss: 0.086442, Train Acc: 0.878205 | Val Loss: 0.111497, Val Acc: 0.773196\n",
      "Epoch 16926 - Train Loss: 0.086439, Train Acc: 0.878205 | Val Loss: 0.111495, Val Acc: 0.773196\n",
      "Epoch 16927 - Train Loss: 0.086436, Train Acc: 0.878205 | Val Loss: 0.111493, Val Acc: 0.773196\n",
      "Epoch 16928 - Train Loss: 0.086433, Train Acc: 0.878205 | Val Loss: 0.111492, Val Acc: 0.773196\n",
      "Epoch 16929 - Train Loss: 0.086430, Train Acc: 0.878205 | Val Loss: 0.111490, Val Acc: 0.773196\n",
      "Epoch 16930 - Train Loss: 0.086427, Train Acc: 0.878205 | Val Loss: 0.111488, Val Acc: 0.773196\n",
      "Epoch 16931 - Train Loss: 0.086424, Train Acc: 0.878205 | Val Loss: 0.111486, Val Acc: 0.773196\n",
      "Epoch 16932 - Train Loss: 0.086421, Train Acc: 0.878205 | Val Loss: 0.111485, Val Acc: 0.773196\n",
      "Epoch 16933 - Train Loss: 0.086418, Train Acc: 0.878205 | Val Loss: 0.111483, Val Acc: 0.773196\n",
      "Epoch 16934 - Train Loss: 0.086415, Train Acc: 0.878205 | Val Loss: 0.111481, Val Acc: 0.773196\n",
      "Epoch 16935 - Train Loss: 0.086412, Train Acc: 0.878205 | Val Loss: 0.111480, Val Acc: 0.773196\n",
      "Epoch 16936 - Train Loss: 0.086409, Train Acc: 0.878205 | Val Loss: 0.111478, Val Acc: 0.773196\n",
      "Epoch 16937 - Train Loss: 0.086406, Train Acc: 0.878205 | Val Loss: 0.111476, Val Acc: 0.773196\n",
      "Epoch 16938 - Train Loss: 0.086403, Train Acc: 0.878205 | Val Loss: 0.111475, Val Acc: 0.773196\n",
      "Epoch 16939 - Train Loss: 0.086400, Train Acc: 0.878205 | Val Loss: 0.111473, Val Acc: 0.773196\n",
      "Epoch 16940 - Train Loss: 0.086397, Train Acc: 0.878205 | Val Loss: 0.111471, Val Acc: 0.773196\n",
      "Epoch 16941 - Train Loss: 0.086394, Train Acc: 0.878205 | Val Loss: 0.111469, Val Acc: 0.773196\n",
      "Epoch 16942 - Train Loss: 0.086391, Train Acc: 0.878205 | Val Loss: 0.111468, Val Acc: 0.773196\n",
      "Epoch 16943 - Train Loss: 0.086388, Train Acc: 0.878205 | Val Loss: 0.111466, Val Acc: 0.773196\n",
      "Epoch 16944 - Train Loss: 0.086385, Train Acc: 0.878205 | Val Loss: 0.111464, Val Acc: 0.773196\n",
      "Epoch 16945 - Train Loss: 0.086382, Train Acc: 0.878205 | Val Loss: 0.111463, Val Acc: 0.773196\n",
      "Epoch 16946 - Train Loss: 0.086379, Train Acc: 0.878205 | Val Loss: 0.111461, Val Acc: 0.773196\n",
      "Epoch 16947 - Train Loss: 0.086376, Train Acc: 0.878205 | Val Loss: 0.111459, Val Acc: 0.773196\n",
      "Epoch 16948 - Train Loss: 0.086373, Train Acc: 0.878205 | Val Loss: 0.111457, Val Acc: 0.773196\n",
      "Epoch 16949 - Train Loss: 0.086370, Train Acc: 0.878205 | Val Loss: 0.111456, Val Acc: 0.773196\n",
      "Epoch 16950 - Train Loss: 0.086367, Train Acc: 0.878205 | Val Loss: 0.111454, Val Acc: 0.773196\n",
      "Epoch 16951 - Train Loss: 0.086364, Train Acc: 0.878205 | Val Loss: 0.111452, Val Acc: 0.773196\n",
      "Epoch 16952 - Train Loss: 0.086361, Train Acc: 0.878205 | Val Loss: 0.111451, Val Acc: 0.773196\n",
      "Epoch 16953 - Train Loss: 0.086358, Train Acc: 0.878205 | Val Loss: 0.111449, Val Acc: 0.773196\n",
      "Epoch 16954 - Train Loss: 0.086355, Train Acc: 0.878205 | Val Loss: 0.111447, Val Acc: 0.773196\n",
      "Epoch 16955 - Train Loss: 0.086352, Train Acc: 0.878205 | Val Loss: 0.111445, Val Acc: 0.773196\n",
      "Epoch 16956 - Train Loss: 0.086349, Train Acc: 0.878205 | Val Loss: 0.111444, Val Acc: 0.773196\n",
      "Epoch 16957 - Train Loss: 0.086346, Train Acc: 0.878205 | Val Loss: 0.111442, Val Acc: 0.773196\n",
      "Epoch 16958 - Train Loss: 0.086343, Train Acc: 0.878205 | Val Loss: 0.111440, Val Acc: 0.773196\n",
      "Epoch 16959 - Train Loss: 0.086340, Train Acc: 0.878205 | Val Loss: 0.111439, Val Acc: 0.773196\n",
      "Epoch 16960 - Train Loss: 0.086337, Train Acc: 0.878205 | Val Loss: 0.111437, Val Acc: 0.773196\n",
      "Epoch 16961 - Train Loss: 0.086334, Train Acc: 0.878205 | Val Loss: 0.111435, Val Acc: 0.773196\n",
      "Epoch 16962 - Train Loss: 0.086331, Train Acc: 0.878205 | Val Loss: 0.111434, Val Acc: 0.773196\n",
      "Epoch 16963 - Train Loss: 0.086328, Train Acc: 0.878205 | Val Loss: 0.111432, Val Acc: 0.773196\n",
      "Epoch 16964 - Train Loss: 0.086325, Train Acc: 0.878205 | Val Loss: 0.111430, Val Acc: 0.773196\n",
      "Epoch 16965 - Train Loss: 0.086322, Train Acc: 0.878205 | Val Loss: 0.111428, Val Acc: 0.773196\n",
      "Epoch 16966 - Train Loss: 0.086319, Train Acc: 0.878205 | Val Loss: 0.111427, Val Acc: 0.773196\n",
      "Epoch 16967 - Train Loss: 0.086316, Train Acc: 0.878205 | Val Loss: 0.111425, Val Acc: 0.773196\n",
      "Epoch 16968 - Train Loss: 0.086313, Train Acc: 0.878205 | Val Loss: 0.111423, Val Acc: 0.773196\n",
      "Epoch 16969 - Train Loss: 0.086311, Train Acc: 0.878205 | Val Loss: 0.111422, Val Acc: 0.773196\n",
      "Epoch 16970 - Train Loss: 0.086308, Train Acc: 0.878205 | Val Loss: 0.111420, Val Acc: 0.773196\n",
      "Epoch 16971 - Train Loss: 0.086305, Train Acc: 0.878205 | Val Loss: 0.111418, Val Acc: 0.773196\n",
      "Epoch 16972 - Train Loss: 0.086302, Train Acc: 0.878205 | Val Loss: 0.111416, Val Acc: 0.773196\n",
      "Epoch 16973 - Train Loss: 0.086299, Train Acc: 0.878205 | Val Loss: 0.111415, Val Acc: 0.773196\n",
      "Epoch 16974 - Train Loss: 0.086296, Train Acc: 0.878205 | Val Loss: 0.111413, Val Acc: 0.773196\n",
      "Epoch 16975 - Train Loss: 0.086293, Train Acc: 0.878205 | Val Loss: 0.111411, Val Acc: 0.773196\n",
      "Epoch 16976 - Train Loss: 0.086290, Train Acc: 0.878205 | Val Loss: 0.111410, Val Acc: 0.773196\n",
      "Epoch 16977 - Train Loss: 0.086287, Train Acc: 0.878205 | Val Loss: 0.111408, Val Acc: 0.773196\n",
      "Epoch 16978 - Train Loss: 0.086284, Train Acc: 0.878205 | Val Loss: 0.111406, Val Acc: 0.773196\n",
      "Epoch 16979 - Train Loss: 0.086281, Train Acc: 0.878205 | Val Loss: 0.111405, Val Acc: 0.773196\n",
      "Epoch 16980 - Train Loss: 0.086278, Train Acc: 0.878205 | Val Loss: 0.111403, Val Acc: 0.773196\n",
      "Epoch 16981 - Train Loss: 0.086275, Train Acc: 0.878205 | Val Loss: 0.111401, Val Acc: 0.773196\n",
      "Epoch 16982 - Train Loss: 0.086272, Train Acc: 0.878205 | Val Loss: 0.111400, Val Acc: 0.773196\n",
      "Epoch 16983 - Train Loss: 0.086269, Train Acc: 0.878205 | Val Loss: 0.111398, Val Acc: 0.773196\n",
      "Epoch 16984 - Train Loss: 0.086266, Train Acc: 0.878205 | Val Loss: 0.111396, Val Acc: 0.773196\n",
      "Epoch 16985 - Train Loss: 0.086263, Train Acc: 0.878205 | Val Loss: 0.111394, Val Acc: 0.773196\n",
      "Epoch 16986 - Train Loss: 0.086260, Train Acc: 0.878205 | Val Loss: 0.111393, Val Acc: 0.773196\n",
      "Epoch 16987 - Train Loss: 0.086257, Train Acc: 0.878205 | Val Loss: 0.111391, Val Acc: 0.773196\n",
      "Epoch 16988 - Train Loss: 0.086254, Train Acc: 0.878205 | Val Loss: 0.111389, Val Acc: 0.773196\n",
      "Epoch 16989 - Train Loss: 0.086251, Train Acc: 0.878205 | Val Loss: 0.111388, Val Acc: 0.773196\n",
      "Epoch 16990 - Train Loss: 0.086248, Train Acc: 0.878205 | Val Loss: 0.111386, Val Acc: 0.773196\n",
      "Epoch 16991 - Train Loss: 0.086245, Train Acc: 0.878205 | Val Loss: 0.111384, Val Acc: 0.773196\n",
      "Epoch 16992 - Train Loss: 0.086242, Train Acc: 0.878205 | Val Loss: 0.111383, Val Acc: 0.773196\n",
      "Epoch 16993 - Train Loss: 0.086239, Train Acc: 0.878205 | Val Loss: 0.111381, Val Acc: 0.773196\n",
      "Epoch 16994 - Train Loss: 0.086236, Train Acc: 0.878205 | Val Loss: 0.111379, Val Acc: 0.773196\n",
      "Epoch 16995 - Train Loss: 0.086233, Train Acc: 0.878205 | Val Loss: 0.111378, Val Acc: 0.773196\n",
      "Epoch 16996 - Train Loss: 0.086230, Train Acc: 0.878205 | Val Loss: 0.111376, Val Acc: 0.773196\n",
      "Epoch 16997 - Train Loss: 0.086227, Train Acc: 0.878205 | Val Loss: 0.111374, Val Acc: 0.773196\n",
      "Epoch 16998 - Train Loss: 0.086224, Train Acc: 0.878205 | Val Loss: 0.111372, Val Acc: 0.773196\n",
      "Epoch 16999 - Train Loss: 0.086221, Train Acc: 0.878205 | Val Loss: 0.111371, Val Acc: 0.773196\n",
      "Epoch 17000 - Train Loss: 0.086218, Train Acc: 0.878205 | Val Loss: 0.111369, Val Acc: 0.773196\n",
      "Epoch 17001 - Train Loss: 0.086216, Train Acc: 0.878205 | Val Loss: 0.111367, Val Acc: 0.773196\n",
      "Epoch 17002 - Train Loss: 0.086213, Train Acc: 0.878205 | Val Loss: 0.111366, Val Acc: 0.773196\n",
      "Epoch 17003 - Train Loss: 0.086210, Train Acc: 0.878205 | Val Loss: 0.111364, Val Acc: 0.773196\n",
      "Epoch 17004 - Train Loss: 0.086207, Train Acc: 0.878205 | Val Loss: 0.111362, Val Acc: 0.773196\n",
      "Epoch 17005 - Train Loss: 0.086204, Train Acc: 0.878205 | Val Loss: 0.111361, Val Acc: 0.773196\n",
      "Epoch 17006 - Train Loss: 0.086201, Train Acc: 0.878205 | Val Loss: 0.111359, Val Acc: 0.773196\n",
      "Epoch 17007 - Train Loss: 0.086198, Train Acc: 0.878205 | Val Loss: 0.111357, Val Acc: 0.773196\n",
      "Epoch 17008 - Train Loss: 0.086195, Train Acc: 0.878205 | Val Loss: 0.111356, Val Acc: 0.773196\n",
      "Epoch 17009 - Train Loss: 0.086192, Train Acc: 0.878205 | Val Loss: 0.111354, Val Acc: 0.773196\n",
      "Epoch 17010 - Train Loss: 0.086189, Train Acc: 0.878205 | Val Loss: 0.111352, Val Acc: 0.773196\n",
      "Epoch 17011 - Train Loss: 0.086186, Train Acc: 0.878205 | Val Loss: 0.111350, Val Acc: 0.773196\n",
      "Epoch 17012 - Train Loss: 0.086183, Train Acc: 0.878205 | Val Loss: 0.111349, Val Acc: 0.773196\n",
      "Epoch 17013 - Train Loss: 0.086180, Train Acc: 0.878205 | Val Loss: 0.111347, Val Acc: 0.773196\n",
      "Epoch 17014 - Train Loss: 0.086177, Train Acc: 0.878205 | Val Loss: 0.111345, Val Acc: 0.773196\n",
      "Epoch 17015 - Train Loss: 0.086174, Train Acc: 0.878205 | Val Loss: 0.111344, Val Acc: 0.773196\n",
      "Epoch 17016 - Train Loss: 0.086171, Train Acc: 0.878205 | Val Loss: 0.111342, Val Acc: 0.773196\n",
      "Epoch 17017 - Train Loss: 0.086168, Train Acc: 0.878205 | Val Loss: 0.111340, Val Acc: 0.773196\n",
      "Epoch 17018 - Train Loss: 0.086165, Train Acc: 0.878205 | Val Loss: 0.111339, Val Acc: 0.773196\n",
      "Epoch 17019 - Train Loss: 0.086162, Train Acc: 0.878205 | Val Loss: 0.111337, Val Acc: 0.773196\n",
      "Epoch 17020 - Train Loss: 0.086159, Train Acc: 0.878205 | Val Loss: 0.111335, Val Acc: 0.773196\n",
      "Epoch 17021 - Train Loss: 0.086156, Train Acc: 0.878205 | Val Loss: 0.111334, Val Acc: 0.773196\n",
      "Epoch 17022 - Train Loss: 0.086153, Train Acc: 0.878205 | Val Loss: 0.111332, Val Acc: 0.773196\n",
      "Epoch 17023 - Train Loss: 0.086150, Train Acc: 0.878205 | Val Loss: 0.111330, Val Acc: 0.773196\n",
      "Epoch 17024 - Train Loss: 0.086147, Train Acc: 0.878205 | Val Loss: 0.111329, Val Acc: 0.773196\n",
      "Epoch 17025 - Train Loss: 0.086144, Train Acc: 0.878205 | Val Loss: 0.111327, Val Acc: 0.773196\n",
      "Epoch 17026 - Train Loss: 0.086142, Train Acc: 0.878205 | Val Loss: 0.111325, Val Acc: 0.773196\n",
      "Epoch 17027 - Train Loss: 0.086139, Train Acc: 0.878205 | Val Loss: 0.111324, Val Acc: 0.773196\n",
      "Epoch 17028 - Train Loss: 0.086136, Train Acc: 0.878205 | Val Loss: 0.111322, Val Acc: 0.773196\n",
      "Epoch 17029 - Train Loss: 0.086133, Train Acc: 0.878205 | Val Loss: 0.111320, Val Acc: 0.773196\n",
      "Epoch 17030 - Train Loss: 0.086130, Train Acc: 0.878205 | Val Loss: 0.111318, Val Acc: 0.773196\n",
      "Epoch 17031 - Train Loss: 0.086127, Train Acc: 0.878205 | Val Loss: 0.111317, Val Acc: 0.773196\n",
      "Epoch 17032 - Train Loss: 0.086124, Train Acc: 0.878205 | Val Loss: 0.111315, Val Acc: 0.773196\n",
      "Epoch 17033 - Train Loss: 0.086121, Train Acc: 0.878205 | Val Loss: 0.111313, Val Acc: 0.773196\n",
      "Epoch 17034 - Train Loss: 0.086118, Train Acc: 0.878205 | Val Loss: 0.111312, Val Acc: 0.773196\n",
      "Epoch 17035 - Train Loss: 0.086115, Train Acc: 0.878205 | Val Loss: 0.111310, Val Acc: 0.773196\n",
      "Epoch 17036 - Train Loss: 0.086112, Train Acc: 0.878205 | Val Loss: 0.111308, Val Acc: 0.773196\n",
      "Epoch 17037 - Train Loss: 0.086109, Train Acc: 0.878205 | Val Loss: 0.111307, Val Acc: 0.773196\n",
      "Epoch 17038 - Train Loss: 0.086106, Train Acc: 0.878205 | Val Loss: 0.111305, Val Acc: 0.773196\n",
      "Epoch 17039 - Train Loss: 0.086103, Train Acc: 0.878205 | Val Loss: 0.111303, Val Acc: 0.773196\n",
      "Epoch 17040 - Train Loss: 0.086100, Train Acc: 0.878205 | Val Loss: 0.111302, Val Acc: 0.773196\n",
      "Epoch 17041 - Train Loss: 0.086097, Train Acc: 0.878205 | Val Loss: 0.111300, Val Acc: 0.773196\n",
      "Epoch 17042 - Train Loss: 0.086094, Train Acc: 0.878205 | Val Loss: 0.111298, Val Acc: 0.773196\n",
      "Epoch 17043 - Train Loss: 0.086091, Train Acc: 0.878205 | Val Loss: 0.111297, Val Acc: 0.773196\n",
      "Epoch 17044 - Train Loss: 0.086088, Train Acc: 0.878205 | Val Loss: 0.111295, Val Acc: 0.773196\n",
      "Epoch 17045 - Train Loss: 0.086085, Train Acc: 0.878205 | Val Loss: 0.111293, Val Acc: 0.773196\n",
      "Epoch 17046 - Train Loss: 0.086083, Train Acc: 0.878205 | Val Loss: 0.111292, Val Acc: 0.773196\n",
      "Epoch 17047 - Train Loss: 0.086080, Train Acc: 0.878205 | Val Loss: 0.111290, Val Acc: 0.773196\n",
      "Epoch 17048 - Train Loss: 0.086077, Train Acc: 0.878205 | Val Loss: 0.111288, Val Acc: 0.773196\n",
      "Epoch 17049 - Train Loss: 0.086074, Train Acc: 0.878205 | Val Loss: 0.111287, Val Acc: 0.773196\n",
      "Epoch 17050 - Train Loss: 0.086071, Train Acc: 0.878205 | Val Loss: 0.111285, Val Acc: 0.773196\n",
      "Epoch 17051 - Train Loss: 0.086068, Train Acc: 0.878205 | Val Loss: 0.111283, Val Acc: 0.773196\n",
      "Epoch 17052 - Train Loss: 0.086065, Train Acc: 0.878205 | Val Loss: 0.111282, Val Acc: 0.773196\n",
      "Epoch 17053 - Train Loss: 0.086062, Train Acc: 0.878205 | Val Loss: 0.111280, Val Acc: 0.773196\n",
      "Epoch 17054 - Train Loss: 0.086059, Train Acc: 0.878205 | Val Loss: 0.111278, Val Acc: 0.773196\n",
      "Epoch 17055 - Train Loss: 0.086056, Train Acc: 0.878205 | Val Loss: 0.111277, Val Acc: 0.773196\n",
      "Epoch 17056 - Train Loss: 0.086053, Train Acc: 0.878205 | Val Loss: 0.111275, Val Acc: 0.773196\n",
      "Epoch 17057 - Train Loss: 0.086050, Train Acc: 0.878205 | Val Loss: 0.111273, Val Acc: 0.773196\n",
      "Epoch 17058 - Train Loss: 0.086047, Train Acc: 0.878205 | Val Loss: 0.111272, Val Acc: 0.773196\n",
      "Epoch 17059 - Train Loss: 0.086044, Train Acc: 0.878205 | Val Loss: 0.111270, Val Acc: 0.773196\n",
      "Epoch 17060 - Train Loss: 0.086041, Train Acc: 0.878205 | Val Loss: 0.111268, Val Acc: 0.773196\n",
      "Epoch 17061 - Train Loss: 0.086038, Train Acc: 0.878205 | Val Loss: 0.111267, Val Acc: 0.773196\n",
      "Epoch 17062 - Train Loss: 0.086035, Train Acc: 0.878205 | Val Loss: 0.111265, Val Acc: 0.773196\n",
      "Epoch 17063 - Train Loss: 0.086032, Train Acc: 0.878205 | Val Loss: 0.111263, Val Acc: 0.773196\n",
      "Epoch 17064 - Train Loss: 0.086030, Train Acc: 0.878205 | Val Loss: 0.111261, Val Acc: 0.773196\n",
      "Epoch 17065 - Train Loss: 0.086027, Train Acc: 0.878205 | Val Loss: 0.111260, Val Acc: 0.773196\n",
      "Epoch 17066 - Train Loss: 0.086024, Train Acc: 0.878205 | Val Loss: 0.111258, Val Acc: 0.773196\n",
      "Epoch 17067 - Train Loss: 0.086021, Train Acc: 0.878205 | Val Loss: 0.111257, Val Acc: 0.773196\n",
      "Epoch 17068 - Train Loss: 0.086018, Train Acc: 0.878205 | Val Loss: 0.111255, Val Acc: 0.773196\n",
      "Epoch 17069 - Train Loss: 0.086015, Train Acc: 0.878205 | Val Loss: 0.111253, Val Acc: 0.773196\n",
      "Epoch 17070 - Train Loss: 0.086012, Train Acc: 0.878205 | Val Loss: 0.111252, Val Acc: 0.773196\n",
      "Epoch 17071 - Train Loss: 0.086009, Train Acc: 0.878205 | Val Loss: 0.111250, Val Acc: 0.773196\n",
      "Epoch 17072 - Train Loss: 0.086006, Train Acc: 0.878205 | Val Loss: 0.111248, Val Acc: 0.773196\n",
      "Epoch 17073 - Train Loss: 0.086003, Train Acc: 0.878205 | Val Loss: 0.111246, Val Acc: 0.773196\n",
      "Epoch 17074 - Train Loss: 0.086000, Train Acc: 0.878205 | Val Loss: 0.111245, Val Acc: 0.773196\n",
      "Epoch 17075 - Train Loss: 0.085997, Train Acc: 0.878205 | Val Loss: 0.111243, Val Acc: 0.773196\n",
      "Epoch 17076 - Train Loss: 0.085994, Train Acc: 0.878205 | Val Loss: 0.111242, Val Acc: 0.773196\n",
      "Epoch 17077 - Train Loss: 0.085991, Train Acc: 0.878205 | Val Loss: 0.111240, Val Acc: 0.773196\n",
      "Epoch 17078 - Train Loss: 0.085988, Train Acc: 0.878205 | Val Loss: 0.111238, Val Acc: 0.773196\n",
      "Epoch 17079 - Train Loss: 0.085985, Train Acc: 0.878205 | Val Loss: 0.111237, Val Acc: 0.773196\n",
      "Epoch 17080 - Train Loss: 0.085982, Train Acc: 0.878205 | Val Loss: 0.111235, Val Acc: 0.773196\n",
      "Epoch 17081 - Train Loss: 0.085980, Train Acc: 0.878205 | Val Loss: 0.111233, Val Acc: 0.773196\n",
      "Epoch 17082 - Train Loss: 0.085977, Train Acc: 0.878205 | Val Loss: 0.111231, Val Acc: 0.773196\n",
      "Epoch 17083 - Train Loss: 0.085974, Train Acc: 0.878205 | Val Loss: 0.111230, Val Acc: 0.773196\n",
      "Epoch 17084 - Train Loss: 0.085971, Train Acc: 0.878205 | Val Loss: 0.111228, Val Acc: 0.773196\n",
      "Epoch 17085 - Train Loss: 0.085968, Train Acc: 0.878205 | Val Loss: 0.111227, Val Acc: 0.773196\n",
      "Epoch 17086 - Train Loss: 0.085965, Train Acc: 0.878205 | Val Loss: 0.111225, Val Acc: 0.773196\n",
      "Epoch 17087 - Train Loss: 0.085962, Train Acc: 0.878205 | Val Loss: 0.111223, Val Acc: 0.773196\n",
      "Epoch 17088 - Train Loss: 0.085959, Train Acc: 0.878205 | Val Loss: 0.111222, Val Acc: 0.773196\n",
      "Epoch 17089 - Train Loss: 0.085956, Train Acc: 0.878205 | Val Loss: 0.111220, Val Acc: 0.773196\n",
      "Epoch 17090 - Train Loss: 0.085953, Train Acc: 0.878205 | Val Loss: 0.111218, Val Acc: 0.773196\n",
      "Epoch 17091 - Train Loss: 0.085950, Train Acc: 0.878205 | Val Loss: 0.111217, Val Acc: 0.773196\n",
      "Epoch 17092 - Train Loss: 0.085947, Train Acc: 0.878205 | Val Loss: 0.111215, Val Acc: 0.773196\n",
      "Epoch 17093 - Train Loss: 0.085944, Train Acc: 0.878205 | Val Loss: 0.111213, Val Acc: 0.773196\n",
      "Epoch 17094 - Train Loss: 0.085941, Train Acc: 0.878205 | Val Loss: 0.111212, Val Acc: 0.773196\n",
      "Epoch 17095 - Train Loss: 0.085938, Train Acc: 0.878205 | Val Loss: 0.111210, Val Acc: 0.773196\n",
      "Epoch 17096 - Train Loss: 0.085936, Train Acc: 0.878205 | Val Loss: 0.111208, Val Acc: 0.773196\n",
      "Epoch 17097 - Train Loss: 0.085933, Train Acc: 0.878205 | Val Loss: 0.111207, Val Acc: 0.773196\n",
      "Epoch 17098 - Train Loss: 0.085930, Train Acc: 0.878205 | Val Loss: 0.111205, Val Acc: 0.773196\n",
      "Epoch 17099 - Train Loss: 0.085927, Train Acc: 0.878205 | Val Loss: 0.111203, Val Acc: 0.773196\n",
      "Epoch 17100 - Train Loss: 0.085924, Train Acc: 0.878205 | Val Loss: 0.111202, Val Acc: 0.773196\n",
      "Epoch 17101 - Train Loss: 0.085921, Train Acc: 0.878205 | Val Loss: 0.111200, Val Acc: 0.773196\n",
      "Epoch 17102 - Train Loss: 0.085918, Train Acc: 0.878205 | Val Loss: 0.111198, Val Acc: 0.773196\n",
      "Epoch 17103 - Train Loss: 0.085915, Train Acc: 0.878205 | Val Loss: 0.111197, Val Acc: 0.773196\n",
      "Epoch 17104 - Train Loss: 0.085912, Train Acc: 0.878205 | Val Loss: 0.111195, Val Acc: 0.773196\n",
      "Epoch 17105 - Train Loss: 0.085909, Train Acc: 0.878205 | Val Loss: 0.111193, Val Acc: 0.773196\n",
      "Epoch 17106 - Train Loss: 0.085906, Train Acc: 0.878205 | Val Loss: 0.111192, Val Acc: 0.773196\n",
      "Epoch 17107 - Train Loss: 0.085903, Train Acc: 0.878205 | Val Loss: 0.111190, Val Acc: 0.773196\n",
      "Epoch 17108 - Train Loss: 0.085900, Train Acc: 0.878205 | Val Loss: 0.111188, Val Acc: 0.773196\n",
      "Epoch 17109 - Train Loss: 0.085897, Train Acc: 0.878205 | Val Loss: 0.111187, Val Acc: 0.773196\n",
      "Epoch 17110 - Train Loss: 0.085895, Train Acc: 0.878205 | Val Loss: 0.111185, Val Acc: 0.773196\n",
      "Epoch 17111 - Train Loss: 0.085892, Train Acc: 0.878205 | Val Loss: 0.111183, Val Acc: 0.773196\n",
      "Epoch 17112 - Train Loss: 0.085889, Train Acc: 0.878205 | Val Loss: 0.111182, Val Acc: 0.773196\n",
      "Epoch 17113 - Train Loss: 0.085886, Train Acc: 0.878205 | Val Loss: 0.111180, Val Acc: 0.773196\n",
      "Epoch 17114 - Train Loss: 0.085883, Train Acc: 0.878205 | Val Loss: 0.111178, Val Acc: 0.773196\n",
      "Epoch 17115 - Train Loss: 0.085880, Train Acc: 0.878205 | Val Loss: 0.111177, Val Acc: 0.773196\n",
      "Epoch 17116 - Train Loss: 0.085877, Train Acc: 0.878205 | Val Loss: 0.111175, Val Acc: 0.773196\n",
      "Epoch 17117 - Train Loss: 0.085874, Train Acc: 0.878205 | Val Loss: 0.111173, Val Acc: 0.773196\n",
      "Epoch 17118 - Train Loss: 0.085871, Train Acc: 0.878205 | Val Loss: 0.111172, Val Acc: 0.773196\n",
      "Epoch 17119 - Train Loss: 0.085868, Train Acc: 0.878205 | Val Loss: 0.111170, Val Acc: 0.773196\n",
      "Epoch 17120 - Train Loss: 0.085865, Train Acc: 0.878205 | Val Loss: 0.111169, Val Acc: 0.773196\n",
      "Epoch 17121 - Train Loss: 0.085862, Train Acc: 0.878205 | Val Loss: 0.111167, Val Acc: 0.773196\n",
      "Epoch 17122 - Train Loss: 0.085859, Train Acc: 0.878205 | Val Loss: 0.111165, Val Acc: 0.773196\n",
      "Epoch 17123 - Train Loss: 0.085857, Train Acc: 0.878205 | Val Loss: 0.111164, Val Acc: 0.773196\n",
      "Epoch 17124 - Train Loss: 0.085854, Train Acc: 0.878205 | Val Loss: 0.111162, Val Acc: 0.773196\n",
      "Epoch 17125 - Train Loss: 0.085851, Train Acc: 0.878205 | Val Loss: 0.111160, Val Acc: 0.773196\n",
      "Epoch 17126 - Train Loss: 0.085848, Train Acc: 0.878205 | Val Loss: 0.111159, Val Acc: 0.773196\n",
      "Epoch 17127 - Train Loss: 0.085845, Train Acc: 0.878205 | Val Loss: 0.111157, Val Acc: 0.773196\n",
      "Epoch 17128 - Train Loss: 0.085842, Train Acc: 0.878205 | Val Loss: 0.111155, Val Acc: 0.773196\n",
      "Epoch 17129 - Train Loss: 0.085839, Train Acc: 0.878205 | Val Loss: 0.111154, Val Acc: 0.773196\n",
      "Epoch 17130 - Train Loss: 0.085836, Train Acc: 0.878205 | Val Loss: 0.111152, Val Acc: 0.773196\n",
      "Epoch 17131 - Train Loss: 0.085833, Train Acc: 0.878205 | Val Loss: 0.111150, Val Acc: 0.773196\n",
      "Epoch 17132 - Train Loss: 0.085830, Train Acc: 0.878205 | Val Loss: 0.111149, Val Acc: 0.773196\n",
      "Epoch 17133 - Train Loss: 0.085827, Train Acc: 0.878205 | Val Loss: 0.111147, Val Acc: 0.773196\n",
      "Epoch 17134 - Train Loss: 0.085824, Train Acc: 0.878205 | Val Loss: 0.111145, Val Acc: 0.773196\n",
      "Epoch 17135 - Train Loss: 0.085822, Train Acc: 0.878205 | Val Loss: 0.111144, Val Acc: 0.773196\n",
      "Epoch 17136 - Train Loss: 0.085819, Train Acc: 0.878205 | Val Loss: 0.111142, Val Acc: 0.773196\n",
      "Epoch 17137 - Train Loss: 0.085816, Train Acc: 0.878205 | Val Loss: 0.111141, Val Acc: 0.773196\n",
      "Epoch 17138 - Train Loss: 0.085813, Train Acc: 0.878205 | Val Loss: 0.111139, Val Acc: 0.773196\n",
      "Epoch 17139 - Train Loss: 0.085810, Train Acc: 0.878205 | Val Loss: 0.111137, Val Acc: 0.773196\n",
      "Epoch 17140 - Train Loss: 0.085807, Train Acc: 0.878205 | Val Loss: 0.111136, Val Acc: 0.773196\n",
      "Epoch 17141 - Train Loss: 0.085804, Train Acc: 0.878205 | Val Loss: 0.111134, Val Acc: 0.773196\n",
      "Epoch 17142 - Train Loss: 0.085801, Train Acc: 0.878205 | Val Loss: 0.111132, Val Acc: 0.773196\n",
      "Epoch 17143 - Train Loss: 0.085798, Train Acc: 0.878205 | Val Loss: 0.111131, Val Acc: 0.773196\n",
      "Epoch 17144 - Train Loss: 0.085795, Train Acc: 0.878205 | Val Loss: 0.111129, Val Acc: 0.773196\n",
      "Epoch 17145 - Train Loss: 0.085792, Train Acc: 0.878205 | Val Loss: 0.111127, Val Acc: 0.773196\n",
      "Epoch 17146 - Train Loss: 0.085789, Train Acc: 0.878205 | Val Loss: 0.111126, Val Acc: 0.773196\n",
      "Epoch 17147 - Train Loss: 0.085787, Train Acc: 0.878205 | Val Loss: 0.111124, Val Acc: 0.773196\n",
      "Epoch 17148 - Train Loss: 0.085784, Train Acc: 0.878205 | Val Loss: 0.111122, Val Acc: 0.773196\n",
      "Epoch 17149 - Train Loss: 0.085781, Train Acc: 0.878205 | Val Loss: 0.111121, Val Acc: 0.773196\n",
      "Epoch 17150 - Train Loss: 0.085778, Train Acc: 0.878205 | Val Loss: 0.111119, Val Acc: 0.773196\n",
      "Epoch 17151 - Train Loss: 0.085775, Train Acc: 0.878205 | Val Loss: 0.111117, Val Acc: 0.773196\n",
      "Epoch 17152 - Train Loss: 0.085772, Train Acc: 0.878205 | Val Loss: 0.111116, Val Acc: 0.773196\n",
      "Epoch 17153 - Train Loss: 0.085769, Train Acc: 0.878205 | Val Loss: 0.111114, Val Acc: 0.773196\n",
      "Epoch 17154 - Train Loss: 0.085766, Train Acc: 0.878205 | Val Loss: 0.111113, Val Acc: 0.773196\n",
      "Epoch 17155 - Train Loss: 0.085763, Train Acc: 0.878205 | Val Loss: 0.111111, Val Acc: 0.773196\n",
      "Epoch 17156 - Train Loss: 0.085760, Train Acc: 0.878205 | Val Loss: 0.111109, Val Acc: 0.773196\n",
      "Epoch 17157 - Train Loss: 0.085757, Train Acc: 0.878205 | Val Loss: 0.111108, Val Acc: 0.773196\n",
      "Epoch 17158 - Train Loss: 0.085755, Train Acc: 0.878205 | Val Loss: 0.111106, Val Acc: 0.773196\n",
      "Epoch 17159 - Train Loss: 0.085752, Train Acc: 0.878205 | Val Loss: 0.111104, Val Acc: 0.773196\n",
      "Epoch 17160 - Train Loss: 0.085749, Train Acc: 0.878205 | Val Loss: 0.111103, Val Acc: 0.773196\n",
      "Epoch 17161 - Train Loss: 0.085746, Train Acc: 0.878205 | Val Loss: 0.111101, Val Acc: 0.773196\n",
      "Epoch 17162 - Train Loss: 0.085743, Train Acc: 0.878205 | Val Loss: 0.111099, Val Acc: 0.773196\n",
      "Epoch 17163 - Train Loss: 0.085740, Train Acc: 0.878205 | Val Loss: 0.111098, Val Acc: 0.773196\n",
      "Epoch 17164 - Train Loss: 0.085737, Train Acc: 0.878205 | Val Loss: 0.111096, Val Acc: 0.773196\n",
      "Epoch 17165 - Train Loss: 0.085734, Train Acc: 0.878205 | Val Loss: 0.111095, Val Acc: 0.773196\n",
      "Epoch 17166 - Train Loss: 0.085731, Train Acc: 0.878205 | Val Loss: 0.111093, Val Acc: 0.773196\n",
      "Epoch 17167 - Train Loss: 0.085728, Train Acc: 0.878205 | Val Loss: 0.111091, Val Acc: 0.773196\n",
      "Epoch 17168 - Train Loss: 0.085725, Train Acc: 0.878205 | Val Loss: 0.111090, Val Acc: 0.773196\n",
      "Epoch 17169 - Train Loss: 0.085723, Train Acc: 0.878205 | Val Loss: 0.111088, Val Acc: 0.773196\n",
      "Epoch 17170 - Train Loss: 0.085720, Train Acc: 0.878205 | Val Loss: 0.111086, Val Acc: 0.773196\n",
      "Epoch 17171 - Train Loss: 0.085717, Train Acc: 0.878205 | Val Loss: 0.111085, Val Acc: 0.773196\n",
      "Epoch 17172 - Train Loss: 0.085714, Train Acc: 0.878205 | Val Loss: 0.111083, Val Acc: 0.773196\n",
      "Epoch 17173 - Train Loss: 0.085711, Train Acc: 0.878205 | Val Loss: 0.111082, Val Acc: 0.773196\n",
      "Epoch 17174 - Train Loss: 0.085708, Train Acc: 0.878205 | Val Loss: 0.111080, Val Acc: 0.773196\n",
      "Epoch 17175 - Train Loss: 0.085705, Train Acc: 0.878205 | Val Loss: 0.111078, Val Acc: 0.773196\n",
      "Epoch 17176 - Train Loss: 0.085702, Train Acc: 0.878205 | Val Loss: 0.111077, Val Acc: 0.773196\n",
      "Epoch 17177 - Train Loss: 0.085699, Train Acc: 0.878205 | Val Loss: 0.111075, Val Acc: 0.773196\n",
      "Epoch 17178 - Train Loss: 0.085696, Train Acc: 0.878205 | Val Loss: 0.111073, Val Acc: 0.773196\n",
      "Epoch 17179 - Train Loss: 0.085693, Train Acc: 0.878205 | Val Loss: 0.111072, Val Acc: 0.773196\n",
      "Epoch 17180 - Train Loss: 0.085691, Train Acc: 0.878205 | Val Loss: 0.111070, Val Acc: 0.773196\n",
      "Epoch 17181 - Train Loss: 0.085688, Train Acc: 0.878205 | Val Loss: 0.111068, Val Acc: 0.773196\n",
      "Epoch 17182 - Train Loss: 0.085685, Train Acc: 0.878205 | Val Loss: 0.111067, Val Acc: 0.773196\n",
      "Epoch 17183 - Train Loss: 0.085682, Train Acc: 0.878205 | Val Loss: 0.111065, Val Acc: 0.773196\n",
      "Epoch 17184 - Train Loss: 0.085679, Train Acc: 0.878205 | Val Loss: 0.111064, Val Acc: 0.773196\n",
      "Epoch 17185 - Train Loss: 0.085676, Train Acc: 0.878205 | Val Loss: 0.111062, Val Acc: 0.773196\n",
      "Epoch 17186 - Train Loss: 0.085673, Train Acc: 0.878205 | Val Loss: 0.111060, Val Acc: 0.773196\n",
      "Epoch 17187 - Train Loss: 0.085670, Train Acc: 0.878205 | Val Loss: 0.111059, Val Acc: 0.773196\n",
      "Epoch 17188 - Train Loss: 0.085667, Train Acc: 0.878205 | Val Loss: 0.111057, Val Acc: 0.773196\n",
      "Epoch 17189 - Train Loss: 0.085664, Train Acc: 0.878205 | Val Loss: 0.111055, Val Acc: 0.773196\n",
      "Epoch 17190 - Train Loss: 0.085662, Train Acc: 0.878205 | Val Loss: 0.111054, Val Acc: 0.773196\n",
      "Epoch 17191 - Train Loss: 0.085659, Train Acc: 0.878205 | Val Loss: 0.111052, Val Acc: 0.773196\n",
      "Epoch 17192 - Train Loss: 0.085656, Train Acc: 0.878205 | Val Loss: 0.111051, Val Acc: 0.773196\n",
      "Epoch 17193 - Train Loss: 0.085653, Train Acc: 0.878205 | Val Loss: 0.111049, Val Acc: 0.773196\n",
      "Epoch 17194 - Train Loss: 0.085650, Train Acc: 0.878205 | Val Loss: 0.111047, Val Acc: 0.773196\n",
      "Epoch 17195 - Train Loss: 0.085647, Train Acc: 0.878205 | Val Loss: 0.111046, Val Acc: 0.773196\n",
      "Epoch 17196 - Train Loss: 0.085644, Train Acc: 0.878205 | Val Loss: 0.111044, Val Acc: 0.773196\n",
      "Epoch 17197 - Train Loss: 0.085641, Train Acc: 0.878205 | Val Loss: 0.111042, Val Acc: 0.773196\n",
      "Epoch 17198 - Train Loss: 0.085638, Train Acc: 0.878205 | Val Loss: 0.111041, Val Acc: 0.773196\n",
      "Epoch 17199 - Train Loss: 0.085636, Train Acc: 0.878205 | Val Loss: 0.111039, Val Acc: 0.773196\n",
      "Epoch 17200 - Train Loss: 0.085633, Train Acc: 0.878205 | Val Loss: 0.111038, Val Acc: 0.773196\n",
      "Epoch 17201 - Train Loss: 0.085630, Train Acc: 0.878205 | Val Loss: 0.111036, Val Acc: 0.773196\n",
      "Epoch 17202 - Train Loss: 0.085627, Train Acc: 0.878205 | Val Loss: 0.111034, Val Acc: 0.773196\n",
      "Epoch 17203 - Train Loss: 0.085624, Train Acc: 0.878205 | Val Loss: 0.111033, Val Acc: 0.773196\n",
      "Epoch 17204 - Train Loss: 0.085621, Train Acc: 0.878205 | Val Loss: 0.111031, Val Acc: 0.773196\n",
      "Epoch 17205 - Train Loss: 0.085618, Train Acc: 0.878205 | Val Loss: 0.111029, Val Acc: 0.773196\n",
      "Epoch 17206 - Train Loss: 0.085615, Train Acc: 0.878205 | Val Loss: 0.111028, Val Acc: 0.773196\n",
      "Epoch 17207 - Train Loss: 0.085612, Train Acc: 0.878205 | Val Loss: 0.111026, Val Acc: 0.773196\n",
      "Epoch 17208 - Train Loss: 0.085609, Train Acc: 0.878205 | Val Loss: 0.111025, Val Acc: 0.773196\n",
      "Epoch 17209 - Train Loss: 0.085607, Train Acc: 0.878205 | Val Loss: 0.111023, Val Acc: 0.773196\n",
      "Epoch 17210 - Train Loss: 0.085604, Train Acc: 0.878205 | Val Loss: 0.111021, Val Acc: 0.773196\n",
      "Epoch 17211 - Train Loss: 0.085601, Train Acc: 0.878205 | Val Loss: 0.111020, Val Acc: 0.773196\n",
      "Epoch 17212 - Train Loss: 0.085598, Train Acc: 0.878205 | Val Loss: 0.111018, Val Acc: 0.773196\n",
      "Epoch 17213 - Train Loss: 0.085595, Train Acc: 0.878205 | Val Loss: 0.111017, Val Acc: 0.773196\n",
      "Epoch 17214 - Train Loss: 0.085592, Train Acc: 0.878205 | Val Loss: 0.111015, Val Acc: 0.773196\n",
      "Epoch 17215 - Train Loss: 0.085589, Train Acc: 0.878205 | Val Loss: 0.111013, Val Acc: 0.773196\n",
      "Epoch 17216 - Train Loss: 0.085586, Train Acc: 0.878205 | Val Loss: 0.111012, Val Acc: 0.773196\n",
      "Epoch 17217 - Train Loss: 0.085583, Train Acc: 0.878205 | Val Loss: 0.111010, Val Acc: 0.773196\n",
      "Epoch 17218 - Train Loss: 0.085581, Train Acc: 0.878205 | Val Loss: 0.111008, Val Acc: 0.773196\n",
      "Epoch 17219 - Train Loss: 0.085578, Train Acc: 0.878205 | Val Loss: 0.111007, Val Acc: 0.773196\n",
      "Epoch 17220 - Train Loss: 0.085575, Train Acc: 0.878205 | Val Loss: 0.111005, Val Acc: 0.773196\n",
      "Epoch 17221 - Train Loss: 0.085572, Train Acc: 0.878205 | Val Loss: 0.111004, Val Acc: 0.773196\n",
      "Epoch 17222 - Train Loss: 0.085569, Train Acc: 0.878205 | Val Loss: 0.111002, Val Acc: 0.773196\n",
      "Epoch 17223 - Train Loss: 0.085566, Train Acc: 0.878205 | Val Loss: 0.111000, Val Acc: 0.773196\n",
      "Epoch 17224 - Train Loss: 0.085563, Train Acc: 0.878205 | Val Loss: 0.110999, Val Acc: 0.773196\n",
      "Epoch 17225 - Train Loss: 0.085560, Train Acc: 0.878205 | Val Loss: 0.110997, Val Acc: 0.773196\n",
      "Epoch 17226 - Train Loss: 0.085557, Train Acc: 0.878205 | Val Loss: 0.110995, Val Acc: 0.773196\n",
      "Epoch 17227 - Train Loss: 0.085555, Train Acc: 0.878205 | Val Loss: 0.110994, Val Acc: 0.773196\n",
      "Epoch 17228 - Train Loss: 0.085552, Train Acc: 0.878205 | Val Loss: 0.110992, Val Acc: 0.773196\n",
      "Epoch 17229 - Train Loss: 0.085549, Train Acc: 0.878205 | Val Loss: 0.110991, Val Acc: 0.773196\n",
      "Epoch 17230 - Train Loss: 0.085546, Train Acc: 0.878205 | Val Loss: 0.110989, Val Acc: 0.773196\n",
      "Epoch 17231 - Train Loss: 0.085543, Train Acc: 0.878205 | Val Loss: 0.110987, Val Acc: 0.773196\n",
      "Epoch 17232 - Train Loss: 0.085540, Train Acc: 0.878205 | Val Loss: 0.110986, Val Acc: 0.773196\n",
      "Epoch 17233 - Train Loss: 0.085537, Train Acc: 0.878205 | Val Loss: 0.110984, Val Acc: 0.773196\n",
      "Epoch 17234 - Train Loss: 0.085534, Train Acc: 0.878205 | Val Loss: 0.110983, Val Acc: 0.773196\n",
      "Epoch 17235 - Train Loss: 0.085532, Train Acc: 0.878205 | Val Loss: 0.110981, Val Acc: 0.773196\n",
      "Epoch 17236 - Train Loss: 0.085529, Train Acc: 0.878205 | Val Loss: 0.110979, Val Acc: 0.773196\n",
      "Epoch 17237 - Train Loss: 0.085526, Train Acc: 0.878205 | Val Loss: 0.110978, Val Acc: 0.773196\n",
      "Epoch 17238 - Train Loss: 0.085523, Train Acc: 0.878205 | Val Loss: 0.110976, Val Acc: 0.773196\n",
      "Epoch 17239 - Train Loss: 0.085520, Train Acc: 0.878205 | Val Loss: 0.110974, Val Acc: 0.773196\n",
      "Epoch 17240 - Train Loss: 0.085517, Train Acc: 0.878205 | Val Loss: 0.110973, Val Acc: 0.773196\n",
      "Epoch 17241 - Train Loss: 0.085514, Train Acc: 0.878205 | Val Loss: 0.110971, Val Acc: 0.773196\n",
      "Epoch 17242 - Train Loss: 0.085511, Train Acc: 0.878205 | Val Loss: 0.110970, Val Acc: 0.773196\n",
      "Epoch 17243 - Train Loss: 0.085508, Train Acc: 0.878205 | Val Loss: 0.110968, Val Acc: 0.773196\n",
      "Epoch 17244 - Train Loss: 0.085506, Train Acc: 0.878205 | Val Loss: 0.110966, Val Acc: 0.773196\n",
      "Epoch 17245 - Train Loss: 0.085503, Train Acc: 0.878205 | Val Loss: 0.110965, Val Acc: 0.773196\n",
      "Epoch 17246 - Train Loss: 0.085500, Train Acc: 0.878205 | Val Loss: 0.110963, Val Acc: 0.773196\n",
      "Epoch 17247 - Train Loss: 0.085497, Train Acc: 0.878205 | Val Loss: 0.110962, Val Acc: 0.773196\n",
      "Epoch 17248 - Train Loss: 0.085494, Train Acc: 0.878205 | Val Loss: 0.110960, Val Acc: 0.773196\n",
      "Epoch 17249 - Train Loss: 0.085491, Train Acc: 0.878205 | Val Loss: 0.110958, Val Acc: 0.773196\n",
      "Epoch 17250 - Train Loss: 0.085488, Train Acc: 0.878205 | Val Loss: 0.110957, Val Acc: 0.773196\n",
      "Epoch 17251 - Train Loss: 0.085485, Train Acc: 0.878205 | Val Loss: 0.110955, Val Acc: 0.773196\n",
      "Epoch 17252 - Train Loss: 0.085483, Train Acc: 0.878205 | Val Loss: 0.110954, Val Acc: 0.773196\n",
      "Epoch 17253 - Train Loss: 0.085480, Train Acc: 0.878205 | Val Loss: 0.110952, Val Acc: 0.773196\n",
      "Epoch 17254 - Train Loss: 0.085477, Train Acc: 0.878205 | Val Loss: 0.110950, Val Acc: 0.773196\n",
      "Epoch 17255 - Train Loss: 0.085474, Train Acc: 0.878205 | Val Loss: 0.110949, Val Acc: 0.773196\n",
      "Epoch 17256 - Train Loss: 0.085471, Train Acc: 0.878205 | Val Loss: 0.110947, Val Acc: 0.773196\n",
      "Epoch 17257 - Train Loss: 0.085468, Train Acc: 0.878205 | Val Loss: 0.110946, Val Acc: 0.773196\n",
      "Epoch 17258 - Train Loss: 0.085465, Train Acc: 0.878205 | Val Loss: 0.110944, Val Acc: 0.773196\n",
      "Epoch 17259 - Train Loss: 0.085462, Train Acc: 0.878205 | Val Loss: 0.110942, Val Acc: 0.773196\n",
      "Epoch 17260 - Train Loss: 0.085460, Train Acc: 0.878205 | Val Loss: 0.110941, Val Acc: 0.773196\n",
      "Epoch 17261 - Train Loss: 0.085457, Train Acc: 0.878205 | Val Loss: 0.110939, Val Acc: 0.773196\n",
      "Epoch 17262 - Train Loss: 0.085454, Train Acc: 0.878205 | Val Loss: 0.110938, Val Acc: 0.773196\n",
      "Epoch 17263 - Train Loss: 0.085451, Train Acc: 0.878205 | Val Loss: 0.110936, Val Acc: 0.773196\n",
      "Epoch 17264 - Train Loss: 0.085448, Train Acc: 0.878205 | Val Loss: 0.110934, Val Acc: 0.773196\n",
      "Epoch 17265 - Train Loss: 0.085445, Train Acc: 0.878205 | Val Loss: 0.110933, Val Acc: 0.773196\n",
      "Epoch 17266 - Train Loss: 0.085442, Train Acc: 0.878205 | Val Loss: 0.110931, Val Acc: 0.773196\n",
      "Epoch 17267 - Train Loss: 0.085439, Train Acc: 0.878205 | Val Loss: 0.110930, Val Acc: 0.773196\n",
      "Epoch 17268 - Train Loss: 0.085437, Train Acc: 0.878205 | Val Loss: 0.110928, Val Acc: 0.773196\n",
      "Epoch 17269 - Train Loss: 0.085434, Train Acc: 0.878205 | Val Loss: 0.110926, Val Acc: 0.773196\n",
      "Epoch 17270 - Train Loss: 0.085431, Train Acc: 0.878205 | Val Loss: 0.110925, Val Acc: 0.773196\n",
      "Epoch 17271 - Train Loss: 0.085428, Train Acc: 0.878205 | Val Loss: 0.110923, Val Acc: 0.773196\n",
      "Epoch 17272 - Train Loss: 0.085425, Train Acc: 0.878205 | Val Loss: 0.110922, Val Acc: 0.773196\n",
      "Epoch 17273 - Train Loss: 0.085422, Train Acc: 0.878205 | Val Loss: 0.110920, Val Acc: 0.773196\n",
      "Epoch 17274 - Train Loss: 0.085419, Train Acc: 0.878205 | Val Loss: 0.110918, Val Acc: 0.773196\n",
      "Epoch 17275 - Train Loss: 0.085416, Train Acc: 0.878205 | Val Loss: 0.110917, Val Acc: 0.773196\n",
      "Epoch 17276 - Train Loss: 0.085414, Train Acc: 0.878205 | Val Loss: 0.110915, Val Acc: 0.773196\n",
      "Epoch 17277 - Train Loss: 0.085411, Train Acc: 0.878205 | Val Loss: 0.110914, Val Acc: 0.773196\n",
      "Epoch 17278 - Train Loss: 0.085408, Train Acc: 0.878205 | Val Loss: 0.110912, Val Acc: 0.773196\n",
      "Epoch 17279 - Train Loss: 0.085405, Train Acc: 0.878205 | Val Loss: 0.110910, Val Acc: 0.773196\n",
      "Epoch 17280 - Train Loss: 0.085402, Train Acc: 0.878205 | Val Loss: 0.110909, Val Acc: 0.773196\n",
      "Epoch 17281 - Train Loss: 0.085399, Train Acc: 0.878205 | Val Loss: 0.110907, Val Acc: 0.773196\n",
      "Epoch 17282 - Train Loss: 0.085396, Train Acc: 0.878205 | Val Loss: 0.110906, Val Acc: 0.773196\n",
      "Epoch 17283 - Train Loss: 0.085394, Train Acc: 0.878205 | Val Loss: 0.110904, Val Acc: 0.773196\n",
      "Epoch 17284 - Train Loss: 0.085391, Train Acc: 0.878205 | Val Loss: 0.110902, Val Acc: 0.773196\n",
      "Epoch 17285 - Train Loss: 0.085388, Train Acc: 0.878205 | Val Loss: 0.110901, Val Acc: 0.773196\n",
      "Epoch 17286 - Train Loss: 0.085385, Train Acc: 0.878205 | Val Loss: 0.110899, Val Acc: 0.773196\n",
      "Epoch 17287 - Train Loss: 0.085382, Train Acc: 0.878205 | Val Loss: 0.110898, Val Acc: 0.773196\n",
      "Epoch 17288 - Train Loss: 0.085379, Train Acc: 0.878205 | Val Loss: 0.110896, Val Acc: 0.773196\n",
      "Epoch 17289 - Train Loss: 0.085376, Train Acc: 0.878205 | Val Loss: 0.110894, Val Acc: 0.773196\n",
      "Epoch 17290 - Train Loss: 0.085373, Train Acc: 0.878205 | Val Loss: 0.110893, Val Acc: 0.773196\n",
      "Epoch 17291 - Train Loss: 0.085371, Train Acc: 0.878205 | Val Loss: 0.110891, Val Acc: 0.773196\n",
      "Epoch 17292 - Train Loss: 0.085368, Train Acc: 0.878205 | Val Loss: 0.110890, Val Acc: 0.773196\n",
      "Epoch 17293 - Train Loss: 0.085365, Train Acc: 0.878205 | Val Loss: 0.110888, Val Acc: 0.773196\n",
      "Epoch 17294 - Train Loss: 0.085362, Train Acc: 0.878205 | Val Loss: 0.110886, Val Acc: 0.773196\n",
      "Epoch 17295 - Train Loss: 0.085359, Train Acc: 0.878205 | Val Loss: 0.110885, Val Acc: 0.773196\n",
      "Epoch 17296 - Train Loss: 0.085356, Train Acc: 0.878205 | Val Loss: 0.110883, Val Acc: 0.773196\n",
      "Epoch 17297 - Train Loss: 0.085353, Train Acc: 0.878205 | Val Loss: 0.110882, Val Acc: 0.773196\n",
      "Epoch 17298 - Train Loss: 0.085351, Train Acc: 0.878205 | Val Loss: 0.110880, Val Acc: 0.773196\n",
      "Epoch 17299 - Train Loss: 0.085348, Train Acc: 0.878205 | Val Loss: 0.110878, Val Acc: 0.773196\n",
      "Epoch 17300 - Train Loss: 0.085345, Train Acc: 0.878205 | Val Loss: 0.110877, Val Acc: 0.773196\n",
      "Epoch 17301 - Train Loss: 0.085342, Train Acc: 0.878205 | Val Loss: 0.110875, Val Acc: 0.773196\n",
      "Epoch 17302 - Train Loss: 0.085339, Train Acc: 0.878205 | Val Loss: 0.110874, Val Acc: 0.773196\n",
      "Epoch 17303 - Train Loss: 0.085336, Train Acc: 0.878205 | Val Loss: 0.110872, Val Acc: 0.773196\n",
      "Epoch 17304 - Train Loss: 0.085333, Train Acc: 0.878205 | Val Loss: 0.110870, Val Acc: 0.773196\n",
      "Epoch 17305 - Train Loss: 0.085331, Train Acc: 0.878205 | Val Loss: 0.110869, Val Acc: 0.773196\n",
      "Epoch 17306 - Train Loss: 0.085328, Train Acc: 0.878205 | Val Loss: 0.110867, Val Acc: 0.773196\n",
      "Epoch 17307 - Train Loss: 0.085325, Train Acc: 0.878205 | Val Loss: 0.110866, Val Acc: 0.773196\n",
      "Epoch 17308 - Train Loss: 0.085322, Train Acc: 0.878205 | Val Loss: 0.110864, Val Acc: 0.773196\n",
      "Epoch 17309 - Train Loss: 0.085319, Train Acc: 0.878205 | Val Loss: 0.110863, Val Acc: 0.773196\n",
      "Epoch 17310 - Train Loss: 0.085316, Train Acc: 0.878205 | Val Loss: 0.110861, Val Acc: 0.773196\n",
      "Epoch 17311 - Train Loss: 0.085313, Train Acc: 0.878205 | Val Loss: 0.110859, Val Acc: 0.773196\n",
      "Epoch 17312 - Train Loss: 0.085311, Train Acc: 0.878205 | Val Loss: 0.110858, Val Acc: 0.773196\n",
      "Epoch 17313 - Train Loss: 0.085308, Train Acc: 0.878205 | Val Loss: 0.110856, Val Acc: 0.773196\n",
      "Epoch 17314 - Train Loss: 0.085305, Train Acc: 0.878205 | Val Loss: 0.110855, Val Acc: 0.773196\n",
      "Epoch 17315 - Train Loss: 0.085302, Train Acc: 0.878205 | Val Loss: 0.110853, Val Acc: 0.773196\n",
      "Epoch 17316 - Train Loss: 0.085299, Train Acc: 0.878205 | Val Loss: 0.110851, Val Acc: 0.773196\n",
      "Epoch 17317 - Train Loss: 0.085296, Train Acc: 0.878205 | Val Loss: 0.110850, Val Acc: 0.773196\n",
      "Epoch 17318 - Train Loss: 0.085293, Train Acc: 0.878205 | Val Loss: 0.110848, Val Acc: 0.773196\n",
      "Epoch 17319 - Train Loss: 0.085291, Train Acc: 0.878205 | Val Loss: 0.110847, Val Acc: 0.773196\n",
      "Epoch 17320 - Train Loss: 0.085288, Train Acc: 0.878205 | Val Loss: 0.110845, Val Acc: 0.773196\n",
      "Epoch 17321 - Train Loss: 0.085285, Train Acc: 0.878205 | Val Loss: 0.110843, Val Acc: 0.773196\n",
      "Epoch 17322 - Train Loss: 0.085282, Train Acc: 0.878205 | Val Loss: 0.110842, Val Acc: 0.773196\n",
      "Epoch 17323 - Train Loss: 0.085279, Train Acc: 0.878205 | Val Loss: 0.110840, Val Acc: 0.773196\n",
      "Epoch 17324 - Train Loss: 0.085276, Train Acc: 0.878205 | Val Loss: 0.110839, Val Acc: 0.773196\n",
      "Epoch 17325 - Train Loss: 0.085273, Train Acc: 0.878205 | Val Loss: 0.110837, Val Acc: 0.773196\n",
      "Epoch 17326 - Train Loss: 0.085271, Train Acc: 0.878205 | Val Loss: 0.110836, Val Acc: 0.773196\n",
      "Epoch 17327 - Train Loss: 0.085268, Train Acc: 0.878205 | Val Loss: 0.110834, Val Acc: 0.773196\n",
      "Epoch 17328 - Train Loss: 0.085265, Train Acc: 0.878205 | Val Loss: 0.110832, Val Acc: 0.773196\n",
      "Epoch 17329 - Train Loss: 0.085262, Train Acc: 0.878205 | Val Loss: 0.110831, Val Acc: 0.773196\n",
      "Epoch 17330 - Train Loss: 0.085259, Train Acc: 0.878205 | Val Loss: 0.110829, Val Acc: 0.773196\n",
      "Epoch 17331 - Train Loss: 0.085256, Train Acc: 0.878205 | Val Loss: 0.110828, Val Acc: 0.773196\n",
      "Epoch 17332 - Train Loss: 0.085253, Train Acc: 0.878205 | Val Loss: 0.110826, Val Acc: 0.773196\n",
      "Epoch 17333 - Train Loss: 0.085251, Train Acc: 0.878205 | Val Loss: 0.110825, Val Acc: 0.773196\n",
      "Epoch 17334 - Train Loss: 0.085248, Train Acc: 0.878205 | Val Loss: 0.110823, Val Acc: 0.773196\n",
      "Epoch 17335 - Train Loss: 0.085245, Train Acc: 0.878205 | Val Loss: 0.110821, Val Acc: 0.773196\n",
      "Epoch 17336 - Train Loss: 0.085242, Train Acc: 0.878205 | Val Loss: 0.110820, Val Acc: 0.773196\n",
      "Epoch 17337 - Train Loss: 0.085239, Train Acc: 0.878205 | Val Loss: 0.110818, Val Acc: 0.773196\n",
      "Epoch 17338 - Train Loss: 0.085236, Train Acc: 0.878205 | Val Loss: 0.110817, Val Acc: 0.773196\n",
      "Epoch 17339 - Train Loss: 0.085233, Train Acc: 0.878205 | Val Loss: 0.110815, Val Acc: 0.773196\n",
      "Epoch 17340 - Train Loss: 0.085231, Train Acc: 0.878205 | Val Loss: 0.110813, Val Acc: 0.773196\n",
      "Epoch 17341 - Train Loss: 0.085228, Train Acc: 0.878205 | Val Loss: 0.110812, Val Acc: 0.773196\n",
      "Epoch 17342 - Train Loss: 0.085225, Train Acc: 0.878205 | Val Loss: 0.110810, Val Acc: 0.773196\n",
      "Epoch 17343 - Train Loss: 0.085222, Train Acc: 0.878205 | Val Loss: 0.110809, Val Acc: 0.773196\n",
      "Epoch 17344 - Train Loss: 0.085219, Train Acc: 0.878205 | Val Loss: 0.110807, Val Acc: 0.773196\n",
      "Epoch 17345 - Train Loss: 0.085216, Train Acc: 0.878205 | Val Loss: 0.110805, Val Acc: 0.773196\n",
      "Epoch 17346 - Train Loss: 0.085214, Train Acc: 0.878205 | Val Loss: 0.110804, Val Acc: 0.773196\n",
      "Epoch 17347 - Train Loss: 0.085211, Train Acc: 0.878205 | Val Loss: 0.110802, Val Acc: 0.773196\n",
      "Epoch 17348 - Train Loss: 0.085208, Train Acc: 0.878205 | Val Loss: 0.110801, Val Acc: 0.773196\n",
      "Epoch 17349 - Train Loss: 0.085205, Train Acc: 0.878205 | Val Loss: 0.110799, Val Acc: 0.773196\n",
      "Epoch 17350 - Train Loss: 0.085202, Train Acc: 0.878205 | Val Loss: 0.110798, Val Acc: 0.773196\n",
      "Epoch 17351 - Train Loss: 0.085199, Train Acc: 0.878205 | Val Loss: 0.110796, Val Acc: 0.773196\n",
      "Epoch 17352 - Train Loss: 0.085196, Train Acc: 0.878205 | Val Loss: 0.110795, Val Acc: 0.773196\n",
      "Epoch 17353 - Train Loss: 0.085194, Train Acc: 0.878205 | Val Loss: 0.110793, Val Acc: 0.773196\n",
      "Epoch 17354 - Train Loss: 0.085191, Train Acc: 0.878205 | Val Loss: 0.110791, Val Acc: 0.773196\n",
      "Epoch 17355 - Train Loss: 0.085188, Train Acc: 0.878205 | Val Loss: 0.110790, Val Acc: 0.773196\n",
      "Epoch 17356 - Train Loss: 0.085185, Train Acc: 0.878205 | Val Loss: 0.110788, Val Acc: 0.773196\n",
      "Epoch 17357 - Train Loss: 0.085182, Train Acc: 0.878205 | Val Loss: 0.110787, Val Acc: 0.773196\n",
      "Epoch 17358 - Train Loss: 0.085179, Train Acc: 0.878205 | Val Loss: 0.110785, Val Acc: 0.773196\n",
      "Epoch 17359 - Train Loss: 0.085177, Train Acc: 0.878205 | Val Loss: 0.110783, Val Acc: 0.773196\n",
      "Epoch 17360 - Train Loss: 0.085174, Train Acc: 0.878205 | Val Loss: 0.110782, Val Acc: 0.773196\n",
      "Epoch 17361 - Train Loss: 0.085171, Train Acc: 0.878205 | Val Loss: 0.110780, Val Acc: 0.773196\n",
      "Epoch 17362 - Train Loss: 0.085168, Train Acc: 0.878205 | Val Loss: 0.110779, Val Acc: 0.773196\n",
      "Epoch 17363 - Train Loss: 0.085165, Train Acc: 0.878205 | Val Loss: 0.110777, Val Acc: 0.773196\n",
      "Epoch 17364 - Train Loss: 0.085162, Train Acc: 0.878205 | Val Loss: 0.110776, Val Acc: 0.773196\n",
      "Epoch 17365 - Train Loss: 0.085160, Train Acc: 0.878205 | Val Loss: 0.110774, Val Acc: 0.773196\n",
      "Epoch 17366 - Train Loss: 0.085157, Train Acc: 0.878205 | Val Loss: 0.110773, Val Acc: 0.773196\n",
      "Epoch 17367 - Train Loss: 0.085154, Train Acc: 0.878205 | Val Loss: 0.110771, Val Acc: 0.773196\n",
      "Epoch 17368 - Train Loss: 0.085151, Train Acc: 0.878205 | Val Loss: 0.110769, Val Acc: 0.773196\n",
      "Epoch 17369 - Train Loss: 0.085148, Train Acc: 0.878205 | Val Loss: 0.110768, Val Acc: 0.773196\n",
      "Epoch 17370 - Train Loss: 0.085145, Train Acc: 0.878205 | Val Loss: 0.110766, Val Acc: 0.773196\n",
      "Epoch 17371 - Train Loss: 0.085143, Train Acc: 0.878205 | Val Loss: 0.110765, Val Acc: 0.773196\n",
      "Epoch 17372 - Train Loss: 0.085140, Train Acc: 0.878205 | Val Loss: 0.110763, Val Acc: 0.773196\n",
      "Epoch 17373 - Train Loss: 0.085137, Train Acc: 0.878205 | Val Loss: 0.110762, Val Acc: 0.773196\n",
      "Epoch 17374 - Train Loss: 0.085134, Train Acc: 0.878205 | Val Loss: 0.110760, Val Acc: 0.773196\n",
      "Epoch 17375 - Train Loss: 0.085131, Train Acc: 0.878205 | Val Loss: 0.110758, Val Acc: 0.773196\n",
      "Epoch 17376 - Train Loss: 0.085128, Train Acc: 0.878205 | Val Loss: 0.110757, Val Acc: 0.773196\n",
      "Epoch 17377 - Train Loss: 0.085125, Train Acc: 0.878205 | Val Loss: 0.110755, Val Acc: 0.773196\n",
      "Epoch 17378 - Train Loss: 0.085123, Train Acc: 0.878205 | Val Loss: 0.110754, Val Acc: 0.773196\n",
      "Epoch 17379 - Train Loss: 0.085120, Train Acc: 0.878205 | Val Loss: 0.110752, Val Acc: 0.773196\n",
      "Epoch 17380 - Train Loss: 0.085117, Train Acc: 0.878205 | Val Loss: 0.110751, Val Acc: 0.773196\n",
      "Epoch 17381 - Train Loss: 0.085114, Train Acc: 0.878205 | Val Loss: 0.110749, Val Acc: 0.773196\n",
      "Epoch 17382 - Train Loss: 0.085111, Train Acc: 0.878205 | Val Loss: 0.110747, Val Acc: 0.773196\n",
      "Epoch 17383 - Train Loss: 0.085108, Train Acc: 0.878205 | Val Loss: 0.110746, Val Acc: 0.773196\n",
      "Epoch 17384 - Train Loss: 0.085106, Train Acc: 0.878205 | Val Loss: 0.110744, Val Acc: 0.773196\n",
      "Epoch 17385 - Train Loss: 0.085103, Train Acc: 0.878205 | Val Loss: 0.110743, Val Acc: 0.773196\n",
      "Epoch 17386 - Train Loss: 0.085100, Train Acc: 0.878205 | Val Loss: 0.110741, Val Acc: 0.773196\n",
      "Epoch 17387 - Train Loss: 0.085097, Train Acc: 0.878205 | Val Loss: 0.110740, Val Acc: 0.773196\n",
      "Epoch 17388 - Train Loss: 0.085094, Train Acc: 0.878205 | Val Loss: 0.110738, Val Acc: 0.773196\n",
      "Epoch 17389 - Train Loss: 0.085091, Train Acc: 0.878205 | Val Loss: 0.110736, Val Acc: 0.773196\n",
      "Epoch 17390 - Train Loss: 0.085089, Train Acc: 0.878205 | Val Loss: 0.110735, Val Acc: 0.773196\n",
      "Epoch 17391 - Train Loss: 0.085086, Train Acc: 0.878205 | Val Loss: 0.110733, Val Acc: 0.773196\n",
      "Epoch 17392 - Train Loss: 0.085083, Train Acc: 0.878205 | Val Loss: 0.110732, Val Acc: 0.773196\n",
      "Epoch 17393 - Train Loss: 0.085080, Train Acc: 0.878205 | Val Loss: 0.110730, Val Acc: 0.773196\n",
      "Epoch 17394 - Train Loss: 0.085077, Train Acc: 0.878205 | Val Loss: 0.110729, Val Acc: 0.773196\n",
      "Epoch 17395 - Train Loss: 0.085074, Train Acc: 0.878205 | Val Loss: 0.110727, Val Acc: 0.773196\n",
      "Epoch 17396 - Train Loss: 0.085072, Train Acc: 0.878205 | Val Loss: 0.110726, Val Acc: 0.773196\n",
      "Epoch 17397 - Train Loss: 0.085069, Train Acc: 0.878205 | Val Loss: 0.110724, Val Acc: 0.773196\n",
      "Epoch 17398 - Train Loss: 0.085066, Train Acc: 0.878205 | Val Loss: 0.110722, Val Acc: 0.773196\n",
      "Epoch 17399 - Train Loss: 0.085063, Train Acc: 0.878205 | Val Loss: 0.110721, Val Acc: 0.773196\n",
      "Epoch 17400 - Train Loss: 0.085060, Train Acc: 0.878205 | Val Loss: 0.110719, Val Acc: 0.773196\n",
      "Epoch 17401 - Train Loss: 0.085058, Train Acc: 0.878205 | Val Loss: 0.110718, Val Acc: 0.773196\n",
      "Epoch 17402 - Train Loss: 0.085055, Train Acc: 0.878205 | Val Loss: 0.110716, Val Acc: 0.773196\n",
      "Epoch 17403 - Train Loss: 0.085052, Train Acc: 0.878205 | Val Loss: 0.110715, Val Acc: 0.773196\n",
      "Epoch 17404 - Train Loss: 0.085049, Train Acc: 0.878205 | Val Loss: 0.110713, Val Acc: 0.773196\n",
      "Epoch 17405 - Train Loss: 0.085046, Train Acc: 0.878205 | Val Loss: 0.110711, Val Acc: 0.773196\n",
      "Epoch 17406 - Train Loss: 0.085043, Train Acc: 0.878205 | Val Loss: 0.110710, Val Acc: 0.773196\n",
      "Epoch 17407 - Train Loss: 0.085041, Train Acc: 0.878205 | Val Loss: 0.110708, Val Acc: 0.773196\n",
      "Epoch 17408 - Train Loss: 0.085038, Train Acc: 0.878205 | Val Loss: 0.110707, Val Acc: 0.773196\n",
      "Epoch 17409 - Train Loss: 0.085035, Train Acc: 0.878205 | Val Loss: 0.110705, Val Acc: 0.773196\n",
      "Epoch 17410 - Train Loss: 0.085032, Train Acc: 0.878205 | Val Loss: 0.110704, Val Acc: 0.773196\n",
      "Epoch 17411 - Train Loss: 0.085029, Train Acc: 0.878205 | Val Loss: 0.110702, Val Acc: 0.773196\n",
      "Epoch 17412 - Train Loss: 0.085026, Train Acc: 0.878205 | Val Loss: 0.110701, Val Acc: 0.773196\n",
      "Epoch 17413 - Train Loss: 0.085024, Train Acc: 0.878205 | Val Loss: 0.110699, Val Acc: 0.773196\n",
      "Epoch 17414 - Train Loss: 0.085021, Train Acc: 0.878205 | Val Loss: 0.110697, Val Acc: 0.773196\n",
      "Epoch 17415 - Train Loss: 0.085018, Train Acc: 0.878205 | Val Loss: 0.110696, Val Acc: 0.773196\n",
      "Epoch 17416 - Train Loss: 0.085015, Train Acc: 0.878205 | Val Loss: 0.110694, Val Acc: 0.773196\n",
      "Epoch 17417 - Train Loss: 0.085012, Train Acc: 0.878205 | Val Loss: 0.110693, Val Acc: 0.773196\n",
      "Epoch 17418 - Train Loss: 0.085009, Train Acc: 0.878205 | Val Loss: 0.110691, Val Acc: 0.773196\n",
      "Epoch 17419 - Train Loss: 0.085007, Train Acc: 0.878205 | Val Loss: 0.110690, Val Acc: 0.773196\n",
      "Epoch 17420 - Train Loss: 0.085004, Train Acc: 0.878205 | Val Loss: 0.110688, Val Acc: 0.773196\n",
      "Epoch 17421 - Train Loss: 0.085001, Train Acc: 0.878205 | Val Loss: 0.110687, Val Acc: 0.773196\n",
      "Epoch 17422 - Train Loss: 0.084998, Train Acc: 0.878205 | Val Loss: 0.110685, Val Acc: 0.773196\n",
      "Epoch 17423 - Train Loss: 0.084995, Train Acc: 0.878205 | Val Loss: 0.110683, Val Acc: 0.773196\n",
      "Epoch 17424 - Train Loss: 0.084993, Train Acc: 0.878205 | Val Loss: 0.110682, Val Acc: 0.773196\n",
      "Epoch 17425 - Train Loss: 0.084990, Train Acc: 0.878205 | Val Loss: 0.110680, Val Acc: 0.773196\n",
      "Epoch 17426 - Train Loss: 0.084987, Train Acc: 0.878205 | Val Loss: 0.110679, Val Acc: 0.773196\n",
      "Epoch 17427 - Train Loss: 0.084984, Train Acc: 0.878205 | Val Loss: 0.110677, Val Acc: 0.773196\n",
      "Epoch 17428 - Train Loss: 0.084981, Train Acc: 0.878205 | Val Loss: 0.110676, Val Acc: 0.773196\n",
      "Epoch 17429 - Train Loss: 0.084978, Train Acc: 0.878205 | Val Loss: 0.110674, Val Acc: 0.773196\n",
      "Epoch 17430 - Train Loss: 0.084976, Train Acc: 0.878205 | Val Loss: 0.110673, Val Acc: 0.773196\n",
      "Epoch 17431 - Train Loss: 0.084973, Train Acc: 0.878205 | Val Loss: 0.110671, Val Acc: 0.773196\n",
      "Epoch 17432 - Train Loss: 0.084970, Train Acc: 0.878205 | Val Loss: 0.110670, Val Acc: 0.773196\n",
      "Epoch 17433 - Train Loss: 0.084967, Train Acc: 0.878205 | Val Loss: 0.110668, Val Acc: 0.773196\n",
      "Epoch 17434 - Train Loss: 0.084964, Train Acc: 0.878205 | Val Loss: 0.110666, Val Acc: 0.773196\n",
      "Epoch 17435 - Train Loss: 0.084962, Train Acc: 0.878205 | Val Loss: 0.110665, Val Acc: 0.773196\n",
      "Epoch 17436 - Train Loss: 0.084959, Train Acc: 0.878205 | Val Loss: 0.110663, Val Acc: 0.773196\n",
      "Epoch 17437 - Train Loss: 0.084956, Train Acc: 0.878205 | Val Loss: 0.110662, Val Acc: 0.773196\n",
      "Epoch 17438 - Train Loss: 0.084953, Train Acc: 0.878205 | Val Loss: 0.110660, Val Acc: 0.773196\n",
      "Epoch 17439 - Train Loss: 0.084950, Train Acc: 0.878205 | Val Loss: 0.110659, Val Acc: 0.773196\n",
      "Epoch 17440 - Train Loss: 0.084947, Train Acc: 0.878205 | Val Loss: 0.110657, Val Acc: 0.773196\n",
      "Epoch 17441 - Train Loss: 0.084945, Train Acc: 0.878205 | Val Loss: 0.110656, Val Acc: 0.773196\n",
      "Epoch 17442 - Train Loss: 0.084942, Train Acc: 0.878205 | Val Loss: 0.110654, Val Acc: 0.773196\n",
      "Epoch 17443 - Train Loss: 0.084939, Train Acc: 0.878205 | Val Loss: 0.110653, Val Acc: 0.773196\n",
      "Epoch 17444 - Train Loss: 0.084936, Train Acc: 0.878205 | Val Loss: 0.110651, Val Acc: 0.773196\n",
      "Epoch 17445 - Train Loss: 0.084933, Train Acc: 0.878205 | Val Loss: 0.110649, Val Acc: 0.773196\n",
      "Epoch 17446 - Train Loss: 0.084931, Train Acc: 0.878205 | Val Loss: 0.110648, Val Acc: 0.773196\n",
      "Epoch 17447 - Train Loss: 0.084928, Train Acc: 0.878205 | Val Loss: 0.110646, Val Acc: 0.773196\n",
      "Epoch 17448 - Train Loss: 0.084925, Train Acc: 0.878205 | Val Loss: 0.110645, Val Acc: 0.773196\n",
      "Epoch 17449 - Train Loss: 0.084922, Train Acc: 0.878205 | Val Loss: 0.110643, Val Acc: 0.773196\n",
      "Epoch 17450 - Train Loss: 0.084919, Train Acc: 0.878205 | Val Loss: 0.110642, Val Acc: 0.773196\n",
      "Epoch 17451 - Train Loss: 0.084917, Train Acc: 0.878205 | Val Loss: 0.110640, Val Acc: 0.773196\n",
      "Epoch 17452 - Train Loss: 0.084914, Train Acc: 0.878205 | Val Loss: 0.110639, Val Acc: 0.773196\n",
      "Epoch 17453 - Train Loss: 0.084911, Train Acc: 0.878205 | Val Loss: 0.110637, Val Acc: 0.773196\n",
      "Epoch 17454 - Train Loss: 0.084908, Train Acc: 0.878205 | Val Loss: 0.110636, Val Acc: 0.773196\n",
      "Epoch 17455 - Train Loss: 0.084905, Train Acc: 0.878205 | Val Loss: 0.110634, Val Acc: 0.773196\n",
      "Epoch 17456 - Train Loss: 0.084902, Train Acc: 0.878205 | Val Loss: 0.110632, Val Acc: 0.773196\n",
      "Epoch 17457 - Train Loss: 0.084900, Train Acc: 0.878205 | Val Loss: 0.110631, Val Acc: 0.773196\n",
      "Epoch 17458 - Train Loss: 0.084897, Train Acc: 0.878205 | Val Loss: 0.110629, Val Acc: 0.773196\n",
      "Epoch 17459 - Train Loss: 0.084894, Train Acc: 0.878205 | Val Loss: 0.110628, Val Acc: 0.773196\n",
      "Epoch 17460 - Train Loss: 0.084891, Train Acc: 0.878205 | Val Loss: 0.110626, Val Acc: 0.773196\n",
      "Epoch 17461 - Train Loss: 0.084888, Train Acc: 0.878205 | Val Loss: 0.110625, Val Acc: 0.773196\n",
      "Epoch 17462 - Train Loss: 0.084886, Train Acc: 0.878205 | Val Loss: 0.110623, Val Acc: 0.773196\n",
      "Epoch 17463 - Train Loss: 0.084883, Train Acc: 0.878205 | Val Loss: 0.110622, Val Acc: 0.773196\n",
      "Epoch 17464 - Train Loss: 0.084880, Train Acc: 0.878205 | Val Loss: 0.110620, Val Acc: 0.773196\n",
      "Epoch 17465 - Train Loss: 0.084877, Train Acc: 0.878205 | Val Loss: 0.110619, Val Acc: 0.773196\n",
      "Epoch 17466 - Train Loss: 0.084874, Train Acc: 0.878205 | Val Loss: 0.110617, Val Acc: 0.773196\n",
      "Epoch 17467 - Train Loss: 0.084872, Train Acc: 0.878205 | Val Loss: 0.110615, Val Acc: 0.773196\n",
      "Epoch 17468 - Train Loss: 0.084869, Train Acc: 0.878205 | Val Loss: 0.110614, Val Acc: 0.773196\n",
      "Epoch 17469 - Train Loss: 0.084866, Train Acc: 0.878205 | Val Loss: 0.110612, Val Acc: 0.773196\n",
      "Epoch 17470 - Train Loss: 0.084863, Train Acc: 0.878205 | Val Loss: 0.110611, Val Acc: 0.773196\n",
      "Epoch 17471 - Train Loss: 0.084860, Train Acc: 0.878205 | Val Loss: 0.110609, Val Acc: 0.773196\n",
      "Epoch 17472 - Train Loss: 0.084858, Train Acc: 0.878205 | Val Loss: 0.110608, Val Acc: 0.773196\n",
      "Epoch 17473 - Train Loss: 0.084855, Train Acc: 0.878205 | Val Loss: 0.110606, Val Acc: 0.773196\n",
      "Epoch 17474 - Train Loss: 0.084852, Train Acc: 0.878205 | Val Loss: 0.110605, Val Acc: 0.773196\n",
      "Epoch 17475 - Train Loss: 0.084849, Train Acc: 0.878205 | Val Loss: 0.110603, Val Acc: 0.773196\n",
      "Epoch 17476 - Train Loss: 0.084846, Train Acc: 0.878205 | Val Loss: 0.110602, Val Acc: 0.773196\n",
      "Epoch 17477 - Train Loss: 0.084844, Train Acc: 0.878205 | Val Loss: 0.110600, Val Acc: 0.773196\n",
      "Epoch 17478 - Train Loss: 0.084841, Train Acc: 0.878205 | Val Loss: 0.110599, Val Acc: 0.773196\n",
      "Epoch 17479 - Train Loss: 0.084838, Train Acc: 0.878205 | Val Loss: 0.110597, Val Acc: 0.773196\n",
      "Epoch 17480 - Train Loss: 0.084835, Train Acc: 0.878205 | Val Loss: 0.110596, Val Acc: 0.773196\n",
      "Epoch 17481 - Train Loss: 0.084832, Train Acc: 0.878205 | Val Loss: 0.110594, Val Acc: 0.773196\n",
      "Epoch 17482 - Train Loss: 0.084829, Train Acc: 0.878205 | Val Loss: 0.110592, Val Acc: 0.773196\n",
      "Epoch 17483 - Train Loss: 0.084827, Train Acc: 0.878205 | Val Loss: 0.110591, Val Acc: 0.773196\n",
      "Epoch 17484 - Train Loss: 0.084824, Train Acc: 0.878205 | Val Loss: 0.110589, Val Acc: 0.773196\n",
      "Epoch 17485 - Train Loss: 0.084821, Train Acc: 0.878205 | Val Loss: 0.110588, Val Acc: 0.773196\n",
      "Epoch 17486 - Train Loss: 0.084818, Train Acc: 0.878205 | Val Loss: 0.110586, Val Acc: 0.773196\n",
      "Epoch 17487 - Train Loss: 0.084815, Train Acc: 0.878205 | Val Loss: 0.110585, Val Acc: 0.773196\n",
      "Epoch 17488 - Train Loss: 0.084813, Train Acc: 0.878205 | Val Loss: 0.110583, Val Acc: 0.773196\n",
      "Epoch 17489 - Train Loss: 0.084810, Train Acc: 0.878205 | Val Loss: 0.110582, Val Acc: 0.773196\n",
      "Epoch 17490 - Train Loss: 0.084807, Train Acc: 0.878205 | Val Loss: 0.110580, Val Acc: 0.773196\n",
      "Epoch 17491 - Train Loss: 0.084804, Train Acc: 0.878205 | Val Loss: 0.110579, Val Acc: 0.773196\n",
      "Epoch 17492 - Train Loss: 0.084801, Train Acc: 0.878205 | Val Loss: 0.110577, Val Acc: 0.773196\n",
      "Epoch 17493 - Train Loss: 0.084799, Train Acc: 0.878205 | Val Loss: 0.110576, Val Acc: 0.773196\n",
      "Epoch 17494 - Train Loss: 0.084796, Train Acc: 0.878205 | Val Loss: 0.110574, Val Acc: 0.773196\n",
      "Epoch 17495 - Train Loss: 0.084793, Train Acc: 0.878205 | Val Loss: 0.110573, Val Acc: 0.773196\n",
      "Epoch 17496 - Train Loss: 0.084790, Train Acc: 0.878205 | Val Loss: 0.110571, Val Acc: 0.773196\n",
      "Epoch 17497 - Train Loss: 0.084787, Train Acc: 0.878205 | Val Loss: 0.110570, Val Acc: 0.773196\n",
      "Epoch 17498 - Train Loss: 0.084785, Train Acc: 0.878205 | Val Loss: 0.110568, Val Acc: 0.773196\n",
      "Epoch 17499 - Train Loss: 0.084782, Train Acc: 0.878205 | Val Loss: 0.110566, Val Acc: 0.773196\n",
      "Epoch 17500 - Train Loss: 0.084779, Train Acc: 0.878205 | Val Loss: 0.110565, Val Acc: 0.773196\n",
      "Epoch 17501 - Train Loss: 0.084776, Train Acc: 0.878205 | Val Loss: 0.110563, Val Acc: 0.773196\n",
      "Epoch 17502 - Train Loss: 0.084774, Train Acc: 0.878205 | Val Loss: 0.110562, Val Acc: 0.773196\n",
      "Epoch 17503 - Train Loss: 0.084771, Train Acc: 0.878205 | Val Loss: 0.110560, Val Acc: 0.773196\n",
      "Epoch 17504 - Train Loss: 0.084768, Train Acc: 0.878205 | Val Loss: 0.110559, Val Acc: 0.773196\n",
      "Epoch 17505 - Train Loss: 0.084765, Train Acc: 0.878205 | Val Loss: 0.110557, Val Acc: 0.773196\n",
      "Epoch 17506 - Train Loss: 0.084762, Train Acc: 0.878205 | Val Loss: 0.110556, Val Acc: 0.773196\n",
      "Epoch 17507 - Train Loss: 0.084760, Train Acc: 0.878205 | Val Loss: 0.110554, Val Acc: 0.773196\n",
      "Epoch 17508 - Train Loss: 0.084757, Train Acc: 0.878205 | Val Loss: 0.110553, Val Acc: 0.773196\n",
      "Epoch 17509 - Train Loss: 0.084754, Train Acc: 0.878205 | Val Loss: 0.110551, Val Acc: 0.773196\n",
      "Epoch 17510 - Train Loss: 0.084751, Train Acc: 0.878205 | Val Loss: 0.110550, Val Acc: 0.773196\n",
      "Epoch 17511 - Train Loss: 0.084748, Train Acc: 0.878205 | Val Loss: 0.110548, Val Acc: 0.773196\n",
      "Epoch 17512 - Train Loss: 0.084746, Train Acc: 0.878205 | Val Loss: 0.110547, Val Acc: 0.773196\n",
      "Epoch 17513 - Train Loss: 0.084743, Train Acc: 0.878205 | Val Loss: 0.110545, Val Acc: 0.773196\n",
      "Epoch 17514 - Train Loss: 0.084740, Train Acc: 0.878205 | Val Loss: 0.110544, Val Acc: 0.773196\n",
      "Epoch 17515 - Train Loss: 0.084737, Train Acc: 0.878205 | Val Loss: 0.110542, Val Acc: 0.773196\n",
      "Epoch 17516 - Train Loss: 0.084734, Train Acc: 0.878205 | Val Loss: 0.110540, Val Acc: 0.773196\n",
      "Epoch 17517 - Train Loss: 0.084732, Train Acc: 0.878205 | Val Loss: 0.110539, Val Acc: 0.773196\n",
      "Epoch 17518 - Train Loss: 0.084729, Train Acc: 0.878205 | Val Loss: 0.110537, Val Acc: 0.773196\n",
      "Epoch 17519 - Train Loss: 0.084726, Train Acc: 0.878205 | Val Loss: 0.110536, Val Acc: 0.773196\n",
      "Epoch 17520 - Train Loss: 0.084723, Train Acc: 0.878205 | Val Loss: 0.110534, Val Acc: 0.773196\n",
      "Epoch 17521 - Train Loss: 0.084720, Train Acc: 0.878205 | Val Loss: 0.110533, Val Acc: 0.773196\n",
      "Epoch 17522 - Train Loss: 0.084718, Train Acc: 0.878205 | Val Loss: 0.110531, Val Acc: 0.773196\n",
      "Epoch 17523 - Train Loss: 0.084715, Train Acc: 0.878205 | Val Loss: 0.110530, Val Acc: 0.773196\n",
      "Epoch 17524 - Train Loss: 0.084712, Train Acc: 0.878205 | Val Loss: 0.110528, Val Acc: 0.773196\n",
      "Epoch 17525 - Train Loss: 0.084709, Train Acc: 0.878205 | Val Loss: 0.110527, Val Acc: 0.773196\n",
      "Epoch 17526 - Train Loss: 0.084707, Train Acc: 0.878205 | Val Loss: 0.110525, Val Acc: 0.773196\n",
      "Epoch 17527 - Train Loss: 0.084704, Train Acc: 0.878205 | Val Loss: 0.110524, Val Acc: 0.773196\n",
      "Epoch 17528 - Train Loss: 0.084701, Train Acc: 0.878205 | Val Loss: 0.110522, Val Acc: 0.773196\n",
      "Epoch 17529 - Train Loss: 0.084698, Train Acc: 0.878205 | Val Loss: 0.110521, Val Acc: 0.773196\n",
      "Epoch 17530 - Train Loss: 0.084695, Train Acc: 0.878205 | Val Loss: 0.110519, Val Acc: 0.773196\n",
      "Epoch 17531 - Train Loss: 0.084693, Train Acc: 0.878205 | Val Loss: 0.110518, Val Acc: 0.773196\n",
      "Epoch 17532 - Train Loss: 0.084690, Train Acc: 0.878205 | Val Loss: 0.110516, Val Acc: 0.773196\n",
      "Epoch 17533 - Train Loss: 0.084687, Train Acc: 0.878205 | Val Loss: 0.110515, Val Acc: 0.773196\n",
      "Epoch 17534 - Train Loss: 0.084684, Train Acc: 0.878205 | Val Loss: 0.110513, Val Acc: 0.773196\n",
      "Epoch 17535 - Train Loss: 0.084681, Train Acc: 0.878205 | Val Loss: 0.110512, Val Acc: 0.773196\n",
      "Epoch 17536 - Train Loss: 0.084679, Train Acc: 0.878205 | Val Loss: 0.110510, Val Acc: 0.773196\n",
      "Epoch 17537 - Train Loss: 0.084676, Train Acc: 0.878205 | Val Loss: 0.110509, Val Acc: 0.773196\n",
      "Epoch 17538 - Train Loss: 0.084673, Train Acc: 0.878205 | Val Loss: 0.110507, Val Acc: 0.773196\n",
      "Epoch 17539 - Train Loss: 0.084670, Train Acc: 0.878205 | Val Loss: 0.110505, Val Acc: 0.773196\n",
      "Epoch 17540 - Train Loss: 0.084668, Train Acc: 0.878205 | Val Loss: 0.110504, Val Acc: 0.773196\n",
      "Epoch 17541 - Train Loss: 0.084665, Train Acc: 0.878205 | Val Loss: 0.110502, Val Acc: 0.773196\n",
      "Epoch 17542 - Train Loss: 0.084662, Train Acc: 0.878205 | Val Loss: 0.110501, Val Acc: 0.773196\n",
      "Epoch 17543 - Train Loss: 0.084659, Train Acc: 0.878205 | Val Loss: 0.110499, Val Acc: 0.773196\n",
      "Epoch 17544 - Train Loss: 0.084656, Train Acc: 0.878205 | Val Loss: 0.110498, Val Acc: 0.773196\n",
      "Epoch 17545 - Train Loss: 0.084654, Train Acc: 0.878205 | Val Loss: 0.110496, Val Acc: 0.773196\n",
      "Epoch 17546 - Train Loss: 0.084651, Train Acc: 0.878205 | Val Loss: 0.110495, Val Acc: 0.773196\n",
      "Epoch 17547 - Train Loss: 0.084648, Train Acc: 0.878205 | Val Loss: 0.110493, Val Acc: 0.773196\n",
      "Epoch 17548 - Train Loss: 0.084645, Train Acc: 0.878205 | Val Loss: 0.110492, Val Acc: 0.773196\n",
      "Epoch 17549 - Train Loss: 0.084643, Train Acc: 0.878205 | Val Loss: 0.110490, Val Acc: 0.773196\n",
      "Epoch 17550 - Train Loss: 0.084640, Train Acc: 0.878205 | Val Loss: 0.110489, Val Acc: 0.773196\n",
      "Epoch 17551 - Train Loss: 0.084637, Train Acc: 0.878205 | Val Loss: 0.110487, Val Acc: 0.773196\n",
      "Epoch 17552 - Train Loss: 0.084634, Train Acc: 0.878205 | Val Loss: 0.110486, Val Acc: 0.773196\n",
      "Epoch 17553 - Train Loss: 0.084631, Train Acc: 0.878205 | Val Loss: 0.110484, Val Acc: 0.773196\n",
      "Epoch 17554 - Train Loss: 0.084629, Train Acc: 0.878205 | Val Loss: 0.110483, Val Acc: 0.773196\n",
      "Epoch 17555 - Train Loss: 0.084626, Train Acc: 0.878205 | Val Loss: 0.110481, Val Acc: 0.773196\n",
      "Epoch 17556 - Train Loss: 0.084623, Train Acc: 0.878205 | Val Loss: 0.110480, Val Acc: 0.773196\n",
      "Epoch 17557 - Train Loss: 0.084620, Train Acc: 0.878205 | Val Loss: 0.110478, Val Acc: 0.773196\n",
      "Epoch 17558 - Train Loss: 0.084618, Train Acc: 0.878205 | Val Loss: 0.110477, Val Acc: 0.773196\n",
      "Epoch 17559 - Train Loss: 0.084615, Train Acc: 0.878205 | Val Loss: 0.110475, Val Acc: 0.773196\n",
      "Epoch 17560 - Train Loss: 0.084612, Train Acc: 0.878205 | Val Loss: 0.110474, Val Acc: 0.773196\n",
      "Epoch 17561 - Train Loss: 0.084609, Train Acc: 0.878205 | Val Loss: 0.110472, Val Acc: 0.773196\n",
      "Epoch 17562 - Train Loss: 0.084606, Train Acc: 0.878205 | Val Loss: 0.110471, Val Acc: 0.773196\n",
      "Epoch 17563 - Train Loss: 0.084604, Train Acc: 0.878205 | Val Loss: 0.110469, Val Acc: 0.773196\n",
      "Epoch 17564 - Train Loss: 0.084601, Train Acc: 0.878205 | Val Loss: 0.110468, Val Acc: 0.773196\n",
      "Epoch 17565 - Train Loss: 0.084598, Train Acc: 0.878205 | Val Loss: 0.110466, Val Acc: 0.773196\n",
      "Epoch 17566 - Train Loss: 0.084595, Train Acc: 0.878205 | Val Loss: 0.110465, Val Acc: 0.773196\n",
      "Epoch 17567 - Train Loss: 0.084593, Train Acc: 0.878205 | Val Loss: 0.110463, Val Acc: 0.773196\n",
      "Epoch 17568 - Train Loss: 0.084590, Train Acc: 0.878205 | Val Loss: 0.110462, Val Acc: 0.773196\n",
      "Epoch 17569 - Train Loss: 0.084587, Train Acc: 0.878205 | Val Loss: 0.110460, Val Acc: 0.773196\n",
      "Epoch 17570 - Train Loss: 0.084584, Train Acc: 0.878205 | Val Loss: 0.110459, Val Acc: 0.773196\n",
      "Epoch 17571 - Train Loss: 0.084581, Train Acc: 0.878205 | Val Loss: 0.110457, Val Acc: 0.773196\n",
      "Epoch 17572 - Train Loss: 0.084579, Train Acc: 0.878205 | Val Loss: 0.110456, Val Acc: 0.773196\n",
      "Epoch 17573 - Train Loss: 0.084576, Train Acc: 0.878205 | Val Loss: 0.110454, Val Acc: 0.773196\n",
      "Epoch 17574 - Train Loss: 0.084573, Train Acc: 0.878205 | Val Loss: 0.110453, Val Acc: 0.773196\n",
      "Epoch 17575 - Train Loss: 0.084570, Train Acc: 0.878205 | Val Loss: 0.110451, Val Acc: 0.773196\n",
      "Epoch 17576 - Train Loss: 0.084568, Train Acc: 0.878205 | Val Loss: 0.110450, Val Acc: 0.773196\n",
      "Epoch 17577 - Train Loss: 0.084565, Train Acc: 0.878205 | Val Loss: 0.110448, Val Acc: 0.773196\n",
      "Epoch 17578 - Train Loss: 0.084562, Train Acc: 0.878205 | Val Loss: 0.110447, Val Acc: 0.773196\n",
      "Epoch 17579 - Train Loss: 0.084559, Train Acc: 0.878205 | Val Loss: 0.110445, Val Acc: 0.773196\n",
      "Epoch 17580 - Train Loss: 0.084556, Train Acc: 0.878205 | Val Loss: 0.110444, Val Acc: 0.773196\n",
      "Epoch 17581 - Train Loss: 0.084554, Train Acc: 0.878205 | Val Loss: 0.110442, Val Acc: 0.773196\n",
      "Epoch 17582 - Train Loss: 0.084551, Train Acc: 0.878205 | Val Loss: 0.110441, Val Acc: 0.773196\n",
      "Epoch 17583 - Train Loss: 0.084548, Train Acc: 0.878205 | Val Loss: 0.110439, Val Acc: 0.773196\n",
      "Epoch 17584 - Train Loss: 0.084545, Train Acc: 0.878205 | Val Loss: 0.110438, Val Acc: 0.773196\n",
      "Epoch 17585 - Train Loss: 0.084543, Train Acc: 0.878205 | Val Loss: 0.110436, Val Acc: 0.773196\n",
      "Epoch 17586 - Train Loss: 0.084540, Train Acc: 0.878205 | Val Loss: 0.110435, Val Acc: 0.773196\n",
      "Epoch 17587 - Train Loss: 0.084537, Train Acc: 0.878205 | Val Loss: 0.110433, Val Acc: 0.773196\n",
      "Epoch 17588 - Train Loss: 0.084534, Train Acc: 0.878205 | Val Loss: 0.110431, Val Acc: 0.773196\n",
      "Epoch 17589 - Train Loss: 0.084532, Train Acc: 0.878205 | Val Loss: 0.110430, Val Acc: 0.773196\n",
      "Epoch 17590 - Train Loss: 0.084529, Train Acc: 0.878205 | Val Loss: 0.110428, Val Acc: 0.773196\n",
      "Epoch 17591 - Train Loss: 0.084526, Train Acc: 0.878205 | Val Loss: 0.110427, Val Acc: 0.773196\n",
      "Epoch 17592 - Train Loss: 0.084523, Train Acc: 0.878205 | Val Loss: 0.110425, Val Acc: 0.773196\n",
      "Epoch 17593 - Train Loss: 0.084521, Train Acc: 0.878205 | Val Loss: 0.110424, Val Acc: 0.773196\n",
      "Epoch 17594 - Train Loss: 0.084518, Train Acc: 0.878205 | Val Loss: 0.110422, Val Acc: 0.773196\n",
      "Epoch 17595 - Train Loss: 0.084515, Train Acc: 0.878205 | Val Loss: 0.110421, Val Acc: 0.773196\n",
      "Epoch 17596 - Train Loss: 0.084512, Train Acc: 0.878205 | Val Loss: 0.110420, Val Acc: 0.773196\n",
      "Epoch 17597 - Train Loss: 0.084509, Train Acc: 0.878205 | Val Loss: 0.110418, Val Acc: 0.773196\n",
      "Epoch 17598 - Train Loss: 0.084507, Train Acc: 0.878205 | Val Loss: 0.110417, Val Acc: 0.773196\n",
      "Epoch 17599 - Train Loss: 0.084504, Train Acc: 0.878205 | Val Loss: 0.110415, Val Acc: 0.773196\n",
      "Epoch 17600 - Train Loss: 0.084501, Train Acc: 0.878205 | Val Loss: 0.110414, Val Acc: 0.773196\n",
      "Epoch 17601 - Train Loss: 0.084498, Train Acc: 0.878205 | Val Loss: 0.110412, Val Acc: 0.773196\n",
      "Epoch 17602 - Train Loss: 0.084496, Train Acc: 0.878205 | Val Loss: 0.110410, Val Acc: 0.773196\n",
      "Epoch 17603 - Train Loss: 0.084493, Train Acc: 0.878205 | Val Loss: 0.110409, Val Acc: 0.773196\n",
      "Epoch 17604 - Train Loss: 0.084490, Train Acc: 0.878205 | Val Loss: 0.110408, Val Acc: 0.773196\n",
      "Epoch 17605 - Train Loss: 0.084487, Train Acc: 0.878205 | Val Loss: 0.110406, Val Acc: 0.773196\n",
      "Epoch 17606 - Train Loss: 0.084485, Train Acc: 0.878205 | Val Loss: 0.110405, Val Acc: 0.773196\n",
      "Epoch 17607 - Train Loss: 0.084482, Train Acc: 0.878205 | Val Loss: 0.110403, Val Acc: 0.773196\n",
      "Epoch 17608 - Train Loss: 0.084479, Train Acc: 0.878205 | Val Loss: 0.110402, Val Acc: 0.773196\n",
      "Epoch 17609 - Train Loss: 0.084476, Train Acc: 0.878205 | Val Loss: 0.110400, Val Acc: 0.773196\n",
      "Epoch 17610 - Train Loss: 0.084474, Train Acc: 0.878205 | Val Loss: 0.110399, Val Acc: 0.773196\n",
      "Epoch 17611 - Train Loss: 0.084471, Train Acc: 0.878205 | Val Loss: 0.110397, Val Acc: 0.773196\n",
      "Epoch 17612 - Train Loss: 0.084468, Train Acc: 0.878205 | Val Loss: 0.110396, Val Acc: 0.773196\n",
      "Epoch 17613 - Train Loss: 0.084465, Train Acc: 0.878205 | Val Loss: 0.110394, Val Acc: 0.773196\n",
      "Epoch 17614 - Train Loss: 0.084463, Train Acc: 0.878205 | Val Loss: 0.110393, Val Acc: 0.773196\n",
      "Epoch 17615 - Train Loss: 0.084460, Train Acc: 0.878205 | Val Loss: 0.110391, Val Acc: 0.773196\n",
      "Epoch 17616 - Train Loss: 0.084457, Train Acc: 0.878205 | Val Loss: 0.110390, Val Acc: 0.773196\n",
      "Epoch 17617 - Train Loss: 0.084454, Train Acc: 0.878205 | Val Loss: 0.110388, Val Acc: 0.773196\n",
      "Epoch 17618 - Train Loss: 0.084451, Train Acc: 0.878205 | Val Loss: 0.110387, Val Acc: 0.773196\n",
      "Epoch 17619 - Train Loss: 0.084449, Train Acc: 0.878205 | Val Loss: 0.110385, Val Acc: 0.773196\n",
      "Epoch 17620 - Train Loss: 0.084446, Train Acc: 0.878205 | Val Loss: 0.110384, Val Acc: 0.773196\n",
      "Epoch 17621 - Train Loss: 0.084443, Train Acc: 0.878205 | Val Loss: 0.110382, Val Acc: 0.773196\n",
      "Epoch 17622 - Train Loss: 0.084440, Train Acc: 0.878205 | Val Loss: 0.110381, Val Acc: 0.773196\n",
      "Epoch 17623 - Train Loss: 0.084438, Train Acc: 0.878205 | Val Loss: 0.110379, Val Acc: 0.773196\n",
      "Epoch 17624 - Train Loss: 0.084435, Train Acc: 0.878205 | Val Loss: 0.110378, Val Acc: 0.773196\n",
      "Epoch 17625 - Train Loss: 0.084432, Train Acc: 0.878205 | Val Loss: 0.110376, Val Acc: 0.773196\n",
      "Epoch 17626 - Train Loss: 0.084429, Train Acc: 0.878205 | Val Loss: 0.110375, Val Acc: 0.773196\n",
      "Epoch 17627 - Train Loss: 0.084427, Train Acc: 0.878205 | Val Loss: 0.110373, Val Acc: 0.773196\n",
      "Epoch 17628 - Train Loss: 0.084424, Train Acc: 0.878205 | Val Loss: 0.110372, Val Acc: 0.773196\n",
      "Epoch 17629 - Train Loss: 0.084421, Train Acc: 0.878205 | Val Loss: 0.110370, Val Acc: 0.773196\n",
      "Epoch 17630 - Train Loss: 0.084418, Train Acc: 0.878205 | Val Loss: 0.110369, Val Acc: 0.773196\n",
      "Epoch 17631 - Train Loss: 0.084416, Train Acc: 0.878205 | Val Loss: 0.110367, Val Acc: 0.773196\n",
      "Epoch 17632 - Train Loss: 0.084413, Train Acc: 0.878205 | Val Loss: 0.110366, Val Acc: 0.773196\n",
      "Epoch 17633 - Train Loss: 0.084410, Train Acc: 0.878205 | Val Loss: 0.110364, Val Acc: 0.773196\n",
      "Epoch 17634 - Train Loss: 0.084407, Train Acc: 0.878205 | Val Loss: 0.110363, Val Acc: 0.773196\n",
      "Epoch 17635 - Train Loss: 0.084405, Train Acc: 0.878205 | Val Loss: 0.110361, Val Acc: 0.773196\n",
      "Epoch 17636 - Train Loss: 0.084402, Train Acc: 0.878205 | Val Loss: 0.110360, Val Acc: 0.773196\n",
      "Epoch 17637 - Train Loss: 0.084399, Train Acc: 0.878205 | Val Loss: 0.110358, Val Acc: 0.773196\n",
      "Epoch 17638 - Train Loss: 0.084396, Train Acc: 0.878205 | Val Loss: 0.110357, Val Acc: 0.773196\n",
      "Epoch 17639 - Train Loss: 0.084394, Train Acc: 0.878205 | Val Loss: 0.110355, Val Acc: 0.773196\n",
      "Epoch 17640 - Train Loss: 0.084391, Train Acc: 0.878205 | Val Loss: 0.110354, Val Acc: 0.773196\n",
      "Epoch 17641 - Train Loss: 0.084388, Train Acc: 0.878205 | Val Loss: 0.110352, Val Acc: 0.773196\n",
      "Epoch 17642 - Train Loss: 0.084385, Train Acc: 0.878205 | Val Loss: 0.110351, Val Acc: 0.773196\n",
      "Epoch 17643 - Train Loss: 0.084383, Train Acc: 0.878205 | Val Loss: 0.110349, Val Acc: 0.773196\n",
      "Epoch 17644 - Train Loss: 0.084380, Train Acc: 0.878205 | Val Loss: 0.110348, Val Acc: 0.773196\n",
      "Epoch 17645 - Train Loss: 0.084377, Train Acc: 0.878205 | Val Loss: 0.110346, Val Acc: 0.773196\n",
      "Epoch 17646 - Train Loss: 0.084374, Train Acc: 0.878205 | Val Loss: 0.110345, Val Acc: 0.773196\n",
      "Epoch 17647 - Train Loss: 0.084372, Train Acc: 0.878205 | Val Loss: 0.110343, Val Acc: 0.773196\n",
      "Epoch 17648 - Train Loss: 0.084369, Train Acc: 0.878205 | Val Loss: 0.110342, Val Acc: 0.773196\n",
      "Epoch 17649 - Train Loss: 0.084366, Train Acc: 0.878205 | Val Loss: 0.110341, Val Acc: 0.773196\n",
      "Epoch 17650 - Train Loss: 0.084363, Train Acc: 0.878205 | Val Loss: 0.110339, Val Acc: 0.773196\n",
      "Epoch 17651 - Train Loss: 0.084361, Train Acc: 0.878205 | Val Loss: 0.110338, Val Acc: 0.773196\n",
      "Epoch 17652 - Train Loss: 0.084358, Train Acc: 0.878205 | Val Loss: 0.110336, Val Acc: 0.773196\n",
      "Epoch 17653 - Train Loss: 0.084355, Train Acc: 0.878205 | Val Loss: 0.110335, Val Acc: 0.773196\n",
      "Epoch 17654 - Train Loss: 0.084352, Train Acc: 0.878205 | Val Loss: 0.110333, Val Acc: 0.773196\n",
      "Epoch 17655 - Train Loss: 0.084350, Train Acc: 0.878205 | Val Loss: 0.110332, Val Acc: 0.773196\n",
      "Epoch 17656 - Train Loss: 0.084347, Train Acc: 0.878205 | Val Loss: 0.110330, Val Acc: 0.773196\n",
      "Epoch 17657 - Train Loss: 0.084344, Train Acc: 0.878205 | Val Loss: 0.110329, Val Acc: 0.773196\n",
      "Epoch 17658 - Train Loss: 0.084341, Train Acc: 0.878205 | Val Loss: 0.110327, Val Acc: 0.773196\n",
      "Epoch 17659 - Train Loss: 0.084339, Train Acc: 0.878205 | Val Loss: 0.110326, Val Acc: 0.773196\n",
      "Epoch 17660 - Train Loss: 0.084336, Train Acc: 0.878205 | Val Loss: 0.110324, Val Acc: 0.773196\n",
      "Epoch 17661 - Train Loss: 0.084333, Train Acc: 0.878205 | Val Loss: 0.110323, Val Acc: 0.773196\n",
      "Epoch 17662 - Train Loss: 0.084330, Train Acc: 0.878205 | Val Loss: 0.110321, Val Acc: 0.773196\n",
      "Epoch 17663 - Train Loss: 0.084328, Train Acc: 0.878205 | Val Loss: 0.110320, Val Acc: 0.773196\n",
      "Epoch 17664 - Train Loss: 0.084325, Train Acc: 0.878205 | Val Loss: 0.110318, Val Acc: 0.773196\n",
      "Epoch 17665 - Train Loss: 0.084322, Train Acc: 0.878205 | Val Loss: 0.110317, Val Acc: 0.773196\n",
      "Epoch 17666 - Train Loss: 0.084319, Train Acc: 0.878205 | Val Loss: 0.110315, Val Acc: 0.773196\n",
      "Epoch 17667 - Train Loss: 0.084317, Train Acc: 0.878205 | Val Loss: 0.110314, Val Acc: 0.773196\n",
      "Epoch 17668 - Train Loss: 0.084314, Train Acc: 0.878205 | Val Loss: 0.110312, Val Acc: 0.773196\n",
      "Epoch 17669 - Train Loss: 0.084311, Train Acc: 0.878205 | Val Loss: 0.110311, Val Acc: 0.773196\n",
      "Epoch 17670 - Train Loss: 0.084309, Train Acc: 0.878205 | Val Loss: 0.110309, Val Acc: 0.773196\n",
      "Epoch 17671 - Train Loss: 0.084306, Train Acc: 0.878205 | Val Loss: 0.110308, Val Acc: 0.773196\n",
      "Epoch 17672 - Train Loss: 0.084303, Train Acc: 0.878205 | Val Loss: 0.110307, Val Acc: 0.773196\n",
      "Epoch 17673 - Train Loss: 0.084300, Train Acc: 0.878205 | Val Loss: 0.110305, Val Acc: 0.773196\n",
      "Epoch 17674 - Train Loss: 0.084298, Train Acc: 0.878205 | Val Loss: 0.110304, Val Acc: 0.773196\n",
      "Epoch 17675 - Train Loss: 0.084295, Train Acc: 0.878205 | Val Loss: 0.110302, Val Acc: 0.773196\n",
      "Epoch 17676 - Train Loss: 0.084292, Train Acc: 0.878205 | Val Loss: 0.110301, Val Acc: 0.773196\n",
      "Epoch 17677 - Train Loss: 0.084289, Train Acc: 0.878205 | Val Loss: 0.110299, Val Acc: 0.773196\n",
      "Epoch 17678 - Train Loss: 0.084287, Train Acc: 0.878205 | Val Loss: 0.110298, Val Acc: 0.773196\n",
      "Epoch 17679 - Train Loss: 0.084284, Train Acc: 0.878205 | Val Loss: 0.110296, Val Acc: 0.773196\n",
      "Epoch 17680 - Train Loss: 0.084281, Train Acc: 0.878205 | Val Loss: 0.110295, Val Acc: 0.773196\n",
      "Epoch 17681 - Train Loss: 0.084278, Train Acc: 0.878205 | Val Loss: 0.110293, Val Acc: 0.773196\n",
      "Epoch 17682 - Train Loss: 0.084276, Train Acc: 0.878205 | Val Loss: 0.110292, Val Acc: 0.773196\n",
      "Epoch 17683 - Train Loss: 0.084273, Train Acc: 0.878205 | Val Loss: 0.110290, Val Acc: 0.773196\n",
      "Epoch 17684 - Train Loss: 0.084270, Train Acc: 0.878205 | Val Loss: 0.110289, Val Acc: 0.773196\n",
      "Epoch 17685 - Train Loss: 0.084267, Train Acc: 0.878205 | Val Loss: 0.110287, Val Acc: 0.773196\n",
      "Epoch 17686 - Train Loss: 0.084265, Train Acc: 0.878205 | Val Loss: 0.110286, Val Acc: 0.773196\n",
      "Epoch 17687 - Train Loss: 0.084262, Train Acc: 0.878205 | Val Loss: 0.110284, Val Acc: 0.773196\n",
      "Epoch 17688 - Train Loss: 0.084259, Train Acc: 0.878205 | Val Loss: 0.110283, Val Acc: 0.773196\n",
      "Epoch 17689 - Train Loss: 0.084256, Train Acc: 0.878205 | Val Loss: 0.110281, Val Acc: 0.773196\n",
      "Epoch 17690 - Train Loss: 0.084254, Train Acc: 0.878205 | Val Loss: 0.110280, Val Acc: 0.773196\n",
      "Epoch 17691 - Train Loss: 0.084251, Train Acc: 0.878205 | Val Loss: 0.110279, Val Acc: 0.773196\n",
      "Epoch 17692 - Train Loss: 0.084248, Train Acc: 0.878205 | Val Loss: 0.110277, Val Acc: 0.773196\n",
      "Epoch 17693 - Train Loss: 0.084246, Train Acc: 0.878205 | Val Loss: 0.110276, Val Acc: 0.773196\n",
      "Epoch 17694 - Train Loss: 0.084243, Train Acc: 0.878205 | Val Loss: 0.110274, Val Acc: 0.773196\n",
      "Epoch 17695 - Train Loss: 0.084240, Train Acc: 0.878205 | Val Loss: 0.110273, Val Acc: 0.773196\n",
      "Epoch 17696 - Train Loss: 0.084237, Train Acc: 0.878205 | Val Loss: 0.110271, Val Acc: 0.773196\n",
      "Epoch 17697 - Train Loss: 0.084235, Train Acc: 0.878205 | Val Loss: 0.110270, Val Acc: 0.773196\n",
      "Epoch 17698 - Train Loss: 0.084232, Train Acc: 0.878205 | Val Loss: 0.110268, Val Acc: 0.773196\n",
      "Epoch 17699 - Train Loss: 0.084229, Train Acc: 0.878205 | Val Loss: 0.110267, Val Acc: 0.773196\n",
      "Epoch 17700 - Train Loss: 0.084226, Train Acc: 0.878205 | Val Loss: 0.110265, Val Acc: 0.773196\n",
      "Epoch 17701 - Train Loss: 0.084224, Train Acc: 0.878205 | Val Loss: 0.110264, Val Acc: 0.773196\n",
      "Epoch 17702 - Train Loss: 0.084221, Train Acc: 0.878205 | Val Loss: 0.110262, Val Acc: 0.773196\n",
      "Epoch 17703 - Train Loss: 0.084218, Train Acc: 0.878205 | Val Loss: 0.110261, Val Acc: 0.773196\n",
      "Epoch 17704 - Train Loss: 0.084215, Train Acc: 0.878205 | Val Loss: 0.110259, Val Acc: 0.773196\n",
      "Epoch 17705 - Train Loss: 0.084213, Train Acc: 0.878205 | Val Loss: 0.110258, Val Acc: 0.773196\n",
      "Epoch 17706 - Train Loss: 0.084210, Train Acc: 0.878205 | Val Loss: 0.110256, Val Acc: 0.773196\n",
      "Epoch 17707 - Train Loss: 0.084207, Train Acc: 0.878205 | Val Loss: 0.110255, Val Acc: 0.773196\n",
      "Epoch 17708 - Train Loss: 0.084205, Train Acc: 0.878205 | Val Loss: 0.110254, Val Acc: 0.773196\n",
      "Epoch 17709 - Train Loss: 0.084202, Train Acc: 0.878205 | Val Loss: 0.110252, Val Acc: 0.773196\n",
      "Epoch 17710 - Train Loss: 0.084199, Train Acc: 0.878205 | Val Loss: 0.110251, Val Acc: 0.773196\n",
      "Epoch 17711 - Train Loss: 0.084196, Train Acc: 0.878205 | Val Loss: 0.110249, Val Acc: 0.773196\n",
      "Epoch 17712 - Train Loss: 0.084194, Train Acc: 0.878205 | Val Loss: 0.110248, Val Acc: 0.773196\n",
      "Epoch 17713 - Train Loss: 0.084191, Train Acc: 0.878205 | Val Loss: 0.110246, Val Acc: 0.773196\n",
      "Epoch 17714 - Train Loss: 0.084188, Train Acc: 0.878205 | Val Loss: 0.110245, Val Acc: 0.773196\n",
      "Epoch 17715 - Train Loss: 0.084185, Train Acc: 0.878205 | Val Loss: 0.110243, Val Acc: 0.773196\n",
      "Epoch 17716 - Train Loss: 0.084183, Train Acc: 0.878205 | Val Loss: 0.110242, Val Acc: 0.773196\n",
      "Epoch 17717 - Train Loss: 0.084180, Train Acc: 0.878205 | Val Loss: 0.110240, Val Acc: 0.773196\n",
      "Epoch 17718 - Train Loss: 0.084177, Train Acc: 0.878205 | Val Loss: 0.110239, Val Acc: 0.773196\n",
      "Epoch 17719 - Train Loss: 0.084175, Train Acc: 0.878205 | Val Loss: 0.110237, Val Acc: 0.773196\n",
      "Epoch 17720 - Train Loss: 0.084172, Train Acc: 0.878205 | Val Loss: 0.110236, Val Acc: 0.773196\n",
      "Epoch 17721 - Train Loss: 0.084169, Train Acc: 0.878205 | Val Loss: 0.110235, Val Acc: 0.773196\n",
      "Epoch 17722 - Train Loss: 0.084166, Train Acc: 0.878205 | Val Loss: 0.110233, Val Acc: 0.773196\n",
      "Epoch 17723 - Train Loss: 0.084164, Train Acc: 0.878205 | Val Loss: 0.110232, Val Acc: 0.773196\n",
      "Epoch 17724 - Train Loss: 0.084161, Train Acc: 0.878205 | Val Loss: 0.110230, Val Acc: 0.773196\n",
      "Epoch 17725 - Train Loss: 0.084158, Train Acc: 0.878205 | Val Loss: 0.110229, Val Acc: 0.773196\n",
      "Epoch 17726 - Train Loss: 0.084155, Train Acc: 0.878205 | Val Loss: 0.110227, Val Acc: 0.773196\n",
      "Epoch 17727 - Train Loss: 0.084153, Train Acc: 0.878205 | Val Loss: 0.110226, Val Acc: 0.773196\n",
      "Epoch 17728 - Train Loss: 0.084150, Train Acc: 0.878205 | Val Loss: 0.110224, Val Acc: 0.773196\n",
      "Epoch 17729 - Train Loss: 0.084147, Train Acc: 0.878205 | Val Loss: 0.110223, Val Acc: 0.773196\n",
      "Epoch 17730 - Train Loss: 0.084145, Train Acc: 0.878205 | Val Loss: 0.110221, Val Acc: 0.773196\n",
      "Epoch 17731 - Train Loss: 0.084142, Train Acc: 0.878205 | Val Loss: 0.110220, Val Acc: 0.773196\n",
      "Epoch 17732 - Train Loss: 0.084139, Train Acc: 0.878205 | Val Loss: 0.110219, Val Acc: 0.773196\n",
      "Epoch 17733 - Train Loss: 0.084136, Train Acc: 0.878205 | Val Loss: 0.110217, Val Acc: 0.773196\n",
      "Epoch 17734 - Train Loss: 0.084134, Train Acc: 0.878205 | Val Loss: 0.110216, Val Acc: 0.773196\n",
      "Epoch 17735 - Train Loss: 0.084131, Train Acc: 0.878205 | Val Loss: 0.110214, Val Acc: 0.773196\n",
      "Epoch 17736 - Train Loss: 0.084128, Train Acc: 0.878205 | Val Loss: 0.110213, Val Acc: 0.773196\n",
      "Epoch 17737 - Train Loss: 0.084126, Train Acc: 0.878205 | Val Loss: 0.110211, Val Acc: 0.773196\n",
      "Epoch 17738 - Train Loss: 0.084123, Train Acc: 0.878205 | Val Loss: 0.110210, Val Acc: 0.773196\n",
      "Epoch 17739 - Train Loss: 0.084120, Train Acc: 0.878205 | Val Loss: 0.110208, Val Acc: 0.773196\n",
      "Epoch 17740 - Train Loss: 0.084117, Train Acc: 0.878205 | Val Loss: 0.110207, Val Acc: 0.773196\n",
      "Epoch 17741 - Train Loss: 0.084115, Train Acc: 0.878205 | Val Loss: 0.110205, Val Acc: 0.773196\n",
      "Epoch 17742 - Train Loss: 0.084112, Train Acc: 0.878205 | Val Loss: 0.110204, Val Acc: 0.773196\n",
      "Epoch 17743 - Train Loss: 0.084109, Train Acc: 0.878205 | Val Loss: 0.110202, Val Acc: 0.773196\n",
      "Epoch 17744 - Train Loss: 0.084107, Train Acc: 0.878205 | Val Loss: 0.110201, Val Acc: 0.773196\n",
      "Epoch 17745 - Train Loss: 0.084104, Train Acc: 0.878205 | Val Loss: 0.110200, Val Acc: 0.773196\n",
      "Epoch 17746 - Train Loss: 0.084101, Train Acc: 0.878205 | Val Loss: 0.110198, Val Acc: 0.773196\n",
      "Epoch 17747 - Train Loss: 0.084098, Train Acc: 0.878205 | Val Loss: 0.110197, Val Acc: 0.773196\n",
      "Epoch 17748 - Train Loss: 0.084096, Train Acc: 0.878205 | Val Loss: 0.110195, Val Acc: 0.773196\n",
      "Epoch 17749 - Train Loss: 0.084093, Train Acc: 0.878205 | Val Loss: 0.110194, Val Acc: 0.773196\n",
      "Epoch 17750 - Train Loss: 0.084090, Train Acc: 0.878205 | Val Loss: 0.110192, Val Acc: 0.773196\n",
      "Epoch 17751 - Train Loss: 0.084087, Train Acc: 0.878205 | Val Loss: 0.110191, Val Acc: 0.773196\n",
      "Epoch 17752 - Train Loss: 0.084085, Train Acc: 0.878205 | Val Loss: 0.110189, Val Acc: 0.773196\n",
      "Epoch 17753 - Train Loss: 0.084082, Train Acc: 0.878205 | Val Loss: 0.110188, Val Acc: 0.773196\n",
      "Epoch 17754 - Train Loss: 0.084079, Train Acc: 0.878205 | Val Loss: 0.110186, Val Acc: 0.773196\n",
      "Epoch 17755 - Train Loss: 0.084077, Train Acc: 0.878205 | Val Loss: 0.110185, Val Acc: 0.773196\n",
      "Epoch 17756 - Train Loss: 0.084074, Train Acc: 0.878205 | Val Loss: 0.110184, Val Acc: 0.773196\n",
      "Epoch 17757 - Train Loss: 0.084071, Train Acc: 0.878205 | Val Loss: 0.110182, Val Acc: 0.773196\n",
      "Epoch 17758 - Train Loss: 0.084068, Train Acc: 0.878205 | Val Loss: 0.110181, Val Acc: 0.773196\n",
      "Epoch 17759 - Train Loss: 0.084066, Train Acc: 0.878205 | Val Loss: 0.110179, Val Acc: 0.773196\n",
      "Epoch 17760 - Train Loss: 0.084063, Train Acc: 0.878205 | Val Loss: 0.110178, Val Acc: 0.773196\n",
      "Epoch 17761 - Train Loss: 0.084060, Train Acc: 0.878205 | Val Loss: 0.110176, Val Acc: 0.773196\n",
      "Epoch 17762 - Train Loss: 0.084058, Train Acc: 0.878205 | Val Loss: 0.110175, Val Acc: 0.773196\n",
      "Epoch 17763 - Train Loss: 0.084055, Train Acc: 0.878205 | Val Loss: 0.110173, Val Acc: 0.773196\n",
      "Epoch 17764 - Train Loss: 0.084052, Train Acc: 0.878205 | Val Loss: 0.110172, Val Acc: 0.773196\n",
      "Epoch 17765 - Train Loss: 0.084050, Train Acc: 0.878205 | Val Loss: 0.110171, Val Acc: 0.773196\n",
      "Epoch 17766 - Train Loss: 0.084047, Train Acc: 0.878205 | Val Loss: 0.110169, Val Acc: 0.773196\n",
      "Epoch 17767 - Train Loss: 0.084044, Train Acc: 0.878205 | Val Loss: 0.110168, Val Acc: 0.773196\n",
      "Epoch 17768 - Train Loss: 0.084041, Train Acc: 0.878205 | Val Loss: 0.110166, Val Acc: 0.773196\n",
      "Epoch 17769 - Train Loss: 0.084039, Train Acc: 0.878205 | Val Loss: 0.110165, Val Acc: 0.773196\n",
      "Epoch 17770 - Train Loss: 0.084036, Train Acc: 0.878205 | Val Loss: 0.110163, Val Acc: 0.773196\n",
      "Epoch 17771 - Train Loss: 0.084033, Train Acc: 0.878205 | Val Loss: 0.110162, Val Acc: 0.773196\n",
      "Epoch 17772 - Train Loss: 0.084031, Train Acc: 0.878205 | Val Loss: 0.110160, Val Acc: 0.773196\n",
      "Epoch 17773 - Train Loss: 0.084028, Train Acc: 0.878205 | Val Loss: 0.110159, Val Acc: 0.773196\n",
      "Epoch 17774 - Train Loss: 0.084025, Train Acc: 0.878205 | Val Loss: 0.110157, Val Acc: 0.773196\n",
      "Epoch 17775 - Train Loss: 0.084022, Train Acc: 0.878205 | Val Loss: 0.110156, Val Acc: 0.773196\n",
      "Epoch 17776 - Train Loss: 0.084020, Train Acc: 0.878205 | Val Loss: 0.110155, Val Acc: 0.773196\n",
      "Epoch 17777 - Train Loss: 0.084017, Train Acc: 0.878205 | Val Loss: 0.110153, Val Acc: 0.773196\n",
      "Epoch 17778 - Train Loss: 0.084014, Train Acc: 0.878205 | Val Loss: 0.110152, Val Acc: 0.773196\n",
      "Epoch 17779 - Train Loss: 0.084012, Train Acc: 0.878205 | Val Loss: 0.110150, Val Acc: 0.773196\n",
      "Epoch 17780 - Train Loss: 0.084009, Train Acc: 0.878205 | Val Loss: 0.110149, Val Acc: 0.773196\n",
      "Epoch 17781 - Train Loss: 0.084006, Train Acc: 0.878205 | Val Loss: 0.110147, Val Acc: 0.773196\n",
      "Epoch 17782 - Train Loss: 0.084003, Train Acc: 0.878205 | Val Loss: 0.110146, Val Acc: 0.773196\n",
      "Epoch 17783 - Train Loss: 0.084001, Train Acc: 0.878205 | Val Loss: 0.110144, Val Acc: 0.773196\n",
      "Epoch 17784 - Train Loss: 0.083998, Train Acc: 0.878205 | Val Loss: 0.110143, Val Acc: 0.773196\n",
      "Epoch 17785 - Train Loss: 0.083995, Train Acc: 0.878205 | Val Loss: 0.110142, Val Acc: 0.773196\n",
      "Epoch 17786 - Train Loss: 0.083993, Train Acc: 0.878205 | Val Loss: 0.110140, Val Acc: 0.773196\n",
      "Epoch 17787 - Train Loss: 0.083990, Train Acc: 0.878205 | Val Loss: 0.110139, Val Acc: 0.773196\n",
      "Epoch 17788 - Train Loss: 0.083987, Train Acc: 0.878205 | Val Loss: 0.110137, Val Acc: 0.773196\n",
      "Epoch 17789 - Train Loss: 0.083985, Train Acc: 0.878205 | Val Loss: 0.110136, Val Acc: 0.773196\n",
      "Epoch 17790 - Train Loss: 0.083982, Train Acc: 0.878205 | Val Loss: 0.110134, Val Acc: 0.773196\n",
      "Epoch 17791 - Train Loss: 0.083979, Train Acc: 0.878205 | Val Loss: 0.110133, Val Acc: 0.773196\n",
      "Epoch 17792 - Train Loss: 0.083976, Train Acc: 0.878205 | Val Loss: 0.110131, Val Acc: 0.773196\n",
      "Epoch 17793 - Train Loss: 0.083974, Train Acc: 0.878205 | Val Loss: 0.110130, Val Acc: 0.773196\n",
      "Epoch 17794 - Train Loss: 0.083971, Train Acc: 0.878205 | Val Loss: 0.110129, Val Acc: 0.773196\n",
      "Epoch 17795 - Train Loss: 0.083968, Train Acc: 0.878205 | Val Loss: 0.110127, Val Acc: 0.773196\n",
      "Epoch 17796 - Train Loss: 0.083966, Train Acc: 0.878205 | Val Loss: 0.110126, Val Acc: 0.773196\n",
      "Epoch 17797 - Train Loss: 0.083963, Train Acc: 0.878205 | Val Loss: 0.110124, Val Acc: 0.773196\n",
      "Epoch 17798 - Train Loss: 0.083960, Train Acc: 0.878205 | Val Loss: 0.110123, Val Acc: 0.773196\n",
      "Epoch 17799 - Train Loss: 0.083957, Train Acc: 0.878205 | Val Loss: 0.110121, Val Acc: 0.773196\n",
      "Epoch 17800 - Train Loss: 0.083955, Train Acc: 0.878205 | Val Loss: 0.110120, Val Acc: 0.773196\n",
      "Epoch 17801 - Train Loss: 0.083952, Train Acc: 0.878205 | Val Loss: 0.110119, Val Acc: 0.773196\n",
      "Epoch 17802 - Train Loss: 0.083949, Train Acc: 0.878205 | Val Loss: 0.110117, Val Acc: 0.773196\n",
      "Epoch 17803 - Train Loss: 0.083947, Train Acc: 0.878205 | Val Loss: 0.110116, Val Acc: 0.773196\n",
      "Epoch 17804 - Train Loss: 0.083944, Train Acc: 0.878205 | Val Loss: 0.110114, Val Acc: 0.773196\n",
      "Epoch 17805 - Train Loss: 0.083941, Train Acc: 0.878205 | Val Loss: 0.110113, Val Acc: 0.773196\n",
      "Epoch 17806 - Train Loss: 0.083939, Train Acc: 0.878205 | Val Loss: 0.110111, Val Acc: 0.773196\n",
      "Epoch 17807 - Train Loss: 0.083936, Train Acc: 0.878205 | Val Loss: 0.110110, Val Acc: 0.773196\n",
      "Epoch 17808 - Train Loss: 0.083933, Train Acc: 0.878205 | Val Loss: 0.110108, Val Acc: 0.773196\n",
      "Epoch 17809 - Train Loss: 0.083930, Train Acc: 0.878205 | Val Loss: 0.110107, Val Acc: 0.773196\n",
      "Epoch 17810 - Train Loss: 0.083928, Train Acc: 0.878205 | Val Loss: 0.110106, Val Acc: 0.773196\n",
      "Epoch 17811 - Train Loss: 0.083925, Train Acc: 0.878205 | Val Loss: 0.110104, Val Acc: 0.773196\n",
      "Epoch 17812 - Train Loss: 0.083922, Train Acc: 0.878205 | Val Loss: 0.110103, Val Acc: 0.773196\n",
      "Epoch 17813 - Train Loss: 0.083920, Train Acc: 0.878205 | Val Loss: 0.110101, Val Acc: 0.773196\n",
      "Epoch 17814 - Train Loss: 0.083917, Train Acc: 0.878205 | Val Loss: 0.110100, Val Acc: 0.773196\n",
      "Epoch 17815 - Train Loss: 0.083914, Train Acc: 0.878205 | Val Loss: 0.110098, Val Acc: 0.773196\n",
      "Epoch 17816 - Train Loss: 0.083912, Train Acc: 0.878205 | Val Loss: 0.110097, Val Acc: 0.773196\n",
      "Epoch 17817 - Train Loss: 0.083909, Train Acc: 0.878205 | Val Loss: 0.110096, Val Acc: 0.773196\n",
      "Epoch 17818 - Train Loss: 0.083906, Train Acc: 0.878205 | Val Loss: 0.110094, Val Acc: 0.773196\n",
      "Epoch 17819 - Train Loss: 0.083904, Train Acc: 0.878205 | Val Loss: 0.110093, Val Acc: 0.773196\n",
      "Epoch 17820 - Train Loss: 0.083901, Train Acc: 0.878205 | Val Loss: 0.110091, Val Acc: 0.773196\n",
      "Epoch 17821 - Train Loss: 0.083898, Train Acc: 0.878205 | Val Loss: 0.110090, Val Acc: 0.773196\n",
      "Epoch 17822 - Train Loss: 0.083895, Train Acc: 0.878205 | Val Loss: 0.110088, Val Acc: 0.773196\n",
      "Epoch 17823 - Train Loss: 0.083893, Train Acc: 0.878205 | Val Loss: 0.110087, Val Acc: 0.773196\n",
      "Epoch 17824 - Train Loss: 0.083890, Train Acc: 0.878205 | Val Loss: 0.110086, Val Acc: 0.773196\n",
      "Epoch 17825 - Train Loss: 0.083887, Train Acc: 0.878205 | Val Loss: 0.110084, Val Acc: 0.773196\n",
      "Epoch 17826 - Train Loss: 0.083885, Train Acc: 0.878205 | Val Loss: 0.110083, Val Acc: 0.773196\n",
      "Epoch 17827 - Train Loss: 0.083882, Train Acc: 0.878205 | Val Loss: 0.110081, Val Acc: 0.773196\n",
      "Epoch 17828 - Train Loss: 0.083879, Train Acc: 0.878205 | Val Loss: 0.110080, Val Acc: 0.773196\n",
      "Epoch 17829 - Train Loss: 0.083877, Train Acc: 0.878205 | Val Loss: 0.110078, Val Acc: 0.773196\n",
      "Epoch 17830 - Train Loss: 0.083874, Train Acc: 0.878205 | Val Loss: 0.110077, Val Acc: 0.773196\n",
      "Epoch 17831 - Train Loss: 0.083871, Train Acc: 0.878205 | Val Loss: 0.110075, Val Acc: 0.773196\n",
      "Epoch 17832 - Train Loss: 0.083869, Train Acc: 0.878205 | Val Loss: 0.110074, Val Acc: 0.773196\n",
      "Epoch 17833 - Train Loss: 0.083866, Train Acc: 0.878205 | Val Loss: 0.110073, Val Acc: 0.773196\n",
      "Epoch 17834 - Train Loss: 0.083863, Train Acc: 0.878205 | Val Loss: 0.110071, Val Acc: 0.773196\n",
      "Epoch 17835 - Train Loss: 0.083860, Train Acc: 0.878205 | Val Loss: 0.110070, Val Acc: 0.773196\n",
      "Epoch 17836 - Train Loss: 0.083858, Train Acc: 0.878205 | Val Loss: 0.110068, Val Acc: 0.773196\n",
      "Epoch 17837 - Train Loss: 0.083855, Train Acc: 0.878205 | Val Loss: 0.110067, Val Acc: 0.773196\n",
      "Epoch 17838 - Train Loss: 0.083852, Train Acc: 0.878205 | Val Loss: 0.110066, Val Acc: 0.773196\n",
      "Epoch 17839 - Train Loss: 0.083850, Train Acc: 0.878205 | Val Loss: 0.110064, Val Acc: 0.773196\n",
      "Epoch 17840 - Train Loss: 0.083847, Train Acc: 0.878205 | Val Loss: 0.110063, Val Acc: 0.773196\n",
      "Epoch 17841 - Train Loss: 0.083844, Train Acc: 0.878205 | Val Loss: 0.110061, Val Acc: 0.773196\n",
      "Epoch 17842 - Train Loss: 0.083842, Train Acc: 0.878205 | Val Loss: 0.110060, Val Acc: 0.773196\n",
      "Epoch 17843 - Train Loss: 0.083839, Train Acc: 0.878205 | Val Loss: 0.110058, Val Acc: 0.773196\n",
      "Epoch 17844 - Train Loss: 0.083836, Train Acc: 0.878205 | Val Loss: 0.110057, Val Acc: 0.773196\n",
      "Epoch 17845 - Train Loss: 0.083834, Train Acc: 0.878205 | Val Loss: 0.110056, Val Acc: 0.773196\n",
      "Epoch 17846 - Train Loss: 0.083831, Train Acc: 0.878205 | Val Loss: 0.110054, Val Acc: 0.773196\n",
      "Epoch 17847 - Train Loss: 0.083828, Train Acc: 0.878205 | Val Loss: 0.110053, Val Acc: 0.773196\n",
      "Epoch 17848 - Train Loss: 0.083826, Train Acc: 0.878205 | Val Loss: 0.110051, Val Acc: 0.773196\n",
      "Epoch 17849 - Train Loss: 0.083823, Train Acc: 0.878205 | Val Loss: 0.110050, Val Acc: 0.773196\n",
      "Epoch 17850 - Train Loss: 0.083820, Train Acc: 0.878205 | Val Loss: 0.110048, Val Acc: 0.773196\n",
      "Epoch 17851 - Train Loss: 0.083817, Train Acc: 0.878205 | Val Loss: 0.110047, Val Acc: 0.773196\n",
      "Epoch 17852 - Train Loss: 0.083815, Train Acc: 0.878205 | Val Loss: 0.110046, Val Acc: 0.773196\n",
      "Epoch 17853 - Train Loss: 0.083812, Train Acc: 0.878205 | Val Loss: 0.110044, Val Acc: 0.773196\n",
      "Epoch 17854 - Train Loss: 0.083809, Train Acc: 0.878205 | Val Loss: 0.110043, Val Acc: 0.773196\n",
      "Epoch 17855 - Train Loss: 0.083807, Train Acc: 0.878205 | Val Loss: 0.110041, Val Acc: 0.773196\n",
      "Epoch 17856 - Train Loss: 0.083804, Train Acc: 0.878205 | Val Loss: 0.110040, Val Acc: 0.773196\n",
      "Epoch 17857 - Train Loss: 0.083801, Train Acc: 0.878205 | Val Loss: 0.110038, Val Acc: 0.773196\n",
      "Epoch 17858 - Train Loss: 0.083799, Train Acc: 0.878205 | Val Loss: 0.110037, Val Acc: 0.773196\n",
      "Epoch 17859 - Train Loss: 0.083796, Train Acc: 0.878205 | Val Loss: 0.110036, Val Acc: 0.773196\n",
      "Epoch 17860 - Train Loss: 0.083793, Train Acc: 0.878205 | Val Loss: 0.110034, Val Acc: 0.773196\n",
      "Epoch 17861 - Train Loss: 0.083791, Train Acc: 0.878205 | Val Loss: 0.110033, Val Acc: 0.773196\n",
      "Epoch 17862 - Train Loss: 0.083788, Train Acc: 0.878205 | Val Loss: 0.110031, Val Acc: 0.773196\n",
      "Epoch 17863 - Train Loss: 0.083785, Train Acc: 0.878205 | Val Loss: 0.110030, Val Acc: 0.773196\n",
      "Epoch 17864 - Train Loss: 0.083783, Train Acc: 0.878205 | Val Loss: 0.110028, Val Acc: 0.773196\n",
      "Epoch 17865 - Train Loss: 0.083780, Train Acc: 0.878205 | Val Loss: 0.110027, Val Acc: 0.773196\n",
      "Epoch 17866 - Train Loss: 0.083777, Train Acc: 0.878205 | Val Loss: 0.110026, Val Acc: 0.773196\n",
      "Epoch 17867 - Train Loss: 0.083775, Train Acc: 0.878205 | Val Loss: 0.110024, Val Acc: 0.773196\n",
      "Epoch 17868 - Train Loss: 0.083772, Train Acc: 0.878205 | Val Loss: 0.110023, Val Acc: 0.773196\n",
      "Epoch 17869 - Train Loss: 0.083769, Train Acc: 0.878205 | Val Loss: 0.110021, Val Acc: 0.773196\n",
      "Epoch 17870 - Train Loss: 0.083766, Train Acc: 0.878205 | Val Loss: 0.110020, Val Acc: 0.773196\n",
      "Epoch 17871 - Train Loss: 0.083764, Train Acc: 0.878205 | Val Loss: 0.110019, Val Acc: 0.773196\n",
      "Epoch 17872 - Train Loss: 0.083761, Train Acc: 0.879487 | Val Loss: 0.110017, Val Acc: 0.773196\n",
      "Epoch 17873 - Train Loss: 0.083758, Train Acc: 0.879487 | Val Loss: 0.110016, Val Acc: 0.773196\n",
      "Epoch 17874 - Train Loss: 0.083756, Train Acc: 0.879487 | Val Loss: 0.110014, Val Acc: 0.773196\n",
      "Epoch 17875 - Train Loss: 0.083753, Train Acc: 0.879487 | Val Loss: 0.110013, Val Acc: 0.773196\n",
      "Epoch 17876 - Train Loss: 0.083750, Train Acc: 0.879487 | Val Loss: 0.110012, Val Acc: 0.773196\n",
      "Epoch 17877 - Train Loss: 0.083748, Train Acc: 0.879487 | Val Loss: 0.110010, Val Acc: 0.773196\n",
      "Epoch 17878 - Train Loss: 0.083745, Train Acc: 0.879487 | Val Loss: 0.110009, Val Acc: 0.773196\n",
      "Epoch 17879 - Train Loss: 0.083742, Train Acc: 0.879487 | Val Loss: 0.110007, Val Acc: 0.773196\n",
      "Epoch 17880 - Train Loss: 0.083740, Train Acc: 0.879487 | Val Loss: 0.110006, Val Acc: 0.773196\n",
      "Epoch 17881 - Train Loss: 0.083737, Train Acc: 0.879487 | Val Loss: 0.110004, Val Acc: 0.773196\n",
      "Epoch 17882 - Train Loss: 0.083734, Train Acc: 0.879487 | Val Loss: 0.110003, Val Acc: 0.773196\n",
      "Epoch 17883 - Train Loss: 0.083732, Train Acc: 0.879487 | Val Loss: 0.110002, Val Acc: 0.773196\n",
      "Epoch 17884 - Train Loss: 0.083729, Train Acc: 0.879487 | Val Loss: 0.110000, Val Acc: 0.773196\n",
      "Epoch 17885 - Train Loss: 0.083726, Train Acc: 0.879487 | Val Loss: 0.109999, Val Acc: 0.773196\n",
      "Epoch 17886 - Train Loss: 0.083724, Train Acc: 0.879487 | Val Loss: 0.109997, Val Acc: 0.773196\n",
      "Epoch 17887 - Train Loss: 0.083721, Train Acc: 0.879487 | Val Loss: 0.109996, Val Acc: 0.773196\n",
      "Epoch 17888 - Train Loss: 0.083718, Train Acc: 0.879487 | Val Loss: 0.109995, Val Acc: 0.773196\n",
      "Epoch 17889 - Train Loss: 0.083716, Train Acc: 0.879487 | Val Loss: 0.109993, Val Acc: 0.773196\n",
      "Epoch 17890 - Train Loss: 0.083713, Train Acc: 0.879487 | Val Loss: 0.109992, Val Acc: 0.773196\n",
      "Epoch 17891 - Train Loss: 0.083710, Train Acc: 0.879487 | Val Loss: 0.109990, Val Acc: 0.773196\n",
      "Epoch 17892 - Train Loss: 0.083708, Train Acc: 0.879487 | Val Loss: 0.109989, Val Acc: 0.773196\n",
      "Epoch 17893 - Train Loss: 0.083705, Train Acc: 0.879487 | Val Loss: 0.109988, Val Acc: 0.773196\n",
      "Epoch 17894 - Train Loss: 0.083702, Train Acc: 0.879487 | Val Loss: 0.109986, Val Acc: 0.773196\n",
      "Epoch 17895 - Train Loss: 0.083700, Train Acc: 0.879487 | Val Loss: 0.109985, Val Acc: 0.773196\n",
      "Epoch 17896 - Train Loss: 0.083697, Train Acc: 0.879487 | Val Loss: 0.109983, Val Acc: 0.773196\n",
      "Epoch 17897 - Train Loss: 0.083694, Train Acc: 0.879487 | Val Loss: 0.109982, Val Acc: 0.773196\n",
      "Epoch 17898 - Train Loss: 0.083692, Train Acc: 0.879487 | Val Loss: 0.109981, Val Acc: 0.773196\n",
      "Epoch 17899 - Train Loss: 0.083689, Train Acc: 0.879487 | Val Loss: 0.109979, Val Acc: 0.773196\n",
      "Epoch 17900 - Train Loss: 0.083686, Train Acc: 0.879487 | Val Loss: 0.109978, Val Acc: 0.773196\n",
      "Epoch 17901 - Train Loss: 0.083684, Train Acc: 0.879487 | Val Loss: 0.109976, Val Acc: 0.773196\n",
      "Epoch 17902 - Train Loss: 0.083681, Train Acc: 0.879487 | Val Loss: 0.109975, Val Acc: 0.773196\n",
      "Epoch 17903 - Train Loss: 0.083678, Train Acc: 0.879487 | Val Loss: 0.109973, Val Acc: 0.773196\n",
      "Epoch 17904 - Train Loss: 0.083676, Train Acc: 0.879487 | Val Loss: 0.109972, Val Acc: 0.773196\n",
      "Epoch 17905 - Train Loss: 0.083673, Train Acc: 0.879487 | Val Loss: 0.109971, Val Acc: 0.773196\n",
      "Epoch 17906 - Train Loss: 0.083670, Train Acc: 0.879487 | Val Loss: 0.109969, Val Acc: 0.773196\n",
      "Epoch 17907 - Train Loss: 0.083668, Train Acc: 0.879487 | Val Loss: 0.109968, Val Acc: 0.773196\n",
      "Epoch 17908 - Train Loss: 0.083665, Train Acc: 0.879487 | Val Loss: 0.109966, Val Acc: 0.773196\n",
      "Epoch 17909 - Train Loss: 0.083662, Train Acc: 0.879487 | Val Loss: 0.109965, Val Acc: 0.773196\n",
      "Epoch 17910 - Train Loss: 0.083660, Train Acc: 0.879487 | Val Loss: 0.109964, Val Acc: 0.773196\n",
      "Epoch 17911 - Train Loss: 0.083657, Train Acc: 0.879487 | Val Loss: 0.109962, Val Acc: 0.773196\n",
      "Epoch 17912 - Train Loss: 0.083654, Train Acc: 0.879487 | Val Loss: 0.109961, Val Acc: 0.773196\n",
      "Epoch 17913 - Train Loss: 0.083652, Train Acc: 0.879487 | Val Loss: 0.109959, Val Acc: 0.773196\n",
      "Epoch 17914 - Train Loss: 0.083649, Train Acc: 0.879487 | Val Loss: 0.109958, Val Acc: 0.773196\n",
      "Epoch 17915 - Train Loss: 0.083646, Train Acc: 0.879487 | Val Loss: 0.109957, Val Acc: 0.773196\n",
      "Epoch 17916 - Train Loss: 0.083644, Train Acc: 0.879487 | Val Loss: 0.109955, Val Acc: 0.773196\n",
      "Epoch 17917 - Train Loss: 0.083641, Train Acc: 0.879487 | Val Loss: 0.109954, Val Acc: 0.773196\n",
      "Epoch 17918 - Train Loss: 0.083638, Train Acc: 0.879487 | Val Loss: 0.109952, Val Acc: 0.773196\n",
      "Epoch 17919 - Train Loss: 0.083636, Train Acc: 0.879487 | Val Loss: 0.109951, Val Acc: 0.773196\n",
      "Epoch 17920 - Train Loss: 0.083633, Train Acc: 0.879487 | Val Loss: 0.109950, Val Acc: 0.773196\n",
      "Epoch 17921 - Train Loss: 0.083630, Train Acc: 0.879487 | Val Loss: 0.109948, Val Acc: 0.773196\n",
      "Epoch 17922 - Train Loss: 0.083628, Train Acc: 0.879487 | Val Loss: 0.109947, Val Acc: 0.773196\n",
      "Epoch 17923 - Train Loss: 0.083625, Train Acc: 0.879487 | Val Loss: 0.109945, Val Acc: 0.773196\n",
      "Epoch 17924 - Train Loss: 0.083622, Train Acc: 0.879487 | Val Loss: 0.109944, Val Acc: 0.773196\n",
      "Epoch 17925 - Train Loss: 0.083620, Train Acc: 0.879487 | Val Loss: 0.109943, Val Acc: 0.773196\n",
      "Epoch 17926 - Train Loss: 0.083617, Train Acc: 0.879487 | Val Loss: 0.109941, Val Acc: 0.773196\n",
      "Epoch 17927 - Train Loss: 0.083614, Train Acc: 0.879487 | Val Loss: 0.109940, Val Acc: 0.773196\n",
      "Epoch 17928 - Train Loss: 0.083612, Train Acc: 0.879487 | Val Loss: 0.109938, Val Acc: 0.773196\n",
      "Epoch 17929 - Train Loss: 0.083609, Train Acc: 0.879487 | Val Loss: 0.109937, Val Acc: 0.773196\n",
      "Epoch 17930 - Train Loss: 0.083606, Train Acc: 0.879487 | Val Loss: 0.109936, Val Acc: 0.773196\n",
      "Epoch 17931 - Train Loss: 0.083604, Train Acc: 0.879487 | Val Loss: 0.109934, Val Acc: 0.773196\n",
      "Epoch 17932 - Train Loss: 0.083601, Train Acc: 0.879487 | Val Loss: 0.109933, Val Acc: 0.773196\n",
      "Epoch 17933 - Train Loss: 0.083598, Train Acc: 0.879487 | Val Loss: 0.109931, Val Acc: 0.773196\n",
      "Epoch 17934 - Train Loss: 0.083596, Train Acc: 0.879487 | Val Loss: 0.109930, Val Acc: 0.773196\n",
      "Epoch 17935 - Train Loss: 0.083593, Train Acc: 0.879487 | Val Loss: 0.109929, Val Acc: 0.773196\n",
      "Epoch 17936 - Train Loss: 0.083590, Train Acc: 0.879487 | Val Loss: 0.109927, Val Acc: 0.773196\n",
      "Epoch 17937 - Train Loss: 0.083588, Train Acc: 0.879487 | Val Loss: 0.109926, Val Acc: 0.773196\n",
      "Epoch 17938 - Train Loss: 0.083585, Train Acc: 0.879487 | Val Loss: 0.109924, Val Acc: 0.773196\n",
      "Epoch 17939 - Train Loss: 0.083582, Train Acc: 0.879487 | Val Loss: 0.109923, Val Acc: 0.773196\n",
      "Epoch 17940 - Train Loss: 0.083580, Train Acc: 0.879487 | Val Loss: 0.109922, Val Acc: 0.773196\n",
      "Epoch 17941 - Train Loss: 0.083577, Train Acc: 0.879487 | Val Loss: 0.109920, Val Acc: 0.773196\n",
      "Epoch 17942 - Train Loss: 0.083574, Train Acc: 0.879487 | Val Loss: 0.109919, Val Acc: 0.773196\n",
      "Epoch 17943 - Train Loss: 0.083572, Train Acc: 0.879487 | Val Loss: 0.109917, Val Acc: 0.773196\n",
      "Epoch 17944 - Train Loss: 0.083569, Train Acc: 0.879487 | Val Loss: 0.109916, Val Acc: 0.773196\n",
      "Epoch 17945 - Train Loss: 0.083566, Train Acc: 0.879487 | Val Loss: 0.109915, Val Acc: 0.773196\n",
      "Epoch 17946 - Train Loss: 0.083564, Train Acc: 0.879487 | Val Loss: 0.109913, Val Acc: 0.773196\n",
      "Epoch 17947 - Train Loss: 0.083561, Train Acc: 0.879487 | Val Loss: 0.109912, Val Acc: 0.773196\n",
      "Epoch 17948 - Train Loss: 0.083558, Train Acc: 0.879487 | Val Loss: 0.109910, Val Acc: 0.773196\n",
      "Epoch 17949 - Train Loss: 0.083556, Train Acc: 0.879487 | Val Loss: 0.109909, Val Acc: 0.773196\n",
      "Epoch 17950 - Train Loss: 0.083553, Train Acc: 0.879487 | Val Loss: 0.109908, Val Acc: 0.773196\n",
      "Epoch 17951 - Train Loss: 0.083550, Train Acc: 0.879487 | Val Loss: 0.109906, Val Acc: 0.773196\n",
      "Epoch 17952 - Train Loss: 0.083548, Train Acc: 0.879487 | Val Loss: 0.109905, Val Acc: 0.773196\n",
      "Epoch 17953 - Train Loss: 0.083545, Train Acc: 0.879487 | Val Loss: 0.109903, Val Acc: 0.773196\n",
      "Epoch 17954 - Train Loss: 0.083543, Train Acc: 0.879487 | Val Loss: 0.109902, Val Acc: 0.773196\n",
      "Epoch 17955 - Train Loss: 0.083540, Train Acc: 0.879487 | Val Loss: 0.109901, Val Acc: 0.773196\n",
      "Epoch 17956 - Train Loss: 0.083537, Train Acc: 0.879487 | Val Loss: 0.109899, Val Acc: 0.773196\n",
      "Epoch 17957 - Train Loss: 0.083535, Train Acc: 0.879487 | Val Loss: 0.109898, Val Acc: 0.773196\n",
      "Epoch 17958 - Train Loss: 0.083532, Train Acc: 0.879487 | Val Loss: 0.109896, Val Acc: 0.773196\n",
      "Epoch 17959 - Train Loss: 0.083529, Train Acc: 0.879487 | Val Loss: 0.109895, Val Acc: 0.773196\n",
      "Epoch 17960 - Train Loss: 0.083527, Train Acc: 0.879487 | Val Loss: 0.109894, Val Acc: 0.773196\n",
      "Epoch 17961 - Train Loss: 0.083524, Train Acc: 0.879487 | Val Loss: 0.109892, Val Acc: 0.773196\n",
      "Epoch 17962 - Train Loss: 0.083521, Train Acc: 0.879487 | Val Loss: 0.109891, Val Acc: 0.773196\n",
      "Epoch 17963 - Train Loss: 0.083519, Train Acc: 0.879487 | Val Loss: 0.109889, Val Acc: 0.773196\n",
      "Epoch 17964 - Train Loss: 0.083516, Train Acc: 0.879487 | Val Loss: 0.109888, Val Acc: 0.773196\n",
      "Epoch 17965 - Train Loss: 0.083513, Train Acc: 0.879487 | Val Loss: 0.109887, Val Acc: 0.773196\n",
      "Epoch 17966 - Train Loss: 0.083511, Train Acc: 0.879487 | Val Loss: 0.109885, Val Acc: 0.773196\n",
      "Epoch 17967 - Train Loss: 0.083508, Train Acc: 0.879487 | Val Loss: 0.109884, Val Acc: 0.773196\n",
      "Epoch 17968 - Train Loss: 0.083505, Train Acc: 0.879487 | Val Loss: 0.109883, Val Acc: 0.773196\n",
      "Epoch 17969 - Train Loss: 0.083503, Train Acc: 0.879487 | Val Loss: 0.109881, Val Acc: 0.773196\n",
      "Epoch 17970 - Train Loss: 0.083500, Train Acc: 0.879487 | Val Loss: 0.109880, Val Acc: 0.773196\n",
      "Epoch 17971 - Train Loss: 0.083497, Train Acc: 0.879487 | Val Loss: 0.109878, Val Acc: 0.773196\n",
      "Epoch 17972 - Train Loss: 0.083495, Train Acc: 0.879487 | Val Loss: 0.109877, Val Acc: 0.773196\n",
      "Epoch 17973 - Train Loss: 0.083492, Train Acc: 0.879487 | Val Loss: 0.109876, Val Acc: 0.773196\n",
      "Epoch 17974 - Train Loss: 0.083490, Train Acc: 0.879487 | Val Loss: 0.109874, Val Acc: 0.773196\n",
      "Epoch 17975 - Train Loss: 0.083487, Train Acc: 0.879487 | Val Loss: 0.109873, Val Acc: 0.773196\n",
      "Epoch 17976 - Train Loss: 0.083484, Train Acc: 0.879487 | Val Loss: 0.109871, Val Acc: 0.773196\n",
      "Epoch 17977 - Train Loss: 0.083482, Train Acc: 0.879487 | Val Loss: 0.109870, Val Acc: 0.773196\n",
      "Epoch 17978 - Train Loss: 0.083479, Train Acc: 0.879487 | Val Loss: 0.109869, Val Acc: 0.773196\n",
      "Epoch 17979 - Train Loss: 0.083476, Train Acc: 0.879487 | Val Loss: 0.109867, Val Acc: 0.773196\n",
      "Epoch 17980 - Train Loss: 0.083474, Train Acc: 0.879487 | Val Loss: 0.109866, Val Acc: 0.773196\n",
      "Epoch 17981 - Train Loss: 0.083471, Train Acc: 0.879487 | Val Loss: 0.109864, Val Acc: 0.773196\n",
      "Epoch 17982 - Train Loss: 0.083468, Train Acc: 0.879487 | Val Loss: 0.109863, Val Acc: 0.773196\n",
      "Epoch 17983 - Train Loss: 0.083466, Train Acc: 0.879487 | Val Loss: 0.109862, Val Acc: 0.773196\n",
      "Epoch 17984 - Train Loss: 0.083463, Train Acc: 0.879487 | Val Loss: 0.109860, Val Acc: 0.773196\n",
      "Epoch 17985 - Train Loss: 0.083460, Train Acc: 0.879487 | Val Loss: 0.109859, Val Acc: 0.773196\n",
      "Epoch 17986 - Train Loss: 0.083458, Train Acc: 0.879487 | Val Loss: 0.109858, Val Acc: 0.773196\n",
      "Epoch 17987 - Train Loss: 0.083455, Train Acc: 0.879487 | Val Loss: 0.109856, Val Acc: 0.773196\n",
      "Epoch 17988 - Train Loss: 0.083452, Train Acc: 0.879487 | Val Loss: 0.109855, Val Acc: 0.773196\n",
      "Epoch 17989 - Train Loss: 0.083450, Train Acc: 0.879487 | Val Loss: 0.109853, Val Acc: 0.773196\n",
      "Epoch 17990 - Train Loss: 0.083447, Train Acc: 0.879487 | Val Loss: 0.109852, Val Acc: 0.773196\n",
      "Epoch 17991 - Train Loss: 0.083445, Train Acc: 0.879487 | Val Loss: 0.109851, Val Acc: 0.773196\n",
      "Epoch 17992 - Train Loss: 0.083442, Train Acc: 0.879487 | Val Loss: 0.109849, Val Acc: 0.773196\n",
      "Epoch 17993 - Train Loss: 0.083439, Train Acc: 0.879487 | Val Loss: 0.109848, Val Acc: 0.773196\n",
      "Epoch 17994 - Train Loss: 0.083437, Train Acc: 0.879487 | Val Loss: 0.109846, Val Acc: 0.773196\n",
      "Epoch 17995 - Train Loss: 0.083434, Train Acc: 0.879487 | Val Loss: 0.109845, Val Acc: 0.773196\n",
      "Epoch 17996 - Train Loss: 0.083431, Train Acc: 0.879487 | Val Loss: 0.109844, Val Acc: 0.773196\n",
      "Epoch 17997 - Train Loss: 0.083429, Train Acc: 0.879487 | Val Loss: 0.109842, Val Acc: 0.773196\n",
      "Epoch 17998 - Train Loss: 0.083426, Train Acc: 0.879487 | Val Loss: 0.109841, Val Acc: 0.773196\n",
      "Epoch 17999 - Train Loss: 0.083423, Train Acc: 0.879487 | Val Loss: 0.109840, Val Acc: 0.773196\n",
      "Epoch 18000 - Train Loss: 0.083421, Train Acc: 0.879487 | Val Loss: 0.109838, Val Acc: 0.773196\n",
      "Epoch 18001 - Train Loss: 0.083418, Train Acc: 0.879487 | Val Loss: 0.109837, Val Acc: 0.773196\n",
      "Epoch 18002 - Train Loss: 0.083415, Train Acc: 0.879487 | Val Loss: 0.109836, Val Acc: 0.773196\n",
      "Epoch 18003 - Train Loss: 0.083413, Train Acc: 0.879487 | Val Loss: 0.109834, Val Acc: 0.773196\n",
      "Epoch 18004 - Train Loss: 0.083410, Train Acc: 0.879487 | Val Loss: 0.109833, Val Acc: 0.773196\n",
      "Epoch 18005 - Train Loss: 0.083408, Train Acc: 0.879487 | Val Loss: 0.109831, Val Acc: 0.773196\n",
      "Epoch 18006 - Train Loss: 0.083405, Train Acc: 0.879487 | Val Loss: 0.109830, Val Acc: 0.773196\n",
      "Epoch 18007 - Train Loss: 0.083402, Train Acc: 0.879487 | Val Loss: 0.109829, Val Acc: 0.773196\n",
      "Epoch 18008 - Train Loss: 0.083400, Train Acc: 0.879487 | Val Loss: 0.109827, Val Acc: 0.773196\n",
      "Epoch 18009 - Train Loss: 0.083397, Train Acc: 0.879487 | Val Loss: 0.109826, Val Acc: 0.773196\n",
      "Epoch 18010 - Train Loss: 0.083394, Train Acc: 0.879487 | Val Loss: 0.109825, Val Acc: 0.773196\n",
      "Epoch 18011 - Train Loss: 0.083392, Train Acc: 0.879487 | Val Loss: 0.109823, Val Acc: 0.773196\n",
      "Epoch 18012 - Train Loss: 0.083389, Train Acc: 0.879487 | Val Loss: 0.109822, Val Acc: 0.773196\n",
      "Epoch 18013 - Train Loss: 0.083386, Train Acc: 0.879487 | Val Loss: 0.109820, Val Acc: 0.773196\n",
      "Epoch 18014 - Train Loss: 0.083384, Train Acc: 0.879487 | Val Loss: 0.109819, Val Acc: 0.773196\n",
      "Epoch 18015 - Train Loss: 0.083381, Train Acc: 0.879487 | Val Loss: 0.109818, Val Acc: 0.773196\n",
      "Epoch 18016 - Train Loss: 0.083379, Train Acc: 0.879487 | Val Loss: 0.109816, Val Acc: 0.773196\n",
      "Epoch 18017 - Train Loss: 0.083376, Train Acc: 0.879487 | Val Loss: 0.109815, Val Acc: 0.773196\n",
      "Epoch 18018 - Train Loss: 0.083373, Train Acc: 0.879487 | Val Loss: 0.109813, Val Acc: 0.773196\n",
      "Epoch 18019 - Train Loss: 0.083371, Train Acc: 0.879487 | Val Loss: 0.109812, Val Acc: 0.773196\n",
      "Epoch 18020 - Train Loss: 0.083368, Train Acc: 0.879487 | Val Loss: 0.109811, Val Acc: 0.773196\n",
      "Epoch 18021 - Train Loss: 0.083365, Train Acc: 0.879487 | Val Loss: 0.109809, Val Acc: 0.773196\n",
      "Epoch 18022 - Train Loss: 0.083363, Train Acc: 0.879487 | Val Loss: 0.109808, Val Acc: 0.773196\n",
      "Epoch 18023 - Train Loss: 0.083360, Train Acc: 0.879487 | Val Loss: 0.109807, Val Acc: 0.773196\n",
      "Epoch 18024 - Train Loss: 0.083357, Train Acc: 0.879487 | Val Loss: 0.109805, Val Acc: 0.773196\n",
      "Epoch 18025 - Train Loss: 0.083355, Train Acc: 0.879487 | Val Loss: 0.109804, Val Acc: 0.773196\n",
      "Epoch 18026 - Train Loss: 0.083352, Train Acc: 0.879487 | Val Loss: 0.109802, Val Acc: 0.773196\n",
      "Epoch 18027 - Train Loss: 0.083350, Train Acc: 0.879487 | Val Loss: 0.109801, Val Acc: 0.773196\n",
      "Epoch 18028 - Train Loss: 0.083347, Train Acc: 0.879487 | Val Loss: 0.109800, Val Acc: 0.773196\n",
      "Epoch 18029 - Train Loss: 0.083344, Train Acc: 0.879487 | Val Loss: 0.109798, Val Acc: 0.773196\n",
      "Epoch 18030 - Train Loss: 0.083342, Train Acc: 0.879487 | Val Loss: 0.109797, Val Acc: 0.773196\n",
      "Epoch 18031 - Train Loss: 0.083339, Train Acc: 0.879487 | Val Loss: 0.109796, Val Acc: 0.773196\n",
      "Epoch 18032 - Train Loss: 0.083336, Train Acc: 0.879487 | Val Loss: 0.109794, Val Acc: 0.773196\n",
      "Epoch 18033 - Train Loss: 0.083334, Train Acc: 0.879487 | Val Loss: 0.109793, Val Acc: 0.773196\n",
      "Epoch 18034 - Train Loss: 0.083331, Train Acc: 0.879487 | Val Loss: 0.109792, Val Acc: 0.773196\n",
      "Epoch 18035 - Train Loss: 0.083329, Train Acc: 0.879487 | Val Loss: 0.109790, Val Acc: 0.773196\n",
      "Epoch 18036 - Train Loss: 0.083326, Train Acc: 0.879487 | Val Loss: 0.109789, Val Acc: 0.773196\n",
      "Epoch 18037 - Train Loss: 0.083323, Train Acc: 0.879487 | Val Loss: 0.109787, Val Acc: 0.773196\n",
      "Epoch 18038 - Train Loss: 0.083321, Train Acc: 0.879487 | Val Loss: 0.109786, Val Acc: 0.773196\n",
      "Epoch 18039 - Train Loss: 0.083318, Train Acc: 0.879487 | Val Loss: 0.109785, Val Acc: 0.773196\n",
      "Epoch 18040 - Train Loss: 0.083315, Train Acc: 0.879487 | Val Loss: 0.109783, Val Acc: 0.773196\n",
      "Epoch 18041 - Train Loss: 0.083313, Train Acc: 0.879487 | Val Loss: 0.109782, Val Acc: 0.773196\n",
      "Epoch 18042 - Train Loss: 0.083310, Train Acc: 0.879487 | Val Loss: 0.109781, Val Acc: 0.773196\n",
      "Epoch 18043 - Train Loss: 0.083308, Train Acc: 0.879487 | Val Loss: 0.109779, Val Acc: 0.773196\n",
      "Epoch 18044 - Train Loss: 0.083305, Train Acc: 0.879487 | Val Loss: 0.109778, Val Acc: 0.773196\n",
      "Epoch 18045 - Train Loss: 0.083302, Train Acc: 0.879487 | Val Loss: 0.109776, Val Acc: 0.773196\n",
      "Epoch 18046 - Train Loss: 0.083300, Train Acc: 0.879487 | Val Loss: 0.109775, Val Acc: 0.773196\n",
      "Epoch 18047 - Train Loss: 0.083297, Train Acc: 0.879487 | Val Loss: 0.109774, Val Acc: 0.773196\n",
      "Epoch 18048 - Train Loss: 0.083294, Train Acc: 0.879487 | Val Loss: 0.109772, Val Acc: 0.773196\n",
      "Epoch 18049 - Train Loss: 0.083292, Train Acc: 0.879487 | Val Loss: 0.109771, Val Acc: 0.773196\n",
      "Epoch 18050 - Train Loss: 0.083289, Train Acc: 0.879487 | Val Loss: 0.109770, Val Acc: 0.773196\n",
      "Epoch 18051 - Train Loss: 0.083287, Train Acc: 0.879487 | Val Loss: 0.109768, Val Acc: 0.773196\n",
      "Epoch 18052 - Train Loss: 0.083284, Train Acc: 0.879487 | Val Loss: 0.109767, Val Acc: 0.773196\n",
      "Epoch 18053 - Train Loss: 0.083281, Train Acc: 0.879487 | Val Loss: 0.109765, Val Acc: 0.773196\n",
      "Epoch 18054 - Train Loss: 0.083279, Train Acc: 0.879487 | Val Loss: 0.109764, Val Acc: 0.773196\n",
      "Epoch 18055 - Train Loss: 0.083276, Train Acc: 0.879487 | Val Loss: 0.109763, Val Acc: 0.773196\n",
      "Epoch 18056 - Train Loss: 0.083273, Train Acc: 0.879487 | Val Loss: 0.109761, Val Acc: 0.773196\n",
      "Epoch 18057 - Train Loss: 0.083271, Train Acc: 0.879487 | Val Loss: 0.109760, Val Acc: 0.773196\n",
      "Epoch 18058 - Train Loss: 0.083268, Train Acc: 0.879487 | Val Loss: 0.109759, Val Acc: 0.773196\n",
      "Epoch 18059 - Train Loss: 0.083266, Train Acc: 0.879487 | Val Loss: 0.109757, Val Acc: 0.773196\n",
      "Epoch 18060 - Train Loss: 0.083263, Train Acc: 0.879487 | Val Loss: 0.109756, Val Acc: 0.773196\n",
      "Epoch 18061 - Train Loss: 0.083260, Train Acc: 0.879487 | Val Loss: 0.109755, Val Acc: 0.773196\n",
      "Epoch 18062 - Train Loss: 0.083258, Train Acc: 0.879487 | Val Loss: 0.109753, Val Acc: 0.773196\n",
      "Epoch 18063 - Train Loss: 0.083255, Train Acc: 0.879487 | Val Loss: 0.109752, Val Acc: 0.773196\n",
      "Epoch 18064 - Train Loss: 0.083252, Train Acc: 0.879487 | Val Loss: 0.109751, Val Acc: 0.773196\n",
      "Epoch 18065 - Train Loss: 0.083250, Train Acc: 0.879487 | Val Loss: 0.109749, Val Acc: 0.773196\n",
      "Epoch 18066 - Train Loss: 0.083247, Train Acc: 0.879487 | Val Loss: 0.109748, Val Acc: 0.773196\n",
      "Epoch 18067 - Train Loss: 0.083245, Train Acc: 0.879487 | Val Loss: 0.109746, Val Acc: 0.773196\n",
      "Epoch 18068 - Train Loss: 0.083242, Train Acc: 0.879487 | Val Loss: 0.109745, Val Acc: 0.773196\n",
      "Epoch 18069 - Train Loss: 0.083239, Train Acc: 0.879487 | Val Loss: 0.109744, Val Acc: 0.773196\n",
      "Epoch 18070 - Train Loss: 0.083237, Train Acc: 0.879487 | Val Loss: 0.109742, Val Acc: 0.773196\n",
      "Epoch 18071 - Train Loss: 0.083234, Train Acc: 0.879487 | Val Loss: 0.109741, Val Acc: 0.773196\n",
      "Epoch 18072 - Train Loss: 0.083231, Train Acc: 0.879487 | Val Loss: 0.109740, Val Acc: 0.773196\n",
      "Epoch 18073 - Train Loss: 0.083229, Train Acc: 0.879487 | Val Loss: 0.109738, Val Acc: 0.773196\n",
      "Epoch 18074 - Train Loss: 0.083226, Train Acc: 0.879487 | Val Loss: 0.109737, Val Acc: 0.773196\n",
      "Epoch 18075 - Train Loss: 0.083224, Train Acc: 0.879487 | Val Loss: 0.109736, Val Acc: 0.773196\n",
      "Epoch 18076 - Train Loss: 0.083221, Train Acc: 0.879487 | Val Loss: 0.109734, Val Acc: 0.773196\n",
      "Epoch 18077 - Train Loss: 0.083218, Train Acc: 0.879487 | Val Loss: 0.109733, Val Acc: 0.773196\n",
      "Epoch 18078 - Train Loss: 0.083216, Train Acc: 0.879487 | Val Loss: 0.109731, Val Acc: 0.773196\n",
      "Epoch 18079 - Train Loss: 0.083213, Train Acc: 0.879487 | Val Loss: 0.109730, Val Acc: 0.773196\n",
      "Epoch 18080 - Train Loss: 0.083211, Train Acc: 0.879487 | Val Loss: 0.109729, Val Acc: 0.773196\n",
      "Epoch 18081 - Train Loss: 0.083208, Train Acc: 0.879487 | Val Loss: 0.109727, Val Acc: 0.773196\n",
      "Epoch 18082 - Train Loss: 0.083205, Train Acc: 0.879487 | Val Loss: 0.109726, Val Acc: 0.773196\n",
      "Epoch 18083 - Train Loss: 0.083203, Train Acc: 0.879487 | Val Loss: 0.109725, Val Acc: 0.773196\n",
      "Epoch 18084 - Train Loss: 0.083200, Train Acc: 0.879487 | Val Loss: 0.109723, Val Acc: 0.773196\n",
      "Epoch 18085 - Train Loss: 0.083197, Train Acc: 0.879487 | Val Loss: 0.109722, Val Acc: 0.773196\n",
      "Epoch 18086 - Train Loss: 0.083195, Train Acc: 0.879487 | Val Loss: 0.109721, Val Acc: 0.773196\n",
      "Epoch 18087 - Train Loss: 0.083192, Train Acc: 0.879487 | Val Loss: 0.109719, Val Acc: 0.773196\n",
      "Epoch 18088 - Train Loss: 0.083190, Train Acc: 0.879487 | Val Loss: 0.109718, Val Acc: 0.773196\n",
      "Epoch 18089 - Train Loss: 0.083187, Train Acc: 0.879487 | Val Loss: 0.109717, Val Acc: 0.773196\n",
      "Epoch 18090 - Train Loss: 0.083184, Train Acc: 0.879487 | Val Loss: 0.109715, Val Acc: 0.773196\n",
      "Epoch 18091 - Train Loss: 0.083182, Train Acc: 0.879487 | Val Loss: 0.109714, Val Acc: 0.773196\n",
      "Epoch 18092 - Train Loss: 0.083179, Train Acc: 0.879487 | Val Loss: 0.109713, Val Acc: 0.773196\n",
      "Epoch 18093 - Train Loss: 0.083177, Train Acc: 0.879487 | Val Loss: 0.109711, Val Acc: 0.773196\n",
      "Epoch 18094 - Train Loss: 0.083174, Train Acc: 0.879487 | Val Loss: 0.109710, Val Acc: 0.773196\n",
      "Epoch 18095 - Train Loss: 0.083171, Train Acc: 0.879487 | Val Loss: 0.109708, Val Acc: 0.773196\n",
      "Epoch 18096 - Train Loss: 0.083169, Train Acc: 0.879487 | Val Loss: 0.109707, Val Acc: 0.773196\n",
      "Epoch 18097 - Train Loss: 0.083166, Train Acc: 0.879487 | Val Loss: 0.109706, Val Acc: 0.773196\n",
      "Epoch 18098 - Train Loss: 0.083163, Train Acc: 0.879487 | Val Loss: 0.109704, Val Acc: 0.773196\n",
      "Epoch 18099 - Train Loss: 0.083161, Train Acc: 0.879487 | Val Loss: 0.109703, Val Acc: 0.773196\n",
      "Epoch 18100 - Train Loss: 0.083158, Train Acc: 0.879487 | Val Loss: 0.109702, Val Acc: 0.773196\n",
      "Epoch 18101 - Train Loss: 0.083156, Train Acc: 0.879487 | Val Loss: 0.109700, Val Acc: 0.773196\n",
      "Epoch 18102 - Train Loss: 0.083153, Train Acc: 0.879487 | Val Loss: 0.109699, Val Acc: 0.773196\n",
      "Epoch 18103 - Train Loss: 0.083150, Train Acc: 0.879487 | Val Loss: 0.109698, Val Acc: 0.773196\n",
      "Epoch 18104 - Train Loss: 0.083148, Train Acc: 0.879487 | Val Loss: 0.109696, Val Acc: 0.773196\n",
      "Epoch 18105 - Train Loss: 0.083145, Train Acc: 0.879487 | Val Loss: 0.109695, Val Acc: 0.773196\n",
      "Epoch 18106 - Train Loss: 0.083143, Train Acc: 0.879487 | Val Loss: 0.109694, Val Acc: 0.773196\n",
      "Epoch 18107 - Train Loss: 0.083140, Train Acc: 0.879487 | Val Loss: 0.109692, Val Acc: 0.773196\n",
      "Epoch 18108 - Train Loss: 0.083137, Train Acc: 0.879487 | Val Loss: 0.109691, Val Acc: 0.773196\n",
      "Epoch 18109 - Train Loss: 0.083135, Train Acc: 0.879487 | Val Loss: 0.109690, Val Acc: 0.773196\n",
      "Epoch 18110 - Train Loss: 0.083132, Train Acc: 0.879487 | Val Loss: 0.109688, Val Acc: 0.773196\n",
      "Epoch 18111 - Train Loss: 0.083130, Train Acc: 0.879487 | Val Loss: 0.109687, Val Acc: 0.773196\n",
      "Epoch 18112 - Train Loss: 0.083127, Train Acc: 0.879487 | Val Loss: 0.109685, Val Acc: 0.773196\n",
      "Epoch 18113 - Train Loss: 0.083124, Train Acc: 0.879487 | Val Loss: 0.109684, Val Acc: 0.773196\n",
      "Epoch 18114 - Train Loss: 0.083122, Train Acc: 0.879487 | Val Loss: 0.109683, Val Acc: 0.773196\n",
      "Epoch 18115 - Train Loss: 0.083119, Train Acc: 0.879487 | Val Loss: 0.109681, Val Acc: 0.773196\n",
      "Epoch 18116 - Train Loss: 0.083116, Train Acc: 0.879487 | Val Loss: 0.109680, Val Acc: 0.773196\n",
      "Epoch 18117 - Train Loss: 0.083114, Train Acc: 0.879487 | Val Loss: 0.109679, Val Acc: 0.773196\n",
      "Epoch 18118 - Train Loss: 0.083111, Train Acc: 0.879487 | Val Loss: 0.109677, Val Acc: 0.773196\n",
      "Epoch 18119 - Train Loss: 0.083109, Train Acc: 0.879487 | Val Loss: 0.109676, Val Acc: 0.773196\n",
      "Epoch 18120 - Train Loss: 0.083106, Train Acc: 0.879487 | Val Loss: 0.109675, Val Acc: 0.773196\n",
      "Epoch 18121 - Train Loss: 0.083103, Train Acc: 0.879487 | Val Loss: 0.109673, Val Acc: 0.773196\n",
      "Epoch 18122 - Train Loss: 0.083101, Train Acc: 0.879487 | Val Loss: 0.109672, Val Acc: 0.773196\n",
      "Epoch 18123 - Train Loss: 0.083098, Train Acc: 0.879487 | Val Loss: 0.109671, Val Acc: 0.773196\n",
      "Epoch 18124 - Train Loss: 0.083096, Train Acc: 0.879487 | Val Loss: 0.109669, Val Acc: 0.773196\n",
      "Epoch 18125 - Train Loss: 0.083093, Train Acc: 0.879487 | Val Loss: 0.109668, Val Acc: 0.773196\n",
      "Epoch 18126 - Train Loss: 0.083090, Train Acc: 0.879487 | Val Loss: 0.109667, Val Acc: 0.773196\n",
      "Epoch 18127 - Train Loss: 0.083088, Train Acc: 0.879487 | Val Loss: 0.109665, Val Acc: 0.773196\n",
      "Epoch 18128 - Train Loss: 0.083085, Train Acc: 0.879487 | Val Loss: 0.109664, Val Acc: 0.773196\n",
      "Epoch 18129 - Train Loss: 0.083083, Train Acc: 0.879487 | Val Loss: 0.109663, Val Acc: 0.773196\n",
      "Epoch 18130 - Train Loss: 0.083080, Train Acc: 0.879487 | Val Loss: 0.109661, Val Acc: 0.773196\n",
      "Epoch 18131 - Train Loss: 0.083077, Train Acc: 0.879487 | Val Loss: 0.109660, Val Acc: 0.773196\n",
      "Epoch 18132 - Train Loss: 0.083075, Train Acc: 0.879487 | Val Loss: 0.109658, Val Acc: 0.773196\n",
      "Epoch 18133 - Train Loss: 0.083072, Train Acc: 0.879487 | Val Loss: 0.109657, Val Acc: 0.773196\n",
      "Epoch 18134 - Train Loss: 0.083070, Train Acc: 0.879487 | Val Loss: 0.109656, Val Acc: 0.773196\n",
      "Epoch 18135 - Train Loss: 0.083067, Train Acc: 0.879487 | Val Loss: 0.109654, Val Acc: 0.773196\n",
      "Epoch 18136 - Train Loss: 0.083064, Train Acc: 0.879487 | Val Loss: 0.109653, Val Acc: 0.773196\n",
      "Epoch 18137 - Train Loss: 0.083062, Train Acc: 0.879487 | Val Loss: 0.109652, Val Acc: 0.773196\n",
      "Epoch 18138 - Train Loss: 0.083059, Train Acc: 0.879487 | Val Loss: 0.109650, Val Acc: 0.773196\n",
      "Epoch 18139 - Train Loss: 0.083057, Train Acc: 0.879487 | Val Loss: 0.109649, Val Acc: 0.773196\n",
      "Epoch 18140 - Train Loss: 0.083054, Train Acc: 0.879487 | Val Loss: 0.109648, Val Acc: 0.773196\n",
      "Epoch 18141 - Train Loss: 0.083051, Train Acc: 0.879487 | Val Loss: 0.109646, Val Acc: 0.773196\n",
      "Epoch 18142 - Train Loss: 0.083049, Train Acc: 0.879487 | Val Loss: 0.109645, Val Acc: 0.773196\n",
      "Epoch 18143 - Train Loss: 0.083046, Train Acc: 0.879487 | Val Loss: 0.109644, Val Acc: 0.773196\n",
      "Epoch 18144 - Train Loss: 0.083044, Train Acc: 0.879487 | Val Loss: 0.109642, Val Acc: 0.773196\n",
      "Epoch 18145 - Train Loss: 0.083041, Train Acc: 0.879487 | Val Loss: 0.109641, Val Acc: 0.773196\n",
      "Epoch 18146 - Train Loss: 0.083038, Train Acc: 0.879487 | Val Loss: 0.109640, Val Acc: 0.773196\n",
      "Epoch 18147 - Train Loss: 0.083036, Train Acc: 0.879487 | Val Loss: 0.109638, Val Acc: 0.773196\n",
      "Epoch 18148 - Train Loss: 0.083033, Train Acc: 0.879487 | Val Loss: 0.109637, Val Acc: 0.773196\n",
      "Epoch 18149 - Train Loss: 0.083031, Train Acc: 0.879487 | Val Loss: 0.109636, Val Acc: 0.773196\n",
      "Epoch 18150 - Train Loss: 0.083028, Train Acc: 0.879487 | Val Loss: 0.109634, Val Acc: 0.773196\n",
      "Epoch 18151 - Train Loss: 0.083025, Train Acc: 0.879487 | Val Loss: 0.109633, Val Acc: 0.773196\n",
      "Epoch 18152 - Train Loss: 0.083023, Train Acc: 0.879487 | Val Loss: 0.109632, Val Acc: 0.773196\n",
      "Epoch 18153 - Train Loss: 0.083020, Train Acc: 0.879487 | Val Loss: 0.109630, Val Acc: 0.773196\n",
      "Epoch 18154 - Train Loss: 0.083018, Train Acc: 0.879487 | Val Loss: 0.109629, Val Acc: 0.773196\n",
      "Epoch 18155 - Train Loss: 0.083015, Train Acc: 0.879487 | Val Loss: 0.109628, Val Acc: 0.773196\n",
      "Epoch 18156 - Train Loss: 0.083012, Train Acc: 0.879487 | Val Loss: 0.109626, Val Acc: 0.773196\n",
      "Epoch 18157 - Train Loss: 0.083010, Train Acc: 0.879487 | Val Loss: 0.109625, Val Acc: 0.773196\n",
      "Epoch 18158 - Train Loss: 0.083007, Train Acc: 0.879487 | Val Loss: 0.109624, Val Acc: 0.773196\n",
      "Epoch 18159 - Train Loss: 0.083005, Train Acc: 0.879487 | Val Loss: 0.109622, Val Acc: 0.773196\n",
      "Epoch 18160 - Train Loss: 0.083002, Train Acc: 0.879487 | Val Loss: 0.109621, Val Acc: 0.773196\n",
      "Epoch 18161 - Train Loss: 0.083000, Train Acc: 0.879487 | Val Loss: 0.109620, Val Acc: 0.773196\n",
      "Epoch 18162 - Train Loss: 0.082997, Train Acc: 0.879487 | Val Loss: 0.109618, Val Acc: 0.773196\n",
      "Epoch 18163 - Train Loss: 0.082994, Train Acc: 0.879487 | Val Loss: 0.109617, Val Acc: 0.773196\n",
      "Epoch 18164 - Train Loss: 0.082992, Train Acc: 0.879487 | Val Loss: 0.109616, Val Acc: 0.773196\n",
      "Epoch 18165 - Train Loss: 0.082989, Train Acc: 0.879487 | Val Loss: 0.109614, Val Acc: 0.773196\n",
      "Epoch 18166 - Train Loss: 0.082987, Train Acc: 0.879487 | Val Loss: 0.109613, Val Acc: 0.773196\n",
      "Epoch 18167 - Train Loss: 0.082984, Train Acc: 0.879487 | Val Loss: 0.109612, Val Acc: 0.773196\n",
      "Epoch 18168 - Train Loss: 0.082981, Train Acc: 0.879487 | Val Loss: 0.109610, Val Acc: 0.773196\n",
      "Epoch 18169 - Train Loss: 0.082979, Train Acc: 0.879487 | Val Loss: 0.109609, Val Acc: 0.773196\n",
      "Epoch 18170 - Train Loss: 0.082976, Train Acc: 0.879487 | Val Loss: 0.109608, Val Acc: 0.773196\n",
      "Epoch 18171 - Train Loss: 0.082974, Train Acc: 0.879487 | Val Loss: 0.109606, Val Acc: 0.773196\n",
      "Epoch 18172 - Train Loss: 0.082971, Train Acc: 0.879487 | Val Loss: 0.109605, Val Acc: 0.773196\n",
      "Epoch 18173 - Train Loss: 0.082968, Train Acc: 0.879487 | Val Loss: 0.109604, Val Acc: 0.773196\n",
      "Epoch 18174 - Train Loss: 0.082966, Train Acc: 0.879487 | Val Loss: 0.109602, Val Acc: 0.773196\n",
      "Epoch 18175 - Train Loss: 0.082963, Train Acc: 0.879487 | Val Loss: 0.109601, Val Acc: 0.773196\n",
      "Epoch 18176 - Train Loss: 0.082961, Train Acc: 0.879487 | Val Loss: 0.109600, Val Acc: 0.773196\n",
      "Epoch 18177 - Train Loss: 0.082958, Train Acc: 0.879487 | Val Loss: 0.109598, Val Acc: 0.773196\n",
      "Epoch 18178 - Train Loss: 0.082955, Train Acc: 0.879487 | Val Loss: 0.109597, Val Acc: 0.773196\n",
      "Epoch 18179 - Train Loss: 0.082953, Train Acc: 0.879487 | Val Loss: 0.109596, Val Acc: 0.773196\n",
      "Epoch 18180 - Train Loss: 0.082950, Train Acc: 0.879487 | Val Loss: 0.109594, Val Acc: 0.773196\n",
      "Epoch 18181 - Train Loss: 0.082948, Train Acc: 0.879487 | Val Loss: 0.109593, Val Acc: 0.773196\n",
      "Epoch 18182 - Train Loss: 0.082945, Train Acc: 0.879487 | Val Loss: 0.109592, Val Acc: 0.773196\n",
      "Epoch 18183 - Train Loss: 0.082943, Train Acc: 0.879487 | Val Loss: 0.109590, Val Acc: 0.773196\n",
      "Epoch 18184 - Train Loss: 0.082940, Train Acc: 0.879487 | Val Loss: 0.109589, Val Acc: 0.773196\n",
      "Epoch 18185 - Train Loss: 0.082937, Train Acc: 0.879487 | Val Loss: 0.109588, Val Acc: 0.773196\n",
      "Epoch 18186 - Train Loss: 0.082935, Train Acc: 0.879487 | Val Loss: 0.109586, Val Acc: 0.773196\n",
      "Epoch 18187 - Train Loss: 0.082932, Train Acc: 0.879487 | Val Loss: 0.109585, Val Acc: 0.773196\n",
      "Epoch 18188 - Train Loss: 0.082930, Train Acc: 0.879487 | Val Loss: 0.109584, Val Acc: 0.773196\n",
      "Epoch 18189 - Train Loss: 0.082927, Train Acc: 0.879487 | Val Loss: 0.109582, Val Acc: 0.773196\n",
      "Epoch 18190 - Train Loss: 0.082924, Train Acc: 0.879487 | Val Loss: 0.109581, Val Acc: 0.773196\n",
      "Epoch 18191 - Train Loss: 0.082922, Train Acc: 0.879487 | Val Loss: 0.109580, Val Acc: 0.773196\n",
      "Epoch 18192 - Train Loss: 0.082919, Train Acc: 0.879487 | Val Loss: 0.109578, Val Acc: 0.773196\n",
      "Epoch 18193 - Train Loss: 0.082917, Train Acc: 0.879487 | Val Loss: 0.109577, Val Acc: 0.773196\n",
      "Epoch 18194 - Train Loss: 0.082914, Train Acc: 0.879487 | Val Loss: 0.109576, Val Acc: 0.773196\n",
      "Epoch 18195 - Train Loss: 0.082912, Train Acc: 0.879487 | Val Loss: 0.109574, Val Acc: 0.773196\n",
      "Epoch 18196 - Train Loss: 0.082909, Train Acc: 0.879487 | Val Loss: 0.109573, Val Acc: 0.773196\n",
      "Epoch 18197 - Train Loss: 0.082906, Train Acc: 0.879487 | Val Loss: 0.109572, Val Acc: 0.773196\n",
      "Epoch 18198 - Train Loss: 0.082904, Train Acc: 0.879487 | Val Loss: 0.109570, Val Acc: 0.773196\n",
      "Epoch 18199 - Train Loss: 0.082901, Train Acc: 0.879487 | Val Loss: 0.109569, Val Acc: 0.773196\n",
      "Epoch 18200 - Train Loss: 0.082899, Train Acc: 0.879487 | Val Loss: 0.109568, Val Acc: 0.773196\n",
      "Epoch 18201 - Train Loss: 0.082896, Train Acc: 0.879487 | Val Loss: 0.109566, Val Acc: 0.773196\n",
      "Epoch 18202 - Train Loss: 0.082893, Train Acc: 0.879487 | Val Loss: 0.109565, Val Acc: 0.773196\n",
      "Epoch 18203 - Train Loss: 0.082891, Train Acc: 0.879487 | Val Loss: 0.109564, Val Acc: 0.773196\n",
      "Epoch 18204 - Train Loss: 0.082888, Train Acc: 0.879487 | Val Loss: 0.109563, Val Acc: 0.773196\n",
      "Epoch 18205 - Train Loss: 0.082886, Train Acc: 0.879487 | Val Loss: 0.109561, Val Acc: 0.773196\n",
      "Epoch 18206 - Train Loss: 0.082883, Train Acc: 0.879487 | Val Loss: 0.109560, Val Acc: 0.773196\n",
      "Epoch 18207 - Train Loss: 0.082881, Train Acc: 0.879487 | Val Loss: 0.109559, Val Acc: 0.773196\n",
      "Epoch 18208 - Train Loss: 0.082878, Train Acc: 0.879487 | Val Loss: 0.109557, Val Acc: 0.773196\n",
      "Epoch 18209 - Train Loss: 0.082875, Train Acc: 0.879487 | Val Loss: 0.109556, Val Acc: 0.773196\n",
      "Epoch 18210 - Train Loss: 0.082873, Train Acc: 0.879487 | Val Loss: 0.109555, Val Acc: 0.773196\n",
      "Epoch 18211 - Train Loss: 0.082870, Train Acc: 0.879487 | Val Loss: 0.109553, Val Acc: 0.773196\n",
      "Epoch 18212 - Train Loss: 0.082868, Train Acc: 0.879487 | Val Loss: 0.109552, Val Acc: 0.773196\n",
      "Epoch 18213 - Train Loss: 0.082865, Train Acc: 0.879487 | Val Loss: 0.109551, Val Acc: 0.773196\n",
      "Epoch 18214 - Train Loss: 0.082862, Train Acc: 0.879487 | Val Loss: 0.109549, Val Acc: 0.773196\n",
      "Epoch 18215 - Train Loss: 0.082860, Train Acc: 0.879487 | Val Loss: 0.109548, Val Acc: 0.773196\n",
      "Epoch 18216 - Train Loss: 0.082857, Train Acc: 0.879487 | Val Loss: 0.109547, Val Acc: 0.773196\n",
      "Epoch 18217 - Train Loss: 0.082855, Train Acc: 0.879487 | Val Loss: 0.109545, Val Acc: 0.773196\n",
      "Epoch 18218 - Train Loss: 0.082852, Train Acc: 0.879487 | Val Loss: 0.109544, Val Acc: 0.773196\n",
      "Epoch 18219 - Train Loss: 0.082850, Train Acc: 0.879487 | Val Loss: 0.109543, Val Acc: 0.773196\n",
      "Epoch 18220 - Train Loss: 0.082847, Train Acc: 0.879487 | Val Loss: 0.109541, Val Acc: 0.773196\n",
      "Epoch 18221 - Train Loss: 0.082844, Train Acc: 0.879487 | Val Loss: 0.109540, Val Acc: 0.773196\n",
      "Epoch 18222 - Train Loss: 0.082842, Train Acc: 0.879487 | Val Loss: 0.109539, Val Acc: 0.773196\n",
      "Epoch 18223 - Train Loss: 0.082839, Train Acc: 0.879487 | Val Loss: 0.109537, Val Acc: 0.773196\n",
      "Epoch 18224 - Train Loss: 0.082837, Train Acc: 0.879487 | Val Loss: 0.109536, Val Acc: 0.773196\n",
      "Epoch 18225 - Train Loss: 0.082834, Train Acc: 0.879487 | Val Loss: 0.109535, Val Acc: 0.773196\n",
      "Epoch 18226 - Train Loss: 0.082832, Train Acc: 0.879487 | Val Loss: 0.109534, Val Acc: 0.773196\n",
      "Epoch 18227 - Train Loss: 0.082829, Train Acc: 0.879487 | Val Loss: 0.109532, Val Acc: 0.773196\n",
      "Epoch 18228 - Train Loss: 0.082826, Train Acc: 0.879487 | Val Loss: 0.109531, Val Acc: 0.773196\n",
      "Epoch 18229 - Train Loss: 0.082824, Train Acc: 0.879487 | Val Loss: 0.109530, Val Acc: 0.773196\n",
      "Epoch 18230 - Train Loss: 0.082821, Train Acc: 0.879487 | Val Loss: 0.109528, Val Acc: 0.773196\n",
      "Epoch 18231 - Train Loss: 0.082819, Train Acc: 0.879487 | Val Loss: 0.109527, Val Acc: 0.773196\n",
      "Epoch 18232 - Train Loss: 0.082816, Train Acc: 0.879487 | Val Loss: 0.109526, Val Acc: 0.773196\n",
      "Epoch 18233 - Train Loss: 0.082814, Train Acc: 0.879487 | Val Loss: 0.109524, Val Acc: 0.773196\n",
      "Epoch 18234 - Train Loss: 0.082811, Train Acc: 0.879487 | Val Loss: 0.109523, Val Acc: 0.773196\n",
      "Epoch 18235 - Train Loss: 0.082808, Train Acc: 0.879487 | Val Loss: 0.109522, Val Acc: 0.773196\n",
      "Epoch 18236 - Train Loss: 0.082806, Train Acc: 0.879487 | Val Loss: 0.109520, Val Acc: 0.773196\n",
      "Epoch 18237 - Train Loss: 0.082803, Train Acc: 0.879487 | Val Loss: 0.109519, Val Acc: 0.773196\n",
      "Epoch 18238 - Train Loss: 0.082801, Train Acc: 0.879487 | Val Loss: 0.109518, Val Acc: 0.773196\n",
      "Epoch 18239 - Train Loss: 0.082798, Train Acc: 0.879487 | Val Loss: 0.109516, Val Acc: 0.773196\n",
      "Epoch 18240 - Train Loss: 0.082796, Train Acc: 0.879487 | Val Loss: 0.109515, Val Acc: 0.773196\n",
      "Epoch 18241 - Train Loss: 0.082793, Train Acc: 0.879487 | Val Loss: 0.109514, Val Acc: 0.773196\n",
      "Epoch 18242 - Train Loss: 0.082790, Train Acc: 0.879487 | Val Loss: 0.109512, Val Acc: 0.773196\n",
      "Epoch 18243 - Train Loss: 0.082788, Train Acc: 0.879487 | Val Loss: 0.109511, Val Acc: 0.773196\n",
      "Epoch 18244 - Train Loss: 0.082785, Train Acc: 0.879487 | Val Loss: 0.109510, Val Acc: 0.773196\n",
      "Epoch 18245 - Train Loss: 0.082783, Train Acc: 0.879487 | Val Loss: 0.109509, Val Acc: 0.773196\n",
      "Epoch 18246 - Train Loss: 0.082780, Train Acc: 0.879487 | Val Loss: 0.109507, Val Acc: 0.773196\n",
      "Epoch 18247 - Train Loss: 0.082778, Train Acc: 0.879487 | Val Loss: 0.109506, Val Acc: 0.773196\n",
      "Epoch 18248 - Train Loss: 0.082775, Train Acc: 0.879487 | Val Loss: 0.109505, Val Acc: 0.773196\n",
      "Epoch 18249 - Train Loss: 0.082772, Train Acc: 0.879487 | Val Loss: 0.109503, Val Acc: 0.773196\n",
      "Epoch 18250 - Train Loss: 0.082770, Train Acc: 0.879487 | Val Loss: 0.109502, Val Acc: 0.773196\n",
      "Epoch 18251 - Train Loss: 0.082767, Train Acc: 0.879487 | Val Loss: 0.109501, Val Acc: 0.773196\n",
      "Epoch 18252 - Train Loss: 0.082765, Train Acc: 0.879487 | Val Loss: 0.109499, Val Acc: 0.773196\n",
      "Epoch 18253 - Train Loss: 0.082762, Train Acc: 0.879487 | Val Loss: 0.109498, Val Acc: 0.773196\n",
      "Epoch 18254 - Train Loss: 0.082760, Train Acc: 0.879487 | Val Loss: 0.109497, Val Acc: 0.773196\n",
      "Epoch 18255 - Train Loss: 0.082757, Train Acc: 0.879487 | Val Loss: 0.109495, Val Acc: 0.773196\n",
      "Epoch 18256 - Train Loss: 0.082754, Train Acc: 0.879487 | Val Loss: 0.109494, Val Acc: 0.773196\n",
      "Epoch 18257 - Train Loss: 0.082752, Train Acc: 0.879487 | Val Loss: 0.109493, Val Acc: 0.773196\n",
      "Epoch 18258 - Train Loss: 0.082749, Train Acc: 0.879487 | Val Loss: 0.109492, Val Acc: 0.773196\n",
      "Epoch 18259 - Train Loss: 0.082747, Train Acc: 0.879487 | Val Loss: 0.109490, Val Acc: 0.773196\n",
      "Epoch 18260 - Train Loss: 0.082744, Train Acc: 0.879487 | Val Loss: 0.109489, Val Acc: 0.773196\n",
      "Epoch 18261 - Train Loss: 0.082742, Train Acc: 0.879487 | Val Loss: 0.109488, Val Acc: 0.773196\n",
      "Epoch 18262 - Train Loss: 0.082739, Train Acc: 0.879487 | Val Loss: 0.109486, Val Acc: 0.773196\n",
      "Epoch 18263 - Train Loss: 0.082737, Train Acc: 0.879487 | Val Loss: 0.109485, Val Acc: 0.773196\n",
      "Epoch 18264 - Train Loss: 0.082734, Train Acc: 0.879487 | Val Loss: 0.109484, Val Acc: 0.773196\n",
      "Epoch 18265 - Train Loss: 0.082731, Train Acc: 0.879487 | Val Loss: 0.109482, Val Acc: 0.773196\n",
      "Epoch 18266 - Train Loss: 0.082729, Train Acc: 0.879487 | Val Loss: 0.109481, Val Acc: 0.773196\n",
      "Epoch 18267 - Train Loss: 0.082726, Train Acc: 0.879487 | Val Loss: 0.109480, Val Acc: 0.773196\n",
      "Epoch 18268 - Train Loss: 0.082724, Train Acc: 0.879487 | Val Loss: 0.109478, Val Acc: 0.773196\n",
      "Epoch 18269 - Train Loss: 0.082721, Train Acc: 0.879487 | Val Loss: 0.109477, Val Acc: 0.773196\n",
      "Epoch 18270 - Train Loss: 0.082719, Train Acc: 0.879487 | Val Loss: 0.109476, Val Acc: 0.773196\n",
      "Epoch 18271 - Train Loss: 0.082716, Train Acc: 0.879487 | Val Loss: 0.109474, Val Acc: 0.773196\n",
      "Epoch 18272 - Train Loss: 0.082713, Train Acc: 0.879487 | Val Loss: 0.109473, Val Acc: 0.773196\n",
      "Epoch 18273 - Train Loss: 0.082711, Train Acc: 0.879487 | Val Loss: 0.109472, Val Acc: 0.773196\n",
      "Epoch 18274 - Train Loss: 0.082708, Train Acc: 0.879487 | Val Loss: 0.109471, Val Acc: 0.773196\n",
      "Epoch 18275 - Train Loss: 0.082706, Train Acc: 0.879487 | Val Loss: 0.109469, Val Acc: 0.773196\n",
      "Epoch 18276 - Train Loss: 0.082703, Train Acc: 0.879487 | Val Loss: 0.109468, Val Acc: 0.773196\n",
      "Epoch 18277 - Train Loss: 0.082701, Train Acc: 0.879487 | Val Loss: 0.109467, Val Acc: 0.773196\n",
      "Epoch 18278 - Train Loss: 0.082698, Train Acc: 0.879487 | Val Loss: 0.109465, Val Acc: 0.773196\n",
      "Epoch 18279 - Train Loss: 0.082696, Train Acc: 0.879487 | Val Loss: 0.109464, Val Acc: 0.773196\n",
      "Epoch 18280 - Train Loss: 0.082693, Train Acc: 0.879487 | Val Loss: 0.109463, Val Acc: 0.773196\n",
      "Epoch 18281 - Train Loss: 0.082690, Train Acc: 0.879487 | Val Loss: 0.109462, Val Acc: 0.773196\n",
      "Epoch 18282 - Train Loss: 0.082688, Train Acc: 0.879487 | Val Loss: 0.109460, Val Acc: 0.773196\n",
      "Epoch 18283 - Train Loss: 0.082685, Train Acc: 0.879487 | Val Loss: 0.109459, Val Acc: 0.773196\n",
      "Epoch 18284 - Train Loss: 0.082683, Train Acc: 0.879487 | Val Loss: 0.109458, Val Acc: 0.773196\n",
      "Epoch 18285 - Train Loss: 0.082680, Train Acc: 0.879487 | Val Loss: 0.109456, Val Acc: 0.773196\n",
      "Epoch 18286 - Train Loss: 0.082678, Train Acc: 0.879487 | Val Loss: 0.109455, Val Acc: 0.773196\n",
      "Epoch 18287 - Train Loss: 0.082675, Train Acc: 0.879487 | Val Loss: 0.109454, Val Acc: 0.773196\n",
      "Epoch 18288 - Train Loss: 0.082673, Train Acc: 0.879487 | Val Loss: 0.109452, Val Acc: 0.773196\n",
      "Epoch 18289 - Train Loss: 0.082670, Train Acc: 0.879487 | Val Loss: 0.109451, Val Acc: 0.773196\n",
      "Epoch 18290 - Train Loss: 0.082667, Train Acc: 0.879487 | Val Loss: 0.109450, Val Acc: 0.773196\n",
      "Epoch 18291 - Train Loss: 0.082665, Train Acc: 0.879487 | Val Loss: 0.109448, Val Acc: 0.773196\n",
      "Epoch 18292 - Train Loss: 0.082662, Train Acc: 0.879487 | Val Loss: 0.109447, Val Acc: 0.773196\n",
      "Epoch 18293 - Train Loss: 0.082660, Train Acc: 0.879487 | Val Loss: 0.109446, Val Acc: 0.773196\n",
      "Epoch 18294 - Train Loss: 0.082657, Train Acc: 0.879487 | Val Loss: 0.109445, Val Acc: 0.773196\n",
      "Epoch 18295 - Train Loss: 0.082655, Train Acc: 0.879487 | Val Loss: 0.109443, Val Acc: 0.773196\n",
      "Epoch 18296 - Train Loss: 0.082652, Train Acc: 0.879487 | Val Loss: 0.109442, Val Acc: 0.773196\n",
      "Epoch 18297 - Train Loss: 0.082649, Train Acc: 0.879487 | Val Loss: 0.109441, Val Acc: 0.773196\n",
      "Epoch 18298 - Train Loss: 0.082647, Train Acc: 0.879487 | Val Loss: 0.109439, Val Acc: 0.773196\n",
      "Epoch 18299 - Train Loss: 0.082644, Train Acc: 0.879487 | Val Loss: 0.109438, Val Acc: 0.773196\n",
      "Epoch 18300 - Train Loss: 0.082642, Train Acc: 0.879487 | Val Loss: 0.109437, Val Acc: 0.773196\n",
      "Epoch 18301 - Train Loss: 0.082639, Train Acc: 0.879487 | Val Loss: 0.109436, Val Acc: 0.773196\n",
      "Epoch 18302 - Train Loss: 0.082637, Train Acc: 0.879487 | Val Loss: 0.109434, Val Acc: 0.773196\n",
      "Epoch 18303 - Train Loss: 0.082634, Train Acc: 0.879487 | Val Loss: 0.109433, Val Acc: 0.773196\n",
      "Epoch 18304 - Train Loss: 0.082632, Train Acc: 0.879487 | Val Loss: 0.109432, Val Acc: 0.773196\n",
      "Epoch 18305 - Train Loss: 0.082629, Train Acc: 0.879487 | Val Loss: 0.109430, Val Acc: 0.773196\n",
      "Epoch 18306 - Train Loss: 0.082627, Train Acc: 0.879487 | Val Loss: 0.109429, Val Acc: 0.773196\n",
      "Epoch 18307 - Train Loss: 0.082624, Train Acc: 0.879487 | Val Loss: 0.109428, Val Acc: 0.773196\n",
      "Epoch 18308 - Train Loss: 0.082621, Train Acc: 0.879487 | Val Loss: 0.109426, Val Acc: 0.773196\n",
      "Epoch 18309 - Train Loss: 0.082619, Train Acc: 0.879487 | Val Loss: 0.109425, Val Acc: 0.773196\n",
      "Epoch 18310 - Train Loss: 0.082616, Train Acc: 0.879487 | Val Loss: 0.109424, Val Acc: 0.773196\n",
      "Epoch 18311 - Train Loss: 0.082614, Train Acc: 0.879487 | Val Loss: 0.109423, Val Acc: 0.773196\n",
      "Epoch 18312 - Train Loss: 0.082611, Train Acc: 0.879487 | Val Loss: 0.109421, Val Acc: 0.773196\n",
      "Epoch 18313 - Train Loss: 0.082609, Train Acc: 0.879487 | Val Loss: 0.109420, Val Acc: 0.773196\n",
      "Epoch 18314 - Train Loss: 0.082606, Train Acc: 0.879487 | Val Loss: 0.109419, Val Acc: 0.773196\n",
      "Epoch 18315 - Train Loss: 0.082604, Train Acc: 0.879487 | Val Loss: 0.109417, Val Acc: 0.773196\n",
      "Epoch 18316 - Train Loss: 0.082601, Train Acc: 0.879487 | Val Loss: 0.109416, Val Acc: 0.773196\n",
      "Epoch 18317 - Train Loss: 0.082598, Train Acc: 0.879487 | Val Loss: 0.109415, Val Acc: 0.773196\n",
      "Epoch 18318 - Train Loss: 0.082596, Train Acc: 0.879487 | Val Loss: 0.109413, Val Acc: 0.773196\n",
      "Epoch 18319 - Train Loss: 0.082593, Train Acc: 0.879487 | Val Loss: 0.109412, Val Acc: 0.773196\n",
      "Epoch 18320 - Train Loss: 0.082591, Train Acc: 0.879487 | Val Loss: 0.109411, Val Acc: 0.773196\n",
      "Epoch 18321 - Train Loss: 0.082588, Train Acc: 0.879487 | Val Loss: 0.109410, Val Acc: 0.773196\n",
      "Epoch 18322 - Train Loss: 0.082586, Train Acc: 0.879487 | Val Loss: 0.109408, Val Acc: 0.773196\n",
      "Epoch 18323 - Train Loss: 0.082583, Train Acc: 0.879487 | Val Loss: 0.109407, Val Acc: 0.773196\n",
      "Epoch 18324 - Train Loss: 0.082581, Train Acc: 0.879487 | Val Loss: 0.109406, Val Acc: 0.773196\n",
      "Epoch 18325 - Train Loss: 0.082578, Train Acc: 0.879487 | Val Loss: 0.109404, Val Acc: 0.773196\n",
      "Epoch 18326 - Train Loss: 0.082576, Train Acc: 0.879487 | Val Loss: 0.109403, Val Acc: 0.773196\n",
      "Epoch 18327 - Train Loss: 0.082573, Train Acc: 0.879487 | Val Loss: 0.109402, Val Acc: 0.773196\n",
      "Epoch 18328 - Train Loss: 0.082570, Train Acc: 0.879487 | Val Loss: 0.109401, Val Acc: 0.773196\n",
      "Epoch 18329 - Train Loss: 0.082568, Train Acc: 0.879487 | Val Loss: 0.109399, Val Acc: 0.773196\n",
      "Epoch 18330 - Train Loss: 0.082565, Train Acc: 0.879487 | Val Loss: 0.109398, Val Acc: 0.773196\n",
      "Epoch 18331 - Train Loss: 0.082563, Train Acc: 0.879487 | Val Loss: 0.109397, Val Acc: 0.773196\n",
      "Epoch 18332 - Train Loss: 0.082560, Train Acc: 0.879487 | Val Loss: 0.109396, Val Acc: 0.773196\n",
      "Epoch 18333 - Train Loss: 0.082558, Train Acc: 0.879487 | Val Loss: 0.109394, Val Acc: 0.773196\n",
      "Epoch 18334 - Train Loss: 0.082555, Train Acc: 0.879487 | Val Loss: 0.109393, Val Acc: 0.773196\n",
      "Epoch 18335 - Train Loss: 0.082553, Train Acc: 0.879487 | Val Loss: 0.109392, Val Acc: 0.773196\n",
      "Epoch 18336 - Train Loss: 0.082550, Train Acc: 0.879487 | Val Loss: 0.109390, Val Acc: 0.773196\n",
      "Epoch 18337 - Train Loss: 0.082548, Train Acc: 0.879487 | Val Loss: 0.109389, Val Acc: 0.773196\n",
      "Epoch 18338 - Train Loss: 0.082545, Train Acc: 0.879487 | Val Loss: 0.109388, Val Acc: 0.773196\n",
      "Epoch 18339 - Train Loss: 0.082542, Train Acc: 0.879487 | Val Loss: 0.109387, Val Acc: 0.773196\n",
      "Epoch 18340 - Train Loss: 0.082540, Train Acc: 0.879487 | Val Loss: 0.109385, Val Acc: 0.773196\n",
      "Epoch 18341 - Train Loss: 0.082537, Train Acc: 0.879487 | Val Loss: 0.109384, Val Acc: 0.773196\n",
      "Epoch 18342 - Train Loss: 0.082535, Train Acc: 0.879487 | Val Loss: 0.109383, Val Acc: 0.773196\n",
      "Epoch 18343 - Train Loss: 0.082532, Train Acc: 0.879487 | Val Loss: 0.109381, Val Acc: 0.773196\n",
      "Epoch 18344 - Train Loss: 0.082530, Train Acc: 0.879487 | Val Loss: 0.109380, Val Acc: 0.773196\n",
      "Epoch 18345 - Train Loss: 0.082527, Train Acc: 0.879487 | Val Loss: 0.109379, Val Acc: 0.773196\n",
      "Epoch 18346 - Train Loss: 0.082525, Train Acc: 0.879487 | Val Loss: 0.109378, Val Acc: 0.773196\n",
      "Epoch 18347 - Train Loss: 0.082522, Train Acc: 0.879487 | Val Loss: 0.109376, Val Acc: 0.773196\n",
      "Epoch 18348 - Train Loss: 0.082520, Train Acc: 0.879487 | Val Loss: 0.109375, Val Acc: 0.773196\n",
      "Epoch 18349 - Train Loss: 0.082517, Train Acc: 0.879487 | Val Loss: 0.109374, Val Acc: 0.773196\n",
      "Epoch 18350 - Train Loss: 0.082515, Train Acc: 0.879487 | Val Loss: 0.109372, Val Acc: 0.773196\n",
      "Epoch 18351 - Train Loss: 0.082512, Train Acc: 0.879487 | Val Loss: 0.109371, Val Acc: 0.773196\n",
      "Epoch 18352 - Train Loss: 0.082509, Train Acc: 0.879487 | Val Loss: 0.109370, Val Acc: 0.773196\n",
      "Epoch 18353 - Train Loss: 0.082507, Train Acc: 0.879487 | Val Loss: 0.109368, Val Acc: 0.773196\n",
      "Epoch 18354 - Train Loss: 0.082504, Train Acc: 0.879487 | Val Loss: 0.109367, Val Acc: 0.773196\n",
      "Epoch 18355 - Train Loss: 0.082502, Train Acc: 0.879487 | Val Loss: 0.109366, Val Acc: 0.773196\n",
      "Epoch 18356 - Train Loss: 0.082499, Train Acc: 0.879487 | Val Loss: 0.109365, Val Acc: 0.773196\n",
      "Epoch 18357 - Train Loss: 0.082497, Train Acc: 0.879487 | Val Loss: 0.109363, Val Acc: 0.773196\n",
      "Epoch 18358 - Train Loss: 0.082494, Train Acc: 0.879487 | Val Loss: 0.109362, Val Acc: 0.773196\n",
      "Epoch 18359 - Train Loss: 0.082492, Train Acc: 0.879487 | Val Loss: 0.109361, Val Acc: 0.773196\n",
      "Epoch 18360 - Train Loss: 0.082489, Train Acc: 0.879487 | Val Loss: 0.109360, Val Acc: 0.773196\n",
      "Epoch 18361 - Train Loss: 0.082487, Train Acc: 0.879487 | Val Loss: 0.109358, Val Acc: 0.773196\n",
      "Epoch 18362 - Train Loss: 0.082484, Train Acc: 0.879487 | Val Loss: 0.109357, Val Acc: 0.773196\n",
      "Epoch 18363 - Train Loss: 0.082482, Train Acc: 0.879487 | Val Loss: 0.109356, Val Acc: 0.773196\n",
      "Epoch 18364 - Train Loss: 0.082479, Train Acc: 0.879487 | Val Loss: 0.109354, Val Acc: 0.773196\n",
      "Epoch 18365 - Train Loss: 0.082476, Train Acc: 0.879487 | Val Loss: 0.109353, Val Acc: 0.773196\n",
      "Epoch 18366 - Train Loss: 0.082474, Train Acc: 0.879487 | Val Loss: 0.109352, Val Acc: 0.773196\n",
      "Epoch 18367 - Train Loss: 0.082471, Train Acc: 0.879487 | Val Loss: 0.109351, Val Acc: 0.773196\n",
      "Epoch 18368 - Train Loss: 0.082469, Train Acc: 0.879487 | Val Loss: 0.109349, Val Acc: 0.773196\n",
      "Epoch 18369 - Train Loss: 0.082466, Train Acc: 0.879487 | Val Loss: 0.109348, Val Acc: 0.773196\n",
      "Epoch 18370 - Train Loss: 0.082464, Train Acc: 0.879487 | Val Loss: 0.109347, Val Acc: 0.773196\n",
      "Epoch 18371 - Train Loss: 0.082461, Train Acc: 0.879487 | Val Loss: 0.109345, Val Acc: 0.773196\n",
      "Epoch 18372 - Train Loss: 0.082459, Train Acc: 0.879487 | Val Loss: 0.109344, Val Acc: 0.773196\n",
      "Epoch 18373 - Train Loss: 0.082456, Train Acc: 0.879487 | Val Loss: 0.109343, Val Acc: 0.773196\n",
      "Epoch 18374 - Train Loss: 0.082454, Train Acc: 0.879487 | Val Loss: 0.109342, Val Acc: 0.773196\n",
      "Epoch 18375 - Train Loss: 0.082451, Train Acc: 0.879487 | Val Loss: 0.109340, Val Acc: 0.773196\n",
      "Epoch 18376 - Train Loss: 0.082449, Train Acc: 0.879487 | Val Loss: 0.109339, Val Acc: 0.773196\n",
      "Epoch 18377 - Train Loss: 0.082446, Train Acc: 0.879487 | Val Loss: 0.109338, Val Acc: 0.773196\n",
      "Epoch 18378 - Train Loss: 0.082444, Train Acc: 0.879487 | Val Loss: 0.109337, Val Acc: 0.773196\n",
      "Epoch 18379 - Train Loss: 0.082441, Train Acc: 0.879487 | Val Loss: 0.109335, Val Acc: 0.773196\n",
      "Epoch 18380 - Train Loss: 0.082438, Train Acc: 0.879487 | Val Loss: 0.109334, Val Acc: 0.773196\n",
      "Epoch 18381 - Train Loss: 0.082436, Train Acc: 0.880769 | Val Loss: 0.109333, Val Acc: 0.773196\n",
      "Epoch 18382 - Train Loss: 0.082433, Train Acc: 0.880769 | Val Loss: 0.109331, Val Acc: 0.773196\n",
      "Epoch 18383 - Train Loss: 0.082431, Train Acc: 0.880769 | Val Loss: 0.109330, Val Acc: 0.773196\n",
      "Epoch 18384 - Train Loss: 0.082428, Train Acc: 0.880769 | Val Loss: 0.109329, Val Acc: 0.773196\n",
      "Epoch 18385 - Train Loss: 0.082426, Train Acc: 0.880769 | Val Loss: 0.109328, Val Acc: 0.773196\n",
      "Epoch 18386 - Train Loss: 0.082423, Train Acc: 0.880769 | Val Loss: 0.109326, Val Acc: 0.773196\n",
      "Epoch 18387 - Train Loss: 0.082421, Train Acc: 0.880769 | Val Loss: 0.109325, Val Acc: 0.773196\n",
      "Epoch 18388 - Train Loss: 0.082418, Train Acc: 0.880769 | Val Loss: 0.109324, Val Acc: 0.773196\n",
      "Epoch 18389 - Train Loss: 0.082416, Train Acc: 0.880769 | Val Loss: 0.109322, Val Acc: 0.773196\n",
      "Epoch 18390 - Train Loss: 0.082413, Train Acc: 0.880769 | Val Loss: 0.109321, Val Acc: 0.773196\n",
      "Epoch 18391 - Train Loss: 0.082411, Train Acc: 0.880769 | Val Loss: 0.109320, Val Acc: 0.773196\n",
      "Epoch 18392 - Train Loss: 0.082408, Train Acc: 0.880769 | Val Loss: 0.109319, Val Acc: 0.773196\n",
      "Epoch 18393 - Train Loss: 0.082406, Train Acc: 0.880769 | Val Loss: 0.109317, Val Acc: 0.773196\n",
      "Epoch 18394 - Train Loss: 0.082403, Train Acc: 0.880769 | Val Loss: 0.109316, Val Acc: 0.773196\n",
      "Epoch 18395 - Train Loss: 0.082401, Train Acc: 0.880769 | Val Loss: 0.109315, Val Acc: 0.773196\n",
      "Epoch 18396 - Train Loss: 0.082398, Train Acc: 0.880769 | Val Loss: 0.109314, Val Acc: 0.773196\n",
      "Epoch 18397 - Train Loss: 0.082396, Train Acc: 0.880769 | Val Loss: 0.109312, Val Acc: 0.773196\n",
      "Epoch 18398 - Train Loss: 0.082393, Train Acc: 0.880769 | Val Loss: 0.109311, Val Acc: 0.773196\n",
      "Epoch 18399 - Train Loss: 0.082390, Train Acc: 0.880769 | Val Loss: 0.109310, Val Acc: 0.773196\n",
      "Epoch 18400 - Train Loss: 0.082388, Train Acc: 0.880769 | Val Loss: 0.109309, Val Acc: 0.773196\n",
      "Epoch 18401 - Train Loss: 0.082385, Train Acc: 0.880769 | Val Loss: 0.109307, Val Acc: 0.773196\n",
      "Epoch 18402 - Train Loss: 0.082383, Train Acc: 0.880769 | Val Loss: 0.109306, Val Acc: 0.773196\n",
      "Epoch 18403 - Train Loss: 0.082380, Train Acc: 0.880769 | Val Loss: 0.109305, Val Acc: 0.773196\n",
      "Epoch 18404 - Train Loss: 0.082378, Train Acc: 0.880769 | Val Loss: 0.109303, Val Acc: 0.773196\n",
      "Epoch 18405 - Train Loss: 0.082375, Train Acc: 0.880769 | Val Loss: 0.109302, Val Acc: 0.773196\n",
      "Epoch 18406 - Train Loss: 0.082373, Train Acc: 0.880769 | Val Loss: 0.109301, Val Acc: 0.773196\n",
      "Epoch 18407 - Train Loss: 0.082370, Train Acc: 0.880769 | Val Loss: 0.109300, Val Acc: 0.773196\n",
      "Epoch 18408 - Train Loss: 0.082368, Train Acc: 0.880769 | Val Loss: 0.109298, Val Acc: 0.773196\n",
      "Epoch 18409 - Train Loss: 0.082365, Train Acc: 0.880769 | Val Loss: 0.109297, Val Acc: 0.773196\n",
      "Epoch 18410 - Train Loss: 0.082363, Train Acc: 0.880769 | Val Loss: 0.109296, Val Acc: 0.773196\n",
      "Epoch 18411 - Train Loss: 0.082360, Train Acc: 0.880769 | Val Loss: 0.109295, Val Acc: 0.773196\n",
      "Epoch 18412 - Train Loss: 0.082358, Train Acc: 0.880769 | Val Loss: 0.109293, Val Acc: 0.773196\n",
      "Epoch 18413 - Train Loss: 0.082355, Train Acc: 0.880769 | Val Loss: 0.109292, Val Acc: 0.773196\n",
      "Epoch 18414 - Train Loss: 0.082353, Train Acc: 0.880769 | Val Loss: 0.109291, Val Acc: 0.773196\n",
      "Epoch 18415 - Train Loss: 0.082350, Train Acc: 0.880769 | Val Loss: 0.109290, Val Acc: 0.773196\n",
      "Epoch 18416 - Train Loss: 0.082348, Train Acc: 0.880769 | Val Loss: 0.109288, Val Acc: 0.773196\n",
      "Epoch 18417 - Train Loss: 0.082345, Train Acc: 0.880769 | Val Loss: 0.109287, Val Acc: 0.773196\n",
      "Epoch 18418 - Train Loss: 0.082343, Train Acc: 0.880769 | Val Loss: 0.109286, Val Acc: 0.773196\n",
      "Epoch 18419 - Train Loss: 0.082340, Train Acc: 0.880769 | Val Loss: 0.109284, Val Acc: 0.773196\n",
      "Epoch 18420 - Train Loss: 0.082338, Train Acc: 0.880769 | Val Loss: 0.109283, Val Acc: 0.773196\n",
      "Epoch 18421 - Train Loss: 0.082335, Train Acc: 0.880769 | Val Loss: 0.109282, Val Acc: 0.773196\n",
      "Epoch 18422 - Train Loss: 0.082332, Train Acc: 0.880769 | Val Loss: 0.109281, Val Acc: 0.773196\n",
      "Epoch 18423 - Train Loss: 0.082330, Train Acc: 0.880769 | Val Loss: 0.109279, Val Acc: 0.773196\n",
      "Epoch 18424 - Train Loss: 0.082327, Train Acc: 0.880769 | Val Loss: 0.109278, Val Acc: 0.773196\n",
      "Epoch 18425 - Train Loss: 0.082325, Train Acc: 0.880769 | Val Loss: 0.109277, Val Acc: 0.773196\n",
      "Epoch 18426 - Train Loss: 0.082322, Train Acc: 0.880769 | Val Loss: 0.109276, Val Acc: 0.773196\n",
      "Epoch 18427 - Train Loss: 0.082320, Train Acc: 0.880769 | Val Loss: 0.109274, Val Acc: 0.773196\n",
      "Epoch 18428 - Train Loss: 0.082317, Train Acc: 0.880769 | Val Loss: 0.109273, Val Acc: 0.773196\n",
      "Epoch 18429 - Train Loss: 0.082315, Train Acc: 0.880769 | Val Loss: 0.109272, Val Acc: 0.773196\n",
      "Epoch 18430 - Train Loss: 0.082312, Train Acc: 0.880769 | Val Loss: 0.109271, Val Acc: 0.773196\n",
      "Epoch 18431 - Train Loss: 0.082310, Train Acc: 0.880769 | Val Loss: 0.109269, Val Acc: 0.773196\n",
      "Epoch 18432 - Train Loss: 0.082307, Train Acc: 0.880769 | Val Loss: 0.109268, Val Acc: 0.773196\n",
      "Epoch 18433 - Train Loss: 0.082305, Train Acc: 0.880769 | Val Loss: 0.109267, Val Acc: 0.773196\n",
      "Epoch 18434 - Train Loss: 0.082302, Train Acc: 0.880769 | Val Loss: 0.109265, Val Acc: 0.773196\n",
      "Epoch 18435 - Train Loss: 0.082300, Train Acc: 0.880769 | Val Loss: 0.109264, Val Acc: 0.773196\n",
      "Epoch 18436 - Train Loss: 0.082297, Train Acc: 0.880769 | Val Loss: 0.109263, Val Acc: 0.773196\n",
      "Epoch 18437 - Train Loss: 0.082295, Train Acc: 0.880769 | Val Loss: 0.109262, Val Acc: 0.773196\n",
      "Epoch 18438 - Train Loss: 0.082292, Train Acc: 0.880769 | Val Loss: 0.109260, Val Acc: 0.773196\n",
      "Epoch 18439 - Train Loss: 0.082290, Train Acc: 0.880769 | Val Loss: 0.109259, Val Acc: 0.773196\n",
      "Epoch 18440 - Train Loss: 0.082287, Train Acc: 0.880769 | Val Loss: 0.109258, Val Acc: 0.773196\n",
      "Epoch 18441 - Train Loss: 0.082285, Train Acc: 0.880769 | Val Loss: 0.109257, Val Acc: 0.773196\n",
      "Epoch 18442 - Train Loss: 0.082282, Train Acc: 0.880769 | Val Loss: 0.109255, Val Acc: 0.773196\n",
      "Epoch 18443 - Train Loss: 0.082280, Train Acc: 0.880769 | Val Loss: 0.109254, Val Acc: 0.773196\n",
      "Epoch 18444 - Train Loss: 0.082277, Train Acc: 0.880769 | Val Loss: 0.109253, Val Acc: 0.773196\n",
      "Epoch 18445 - Train Loss: 0.082275, Train Acc: 0.880769 | Val Loss: 0.109252, Val Acc: 0.773196\n",
      "Epoch 18446 - Train Loss: 0.082272, Train Acc: 0.880769 | Val Loss: 0.109250, Val Acc: 0.773196\n",
      "Epoch 18447 - Train Loss: 0.082270, Train Acc: 0.880769 | Val Loss: 0.109249, Val Acc: 0.773196\n",
      "Epoch 18448 - Train Loss: 0.082267, Train Acc: 0.880769 | Val Loss: 0.109248, Val Acc: 0.773196\n",
      "Epoch 18449 - Train Loss: 0.082265, Train Acc: 0.880769 | Val Loss: 0.109247, Val Acc: 0.773196\n",
      "Epoch 18450 - Train Loss: 0.082262, Train Acc: 0.880769 | Val Loss: 0.109245, Val Acc: 0.773196\n",
      "Epoch 18451 - Train Loss: 0.082260, Train Acc: 0.880769 | Val Loss: 0.109244, Val Acc: 0.773196\n",
      "Epoch 18452 - Train Loss: 0.082257, Train Acc: 0.880769 | Val Loss: 0.109243, Val Acc: 0.773196\n",
      "Epoch 18453 - Train Loss: 0.082255, Train Acc: 0.880769 | Val Loss: 0.109242, Val Acc: 0.773196\n",
      "Epoch 18454 - Train Loss: 0.082252, Train Acc: 0.880769 | Val Loss: 0.109240, Val Acc: 0.773196\n",
      "Epoch 18455 - Train Loss: 0.082250, Train Acc: 0.880769 | Val Loss: 0.109239, Val Acc: 0.773196\n",
      "Epoch 18456 - Train Loss: 0.082247, Train Acc: 0.880769 | Val Loss: 0.109238, Val Acc: 0.773196\n",
      "Epoch 18457 - Train Loss: 0.082245, Train Acc: 0.880769 | Val Loss: 0.109237, Val Acc: 0.773196\n",
      "Epoch 18458 - Train Loss: 0.082242, Train Acc: 0.880769 | Val Loss: 0.109235, Val Acc: 0.773196\n",
      "Epoch 18459 - Train Loss: 0.082239, Train Acc: 0.880769 | Val Loss: 0.109234, Val Acc: 0.773196\n",
      "Epoch 18460 - Train Loss: 0.082237, Train Acc: 0.880769 | Val Loss: 0.109233, Val Acc: 0.773196\n",
      "Epoch 18461 - Train Loss: 0.082234, Train Acc: 0.880769 | Val Loss: 0.109232, Val Acc: 0.773196\n",
      "Epoch 18462 - Train Loss: 0.082232, Train Acc: 0.880769 | Val Loss: 0.109230, Val Acc: 0.773196\n",
      "Epoch 18463 - Train Loss: 0.082229, Train Acc: 0.880769 | Val Loss: 0.109229, Val Acc: 0.773196\n",
      "Epoch 18464 - Train Loss: 0.082227, Train Acc: 0.880769 | Val Loss: 0.109228, Val Acc: 0.773196\n",
      "Epoch 18465 - Train Loss: 0.082224, Train Acc: 0.880769 | Val Loss: 0.109226, Val Acc: 0.773196\n",
      "Epoch 18466 - Train Loss: 0.082222, Train Acc: 0.880769 | Val Loss: 0.109225, Val Acc: 0.773196\n",
      "Epoch 18467 - Train Loss: 0.082219, Train Acc: 0.880769 | Val Loss: 0.109224, Val Acc: 0.773196\n",
      "Epoch 18468 - Train Loss: 0.082217, Train Acc: 0.880769 | Val Loss: 0.109223, Val Acc: 0.773196\n",
      "Epoch 18469 - Train Loss: 0.082214, Train Acc: 0.880769 | Val Loss: 0.109222, Val Acc: 0.773196\n",
      "Epoch 18470 - Train Loss: 0.082212, Train Acc: 0.880769 | Val Loss: 0.109220, Val Acc: 0.773196\n",
      "Epoch 18471 - Train Loss: 0.082209, Train Acc: 0.880769 | Val Loss: 0.109219, Val Acc: 0.773196\n",
      "Epoch 18472 - Train Loss: 0.082207, Train Acc: 0.880769 | Val Loss: 0.109218, Val Acc: 0.773196\n",
      "Epoch 18473 - Train Loss: 0.082204, Train Acc: 0.880769 | Val Loss: 0.109216, Val Acc: 0.773196\n",
      "Epoch 18474 - Train Loss: 0.082202, Train Acc: 0.880769 | Val Loss: 0.109215, Val Acc: 0.773196\n",
      "Epoch 18475 - Train Loss: 0.082199, Train Acc: 0.880769 | Val Loss: 0.109214, Val Acc: 0.773196\n",
      "Epoch 18476 - Train Loss: 0.082197, Train Acc: 0.880769 | Val Loss: 0.109213, Val Acc: 0.773196\n",
      "Epoch 18477 - Train Loss: 0.082194, Train Acc: 0.880769 | Val Loss: 0.109211, Val Acc: 0.773196\n",
      "Epoch 18478 - Train Loss: 0.082192, Train Acc: 0.880769 | Val Loss: 0.109210, Val Acc: 0.773196\n",
      "Epoch 18479 - Train Loss: 0.082189, Train Acc: 0.880769 | Val Loss: 0.109209, Val Acc: 0.773196\n",
      "Epoch 18480 - Train Loss: 0.082187, Train Acc: 0.880769 | Val Loss: 0.109208, Val Acc: 0.773196\n",
      "Epoch 18481 - Train Loss: 0.082184, Train Acc: 0.880769 | Val Loss: 0.109206, Val Acc: 0.773196\n",
      "Epoch 18482 - Train Loss: 0.082182, Train Acc: 0.880769 | Val Loss: 0.109205, Val Acc: 0.773196\n",
      "Epoch 18483 - Train Loss: 0.082179, Train Acc: 0.880769 | Val Loss: 0.109204, Val Acc: 0.773196\n",
      "Epoch 18484 - Train Loss: 0.082177, Train Acc: 0.880769 | Val Loss: 0.109203, Val Acc: 0.773196\n",
      "Epoch 18485 - Train Loss: 0.082174, Train Acc: 0.880769 | Val Loss: 0.109201, Val Acc: 0.773196\n",
      "Epoch 18486 - Train Loss: 0.082172, Train Acc: 0.880769 | Val Loss: 0.109200, Val Acc: 0.773196\n",
      "Epoch 18487 - Train Loss: 0.082169, Train Acc: 0.880769 | Val Loss: 0.109199, Val Acc: 0.773196\n",
      "Epoch 18488 - Train Loss: 0.082167, Train Acc: 0.880769 | Val Loss: 0.109198, Val Acc: 0.773196\n",
      "Epoch 18489 - Train Loss: 0.082164, Train Acc: 0.880769 | Val Loss: 0.109196, Val Acc: 0.773196\n",
      "Epoch 18490 - Train Loss: 0.082162, Train Acc: 0.880769 | Val Loss: 0.109195, Val Acc: 0.773196\n",
      "Epoch 18491 - Train Loss: 0.082159, Train Acc: 0.880769 | Val Loss: 0.109194, Val Acc: 0.773196\n",
      "Epoch 18492 - Train Loss: 0.082157, Train Acc: 0.880769 | Val Loss: 0.109193, Val Acc: 0.773196\n",
      "Epoch 18493 - Train Loss: 0.082154, Train Acc: 0.880769 | Val Loss: 0.109191, Val Acc: 0.773196\n",
      "Epoch 18494 - Train Loss: 0.082152, Train Acc: 0.880769 | Val Loss: 0.109190, Val Acc: 0.773196\n",
      "Epoch 18495 - Train Loss: 0.082149, Train Acc: 0.880769 | Val Loss: 0.109189, Val Acc: 0.773196\n",
      "Epoch 18496 - Train Loss: 0.082147, Train Acc: 0.880769 | Val Loss: 0.109188, Val Acc: 0.773196\n",
      "Epoch 18497 - Train Loss: 0.082144, Train Acc: 0.880769 | Val Loss: 0.109187, Val Acc: 0.773196\n",
      "Epoch 18498 - Train Loss: 0.082142, Train Acc: 0.880769 | Val Loss: 0.109185, Val Acc: 0.773196\n",
      "Epoch 18499 - Train Loss: 0.082139, Train Acc: 0.880769 | Val Loss: 0.109184, Val Acc: 0.773196\n",
      "Epoch 18500 - Train Loss: 0.082137, Train Acc: 0.880769 | Val Loss: 0.109183, Val Acc: 0.773196\n",
      "Epoch 18501 - Train Loss: 0.082134, Train Acc: 0.880769 | Val Loss: 0.109181, Val Acc: 0.773196\n",
      "Epoch 18502 - Train Loss: 0.082132, Train Acc: 0.880769 | Val Loss: 0.109180, Val Acc: 0.773196\n",
      "Epoch 18503 - Train Loss: 0.082129, Train Acc: 0.880769 | Val Loss: 0.109179, Val Acc: 0.773196\n",
      "Epoch 18504 - Train Loss: 0.082127, Train Acc: 0.880769 | Val Loss: 0.109178, Val Acc: 0.773196\n",
      "Epoch 18505 - Train Loss: 0.082124, Train Acc: 0.880769 | Val Loss: 0.109177, Val Acc: 0.773196\n",
      "Epoch 18506 - Train Loss: 0.082122, Train Acc: 0.880769 | Val Loss: 0.109175, Val Acc: 0.773196\n",
      "Epoch 18507 - Train Loss: 0.082119, Train Acc: 0.880769 | Val Loss: 0.109174, Val Acc: 0.773196\n",
      "Epoch 18508 - Train Loss: 0.082117, Train Acc: 0.880769 | Val Loss: 0.109173, Val Acc: 0.773196\n",
      "Epoch 18509 - Train Loss: 0.082114, Train Acc: 0.880769 | Val Loss: 0.109172, Val Acc: 0.773196\n",
      "Epoch 18510 - Train Loss: 0.082112, Train Acc: 0.880769 | Val Loss: 0.109170, Val Acc: 0.773196\n",
      "Epoch 18511 - Train Loss: 0.082109, Train Acc: 0.880769 | Val Loss: 0.109169, Val Acc: 0.773196\n",
      "Epoch 18512 - Train Loss: 0.082107, Train Acc: 0.880769 | Val Loss: 0.109168, Val Acc: 0.773196\n",
      "Epoch 18513 - Train Loss: 0.082104, Train Acc: 0.880769 | Val Loss: 0.109167, Val Acc: 0.773196\n",
      "Epoch 18514 - Train Loss: 0.082102, Train Acc: 0.880769 | Val Loss: 0.109165, Val Acc: 0.773196\n",
      "Epoch 18515 - Train Loss: 0.082099, Train Acc: 0.880769 | Val Loss: 0.109164, Val Acc: 0.773196\n",
      "Epoch 18516 - Train Loss: 0.082097, Train Acc: 0.880769 | Val Loss: 0.109163, Val Acc: 0.773196\n",
      "Epoch 18517 - Train Loss: 0.082094, Train Acc: 0.880769 | Val Loss: 0.109162, Val Acc: 0.773196\n",
      "Epoch 18518 - Train Loss: 0.082092, Train Acc: 0.880769 | Val Loss: 0.109160, Val Acc: 0.773196\n",
      "Epoch 18519 - Train Loss: 0.082090, Train Acc: 0.880769 | Val Loss: 0.109159, Val Acc: 0.773196\n",
      "Epoch 18520 - Train Loss: 0.082087, Train Acc: 0.880769 | Val Loss: 0.109158, Val Acc: 0.773196\n",
      "Epoch 18521 - Train Loss: 0.082085, Train Acc: 0.880769 | Val Loss: 0.109157, Val Acc: 0.773196\n",
      "Epoch 18522 - Train Loss: 0.082082, Train Acc: 0.880769 | Val Loss: 0.109155, Val Acc: 0.773196\n",
      "Epoch 18523 - Train Loss: 0.082080, Train Acc: 0.880769 | Val Loss: 0.109154, Val Acc: 0.773196\n",
      "Epoch 18524 - Train Loss: 0.082077, Train Acc: 0.880769 | Val Loss: 0.109153, Val Acc: 0.773196\n",
      "Epoch 18525 - Train Loss: 0.082075, Train Acc: 0.880769 | Val Loss: 0.109152, Val Acc: 0.773196\n",
      "Epoch 18526 - Train Loss: 0.082072, Train Acc: 0.880769 | Val Loss: 0.109150, Val Acc: 0.773196\n",
      "Epoch 18527 - Train Loss: 0.082070, Train Acc: 0.880769 | Val Loss: 0.109149, Val Acc: 0.773196\n",
      "Epoch 18528 - Train Loss: 0.082067, Train Acc: 0.880769 | Val Loss: 0.109148, Val Acc: 0.773196\n",
      "Epoch 18529 - Train Loss: 0.082065, Train Acc: 0.880769 | Val Loss: 0.109147, Val Acc: 0.773196\n",
      "Epoch 18530 - Train Loss: 0.082062, Train Acc: 0.880769 | Val Loss: 0.109146, Val Acc: 0.773196\n",
      "Epoch 18531 - Train Loss: 0.082060, Train Acc: 0.880769 | Val Loss: 0.109144, Val Acc: 0.773196\n",
      "Epoch 18532 - Train Loss: 0.082057, Train Acc: 0.880769 | Val Loss: 0.109143, Val Acc: 0.773196\n",
      "Epoch 18533 - Train Loss: 0.082055, Train Acc: 0.880769 | Val Loss: 0.109142, Val Acc: 0.773196\n",
      "Epoch 18534 - Train Loss: 0.082052, Train Acc: 0.880769 | Val Loss: 0.109141, Val Acc: 0.773196\n",
      "Epoch 18535 - Train Loss: 0.082050, Train Acc: 0.880769 | Val Loss: 0.109139, Val Acc: 0.773196\n",
      "Epoch 18536 - Train Loss: 0.082047, Train Acc: 0.880769 | Val Loss: 0.109138, Val Acc: 0.773196\n",
      "Epoch 18537 - Train Loss: 0.082045, Train Acc: 0.880769 | Val Loss: 0.109137, Val Acc: 0.773196\n",
      "Epoch 18538 - Train Loss: 0.082042, Train Acc: 0.880769 | Val Loss: 0.109136, Val Acc: 0.773196\n",
      "Epoch 18539 - Train Loss: 0.082040, Train Acc: 0.880769 | Val Loss: 0.109134, Val Acc: 0.773196\n",
      "Epoch 18540 - Train Loss: 0.082037, Train Acc: 0.880769 | Val Loss: 0.109133, Val Acc: 0.773196\n",
      "Epoch 18541 - Train Loss: 0.082035, Train Acc: 0.880769 | Val Loss: 0.109132, Val Acc: 0.773196\n",
      "Epoch 18542 - Train Loss: 0.082032, Train Acc: 0.880769 | Val Loss: 0.109131, Val Acc: 0.773196\n",
      "Epoch 18543 - Train Loss: 0.082030, Train Acc: 0.880769 | Val Loss: 0.109129, Val Acc: 0.773196\n",
      "Epoch 18544 - Train Loss: 0.082027, Train Acc: 0.880769 | Val Loss: 0.109128, Val Acc: 0.773196\n",
      "Epoch 18545 - Train Loss: 0.082025, Train Acc: 0.880769 | Val Loss: 0.109127, Val Acc: 0.773196\n",
      "Epoch 18546 - Train Loss: 0.082022, Train Acc: 0.880769 | Val Loss: 0.109126, Val Acc: 0.773196\n",
      "Epoch 18547 - Train Loss: 0.082020, Train Acc: 0.880769 | Val Loss: 0.109125, Val Acc: 0.773196\n",
      "Epoch 18548 - Train Loss: 0.082017, Train Acc: 0.880769 | Val Loss: 0.109123, Val Acc: 0.773196\n",
      "Epoch 18549 - Train Loss: 0.082015, Train Acc: 0.880769 | Val Loss: 0.109122, Val Acc: 0.773196\n",
      "Epoch 18550 - Train Loss: 0.082012, Train Acc: 0.880769 | Val Loss: 0.109121, Val Acc: 0.773196\n",
      "Epoch 18551 - Train Loss: 0.082010, Train Acc: 0.880769 | Val Loss: 0.109120, Val Acc: 0.773196\n",
      "Epoch 18552 - Train Loss: 0.082007, Train Acc: 0.880769 | Val Loss: 0.109118, Val Acc: 0.773196\n",
      "Epoch 18553 - Train Loss: 0.082005, Train Acc: 0.880769 | Val Loss: 0.109117, Val Acc: 0.773196\n",
      "Epoch 18554 - Train Loss: 0.082002, Train Acc: 0.880769 | Val Loss: 0.109116, Val Acc: 0.773196\n",
      "Epoch 18555 - Train Loss: 0.082000, Train Acc: 0.880769 | Val Loss: 0.109115, Val Acc: 0.773196\n",
      "Epoch 18556 - Train Loss: 0.081998, Train Acc: 0.880769 | Val Loss: 0.109113, Val Acc: 0.773196\n",
      "Epoch 18557 - Train Loss: 0.081995, Train Acc: 0.880769 | Val Loss: 0.109112, Val Acc: 0.773196\n",
      "Epoch 18558 - Train Loss: 0.081993, Train Acc: 0.880769 | Val Loss: 0.109111, Val Acc: 0.773196\n",
      "Epoch 18559 - Train Loss: 0.081990, Train Acc: 0.880769 | Val Loss: 0.109110, Val Acc: 0.773196\n",
      "Epoch 18560 - Train Loss: 0.081988, Train Acc: 0.880769 | Val Loss: 0.109109, Val Acc: 0.773196\n",
      "Epoch 18561 - Train Loss: 0.081985, Train Acc: 0.880769 | Val Loss: 0.109107, Val Acc: 0.773196\n",
      "Epoch 18562 - Train Loss: 0.081983, Train Acc: 0.880769 | Val Loss: 0.109106, Val Acc: 0.773196\n",
      "Epoch 18563 - Train Loss: 0.081980, Train Acc: 0.880769 | Val Loss: 0.109105, Val Acc: 0.773196\n",
      "Epoch 18564 - Train Loss: 0.081978, Train Acc: 0.880769 | Val Loss: 0.109104, Val Acc: 0.773196\n",
      "Epoch 18565 - Train Loss: 0.081975, Train Acc: 0.880769 | Val Loss: 0.109102, Val Acc: 0.773196\n",
      "Epoch 18566 - Train Loss: 0.081973, Train Acc: 0.880769 | Val Loss: 0.109101, Val Acc: 0.773196\n",
      "Epoch 18567 - Train Loss: 0.081970, Train Acc: 0.880769 | Val Loss: 0.109100, Val Acc: 0.773196\n",
      "Epoch 18568 - Train Loss: 0.081968, Train Acc: 0.880769 | Val Loss: 0.109099, Val Acc: 0.773196\n",
      "Epoch 18569 - Train Loss: 0.081965, Train Acc: 0.880769 | Val Loss: 0.109097, Val Acc: 0.773196\n",
      "Epoch 18570 - Train Loss: 0.081963, Train Acc: 0.880769 | Val Loss: 0.109096, Val Acc: 0.773196\n",
      "Epoch 18571 - Train Loss: 0.081960, Train Acc: 0.880769 | Val Loss: 0.109095, Val Acc: 0.773196\n",
      "Epoch 18572 - Train Loss: 0.081958, Train Acc: 0.880769 | Val Loss: 0.109094, Val Acc: 0.773196\n",
      "Epoch 18573 - Train Loss: 0.081955, Train Acc: 0.880769 | Val Loss: 0.109093, Val Acc: 0.773196\n",
      "Epoch 18574 - Train Loss: 0.081953, Train Acc: 0.880769 | Val Loss: 0.109091, Val Acc: 0.773196\n",
      "Epoch 18575 - Train Loss: 0.081950, Train Acc: 0.880769 | Val Loss: 0.109090, Val Acc: 0.773196\n",
      "Epoch 18576 - Train Loss: 0.081948, Train Acc: 0.880769 | Val Loss: 0.109089, Val Acc: 0.773196\n",
      "Epoch 18577 - Train Loss: 0.081945, Train Acc: 0.880769 | Val Loss: 0.109088, Val Acc: 0.773196\n",
      "Epoch 18578 - Train Loss: 0.081943, Train Acc: 0.880769 | Val Loss: 0.109086, Val Acc: 0.773196\n",
      "Epoch 18579 - Train Loss: 0.081941, Train Acc: 0.880769 | Val Loss: 0.109085, Val Acc: 0.773196\n",
      "Epoch 18580 - Train Loss: 0.081938, Train Acc: 0.880769 | Val Loss: 0.109084, Val Acc: 0.773196\n",
      "Epoch 18581 - Train Loss: 0.081936, Train Acc: 0.880769 | Val Loss: 0.109083, Val Acc: 0.773196\n",
      "Epoch 18582 - Train Loss: 0.081933, Train Acc: 0.880769 | Val Loss: 0.109081, Val Acc: 0.773196\n",
      "Epoch 18583 - Train Loss: 0.081931, Train Acc: 0.880769 | Val Loss: 0.109080, Val Acc: 0.773196\n",
      "Epoch 18584 - Train Loss: 0.081928, Train Acc: 0.880769 | Val Loss: 0.109079, Val Acc: 0.773196\n",
      "Epoch 18585 - Train Loss: 0.081926, Train Acc: 0.880769 | Val Loss: 0.109078, Val Acc: 0.773196\n",
      "Epoch 18586 - Train Loss: 0.081923, Train Acc: 0.880769 | Val Loss: 0.109077, Val Acc: 0.773196\n",
      "Epoch 18587 - Train Loss: 0.081921, Train Acc: 0.880769 | Val Loss: 0.109075, Val Acc: 0.773196\n",
      "Epoch 18588 - Train Loss: 0.081918, Train Acc: 0.880769 | Val Loss: 0.109074, Val Acc: 0.773196\n",
      "Epoch 18589 - Train Loss: 0.081916, Train Acc: 0.880769 | Val Loss: 0.109073, Val Acc: 0.773196\n",
      "Epoch 18590 - Train Loss: 0.081913, Train Acc: 0.880769 | Val Loss: 0.109072, Val Acc: 0.773196\n",
      "Epoch 18591 - Train Loss: 0.081911, Train Acc: 0.880769 | Val Loss: 0.109070, Val Acc: 0.773196\n",
      "Epoch 18592 - Train Loss: 0.081908, Train Acc: 0.880769 | Val Loss: 0.109069, Val Acc: 0.773196\n",
      "Epoch 18593 - Train Loss: 0.081906, Train Acc: 0.880769 | Val Loss: 0.109068, Val Acc: 0.773196\n",
      "Epoch 18594 - Train Loss: 0.081903, Train Acc: 0.880769 | Val Loss: 0.109067, Val Acc: 0.773196\n",
      "Epoch 18595 - Train Loss: 0.081901, Train Acc: 0.880769 | Val Loss: 0.109066, Val Acc: 0.773196\n",
      "Epoch 18596 - Train Loss: 0.081898, Train Acc: 0.880769 | Val Loss: 0.109064, Val Acc: 0.773196\n",
      "Epoch 18597 - Train Loss: 0.081896, Train Acc: 0.880769 | Val Loss: 0.109063, Val Acc: 0.773196\n",
      "Epoch 18598 - Train Loss: 0.081894, Train Acc: 0.880769 | Val Loss: 0.109062, Val Acc: 0.773196\n",
      "Epoch 18599 - Train Loss: 0.081891, Train Acc: 0.880769 | Val Loss: 0.109061, Val Acc: 0.773196\n",
      "Epoch 18600 - Train Loss: 0.081889, Train Acc: 0.880769 | Val Loss: 0.109060, Val Acc: 0.773196\n",
      "Epoch 18601 - Train Loss: 0.081886, Train Acc: 0.880769 | Val Loss: 0.109058, Val Acc: 0.773196\n",
      "Epoch 18602 - Train Loss: 0.081884, Train Acc: 0.880769 | Val Loss: 0.109057, Val Acc: 0.773196\n",
      "Epoch 18603 - Train Loss: 0.081881, Train Acc: 0.880769 | Val Loss: 0.109056, Val Acc: 0.773196\n",
      "Epoch 18604 - Train Loss: 0.081879, Train Acc: 0.880769 | Val Loss: 0.109055, Val Acc: 0.773196\n",
      "Epoch 18605 - Train Loss: 0.081876, Train Acc: 0.880769 | Val Loss: 0.109053, Val Acc: 0.773196\n",
      "Epoch 18606 - Train Loss: 0.081874, Train Acc: 0.880769 | Val Loss: 0.109052, Val Acc: 0.773196\n",
      "Epoch 18607 - Train Loss: 0.081871, Train Acc: 0.880769 | Val Loss: 0.109051, Val Acc: 0.773196\n",
      "Epoch 18608 - Train Loss: 0.081869, Train Acc: 0.880769 | Val Loss: 0.109050, Val Acc: 0.773196\n",
      "Epoch 18609 - Train Loss: 0.081866, Train Acc: 0.880769 | Val Loss: 0.109049, Val Acc: 0.773196\n",
      "Epoch 18610 - Train Loss: 0.081864, Train Acc: 0.880769 | Val Loss: 0.109047, Val Acc: 0.773196\n",
      "Epoch 18611 - Train Loss: 0.081861, Train Acc: 0.880769 | Val Loss: 0.109046, Val Acc: 0.773196\n",
      "Epoch 18612 - Train Loss: 0.081859, Train Acc: 0.880769 | Val Loss: 0.109045, Val Acc: 0.773196\n",
      "Epoch 18613 - Train Loss: 0.081857, Train Acc: 0.880769 | Val Loss: 0.109044, Val Acc: 0.773196\n",
      "Epoch 18614 - Train Loss: 0.081854, Train Acc: 0.880769 | Val Loss: 0.109043, Val Acc: 0.773196\n",
      "Epoch 18615 - Train Loss: 0.081852, Train Acc: 0.880769 | Val Loss: 0.109041, Val Acc: 0.773196\n",
      "Epoch 18616 - Train Loss: 0.081849, Train Acc: 0.880769 | Val Loss: 0.109040, Val Acc: 0.773196\n",
      "Epoch 18617 - Train Loss: 0.081847, Train Acc: 0.880769 | Val Loss: 0.109039, Val Acc: 0.773196\n",
      "Epoch 18618 - Train Loss: 0.081844, Train Acc: 0.880769 | Val Loss: 0.109038, Val Acc: 0.773196\n",
      "Epoch 18619 - Train Loss: 0.081842, Train Acc: 0.880769 | Val Loss: 0.109036, Val Acc: 0.773196\n",
      "Epoch 18620 - Train Loss: 0.081839, Train Acc: 0.880769 | Val Loss: 0.109035, Val Acc: 0.773196\n",
      "Epoch 18621 - Train Loss: 0.081837, Train Acc: 0.880769 | Val Loss: 0.109034, Val Acc: 0.773196\n",
      "Epoch 18622 - Train Loss: 0.081834, Train Acc: 0.880769 | Val Loss: 0.109033, Val Acc: 0.773196\n",
      "Epoch 18623 - Train Loss: 0.081832, Train Acc: 0.880769 | Val Loss: 0.109032, Val Acc: 0.773196\n",
      "Epoch 18624 - Train Loss: 0.081829, Train Acc: 0.880769 | Val Loss: 0.109030, Val Acc: 0.773196\n",
      "Epoch 18625 - Train Loss: 0.081827, Train Acc: 0.880769 | Val Loss: 0.109029, Val Acc: 0.773196\n",
      "Epoch 18626 - Train Loss: 0.081824, Train Acc: 0.880769 | Val Loss: 0.109028, Val Acc: 0.773196\n",
      "Epoch 18627 - Train Loss: 0.081822, Train Acc: 0.880769 | Val Loss: 0.109027, Val Acc: 0.773196\n",
      "Epoch 18628 - Train Loss: 0.081820, Train Acc: 0.880769 | Val Loss: 0.109026, Val Acc: 0.773196\n",
      "Epoch 18629 - Train Loss: 0.081817, Train Acc: 0.880769 | Val Loss: 0.109024, Val Acc: 0.773196\n",
      "Epoch 18630 - Train Loss: 0.081815, Train Acc: 0.880769 | Val Loss: 0.109023, Val Acc: 0.773196\n",
      "Epoch 18631 - Train Loss: 0.081812, Train Acc: 0.880769 | Val Loss: 0.109022, Val Acc: 0.773196\n",
      "Epoch 18632 - Train Loss: 0.081810, Train Acc: 0.880769 | Val Loss: 0.109021, Val Acc: 0.773196\n",
      "Epoch 18633 - Train Loss: 0.081807, Train Acc: 0.880769 | Val Loss: 0.109019, Val Acc: 0.773196\n",
      "Epoch 18634 - Train Loss: 0.081805, Train Acc: 0.880769 | Val Loss: 0.109018, Val Acc: 0.773196\n",
      "Epoch 18635 - Train Loss: 0.081802, Train Acc: 0.880769 | Val Loss: 0.109017, Val Acc: 0.773196\n",
      "Epoch 18636 - Train Loss: 0.081800, Train Acc: 0.880769 | Val Loss: 0.109016, Val Acc: 0.773196\n",
      "Epoch 18637 - Train Loss: 0.081797, Train Acc: 0.880769 | Val Loss: 0.109015, Val Acc: 0.773196\n",
      "Epoch 18638 - Train Loss: 0.081795, Train Acc: 0.880769 | Val Loss: 0.109013, Val Acc: 0.773196\n",
      "Epoch 18639 - Train Loss: 0.081792, Train Acc: 0.880769 | Val Loss: 0.109012, Val Acc: 0.773196\n",
      "Epoch 18640 - Train Loss: 0.081790, Train Acc: 0.880769 | Val Loss: 0.109011, Val Acc: 0.773196\n",
      "Epoch 18641 - Train Loss: 0.081788, Train Acc: 0.880769 | Val Loss: 0.109010, Val Acc: 0.773196\n",
      "Epoch 18642 - Train Loss: 0.081785, Train Acc: 0.880769 | Val Loss: 0.109009, Val Acc: 0.773196\n",
      "Epoch 18643 - Train Loss: 0.081783, Train Acc: 0.880769 | Val Loss: 0.109007, Val Acc: 0.773196\n",
      "Epoch 18644 - Train Loss: 0.081780, Train Acc: 0.880769 | Val Loss: 0.109006, Val Acc: 0.773196\n",
      "Epoch 18645 - Train Loss: 0.081778, Train Acc: 0.880769 | Val Loss: 0.109005, Val Acc: 0.773196\n",
      "Epoch 18646 - Train Loss: 0.081775, Train Acc: 0.880769 | Val Loss: 0.109004, Val Acc: 0.773196\n",
      "Epoch 18647 - Train Loss: 0.081773, Train Acc: 0.880769 | Val Loss: 0.109003, Val Acc: 0.773196\n",
      "Epoch 18648 - Train Loss: 0.081770, Train Acc: 0.880769 | Val Loss: 0.109001, Val Acc: 0.773196\n",
      "Epoch 18649 - Train Loss: 0.081768, Train Acc: 0.880769 | Val Loss: 0.109000, Val Acc: 0.773196\n",
      "Epoch 18650 - Train Loss: 0.081765, Train Acc: 0.880769 | Val Loss: 0.108999, Val Acc: 0.773196\n",
      "Epoch 18651 - Train Loss: 0.081763, Train Acc: 0.880769 | Val Loss: 0.108998, Val Acc: 0.773196\n",
      "Epoch 18652 - Train Loss: 0.081761, Train Acc: 0.880769 | Val Loss: 0.108997, Val Acc: 0.773196\n",
      "Epoch 18653 - Train Loss: 0.081758, Train Acc: 0.880769 | Val Loss: 0.108995, Val Acc: 0.773196\n",
      "Epoch 18654 - Train Loss: 0.081756, Train Acc: 0.880769 | Val Loss: 0.108994, Val Acc: 0.773196\n",
      "Epoch 18655 - Train Loss: 0.081753, Train Acc: 0.880769 | Val Loss: 0.108993, Val Acc: 0.773196\n",
      "Epoch 18656 - Train Loss: 0.081751, Train Acc: 0.880769 | Val Loss: 0.108992, Val Acc: 0.773196\n",
      "Epoch 18657 - Train Loss: 0.081748, Train Acc: 0.880769 | Val Loss: 0.108991, Val Acc: 0.773196\n",
      "Epoch 18658 - Train Loss: 0.081746, Train Acc: 0.880769 | Val Loss: 0.108989, Val Acc: 0.773196\n",
      "Epoch 18659 - Train Loss: 0.081743, Train Acc: 0.880769 | Val Loss: 0.108988, Val Acc: 0.773196\n",
      "Epoch 18660 - Train Loss: 0.081741, Train Acc: 0.880769 | Val Loss: 0.108987, Val Acc: 0.773196\n",
      "Epoch 18661 - Train Loss: 0.081738, Train Acc: 0.880769 | Val Loss: 0.108986, Val Acc: 0.773196\n",
      "Epoch 18662 - Train Loss: 0.081736, Train Acc: 0.880769 | Val Loss: 0.108985, Val Acc: 0.773196\n",
      "Epoch 18663 - Train Loss: 0.081734, Train Acc: 0.880769 | Val Loss: 0.108983, Val Acc: 0.773196\n",
      "Epoch 18664 - Train Loss: 0.081731, Train Acc: 0.880769 | Val Loss: 0.108982, Val Acc: 0.773196\n",
      "Epoch 18665 - Train Loss: 0.081729, Train Acc: 0.880769 | Val Loss: 0.108981, Val Acc: 0.773196\n",
      "Epoch 18666 - Train Loss: 0.081726, Train Acc: 0.880769 | Val Loss: 0.108980, Val Acc: 0.773196\n",
      "Epoch 18667 - Train Loss: 0.081724, Train Acc: 0.880769 | Val Loss: 0.108979, Val Acc: 0.773196\n",
      "Epoch 18668 - Train Loss: 0.081721, Train Acc: 0.880769 | Val Loss: 0.108977, Val Acc: 0.773196\n",
      "Epoch 18669 - Train Loss: 0.081719, Train Acc: 0.880769 | Val Loss: 0.108976, Val Acc: 0.773196\n",
      "Epoch 18670 - Train Loss: 0.081716, Train Acc: 0.880769 | Val Loss: 0.108975, Val Acc: 0.773196\n",
      "Epoch 18671 - Train Loss: 0.081714, Train Acc: 0.880769 | Val Loss: 0.108974, Val Acc: 0.773196\n",
      "Epoch 18672 - Train Loss: 0.081711, Train Acc: 0.880769 | Val Loss: 0.108972, Val Acc: 0.773196\n",
      "Epoch 18673 - Train Loss: 0.081709, Train Acc: 0.880769 | Val Loss: 0.108971, Val Acc: 0.773196\n",
      "Epoch 18674 - Train Loss: 0.081707, Train Acc: 0.880769 | Val Loss: 0.108970, Val Acc: 0.773196\n",
      "Epoch 18675 - Train Loss: 0.081704, Train Acc: 0.880769 | Val Loss: 0.108969, Val Acc: 0.773196\n",
      "Epoch 18676 - Train Loss: 0.081702, Train Acc: 0.880769 | Val Loss: 0.108968, Val Acc: 0.773196\n",
      "Epoch 18677 - Train Loss: 0.081699, Train Acc: 0.880769 | Val Loss: 0.108967, Val Acc: 0.773196\n",
      "Epoch 18678 - Train Loss: 0.081697, Train Acc: 0.880769 | Val Loss: 0.108965, Val Acc: 0.773196\n",
      "Epoch 18679 - Train Loss: 0.081694, Train Acc: 0.880769 | Val Loss: 0.108964, Val Acc: 0.773196\n",
      "Epoch 18680 - Train Loss: 0.081692, Train Acc: 0.880769 | Val Loss: 0.108963, Val Acc: 0.773196\n",
      "Epoch 18681 - Train Loss: 0.081689, Train Acc: 0.880769 | Val Loss: 0.108962, Val Acc: 0.773196\n",
      "Epoch 18682 - Train Loss: 0.081687, Train Acc: 0.880769 | Val Loss: 0.108961, Val Acc: 0.773196\n",
      "Epoch 18683 - Train Loss: 0.081685, Train Acc: 0.880769 | Val Loss: 0.108959, Val Acc: 0.773196\n",
      "Epoch 18684 - Train Loss: 0.081682, Train Acc: 0.880769 | Val Loss: 0.108958, Val Acc: 0.773196\n",
      "Epoch 18685 - Train Loss: 0.081680, Train Acc: 0.880769 | Val Loss: 0.108957, Val Acc: 0.773196\n",
      "Epoch 18686 - Train Loss: 0.081677, Train Acc: 0.880769 | Val Loss: 0.108956, Val Acc: 0.773196\n",
      "Epoch 18687 - Train Loss: 0.081675, Train Acc: 0.880769 | Val Loss: 0.108955, Val Acc: 0.773196\n",
      "Epoch 18688 - Train Loss: 0.081672, Train Acc: 0.882051 | Val Loss: 0.108953, Val Acc: 0.773196\n",
      "Epoch 18689 - Train Loss: 0.081670, Train Acc: 0.882051 | Val Loss: 0.108952, Val Acc: 0.773196\n",
      "Epoch 18690 - Train Loss: 0.081667, Train Acc: 0.882051 | Val Loss: 0.108951, Val Acc: 0.773196\n",
      "Epoch 18691 - Train Loss: 0.081665, Train Acc: 0.882051 | Val Loss: 0.108950, Val Acc: 0.773196\n",
      "Epoch 18692 - Train Loss: 0.081663, Train Acc: 0.882051 | Val Loss: 0.108949, Val Acc: 0.773196\n",
      "Epoch 18693 - Train Loss: 0.081660, Train Acc: 0.882051 | Val Loss: 0.108947, Val Acc: 0.773196\n",
      "Epoch 18694 - Train Loss: 0.081658, Train Acc: 0.882051 | Val Loss: 0.108946, Val Acc: 0.773196\n",
      "Epoch 18695 - Train Loss: 0.081655, Train Acc: 0.882051 | Val Loss: 0.108945, Val Acc: 0.773196\n",
      "Epoch 18696 - Train Loss: 0.081653, Train Acc: 0.882051 | Val Loss: 0.108944, Val Acc: 0.773196\n",
      "Epoch 18697 - Train Loss: 0.081650, Train Acc: 0.882051 | Val Loss: 0.108943, Val Acc: 0.773196\n",
      "Epoch 18698 - Train Loss: 0.081648, Train Acc: 0.882051 | Val Loss: 0.108941, Val Acc: 0.773196\n",
      "Epoch 18699 - Train Loss: 0.081645, Train Acc: 0.882051 | Val Loss: 0.108940, Val Acc: 0.773196\n",
      "Epoch 18700 - Train Loss: 0.081643, Train Acc: 0.882051 | Val Loss: 0.108939, Val Acc: 0.773196\n",
      "Epoch 18701 - Train Loss: 0.081641, Train Acc: 0.882051 | Val Loss: 0.108938, Val Acc: 0.773196\n",
      "Epoch 18702 - Train Loss: 0.081638, Train Acc: 0.882051 | Val Loss: 0.108937, Val Acc: 0.773196\n",
      "Epoch 18703 - Train Loss: 0.081636, Train Acc: 0.882051 | Val Loss: 0.108936, Val Acc: 0.773196\n",
      "Epoch 18704 - Train Loss: 0.081633, Train Acc: 0.882051 | Val Loss: 0.108934, Val Acc: 0.773196\n",
      "Epoch 18705 - Train Loss: 0.081631, Train Acc: 0.882051 | Val Loss: 0.108933, Val Acc: 0.773196\n",
      "Epoch 18706 - Train Loss: 0.081628, Train Acc: 0.882051 | Val Loss: 0.108932, Val Acc: 0.773196\n",
      "Epoch 18707 - Train Loss: 0.081626, Train Acc: 0.882051 | Val Loss: 0.108931, Val Acc: 0.773196\n",
      "Epoch 18708 - Train Loss: 0.081623, Train Acc: 0.882051 | Val Loss: 0.108930, Val Acc: 0.773196\n",
      "Epoch 18709 - Train Loss: 0.081621, Train Acc: 0.882051 | Val Loss: 0.108928, Val Acc: 0.773196\n",
      "Epoch 18710 - Train Loss: 0.081619, Train Acc: 0.882051 | Val Loss: 0.108927, Val Acc: 0.773196\n",
      "Epoch 18711 - Train Loss: 0.081616, Train Acc: 0.882051 | Val Loss: 0.108926, Val Acc: 0.773196\n",
      "Epoch 18712 - Train Loss: 0.081614, Train Acc: 0.882051 | Val Loss: 0.108925, Val Acc: 0.773196\n",
      "Epoch 18713 - Train Loss: 0.081611, Train Acc: 0.882051 | Val Loss: 0.108924, Val Acc: 0.773196\n",
      "Epoch 18714 - Train Loss: 0.081609, Train Acc: 0.882051 | Val Loss: 0.108922, Val Acc: 0.773196\n",
      "Epoch 18715 - Train Loss: 0.081606, Train Acc: 0.882051 | Val Loss: 0.108921, Val Acc: 0.773196\n",
      "Epoch 18716 - Train Loss: 0.081604, Train Acc: 0.882051 | Val Loss: 0.108920, Val Acc: 0.773196\n",
      "Epoch 18717 - Train Loss: 0.081601, Train Acc: 0.882051 | Val Loss: 0.108919, Val Acc: 0.773196\n",
      "Epoch 18718 - Train Loss: 0.081599, Train Acc: 0.882051 | Val Loss: 0.108918, Val Acc: 0.773196\n",
      "Epoch 18719 - Train Loss: 0.081597, Train Acc: 0.882051 | Val Loss: 0.108917, Val Acc: 0.773196\n",
      "Epoch 18720 - Train Loss: 0.081594, Train Acc: 0.882051 | Val Loss: 0.108915, Val Acc: 0.773196\n",
      "Epoch 18721 - Train Loss: 0.081592, Train Acc: 0.882051 | Val Loss: 0.108914, Val Acc: 0.773196\n",
      "Epoch 18722 - Train Loss: 0.081589, Train Acc: 0.882051 | Val Loss: 0.108913, Val Acc: 0.773196\n",
      "Epoch 18723 - Train Loss: 0.081587, Train Acc: 0.882051 | Val Loss: 0.108912, Val Acc: 0.773196\n",
      "Epoch 18724 - Train Loss: 0.081584, Train Acc: 0.882051 | Val Loss: 0.108911, Val Acc: 0.773196\n",
      "Epoch 18725 - Train Loss: 0.081582, Train Acc: 0.882051 | Val Loss: 0.108909, Val Acc: 0.773196\n",
      "Epoch 18726 - Train Loss: 0.081580, Train Acc: 0.882051 | Val Loss: 0.108908, Val Acc: 0.773196\n",
      "Epoch 18727 - Train Loss: 0.081577, Train Acc: 0.882051 | Val Loss: 0.108907, Val Acc: 0.773196\n",
      "Epoch 18728 - Train Loss: 0.081575, Train Acc: 0.882051 | Val Loss: 0.108906, Val Acc: 0.773196\n",
      "Epoch 18729 - Train Loss: 0.081572, Train Acc: 0.882051 | Val Loss: 0.108905, Val Acc: 0.773196\n",
      "Epoch 18730 - Train Loss: 0.081570, Train Acc: 0.882051 | Val Loss: 0.108903, Val Acc: 0.773196\n",
      "Epoch 18731 - Train Loss: 0.081567, Train Acc: 0.882051 | Val Loss: 0.108902, Val Acc: 0.773196\n",
      "Epoch 18732 - Train Loss: 0.081565, Train Acc: 0.882051 | Val Loss: 0.108901, Val Acc: 0.783505\n",
      "Epoch 18733 - Train Loss: 0.081563, Train Acc: 0.882051 | Val Loss: 0.108900, Val Acc: 0.783505\n",
      "Epoch 18734 - Train Loss: 0.081560, Train Acc: 0.882051 | Val Loss: 0.108899, Val Acc: 0.783505\n",
      "Epoch 18735 - Train Loss: 0.081558, Train Acc: 0.882051 | Val Loss: 0.108898, Val Acc: 0.783505\n",
      "Epoch 18736 - Train Loss: 0.081555, Train Acc: 0.882051 | Val Loss: 0.108896, Val Acc: 0.783505\n",
      "Epoch 18737 - Train Loss: 0.081553, Train Acc: 0.882051 | Val Loss: 0.108895, Val Acc: 0.783505\n",
      "Epoch 18738 - Train Loss: 0.081550, Train Acc: 0.882051 | Val Loss: 0.108894, Val Acc: 0.783505\n",
      "Epoch 18739 - Train Loss: 0.081548, Train Acc: 0.882051 | Val Loss: 0.108893, Val Acc: 0.783505\n",
      "Epoch 18740 - Train Loss: 0.081545, Train Acc: 0.882051 | Val Loss: 0.108892, Val Acc: 0.783505\n",
      "Epoch 18741 - Train Loss: 0.081543, Train Acc: 0.882051 | Val Loss: 0.108890, Val Acc: 0.783505\n",
      "Epoch 18742 - Train Loss: 0.081541, Train Acc: 0.882051 | Val Loss: 0.108889, Val Acc: 0.783505\n",
      "Epoch 18743 - Train Loss: 0.081538, Train Acc: 0.882051 | Val Loss: 0.108888, Val Acc: 0.783505\n",
      "Epoch 18744 - Train Loss: 0.081536, Train Acc: 0.882051 | Val Loss: 0.108887, Val Acc: 0.783505\n",
      "Epoch 18745 - Train Loss: 0.081533, Train Acc: 0.882051 | Val Loss: 0.108886, Val Acc: 0.783505\n",
      "Epoch 18746 - Train Loss: 0.081531, Train Acc: 0.882051 | Val Loss: 0.108884, Val Acc: 0.783505\n",
      "Epoch 18747 - Train Loss: 0.081528, Train Acc: 0.882051 | Val Loss: 0.108883, Val Acc: 0.783505\n",
      "Epoch 18748 - Train Loss: 0.081526, Train Acc: 0.882051 | Val Loss: 0.108882, Val Acc: 0.783505\n",
      "Epoch 18749 - Train Loss: 0.081524, Train Acc: 0.882051 | Val Loss: 0.108881, Val Acc: 0.783505\n",
      "Epoch 18750 - Train Loss: 0.081521, Train Acc: 0.882051 | Val Loss: 0.108880, Val Acc: 0.783505\n",
      "Epoch 18751 - Train Loss: 0.081519, Train Acc: 0.882051 | Val Loss: 0.108879, Val Acc: 0.783505\n",
      "Epoch 18752 - Train Loss: 0.081516, Train Acc: 0.882051 | Val Loss: 0.108877, Val Acc: 0.783505\n",
      "Epoch 18753 - Train Loss: 0.081514, Train Acc: 0.882051 | Val Loss: 0.108876, Val Acc: 0.783505\n",
      "Epoch 18754 - Train Loss: 0.081511, Train Acc: 0.882051 | Val Loss: 0.108875, Val Acc: 0.783505\n",
      "Epoch 18755 - Train Loss: 0.081509, Train Acc: 0.882051 | Val Loss: 0.108874, Val Acc: 0.783505\n",
      "Epoch 18756 - Train Loss: 0.081507, Train Acc: 0.882051 | Val Loss: 0.108873, Val Acc: 0.783505\n",
      "Epoch 18757 - Train Loss: 0.081504, Train Acc: 0.882051 | Val Loss: 0.108871, Val Acc: 0.783505\n",
      "Epoch 18758 - Train Loss: 0.081502, Train Acc: 0.882051 | Val Loss: 0.108870, Val Acc: 0.783505\n",
      "Epoch 18759 - Train Loss: 0.081499, Train Acc: 0.882051 | Val Loss: 0.108869, Val Acc: 0.783505\n",
      "Epoch 18760 - Train Loss: 0.081497, Train Acc: 0.882051 | Val Loss: 0.108868, Val Acc: 0.783505\n",
      "Epoch 18761 - Train Loss: 0.081494, Train Acc: 0.882051 | Val Loss: 0.108867, Val Acc: 0.783505\n",
      "Epoch 18762 - Train Loss: 0.081492, Train Acc: 0.882051 | Val Loss: 0.108866, Val Acc: 0.783505\n",
      "Epoch 18763 - Train Loss: 0.081490, Train Acc: 0.882051 | Val Loss: 0.108864, Val Acc: 0.783505\n",
      "Epoch 18764 - Train Loss: 0.081487, Train Acc: 0.882051 | Val Loss: 0.108863, Val Acc: 0.783505\n",
      "Epoch 18765 - Train Loss: 0.081485, Train Acc: 0.882051 | Val Loss: 0.108862, Val Acc: 0.783505\n",
      "Epoch 18766 - Train Loss: 0.081482, Train Acc: 0.882051 | Val Loss: 0.108861, Val Acc: 0.783505\n",
      "Epoch 18767 - Train Loss: 0.081480, Train Acc: 0.882051 | Val Loss: 0.108860, Val Acc: 0.783505\n",
      "Epoch 18768 - Train Loss: 0.081478, Train Acc: 0.882051 | Val Loss: 0.108858, Val Acc: 0.783505\n",
      "Epoch 18769 - Train Loss: 0.081475, Train Acc: 0.882051 | Val Loss: 0.108857, Val Acc: 0.783505\n",
      "Epoch 18770 - Train Loss: 0.081473, Train Acc: 0.882051 | Val Loss: 0.108856, Val Acc: 0.783505\n",
      "Epoch 18771 - Train Loss: 0.081470, Train Acc: 0.882051 | Val Loss: 0.108855, Val Acc: 0.783505\n",
      "Epoch 18772 - Train Loss: 0.081468, Train Acc: 0.882051 | Val Loss: 0.108854, Val Acc: 0.783505\n",
      "Epoch 18773 - Train Loss: 0.081465, Train Acc: 0.882051 | Val Loss: 0.108853, Val Acc: 0.783505\n",
      "Epoch 18774 - Train Loss: 0.081463, Train Acc: 0.882051 | Val Loss: 0.108852, Val Acc: 0.783505\n",
      "Epoch 18775 - Train Loss: 0.081461, Train Acc: 0.882051 | Val Loss: 0.108850, Val Acc: 0.783505\n",
      "Epoch 18776 - Train Loss: 0.081458, Train Acc: 0.882051 | Val Loss: 0.108849, Val Acc: 0.783505\n",
      "Epoch 18777 - Train Loss: 0.081456, Train Acc: 0.882051 | Val Loss: 0.108848, Val Acc: 0.783505\n",
      "Epoch 18778 - Train Loss: 0.081453, Train Acc: 0.882051 | Val Loss: 0.108847, Val Acc: 0.783505\n",
      "Epoch 18779 - Train Loss: 0.081451, Train Acc: 0.882051 | Val Loss: 0.108846, Val Acc: 0.783505\n",
      "Epoch 18780 - Train Loss: 0.081448, Train Acc: 0.882051 | Val Loss: 0.108844, Val Acc: 0.783505\n",
      "Epoch 18781 - Train Loss: 0.081446, Train Acc: 0.882051 | Val Loss: 0.108843, Val Acc: 0.783505\n",
      "Epoch 18782 - Train Loss: 0.081444, Train Acc: 0.882051 | Val Loss: 0.108842, Val Acc: 0.783505\n",
      "Epoch 18783 - Train Loss: 0.081441, Train Acc: 0.882051 | Val Loss: 0.108841, Val Acc: 0.783505\n",
      "Epoch 18784 - Train Loss: 0.081439, Train Acc: 0.882051 | Val Loss: 0.108840, Val Acc: 0.783505\n",
      "Epoch 18785 - Train Loss: 0.081436, Train Acc: 0.882051 | Val Loss: 0.108839, Val Acc: 0.783505\n",
      "Epoch 18786 - Train Loss: 0.081434, Train Acc: 0.882051 | Val Loss: 0.108837, Val Acc: 0.783505\n",
      "Epoch 18787 - Train Loss: 0.081431, Train Acc: 0.882051 | Val Loss: 0.108836, Val Acc: 0.783505\n",
      "Epoch 18788 - Train Loss: 0.081429, Train Acc: 0.882051 | Val Loss: 0.108835, Val Acc: 0.783505\n",
      "Epoch 18789 - Train Loss: 0.081427, Train Acc: 0.882051 | Val Loss: 0.108834, Val Acc: 0.783505\n",
      "Epoch 18790 - Train Loss: 0.081424, Train Acc: 0.882051 | Val Loss: 0.108833, Val Acc: 0.783505\n",
      "Epoch 18791 - Train Loss: 0.081422, Train Acc: 0.882051 | Val Loss: 0.108832, Val Acc: 0.783505\n",
      "Epoch 18792 - Train Loss: 0.081419, Train Acc: 0.882051 | Val Loss: 0.108830, Val Acc: 0.783505\n",
      "Epoch 18793 - Train Loss: 0.081417, Train Acc: 0.882051 | Val Loss: 0.108829, Val Acc: 0.783505\n",
      "Epoch 18794 - Train Loss: 0.081415, Train Acc: 0.882051 | Val Loss: 0.108828, Val Acc: 0.783505\n",
      "Epoch 18795 - Train Loss: 0.081412, Train Acc: 0.882051 | Val Loss: 0.108827, Val Acc: 0.783505\n",
      "Epoch 18796 - Train Loss: 0.081410, Train Acc: 0.882051 | Val Loss: 0.108826, Val Acc: 0.783505\n",
      "Epoch 18797 - Train Loss: 0.081407, Train Acc: 0.882051 | Val Loss: 0.108825, Val Acc: 0.783505\n",
      "Epoch 18798 - Train Loss: 0.081405, Train Acc: 0.882051 | Val Loss: 0.108823, Val Acc: 0.783505\n",
      "Epoch 18799 - Train Loss: 0.081402, Train Acc: 0.882051 | Val Loss: 0.108822, Val Acc: 0.783505\n",
      "Epoch 18800 - Train Loss: 0.081400, Train Acc: 0.882051 | Val Loss: 0.108821, Val Acc: 0.783505\n",
      "Epoch 18801 - Train Loss: 0.081398, Train Acc: 0.882051 | Val Loss: 0.108820, Val Acc: 0.783505\n",
      "Epoch 18802 - Train Loss: 0.081395, Train Acc: 0.882051 | Val Loss: 0.108819, Val Acc: 0.783505\n",
      "Epoch 18803 - Train Loss: 0.081393, Train Acc: 0.882051 | Val Loss: 0.108817, Val Acc: 0.783505\n",
      "Epoch 18804 - Train Loss: 0.081390, Train Acc: 0.882051 | Val Loss: 0.108816, Val Acc: 0.783505\n",
      "Epoch 18805 - Train Loss: 0.081388, Train Acc: 0.882051 | Val Loss: 0.108815, Val Acc: 0.783505\n",
      "Epoch 18806 - Train Loss: 0.081386, Train Acc: 0.882051 | Val Loss: 0.108814, Val Acc: 0.783505\n",
      "Epoch 18807 - Train Loss: 0.081383, Train Acc: 0.882051 | Val Loss: 0.108813, Val Acc: 0.783505\n",
      "Epoch 18808 - Train Loss: 0.081381, Train Acc: 0.882051 | Val Loss: 0.108812, Val Acc: 0.783505\n",
      "Epoch 18809 - Train Loss: 0.081378, Train Acc: 0.882051 | Val Loss: 0.108811, Val Acc: 0.783505\n",
      "Epoch 18810 - Train Loss: 0.081376, Train Acc: 0.882051 | Val Loss: 0.108809, Val Acc: 0.783505\n",
      "Epoch 18811 - Train Loss: 0.081374, Train Acc: 0.882051 | Val Loss: 0.108808, Val Acc: 0.783505\n",
      "Epoch 18812 - Train Loss: 0.081371, Train Acc: 0.882051 | Val Loss: 0.108807, Val Acc: 0.783505\n",
      "Epoch 18813 - Train Loss: 0.081369, Train Acc: 0.882051 | Val Loss: 0.108806, Val Acc: 0.783505\n",
      "Epoch 18814 - Train Loss: 0.081366, Train Acc: 0.882051 | Val Loss: 0.108805, Val Acc: 0.783505\n",
      "Epoch 18815 - Train Loss: 0.081364, Train Acc: 0.882051 | Val Loss: 0.108804, Val Acc: 0.783505\n",
      "Epoch 18816 - Train Loss: 0.081361, Train Acc: 0.882051 | Val Loss: 0.108802, Val Acc: 0.783505\n",
      "Epoch 18817 - Train Loss: 0.081359, Train Acc: 0.882051 | Val Loss: 0.108801, Val Acc: 0.783505\n",
      "Epoch 18818 - Train Loss: 0.081357, Train Acc: 0.882051 | Val Loss: 0.108800, Val Acc: 0.783505\n",
      "Epoch 18819 - Train Loss: 0.081354, Train Acc: 0.882051 | Val Loss: 0.108799, Val Acc: 0.783505\n",
      "Epoch 18820 - Train Loss: 0.081352, Train Acc: 0.882051 | Val Loss: 0.108798, Val Acc: 0.783505\n",
      "Epoch 18821 - Train Loss: 0.081349, Train Acc: 0.882051 | Val Loss: 0.108797, Val Acc: 0.783505\n",
      "Epoch 18822 - Train Loss: 0.081347, Train Acc: 0.882051 | Val Loss: 0.108795, Val Acc: 0.783505\n",
      "Epoch 18823 - Train Loss: 0.081345, Train Acc: 0.882051 | Val Loss: 0.108794, Val Acc: 0.783505\n",
      "Epoch 18824 - Train Loss: 0.081342, Train Acc: 0.882051 | Val Loss: 0.108793, Val Acc: 0.783505\n",
      "Epoch 18825 - Train Loss: 0.081340, Train Acc: 0.882051 | Val Loss: 0.108792, Val Acc: 0.783505\n",
      "Epoch 18826 - Train Loss: 0.081337, Train Acc: 0.882051 | Val Loss: 0.108791, Val Acc: 0.783505\n",
      "Epoch 18827 - Train Loss: 0.081335, Train Acc: 0.882051 | Val Loss: 0.108790, Val Acc: 0.783505\n",
      "Epoch 18828 - Train Loss: 0.081333, Train Acc: 0.882051 | Val Loss: 0.108788, Val Acc: 0.783505\n",
      "Epoch 18829 - Train Loss: 0.081330, Train Acc: 0.882051 | Val Loss: 0.108787, Val Acc: 0.783505\n",
      "Epoch 18830 - Train Loss: 0.081328, Train Acc: 0.882051 | Val Loss: 0.108786, Val Acc: 0.783505\n",
      "Epoch 18831 - Train Loss: 0.081325, Train Acc: 0.883333 | Val Loss: 0.108785, Val Acc: 0.783505\n",
      "Epoch 18832 - Train Loss: 0.081323, Train Acc: 0.883333 | Val Loss: 0.108784, Val Acc: 0.783505\n",
      "Epoch 18833 - Train Loss: 0.081320, Train Acc: 0.883333 | Val Loss: 0.108783, Val Acc: 0.783505\n",
      "Epoch 18834 - Train Loss: 0.081318, Train Acc: 0.883333 | Val Loss: 0.108782, Val Acc: 0.783505\n",
      "Epoch 18835 - Train Loss: 0.081316, Train Acc: 0.883333 | Val Loss: 0.108780, Val Acc: 0.783505\n",
      "Epoch 18836 - Train Loss: 0.081313, Train Acc: 0.883333 | Val Loss: 0.108779, Val Acc: 0.783505\n",
      "Epoch 18837 - Train Loss: 0.081311, Train Acc: 0.883333 | Val Loss: 0.108778, Val Acc: 0.783505\n",
      "Epoch 18838 - Train Loss: 0.081308, Train Acc: 0.883333 | Val Loss: 0.108777, Val Acc: 0.783505\n",
      "Epoch 18839 - Train Loss: 0.081306, Train Acc: 0.883333 | Val Loss: 0.108776, Val Acc: 0.783505\n",
      "Epoch 18840 - Train Loss: 0.081304, Train Acc: 0.883333 | Val Loss: 0.108775, Val Acc: 0.783505\n",
      "Epoch 18841 - Train Loss: 0.081301, Train Acc: 0.883333 | Val Loss: 0.108773, Val Acc: 0.783505\n",
      "Epoch 18842 - Train Loss: 0.081299, Train Acc: 0.883333 | Val Loss: 0.108772, Val Acc: 0.783505\n",
      "Epoch 18843 - Train Loss: 0.081296, Train Acc: 0.883333 | Val Loss: 0.108771, Val Acc: 0.783505\n",
      "Epoch 18844 - Train Loss: 0.081294, Train Acc: 0.883333 | Val Loss: 0.108770, Val Acc: 0.783505\n",
      "Epoch 18845 - Train Loss: 0.081292, Train Acc: 0.883333 | Val Loss: 0.108769, Val Acc: 0.783505\n",
      "Epoch 18846 - Train Loss: 0.081289, Train Acc: 0.883333 | Val Loss: 0.108768, Val Acc: 0.783505\n",
      "Epoch 18847 - Train Loss: 0.081287, Train Acc: 0.883333 | Val Loss: 0.108766, Val Acc: 0.783505\n",
      "Epoch 18848 - Train Loss: 0.081284, Train Acc: 0.883333 | Val Loss: 0.108765, Val Acc: 0.783505\n",
      "Epoch 18849 - Train Loss: 0.081282, Train Acc: 0.883333 | Val Loss: 0.108764, Val Acc: 0.783505\n",
      "Epoch 18850 - Train Loss: 0.081280, Train Acc: 0.883333 | Val Loss: 0.108763, Val Acc: 0.783505\n",
      "Epoch 18851 - Train Loss: 0.081277, Train Acc: 0.883333 | Val Loss: 0.108762, Val Acc: 0.783505\n",
      "Epoch 18852 - Train Loss: 0.081275, Train Acc: 0.883333 | Val Loss: 0.108761, Val Acc: 0.783505\n",
      "Epoch 18853 - Train Loss: 0.081272, Train Acc: 0.883333 | Val Loss: 0.108760, Val Acc: 0.783505\n",
      "Epoch 18854 - Train Loss: 0.081270, Train Acc: 0.883333 | Val Loss: 0.108758, Val Acc: 0.783505\n",
      "Epoch 18855 - Train Loss: 0.081268, Train Acc: 0.883333 | Val Loss: 0.108757, Val Acc: 0.783505\n",
      "Epoch 18856 - Train Loss: 0.081265, Train Acc: 0.883333 | Val Loss: 0.108756, Val Acc: 0.783505\n",
      "Epoch 18857 - Train Loss: 0.081263, Train Acc: 0.883333 | Val Loss: 0.108755, Val Acc: 0.783505\n",
      "Epoch 18858 - Train Loss: 0.081260, Train Acc: 0.883333 | Val Loss: 0.108754, Val Acc: 0.783505\n",
      "Epoch 18859 - Train Loss: 0.081258, Train Acc: 0.883333 | Val Loss: 0.108753, Val Acc: 0.783505\n",
      "Epoch 18860 - Train Loss: 0.081256, Train Acc: 0.883333 | Val Loss: 0.108752, Val Acc: 0.783505\n",
      "Epoch 18861 - Train Loss: 0.081253, Train Acc: 0.883333 | Val Loss: 0.108750, Val Acc: 0.783505\n",
      "Epoch 18862 - Train Loss: 0.081251, Train Acc: 0.883333 | Val Loss: 0.108749, Val Acc: 0.783505\n",
      "Epoch 18863 - Train Loss: 0.081248, Train Acc: 0.883333 | Val Loss: 0.108748, Val Acc: 0.783505\n",
      "Epoch 18864 - Train Loss: 0.081246, Train Acc: 0.883333 | Val Loss: 0.108747, Val Acc: 0.783505\n",
      "Epoch 18865 - Train Loss: 0.081244, Train Acc: 0.883333 | Val Loss: 0.108746, Val Acc: 0.783505\n",
      "Epoch 18866 - Train Loss: 0.081241, Train Acc: 0.883333 | Val Loss: 0.108745, Val Acc: 0.783505\n",
      "Epoch 18867 - Train Loss: 0.081239, Train Acc: 0.883333 | Val Loss: 0.108744, Val Acc: 0.783505\n",
      "Epoch 18868 - Train Loss: 0.081236, Train Acc: 0.883333 | Val Loss: 0.108742, Val Acc: 0.783505\n",
      "Epoch 18869 - Train Loss: 0.081234, Train Acc: 0.883333 | Val Loss: 0.108741, Val Acc: 0.783505\n",
      "Epoch 18870 - Train Loss: 0.081232, Train Acc: 0.883333 | Val Loss: 0.108740, Val Acc: 0.783505\n",
      "Epoch 18871 - Train Loss: 0.081229, Train Acc: 0.883333 | Val Loss: 0.108739, Val Acc: 0.783505\n",
      "Epoch 18872 - Train Loss: 0.081227, Train Acc: 0.883333 | Val Loss: 0.108738, Val Acc: 0.783505\n",
      "Epoch 18873 - Train Loss: 0.081224, Train Acc: 0.883333 | Val Loss: 0.108737, Val Acc: 0.783505\n",
      "Epoch 18874 - Train Loss: 0.081222, Train Acc: 0.883333 | Val Loss: 0.108736, Val Acc: 0.783505\n",
      "Epoch 18875 - Train Loss: 0.081220, Train Acc: 0.883333 | Val Loss: 0.108734, Val Acc: 0.783505\n",
      "Epoch 18876 - Train Loss: 0.081217, Train Acc: 0.883333 | Val Loss: 0.108733, Val Acc: 0.783505\n",
      "Epoch 18877 - Train Loss: 0.081215, Train Acc: 0.883333 | Val Loss: 0.108732, Val Acc: 0.783505\n",
      "Epoch 18878 - Train Loss: 0.081212, Train Acc: 0.883333 | Val Loss: 0.108731, Val Acc: 0.783505\n",
      "Epoch 18879 - Train Loss: 0.081210, Train Acc: 0.883333 | Val Loss: 0.108730, Val Acc: 0.783505\n",
      "Epoch 18880 - Train Loss: 0.081208, Train Acc: 0.883333 | Val Loss: 0.108729, Val Acc: 0.783505\n",
      "Epoch 18881 - Train Loss: 0.081205, Train Acc: 0.883333 | Val Loss: 0.108728, Val Acc: 0.783505\n",
      "Epoch 18882 - Train Loss: 0.081203, Train Acc: 0.883333 | Val Loss: 0.108726, Val Acc: 0.783505\n",
      "Epoch 18883 - Train Loss: 0.081200, Train Acc: 0.883333 | Val Loss: 0.108725, Val Acc: 0.783505\n",
      "Epoch 18884 - Train Loss: 0.081198, Train Acc: 0.883333 | Val Loss: 0.108724, Val Acc: 0.783505\n",
      "Epoch 18885 - Train Loss: 0.081196, Train Acc: 0.883333 | Val Loss: 0.108723, Val Acc: 0.783505\n",
      "Epoch 18886 - Train Loss: 0.081193, Train Acc: 0.883333 | Val Loss: 0.108722, Val Acc: 0.783505\n",
      "Epoch 18887 - Train Loss: 0.081191, Train Acc: 0.883333 | Val Loss: 0.108721, Val Acc: 0.783505\n",
      "Epoch 18888 - Train Loss: 0.081188, Train Acc: 0.883333 | Val Loss: 0.108720, Val Acc: 0.783505\n",
      "Epoch 18889 - Train Loss: 0.081186, Train Acc: 0.883333 | Val Loss: 0.108718, Val Acc: 0.783505\n",
      "Epoch 18890 - Train Loss: 0.081184, Train Acc: 0.883333 | Val Loss: 0.108717, Val Acc: 0.783505\n",
      "Epoch 18891 - Train Loss: 0.081181, Train Acc: 0.883333 | Val Loss: 0.108716, Val Acc: 0.783505\n",
      "Epoch 18892 - Train Loss: 0.081179, Train Acc: 0.883333 | Val Loss: 0.108715, Val Acc: 0.783505\n",
      "Epoch 18893 - Train Loss: 0.081177, Train Acc: 0.883333 | Val Loss: 0.108714, Val Acc: 0.783505\n",
      "Epoch 18894 - Train Loss: 0.081174, Train Acc: 0.883333 | Val Loss: 0.108713, Val Acc: 0.783505\n",
      "Epoch 18895 - Train Loss: 0.081172, Train Acc: 0.883333 | Val Loss: 0.108712, Val Acc: 0.783505\n",
      "Epoch 18896 - Train Loss: 0.081169, Train Acc: 0.883333 | Val Loss: 0.108710, Val Acc: 0.783505\n",
      "Epoch 18897 - Train Loss: 0.081167, Train Acc: 0.883333 | Val Loss: 0.108709, Val Acc: 0.783505\n",
      "Epoch 18898 - Train Loss: 0.081165, Train Acc: 0.883333 | Val Loss: 0.108708, Val Acc: 0.783505\n",
      "Epoch 18899 - Train Loss: 0.081162, Train Acc: 0.883333 | Val Loss: 0.108707, Val Acc: 0.783505\n",
      "Epoch 18900 - Train Loss: 0.081160, Train Acc: 0.883333 | Val Loss: 0.108706, Val Acc: 0.783505\n",
      "Epoch 18901 - Train Loss: 0.081157, Train Acc: 0.883333 | Val Loss: 0.108705, Val Acc: 0.783505\n",
      "Epoch 18902 - Train Loss: 0.081155, Train Acc: 0.883333 | Val Loss: 0.108704, Val Acc: 0.783505\n",
      "Epoch 18903 - Train Loss: 0.081153, Train Acc: 0.883333 | Val Loss: 0.108702, Val Acc: 0.783505\n",
      "Epoch 18904 - Train Loss: 0.081150, Train Acc: 0.883333 | Val Loss: 0.108701, Val Acc: 0.783505\n",
      "Epoch 18905 - Train Loss: 0.081148, Train Acc: 0.883333 | Val Loss: 0.108700, Val Acc: 0.783505\n",
      "Epoch 18906 - Train Loss: 0.081145, Train Acc: 0.883333 | Val Loss: 0.108699, Val Acc: 0.783505\n",
      "Epoch 18907 - Train Loss: 0.081143, Train Acc: 0.883333 | Val Loss: 0.108698, Val Acc: 0.783505\n",
      "Epoch 18908 - Train Loss: 0.081141, Train Acc: 0.883333 | Val Loss: 0.108697, Val Acc: 0.783505\n",
      "Epoch 18909 - Train Loss: 0.081138, Train Acc: 0.883333 | Val Loss: 0.108696, Val Acc: 0.783505\n",
      "Epoch 18910 - Train Loss: 0.081136, Train Acc: 0.883333 | Val Loss: 0.108695, Val Acc: 0.783505\n",
      "Epoch 18911 - Train Loss: 0.081134, Train Acc: 0.883333 | Val Loss: 0.108693, Val Acc: 0.783505\n",
      "Epoch 18912 - Train Loss: 0.081131, Train Acc: 0.883333 | Val Loss: 0.108692, Val Acc: 0.783505\n",
      "Epoch 18913 - Train Loss: 0.081129, Train Acc: 0.883333 | Val Loss: 0.108691, Val Acc: 0.783505\n",
      "Epoch 18914 - Train Loss: 0.081126, Train Acc: 0.883333 | Val Loss: 0.108690, Val Acc: 0.783505\n",
      "Epoch 18915 - Train Loss: 0.081124, Train Acc: 0.883333 | Val Loss: 0.108689, Val Acc: 0.783505\n",
      "Epoch 18916 - Train Loss: 0.081122, Train Acc: 0.883333 | Val Loss: 0.108688, Val Acc: 0.783505\n",
      "Epoch 18917 - Train Loss: 0.081119, Train Acc: 0.883333 | Val Loss: 0.108687, Val Acc: 0.783505\n",
      "Epoch 18918 - Train Loss: 0.081117, Train Acc: 0.883333 | Val Loss: 0.108685, Val Acc: 0.783505\n",
      "Epoch 18919 - Train Loss: 0.081114, Train Acc: 0.883333 | Val Loss: 0.108684, Val Acc: 0.783505\n",
      "Epoch 18920 - Train Loss: 0.081112, Train Acc: 0.883333 | Val Loss: 0.108683, Val Acc: 0.783505\n",
      "Epoch 18921 - Train Loss: 0.081110, Train Acc: 0.883333 | Val Loss: 0.108682, Val Acc: 0.783505\n",
      "Epoch 18922 - Train Loss: 0.081107, Train Acc: 0.883333 | Val Loss: 0.108681, Val Acc: 0.783505\n",
      "Epoch 18923 - Train Loss: 0.081105, Train Acc: 0.883333 | Val Loss: 0.108680, Val Acc: 0.783505\n",
      "Epoch 18924 - Train Loss: 0.081103, Train Acc: 0.883333 | Val Loss: 0.108679, Val Acc: 0.783505\n",
      "Epoch 18925 - Train Loss: 0.081100, Train Acc: 0.883333 | Val Loss: 0.108678, Val Acc: 0.783505\n",
      "Epoch 18926 - Train Loss: 0.081098, Train Acc: 0.883333 | Val Loss: 0.108676, Val Acc: 0.783505\n",
      "Epoch 18927 - Train Loss: 0.081095, Train Acc: 0.883333 | Val Loss: 0.108675, Val Acc: 0.783505\n",
      "Epoch 18928 - Train Loss: 0.081093, Train Acc: 0.883333 | Val Loss: 0.108674, Val Acc: 0.783505\n",
      "Epoch 18929 - Train Loss: 0.081091, Train Acc: 0.883333 | Val Loss: 0.108673, Val Acc: 0.783505\n",
      "Epoch 18930 - Train Loss: 0.081088, Train Acc: 0.883333 | Val Loss: 0.108672, Val Acc: 0.783505\n",
      "Epoch 18931 - Train Loss: 0.081086, Train Acc: 0.883333 | Val Loss: 0.108671, Val Acc: 0.783505\n",
      "Epoch 18932 - Train Loss: 0.081083, Train Acc: 0.883333 | Val Loss: 0.108670, Val Acc: 0.783505\n",
      "Epoch 18933 - Train Loss: 0.081081, Train Acc: 0.883333 | Val Loss: 0.108669, Val Acc: 0.783505\n",
      "Epoch 18934 - Train Loss: 0.081079, Train Acc: 0.883333 | Val Loss: 0.108667, Val Acc: 0.783505\n",
      "Epoch 18935 - Train Loss: 0.081076, Train Acc: 0.883333 | Val Loss: 0.108666, Val Acc: 0.783505\n",
      "Epoch 18936 - Train Loss: 0.081074, Train Acc: 0.883333 | Val Loss: 0.108665, Val Acc: 0.783505\n",
      "Epoch 18937 - Train Loss: 0.081072, Train Acc: 0.883333 | Val Loss: 0.108664, Val Acc: 0.783505\n",
      "Epoch 18938 - Train Loss: 0.081069, Train Acc: 0.883333 | Val Loss: 0.108663, Val Acc: 0.783505\n",
      "Epoch 18939 - Train Loss: 0.081067, Train Acc: 0.883333 | Val Loss: 0.108662, Val Acc: 0.783505\n",
      "Epoch 18940 - Train Loss: 0.081064, Train Acc: 0.883333 | Val Loss: 0.108661, Val Acc: 0.783505\n",
      "Epoch 18941 - Train Loss: 0.081062, Train Acc: 0.883333 | Val Loss: 0.108660, Val Acc: 0.783505\n",
      "Epoch 18942 - Train Loss: 0.081060, Train Acc: 0.883333 | Val Loss: 0.108658, Val Acc: 0.783505\n",
      "Epoch 18943 - Train Loss: 0.081057, Train Acc: 0.883333 | Val Loss: 0.108657, Val Acc: 0.783505\n",
      "Epoch 18944 - Train Loss: 0.081055, Train Acc: 0.883333 | Val Loss: 0.108656, Val Acc: 0.783505\n",
      "Epoch 18945 - Train Loss: 0.081053, Train Acc: 0.883333 | Val Loss: 0.108655, Val Acc: 0.783505\n",
      "Epoch 18946 - Train Loss: 0.081050, Train Acc: 0.883333 | Val Loss: 0.108654, Val Acc: 0.783505\n",
      "Epoch 18947 - Train Loss: 0.081048, Train Acc: 0.883333 | Val Loss: 0.108653, Val Acc: 0.783505\n",
      "Epoch 18948 - Train Loss: 0.081045, Train Acc: 0.883333 | Val Loss: 0.108652, Val Acc: 0.783505\n",
      "Epoch 18949 - Train Loss: 0.081043, Train Acc: 0.883333 | Val Loss: 0.108650, Val Acc: 0.783505\n",
      "Epoch 18950 - Train Loss: 0.081041, Train Acc: 0.883333 | Val Loss: 0.108649, Val Acc: 0.783505\n",
      "Epoch 18951 - Train Loss: 0.081038, Train Acc: 0.883333 | Val Loss: 0.108648, Val Acc: 0.783505\n",
      "Epoch 18952 - Train Loss: 0.081036, Train Acc: 0.883333 | Val Loss: 0.108647, Val Acc: 0.783505\n",
      "Epoch 18953 - Train Loss: 0.081034, Train Acc: 0.883333 | Val Loss: 0.108646, Val Acc: 0.783505\n",
      "Epoch 18954 - Train Loss: 0.081031, Train Acc: 0.883333 | Val Loss: 0.108645, Val Acc: 0.783505\n",
      "Epoch 18955 - Train Loss: 0.081029, Train Acc: 0.883333 | Val Loss: 0.108644, Val Acc: 0.783505\n",
      "Epoch 18956 - Train Loss: 0.081026, Train Acc: 0.883333 | Val Loss: 0.108643, Val Acc: 0.783505\n",
      "Epoch 18957 - Train Loss: 0.081024, Train Acc: 0.883333 | Val Loss: 0.108641, Val Acc: 0.783505\n",
      "Epoch 18958 - Train Loss: 0.081022, Train Acc: 0.883333 | Val Loss: 0.108640, Val Acc: 0.783505\n",
      "Epoch 18959 - Train Loss: 0.081019, Train Acc: 0.883333 | Val Loss: 0.108639, Val Acc: 0.783505\n",
      "Epoch 18960 - Train Loss: 0.081017, Train Acc: 0.883333 | Val Loss: 0.108638, Val Acc: 0.783505\n",
      "Epoch 18961 - Train Loss: 0.081015, Train Acc: 0.883333 | Val Loss: 0.108637, Val Acc: 0.783505\n",
      "Epoch 18962 - Train Loss: 0.081012, Train Acc: 0.883333 | Val Loss: 0.108636, Val Acc: 0.783505\n",
      "Epoch 18963 - Train Loss: 0.081010, Train Acc: 0.883333 | Val Loss: 0.108635, Val Acc: 0.783505\n",
      "Epoch 18964 - Train Loss: 0.081007, Train Acc: 0.883333 | Val Loss: 0.108634, Val Acc: 0.783505\n",
      "Epoch 18965 - Train Loss: 0.081005, Train Acc: 0.883333 | Val Loss: 0.108633, Val Acc: 0.783505\n",
      "Epoch 18966 - Train Loss: 0.081003, Train Acc: 0.883333 | Val Loss: 0.108631, Val Acc: 0.783505\n",
      "Epoch 18967 - Train Loss: 0.081000, Train Acc: 0.883333 | Val Loss: 0.108630, Val Acc: 0.783505\n",
      "Epoch 18968 - Train Loss: 0.080998, Train Acc: 0.883333 | Val Loss: 0.108629, Val Acc: 0.783505\n",
      "Epoch 18969 - Train Loss: 0.080996, Train Acc: 0.883333 | Val Loss: 0.108628, Val Acc: 0.783505\n",
      "Epoch 18970 - Train Loss: 0.080993, Train Acc: 0.883333 | Val Loss: 0.108627, Val Acc: 0.783505\n",
      "Epoch 18971 - Train Loss: 0.080991, Train Acc: 0.883333 | Val Loss: 0.108626, Val Acc: 0.783505\n",
      "Epoch 18972 - Train Loss: 0.080988, Train Acc: 0.883333 | Val Loss: 0.108625, Val Acc: 0.783505\n",
      "Epoch 18973 - Train Loss: 0.080986, Train Acc: 0.883333 | Val Loss: 0.108624, Val Acc: 0.783505\n",
      "Epoch 18974 - Train Loss: 0.080984, Train Acc: 0.883333 | Val Loss: 0.108622, Val Acc: 0.783505\n",
      "Epoch 18975 - Train Loss: 0.080981, Train Acc: 0.883333 | Val Loss: 0.108621, Val Acc: 0.783505\n",
      "Epoch 18976 - Train Loss: 0.080979, Train Acc: 0.883333 | Val Loss: 0.108620, Val Acc: 0.783505\n",
      "Epoch 18977 - Train Loss: 0.080977, Train Acc: 0.883333 | Val Loss: 0.108619, Val Acc: 0.783505\n",
      "Epoch 18978 - Train Loss: 0.080974, Train Acc: 0.883333 | Val Loss: 0.108618, Val Acc: 0.783505\n",
      "Epoch 18979 - Train Loss: 0.080972, Train Acc: 0.883333 | Val Loss: 0.108617, Val Acc: 0.783505\n",
      "Epoch 18980 - Train Loss: 0.080969, Train Acc: 0.883333 | Val Loss: 0.108616, Val Acc: 0.783505\n",
      "Epoch 18981 - Train Loss: 0.080967, Train Acc: 0.883333 | Val Loss: 0.108615, Val Acc: 0.783505\n",
      "Epoch 18982 - Train Loss: 0.080965, Train Acc: 0.883333 | Val Loss: 0.108614, Val Acc: 0.783505\n",
      "Epoch 18983 - Train Loss: 0.080962, Train Acc: 0.883333 | Val Loss: 0.108612, Val Acc: 0.783505\n",
      "Epoch 18984 - Train Loss: 0.080960, Train Acc: 0.883333 | Val Loss: 0.108611, Val Acc: 0.783505\n",
      "Epoch 18985 - Train Loss: 0.080958, Train Acc: 0.883333 | Val Loss: 0.108610, Val Acc: 0.783505\n",
      "Epoch 18986 - Train Loss: 0.080955, Train Acc: 0.883333 | Val Loss: 0.108609, Val Acc: 0.783505\n",
      "Epoch 18987 - Train Loss: 0.080953, Train Acc: 0.883333 | Val Loss: 0.108608, Val Acc: 0.783505\n",
      "Epoch 18988 - Train Loss: 0.080951, Train Acc: 0.883333 | Val Loss: 0.108607, Val Acc: 0.783505\n",
      "Epoch 18989 - Train Loss: 0.080948, Train Acc: 0.883333 | Val Loss: 0.108606, Val Acc: 0.783505\n",
      "Epoch 18990 - Train Loss: 0.080946, Train Acc: 0.883333 | Val Loss: 0.108604, Val Acc: 0.783505\n",
      "Epoch 18991 - Train Loss: 0.080943, Train Acc: 0.883333 | Val Loss: 0.108603, Val Acc: 0.783505\n",
      "Epoch 18992 - Train Loss: 0.080941, Train Acc: 0.883333 | Val Loss: 0.108602, Val Acc: 0.783505\n",
      "Epoch 18993 - Train Loss: 0.080939, Train Acc: 0.883333 | Val Loss: 0.108601, Val Acc: 0.783505\n",
      "Epoch 18994 - Train Loss: 0.080936, Train Acc: 0.883333 | Val Loss: 0.108600, Val Acc: 0.783505\n",
      "Epoch 18995 - Train Loss: 0.080934, Train Acc: 0.883333 | Val Loss: 0.108599, Val Acc: 0.783505\n",
      "Epoch 18996 - Train Loss: 0.080932, Train Acc: 0.883333 | Val Loss: 0.108598, Val Acc: 0.783505\n",
      "Epoch 18997 - Train Loss: 0.080929, Train Acc: 0.883333 | Val Loss: 0.108597, Val Acc: 0.783505\n",
      "Epoch 18998 - Train Loss: 0.080927, Train Acc: 0.883333 | Val Loss: 0.108596, Val Acc: 0.783505\n",
      "Epoch 18999 - Train Loss: 0.080924, Train Acc: 0.883333 | Val Loss: 0.108595, Val Acc: 0.783505\n",
      "Epoch 19000 - Train Loss: 0.080922, Train Acc: 0.883333 | Val Loss: 0.108593, Val Acc: 0.783505\n",
      "Epoch 19001 - Train Loss: 0.080920, Train Acc: 0.883333 | Val Loss: 0.108592, Val Acc: 0.783505\n",
      "Epoch 19002 - Train Loss: 0.080917, Train Acc: 0.883333 | Val Loss: 0.108591, Val Acc: 0.783505\n",
      "Epoch 19003 - Train Loss: 0.080915, Train Acc: 0.883333 | Val Loss: 0.108590, Val Acc: 0.783505\n",
      "Epoch 19004 - Train Loss: 0.080913, Train Acc: 0.883333 | Val Loss: 0.108589, Val Acc: 0.783505\n",
      "Epoch 19005 - Train Loss: 0.080910, Train Acc: 0.883333 | Val Loss: 0.108588, Val Acc: 0.783505\n",
      "Epoch 19006 - Train Loss: 0.080908, Train Acc: 0.883333 | Val Loss: 0.108587, Val Acc: 0.783505\n",
      "Epoch 19007 - Train Loss: 0.080906, Train Acc: 0.883333 | Val Loss: 0.108586, Val Acc: 0.783505\n",
      "Epoch 19008 - Train Loss: 0.080903, Train Acc: 0.883333 | Val Loss: 0.108585, Val Acc: 0.783505\n",
      "Epoch 19009 - Train Loss: 0.080901, Train Acc: 0.883333 | Val Loss: 0.108583, Val Acc: 0.783505\n",
      "Epoch 19010 - Train Loss: 0.080899, Train Acc: 0.883333 | Val Loss: 0.108582, Val Acc: 0.783505\n",
      "Epoch 19011 - Train Loss: 0.080896, Train Acc: 0.883333 | Val Loss: 0.108581, Val Acc: 0.783505\n",
      "Epoch 19012 - Train Loss: 0.080894, Train Acc: 0.883333 | Val Loss: 0.108580, Val Acc: 0.783505\n",
      "Epoch 19013 - Train Loss: 0.080891, Train Acc: 0.883333 | Val Loss: 0.108579, Val Acc: 0.783505\n",
      "Epoch 19014 - Train Loss: 0.080889, Train Acc: 0.883333 | Val Loss: 0.108578, Val Acc: 0.783505\n",
      "Epoch 19015 - Train Loss: 0.080887, Train Acc: 0.883333 | Val Loss: 0.108577, Val Acc: 0.783505\n",
      "Epoch 19016 - Train Loss: 0.080884, Train Acc: 0.883333 | Val Loss: 0.108576, Val Acc: 0.783505\n",
      "Epoch 19017 - Train Loss: 0.080882, Train Acc: 0.883333 | Val Loss: 0.108575, Val Acc: 0.783505\n",
      "Epoch 19018 - Train Loss: 0.080880, Train Acc: 0.883333 | Val Loss: 0.108573, Val Acc: 0.783505\n",
      "Epoch 19019 - Train Loss: 0.080877, Train Acc: 0.883333 | Val Loss: 0.108572, Val Acc: 0.783505\n",
      "Epoch 19020 - Train Loss: 0.080875, Train Acc: 0.883333 | Val Loss: 0.108571, Val Acc: 0.783505\n",
      "Epoch 19021 - Train Loss: 0.080873, Train Acc: 0.883333 | Val Loss: 0.108570, Val Acc: 0.783505\n",
      "Epoch 19022 - Train Loss: 0.080870, Train Acc: 0.883333 | Val Loss: 0.108569, Val Acc: 0.783505\n",
      "Epoch 19023 - Train Loss: 0.080868, Train Acc: 0.883333 | Val Loss: 0.108568, Val Acc: 0.783505\n",
      "Epoch 19024 - Train Loss: 0.080865, Train Acc: 0.883333 | Val Loss: 0.108567, Val Acc: 0.783505\n",
      "Epoch 19025 - Train Loss: 0.080863, Train Acc: 0.883333 | Val Loss: 0.108566, Val Acc: 0.783505\n",
      "Epoch 19026 - Train Loss: 0.080861, Train Acc: 0.883333 | Val Loss: 0.108565, Val Acc: 0.783505\n",
      "Epoch 19027 - Train Loss: 0.080858, Train Acc: 0.883333 | Val Loss: 0.108563, Val Acc: 0.783505\n",
      "Epoch 19028 - Train Loss: 0.080856, Train Acc: 0.883333 | Val Loss: 0.108562, Val Acc: 0.783505\n",
      "Epoch 19029 - Train Loss: 0.080854, Train Acc: 0.883333 | Val Loss: 0.108561, Val Acc: 0.783505\n",
      "Epoch 19030 - Train Loss: 0.080851, Train Acc: 0.883333 | Val Loss: 0.108560, Val Acc: 0.783505\n",
      "Epoch 19031 - Train Loss: 0.080849, Train Acc: 0.883333 | Val Loss: 0.108559, Val Acc: 0.783505\n",
      "Epoch 19032 - Train Loss: 0.080847, Train Acc: 0.883333 | Val Loss: 0.108558, Val Acc: 0.783505\n",
      "Epoch 19033 - Train Loss: 0.080844, Train Acc: 0.883333 | Val Loss: 0.108557, Val Acc: 0.783505\n",
      "Epoch 19034 - Train Loss: 0.080842, Train Acc: 0.883333 | Val Loss: 0.108556, Val Acc: 0.783505\n",
      "Epoch 19035 - Train Loss: 0.080840, Train Acc: 0.883333 | Val Loss: 0.108555, Val Acc: 0.783505\n",
      "Epoch 19036 - Train Loss: 0.080837, Train Acc: 0.883333 | Val Loss: 0.108554, Val Acc: 0.783505\n",
      "Epoch 19037 - Train Loss: 0.080835, Train Acc: 0.883333 | Val Loss: 0.108552, Val Acc: 0.783505\n",
      "Epoch 19038 - Train Loss: 0.080832, Train Acc: 0.883333 | Val Loss: 0.108551, Val Acc: 0.783505\n",
      "Epoch 19039 - Train Loss: 0.080830, Train Acc: 0.883333 | Val Loss: 0.108550, Val Acc: 0.783505\n",
      "Epoch 19040 - Train Loss: 0.080828, Train Acc: 0.883333 | Val Loss: 0.108549, Val Acc: 0.783505\n",
      "Epoch 19041 - Train Loss: 0.080825, Train Acc: 0.883333 | Val Loss: 0.108548, Val Acc: 0.783505\n",
      "Epoch 19042 - Train Loss: 0.080823, Train Acc: 0.883333 | Val Loss: 0.108547, Val Acc: 0.783505\n",
      "Epoch 19043 - Train Loss: 0.080821, Train Acc: 0.883333 | Val Loss: 0.108546, Val Acc: 0.783505\n",
      "Epoch 19044 - Train Loss: 0.080818, Train Acc: 0.883333 | Val Loss: 0.108545, Val Acc: 0.783505\n",
      "Epoch 19045 - Train Loss: 0.080816, Train Acc: 0.883333 | Val Loss: 0.108544, Val Acc: 0.783505\n",
      "Epoch 19046 - Train Loss: 0.080814, Train Acc: 0.883333 | Val Loss: 0.108543, Val Acc: 0.783505\n",
      "Epoch 19047 - Train Loss: 0.080811, Train Acc: 0.883333 | Val Loss: 0.108541, Val Acc: 0.783505\n",
      "Epoch 19048 - Train Loss: 0.080809, Train Acc: 0.883333 | Val Loss: 0.108540, Val Acc: 0.783505\n",
      "Epoch 19049 - Train Loss: 0.080807, Train Acc: 0.883333 | Val Loss: 0.108539, Val Acc: 0.783505\n",
      "Epoch 19050 - Train Loss: 0.080804, Train Acc: 0.883333 | Val Loss: 0.108538, Val Acc: 0.783505\n",
      "Epoch 19051 - Train Loss: 0.080802, Train Acc: 0.883333 | Val Loss: 0.108537, Val Acc: 0.783505\n",
      "Epoch 19052 - Train Loss: 0.080800, Train Acc: 0.883333 | Val Loss: 0.108536, Val Acc: 0.783505\n",
      "Epoch 19053 - Train Loss: 0.080797, Train Acc: 0.883333 | Val Loss: 0.108535, Val Acc: 0.783505\n",
      "Epoch 19054 - Train Loss: 0.080795, Train Acc: 0.883333 | Val Loss: 0.108534, Val Acc: 0.783505\n",
      "Epoch 19055 - Train Loss: 0.080792, Train Acc: 0.883333 | Val Loss: 0.108533, Val Acc: 0.783505\n",
      "Epoch 19056 - Train Loss: 0.080790, Train Acc: 0.883333 | Val Loss: 0.108531, Val Acc: 0.783505\n",
      "Epoch 19057 - Train Loss: 0.080788, Train Acc: 0.883333 | Val Loss: 0.108530, Val Acc: 0.783505\n",
      "Epoch 19058 - Train Loss: 0.080785, Train Acc: 0.883333 | Val Loss: 0.108529, Val Acc: 0.783505\n",
      "Epoch 19059 - Train Loss: 0.080783, Train Acc: 0.883333 | Val Loss: 0.108528, Val Acc: 0.783505\n",
      "Epoch 19060 - Train Loss: 0.080781, Train Acc: 0.883333 | Val Loss: 0.108527, Val Acc: 0.783505\n",
      "Epoch 19061 - Train Loss: 0.080778, Train Acc: 0.883333 | Val Loss: 0.108526, Val Acc: 0.783505\n",
      "Epoch 19062 - Train Loss: 0.080776, Train Acc: 0.883333 | Val Loss: 0.108525, Val Acc: 0.783505\n",
      "Epoch 19063 - Train Loss: 0.080774, Train Acc: 0.883333 | Val Loss: 0.108524, Val Acc: 0.783505\n",
      "Epoch 19064 - Train Loss: 0.080771, Train Acc: 0.883333 | Val Loss: 0.108523, Val Acc: 0.783505\n",
      "Epoch 19065 - Train Loss: 0.080769, Train Acc: 0.883333 | Val Loss: 0.108522, Val Acc: 0.783505\n",
      "Epoch 19066 - Train Loss: 0.080767, Train Acc: 0.883333 | Val Loss: 0.108521, Val Acc: 0.783505\n",
      "Epoch 19067 - Train Loss: 0.080764, Train Acc: 0.883333 | Val Loss: 0.108519, Val Acc: 0.783505\n",
      "Epoch 19068 - Train Loss: 0.080762, Train Acc: 0.883333 | Val Loss: 0.108518, Val Acc: 0.783505\n",
      "Epoch 19069 - Train Loss: 0.080760, Train Acc: 0.883333 | Val Loss: 0.108517, Val Acc: 0.783505\n",
      "Epoch 19070 - Train Loss: 0.080757, Train Acc: 0.883333 | Val Loss: 0.108516, Val Acc: 0.783505\n",
      "Epoch 19071 - Train Loss: 0.080755, Train Acc: 0.883333 | Val Loss: 0.108515, Val Acc: 0.783505\n",
      "Epoch 19072 - Train Loss: 0.080753, Train Acc: 0.883333 | Val Loss: 0.108514, Val Acc: 0.783505\n",
      "Epoch 19073 - Train Loss: 0.080750, Train Acc: 0.883333 | Val Loss: 0.108513, Val Acc: 0.783505\n",
      "Epoch 19074 - Train Loss: 0.080748, Train Acc: 0.883333 | Val Loss: 0.108512, Val Acc: 0.783505\n",
      "Epoch 19075 - Train Loss: 0.080746, Train Acc: 0.884615 | Val Loss: 0.108511, Val Acc: 0.783505\n",
      "Epoch 19076 - Train Loss: 0.080743, Train Acc: 0.884615 | Val Loss: 0.108510, Val Acc: 0.783505\n",
      "Epoch 19077 - Train Loss: 0.080741, Train Acc: 0.884615 | Val Loss: 0.108508, Val Acc: 0.783505\n",
      "Epoch 19078 - Train Loss: 0.080738, Train Acc: 0.884615 | Val Loss: 0.108507, Val Acc: 0.783505\n",
      "Epoch 19079 - Train Loss: 0.080736, Train Acc: 0.884615 | Val Loss: 0.108506, Val Acc: 0.783505\n",
      "Epoch 19080 - Train Loss: 0.080734, Train Acc: 0.884615 | Val Loss: 0.108505, Val Acc: 0.783505\n",
      "Epoch 19081 - Train Loss: 0.080731, Train Acc: 0.884615 | Val Loss: 0.108504, Val Acc: 0.783505\n",
      "Epoch 19082 - Train Loss: 0.080729, Train Acc: 0.884615 | Val Loss: 0.108503, Val Acc: 0.783505\n",
      "Epoch 19083 - Train Loss: 0.080727, Train Acc: 0.884615 | Val Loss: 0.108502, Val Acc: 0.783505\n",
      "Epoch 19084 - Train Loss: 0.080724, Train Acc: 0.884615 | Val Loss: 0.108501, Val Acc: 0.783505\n",
      "Epoch 19085 - Train Loss: 0.080722, Train Acc: 0.884615 | Val Loss: 0.108500, Val Acc: 0.783505\n",
      "Epoch 19086 - Train Loss: 0.080720, Train Acc: 0.884615 | Val Loss: 0.108499, Val Acc: 0.783505\n",
      "Epoch 19087 - Train Loss: 0.080717, Train Acc: 0.884615 | Val Loss: 0.108498, Val Acc: 0.783505\n",
      "Epoch 19088 - Train Loss: 0.080715, Train Acc: 0.884615 | Val Loss: 0.108497, Val Acc: 0.783505\n",
      "Epoch 19089 - Train Loss: 0.080713, Train Acc: 0.884615 | Val Loss: 0.108495, Val Acc: 0.783505\n",
      "Epoch 19090 - Train Loss: 0.080710, Train Acc: 0.884615 | Val Loss: 0.108494, Val Acc: 0.783505\n",
      "Epoch 19091 - Train Loss: 0.080708, Train Acc: 0.884615 | Val Loss: 0.108493, Val Acc: 0.783505\n",
      "Epoch 19092 - Train Loss: 0.080706, Train Acc: 0.884615 | Val Loss: 0.108492, Val Acc: 0.783505\n",
      "Epoch 19093 - Train Loss: 0.080703, Train Acc: 0.884615 | Val Loss: 0.108491, Val Acc: 0.783505\n",
      "Epoch 19094 - Train Loss: 0.080701, Train Acc: 0.884615 | Val Loss: 0.108490, Val Acc: 0.783505\n",
      "Epoch 19095 - Train Loss: 0.080699, Train Acc: 0.884615 | Val Loss: 0.108489, Val Acc: 0.783505\n",
      "Epoch 19096 - Train Loss: 0.080696, Train Acc: 0.884615 | Val Loss: 0.108488, Val Acc: 0.783505\n",
      "Epoch 19097 - Train Loss: 0.080694, Train Acc: 0.884615 | Val Loss: 0.108487, Val Acc: 0.783505\n",
      "Epoch 19098 - Train Loss: 0.080692, Train Acc: 0.884615 | Val Loss: 0.108486, Val Acc: 0.783505\n",
      "Epoch 19099 - Train Loss: 0.080689, Train Acc: 0.884615 | Val Loss: 0.108484, Val Acc: 0.783505\n",
      "Epoch 19100 - Train Loss: 0.080687, Train Acc: 0.884615 | Val Loss: 0.108483, Val Acc: 0.783505\n",
      "Epoch 19101 - Train Loss: 0.080685, Train Acc: 0.884615 | Val Loss: 0.108482, Val Acc: 0.783505\n",
      "Epoch 19102 - Train Loss: 0.080682, Train Acc: 0.884615 | Val Loss: 0.108481, Val Acc: 0.783505\n",
      "Epoch 19103 - Train Loss: 0.080680, Train Acc: 0.884615 | Val Loss: 0.108480, Val Acc: 0.783505\n",
      "Epoch 19104 - Train Loss: 0.080678, Train Acc: 0.884615 | Val Loss: 0.108479, Val Acc: 0.783505\n",
      "Epoch 19105 - Train Loss: 0.080675, Train Acc: 0.884615 | Val Loss: 0.108478, Val Acc: 0.783505\n",
      "Epoch 19106 - Train Loss: 0.080673, Train Acc: 0.884615 | Val Loss: 0.108477, Val Acc: 0.783505\n",
      "Epoch 19107 - Train Loss: 0.080671, Train Acc: 0.884615 | Val Loss: 0.108476, Val Acc: 0.783505\n",
      "Epoch 19108 - Train Loss: 0.080668, Train Acc: 0.884615 | Val Loss: 0.108475, Val Acc: 0.783505\n",
      "Epoch 19109 - Train Loss: 0.080666, Train Acc: 0.884615 | Val Loss: 0.108474, Val Acc: 0.783505\n",
      "Epoch 19110 - Train Loss: 0.080664, Train Acc: 0.884615 | Val Loss: 0.108472, Val Acc: 0.783505\n",
      "Epoch 19111 - Train Loss: 0.080661, Train Acc: 0.884615 | Val Loss: 0.108471, Val Acc: 0.783505\n",
      "Epoch 19112 - Train Loss: 0.080659, Train Acc: 0.884615 | Val Loss: 0.108470, Val Acc: 0.783505\n",
      "Epoch 19113 - Train Loss: 0.080657, Train Acc: 0.884615 | Val Loss: 0.108469, Val Acc: 0.783505\n",
      "Epoch 19114 - Train Loss: 0.080654, Train Acc: 0.884615 | Val Loss: 0.108468, Val Acc: 0.783505\n",
      "Epoch 19115 - Train Loss: 0.080652, Train Acc: 0.884615 | Val Loss: 0.108467, Val Acc: 0.783505\n",
      "Epoch 19116 - Train Loss: 0.080650, Train Acc: 0.884615 | Val Loss: 0.108466, Val Acc: 0.783505\n",
      "Epoch 19117 - Train Loss: 0.080647, Train Acc: 0.884615 | Val Loss: 0.108465, Val Acc: 0.783505\n",
      "Epoch 19118 - Train Loss: 0.080645, Train Acc: 0.884615 | Val Loss: 0.108464, Val Acc: 0.783505\n",
      "Epoch 19119 - Train Loss: 0.080643, Train Acc: 0.884615 | Val Loss: 0.108463, Val Acc: 0.783505\n",
      "Epoch 19120 - Train Loss: 0.080640, Train Acc: 0.884615 | Val Loss: 0.108462, Val Acc: 0.783505\n",
      "Epoch 19121 - Train Loss: 0.080638, Train Acc: 0.884615 | Val Loss: 0.108460, Val Acc: 0.783505\n",
      "Epoch 19122 - Train Loss: 0.080636, Train Acc: 0.884615 | Val Loss: 0.108459, Val Acc: 0.783505\n",
      "Epoch 19123 - Train Loss: 0.080633, Train Acc: 0.884615 | Val Loss: 0.108458, Val Acc: 0.783505\n",
      "Epoch 19124 - Train Loss: 0.080631, Train Acc: 0.884615 | Val Loss: 0.108457, Val Acc: 0.783505\n",
      "Epoch 19125 - Train Loss: 0.080629, Train Acc: 0.884615 | Val Loss: 0.108456, Val Acc: 0.783505\n",
      "Epoch 19126 - Train Loss: 0.080626, Train Acc: 0.884615 | Val Loss: 0.108455, Val Acc: 0.783505\n",
      "Epoch 19127 - Train Loss: 0.080624, Train Acc: 0.884615 | Val Loss: 0.108454, Val Acc: 0.783505\n",
      "Epoch 19128 - Train Loss: 0.080622, Train Acc: 0.884615 | Val Loss: 0.108453, Val Acc: 0.783505\n",
      "Epoch 19129 - Train Loss: 0.080619, Train Acc: 0.884615 | Val Loss: 0.108452, Val Acc: 0.783505\n",
      "Epoch 19130 - Train Loss: 0.080617, Train Acc: 0.884615 | Val Loss: 0.108451, Val Acc: 0.783505\n",
      "Epoch 19131 - Train Loss: 0.080615, Train Acc: 0.884615 | Val Loss: 0.108450, Val Acc: 0.783505\n",
      "Epoch 19132 - Train Loss: 0.080612, Train Acc: 0.884615 | Val Loss: 0.108449, Val Acc: 0.783505\n",
      "Epoch 19133 - Train Loss: 0.080610, Train Acc: 0.884615 | Val Loss: 0.108447, Val Acc: 0.783505\n",
      "Epoch 19134 - Train Loss: 0.080608, Train Acc: 0.884615 | Val Loss: 0.108446, Val Acc: 0.783505\n",
      "Epoch 19135 - Train Loss: 0.080605, Train Acc: 0.884615 | Val Loss: 0.108445, Val Acc: 0.783505\n",
      "Epoch 19136 - Train Loss: 0.080603, Train Acc: 0.884615 | Val Loss: 0.108444, Val Acc: 0.783505\n",
      "Epoch 19137 - Train Loss: 0.080601, Train Acc: 0.884615 | Val Loss: 0.108443, Val Acc: 0.783505\n",
      "Epoch 19138 - Train Loss: 0.080598, Train Acc: 0.884615 | Val Loss: 0.108442, Val Acc: 0.783505\n",
      "Epoch 19139 - Train Loss: 0.080596, Train Acc: 0.884615 | Val Loss: 0.108441, Val Acc: 0.783505\n",
      "Epoch 19140 - Train Loss: 0.080594, Train Acc: 0.884615 | Val Loss: 0.108440, Val Acc: 0.783505\n",
      "Epoch 19141 - Train Loss: 0.080591, Train Acc: 0.884615 | Val Loss: 0.108439, Val Acc: 0.783505\n",
      "Epoch 19142 - Train Loss: 0.080589, Train Acc: 0.884615 | Val Loss: 0.108438, Val Acc: 0.783505\n",
      "Epoch 19143 - Train Loss: 0.080587, Train Acc: 0.884615 | Val Loss: 0.108437, Val Acc: 0.783505\n",
      "Epoch 19144 - Train Loss: 0.080584, Train Acc: 0.884615 | Val Loss: 0.108436, Val Acc: 0.783505\n",
      "Epoch 19145 - Train Loss: 0.080582, Train Acc: 0.884615 | Val Loss: 0.108435, Val Acc: 0.783505\n",
      "Epoch 19146 - Train Loss: 0.080580, Train Acc: 0.884615 | Val Loss: 0.108433, Val Acc: 0.783505\n",
      "Epoch 19147 - Train Loss: 0.080577, Train Acc: 0.884615 | Val Loss: 0.108432, Val Acc: 0.783505\n",
      "Epoch 19148 - Train Loss: 0.080575, Train Acc: 0.884615 | Val Loss: 0.108431, Val Acc: 0.783505\n",
      "Epoch 19149 - Train Loss: 0.080573, Train Acc: 0.884615 | Val Loss: 0.108430, Val Acc: 0.783505\n",
      "Epoch 19150 - Train Loss: 0.080570, Train Acc: 0.884615 | Val Loss: 0.108429, Val Acc: 0.783505\n",
      "Epoch 19151 - Train Loss: 0.080568, Train Acc: 0.884615 | Val Loss: 0.108428, Val Acc: 0.783505\n",
      "Epoch 19152 - Train Loss: 0.080566, Train Acc: 0.884615 | Val Loss: 0.108427, Val Acc: 0.783505\n",
      "Epoch 19153 - Train Loss: 0.080563, Train Acc: 0.884615 | Val Loss: 0.108426, Val Acc: 0.783505\n",
      "Epoch 19154 - Train Loss: 0.080561, Train Acc: 0.884615 | Val Loss: 0.108425, Val Acc: 0.783505\n",
      "Epoch 19155 - Train Loss: 0.080559, Train Acc: 0.884615 | Val Loss: 0.108424, Val Acc: 0.783505\n",
      "Epoch 19156 - Train Loss: 0.080556, Train Acc: 0.884615 | Val Loss: 0.108423, Val Acc: 0.783505\n",
      "Epoch 19157 - Train Loss: 0.080554, Train Acc: 0.884615 | Val Loss: 0.108422, Val Acc: 0.783505\n",
      "Epoch 19158 - Train Loss: 0.080552, Train Acc: 0.884615 | Val Loss: 0.108420, Val Acc: 0.783505\n",
      "Epoch 19159 - Train Loss: 0.080549, Train Acc: 0.884615 | Val Loss: 0.108419, Val Acc: 0.783505\n",
      "Epoch 19160 - Train Loss: 0.080547, Train Acc: 0.884615 | Val Loss: 0.108418, Val Acc: 0.783505\n",
      "Epoch 19161 - Train Loss: 0.080545, Train Acc: 0.884615 | Val Loss: 0.108417, Val Acc: 0.783505\n",
      "Epoch 19162 - Train Loss: 0.080542, Train Acc: 0.884615 | Val Loss: 0.108416, Val Acc: 0.783505\n",
      "Epoch 19163 - Train Loss: 0.080540, Train Acc: 0.884615 | Val Loss: 0.108415, Val Acc: 0.783505\n",
      "Epoch 19164 - Train Loss: 0.080538, Train Acc: 0.884615 | Val Loss: 0.108414, Val Acc: 0.783505\n",
      "Epoch 19165 - Train Loss: 0.080535, Train Acc: 0.884615 | Val Loss: 0.108413, Val Acc: 0.783505\n",
      "Epoch 19166 - Train Loss: 0.080533, Train Acc: 0.884615 | Val Loss: 0.108412, Val Acc: 0.783505\n",
      "Epoch 19167 - Train Loss: 0.080531, Train Acc: 0.884615 | Val Loss: 0.108411, Val Acc: 0.783505\n",
      "Epoch 19168 - Train Loss: 0.080529, Train Acc: 0.884615 | Val Loss: 0.108410, Val Acc: 0.783505\n",
      "Epoch 19169 - Train Loss: 0.080526, Train Acc: 0.884615 | Val Loss: 0.108409, Val Acc: 0.783505\n",
      "Epoch 19170 - Train Loss: 0.080524, Train Acc: 0.884615 | Val Loss: 0.108408, Val Acc: 0.783505\n",
      "Epoch 19171 - Train Loss: 0.080522, Train Acc: 0.884615 | Val Loss: 0.108406, Val Acc: 0.783505\n",
      "Epoch 19172 - Train Loss: 0.080519, Train Acc: 0.884615 | Val Loss: 0.108405, Val Acc: 0.783505\n",
      "Epoch 19173 - Train Loss: 0.080517, Train Acc: 0.884615 | Val Loss: 0.108404, Val Acc: 0.783505\n",
      "Epoch 19174 - Train Loss: 0.080515, Train Acc: 0.884615 | Val Loss: 0.108403, Val Acc: 0.783505\n",
      "Epoch 19175 - Train Loss: 0.080512, Train Acc: 0.884615 | Val Loss: 0.108402, Val Acc: 0.783505\n",
      "Epoch 19176 - Train Loss: 0.080510, Train Acc: 0.884615 | Val Loss: 0.108401, Val Acc: 0.783505\n",
      "Epoch 19177 - Train Loss: 0.080508, Train Acc: 0.884615 | Val Loss: 0.108400, Val Acc: 0.783505\n",
      "Epoch 19178 - Train Loss: 0.080505, Train Acc: 0.884615 | Val Loss: 0.108399, Val Acc: 0.783505\n",
      "Epoch 19179 - Train Loss: 0.080503, Train Acc: 0.884615 | Val Loss: 0.108398, Val Acc: 0.783505\n",
      "Epoch 19180 - Train Loss: 0.080501, Train Acc: 0.884615 | Val Loss: 0.108397, Val Acc: 0.783505\n",
      "Epoch 19181 - Train Loss: 0.080498, Train Acc: 0.884615 | Val Loss: 0.108396, Val Acc: 0.783505\n",
      "Epoch 19182 - Train Loss: 0.080496, Train Acc: 0.884615 | Val Loss: 0.108395, Val Acc: 0.783505\n",
      "Epoch 19183 - Train Loss: 0.080494, Train Acc: 0.884615 | Val Loss: 0.108394, Val Acc: 0.783505\n",
      "Epoch 19184 - Train Loss: 0.080491, Train Acc: 0.884615 | Val Loss: 0.108392, Val Acc: 0.783505\n",
      "Epoch 19185 - Train Loss: 0.080489, Train Acc: 0.884615 | Val Loss: 0.108391, Val Acc: 0.783505\n",
      "Epoch 19186 - Train Loss: 0.080487, Train Acc: 0.884615 | Val Loss: 0.108390, Val Acc: 0.783505\n",
      "Epoch 19187 - Train Loss: 0.080484, Train Acc: 0.884615 | Val Loss: 0.108389, Val Acc: 0.783505\n",
      "Epoch 19188 - Train Loss: 0.080482, Train Acc: 0.884615 | Val Loss: 0.108388, Val Acc: 0.783505\n",
      "Epoch 19189 - Train Loss: 0.080480, Train Acc: 0.884615 | Val Loss: 0.108387, Val Acc: 0.783505\n",
      "Epoch 19190 - Train Loss: 0.080477, Train Acc: 0.884615 | Val Loss: 0.108386, Val Acc: 0.783505\n",
      "Epoch 19191 - Train Loss: 0.080475, Train Acc: 0.884615 | Val Loss: 0.108385, Val Acc: 0.783505\n",
      "Epoch 19192 - Train Loss: 0.080473, Train Acc: 0.884615 | Val Loss: 0.108384, Val Acc: 0.783505\n",
      "Epoch 19193 - Train Loss: 0.080471, Train Acc: 0.884615 | Val Loss: 0.108383, Val Acc: 0.783505\n",
      "Epoch 19194 - Train Loss: 0.080468, Train Acc: 0.884615 | Val Loss: 0.108382, Val Acc: 0.783505\n",
      "Epoch 19195 - Train Loss: 0.080466, Train Acc: 0.884615 | Val Loss: 0.108381, Val Acc: 0.783505\n",
      "Epoch 19196 - Train Loss: 0.080464, Train Acc: 0.884615 | Val Loss: 0.108380, Val Acc: 0.783505\n",
      "Epoch 19197 - Train Loss: 0.080461, Train Acc: 0.884615 | Val Loss: 0.108379, Val Acc: 0.783505\n",
      "Epoch 19198 - Train Loss: 0.080459, Train Acc: 0.884615 | Val Loss: 0.108378, Val Acc: 0.783505\n",
      "Epoch 19199 - Train Loss: 0.080457, Train Acc: 0.884615 | Val Loss: 0.108376, Val Acc: 0.783505\n",
      "Epoch 19200 - Train Loss: 0.080454, Train Acc: 0.884615 | Val Loss: 0.108375, Val Acc: 0.783505\n",
      "Epoch 19201 - Train Loss: 0.080452, Train Acc: 0.884615 | Val Loss: 0.108374, Val Acc: 0.783505\n",
      "Epoch 19202 - Train Loss: 0.080450, Train Acc: 0.884615 | Val Loss: 0.108373, Val Acc: 0.783505\n",
      "Epoch 19203 - Train Loss: 0.080447, Train Acc: 0.884615 | Val Loss: 0.108372, Val Acc: 0.783505\n",
      "Epoch 19204 - Train Loss: 0.080445, Train Acc: 0.884615 | Val Loss: 0.108371, Val Acc: 0.783505\n",
      "Epoch 19205 - Train Loss: 0.080443, Train Acc: 0.884615 | Val Loss: 0.108370, Val Acc: 0.783505\n",
      "Epoch 19206 - Train Loss: 0.080440, Train Acc: 0.884615 | Val Loss: 0.108369, Val Acc: 0.783505\n",
      "Epoch 19207 - Train Loss: 0.080438, Train Acc: 0.884615 | Val Loss: 0.108368, Val Acc: 0.783505\n",
      "Epoch 19208 - Train Loss: 0.080436, Train Acc: 0.884615 | Val Loss: 0.108367, Val Acc: 0.783505\n",
      "Epoch 19209 - Train Loss: 0.080434, Train Acc: 0.884615 | Val Loss: 0.108366, Val Acc: 0.783505\n",
      "Epoch 19210 - Train Loss: 0.080431, Train Acc: 0.884615 | Val Loss: 0.108365, Val Acc: 0.783505\n",
      "Epoch 19211 - Train Loss: 0.080429, Train Acc: 0.884615 | Val Loss: 0.108364, Val Acc: 0.783505\n",
      "Epoch 19212 - Train Loss: 0.080427, Train Acc: 0.884615 | Val Loss: 0.108363, Val Acc: 0.783505\n",
      "Epoch 19213 - Train Loss: 0.080424, Train Acc: 0.884615 | Val Loss: 0.108361, Val Acc: 0.783505\n",
      "Epoch 19214 - Train Loss: 0.080422, Train Acc: 0.884615 | Val Loss: 0.108360, Val Acc: 0.783505\n",
      "Epoch 19215 - Train Loss: 0.080420, Train Acc: 0.884615 | Val Loss: 0.108359, Val Acc: 0.783505\n",
      "Epoch 19216 - Train Loss: 0.080417, Train Acc: 0.884615 | Val Loss: 0.108358, Val Acc: 0.783505\n",
      "Epoch 19217 - Train Loss: 0.080415, Train Acc: 0.884615 | Val Loss: 0.108357, Val Acc: 0.783505\n",
      "Epoch 19218 - Train Loss: 0.080413, Train Acc: 0.884615 | Val Loss: 0.108356, Val Acc: 0.783505\n",
      "Epoch 19219 - Train Loss: 0.080410, Train Acc: 0.884615 | Val Loss: 0.108355, Val Acc: 0.783505\n",
      "Epoch 19220 - Train Loss: 0.080408, Train Acc: 0.884615 | Val Loss: 0.108354, Val Acc: 0.783505\n",
      "Epoch 19221 - Train Loss: 0.080406, Train Acc: 0.884615 | Val Loss: 0.108353, Val Acc: 0.783505\n",
      "Epoch 19222 - Train Loss: 0.080403, Train Acc: 0.884615 | Val Loss: 0.108352, Val Acc: 0.783505\n",
      "Epoch 19223 - Train Loss: 0.080401, Train Acc: 0.884615 | Val Loss: 0.108351, Val Acc: 0.783505\n",
      "Epoch 19224 - Train Loss: 0.080399, Train Acc: 0.884615 | Val Loss: 0.108350, Val Acc: 0.783505\n",
      "Epoch 19225 - Train Loss: 0.080397, Train Acc: 0.884615 | Val Loss: 0.108349, Val Acc: 0.783505\n",
      "Epoch 19226 - Train Loss: 0.080394, Train Acc: 0.884615 | Val Loss: 0.108348, Val Acc: 0.783505\n",
      "Epoch 19227 - Train Loss: 0.080392, Train Acc: 0.884615 | Val Loss: 0.108347, Val Acc: 0.783505\n",
      "Epoch 19228 - Train Loss: 0.080390, Train Acc: 0.884615 | Val Loss: 0.108346, Val Acc: 0.783505\n",
      "Epoch 19229 - Train Loss: 0.080387, Train Acc: 0.884615 | Val Loss: 0.108344, Val Acc: 0.783505\n",
      "Epoch 19230 - Train Loss: 0.080385, Train Acc: 0.884615 | Val Loss: 0.108343, Val Acc: 0.783505\n",
      "Epoch 19231 - Train Loss: 0.080383, Train Acc: 0.884615 | Val Loss: 0.108342, Val Acc: 0.783505\n",
      "Epoch 19232 - Train Loss: 0.080380, Train Acc: 0.884615 | Val Loss: 0.108341, Val Acc: 0.783505\n",
      "Epoch 19233 - Train Loss: 0.080378, Train Acc: 0.884615 | Val Loss: 0.108340, Val Acc: 0.783505\n",
      "Epoch 19234 - Train Loss: 0.080376, Train Acc: 0.884615 | Val Loss: 0.108339, Val Acc: 0.783505\n",
      "Epoch 19235 - Train Loss: 0.080373, Train Acc: 0.884615 | Val Loss: 0.108338, Val Acc: 0.783505\n",
      "Epoch 19236 - Train Loss: 0.080371, Train Acc: 0.884615 | Val Loss: 0.108337, Val Acc: 0.783505\n",
      "Epoch 19237 - Train Loss: 0.080369, Train Acc: 0.884615 | Val Loss: 0.108336, Val Acc: 0.783505\n",
      "Epoch 19238 - Train Loss: 0.080367, Train Acc: 0.884615 | Val Loss: 0.108335, Val Acc: 0.783505\n",
      "Epoch 19239 - Train Loss: 0.080364, Train Acc: 0.884615 | Val Loss: 0.108334, Val Acc: 0.783505\n",
      "Epoch 19240 - Train Loss: 0.080362, Train Acc: 0.884615 | Val Loss: 0.108333, Val Acc: 0.783505\n",
      "Epoch 19241 - Train Loss: 0.080360, Train Acc: 0.884615 | Val Loss: 0.108332, Val Acc: 0.783505\n",
      "Epoch 19242 - Train Loss: 0.080357, Train Acc: 0.884615 | Val Loss: 0.108331, Val Acc: 0.783505\n",
      "Epoch 19243 - Train Loss: 0.080355, Train Acc: 0.884615 | Val Loss: 0.108330, Val Acc: 0.783505\n",
      "Epoch 19244 - Train Loss: 0.080353, Train Acc: 0.884615 | Val Loss: 0.108329, Val Acc: 0.783505\n",
      "Epoch 19245 - Train Loss: 0.080350, Train Acc: 0.884615 | Val Loss: 0.108328, Val Acc: 0.783505\n",
      "Epoch 19246 - Train Loss: 0.080348, Train Acc: 0.884615 | Val Loss: 0.108326, Val Acc: 0.783505\n",
      "Epoch 19247 - Train Loss: 0.080346, Train Acc: 0.884615 | Val Loss: 0.108325, Val Acc: 0.783505\n",
      "Epoch 19248 - Train Loss: 0.080344, Train Acc: 0.884615 | Val Loss: 0.108324, Val Acc: 0.783505\n",
      "Epoch 19249 - Train Loss: 0.080341, Train Acc: 0.884615 | Val Loss: 0.108323, Val Acc: 0.783505\n",
      "Epoch 19250 - Train Loss: 0.080339, Train Acc: 0.884615 | Val Loss: 0.108322, Val Acc: 0.783505\n",
      "Epoch 19251 - Train Loss: 0.080337, Train Acc: 0.884615 | Val Loss: 0.108321, Val Acc: 0.783505\n",
      "Epoch 19252 - Train Loss: 0.080334, Train Acc: 0.884615 | Val Loss: 0.108320, Val Acc: 0.783505\n",
      "Epoch 19253 - Train Loss: 0.080332, Train Acc: 0.884615 | Val Loss: 0.108319, Val Acc: 0.783505\n",
      "Epoch 19254 - Train Loss: 0.080330, Train Acc: 0.884615 | Val Loss: 0.108318, Val Acc: 0.783505\n",
      "Epoch 19255 - Train Loss: 0.080327, Train Acc: 0.884615 | Val Loss: 0.108317, Val Acc: 0.783505\n",
      "Epoch 19256 - Train Loss: 0.080325, Train Acc: 0.884615 | Val Loss: 0.108316, Val Acc: 0.783505\n",
      "Epoch 19257 - Train Loss: 0.080323, Train Acc: 0.884615 | Val Loss: 0.108315, Val Acc: 0.783505\n",
      "Epoch 19258 - Train Loss: 0.080321, Train Acc: 0.884615 | Val Loss: 0.108314, Val Acc: 0.783505\n",
      "Epoch 19259 - Train Loss: 0.080318, Train Acc: 0.884615 | Val Loss: 0.108313, Val Acc: 0.783505\n",
      "Epoch 19260 - Train Loss: 0.080316, Train Acc: 0.884615 | Val Loss: 0.108312, Val Acc: 0.783505\n",
      "Epoch 19261 - Train Loss: 0.080314, Train Acc: 0.884615 | Val Loss: 0.108311, Val Acc: 0.783505\n",
      "Epoch 19262 - Train Loss: 0.080311, Train Acc: 0.884615 | Val Loss: 0.108310, Val Acc: 0.783505\n",
      "Epoch 19263 - Train Loss: 0.080309, Train Acc: 0.884615 | Val Loss: 0.108308, Val Acc: 0.783505\n",
      "Epoch 19264 - Train Loss: 0.080307, Train Acc: 0.884615 | Val Loss: 0.108307, Val Acc: 0.783505\n",
      "Epoch 19265 - Train Loss: 0.080304, Train Acc: 0.884615 | Val Loss: 0.108306, Val Acc: 0.783505\n",
      "Epoch 19266 - Train Loss: 0.080302, Train Acc: 0.884615 | Val Loss: 0.108305, Val Acc: 0.783505\n",
      "Epoch 19267 - Train Loss: 0.080300, Train Acc: 0.884615 | Val Loss: 0.108304, Val Acc: 0.783505\n",
      "Epoch 19268 - Train Loss: 0.080298, Train Acc: 0.884615 | Val Loss: 0.108303, Val Acc: 0.783505\n",
      "Epoch 19269 - Train Loss: 0.080295, Train Acc: 0.884615 | Val Loss: 0.108302, Val Acc: 0.783505\n",
      "Epoch 19270 - Train Loss: 0.080293, Train Acc: 0.884615 | Val Loss: 0.108301, Val Acc: 0.783505\n",
      "Epoch 19271 - Train Loss: 0.080291, Train Acc: 0.884615 | Val Loss: 0.108300, Val Acc: 0.783505\n",
      "Epoch 19272 - Train Loss: 0.080288, Train Acc: 0.884615 | Val Loss: 0.108299, Val Acc: 0.783505\n",
      "Epoch 19273 - Train Loss: 0.080286, Train Acc: 0.884615 | Val Loss: 0.108298, Val Acc: 0.783505\n",
      "Epoch 19274 - Train Loss: 0.080284, Train Acc: 0.884615 | Val Loss: 0.108297, Val Acc: 0.783505\n",
      "Epoch 19275 - Train Loss: 0.080281, Train Acc: 0.884615 | Val Loss: 0.108296, Val Acc: 0.783505\n",
      "Epoch 19276 - Train Loss: 0.080279, Train Acc: 0.884615 | Val Loss: 0.108295, Val Acc: 0.783505\n",
      "Epoch 19277 - Train Loss: 0.080277, Train Acc: 0.884615 | Val Loss: 0.108294, Val Acc: 0.783505\n",
      "Epoch 19278 - Train Loss: 0.080275, Train Acc: 0.884615 | Val Loss: 0.108293, Val Acc: 0.783505\n",
      "Epoch 19279 - Train Loss: 0.080272, Train Acc: 0.884615 | Val Loss: 0.108292, Val Acc: 0.783505\n",
      "Epoch 19280 - Train Loss: 0.080270, Train Acc: 0.884615 | Val Loss: 0.108291, Val Acc: 0.783505\n",
      "Epoch 19281 - Train Loss: 0.080268, Train Acc: 0.884615 | Val Loss: 0.108290, Val Acc: 0.783505\n",
      "Epoch 19282 - Train Loss: 0.080265, Train Acc: 0.884615 | Val Loss: 0.108288, Val Acc: 0.783505\n",
      "Epoch 19283 - Train Loss: 0.080263, Train Acc: 0.884615 | Val Loss: 0.108287, Val Acc: 0.783505\n",
      "Epoch 19284 - Train Loss: 0.080261, Train Acc: 0.884615 | Val Loss: 0.108286, Val Acc: 0.783505\n",
      "Epoch 19285 - Train Loss: 0.080258, Train Acc: 0.884615 | Val Loss: 0.108285, Val Acc: 0.783505\n",
      "Epoch 19286 - Train Loss: 0.080256, Train Acc: 0.884615 | Val Loss: 0.108284, Val Acc: 0.783505\n",
      "Epoch 19287 - Train Loss: 0.080254, Train Acc: 0.884615 | Val Loss: 0.108283, Val Acc: 0.783505\n",
      "Epoch 19288 - Train Loss: 0.080252, Train Acc: 0.884615 | Val Loss: 0.108282, Val Acc: 0.783505\n",
      "Epoch 19289 - Train Loss: 0.080249, Train Acc: 0.884615 | Val Loss: 0.108281, Val Acc: 0.783505\n",
      "Epoch 19290 - Train Loss: 0.080247, Train Acc: 0.884615 | Val Loss: 0.108280, Val Acc: 0.783505\n",
      "Epoch 19291 - Train Loss: 0.080245, Train Acc: 0.884615 | Val Loss: 0.108279, Val Acc: 0.783505\n",
      "Epoch 19292 - Train Loss: 0.080242, Train Acc: 0.884615 | Val Loss: 0.108278, Val Acc: 0.783505\n",
      "Epoch 19293 - Train Loss: 0.080240, Train Acc: 0.884615 | Val Loss: 0.108277, Val Acc: 0.783505\n",
      "Epoch 19294 - Train Loss: 0.080238, Train Acc: 0.884615 | Val Loss: 0.108276, Val Acc: 0.783505\n",
      "Epoch 19295 - Train Loss: 0.080236, Train Acc: 0.884615 | Val Loss: 0.108275, Val Acc: 0.783505\n",
      "Epoch 19296 - Train Loss: 0.080233, Train Acc: 0.884615 | Val Loss: 0.108274, Val Acc: 0.783505\n",
      "Epoch 19297 - Train Loss: 0.080231, Train Acc: 0.884615 | Val Loss: 0.108273, Val Acc: 0.783505\n",
      "Epoch 19298 - Train Loss: 0.080229, Train Acc: 0.884615 | Val Loss: 0.108272, Val Acc: 0.783505\n",
      "Epoch 19299 - Train Loss: 0.080226, Train Acc: 0.884615 | Val Loss: 0.108271, Val Acc: 0.783505\n",
      "Epoch 19300 - Train Loss: 0.080224, Train Acc: 0.884615 | Val Loss: 0.108270, Val Acc: 0.783505\n",
      "Epoch 19301 - Train Loss: 0.080222, Train Acc: 0.884615 | Val Loss: 0.108268, Val Acc: 0.783505\n",
      "Epoch 19302 - Train Loss: 0.080220, Train Acc: 0.884615 | Val Loss: 0.108267, Val Acc: 0.783505\n",
      "Epoch 19303 - Train Loss: 0.080217, Train Acc: 0.884615 | Val Loss: 0.108266, Val Acc: 0.783505\n",
      "Epoch 19304 - Train Loss: 0.080215, Train Acc: 0.884615 | Val Loss: 0.108265, Val Acc: 0.783505\n",
      "Epoch 19305 - Train Loss: 0.080213, Train Acc: 0.884615 | Val Loss: 0.108264, Val Acc: 0.783505\n",
      "Epoch 19306 - Train Loss: 0.080210, Train Acc: 0.884615 | Val Loss: 0.108263, Val Acc: 0.783505\n",
      "Epoch 19307 - Train Loss: 0.080208, Train Acc: 0.884615 | Val Loss: 0.108262, Val Acc: 0.783505\n",
      "Epoch 19308 - Train Loss: 0.080206, Train Acc: 0.884615 | Val Loss: 0.108261, Val Acc: 0.783505\n",
      "Epoch 19309 - Train Loss: 0.080204, Train Acc: 0.884615 | Val Loss: 0.108260, Val Acc: 0.783505\n",
      "Epoch 19310 - Train Loss: 0.080201, Train Acc: 0.884615 | Val Loss: 0.108259, Val Acc: 0.783505\n",
      "Epoch 19311 - Train Loss: 0.080199, Train Acc: 0.884615 | Val Loss: 0.108258, Val Acc: 0.783505\n",
      "Epoch 19312 - Train Loss: 0.080197, Train Acc: 0.884615 | Val Loss: 0.108257, Val Acc: 0.783505\n",
      "Epoch 19313 - Train Loss: 0.080194, Train Acc: 0.884615 | Val Loss: 0.108256, Val Acc: 0.783505\n",
      "Epoch 19314 - Train Loss: 0.080192, Train Acc: 0.884615 | Val Loss: 0.108255, Val Acc: 0.783505\n",
      "Epoch 19315 - Train Loss: 0.080190, Train Acc: 0.884615 | Val Loss: 0.108254, Val Acc: 0.783505\n",
      "Epoch 19316 - Train Loss: 0.080188, Train Acc: 0.884615 | Val Loss: 0.108253, Val Acc: 0.783505\n",
      "Epoch 19317 - Train Loss: 0.080185, Train Acc: 0.884615 | Val Loss: 0.108252, Val Acc: 0.783505\n",
      "Epoch 19318 - Train Loss: 0.080183, Train Acc: 0.884615 | Val Loss: 0.108251, Val Acc: 0.783505\n",
      "Epoch 19319 - Train Loss: 0.080181, Train Acc: 0.884615 | Val Loss: 0.108250, Val Acc: 0.783505\n",
      "Epoch 19320 - Train Loss: 0.080178, Train Acc: 0.884615 | Val Loss: 0.108249, Val Acc: 0.783505\n",
      "Epoch 19321 - Train Loss: 0.080176, Train Acc: 0.884615 | Val Loss: 0.108248, Val Acc: 0.783505\n",
      "Epoch 19322 - Train Loss: 0.080174, Train Acc: 0.884615 | Val Loss: 0.108247, Val Acc: 0.783505\n",
      "Epoch 19323 - Train Loss: 0.080172, Train Acc: 0.884615 | Val Loss: 0.108246, Val Acc: 0.783505\n",
      "Epoch 19324 - Train Loss: 0.080169, Train Acc: 0.884615 | Val Loss: 0.108245, Val Acc: 0.783505\n",
      "Epoch 19325 - Train Loss: 0.080167, Train Acc: 0.884615 | Val Loss: 0.108244, Val Acc: 0.783505\n",
      "Epoch 19326 - Train Loss: 0.080165, Train Acc: 0.884615 | Val Loss: 0.108242, Val Acc: 0.783505\n",
      "Epoch 19327 - Train Loss: 0.080162, Train Acc: 0.884615 | Val Loss: 0.108241, Val Acc: 0.783505\n",
      "Epoch 19328 - Train Loss: 0.080160, Train Acc: 0.884615 | Val Loss: 0.108240, Val Acc: 0.783505\n",
      "Epoch 19329 - Train Loss: 0.080158, Train Acc: 0.884615 | Val Loss: 0.108239, Val Acc: 0.783505\n",
      "Epoch 19330 - Train Loss: 0.080156, Train Acc: 0.884615 | Val Loss: 0.108238, Val Acc: 0.783505\n",
      "Epoch 19331 - Train Loss: 0.080153, Train Acc: 0.884615 | Val Loss: 0.108237, Val Acc: 0.783505\n",
      "Epoch 19332 - Train Loss: 0.080151, Train Acc: 0.884615 | Val Loss: 0.108236, Val Acc: 0.783505\n",
      "Epoch 19333 - Train Loss: 0.080149, Train Acc: 0.884615 | Val Loss: 0.108235, Val Acc: 0.783505\n",
      "Epoch 19334 - Train Loss: 0.080146, Train Acc: 0.884615 | Val Loss: 0.108234, Val Acc: 0.783505\n",
      "Epoch 19335 - Train Loss: 0.080144, Train Acc: 0.884615 | Val Loss: 0.108233, Val Acc: 0.783505\n",
      "Epoch 19336 - Train Loss: 0.080142, Train Acc: 0.884615 | Val Loss: 0.108232, Val Acc: 0.783505\n",
      "Epoch 19337 - Train Loss: 0.080140, Train Acc: 0.884615 | Val Loss: 0.108231, Val Acc: 0.783505\n",
      "Epoch 19338 - Train Loss: 0.080137, Train Acc: 0.884615 | Val Loss: 0.108230, Val Acc: 0.783505\n",
      "Epoch 19339 - Train Loss: 0.080135, Train Acc: 0.884615 | Val Loss: 0.108229, Val Acc: 0.783505\n",
      "Epoch 19340 - Train Loss: 0.080133, Train Acc: 0.884615 | Val Loss: 0.108228, Val Acc: 0.783505\n",
      "Epoch 19341 - Train Loss: 0.080130, Train Acc: 0.884615 | Val Loss: 0.108227, Val Acc: 0.783505\n",
      "Epoch 19342 - Train Loss: 0.080128, Train Acc: 0.884615 | Val Loss: 0.108226, Val Acc: 0.783505\n",
      "Epoch 19343 - Train Loss: 0.080126, Train Acc: 0.884615 | Val Loss: 0.108225, Val Acc: 0.783505\n",
      "Epoch 19344 - Train Loss: 0.080124, Train Acc: 0.884615 | Val Loss: 0.108224, Val Acc: 0.783505\n",
      "Epoch 19345 - Train Loss: 0.080121, Train Acc: 0.884615 | Val Loss: 0.108223, Val Acc: 0.783505\n",
      "Epoch 19346 - Train Loss: 0.080119, Train Acc: 0.884615 | Val Loss: 0.108222, Val Acc: 0.783505\n",
      "Epoch 19347 - Train Loss: 0.080117, Train Acc: 0.884615 | Val Loss: 0.108221, Val Acc: 0.783505\n",
      "Epoch 19348 - Train Loss: 0.080114, Train Acc: 0.884615 | Val Loss: 0.108220, Val Acc: 0.783505\n",
      "Epoch 19349 - Train Loss: 0.080112, Train Acc: 0.884615 | Val Loss: 0.108219, Val Acc: 0.783505\n",
      "Epoch 19350 - Train Loss: 0.080110, Train Acc: 0.884615 | Val Loss: 0.108218, Val Acc: 0.783505\n",
      "Epoch 19351 - Train Loss: 0.080108, Train Acc: 0.884615 | Val Loss: 0.108217, Val Acc: 0.783505\n",
      "Epoch 19352 - Train Loss: 0.080105, Train Acc: 0.884615 | Val Loss: 0.108216, Val Acc: 0.783505\n",
      "Epoch 19353 - Train Loss: 0.080103, Train Acc: 0.884615 | Val Loss: 0.108215, Val Acc: 0.783505\n",
      "Epoch 19354 - Train Loss: 0.080101, Train Acc: 0.884615 | Val Loss: 0.108214, Val Acc: 0.783505\n",
      "Epoch 19355 - Train Loss: 0.080099, Train Acc: 0.884615 | Val Loss: 0.108212, Val Acc: 0.783505\n",
      "Epoch 19356 - Train Loss: 0.080096, Train Acc: 0.884615 | Val Loss: 0.108211, Val Acc: 0.783505\n",
      "Epoch 19357 - Train Loss: 0.080094, Train Acc: 0.884615 | Val Loss: 0.108210, Val Acc: 0.783505\n",
      "Epoch 19358 - Train Loss: 0.080092, Train Acc: 0.884615 | Val Loss: 0.108209, Val Acc: 0.783505\n",
      "Epoch 19359 - Train Loss: 0.080089, Train Acc: 0.884615 | Val Loss: 0.108208, Val Acc: 0.783505\n",
      "Epoch 19360 - Train Loss: 0.080087, Train Acc: 0.884615 | Val Loss: 0.108207, Val Acc: 0.783505\n",
      "Epoch 19361 - Train Loss: 0.080085, Train Acc: 0.884615 | Val Loss: 0.108206, Val Acc: 0.783505\n",
      "Epoch 19362 - Train Loss: 0.080083, Train Acc: 0.884615 | Val Loss: 0.108205, Val Acc: 0.783505\n",
      "Epoch 19363 - Train Loss: 0.080080, Train Acc: 0.884615 | Val Loss: 0.108204, Val Acc: 0.783505\n",
      "Epoch 19364 - Train Loss: 0.080078, Train Acc: 0.884615 | Val Loss: 0.108203, Val Acc: 0.783505\n",
      "Epoch 19365 - Train Loss: 0.080076, Train Acc: 0.884615 | Val Loss: 0.108202, Val Acc: 0.783505\n",
      "Epoch 19366 - Train Loss: 0.080074, Train Acc: 0.884615 | Val Loss: 0.108201, Val Acc: 0.783505\n",
      "Epoch 19367 - Train Loss: 0.080071, Train Acc: 0.884615 | Val Loss: 0.108200, Val Acc: 0.783505\n",
      "Epoch 19368 - Train Loss: 0.080069, Train Acc: 0.884615 | Val Loss: 0.108199, Val Acc: 0.783505\n",
      "Epoch 19369 - Train Loss: 0.080067, Train Acc: 0.884615 | Val Loss: 0.108198, Val Acc: 0.783505\n",
      "Epoch 19370 - Train Loss: 0.080064, Train Acc: 0.884615 | Val Loss: 0.108197, Val Acc: 0.783505\n",
      "Epoch 19371 - Train Loss: 0.080062, Train Acc: 0.884615 | Val Loss: 0.108196, Val Acc: 0.783505\n",
      "Epoch 19372 - Train Loss: 0.080060, Train Acc: 0.884615 | Val Loss: 0.108195, Val Acc: 0.783505\n",
      "Epoch 19373 - Train Loss: 0.080058, Train Acc: 0.884615 | Val Loss: 0.108194, Val Acc: 0.783505\n",
      "Epoch 19374 - Train Loss: 0.080055, Train Acc: 0.884615 | Val Loss: 0.108193, Val Acc: 0.783505\n",
      "Epoch 19375 - Train Loss: 0.080053, Train Acc: 0.884615 | Val Loss: 0.108192, Val Acc: 0.783505\n",
      "Epoch 19376 - Train Loss: 0.080051, Train Acc: 0.884615 | Val Loss: 0.108191, Val Acc: 0.783505\n",
      "Epoch 19377 - Train Loss: 0.080049, Train Acc: 0.884615 | Val Loss: 0.108190, Val Acc: 0.783505\n",
      "Epoch 19378 - Train Loss: 0.080046, Train Acc: 0.884615 | Val Loss: 0.108189, Val Acc: 0.783505\n",
      "Epoch 19379 - Train Loss: 0.080044, Train Acc: 0.884615 | Val Loss: 0.108188, Val Acc: 0.783505\n",
      "Epoch 19380 - Train Loss: 0.080042, Train Acc: 0.884615 | Val Loss: 0.108187, Val Acc: 0.783505\n",
      "Epoch 19381 - Train Loss: 0.080039, Train Acc: 0.884615 | Val Loss: 0.108186, Val Acc: 0.783505\n",
      "Epoch 19382 - Train Loss: 0.080037, Train Acc: 0.884615 | Val Loss: 0.108185, Val Acc: 0.783505\n",
      "Epoch 19383 - Train Loss: 0.080035, Train Acc: 0.884615 | Val Loss: 0.108184, Val Acc: 0.783505\n",
      "Epoch 19384 - Train Loss: 0.080033, Train Acc: 0.884615 | Val Loss: 0.108183, Val Acc: 0.783505\n",
      "Epoch 19385 - Train Loss: 0.080030, Train Acc: 0.884615 | Val Loss: 0.108182, Val Acc: 0.783505\n",
      "Epoch 19386 - Train Loss: 0.080028, Train Acc: 0.884615 | Val Loss: 0.108181, Val Acc: 0.783505\n",
      "Epoch 19387 - Train Loss: 0.080026, Train Acc: 0.884615 | Val Loss: 0.108180, Val Acc: 0.783505\n",
      "Epoch 19388 - Train Loss: 0.080024, Train Acc: 0.884615 | Val Loss: 0.108178, Val Acc: 0.783505\n",
      "Epoch 19389 - Train Loss: 0.080021, Train Acc: 0.884615 | Val Loss: 0.108178, Val Acc: 0.783505\n",
      "Epoch 19390 - Train Loss: 0.080019, Train Acc: 0.884615 | Val Loss: 0.108176, Val Acc: 0.783505\n",
      "Epoch 19391 - Train Loss: 0.080017, Train Acc: 0.884615 | Val Loss: 0.108175, Val Acc: 0.783505\n",
      "Epoch 19392 - Train Loss: 0.080014, Train Acc: 0.884615 | Val Loss: 0.108174, Val Acc: 0.783505\n",
      "Epoch 19393 - Train Loss: 0.080012, Train Acc: 0.884615 | Val Loss: 0.108173, Val Acc: 0.783505\n",
      "Epoch 19394 - Train Loss: 0.080010, Train Acc: 0.884615 | Val Loss: 0.108172, Val Acc: 0.783505\n",
      "Epoch 19395 - Train Loss: 0.080008, Train Acc: 0.884615 | Val Loss: 0.108171, Val Acc: 0.783505\n",
      "Epoch 19396 - Train Loss: 0.080005, Train Acc: 0.884615 | Val Loss: 0.108170, Val Acc: 0.783505\n",
      "Epoch 19397 - Train Loss: 0.080003, Train Acc: 0.884615 | Val Loss: 0.108169, Val Acc: 0.783505\n",
      "Epoch 19398 - Train Loss: 0.080001, Train Acc: 0.884615 | Val Loss: 0.108168, Val Acc: 0.783505\n",
      "Epoch 19399 - Train Loss: 0.079999, Train Acc: 0.884615 | Val Loss: 0.108167, Val Acc: 0.783505\n",
      "Epoch 19400 - Train Loss: 0.079996, Train Acc: 0.884615 | Val Loss: 0.108166, Val Acc: 0.783505\n",
      "Epoch 19401 - Train Loss: 0.079994, Train Acc: 0.884615 | Val Loss: 0.108165, Val Acc: 0.783505\n",
      "Epoch 19402 - Train Loss: 0.079992, Train Acc: 0.884615 | Val Loss: 0.108164, Val Acc: 0.783505\n",
      "Epoch 19403 - Train Loss: 0.079990, Train Acc: 0.884615 | Val Loss: 0.108163, Val Acc: 0.783505\n",
      "Epoch 19404 - Train Loss: 0.079987, Train Acc: 0.884615 | Val Loss: 0.108162, Val Acc: 0.783505\n",
      "Epoch 19405 - Train Loss: 0.079985, Train Acc: 0.884615 | Val Loss: 0.108161, Val Acc: 0.783505\n",
      "Epoch 19406 - Train Loss: 0.079983, Train Acc: 0.884615 | Val Loss: 0.108160, Val Acc: 0.783505\n",
      "Epoch 19407 - Train Loss: 0.079980, Train Acc: 0.884615 | Val Loss: 0.108159, Val Acc: 0.783505\n",
      "Epoch 19408 - Train Loss: 0.079978, Train Acc: 0.884615 | Val Loss: 0.108158, Val Acc: 0.783505\n",
      "Epoch 19409 - Train Loss: 0.079976, Train Acc: 0.884615 | Val Loss: 0.108157, Val Acc: 0.783505\n",
      "Epoch 19410 - Train Loss: 0.079974, Train Acc: 0.884615 | Val Loss: 0.108156, Val Acc: 0.783505\n",
      "Epoch 19411 - Train Loss: 0.079971, Train Acc: 0.884615 | Val Loss: 0.108155, Val Acc: 0.783505\n",
      "Epoch 19412 - Train Loss: 0.079969, Train Acc: 0.884615 | Val Loss: 0.108154, Val Acc: 0.783505\n",
      "Epoch 19413 - Train Loss: 0.079967, Train Acc: 0.884615 | Val Loss: 0.108153, Val Acc: 0.783505\n",
      "Epoch 19414 - Train Loss: 0.079965, Train Acc: 0.884615 | Val Loss: 0.108152, Val Acc: 0.783505\n",
      "Epoch 19415 - Train Loss: 0.079962, Train Acc: 0.884615 | Val Loss: 0.108151, Val Acc: 0.783505\n",
      "Epoch 19416 - Train Loss: 0.079960, Train Acc: 0.884615 | Val Loss: 0.108150, Val Acc: 0.783505\n",
      "Epoch 19417 - Train Loss: 0.079958, Train Acc: 0.884615 | Val Loss: 0.108149, Val Acc: 0.783505\n",
      "Epoch 19418 - Train Loss: 0.079956, Train Acc: 0.884615 | Val Loss: 0.108148, Val Acc: 0.783505\n",
      "Epoch 19419 - Train Loss: 0.079953, Train Acc: 0.884615 | Val Loss: 0.108147, Val Acc: 0.783505\n",
      "Epoch 19420 - Train Loss: 0.079951, Train Acc: 0.884615 | Val Loss: 0.108146, Val Acc: 0.783505\n",
      "Epoch 19421 - Train Loss: 0.079949, Train Acc: 0.884615 | Val Loss: 0.108145, Val Acc: 0.783505\n",
      "Epoch 19422 - Train Loss: 0.079947, Train Acc: 0.884615 | Val Loss: 0.108144, Val Acc: 0.783505\n",
      "Epoch 19423 - Train Loss: 0.079944, Train Acc: 0.884615 | Val Loss: 0.108143, Val Acc: 0.783505\n",
      "Epoch 19424 - Train Loss: 0.079942, Train Acc: 0.884615 | Val Loss: 0.108142, Val Acc: 0.783505\n",
      "Epoch 19425 - Train Loss: 0.079940, Train Acc: 0.884615 | Val Loss: 0.108141, Val Acc: 0.783505\n",
      "Epoch 19426 - Train Loss: 0.079937, Train Acc: 0.884615 | Val Loss: 0.108140, Val Acc: 0.783505\n",
      "Epoch 19427 - Train Loss: 0.079935, Train Acc: 0.884615 | Val Loss: 0.108139, Val Acc: 0.783505\n",
      "Epoch 19428 - Train Loss: 0.079933, Train Acc: 0.884615 | Val Loss: 0.108138, Val Acc: 0.783505\n",
      "Epoch 19429 - Train Loss: 0.079931, Train Acc: 0.884615 | Val Loss: 0.108137, Val Acc: 0.783505\n",
      "Epoch 19430 - Train Loss: 0.079928, Train Acc: 0.884615 | Val Loss: 0.108136, Val Acc: 0.783505\n",
      "Epoch 19431 - Train Loss: 0.079926, Train Acc: 0.884615 | Val Loss: 0.108135, Val Acc: 0.783505\n",
      "Epoch 19432 - Train Loss: 0.079924, Train Acc: 0.884615 | Val Loss: 0.108134, Val Acc: 0.783505\n",
      "Epoch 19433 - Train Loss: 0.079922, Train Acc: 0.884615 | Val Loss: 0.108133, Val Acc: 0.783505\n",
      "Epoch 19434 - Train Loss: 0.079919, Train Acc: 0.884615 | Val Loss: 0.108132, Val Acc: 0.783505\n",
      "Epoch 19435 - Train Loss: 0.079917, Train Acc: 0.884615 | Val Loss: 0.108131, Val Acc: 0.783505\n",
      "Epoch 19436 - Train Loss: 0.079915, Train Acc: 0.884615 | Val Loss: 0.108130, Val Acc: 0.783505\n",
      "Epoch 19437 - Train Loss: 0.079913, Train Acc: 0.884615 | Val Loss: 0.108129, Val Acc: 0.783505\n",
      "Epoch 19438 - Train Loss: 0.079910, Train Acc: 0.884615 | Val Loss: 0.108128, Val Acc: 0.783505\n",
      "Epoch 19439 - Train Loss: 0.079908, Train Acc: 0.884615 | Val Loss: 0.108127, Val Acc: 0.783505\n",
      "Epoch 19440 - Train Loss: 0.079906, Train Acc: 0.884615 | Val Loss: 0.108126, Val Acc: 0.783505\n",
      "Epoch 19441 - Train Loss: 0.079904, Train Acc: 0.884615 | Val Loss: 0.108125, Val Acc: 0.783505\n",
      "Epoch 19442 - Train Loss: 0.079901, Train Acc: 0.884615 | Val Loss: 0.108124, Val Acc: 0.783505\n",
      "Epoch 19443 - Train Loss: 0.079899, Train Acc: 0.884615 | Val Loss: 0.108123, Val Acc: 0.783505\n",
      "Epoch 19444 - Train Loss: 0.079897, Train Acc: 0.884615 | Val Loss: 0.108122, Val Acc: 0.783505\n",
      "Epoch 19445 - Train Loss: 0.079895, Train Acc: 0.884615 | Val Loss: 0.108121, Val Acc: 0.783505\n",
      "Epoch 19446 - Train Loss: 0.079892, Train Acc: 0.884615 | Val Loss: 0.108120, Val Acc: 0.783505\n",
      "Epoch 19447 - Train Loss: 0.079890, Train Acc: 0.884615 | Val Loss: 0.108119, Val Acc: 0.783505\n",
      "Epoch 19448 - Train Loss: 0.079888, Train Acc: 0.884615 | Val Loss: 0.108118, Val Acc: 0.783505\n",
      "Epoch 19449 - Train Loss: 0.079886, Train Acc: 0.884615 | Val Loss: 0.108117, Val Acc: 0.783505\n",
      "Epoch 19450 - Train Loss: 0.079883, Train Acc: 0.884615 | Val Loss: 0.108116, Val Acc: 0.783505\n",
      "Epoch 19451 - Train Loss: 0.079881, Train Acc: 0.884615 | Val Loss: 0.108115, Val Acc: 0.783505\n",
      "Epoch 19452 - Train Loss: 0.079879, Train Acc: 0.884615 | Val Loss: 0.108114, Val Acc: 0.783505\n",
      "Epoch 19453 - Train Loss: 0.079877, Train Acc: 0.884615 | Val Loss: 0.108113, Val Acc: 0.783505\n",
      "Epoch 19454 - Train Loss: 0.079874, Train Acc: 0.884615 | Val Loss: 0.108112, Val Acc: 0.783505\n",
      "Epoch 19455 - Train Loss: 0.079872, Train Acc: 0.884615 | Val Loss: 0.108110, Val Acc: 0.783505\n",
      "Epoch 19456 - Train Loss: 0.079870, Train Acc: 0.884615 | Val Loss: 0.108110, Val Acc: 0.783505\n",
      "Epoch 19457 - Train Loss: 0.079868, Train Acc: 0.884615 | Val Loss: 0.108109, Val Acc: 0.783505\n",
      "Epoch 19458 - Train Loss: 0.079865, Train Acc: 0.884615 | Val Loss: 0.108107, Val Acc: 0.783505\n",
      "Epoch 19459 - Train Loss: 0.079863, Train Acc: 0.884615 | Val Loss: 0.108107, Val Acc: 0.783505\n",
      "Epoch 19460 - Train Loss: 0.079861, Train Acc: 0.884615 | Val Loss: 0.108105, Val Acc: 0.783505\n",
      "Epoch 19461 - Train Loss: 0.079859, Train Acc: 0.884615 | Val Loss: 0.108105, Val Acc: 0.783505\n",
      "Epoch 19462 - Train Loss: 0.079856, Train Acc: 0.884615 | Val Loss: 0.108104, Val Acc: 0.783505\n",
      "Epoch 19463 - Train Loss: 0.079854, Train Acc: 0.884615 | Val Loss: 0.108102, Val Acc: 0.783505\n",
      "Epoch 19464 - Train Loss: 0.079852, Train Acc: 0.884615 | Val Loss: 0.108102, Val Acc: 0.783505\n",
      "Epoch 19465 - Train Loss: 0.079850, Train Acc: 0.884615 | Val Loss: 0.108100, Val Acc: 0.783505\n",
      "Epoch 19466 - Train Loss: 0.079847, Train Acc: 0.884615 | Val Loss: 0.108099, Val Acc: 0.783505\n",
      "Epoch 19467 - Train Loss: 0.079845, Train Acc: 0.884615 | Val Loss: 0.108098, Val Acc: 0.783505\n",
      "Epoch 19468 - Train Loss: 0.079843, Train Acc: 0.884615 | Val Loss: 0.108097, Val Acc: 0.783505\n",
      "Epoch 19469 - Train Loss: 0.079841, Train Acc: 0.884615 | Val Loss: 0.108097, Val Acc: 0.783505\n",
      "Epoch 19470 - Train Loss: 0.079838, Train Acc: 0.884615 | Val Loss: 0.108095, Val Acc: 0.783505\n",
      "Epoch 19471 - Train Loss: 0.079836, Train Acc: 0.884615 | Val Loss: 0.108095, Val Acc: 0.783505\n",
      "Epoch 19472 - Train Loss: 0.079834, Train Acc: 0.884615 | Val Loss: 0.108093, Val Acc: 0.783505\n",
      "Epoch 19473 - Train Loss: 0.079832, Train Acc: 0.884615 | Val Loss: 0.108092, Val Acc: 0.783505\n",
      "Epoch 19474 - Train Loss: 0.079829, Train Acc: 0.884615 | Val Loss: 0.108091, Val Acc: 0.783505\n",
      "Epoch 19475 - Train Loss: 0.079827, Train Acc: 0.884615 | Val Loss: 0.108091, Val Acc: 0.783505\n",
      "Epoch 19476 - Train Loss: 0.079825, Train Acc: 0.884615 | Val Loss: 0.108089, Val Acc: 0.783505\n",
      "Epoch 19477 - Train Loss: 0.079823, Train Acc: 0.884615 | Val Loss: 0.108088, Val Acc: 0.783505\n",
      "Epoch 19478 - Train Loss: 0.079820, Train Acc: 0.884615 | Val Loss: 0.108087, Val Acc: 0.783505\n",
      "Epoch 19479 - Train Loss: 0.079818, Train Acc: 0.884615 | Val Loss: 0.108086, Val Acc: 0.783505\n",
      "Epoch 19480 - Train Loss: 0.079816, Train Acc: 0.884615 | Val Loss: 0.108085, Val Acc: 0.783505\n",
      "Epoch 19481 - Train Loss: 0.079814, Train Acc: 0.884615 | Val Loss: 0.108084, Val Acc: 0.783505\n",
      "Epoch 19482 - Train Loss: 0.079811, Train Acc: 0.884615 | Val Loss: 0.108083, Val Acc: 0.783505\n",
      "Epoch 19483 - Train Loss: 0.079809, Train Acc: 0.884615 | Val Loss: 0.108082, Val Acc: 0.783505\n",
      "Epoch 19484 - Train Loss: 0.079807, Train Acc: 0.884615 | Val Loss: 0.108081, Val Acc: 0.783505\n",
      "Epoch 19485 - Train Loss: 0.079805, Train Acc: 0.884615 | Val Loss: 0.108080, Val Acc: 0.783505\n",
      "Epoch 19486 - Train Loss: 0.079802, Train Acc: 0.884615 | Val Loss: 0.108079, Val Acc: 0.783505\n",
      "Epoch 19487 - Train Loss: 0.079800, Train Acc: 0.884615 | Val Loss: 0.108078, Val Acc: 0.783505\n",
      "Epoch 19488 - Train Loss: 0.079798, Train Acc: 0.884615 | Val Loss: 0.108077, Val Acc: 0.783505\n",
      "Epoch 19489 - Train Loss: 0.079796, Train Acc: 0.884615 | Val Loss: 0.108076, Val Acc: 0.783505\n",
      "Epoch 19490 - Train Loss: 0.079793, Train Acc: 0.884615 | Val Loss: 0.108075, Val Acc: 0.783505\n",
      "Epoch 19491 - Train Loss: 0.079791, Train Acc: 0.884615 | Val Loss: 0.108074, Val Acc: 0.783505\n",
      "Epoch 19492 - Train Loss: 0.079789, Train Acc: 0.884615 | Val Loss: 0.108073, Val Acc: 0.783505\n",
      "Epoch 19493 - Train Loss: 0.079787, Train Acc: 0.884615 | Val Loss: 0.108072, Val Acc: 0.783505\n",
      "Epoch 19494 - Train Loss: 0.079784, Train Acc: 0.884615 | Val Loss: 0.108071, Val Acc: 0.783505\n",
      "Epoch 19495 - Train Loss: 0.079782, Train Acc: 0.884615 | Val Loss: 0.108070, Val Acc: 0.783505\n",
      "Epoch 19496 - Train Loss: 0.079780, Train Acc: 0.884615 | Val Loss: 0.108069, Val Acc: 0.783505\n",
      "Epoch 19497 - Train Loss: 0.079778, Train Acc: 0.884615 | Val Loss: 0.108068, Val Acc: 0.783505\n",
      "Epoch 19498 - Train Loss: 0.079775, Train Acc: 0.884615 | Val Loss: 0.108067, Val Acc: 0.783505\n",
      "Epoch 19499 - Train Loss: 0.079773, Train Acc: 0.884615 | Val Loss: 0.108066, Val Acc: 0.783505\n",
      "Epoch 19500 - Train Loss: 0.079771, Train Acc: 0.884615 | Val Loss: 0.108065, Val Acc: 0.783505\n",
      "Epoch 19501 - Train Loss: 0.079769, Train Acc: 0.884615 | Val Loss: 0.108064, Val Acc: 0.783505\n",
      "Epoch 19502 - Train Loss: 0.079766, Train Acc: 0.884615 | Val Loss: 0.108064, Val Acc: 0.783505\n",
      "Epoch 19503 - Train Loss: 0.079764, Train Acc: 0.884615 | Val Loss: 0.108063, Val Acc: 0.783505\n",
      "Epoch 19504 - Train Loss: 0.079762, Train Acc: 0.884615 | Val Loss: 0.108061, Val Acc: 0.783505\n",
      "Epoch 19505 - Train Loss: 0.079760, Train Acc: 0.884615 | Val Loss: 0.108060, Val Acc: 0.783505\n",
      "Epoch 19506 - Train Loss: 0.079757, Train Acc: 0.884615 | Val Loss: 0.108059, Val Acc: 0.783505\n",
      "Epoch 19507 - Train Loss: 0.079755, Train Acc: 0.884615 | Val Loss: 0.108059, Val Acc: 0.783505\n",
      "Epoch 19508 - Train Loss: 0.079753, Train Acc: 0.884615 | Val Loss: 0.108057, Val Acc: 0.783505\n",
      "Epoch 19509 - Train Loss: 0.079751, Train Acc: 0.884615 | Val Loss: 0.108056, Val Acc: 0.783505\n",
      "Epoch 19510 - Train Loss: 0.079748, Train Acc: 0.884615 | Val Loss: 0.108056, Val Acc: 0.783505\n",
      "Epoch 19511 - Train Loss: 0.079746, Train Acc: 0.884615 | Val Loss: 0.108054, Val Acc: 0.783505\n",
      "Epoch 19512 - Train Loss: 0.079744, Train Acc: 0.884615 | Val Loss: 0.108054, Val Acc: 0.783505\n",
      "Epoch 19513 - Train Loss: 0.079742, Train Acc: 0.884615 | Val Loss: 0.108053, Val Acc: 0.783505\n",
      "Epoch 19514 - Train Loss: 0.079740, Train Acc: 0.884615 | Val Loss: 0.108052, Val Acc: 0.783505\n",
      "Epoch 19515 - Train Loss: 0.079737, Train Acc: 0.884615 | Val Loss: 0.108051, Val Acc: 0.783505\n",
      "Epoch 19516 - Train Loss: 0.079735, Train Acc: 0.884615 | Val Loss: 0.108050, Val Acc: 0.783505\n",
      "Epoch 19517 - Train Loss: 0.079733, Train Acc: 0.884615 | Val Loss: 0.108048, Val Acc: 0.783505\n",
      "Epoch 19518 - Train Loss: 0.079731, Train Acc: 0.884615 | Val Loss: 0.108048, Val Acc: 0.783505\n",
      "Epoch 19519 - Train Loss: 0.079728, Train Acc: 0.884615 | Val Loss: 0.108047, Val Acc: 0.783505\n",
      "Epoch 19520 - Train Loss: 0.079726, Train Acc: 0.884615 | Val Loss: 0.108046, Val Acc: 0.783505\n",
      "Epoch 19521 - Train Loss: 0.079724, Train Acc: 0.884615 | Val Loss: 0.108045, Val Acc: 0.783505\n",
      "Epoch 19522 - Train Loss: 0.079722, Train Acc: 0.884615 | Val Loss: 0.108044, Val Acc: 0.783505\n",
      "Epoch 19523 - Train Loss: 0.079719, Train Acc: 0.884615 | Val Loss: 0.108043, Val Acc: 0.783505\n",
      "Epoch 19524 - Train Loss: 0.079717, Train Acc: 0.884615 | Val Loss: 0.108042, Val Acc: 0.783505\n",
      "Epoch 19525 - Train Loss: 0.079715, Train Acc: 0.884615 | Val Loss: 0.108041, Val Acc: 0.783505\n",
      "Epoch 19526 - Train Loss: 0.079713, Train Acc: 0.884615 | Val Loss: 0.108040, Val Acc: 0.783505\n",
      "Epoch 19527 - Train Loss: 0.079710, Train Acc: 0.884615 | Val Loss: 0.108039, Val Acc: 0.783505\n",
      "Epoch 19528 - Train Loss: 0.079708, Train Acc: 0.884615 | Val Loss: 0.108038, Val Acc: 0.783505\n",
      "Epoch 19529 - Train Loss: 0.079706, Train Acc: 0.884615 | Val Loss: 0.108037, Val Acc: 0.783505\n",
      "Epoch 19530 - Train Loss: 0.079704, Train Acc: 0.884615 | Val Loss: 0.108036, Val Acc: 0.783505\n",
      "Epoch 19531 - Train Loss: 0.079701, Train Acc: 0.884615 | Val Loss: 0.108035, Val Acc: 0.783505\n",
      "Epoch 19532 - Train Loss: 0.079699, Train Acc: 0.884615 | Val Loss: 0.108034, Val Acc: 0.783505\n",
      "Epoch 19533 - Train Loss: 0.079697, Train Acc: 0.884615 | Val Loss: 0.108033, Val Acc: 0.783505\n",
      "Epoch 19534 - Train Loss: 0.079695, Train Acc: 0.884615 | Val Loss: 0.108032, Val Acc: 0.783505\n",
      "Epoch 19535 - Train Loss: 0.079693, Train Acc: 0.884615 | Val Loss: 0.108031, Val Acc: 0.783505\n",
      "Epoch 19536 - Train Loss: 0.079690, Train Acc: 0.884615 | Val Loss: 0.108030, Val Acc: 0.783505\n",
      "Epoch 19537 - Train Loss: 0.079688, Train Acc: 0.884615 | Val Loss: 0.108029, Val Acc: 0.783505\n",
      "Epoch 19538 - Train Loss: 0.079686, Train Acc: 0.884615 | Val Loss: 0.108028, Val Acc: 0.783505\n",
      "Epoch 19539 - Train Loss: 0.079684, Train Acc: 0.884615 | Val Loss: 0.108027, Val Acc: 0.783505\n",
      "Epoch 19540 - Train Loss: 0.079681, Train Acc: 0.884615 | Val Loss: 0.108026, Val Acc: 0.783505\n",
      "Epoch 19541 - Train Loss: 0.079679, Train Acc: 0.884615 | Val Loss: 0.108025, Val Acc: 0.783505\n",
      "Epoch 19542 - Train Loss: 0.079677, Train Acc: 0.884615 | Val Loss: 0.108024, Val Acc: 0.783505\n",
      "Epoch 19543 - Train Loss: 0.079675, Train Acc: 0.884615 | Val Loss: 0.108023, Val Acc: 0.783505\n",
      "Epoch 19544 - Train Loss: 0.079672, Train Acc: 0.884615 | Val Loss: 0.108022, Val Acc: 0.783505\n",
      "Epoch 19545 - Train Loss: 0.079670, Train Acc: 0.884615 | Val Loss: 0.108021, Val Acc: 0.783505\n",
      "Epoch 19546 - Train Loss: 0.079668, Train Acc: 0.884615 | Val Loss: 0.108020, Val Acc: 0.783505\n",
      "Epoch 19547 - Train Loss: 0.079666, Train Acc: 0.884615 | Val Loss: 0.108019, Val Acc: 0.783505\n",
      "Epoch 19548 - Train Loss: 0.079663, Train Acc: 0.884615 | Val Loss: 0.108018, Val Acc: 0.783505\n",
      "Epoch 19549 - Train Loss: 0.079661, Train Acc: 0.884615 | Val Loss: 0.108017, Val Acc: 0.783505\n",
      "Epoch 19550 - Train Loss: 0.079659, Train Acc: 0.884615 | Val Loss: 0.108016, Val Acc: 0.783505\n",
      "Epoch 19551 - Train Loss: 0.079657, Train Acc: 0.884615 | Val Loss: 0.108015, Val Acc: 0.783505\n",
      "Epoch 19552 - Train Loss: 0.079655, Train Acc: 0.884615 | Val Loss: 0.108014, Val Acc: 0.783505\n",
      "Epoch 19553 - Train Loss: 0.079652, Train Acc: 0.884615 | Val Loss: 0.108013, Val Acc: 0.783505\n",
      "Epoch 19554 - Train Loss: 0.079650, Train Acc: 0.884615 | Val Loss: 0.108012, Val Acc: 0.783505\n",
      "Epoch 19555 - Train Loss: 0.079648, Train Acc: 0.884615 | Val Loss: 0.108011, Val Acc: 0.783505\n",
      "Epoch 19556 - Train Loss: 0.079646, Train Acc: 0.884615 | Val Loss: 0.108010, Val Acc: 0.783505\n",
      "Epoch 19557 - Train Loss: 0.079643, Train Acc: 0.884615 | Val Loss: 0.108009, Val Acc: 0.783505\n",
      "Epoch 19558 - Train Loss: 0.079641, Train Acc: 0.884615 | Val Loss: 0.108008, Val Acc: 0.783505\n",
      "Epoch 19559 - Train Loss: 0.079639, Train Acc: 0.884615 | Val Loss: 0.108007, Val Acc: 0.783505\n",
      "Epoch 19560 - Train Loss: 0.079637, Train Acc: 0.884615 | Val Loss: 0.108006, Val Acc: 0.783505\n",
      "Epoch 19561 - Train Loss: 0.079634, Train Acc: 0.884615 | Val Loss: 0.108005, Val Acc: 0.783505\n",
      "Epoch 19562 - Train Loss: 0.079632, Train Acc: 0.884615 | Val Loss: 0.108004, Val Acc: 0.783505\n",
      "Epoch 19563 - Train Loss: 0.079630, Train Acc: 0.884615 | Val Loss: 0.108003, Val Acc: 0.783505\n",
      "Epoch 19564 - Train Loss: 0.079628, Train Acc: 0.884615 | Val Loss: 0.108002, Val Acc: 0.783505\n",
      "Epoch 19565 - Train Loss: 0.079626, Train Acc: 0.884615 | Val Loss: 0.108001, Val Acc: 0.783505\n",
      "Epoch 19566 - Train Loss: 0.079623, Train Acc: 0.884615 | Val Loss: 0.108000, Val Acc: 0.783505\n",
      "Epoch 19567 - Train Loss: 0.079621, Train Acc: 0.884615 | Val Loss: 0.107999, Val Acc: 0.783505\n",
      "Epoch 19568 - Train Loss: 0.079619, Train Acc: 0.884615 | Val Loss: 0.107998, Val Acc: 0.783505\n",
      "Epoch 19569 - Train Loss: 0.079617, Train Acc: 0.884615 | Val Loss: 0.107997, Val Acc: 0.783505\n",
      "Epoch 19570 - Train Loss: 0.079614, Train Acc: 0.884615 | Val Loss: 0.107996, Val Acc: 0.783505\n",
      "Epoch 19571 - Train Loss: 0.079612, Train Acc: 0.884615 | Val Loss: 0.107995, Val Acc: 0.783505\n",
      "Epoch 19572 - Train Loss: 0.079610, Train Acc: 0.884615 | Val Loss: 0.107994, Val Acc: 0.783505\n",
      "Epoch 19573 - Train Loss: 0.079608, Train Acc: 0.884615 | Val Loss: 0.107993, Val Acc: 0.783505\n",
      "Epoch 19574 - Train Loss: 0.079606, Train Acc: 0.884615 | Val Loss: 0.107992, Val Acc: 0.783505\n",
      "Epoch 19575 - Train Loss: 0.079603, Train Acc: 0.884615 | Val Loss: 0.107991, Val Acc: 0.783505\n",
      "Epoch 19576 - Train Loss: 0.079601, Train Acc: 0.884615 | Val Loss: 0.107990, Val Acc: 0.783505\n",
      "Epoch 19577 - Train Loss: 0.079599, Train Acc: 0.884615 | Val Loss: 0.107989, Val Acc: 0.783505\n",
      "Epoch 19578 - Train Loss: 0.079597, Train Acc: 0.884615 | Val Loss: 0.107988, Val Acc: 0.783505\n",
      "Epoch 19579 - Train Loss: 0.079594, Train Acc: 0.884615 | Val Loss: 0.107987, Val Acc: 0.783505\n",
      "Epoch 19580 - Train Loss: 0.079592, Train Acc: 0.884615 | Val Loss: 0.107986, Val Acc: 0.783505\n",
      "Epoch 19581 - Train Loss: 0.079590, Train Acc: 0.884615 | Val Loss: 0.107985, Val Acc: 0.783505\n",
      "Epoch 19582 - Train Loss: 0.079588, Train Acc: 0.884615 | Val Loss: 0.107985, Val Acc: 0.783505\n",
      "Epoch 19583 - Train Loss: 0.079586, Train Acc: 0.884615 | Val Loss: 0.107983, Val Acc: 0.783505\n",
      "Epoch 19584 - Train Loss: 0.079583, Train Acc: 0.884615 | Val Loss: 0.107983, Val Acc: 0.783505\n",
      "Epoch 19585 - Train Loss: 0.079581, Train Acc: 0.884615 | Val Loss: 0.107982, Val Acc: 0.783505\n",
      "Epoch 19586 - Train Loss: 0.079579, Train Acc: 0.884615 | Val Loss: 0.107981, Val Acc: 0.783505\n",
      "Epoch 19587 - Train Loss: 0.079577, Train Acc: 0.884615 | Val Loss: 0.107980, Val Acc: 0.783505\n",
      "Epoch 19588 - Train Loss: 0.079574, Train Acc: 0.884615 | Val Loss: 0.107979, Val Acc: 0.783505\n",
      "Epoch 19589 - Train Loss: 0.079572, Train Acc: 0.884615 | Val Loss: 0.107978, Val Acc: 0.783505\n",
      "Epoch 19590 - Train Loss: 0.079570, Train Acc: 0.884615 | Val Loss: 0.107977, Val Acc: 0.783505\n",
      "Epoch 19591 - Train Loss: 0.079568, Train Acc: 0.884615 | Val Loss: 0.107976, Val Acc: 0.783505\n",
      "Epoch 19592 - Train Loss: 0.079566, Train Acc: 0.884615 | Val Loss: 0.107975, Val Acc: 0.783505\n",
      "Epoch 19593 - Train Loss: 0.079563, Train Acc: 0.884615 | Val Loss: 0.107974, Val Acc: 0.783505\n",
      "Epoch 19594 - Train Loss: 0.079561, Train Acc: 0.884615 | Val Loss: 0.107973, Val Acc: 0.783505\n",
      "Epoch 19595 - Train Loss: 0.079559, Train Acc: 0.884615 | Val Loss: 0.107972, Val Acc: 0.783505\n",
      "Epoch 19596 - Train Loss: 0.079557, Train Acc: 0.884615 | Val Loss: 0.107971, Val Acc: 0.783505\n",
      "Epoch 19597 - Train Loss: 0.079554, Train Acc: 0.884615 | Val Loss: 0.107970, Val Acc: 0.783505\n",
      "Epoch 19598 - Train Loss: 0.079552, Train Acc: 0.884615 | Val Loss: 0.107969, Val Acc: 0.783505\n",
      "Epoch 19599 - Train Loss: 0.079550, Train Acc: 0.884615 | Val Loss: 0.107968, Val Acc: 0.783505\n",
      "Epoch 19600 - Train Loss: 0.079548, Train Acc: 0.884615 | Val Loss: 0.107967, Val Acc: 0.783505\n",
      "Epoch 19601 - Train Loss: 0.079546, Train Acc: 0.884615 | Val Loss: 0.107966, Val Acc: 0.783505\n",
      "Epoch 19602 - Train Loss: 0.079543, Train Acc: 0.884615 | Val Loss: 0.107965, Val Acc: 0.783505\n",
      "Epoch 19603 - Train Loss: 0.079541, Train Acc: 0.884615 | Val Loss: 0.107964, Val Acc: 0.783505\n",
      "Epoch 19604 - Train Loss: 0.079539, Train Acc: 0.884615 | Val Loss: 0.107963, Val Acc: 0.783505\n",
      "Epoch 19605 - Train Loss: 0.079537, Train Acc: 0.884615 | Val Loss: 0.107962, Val Acc: 0.783505\n",
      "Epoch 19606 - Train Loss: 0.079534, Train Acc: 0.884615 | Val Loss: 0.107961, Val Acc: 0.783505\n",
      "Epoch 19607 - Train Loss: 0.079532, Train Acc: 0.884615 | Val Loss: 0.107960, Val Acc: 0.783505\n",
      "Epoch 19608 - Train Loss: 0.079530, Train Acc: 0.884615 | Val Loss: 0.107959, Val Acc: 0.783505\n",
      "Epoch 19609 - Train Loss: 0.079528, Train Acc: 0.884615 | Val Loss: 0.107958, Val Acc: 0.783505\n",
      "Epoch 19610 - Train Loss: 0.079526, Train Acc: 0.884615 | Val Loss: 0.107957, Val Acc: 0.783505\n",
      "Epoch 19611 - Train Loss: 0.079523, Train Acc: 0.884615 | Val Loss: 0.107956, Val Acc: 0.783505\n",
      "Epoch 19612 - Train Loss: 0.079521, Train Acc: 0.884615 | Val Loss: 0.107955, Val Acc: 0.783505\n",
      "Epoch 19613 - Train Loss: 0.079519, Train Acc: 0.884615 | Val Loss: 0.107954, Val Acc: 0.783505\n",
      "Epoch 19614 - Train Loss: 0.079517, Train Acc: 0.884615 | Val Loss: 0.107953, Val Acc: 0.783505\n",
      "Epoch 19615 - Train Loss: 0.079514, Train Acc: 0.884615 | Val Loss: 0.107952, Val Acc: 0.783505\n",
      "Epoch 19616 - Train Loss: 0.079512, Train Acc: 0.884615 | Val Loss: 0.107951, Val Acc: 0.783505\n",
      "Epoch 19617 - Train Loss: 0.079510, Train Acc: 0.884615 | Val Loss: 0.107950, Val Acc: 0.783505\n",
      "Epoch 19618 - Train Loss: 0.079508, Train Acc: 0.884615 | Val Loss: 0.107949, Val Acc: 0.783505\n",
      "Epoch 19619 - Train Loss: 0.079506, Train Acc: 0.884615 | Val Loss: 0.107948, Val Acc: 0.783505\n",
      "Epoch 19620 - Train Loss: 0.079503, Train Acc: 0.884615 | Val Loss: 0.107947, Val Acc: 0.783505\n",
      "Epoch 19621 - Train Loss: 0.079501, Train Acc: 0.884615 | Val Loss: 0.107946, Val Acc: 0.783505\n",
      "Epoch 19622 - Train Loss: 0.079499, Train Acc: 0.884615 | Val Loss: 0.107946, Val Acc: 0.783505\n",
      "Epoch 19623 - Train Loss: 0.079497, Train Acc: 0.884615 | Val Loss: 0.107945, Val Acc: 0.783505\n",
      "Epoch 19624 - Train Loss: 0.079495, Train Acc: 0.884615 | Val Loss: 0.107944, Val Acc: 0.783505\n",
      "Epoch 19625 - Train Loss: 0.079492, Train Acc: 0.884615 | Val Loss: 0.107943, Val Acc: 0.783505\n",
      "Epoch 19626 - Train Loss: 0.079490, Train Acc: 0.884615 | Val Loss: 0.107942, Val Acc: 0.783505\n",
      "Epoch 19627 - Train Loss: 0.079488, Train Acc: 0.884615 | Val Loss: 0.107941, Val Acc: 0.783505\n",
      "Epoch 19628 - Train Loss: 0.079486, Train Acc: 0.884615 | Val Loss: 0.107940, Val Acc: 0.783505\n",
      "Epoch 19629 - Train Loss: 0.079483, Train Acc: 0.884615 | Val Loss: 0.107939, Val Acc: 0.783505\n",
      "Epoch 19630 - Train Loss: 0.079481, Train Acc: 0.884615 | Val Loss: 0.107938, Val Acc: 0.783505\n",
      "Epoch 19631 - Train Loss: 0.079479, Train Acc: 0.884615 | Val Loss: 0.107937, Val Acc: 0.783505\n",
      "Epoch 19632 - Train Loss: 0.079477, Train Acc: 0.884615 | Val Loss: 0.107936, Val Acc: 0.783505\n",
      "Epoch 19633 - Train Loss: 0.079475, Train Acc: 0.884615 | Val Loss: 0.107935, Val Acc: 0.783505\n",
      "Epoch 19634 - Train Loss: 0.079472, Train Acc: 0.884615 | Val Loss: 0.107934, Val Acc: 0.783505\n",
      "Epoch 19635 - Train Loss: 0.079470, Train Acc: 0.884615 | Val Loss: 0.107933, Val Acc: 0.783505\n",
      "Epoch 19636 - Train Loss: 0.079468, Train Acc: 0.884615 | Val Loss: 0.107932, Val Acc: 0.783505\n",
      "Epoch 19637 - Train Loss: 0.079466, Train Acc: 0.884615 | Val Loss: 0.107931, Val Acc: 0.783505\n",
      "Epoch 19638 - Train Loss: 0.079464, Train Acc: 0.884615 | Val Loss: 0.107930, Val Acc: 0.783505\n",
      "Epoch 19639 - Train Loss: 0.079461, Train Acc: 0.884615 | Val Loss: 0.107929, Val Acc: 0.783505\n",
      "Epoch 19640 - Train Loss: 0.079459, Train Acc: 0.884615 | Val Loss: 0.107928, Val Acc: 0.783505\n",
      "Epoch 19641 - Train Loss: 0.079457, Train Acc: 0.884615 | Val Loss: 0.107927, Val Acc: 0.783505\n",
      "Epoch 19642 - Train Loss: 0.079455, Train Acc: 0.884615 | Val Loss: 0.107926, Val Acc: 0.783505\n",
      "Epoch 19643 - Train Loss: 0.079452, Train Acc: 0.884615 | Val Loss: 0.107925, Val Acc: 0.783505\n",
      "Epoch 19644 - Train Loss: 0.079450, Train Acc: 0.884615 | Val Loss: 0.107924, Val Acc: 0.783505\n",
      "Epoch 19645 - Train Loss: 0.079448, Train Acc: 0.884615 | Val Loss: 0.107923, Val Acc: 0.783505\n",
      "Epoch 19646 - Train Loss: 0.079446, Train Acc: 0.884615 | Val Loss: 0.107922, Val Acc: 0.783505\n",
      "Epoch 19647 - Train Loss: 0.079444, Train Acc: 0.884615 | Val Loss: 0.107921, Val Acc: 0.783505\n",
      "Epoch 19648 - Train Loss: 0.079441, Train Acc: 0.884615 | Val Loss: 0.107920, Val Acc: 0.783505\n",
      "Epoch 19649 - Train Loss: 0.079439, Train Acc: 0.884615 | Val Loss: 0.107919, Val Acc: 0.783505\n",
      "Epoch 19650 - Train Loss: 0.079437, Train Acc: 0.884615 | Val Loss: 0.107918, Val Acc: 0.783505\n",
      "Epoch 19651 - Train Loss: 0.079435, Train Acc: 0.884615 | Val Loss: 0.107918, Val Acc: 0.783505\n",
      "Epoch 19652 - Train Loss: 0.079433, Train Acc: 0.884615 | Val Loss: 0.107917, Val Acc: 0.783505\n",
      "Epoch 19653 - Train Loss: 0.079430, Train Acc: 0.884615 | Val Loss: 0.107916, Val Acc: 0.783505\n",
      "Epoch 19654 - Train Loss: 0.079428, Train Acc: 0.884615 | Val Loss: 0.107915, Val Acc: 0.783505\n",
      "Epoch 19655 - Train Loss: 0.079426, Train Acc: 0.884615 | Val Loss: 0.107914, Val Acc: 0.783505\n",
      "Epoch 19656 - Train Loss: 0.079424, Train Acc: 0.884615 | Val Loss: 0.107913, Val Acc: 0.783505\n",
      "Epoch 19657 - Train Loss: 0.079422, Train Acc: 0.884615 | Val Loss: 0.107912, Val Acc: 0.783505\n",
      "Epoch 19658 - Train Loss: 0.079419, Train Acc: 0.884615 | Val Loss: 0.107911, Val Acc: 0.783505\n",
      "Epoch 19659 - Train Loss: 0.079417, Train Acc: 0.884615 | Val Loss: 0.107910, Val Acc: 0.783505\n",
      "Epoch 19660 - Train Loss: 0.079415, Train Acc: 0.884615 | Val Loss: 0.107909, Val Acc: 0.783505\n",
      "Epoch 19661 - Train Loss: 0.079413, Train Acc: 0.884615 | Val Loss: 0.107908, Val Acc: 0.783505\n",
      "Epoch 19662 - Train Loss: 0.079411, Train Acc: 0.884615 | Val Loss: 0.107907, Val Acc: 0.783505\n",
      "Epoch 19663 - Train Loss: 0.079408, Train Acc: 0.884615 | Val Loss: 0.107906, Val Acc: 0.783505\n",
      "Epoch 19664 - Train Loss: 0.079406, Train Acc: 0.884615 | Val Loss: 0.107905, Val Acc: 0.783505\n",
      "Epoch 19665 - Train Loss: 0.079404, Train Acc: 0.884615 | Val Loss: 0.107904, Val Acc: 0.783505\n",
      "Epoch 19666 - Train Loss: 0.079402, Train Acc: 0.884615 | Val Loss: 0.107903, Val Acc: 0.783505\n",
      "Epoch 19667 - Train Loss: 0.079400, Train Acc: 0.884615 | Val Loss: 0.107902, Val Acc: 0.783505\n",
      "Epoch 19668 - Train Loss: 0.079397, Train Acc: 0.884615 | Val Loss: 0.107901, Val Acc: 0.783505\n",
      "Epoch 19669 - Train Loss: 0.079395, Train Acc: 0.884615 | Val Loss: 0.107900, Val Acc: 0.783505\n",
      "Epoch 19670 - Train Loss: 0.079393, Train Acc: 0.884615 | Val Loss: 0.107899, Val Acc: 0.783505\n",
      "Epoch 19671 - Train Loss: 0.079391, Train Acc: 0.884615 | Val Loss: 0.107898, Val Acc: 0.783505\n",
      "Epoch 19672 - Train Loss: 0.079388, Train Acc: 0.884615 | Val Loss: 0.107897, Val Acc: 0.783505\n",
      "Epoch 19673 - Train Loss: 0.079386, Train Acc: 0.884615 | Val Loss: 0.107896, Val Acc: 0.783505\n",
      "Epoch 19674 - Train Loss: 0.079384, Train Acc: 0.884615 | Val Loss: 0.107895, Val Acc: 0.783505\n",
      "Epoch 19675 - Train Loss: 0.079382, Train Acc: 0.884615 | Val Loss: 0.107894, Val Acc: 0.783505\n",
      "Epoch 19676 - Train Loss: 0.079380, Train Acc: 0.884615 | Val Loss: 0.107894, Val Acc: 0.783505\n",
      "Epoch 19677 - Train Loss: 0.079377, Train Acc: 0.884615 | Val Loss: 0.107893, Val Acc: 0.783505\n",
      "Epoch 19678 - Train Loss: 0.079375, Train Acc: 0.884615 | Val Loss: 0.107892, Val Acc: 0.783505\n",
      "Epoch 19679 - Train Loss: 0.079373, Train Acc: 0.884615 | Val Loss: 0.107891, Val Acc: 0.783505\n",
      "Epoch 19680 - Train Loss: 0.079371, Train Acc: 0.884615 | Val Loss: 0.107890, Val Acc: 0.783505\n",
      "Epoch 19681 - Train Loss: 0.079369, Train Acc: 0.884615 | Val Loss: 0.107889, Val Acc: 0.783505\n",
      "Epoch 19682 - Train Loss: 0.079366, Train Acc: 0.884615 | Val Loss: 0.107888, Val Acc: 0.783505\n",
      "Epoch 19683 - Train Loss: 0.079364, Train Acc: 0.884615 | Val Loss: 0.107887, Val Acc: 0.783505\n",
      "Epoch 19684 - Train Loss: 0.079362, Train Acc: 0.884615 | Val Loss: 0.107886, Val Acc: 0.783505\n",
      "Epoch 19685 - Train Loss: 0.079360, Train Acc: 0.884615 | Val Loss: 0.107885, Val Acc: 0.783505\n",
      "Epoch 19686 - Train Loss: 0.079358, Train Acc: 0.884615 | Val Loss: 0.107884, Val Acc: 0.783505\n",
      "Epoch 19687 - Train Loss: 0.079355, Train Acc: 0.884615 | Val Loss: 0.107883, Val Acc: 0.783505\n",
      "Epoch 19688 - Train Loss: 0.079353, Train Acc: 0.884615 | Val Loss: 0.107882, Val Acc: 0.783505\n",
      "Epoch 19689 - Train Loss: 0.079351, Train Acc: 0.884615 | Val Loss: 0.107881, Val Acc: 0.783505\n",
      "Epoch 19690 - Train Loss: 0.079349, Train Acc: 0.884615 | Val Loss: 0.107880, Val Acc: 0.783505\n",
      "Epoch 19691 - Train Loss: 0.079347, Train Acc: 0.884615 | Val Loss: 0.107879, Val Acc: 0.783505\n",
      "Epoch 19692 - Train Loss: 0.079344, Train Acc: 0.884615 | Val Loss: 0.107878, Val Acc: 0.783505\n",
      "Epoch 19693 - Train Loss: 0.079342, Train Acc: 0.884615 | Val Loss: 0.107877, Val Acc: 0.783505\n",
      "Epoch 19694 - Train Loss: 0.079340, Train Acc: 0.884615 | Val Loss: 0.107876, Val Acc: 0.783505\n",
      "Epoch 19695 - Train Loss: 0.079338, Train Acc: 0.884615 | Val Loss: 0.107875, Val Acc: 0.783505\n",
      "Epoch 19696 - Train Loss: 0.079336, Train Acc: 0.884615 | Val Loss: 0.107874, Val Acc: 0.783505\n",
      "Epoch 19697 - Train Loss: 0.079333, Train Acc: 0.884615 | Val Loss: 0.107873, Val Acc: 0.783505\n",
      "Epoch 19698 - Train Loss: 0.079331, Train Acc: 0.884615 | Val Loss: 0.107872, Val Acc: 0.783505\n",
      "Epoch 19699 - Train Loss: 0.079329, Train Acc: 0.884615 | Val Loss: 0.107872, Val Acc: 0.783505\n",
      "Epoch 19700 - Train Loss: 0.079327, Train Acc: 0.884615 | Val Loss: 0.107871, Val Acc: 0.783505\n",
      "Epoch 19701 - Train Loss: 0.079325, Train Acc: 0.884615 | Val Loss: 0.107870, Val Acc: 0.783505\n",
      "Epoch 19702 - Train Loss: 0.079322, Train Acc: 0.884615 | Val Loss: 0.107869, Val Acc: 0.783505\n",
      "Epoch 19703 - Train Loss: 0.079320, Train Acc: 0.884615 | Val Loss: 0.107868, Val Acc: 0.783505\n",
      "Epoch 19704 - Train Loss: 0.079318, Train Acc: 0.884615 | Val Loss: 0.107867, Val Acc: 0.783505\n",
      "Epoch 19705 - Train Loss: 0.079316, Train Acc: 0.884615 | Val Loss: 0.107866, Val Acc: 0.783505\n",
      "Epoch 19706 - Train Loss: 0.079314, Train Acc: 0.884615 | Val Loss: 0.107865, Val Acc: 0.783505\n",
      "Epoch 19707 - Train Loss: 0.079312, Train Acc: 0.884615 | Val Loss: 0.107864, Val Acc: 0.783505\n",
      "Epoch 19708 - Train Loss: 0.079309, Train Acc: 0.884615 | Val Loss: 0.107863, Val Acc: 0.783505\n",
      "Epoch 19709 - Train Loss: 0.079307, Train Acc: 0.884615 | Val Loss: 0.107862, Val Acc: 0.783505\n",
      "Epoch 19710 - Train Loss: 0.079305, Train Acc: 0.884615 | Val Loss: 0.107861, Val Acc: 0.783505\n",
      "Epoch 19711 - Train Loss: 0.079303, Train Acc: 0.884615 | Val Loss: 0.107860, Val Acc: 0.783505\n",
      "Epoch 19712 - Train Loss: 0.079301, Train Acc: 0.884615 | Val Loss: 0.107859, Val Acc: 0.783505\n",
      "Epoch 19713 - Train Loss: 0.079298, Train Acc: 0.884615 | Val Loss: 0.107858, Val Acc: 0.783505\n",
      "Epoch 19714 - Train Loss: 0.079296, Train Acc: 0.884615 | Val Loss: 0.107857, Val Acc: 0.783505\n",
      "Epoch 19715 - Train Loss: 0.079294, Train Acc: 0.884615 | Val Loss: 0.107856, Val Acc: 0.783505\n",
      "Epoch 19716 - Train Loss: 0.079292, Train Acc: 0.884615 | Val Loss: 0.107855, Val Acc: 0.783505\n",
      "Epoch 19717 - Train Loss: 0.079290, Train Acc: 0.884615 | Val Loss: 0.107854, Val Acc: 0.783505\n",
      "Epoch 19718 - Train Loss: 0.079287, Train Acc: 0.884615 | Val Loss: 0.107853, Val Acc: 0.783505\n",
      "Epoch 19719 - Train Loss: 0.079285, Train Acc: 0.884615 | Val Loss: 0.107853, Val Acc: 0.783505\n",
      "Epoch 19720 - Train Loss: 0.079283, Train Acc: 0.884615 | Val Loss: 0.107851, Val Acc: 0.783505\n",
      "Epoch 19721 - Train Loss: 0.079281, Train Acc: 0.884615 | Val Loss: 0.107851, Val Acc: 0.783505\n",
      "Epoch 19722 - Train Loss: 0.079279, Train Acc: 0.884615 | Val Loss: 0.107850, Val Acc: 0.783505\n",
      "Epoch 19723 - Train Loss: 0.079276, Train Acc: 0.884615 | Val Loss: 0.107849, Val Acc: 0.783505\n",
      "Epoch 19724 - Train Loss: 0.079274, Train Acc: 0.884615 | Val Loss: 0.107848, Val Acc: 0.783505\n",
      "Epoch 19725 - Train Loss: 0.079272, Train Acc: 0.884615 | Val Loss: 0.107847, Val Acc: 0.783505\n",
      "Epoch 19726 - Train Loss: 0.079270, Train Acc: 0.884615 | Val Loss: 0.107846, Val Acc: 0.783505\n",
      "Epoch 19727 - Train Loss: 0.079268, Train Acc: 0.884615 | Val Loss: 0.107845, Val Acc: 0.783505\n",
      "Epoch 19728 - Train Loss: 0.079265, Train Acc: 0.884615 | Val Loss: 0.107844, Val Acc: 0.783505\n",
      "Epoch 19729 - Train Loss: 0.079263, Train Acc: 0.884615 | Val Loss: 0.107843, Val Acc: 0.783505\n",
      "Epoch 19730 - Train Loss: 0.079261, Train Acc: 0.884615 | Val Loss: 0.107842, Val Acc: 0.783505\n",
      "Epoch 19731 - Train Loss: 0.079259, Train Acc: 0.884615 | Val Loss: 0.107841, Val Acc: 0.783505\n",
      "Epoch 19732 - Train Loss: 0.079257, Train Acc: 0.884615 | Val Loss: 0.107840, Val Acc: 0.783505\n",
      "Epoch 19733 - Train Loss: 0.079254, Train Acc: 0.884615 | Val Loss: 0.107839, Val Acc: 0.783505\n",
      "Epoch 19734 - Train Loss: 0.079252, Train Acc: 0.884615 | Val Loss: 0.107838, Val Acc: 0.783505\n",
      "Epoch 19735 - Train Loss: 0.079250, Train Acc: 0.884615 | Val Loss: 0.107837, Val Acc: 0.783505\n",
      "Epoch 19736 - Train Loss: 0.079248, Train Acc: 0.884615 | Val Loss: 0.107836, Val Acc: 0.783505\n",
      "Epoch 19737 - Train Loss: 0.079246, Train Acc: 0.884615 | Val Loss: 0.107835, Val Acc: 0.783505\n",
      "Epoch 19738 - Train Loss: 0.079244, Train Acc: 0.884615 | Val Loss: 0.107835, Val Acc: 0.783505\n",
      "Epoch 19739 - Train Loss: 0.079241, Train Acc: 0.884615 | Val Loss: 0.107834, Val Acc: 0.783505\n",
      "Epoch 19740 - Train Loss: 0.079239, Train Acc: 0.884615 | Val Loss: 0.107833, Val Acc: 0.783505\n",
      "Epoch 19741 - Train Loss: 0.079237, Train Acc: 0.884615 | Val Loss: 0.107832, Val Acc: 0.783505\n",
      "Epoch 19742 - Train Loss: 0.079235, Train Acc: 0.884615 | Val Loss: 0.107831, Val Acc: 0.783505\n",
      "Epoch 19743 - Train Loss: 0.079233, Train Acc: 0.884615 | Val Loss: 0.107830, Val Acc: 0.783505\n",
      "Epoch 19744 - Train Loss: 0.079230, Train Acc: 0.884615 | Val Loss: 0.107829, Val Acc: 0.783505\n",
      "Epoch 19745 - Train Loss: 0.079228, Train Acc: 0.884615 | Val Loss: 0.107828, Val Acc: 0.783505\n",
      "Epoch 19746 - Train Loss: 0.079226, Train Acc: 0.884615 | Val Loss: 0.107827, Val Acc: 0.783505\n",
      "Epoch 19747 - Train Loss: 0.079224, Train Acc: 0.884615 | Val Loss: 0.107826, Val Acc: 0.783505\n",
      "Epoch 19748 - Train Loss: 0.079222, Train Acc: 0.884615 | Val Loss: 0.107825, Val Acc: 0.783505\n",
      "Epoch 19749 - Train Loss: 0.079219, Train Acc: 0.884615 | Val Loss: 0.107824, Val Acc: 0.783505\n",
      "Epoch 19750 - Train Loss: 0.079217, Train Acc: 0.884615 | Val Loss: 0.107823, Val Acc: 0.783505\n",
      "Epoch 19751 - Train Loss: 0.079215, Train Acc: 0.884615 | Val Loss: 0.107822, Val Acc: 0.783505\n",
      "Epoch 19752 - Train Loss: 0.079213, Train Acc: 0.884615 | Val Loss: 0.107821, Val Acc: 0.783505\n",
      "Epoch 19753 - Train Loss: 0.079211, Train Acc: 0.884615 | Val Loss: 0.107820, Val Acc: 0.783505\n",
      "Epoch 19754 - Train Loss: 0.079209, Train Acc: 0.884615 | Val Loss: 0.107819, Val Acc: 0.783505\n",
      "Epoch 19755 - Train Loss: 0.079206, Train Acc: 0.884615 | Val Loss: 0.107818, Val Acc: 0.783505\n",
      "Epoch 19756 - Train Loss: 0.079204, Train Acc: 0.884615 | Val Loss: 0.107817, Val Acc: 0.783505\n",
      "Epoch 19757 - Train Loss: 0.079202, Train Acc: 0.884615 | Val Loss: 0.107817, Val Acc: 0.783505\n",
      "Epoch 19758 - Train Loss: 0.079200, Train Acc: 0.884615 | Val Loss: 0.107816, Val Acc: 0.783505\n",
      "Epoch 19759 - Train Loss: 0.079198, Train Acc: 0.884615 | Val Loss: 0.107815, Val Acc: 0.783505\n",
      "Epoch 19760 - Train Loss: 0.079195, Train Acc: 0.884615 | Val Loss: 0.107814, Val Acc: 0.783505\n",
      "Epoch 19761 - Train Loss: 0.079193, Train Acc: 0.884615 | Val Loss: 0.107813, Val Acc: 0.783505\n",
      "Epoch 19762 - Train Loss: 0.079191, Train Acc: 0.884615 | Val Loss: 0.107812, Val Acc: 0.783505\n",
      "Epoch 19763 - Train Loss: 0.079189, Train Acc: 0.884615 | Val Loss: 0.107811, Val Acc: 0.783505\n",
      "Epoch 19764 - Train Loss: 0.079187, Train Acc: 0.884615 | Val Loss: 0.107810, Val Acc: 0.783505\n",
      "Epoch 19765 - Train Loss: 0.079185, Train Acc: 0.884615 | Val Loss: 0.107809, Val Acc: 0.783505\n",
      "Epoch 19766 - Train Loss: 0.079182, Train Acc: 0.884615 | Val Loss: 0.107808, Val Acc: 0.783505\n",
      "Epoch 19767 - Train Loss: 0.079180, Train Acc: 0.884615 | Val Loss: 0.107807, Val Acc: 0.783505\n",
      "Epoch 19768 - Train Loss: 0.079178, Train Acc: 0.884615 | Val Loss: 0.107806, Val Acc: 0.783505\n",
      "Epoch 19769 - Train Loss: 0.079176, Train Acc: 0.884615 | Val Loss: 0.107805, Val Acc: 0.783505\n",
      "Epoch 19770 - Train Loss: 0.079174, Train Acc: 0.884615 | Val Loss: 0.107804, Val Acc: 0.783505\n",
      "Epoch 19771 - Train Loss: 0.079171, Train Acc: 0.884615 | Val Loss: 0.107803, Val Acc: 0.783505\n",
      "Epoch 19772 - Train Loss: 0.079169, Train Acc: 0.884615 | Val Loss: 0.107802, Val Acc: 0.783505\n",
      "Epoch 19773 - Train Loss: 0.079167, Train Acc: 0.884615 | Val Loss: 0.107802, Val Acc: 0.783505\n",
      "Epoch 19774 - Train Loss: 0.079165, Train Acc: 0.884615 | Val Loss: 0.107801, Val Acc: 0.783505\n",
      "Epoch 19775 - Train Loss: 0.079163, Train Acc: 0.884615 | Val Loss: 0.107800, Val Acc: 0.783505\n",
      "Epoch 19776 - Train Loss: 0.079161, Train Acc: 0.884615 | Val Loss: 0.107799, Val Acc: 0.783505\n",
      "Epoch 19777 - Train Loss: 0.079158, Train Acc: 0.884615 | Val Loss: 0.107798, Val Acc: 0.783505\n",
      "Epoch 19778 - Train Loss: 0.079156, Train Acc: 0.884615 | Val Loss: 0.107797, Val Acc: 0.783505\n",
      "Epoch 19779 - Train Loss: 0.079154, Train Acc: 0.884615 | Val Loss: 0.107796, Val Acc: 0.783505\n",
      "Epoch 19780 - Train Loss: 0.079152, Train Acc: 0.884615 | Val Loss: 0.107795, Val Acc: 0.783505\n",
      "Epoch 19781 - Train Loss: 0.079150, Train Acc: 0.884615 | Val Loss: 0.107794, Val Acc: 0.783505\n",
      "Epoch 19782 - Train Loss: 0.079147, Train Acc: 0.884615 | Val Loss: 0.107793, Val Acc: 0.783505\n",
      "Epoch 19783 - Train Loss: 0.079145, Train Acc: 0.884615 | Val Loss: 0.107792, Val Acc: 0.783505\n",
      "Epoch 19784 - Train Loss: 0.079143, Train Acc: 0.884615 | Val Loss: 0.107791, Val Acc: 0.783505\n",
      "Epoch 19785 - Train Loss: 0.079141, Train Acc: 0.884615 | Val Loss: 0.107790, Val Acc: 0.783505\n",
      "Epoch 19786 - Train Loss: 0.079139, Train Acc: 0.884615 | Val Loss: 0.107789, Val Acc: 0.783505\n",
      "Epoch 19787 - Train Loss: 0.079137, Train Acc: 0.884615 | Val Loss: 0.107788, Val Acc: 0.783505\n",
      "Epoch 19788 - Train Loss: 0.079134, Train Acc: 0.884615 | Val Loss: 0.107788, Val Acc: 0.783505\n",
      "Epoch 19789 - Train Loss: 0.079132, Train Acc: 0.884615 | Val Loss: 0.107786, Val Acc: 0.783505\n",
      "Epoch 19790 - Train Loss: 0.079130, Train Acc: 0.884615 | Val Loss: 0.107786, Val Acc: 0.783505\n",
      "Epoch 19791 - Train Loss: 0.079128, Train Acc: 0.884615 | Val Loss: 0.107785, Val Acc: 0.783505\n",
      "Epoch 19792 - Train Loss: 0.079126, Train Acc: 0.884615 | Val Loss: 0.107784, Val Acc: 0.783505\n",
      "Epoch 19793 - Train Loss: 0.079124, Train Acc: 0.884615 | Val Loss: 0.107783, Val Acc: 0.783505\n",
      "Epoch 19794 - Train Loss: 0.079121, Train Acc: 0.884615 | Val Loss: 0.107782, Val Acc: 0.783505\n",
      "Epoch 19795 - Train Loss: 0.079119, Train Acc: 0.884615 | Val Loss: 0.107781, Val Acc: 0.783505\n",
      "Epoch 19796 - Train Loss: 0.079117, Train Acc: 0.884615 | Val Loss: 0.107780, Val Acc: 0.783505\n",
      "Epoch 19797 - Train Loss: 0.079115, Train Acc: 0.884615 | Val Loss: 0.107779, Val Acc: 0.783505\n",
      "Epoch 19798 - Train Loss: 0.079113, Train Acc: 0.884615 | Val Loss: 0.107778, Val Acc: 0.783505\n",
      "Epoch 19799 - Train Loss: 0.079110, Train Acc: 0.884615 | Val Loss: 0.107777, Val Acc: 0.783505\n",
      "Epoch 19800 - Train Loss: 0.079108, Train Acc: 0.884615 | Val Loss: 0.107776, Val Acc: 0.783505\n",
      "Epoch 19801 - Train Loss: 0.079106, Train Acc: 0.884615 | Val Loss: 0.107775, Val Acc: 0.783505\n",
      "Epoch 19802 - Train Loss: 0.079104, Train Acc: 0.884615 | Val Loss: 0.107774, Val Acc: 0.783505\n",
      "Epoch 19803 - Train Loss: 0.079102, Train Acc: 0.884615 | Val Loss: 0.107773, Val Acc: 0.783505\n",
      "Epoch 19804 - Train Loss: 0.079100, Train Acc: 0.884615 | Val Loss: 0.107772, Val Acc: 0.783505\n",
      "Epoch 19805 - Train Loss: 0.079097, Train Acc: 0.884615 | Val Loss: 0.107772, Val Acc: 0.783505\n",
      "Epoch 19806 - Train Loss: 0.079095, Train Acc: 0.884615 | Val Loss: 0.107771, Val Acc: 0.783505\n",
      "Epoch 19807 - Train Loss: 0.079093, Train Acc: 0.884615 | Val Loss: 0.107770, Val Acc: 0.783505\n",
      "Epoch 19808 - Train Loss: 0.079091, Train Acc: 0.884615 | Val Loss: 0.107769, Val Acc: 0.783505\n",
      "Epoch 19809 - Train Loss: 0.079089, Train Acc: 0.884615 | Val Loss: 0.107768, Val Acc: 0.783505\n",
      "Epoch 19810 - Train Loss: 0.079087, Train Acc: 0.884615 | Val Loss: 0.107767, Val Acc: 0.783505\n",
      "Epoch 19811 - Train Loss: 0.079084, Train Acc: 0.884615 | Val Loss: 0.107766, Val Acc: 0.783505\n",
      "Epoch 19812 - Train Loss: 0.079082, Train Acc: 0.884615 | Val Loss: 0.107765, Val Acc: 0.783505\n",
      "Epoch 19813 - Train Loss: 0.079080, Train Acc: 0.884615 | Val Loss: 0.107764, Val Acc: 0.783505\n",
      "Epoch 19814 - Train Loss: 0.079078, Train Acc: 0.884615 | Val Loss: 0.107763, Val Acc: 0.783505\n",
      "Epoch 19815 - Train Loss: 0.079076, Train Acc: 0.884615 | Val Loss: 0.107762, Val Acc: 0.783505\n",
      "Epoch 19816 - Train Loss: 0.079073, Train Acc: 0.884615 | Val Loss: 0.107761, Val Acc: 0.783505\n",
      "Epoch 19817 - Train Loss: 0.079071, Train Acc: 0.884615 | Val Loss: 0.107760, Val Acc: 0.783505\n",
      "Epoch 19818 - Train Loss: 0.079069, Train Acc: 0.884615 | Val Loss: 0.107759, Val Acc: 0.783505\n",
      "Epoch 19819 - Train Loss: 0.079067, Train Acc: 0.884615 | Val Loss: 0.107759, Val Acc: 0.783505\n",
      "Epoch 19820 - Train Loss: 0.079065, Train Acc: 0.884615 | Val Loss: 0.107758, Val Acc: 0.783505\n",
      "Epoch 19821 - Train Loss: 0.079063, Train Acc: 0.884615 | Val Loss: 0.107757, Val Acc: 0.783505\n",
      "Epoch 19822 - Train Loss: 0.079060, Train Acc: 0.884615 | Val Loss: 0.107756, Val Acc: 0.783505\n",
      "Epoch 19823 - Train Loss: 0.079058, Train Acc: 0.884615 | Val Loss: 0.107755, Val Acc: 0.783505\n",
      "Epoch 19824 - Train Loss: 0.079056, Train Acc: 0.884615 | Val Loss: 0.107754, Val Acc: 0.783505\n",
      "Epoch 19825 - Train Loss: 0.079054, Train Acc: 0.884615 | Val Loss: 0.107753, Val Acc: 0.783505\n",
      "Epoch 19826 - Train Loss: 0.079052, Train Acc: 0.884615 | Val Loss: 0.107752, Val Acc: 0.783505\n",
      "Epoch 19827 - Train Loss: 0.079050, Train Acc: 0.884615 | Val Loss: 0.107751, Val Acc: 0.783505\n",
      "Epoch 19828 - Train Loss: 0.079047, Train Acc: 0.884615 | Val Loss: 0.107750, Val Acc: 0.783505\n",
      "Epoch 19829 - Train Loss: 0.079045, Train Acc: 0.884615 | Val Loss: 0.107749, Val Acc: 0.783505\n",
      "Epoch 19830 - Train Loss: 0.079043, Train Acc: 0.884615 | Val Loss: 0.107748, Val Acc: 0.783505\n",
      "Epoch 19831 - Train Loss: 0.079041, Train Acc: 0.884615 | Val Loss: 0.107747, Val Acc: 0.783505\n",
      "Epoch 19832 - Train Loss: 0.079039, Train Acc: 0.884615 | Val Loss: 0.107746, Val Acc: 0.783505\n",
      "Epoch 19833 - Train Loss: 0.079037, Train Acc: 0.884615 | Val Loss: 0.107746, Val Acc: 0.783505\n",
      "Epoch 19834 - Train Loss: 0.079034, Train Acc: 0.884615 | Val Loss: 0.107745, Val Acc: 0.783505\n",
      "Epoch 19835 - Train Loss: 0.079032, Train Acc: 0.884615 | Val Loss: 0.107744, Val Acc: 0.783505\n",
      "Epoch 19836 - Train Loss: 0.079030, Train Acc: 0.884615 | Val Loss: 0.107743, Val Acc: 0.783505\n",
      "Epoch 19837 - Train Loss: 0.079028, Train Acc: 0.884615 | Val Loss: 0.107742, Val Acc: 0.783505\n",
      "Epoch 19838 - Train Loss: 0.079026, Train Acc: 0.884615 | Val Loss: 0.107741, Val Acc: 0.783505\n",
      "Epoch 19839 - Train Loss: 0.079024, Train Acc: 0.884615 | Val Loss: 0.107740, Val Acc: 0.783505\n",
      "Epoch 19840 - Train Loss: 0.079021, Train Acc: 0.884615 | Val Loss: 0.107739, Val Acc: 0.783505\n",
      "Epoch 19841 - Train Loss: 0.079019, Train Acc: 0.884615 | Val Loss: 0.107738, Val Acc: 0.783505\n",
      "Epoch 19842 - Train Loss: 0.079017, Train Acc: 0.884615 | Val Loss: 0.107737, Val Acc: 0.783505\n",
      "Epoch 19843 - Train Loss: 0.079015, Train Acc: 0.884615 | Val Loss: 0.107736, Val Acc: 0.783505\n",
      "Epoch 19844 - Train Loss: 0.079013, Train Acc: 0.884615 | Val Loss: 0.107735, Val Acc: 0.783505\n",
      "Epoch 19845 - Train Loss: 0.079011, Train Acc: 0.884615 | Val Loss: 0.107734, Val Acc: 0.783505\n",
      "Epoch 19846 - Train Loss: 0.079008, Train Acc: 0.884615 | Val Loss: 0.107734, Val Acc: 0.783505\n",
      "Epoch 19847 - Train Loss: 0.079006, Train Acc: 0.884615 | Val Loss: 0.107733, Val Acc: 0.783505\n",
      "Epoch 19848 - Train Loss: 0.079004, Train Acc: 0.884615 | Val Loss: 0.107732, Val Acc: 0.783505\n",
      "Epoch 19849 - Train Loss: 0.079002, Train Acc: 0.884615 | Val Loss: 0.107731, Val Acc: 0.783505\n",
      "Epoch 19850 - Train Loss: 0.079000, Train Acc: 0.884615 | Val Loss: 0.107730, Val Acc: 0.783505\n",
      "Epoch 19851 - Train Loss: 0.078998, Train Acc: 0.884615 | Val Loss: 0.107729, Val Acc: 0.783505\n",
      "Epoch 19852 - Train Loss: 0.078995, Train Acc: 0.884615 | Val Loss: 0.107728, Val Acc: 0.783505\n",
      "Epoch 19853 - Train Loss: 0.078993, Train Acc: 0.884615 | Val Loss: 0.107727, Val Acc: 0.783505\n",
      "Epoch 19854 - Train Loss: 0.078991, Train Acc: 0.884615 | Val Loss: 0.107726, Val Acc: 0.783505\n",
      "Epoch 19855 - Train Loss: 0.078989, Train Acc: 0.884615 | Val Loss: 0.107725, Val Acc: 0.783505\n",
      "Epoch 19856 - Train Loss: 0.078987, Train Acc: 0.884615 | Val Loss: 0.107724, Val Acc: 0.783505\n",
      "Epoch 19857 - Train Loss: 0.078985, Train Acc: 0.884615 | Val Loss: 0.107723, Val Acc: 0.783505\n",
      "Epoch 19858 - Train Loss: 0.078982, Train Acc: 0.884615 | Val Loss: 0.107722, Val Acc: 0.783505\n",
      "Epoch 19859 - Train Loss: 0.078980, Train Acc: 0.884615 | Val Loss: 0.107722, Val Acc: 0.783505\n",
      "Epoch 19860 - Train Loss: 0.078978, Train Acc: 0.884615 | Val Loss: 0.107721, Val Acc: 0.783505\n",
      "Epoch 19861 - Train Loss: 0.078976, Train Acc: 0.884615 | Val Loss: 0.107720, Val Acc: 0.783505\n",
      "Epoch 19862 - Train Loss: 0.078974, Train Acc: 0.884615 | Val Loss: 0.107719, Val Acc: 0.783505\n",
      "Epoch 19863 - Train Loss: 0.078972, Train Acc: 0.884615 | Val Loss: 0.107718, Val Acc: 0.783505\n",
      "Epoch 19864 - Train Loss: 0.078970, Train Acc: 0.884615 | Val Loss: 0.107717, Val Acc: 0.783505\n",
      "Epoch 19865 - Train Loss: 0.078967, Train Acc: 0.884615 | Val Loss: 0.107716, Val Acc: 0.783505\n",
      "Epoch 19866 - Train Loss: 0.078965, Train Acc: 0.884615 | Val Loss: 0.107715, Val Acc: 0.783505\n",
      "Epoch 19867 - Train Loss: 0.078963, Train Acc: 0.884615 | Val Loss: 0.107714, Val Acc: 0.783505\n",
      "Epoch 19868 - Train Loss: 0.078961, Train Acc: 0.884615 | Val Loss: 0.107713, Val Acc: 0.783505\n",
      "Epoch 19869 - Train Loss: 0.078959, Train Acc: 0.884615 | Val Loss: 0.107712, Val Acc: 0.783505\n",
      "Epoch 19870 - Train Loss: 0.078957, Train Acc: 0.884615 | Val Loss: 0.107711, Val Acc: 0.783505\n",
      "Epoch 19871 - Train Loss: 0.078954, Train Acc: 0.884615 | Val Loss: 0.107710, Val Acc: 0.783505\n",
      "Epoch 19872 - Train Loss: 0.078952, Train Acc: 0.884615 | Val Loss: 0.107710, Val Acc: 0.783505\n",
      "Epoch 19873 - Train Loss: 0.078950, Train Acc: 0.884615 | Val Loss: 0.107709, Val Acc: 0.783505\n",
      "Epoch 19874 - Train Loss: 0.078948, Train Acc: 0.884615 | Val Loss: 0.107708, Val Acc: 0.783505\n",
      "Epoch 19875 - Train Loss: 0.078946, Train Acc: 0.884615 | Val Loss: 0.107707, Val Acc: 0.783505\n",
      "Epoch 19876 - Train Loss: 0.078944, Train Acc: 0.884615 | Val Loss: 0.107706, Val Acc: 0.783505\n",
      "Epoch 19877 - Train Loss: 0.078941, Train Acc: 0.884615 | Val Loss: 0.107705, Val Acc: 0.783505\n",
      "Epoch 19878 - Train Loss: 0.078939, Train Acc: 0.884615 | Val Loss: 0.107704, Val Acc: 0.783505\n",
      "Epoch 19879 - Train Loss: 0.078937, Train Acc: 0.884615 | Val Loss: 0.107703, Val Acc: 0.783505\n",
      "Epoch 19880 - Train Loss: 0.078935, Train Acc: 0.884615 | Val Loss: 0.107702, Val Acc: 0.783505\n",
      "Epoch 19881 - Train Loss: 0.078933, Train Acc: 0.884615 | Val Loss: 0.107701, Val Acc: 0.783505\n",
      "Epoch 19882 - Train Loss: 0.078931, Train Acc: 0.884615 | Val Loss: 0.107700, Val Acc: 0.783505\n",
      "Epoch 19883 - Train Loss: 0.078928, Train Acc: 0.884615 | Val Loss: 0.107699, Val Acc: 0.783505\n",
      "Epoch 19884 - Train Loss: 0.078926, Train Acc: 0.884615 | Val Loss: 0.107699, Val Acc: 0.783505\n",
      "Epoch 19885 - Train Loss: 0.078924, Train Acc: 0.884615 | Val Loss: 0.107698, Val Acc: 0.783505\n",
      "Epoch 19886 - Train Loss: 0.078922, Train Acc: 0.884615 | Val Loss: 0.107697, Val Acc: 0.783505\n",
      "Epoch 19887 - Train Loss: 0.078920, Train Acc: 0.884615 | Val Loss: 0.107696, Val Acc: 0.783505\n",
      "Epoch 19888 - Train Loss: 0.078918, Train Acc: 0.884615 | Val Loss: 0.107695, Val Acc: 0.783505\n",
      "Epoch 19889 - Train Loss: 0.078916, Train Acc: 0.884615 | Val Loss: 0.107694, Val Acc: 0.783505\n",
      "Epoch 19890 - Train Loss: 0.078913, Train Acc: 0.884615 | Val Loss: 0.107693, Val Acc: 0.783505\n",
      "Epoch 19891 - Train Loss: 0.078911, Train Acc: 0.884615 | Val Loss: 0.107692, Val Acc: 0.783505\n",
      "Epoch 19892 - Train Loss: 0.078909, Train Acc: 0.884615 | Val Loss: 0.107691, Val Acc: 0.783505\n",
      "Epoch 19893 - Train Loss: 0.078907, Train Acc: 0.884615 | Val Loss: 0.107690, Val Acc: 0.783505\n",
      "Epoch 19894 - Train Loss: 0.078905, Train Acc: 0.884615 | Val Loss: 0.107689, Val Acc: 0.783505\n",
      "Epoch 19895 - Train Loss: 0.078903, Train Acc: 0.884615 | Val Loss: 0.107689, Val Acc: 0.783505\n",
      "Epoch 19896 - Train Loss: 0.078900, Train Acc: 0.884615 | Val Loss: 0.107688, Val Acc: 0.783505\n",
      "Epoch 19897 - Train Loss: 0.078898, Train Acc: 0.884615 | Val Loss: 0.107687, Val Acc: 0.783505\n",
      "Epoch 19898 - Train Loss: 0.078896, Train Acc: 0.884615 | Val Loss: 0.107686, Val Acc: 0.783505\n",
      "Epoch 19899 - Train Loss: 0.078894, Train Acc: 0.884615 | Val Loss: 0.107685, Val Acc: 0.783505\n",
      "Epoch 19900 - Train Loss: 0.078892, Train Acc: 0.884615 | Val Loss: 0.107684, Val Acc: 0.783505\n",
      "Epoch 19901 - Train Loss: 0.078890, Train Acc: 0.884615 | Val Loss: 0.107683, Val Acc: 0.783505\n",
      "Epoch 19902 - Train Loss: 0.078888, Train Acc: 0.884615 | Val Loss: 0.107682, Val Acc: 0.783505\n",
      "Epoch 19903 - Train Loss: 0.078885, Train Acc: 0.884615 | Val Loss: 0.107681, Val Acc: 0.783505\n",
      "Epoch 19904 - Train Loss: 0.078883, Train Acc: 0.884615 | Val Loss: 0.107680, Val Acc: 0.783505\n",
      "Epoch 19905 - Train Loss: 0.078881, Train Acc: 0.884615 | Val Loss: 0.107679, Val Acc: 0.783505\n",
      "Epoch 19906 - Train Loss: 0.078879, Train Acc: 0.884615 | Val Loss: 0.107678, Val Acc: 0.783505\n",
      "Epoch 19907 - Train Loss: 0.078877, Train Acc: 0.884615 | Val Loss: 0.107678, Val Acc: 0.783505\n",
      "Epoch 19908 - Train Loss: 0.078875, Train Acc: 0.884615 | Val Loss: 0.107677, Val Acc: 0.783505\n",
      "Epoch 19909 - Train Loss: 0.078872, Train Acc: 0.884615 | Val Loss: 0.107676, Val Acc: 0.783505\n",
      "Epoch 19910 - Train Loss: 0.078870, Train Acc: 0.884615 | Val Loss: 0.107675, Val Acc: 0.783505\n",
      "Epoch 19911 - Train Loss: 0.078868, Train Acc: 0.884615 | Val Loss: 0.107674, Val Acc: 0.783505\n",
      "Epoch 19912 - Train Loss: 0.078866, Train Acc: 0.884615 | Val Loss: 0.107673, Val Acc: 0.783505\n",
      "Epoch 19913 - Train Loss: 0.078864, Train Acc: 0.884615 | Val Loss: 0.107672, Val Acc: 0.783505\n",
      "Epoch 19914 - Train Loss: 0.078862, Train Acc: 0.884615 | Val Loss: 0.107671, Val Acc: 0.783505\n",
      "Epoch 19915 - Train Loss: 0.078860, Train Acc: 0.884615 | Val Loss: 0.107670, Val Acc: 0.783505\n",
      "Epoch 19916 - Train Loss: 0.078857, Train Acc: 0.884615 | Val Loss: 0.107669, Val Acc: 0.783505\n",
      "Epoch 19917 - Train Loss: 0.078855, Train Acc: 0.884615 | Val Loss: 0.107668, Val Acc: 0.783505\n",
      "Epoch 19918 - Train Loss: 0.078853, Train Acc: 0.884615 | Val Loss: 0.107668, Val Acc: 0.783505\n",
      "Epoch 19919 - Train Loss: 0.078851, Train Acc: 0.884615 | Val Loss: 0.107667, Val Acc: 0.783505\n",
      "Epoch 19920 - Train Loss: 0.078849, Train Acc: 0.884615 | Val Loss: 0.107666, Val Acc: 0.783505\n",
      "Epoch 19921 - Train Loss: 0.078847, Train Acc: 0.884615 | Val Loss: 0.107665, Val Acc: 0.783505\n",
      "Epoch 19922 - Train Loss: 0.078845, Train Acc: 0.884615 | Val Loss: 0.107664, Val Acc: 0.783505\n",
      "Epoch 19923 - Train Loss: 0.078842, Train Acc: 0.884615 | Val Loss: 0.107663, Val Acc: 0.783505\n",
      "Epoch 19924 - Train Loss: 0.078840, Train Acc: 0.884615 | Val Loss: 0.107662, Val Acc: 0.783505\n",
      "Epoch 19925 - Train Loss: 0.078838, Train Acc: 0.884615 | Val Loss: 0.107661, Val Acc: 0.783505\n",
      "Epoch 19926 - Train Loss: 0.078836, Train Acc: 0.884615 | Val Loss: 0.107660, Val Acc: 0.783505\n",
      "Epoch 19927 - Train Loss: 0.078834, Train Acc: 0.884615 | Val Loss: 0.107659, Val Acc: 0.783505\n",
      "Epoch 19928 - Train Loss: 0.078832, Train Acc: 0.884615 | Val Loss: 0.107658, Val Acc: 0.783505\n",
      "Epoch 19929 - Train Loss: 0.078830, Train Acc: 0.884615 | Val Loss: 0.107658, Val Acc: 0.783505\n",
      "Epoch 19930 - Train Loss: 0.078827, Train Acc: 0.884615 | Val Loss: 0.107657, Val Acc: 0.783505\n",
      "Epoch 19931 - Train Loss: 0.078825, Train Acc: 0.884615 | Val Loss: 0.107656, Val Acc: 0.783505\n",
      "Epoch 19932 - Train Loss: 0.078823, Train Acc: 0.884615 | Val Loss: 0.107655, Val Acc: 0.783505\n",
      "Epoch 19933 - Train Loss: 0.078821, Train Acc: 0.884615 | Val Loss: 0.107654, Val Acc: 0.783505\n",
      "Epoch 19934 - Train Loss: 0.078819, Train Acc: 0.884615 | Val Loss: 0.107653, Val Acc: 0.783505\n",
      "Epoch 19935 - Train Loss: 0.078817, Train Acc: 0.884615 | Val Loss: 0.107652, Val Acc: 0.783505\n",
      "Epoch 19936 - Train Loss: 0.078814, Train Acc: 0.884615 | Val Loss: 0.107651, Val Acc: 0.783505\n",
      "Epoch 19937 - Train Loss: 0.078812, Train Acc: 0.884615 | Val Loss: 0.107650, Val Acc: 0.783505\n",
      "Epoch 19938 - Train Loss: 0.078810, Train Acc: 0.884615 | Val Loss: 0.107649, Val Acc: 0.783505\n",
      "Epoch 19939 - Train Loss: 0.078808, Train Acc: 0.884615 | Val Loss: 0.107648, Val Acc: 0.783505\n",
      "Epoch 19940 - Train Loss: 0.078806, Train Acc: 0.884615 | Val Loss: 0.107648, Val Acc: 0.783505\n",
      "Epoch 19941 - Train Loss: 0.078804, Train Acc: 0.884615 | Val Loss: 0.107647, Val Acc: 0.783505\n",
      "Epoch 19942 - Train Loss: 0.078802, Train Acc: 0.884615 | Val Loss: 0.107646, Val Acc: 0.783505\n",
      "Epoch 19943 - Train Loss: 0.078799, Train Acc: 0.884615 | Val Loss: 0.107645, Val Acc: 0.783505\n",
      "Epoch 19944 - Train Loss: 0.078797, Train Acc: 0.884615 | Val Loss: 0.107644, Val Acc: 0.783505\n",
      "Epoch 19945 - Train Loss: 0.078795, Train Acc: 0.884615 | Val Loss: 0.107643, Val Acc: 0.783505\n",
      "Epoch 19946 - Train Loss: 0.078793, Train Acc: 0.884615 | Val Loss: 0.107642, Val Acc: 0.783505\n",
      "Epoch 19947 - Train Loss: 0.078791, Train Acc: 0.884615 | Val Loss: 0.107641, Val Acc: 0.783505\n",
      "Epoch 19948 - Train Loss: 0.078789, Train Acc: 0.884615 | Val Loss: 0.107640, Val Acc: 0.783505\n",
      "Epoch 19949 - Train Loss: 0.078787, Train Acc: 0.884615 | Val Loss: 0.107639, Val Acc: 0.783505\n",
      "Epoch 19950 - Train Loss: 0.078784, Train Acc: 0.884615 | Val Loss: 0.107639, Val Acc: 0.783505\n",
      "Epoch 19951 - Train Loss: 0.078782, Train Acc: 0.884615 | Val Loss: 0.107638, Val Acc: 0.783505\n",
      "Epoch 19952 - Train Loss: 0.078780, Train Acc: 0.884615 | Val Loss: 0.107637, Val Acc: 0.783505\n",
      "Epoch 19953 - Train Loss: 0.078778, Train Acc: 0.884615 | Val Loss: 0.107636, Val Acc: 0.783505\n",
      "Epoch 19954 - Train Loss: 0.078776, Train Acc: 0.884615 | Val Loss: 0.107635, Val Acc: 0.783505\n",
      "Epoch 19955 - Train Loss: 0.078774, Train Acc: 0.884615 | Val Loss: 0.107634, Val Acc: 0.783505\n",
      "Epoch 19956 - Train Loss: 0.078772, Train Acc: 0.884615 | Val Loss: 0.107633, Val Acc: 0.783505\n",
      "Epoch 19957 - Train Loss: 0.078769, Train Acc: 0.884615 | Val Loss: 0.107632, Val Acc: 0.783505\n",
      "Epoch 19958 - Train Loss: 0.078767, Train Acc: 0.884615 | Val Loss: 0.107631, Val Acc: 0.783505\n",
      "Epoch 19959 - Train Loss: 0.078765, Train Acc: 0.884615 | Val Loss: 0.107630, Val Acc: 0.783505\n",
      "Epoch 19960 - Train Loss: 0.078763, Train Acc: 0.884615 | Val Loss: 0.107630, Val Acc: 0.783505\n",
      "Epoch 19961 - Train Loss: 0.078761, Train Acc: 0.884615 | Val Loss: 0.107629, Val Acc: 0.783505\n",
      "Epoch 19962 - Train Loss: 0.078759, Train Acc: 0.884615 | Val Loss: 0.107628, Val Acc: 0.783505\n",
      "Epoch 19963 - Train Loss: 0.078757, Train Acc: 0.884615 | Val Loss: 0.107627, Val Acc: 0.783505\n",
      "Epoch 19964 - Train Loss: 0.078755, Train Acc: 0.884615 | Val Loss: 0.107626, Val Acc: 0.783505\n",
      "Epoch 19965 - Train Loss: 0.078752, Train Acc: 0.884615 | Val Loss: 0.107625, Val Acc: 0.783505\n",
      "Epoch 19966 - Train Loss: 0.078750, Train Acc: 0.884615 | Val Loss: 0.107624, Val Acc: 0.783505\n",
      "Epoch 19967 - Train Loss: 0.078748, Train Acc: 0.884615 | Val Loss: 0.107623, Val Acc: 0.783505\n",
      "Epoch 19968 - Train Loss: 0.078746, Train Acc: 0.884615 | Val Loss: 0.107622, Val Acc: 0.783505\n",
      "Epoch 19969 - Train Loss: 0.078744, Train Acc: 0.884615 | Val Loss: 0.107621, Val Acc: 0.783505\n",
      "Epoch 19970 - Train Loss: 0.078742, Train Acc: 0.884615 | Val Loss: 0.107621, Val Acc: 0.783505\n",
      "Epoch 19971 - Train Loss: 0.078740, Train Acc: 0.884615 | Val Loss: 0.107620, Val Acc: 0.783505\n",
      "Epoch 19972 - Train Loss: 0.078737, Train Acc: 0.884615 | Val Loss: 0.107619, Val Acc: 0.783505\n",
      "Epoch 19973 - Train Loss: 0.078735, Train Acc: 0.884615 | Val Loss: 0.107618, Val Acc: 0.783505\n",
      "Epoch 19974 - Train Loss: 0.078733, Train Acc: 0.884615 | Val Loss: 0.107617, Val Acc: 0.783505\n",
      "Epoch 19975 - Train Loss: 0.078731, Train Acc: 0.884615 | Val Loss: 0.107616, Val Acc: 0.783505\n",
      "Epoch 19976 - Train Loss: 0.078729, Train Acc: 0.884615 | Val Loss: 0.107615, Val Acc: 0.783505\n",
      "Epoch 19977 - Train Loss: 0.078727, Train Acc: 0.884615 | Val Loss: 0.107614, Val Acc: 0.783505\n",
      "Epoch 19978 - Train Loss: 0.078725, Train Acc: 0.884615 | Val Loss: 0.107613, Val Acc: 0.783505\n",
      "Epoch 19979 - Train Loss: 0.078722, Train Acc: 0.884615 | Val Loss: 0.107612, Val Acc: 0.783505\n",
      "Epoch 19980 - Train Loss: 0.078720, Train Acc: 0.884615 | Val Loss: 0.107612, Val Acc: 0.783505\n",
      "Epoch 19981 - Train Loss: 0.078718, Train Acc: 0.884615 | Val Loss: 0.107611, Val Acc: 0.783505\n",
      "Epoch 19982 - Train Loss: 0.078716, Train Acc: 0.884615 | Val Loss: 0.107610, Val Acc: 0.783505\n",
      "Epoch 19983 - Train Loss: 0.078714, Train Acc: 0.884615 | Val Loss: 0.107609, Val Acc: 0.783505\n",
      "Epoch 19984 - Train Loss: 0.078712, Train Acc: 0.884615 | Val Loss: 0.107608, Val Acc: 0.783505\n",
      "Epoch 19985 - Train Loss: 0.078710, Train Acc: 0.884615 | Val Loss: 0.107607, Val Acc: 0.783505\n",
      "Epoch 19986 - Train Loss: 0.078707, Train Acc: 0.884615 | Val Loss: 0.107606, Val Acc: 0.783505\n",
      "Epoch 19987 - Train Loss: 0.078705, Train Acc: 0.884615 | Val Loss: 0.107605, Val Acc: 0.783505\n",
      "Epoch 19988 - Train Loss: 0.078703, Train Acc: 0.884615 | Val Loss: 0.107604, Val Acc: 0.783505\n",
      "Epoch 19989 - Train Loss: 0.078701, Train Acc: 0.884615 | Val Loss: 0.107603, Val Acc: 0.783505\n",
      "Epoch 19990 - Train Loss: 0.078699, Train Acc: 0.884615 | Val Loss: 0.107603, Val Acc: 0.783505\n",
      "Epoch 19991 - Train Loss: 0.078697, Train Acc: 0.884615 | Val Loss: 0.107602, Val Acc: 0.783505\n",
      "Epoch 19992 - Train Loss: 0.078695, Train Acc: 0.884615 | Val Loss: 0.107601, Val Acc: 0.783505\n",
      "Epoch 19993 - Train Loss: 0.078693, Train Acc: 0.884615 | Val Loss: 0.107600, Val Acc: 0.783505\n",
      "Epoch 19994 - Train Loss: 0.078690, Train Acc: 0.884615 | Val Loss: 0.107599, Val Acc: 0.783505\n",
      "Epoch 19995 - Train Loss: 0.078688, Train Acc: 0.884615 | Val Loss: 0.107598, Val Acc: 0.783505\n",
      "Epoch 19996 - Train Loss: 0.078686, Train Acc: 0.884615 | Val Loss: 0.107597, Val Acc: 0.783505\n",
      "Epoch 19997 - Train Loss: 0.078684, Train Acc: 0.884615 | Val Loss: 0.107596, Val Acc: 0.783505\n",
      "Epoch 19998 - Train Loss: 0.078682, Train Acc: 0.884615 | Val Loss: 0.107595, Val Acc: 0.783505\n",
      "Epoch 19999 - Train Loss: 0.078680, Train Acc: 0.884615 | Val Loss: 0.107595, Val Acc: 0.783505\n",
      "Epoch 20000 - Train Loss: 0.078678, Train Acc: 0.884615 | Val Loss: 0.107594, Val Acc: 0.783505\n",
      "Epoch 20001 - Train Loss: 0.078675, Train Acc: 0.884615 | Val Loss: 0.107593, Val Acc: 0.783505\n",
      "Epoch 20002 - Train Loss: 0.078673, Train Acc: 0.884615 | Val Loss: 0.107592, Val Acc: 0.783505\n",
      "Epoch 20003 - Train Loss: 0.078671, Train Acc: 0.884615 | Val Loss: 0.107591, Val Acc: 0.783505\n",
      "Epoch 20004 - Train Loss: 0.078669, Train Acc: 0.884615 | Val Loss: 0.107590, Val Acc: 0.783505\n",
      "Epoch 20005 - Train Loss: 0.078667, Train Acc: 0.884615 | Val Loss: 0.107589, Val Acc: 0.783505\n",
      "Epoch 20006 - Train Loss: 0.078665, Train Acc: 0.884615 | Val Loss: 0.107588, Val Acc: 0.783505\n",
      "Epoch 20007 - Train Loss: 0.078663, Train Acc: 0.884615 | Val Loss: 0.107587, Val Acc: 0.783505\n",
      "Epoch 20008 - Train Loss: 0.078661, Train Acc: 0.884615 | Val Loss: 0.107587, Val Acc: 0.783505\n",
      "Epoch 20009 - Train Loss: 0.078658, Train Acc: 0.884615 | Val Loss: 0.107586, Val Acc: 0.783505\n",
      "Epoch 20010 - Train Loss: 0.078656, Train Acc: 0.884615 | Val Loss: 0.107585, Val Acc: 0.783505\n",
      "Epoch 20011 - Train Loss: 0.078654, Train Acc: 0.884615 | Val Loss: 0.107584, Val Acc: 0.783505\n",
      "Epoch 20012 - Train Loss: 0.078652, Train Acc: 0.884615 | Val Loss: 0.107583, Val Acc: 0.783505\n",
      "Epoch 20013 - Train Loss: 0.078650, Train Acc: 0.884615 | Val Loss: 0.107582, Val Acc: 0.783505\n",
      "Epoch 20014 - Train Loss: 0.078648, Train Acc: 0.884615 | Val Loss: 0.107581, Val Acc: 0.783505\n",
      "Epoch 20015 - Train Loss: 0.078646, Train Acc: 0.884615 | Val Loss: 0.107580, Val Acc: 0.783505\n",
      "Epoch 20016 - Train Loss: 0.078644, Train Acc: 0.884615 | Val Loss: 0.107579, Val Acc: 0.783505\n",
      "Epoch 20017 - Train Loss: 0.078641, Train Acc: 0.884615 | Val Loss: 0.107579, Val Acc: 0.783505\n",
      "Epoch 20018 - Train Loss: 0.078639, Train Acc: 0.884615 | Val Loss: 0.107578, Val Acc: 0.783505\n",
      "Epoch 20019 - Train Loss: 0.078637, Train Acc: 0.884615 | Val Loss: 0.107577, Val Acc: 0.783505\n",
      "Epoch 20020 - Train Loss: 0.078635, Train Acc: 0.884615 | Val Loss: 0.107576, Val Acc: 0.783505\n",
      "Epoch 20021 - Train Loss: 0.078633, Train Acc: 0.884615 | Val Loss: 0.107575, Val Acc: 0.783505\n",
      "Epoch 20022 - Train Loss: 0.078631, Train Acc: 0.884615 | Val Loss: 0.107574, Val Acc: 0.783505\n",
      "Epoch 20023 - Train Loss: 0.078629, Train Acc: 0.884615 | Val Loss: 0.107573, Val Acc: 0.783505\n",
      "Epoch 20024 - Train Loss: 0.078627, Train Acc: 0.884615 | Val Loss: 0.107572, Val Acc: 0.783505\n",
      "Epoch 20025 - Train Loss: 0.078624, Train Acc: 0.884615 | Val Loss: 0.107571, Val Acc: 0.783505\n",
      "Epoch 20026 - Train Loss: 0.078622, Train Acc: 0.884615 | Val Loss: 0.107571, Val Acc: 0.783505\n",
      "Epoch 20027 - Train Loss: 0.078620, Train Acc: 0.884615 | Val Loss: 0.107570, Val Acc: 0.783505\n",
      "Epoch 20028 - Train Loss: 0.078618, Train Acc: 0.884615 | Val Loss: 0.107569, Val Acc: 0.783505\n",
      "Epoch 20029 - Train Loss: 0.078616, Train Acc: 0.884615 | Val Loss: 0.107568, Val Acc: 0.783505\n",
      "Epoch 20030 - Train Loss: 0.078614, Train Acc: 0.884615 | Val Loss: 0.107567, Val Acc: 0.783505\n",
      "Epoch 20031 - Train Loss: 0.078612, Train Acc: 0.884615 | Val Loss: 0.107566, Val Acc: 0.783505\n",
      "Epoch 20032 - Train Loss: 0.078610, Train Acc: 0.884615 | Val Loss: 0.107565, Val Acc: 0.783505\n",
      "Epoch 20033 - Train Loss: 0.078607, Train Acc: 0.884615 | Val Loss: 0.107564, Val Acc: 0.783505\n",
      "Epoch 20034 - Train Loss: 0.078605, Train Acc: 0.884615 | Val Loss: 0.107563, Val Acc: 0.783505\n",
      "Epoch 20035 - Train Loss: 0.078603, Train Acc: 0.884615 | Val Loss: 0.107563, Val Acc: 0.783505\n",
      "Epoch 20036 - Train Loss: 0.078601, Train Acc: 0.884615 | Val Loss: 0.107562, Val Acc: 0.783505\n",
      "Epoch 20037 - Train Loss: 0.078599, Train Acc: 0.884615 | Val Loss: 0.107561, Val Acc: 0.783505\n",
      "Epoch 20038 - Train Loss: 0.078597, Train Acc: 0.884615 | Val Loss: 0.107560, Val Acc: 0.783505\n",
      "Epoch 20039 - Train Loss: 0.078595, Train Acc: 0.884615 | Val Loss: 0.107559, Val Acc: 0.783505\n",
      "Epoch 20040 - Train Loss: 0.078593, Train Acc: 0.884615 | Val Loss: 0.107558, Val Acc: 0.783505\n",
      "Epoch 20041 - Train Loss: 0.078590, Train Acc: 0.884615 | Val Loss: 0.107557, Val Acc: 0.783505\n",
      "Epoch 20042 - Train Loss: 0.078588, Train Acc: 0.884615 | Val Loss: 0.107556, Val Acc: 0.783505\n",
      "Epoch 20043 - Train Loss: 0.078586, Train Acc: 0.884615 | Val Loss: 0.107556, Val Acc: 0.783505\n",
      "Epoch 20044 - Train Loss: 0.078584, Train Acc: 0.884615 | Val Loss: 0.107555, Val Acc: 0.783505\n",
      "Epoch 20045 - Train Loss: 0.078582, Train Acc: 0.884615 | Val Loss: 0.107554, Val Acc: 0.783505\n",
      "Epoch 20046 - Train Loss: 0.078580, Train Acc: 0.884615 | Val Loss: 0.107553, Val Acc: 0.783505\n",
      "Epoch 20047 - Train Loss: 0.078578, Train Acc: 0.884615 | Val Loss: 0.107552, Val Acc: 0.783505\n",
      "Epoch 20048 - Train Loss: 0.078576, Train Acc: 0.884615 | Val Loss: 0.107551, Val Acc: 0.783505\n",
      "Epoch 20049 - Train Loss: 0.078573, Train Acc: 0.884615 | Val Loss: 0.107550, Val Acc: 0.783505\n",
      "Epoch 20050 - Train Loss: 0.078571, Train Acc: 0.884615 | Val Loss: 0.107549, Val Acc: 0.783505\n",
      "Epoch 20051 - Train Loss: 0.078569, Train Acc: 0.884615 | Val Loss: 0.107548, Val Acc: 0.783505\n",
      "Epoch 20052 - Train Loss: 0.078567, Train Acc: 0.884615 | Val Loss: 0.107548, Val Acc: 0.783505\n",
      "Epoch 20053 - Train Loss: 0.078565, Train Acc: 0.884615 | Val Loss: 0.107547, Val Acc: 0.783505\n",
      "Epoch 20054 - Train Loss: 0.078563, Train Acc: 0.884615 | Val Loss: 0.107546, Val Acc: 0.783505\n",
      "Epoch 20055 - Train Loss: 0.078561, Train Acc: 0.884615 | Val Loss: 0.107545, Val Acc: 0.783505\n",
      "Epoch 20056 - Train Loss: 0.078559, Train Acc: 0.884615 | Val Loss: 0.107544, Val Acc: 0.783505\n",
      "Epoch 20057 - Train Loss: 0.078556, Train Acc: 0.884615 | Val Loss: 0.107543, Val Acc: 0.783505\n",
      "Epoch 20058 - Train Loss: 0.078554, Train Acc: 0.884615 | Val Loss: 0.107542, Val Acc: 0.783505\n",
      "Epoch 20059 - Train Loss: 0.078552, Train Acc: 0.884615 | Val Loss: 0.107541, Val Acc: 0.783505\n",
      "Epoch 20060 - Train Loss: 0.078550, Train Acc: 0.884615 | Val Loss: 0.107540, Val Acc: 0.783505\n",
      "Epoch 20061 - Train Loss: 0.078548, Train Acc: 0.884615 | Val Loss: 0.107540, Val Acc: 0.783505\n",
      "Epoch 20062 - Train Loss: 0.078546, Train Acc: 0.884615 | Val Loss: 0.107539, Val Acc: 0.783505\n",
      "Epoch 20063 - Train Loss: 0.078544, Train Acc: 0.884615 | Val Loss: 0.107538, Val Acc: 0.783505\n",
      "Epoch 20064 - Train Loss: 0.078542, Train Acc: 0.884615 | Val Loss: 0.107537, Val Acc: 0.783505\n",
      "Epoch 20065 - Train Loss: 0.078540, Train Acc: 0.884615 | Val Loss: 0.107536, Val Acc: 0.783505\n",
      "Epoch 20066 - Train Loss: 0.078537, Train Acc: 0.884615 | Val Loss: 0.107535, Val Acc: 0.783505\n",
      "Epoch 20067 - Train Loss: 0.078535, Train Acc: 0.884615 | Val Loss: 0.107534, Val Acc: 0.783505\n",
      "Epoch 20068 - Train Loss: 0.078533, Train Acc: 0.884615 | Val Loss: 0.107534, Val Acc: 0.783505\n",
      "Epoch 20069 - Train Loss: 0.078531, Train Acc: 0.884615 | Val Loss: 0.107533, Val Acc: 0.783505\n",
      "Epoch 20070 - Train Loss: 0.078529, Train Acc: 0.884615 | Val Loss: 0.107532, Val Acc: 0.783505\n",
      "Epoch 20071 - Train Loss: 0.078527, Train Acc: 0.884615 | Val Loss: 0.107531, Val Acc: 0.783505\n",
      "Epoch 20072 - Train Loss: 0.078525, Train Acc: 0.884615 | Val Loss: 0.107530, Val Acc: 0.783505\n",
      "Epoch 20073 - Train Loss: 0.078523, Train Acc: 0.884615 | Val Loss: 0.107529, Val Acc: 0.783505\n",
      "Epoch 20074 - Train Loss: 0.078520, Train Acc: 0.884615 | Val Loss: 0.107528, Val Acc: 0.783505\n",
      "Epoch 20075 - Train Loss: 0.078518, Train Acc: 0.884615 | Val Loss: 0.107527, Val Acc: 0.783505\n",
      "Epoch 20076 - Train Loss: 0.078516, Train Acc: 0.884615 | Val Loss: 0.107526, Val Acc: 0.783505\n",
      "Epoch 20077 - Train Loss: 0.078514, Train Acc: 0.884615 | Val Loss: 0.107526, Val Acc: 0.783505\n",
      "Epoch 20078 - Train Loss: 0.078512, Train Acc: 0.884615 | Val Loss: 0.107525, Val Acc: 0.783505\n",
      "Epoch 20079 - Train Loss: 0.078510, Train Acc: 0.884615 | Val Loss: 0.107524, Val Acc: 0.783505\n",
      "Epoch 20080 - Train Loss: 0.078508, Train Acc: 0.884615 | Val Loss: 0.107523, Val Acc: 0.783505\n",
      "Epoch 20081 - Train Loss: 0.078506, Train Acc: 0.884615 | Val Loss: 0.107522, Val Acc: 0.783505\n",
      "Epoch 20082 - Train Loss: 0.078504, Train Acc: 0.884615 | Val Loss: 0.107521, Val Acc: 0.783505\n",
      "Epoch 20083 - Train Loss: 0.078501, Train Acc: 0.884615 | Val Loss: 0.107520, Val Acc: 0.783505\n",
      "Epoch 20084 - Train Loss: 0.078499, Train Acc: 0.884615 | Val Loss: 0.107519, Val Acc: 0.783505\n",
      "Epoch 20085 - Train Loss: 0.078497, Train Acc: 0.884615 | Val Loss: 0.107519, Val Acc: 0.783505\n",
      "Epoch 20086 - Train Loss: 0.078495, Train Acc: 0.884615 | Val Loss: 0.107518, Val Acc: 0.783505\n",
      "Epoch 20087 - Train Loss: 0.078493, Train Acc: 0.884615 | Val Loss: 0.107517, Val Acc: 0.783505\n",
      "Epoch 20088 - Train Loss: 0.078491, Train Acc: 0.884615 | Val Loss: 0.107516, Val Acc: 0.783505\n",
      "Epoch 20089 - Train Loss: 0.078489, Train Acc: 0.884615 | Val Loss: 0.107515, Val Acc: 0.783505\n",
      "Epoch 20090 - Train Loss: 0.078487, Train Acc: 0.884615 | Val Loss: 0.107514, Val Acc: 0.783505\n",
      "Epoch 20091 - Train Loss: 0.078485, Train Acc: 0.884615 | Val Loss: 0.107513, Val Acc: 0.783505\n",
      "Epoch 20092 - Train Loss: 0.078482, Train Acc: 0.884615 | Val Loss: 0.107513, Val Acc: 0.783505\n",
      "Epoch 20093 - Train Loss: 0.078480, Train Acc: 0.884615 | Val Loss: 0.107512, Val Acc: 0.783505\n",
      "Epoch 20094 - Train Loss: 0.078478, Train Acc: 0.884615 | Val Loss: 0.107511, Val Acc: 0.783505\n",
      "Epoch 20095 - Train Loss: 0.078476, Train Acc: 0.884615 | Val Loss: 0.107510, Val Acc: 0.783505\n",
      "Epoch 20096 - Train Loss: 0.078474, Train Acc: 0.884615 | Val Loss: 0.107509, Val Acc: 0.783505\n",
      "Epoch 20097 - Train Loss: 0.078472, Train Acc: 0.884615 | Val Loss: 0.107508, Val Acc: 0.783505\n",
      "Epoch 20098 - Train Loss: 0.078470, Train Acc: 0.884615 | Val Loss: 0.107507, Val Acc: 0.783505\n",
      "Epoch 20099 - Train Loss: 0.078468, Train Acc: 0.884615 | Val Loss: 0.107506, Val Acc: 0.783505\n",
      "Epoch 20100 - Train Loss: 0.078466, Train Acc: 0.884615 | Val Loss: 0.107506, Val Acc: 0.783505\n",
      "Epoch 20101 - Train Loss: 0.078463, Train Acc: 0.884615 | Val Loss: 0.107505, Val Acc: 0.783505\n",
      "Epoch 20102 - Train Loss: 0.078461, Train Acc: 0.884615 | Val Loss: 0.107504, Val Acc: 0.783505\n",
      "Epoch 20103 - Train Loss: 0.078459, Train Acc: 0.884615 | Val Loss: 0.107503, Val Acc: 0.783505\n",
      "Epoch 20104 - Train Loss: 0.078457, Train Acc: 0.884615 | Val Loss: 0.107502, Val Acc: 0.783505\n",
      "Epoch 20105 - Train Loss: 0.078455, Train Acc: 0.884615 | Val Loss: 0.107501, Val Acc: 0.783505\n",
      "Epoch 20106 - Train Loss: 0.078453, Train Acc: 0.884615 | Val Loss: 0.107500, Val Acc: 0.783505\n",
      "Epoch 20107 - Train Loss: 0.078451, Train Acc: 0.884615 | Val Loss: 0.107499, Val Acc: 0.783505\n",
      "Epoch 20108 - Train Loss: 0.078449, Train Acc: 0.884615 | Val Loss: 0.107499, Val Acc: 0.783505\n",
      "Epoch 20109 - Train Loss: 0.078447, Train Acc: 0.884615 | Val Loss: 0.107498, Val Acc: 0.783505\n",
      "Epoch 20110 - Train Loss: 0.078444, Train Acc: 0.884615 | Val Loss: 0.107497, Val Acc: 0.783505\n",
      "Epoch 20111 - Train Loss: 0.078442, Train Acc: 0.884615 | Val Loss: 0.107496, Val Acc: 0.783505\n",
      "Epoch 20112 - Train Loss: 0.078440, Train Acc: 0.884615 | Val Loss: 0.107495, Val Acc: 0.783505\n",
      "Epoch 20113 - Train Loss: 0.078438, Train Acc: 0.884615 | Val Loss: 0.107494, Val Acc: 0.783505\n",
      "Epoch 20114 - Train Loss: 0.078436, Train Acc: 0.884615 | Val Loss: 0.107493, Val Acc: 0.783505\n",
      "Epoch 20115 - Train Loss: 0.078434, Train Acc: 0.884615 | Val Loss: 0.107492, Val Acc: 0.783505\n",
      "Epoch 20116 - Train Loss: 0.078432, Train Acc: 0.884615 | Val Loss: 0.107492, Val Acc: 0.783505\n",
      "Epoch 20117 - Train Loss: 0.078430, Train Acc: 0.884615 | Val Loss: 0.107491, Val Acc: 0.783505\n",
      "Epoch 20118 - Train Loss: 0.078428, Train Acc: 0.884615 | Val Loss: 0.107490, Val Acc: 0.783505\n",
      "Epoch 20119 - Train Loss: 0.078425, Train Acc: 0.884615 | Val Loss: 0.107489, Val Acc: 0.783505\n",
      "Epoch 20120 - Train Loss: 0.078423, Train Acc: 0.884615 | Val Loss: 0.107488, Val Acc: 0.783505\n",
      "Epoch 20121 - Train Loss: 0.078421, Train Acc: 0.884615 | Val Loss: 0.107487, Val Acc: 0.783505\n",
      "Epoch 20122 - Train Loss: 0.078419, Train Acc: 0.884615 | Val Loss: 0.107486, Val Acc: 0.783505\n",
      "Epoch 20123 - Train Loss: 0.078417, Train Acc: 0.884615 | Val Loss: 0.107485, Val Acc: 0.783505\n",
      "Epoch 20124 - Train Loss: 0.078415, Train Acc: 0.884615 | Val Loss: 0.107485, Val Acc: 0.783505\n",
      "Epoch 20125 - Train Loss: 0.078413, Train Acc: 0.884615 | Val Loss: 0.107484, Val Acc: 0.783505\n",
      "Epoch 20126 - Train Loss: 0.078411, Train Acc: 0.884615 | Val Loss: 0.107483, Val Acc: 0.783505\n",
      "Epoch 20127 - Train Loss: 0.078409, Train Acc: 0.884615 | Val Loss: 0.107482, Val Acc: 0.783505\n",
      "Epoch 20128 - Train Loss: 0.078407, Train Acc: 0.884615 | Val Loss: 0.107481, Val Acc: 0.783505\n",
      "Epoch 20129 - Train Loss: 0.078404, Train Acc: 0.884615 | Val Loss: 0.107480, Val Acc: 0.783505\n",
      "Epoch 20130 - Train Loss: 0.078402, Train Acc: 0.884615 | Val Loss: 0.107479, Val Acc: 0.783505\n",
      "Epoch 20131 - Train Loss: 0.078400, Train Acc: 0.884615 | Val Loss: 0.107479, Val Acc: 0.783505\n",
      "Epoch 20132 - Train Loss: 0.078398, Train Acc: 0.884615 | Val Loss: 0.107478, Val Acc: 0.783505\n",
      "Epoch 20133 - Train Loss: 0.078396, Train Acc: 0.884615 | Val Loss: 0.107477, Val Acc: 0.783505\n",
      "Epoch 20134 - Train Loss: 0.078394, Train Acc: 0.884615 | Val Loss: 0.107476, Val Acc: 0.783505\n",
      "Epoch 20135 - Train Loss: 0.078392, Train Acc: 0.884615 | Val Loss: 0.107475, Val Acc: 0.783505\n",
      "Epoch 20136 - Train Loss: 0.078390, Train Acc: 0.884615 | Val Loss: 0.107474, Val Acc: 0.783505\n",
      "Epoch 20137 - Train Loss: 0.078388, Train Acc: 0.884615 | Val Loss: 0.107473, Val Acc: 0.783505\n",
      "Epoch 20138 - Train Loss: 0.078385, Train Acc: 0.884615 | Val Loss: 0.107473, Val Acc: 0.783505\n",
      "Epoch 20139 - Train Loss: 0.078383, Train Acc: 0.884615 | Val Loss: 0.107472, Val Acc: 0.783505\n",
      "Epoch 20140 - Train Loss: 0.078381, Train Acc: 0.885897 | Val Loss: 0.107471, Val Acc: 0.783505\n",
      "Epoch 20141 - Train Loss: 0.078379, Train Acc: 0.885897 | Val Loss: 0.107470, Val Acc: 0.783505\n",
      "Epoch 20142 - Train Loss: 0.078377, Train Acc: 0.885897 | Val Loss: 0.107469, Val Acc: 0.783505\n",
      "Epoch 20143 - Train Loss: 0.078375, Train Acc: 0.885897 | Val Loss: 0.107468, Val Acc: 0.783505\n",
      "Epoch 20144 - Train Loss: 0.078373, Train Acc: 0.885897 | Val Loss: 0.107467, Val Acc: 0.783505\n",
      "Epoch 20145 - Train Loss: 0.078371, Train Acc: 0.885897 | Val Loss: 0.107466, Val Acc: 0.783505\n",
      "Epoch 20146 - Train Loss: 0.078369, Train Acc: 0.885897 | Val Loss: 0.107466, Val Acc: 0.783505\n",
      "Epoch 20147 - Train Loss: 0.078367, Train Acc: 0.885897 | Val Loss: 0.107465, Val Acc: 0.783505\n",
      "Epoch 20148 - Train Loss: 0.078364, Train Acc: 0.885897 | Val Loss: 0.107464, Val Acc: 0.783505\n",
      "Epoch 20149 - Train Loss: 0.078362, Train Acc: 0.885897 | Val Loss: 0.107463, Val Acc: 0.783505\n",
      "Epoch 20150 - Train Loss: 0.078360, Train Acc: 0.885897 | Val Loss: 0.107462, Val Acc: 0.783505\n",
      "Epoch 20151 - Train Loss: 0.078358, Train Acc: 0.885897 | Val Loss: 0.107461, Val Acc: 0.783505\n",
      "Epoch 20152 - Train Loss: 0.078356, Train Acc: 0.885897 | Val Loss: 0.107460, Val Acc: 0.783505\n",
      "Epoch 20153 - Train Loss: 0.078354, Train Acc: 0.885897 | Val Loss: 0.107460, Val Acc: 0.783505\n",
      "Epoch 20154 - Train Loss: 0.078352, Train Acc: 0.885897 | Val Loss: 0.107459, Val Acc: 0.783505\n",
      "Epoch 20155 - Train Loss: 0.078350, Train Acc: 0.885897 | Val Loss: 0.107458, Val Acc: 0.783505\n",
      "Epoch 20156 - Train Loss: 0.078348, Train Acc: 0.885897 | Val Loss: 0.107457, Val Acc: 0.783505\n",
      "Epoch 20157 - Train Loss: 0.078346, Train Acc: 0.885897 | Val Loss: 0.107456, Val Acc: 0.783505\n",
      "Epoch 20158 - Train Loss: 0.078343, Train Acc: 0.885897 | Val Loss: 0.107455, Val Acc: 0.783505\n",
      "Epoch 20159 - Train Loss: 0.078341, Train Acc: 0.885897 | Val Loss: 0.107455, Val Acc: 0.783505\n",
      "Epoch 20160 - Train Loss: 0.078339, Train Acc: 0.885897 | Val Loss: 0.107454, Val Acc: 0.783505\n",
      "Epoch 20161 - Train Loss: 0.078337, Train Acc: 0.885897 | Val Loss: 0.107453, Val Acc: 0.783505\n",
      "Epoch 20162 - Train Loss: 0.078335, Train Acc: 0.885897 | Val Loss: 0.107452, Val Acc: 0.783505\n",
      "Epoch 20163 - Train Loss: 0.078333, Train Acc: 0.885897 | Val Loss: 0.107451, Val Acc: 0.783505\n",
      "Epoch 20164 - Train Loss: 0.078331, Train Acc: 0.885897 | Val Loss: 0.107450, Val Acc: 0.783505\n",
      "Epoch 20165 - Train Loss: 0.078329, Train Acc: 0.885897 | Val Loss: 0.107449, Val Acc: 0.783505\n",
      "Epoch 20166 - Train Loss: 0.078327, Train Acc: 0.885897 | Val Loss: 0.107448, Val Acc: 0.783505\n",
      "Epoch 20167 - Train Loss: 0.078325, Train Acc: 0.885897 | Val Loss: 0.107448, Val Acc: 0.783505\n",
      "Epoch 20168 - Train Loss: 0.078322, Train Acc: 0.885897 | Val Loss: 0.107447, Val Acc: 0.783505\n",
      "Epoch 20169 - Train Loss: 0.078320, Train Acc: 0.885897 | Val Loss: 0.107446, Val Acc: 0.783505\n",
      "Epoch 20170 - Train Loss: 0.078318, Train Acc: 0.885897 | Val Loss: 0.107445, Val Acc: 0.783505\n",
      "Epoch 20171 - Train Loss: 0.078316, Train Acc: 0.885897 | Val Loss: 0.107444, Val Acc: 0.783505\n",
      "Epoch 20172 - Train Loss: 0.078314, Train Acc: 0.885897 | Val Loss: 0.107443, Val Acc: 0.783505\n",
      "Epoch 20173 - Train Loss: 0.078312, Train Acc: 0.885897 | Val Loss: 0.107442, Val Acc: 0.783505\n",
      "Epoch 20174 - Train Loss: 0.078310, Train Acc: 0.885897 | Val Loss: 0.107442, Val Acc: 0.783505\n",
      "Epoch 20175 - Train Loss: 0.078308, Train Acc: 0.885897 | Val Loss: 0.107441, Val Acc: 0.783505\n",
      "Epoch 20176 - Train Loss: 0.078306, Train Acc: 0.885897 | Val Loss: 0.107440, Val Acc: 0.783505\n",
      "Epoch 20177 - Train Loss: 0.078304, Train Acc: 0.885897 | Val Loss: 0.107439, Val Acc: 0.783505\n",
      "Epoch 20178 - Train Loss: 0.078302, Train Acc: 0.885897 | Val Loss: 0.107438, Val Acc: 0.783505\n",
      "Epoch 20179 - Train Loss: 0.078299, Train Acc: 0.885897 | Val Loss: 0.107437, Val Acc: 0.783505\n",
      "Epoch 20180 - Train Loss: 0.078297, Train Acc: 0.885897 | Val Loss: 0.107436, Val Acc: 0.783505\n",
      "Epoch 20181 - Train Loss: 0.078295, Train Acc: 0.885897 | Val Loss: 0.107436, Val Acc: 0.783505\n",
      "Epoch 20182 - Train Loss: 0.078293, Train Acc: 0.885897 | Val Loss: 0.107435, Val Acc: 0.783505\n",
      "Epoch 20183 - Train Loss: 0.078291, Train Acc: 0.885897 | Val Loss: 0.107434, Val Acc: 0.783505\n",
      "Epoch 20184 - Train Loss: 0.078289, Train Acc: 0.885897 | Val Loss: 0.107433, Val Acc: 0.783505\n",
      "Epoch 20185 - Train Loss: 0.078287, Train Acc: 0.885897 | Val Loss: 0.107432, Val Acc: 0.783505\n",
      "Epoch 20186 - Train Loss: 0.078285, Train Acc: 0.885897 | Val Loss: 0.107431, Val Acc: 0.783505\n",
      "Epoch 20187 - Train Loss: 0.078283, Train Acc: 0.885897 | Val Loss: 0.107430, Val Acc: 0.783505\n",
      "Epoch 20188 - Train Loss: 0.078281, Train Acc: 0.885897 | Val Loss: 0.107430, Val Acc: 0.783505\n",
      "Epoch 20189 - Train Loss: 0.078279, Train Acc: 0.885897 | Val Loss: 0.107429, Val Acc: 0.783505\n",
      "Epoch 20190 - Train Loss: 0.078276, Train Acc: 0.885897 | Val Loss: 0.107428, Val Acc: 0.783505\n",
      "Epoch 20191 - Train Loss: 0.078274, Train Acc: 0.885897 | Val Loss: 0.107427, Val Acc: 0.783505\n",
      "Epoch 20192 - Train Loss: 0.078272, Train Acc: 0.885897 | Val Loss: 0.107426, Val Acc: 0.783505\n",
      "Epoch 20193 - Train Loss: 0.078270, Train Acc: 0.885897 | Val Loss: 0.107425, Val Acc: 0.783505\n",
      "Epoch 20194 - Train Loss: 0.078268, Train Acc: 0.885897 | Val Loss: 0.107424, Val Acc: 0.783505\n",
      "Epoch 20195 - Train Loss: 0.078266, Train Acc: 0.885897 | Val Loss: 0.107424, Val Acc: 0.783505\n",
      "Epoch 20196 - Train Loss: 0.078264, Train Acc: 0.885897 | Val Loss: 0.107423, Val Acc: 0.783505\n",
      "Epoch 20197 - Train Loss: 0.078262, Train Acc: 0.885897 | Val Loss: 0.107422, Val Acc: 0.783505\n",
      "Epoch 20198 - Train Loss: 0.078260, Train Acc: 0.885897 | Val Loss: 0.107421, Val Acc: 0.783505\n",
      "Epoch 20199 - Train Loss: 0.078258, Train Acc: 0.885897 | Val Loss: 0.107420, Val Acc: 0.783505\n",
      "Epoch 20200 - Train Loss: 0.078256, Train Acc: 0.885897 | Val Loss: 0.107419, Val Acc: 0.783505\n",
      "Epoch 20201 - Train Loss: 0.078253, Train Acc: 0.885897 | Val Loss: 0.107418, Val Acc: 0.783505\n",
      "Epoch 20202 - Train Loss: 0.078251, Train Acc: 0.885897 | Val Loss: 0.107418, Val Acc: 0.783505\n",
      "Epoch 20203 - Train Loss: 0.078249, Train Acc: 0.885897 | Val Loss: 0.107417, Val Acc: 0.783505\n",
      "Epoch 20204 - Train Loss: 0.078247, Train Acc: 0.885897 | Val Loss: 0.107416, Val Acc: 0.783505\n",
      "Epoch 20205 - Train Loss: 0.078245, Train Acc: 0.885897 | Val Loss: 0.107415, Val Acc: 0.783505\n",
      "Epoch 20206 - Train Loss: 0.078243, Train Acc: 0.885897 | Val Loss: 0.107414, Val Acc: 0.783505\n",
      "Epoch 20207 - Train Loss: 0.078241, Train Acc: 0.885897 | Val Loss: 0.107413, Val Acc: 0.783505\n",
      "Epoch 20208 - Train Loss: 0.078239, Train Acc: 0.885897 | Val Loss: 0.107413, Val Acc: 0.783505\n",
      "Epoch 20209 - Train Loss: 0.078237, Train Acc: 0.885897 | Val Loss: 0.107412, Val Acc: 0.783505\n",
      "Epoch 20210 - Train Loss: 0.078235, Train Acc: 0.885897 | Val Loss: 0.107411, Val Acc: 0.783505\n",
      "Epoch 20211 - Train Loss: 0.078233, Train Acc: 0.885897 | Val Loss: 0.107410, Val Acc: 0.783505\n",
      "Epoch 20212 - Train Loss: 0.078230, Train Acc: 0.885897 | Val Loss: 0.107409, Val Acc: 0.783505\n",
      "Epoch 20213 - Train Loss: 0.078228, Train Acc: 0.885897 | Val Loss: 0.107408, Val Acc: 0.783505\n",
      "Epoch 20214 - Train Loss: 0.078226, Train Acc: 0.885897 | Val Loss: 0.107407, Val Acc: 0.783505\n",
      "Epoch 20215 - Train Loss: 0.078224, Train Acc: 0.885897 | Val Loss: 0.107407, Val Acc: 0.783505\n",
      "Epoch 20216 - Train Loss: 0.078222, Train Acc: 0.885897 | Val Loss: 0.107406, Val Acc: 0.783505\n",
      "Epoch 20217 - Train Loss: 0.078220, Train Acc: 0.885897 | Val Loss: 0.107405, Val Acc: 0.783505\n",
      "Epoch 20218 - Train Loss: 0.078218, Train Acc: 0.885897 | Val Loss: 0.107404, Val Acc: 0.783505\n",
      "Epoch 20219 - Train Loss: 0.078216, Train Acc: 0.885897 | Val Loss: 0.107403, Val Acc: 0.783505\n",
      "Epoch 20220 - Train Loss: 0.078214, Train Acc: 0.885897 | Val Loss: 0.107402, Val Acc: 0.783505\n",
      "Epoch 20221 - Train Loss: 0.078212, Train Acc: 0.885897 | Val Loss: 0.107402, Val Acc: 0.783505\n",
      "Epoch 20222 - Train Loss: 0.078210, Train Acc: 0.885897 | Val Loss: 0.107401, Val Acc: 0.783505\n",
      "Epoch 20223 - Train Loss: 0.078208, Train Acc: 0.885897 | Val Loss: 0.107400, Val Acc: 0.783505\n",
      "Epoch 20224 - Train Loss: 0.078205, Train Acc: 0.885897 | Val Loss: 0.107399, Val Acc: 0.783505\n",
      "Epoch 20225 - Train Loss: 0.078203, Train Acc: 0.885897 | Val Loss: 0.107398, Val Acc: 0.783505\n",
      "Epoch 20226 - Train Loss: 0.078201, Train Acc: 0.885897 | Val Loss: 0.107397, Val Acc: 0.783505\n",
      "Epoch 20227 - Train Loss: 0.078199, Train Acc: 0.885897 | Val Loss: 0.107396, Val Acc: 0.783505\n",
      "Epoch 20228 - Train Loss: 0.078197, Train Acc: 0.885897 | Val Loss: 0.107396, Val Acc: 0.783505\n",
      "Epoch 20229 - Train Loss: 0.078195, Train Acc: 0.885897 | Val Loss: 0.107395, Val Acc: 0.783505\n",
      "Epoch 20230 - Train Loss: 0.078193, Train Acc: 0.885897 | Val Loss: 0.107394, Val Acc: 0.783505\n",
      "Epoch 20231 - Train Loss: 0.078191, Train Acc: 0.885897 | Val Loss: 0.107393, Val Acc: 0.783505\n",
      "Epoch 20232 - Train Loss: 0.078189, Train Acc: 0.885897 | Val Loss: 0.107392, Val Acc: 0.783505\n",
      "Epoch 20233 - Train Loss: 0.078187, Train Acc: 0.885897 | Val Loss: 0.107391, Val Acc: 0.783505\n",
      "Epoch 20234 - Train Loss: 0.078185, Train Acc: 0.885897 | Val Loss: 0.107391, Val Acc: 0.783505\n",
      "Epoch 20235 - Train Loss: 0.078183, Train Acc: 0.885897 | Val Loss: 0.107390, Val Acc: 0.783505\n",
      "Epoch 20236 - Train Loss: 0.078180, Train Acc: 0.885897 | Val Loss: 0.107389, Val Acc: 0.783505\n",
      "Epoch 20237 - Train Loss: 0.078178, Train Acc: 0.885897 | Val Loss: 0.107388, Val Acc: 0.783505\n",
      "Epoch 20238 - Train Loss: 0.078176, Train Acc: 0.885897 | Val Loss: 0.107387, Val Acc: 0.783505\n",
      "Epoch 20239 - Train Loss: 0.078174, Train Acc: 0.885897 | Val Loss: 0.107386, Val Acc: 0.783505\n",
      "Epoch 20240 - Train Loss: 0.078172, Train Acc: 0.885897 | Val Loss: 0.107385, Val Acc: 0.783505\n",
      "Epoch 20241 - Train Loss: 0.078170, Train Acc: 0.885897 | Val Loss: 0.107385, Val Acc: 0.783505\n",
      "Epoch 20242 - Train Loss: 0.078168, Train Acc: 0.885897 | Val Loss: 0.107384, Val Acc: 0.783505\n",
      "Epoch 20243 - Train Loss: 0.078166, Train Acc: 0.885897 | Val Loss: 0.107383, Val Acc: 0.783505\n",
      "Epoch 20244 - Train Loss: 0.078164, Train Acc: 0.885897 | Val Loss: 0.107382, Val Acc: 0.783505\n",
      "Epoch 20245 - Train Loss: 0.078162, Train Acc: 0.885897 | Val Loss: 0.107381, Val Acc: 0.783505\n",
      "Epoch 20246 - Train Loss: 0.078160, Train Acc: 0.885897 | Val Loss: 0.107380, Val Acc: 0.783505\n",
      "Epoch 20247 - Train Loss: 0.078158, Train Acc: 0.885897 | Val Loss: 0.107380, Val Acc: 0.783505\n",
      "Epoch 20248 - Train Loss: 0.078155, Train Acc: 0.885897 | Val Loss: 0.107379, Val Acc: 0.783505\n",
      "Epoch 20249 - Train Loss: 0.078153, Train Acc: 0.885897 | Val Loss: 0.107378, Val Acc: 0.783505\n",
      "Epoch 20250 - Train Loss: 0.078151, Train Acc: 0.885897 | Val Loss: 0.107377, Val Acc: 0.783505\n",
      "Epoch 20251 - Train Loss: 0.078149, Train Acc: 0.885897 | Val Loss: 0.107376, Val Acc: 0.783505\n",
      "Epoch 20252 - Train Loss: 0.078147, Train Acc: 0.885897 | Val Loss: 0.107375, Val Acc: 0.783505\n",
      "Epoch 20253 - Train Loss: 0.078145, Train Acc: 0.885897 | Val Loss: 0.107375, Val Acc: 0.783505\n",
      "Epoch 20254 - Train Loss: 0.078143, Train Acc: 0.885897 | Val Loss: 0.107374, Val Acc: 0.783505\n",
      "Epoch 20255 - Train Loss: 0.078141, Train Acc: 0.885897 | Val Loss: 0.107373, Val Acc: 0.783505\n",
      "Epoch 20256 - Train Loss: 0.078139, Train Acc: 0.885897 | Val Loss: 0.107372, Val Acc: 0.783505\n",
      "Epoch 20257 - Train Loss: 0.078137, Train Acc: 0.885897 | Val Loss: 0.107371, Val Acc: 0.783505\n",
      "Epoch 20258 - Train Loss: 0.078135, Train Acc: 0.885897 | Val Loss: 0.107370, Val Acc: 0.783505\n",
      "Epoch 20259 - Train Loss: 0.078133, Train Acc: 0.885897 | Val Loss: 0.107369, Val Acc: 0.783505\n",
      "Epoch 20260 - Train Loss: 0.078131, Train Acc: 0.885897 | Val Loss: 0.107369, Val Acc: 0.783505\n",
      "Epoch 20261 - Train Loss: 0.078128, Train Acc: 0.885897 | Val Loss: 0.107368, Val Acc: 0.783505\n",
      "Epoch 20262 - Train Loss: 0.078126, Train Acc: 0.885897 | Val Loss: 0.107367, Val Acc: 0.783505\n",
      "Epoch 20263 - Train Loss: 0.078124, Train Acc: 0.885897 | Val Loss: 0.107366, Val Acc: 0.783505\n",
      "Epoch 20264 - Train Loss: 0.078122, Train Acc: 0.885897 | Val Loss: 0.107365, Val Acc: 0.783505\n",
      "Epoch 20265 - Train Loss: 0.078120, Train Acc: 0.885897 | Val Loss: 0.107364, Val Acc: 0.783505\n",
      "Epoch 20266 - Train Loss: 0.078118, Train Acc: 0.885897 | Val Loss: 0.107363, Val Acc: 0.783505\n",
      "Epoch 20267 - Train Loss: 0.078116, Train Acc: 0.885897 | Val Loss: 0.107363, Val Acc: 0.783505\n",
      "Epoch 20268 - Train Loss: 0.078114, Train Acc: 0.885897 | Val Loss: 0.107362, Val Acc: 0.783505\n",
      "Epoch 20269 - Train Loss: 0.078112, Train Acc: 0.885897 | Val Loss: 0.107361, Val Acc: 0.783505\n",
      "Epoch 20270 - Train Loss: 0.078110, Train Acc: 0.885897 | Val Loss: 0.107360, Val Acc: 0.783505\n",
      "Epoch 20271 - Train Loss: 0.078108, Train Acc: 0.885897 | Val Loss: 0.107359, Val Acc: 0.783505\n",
      "Epoch 20272 - Train Loss: 0.078106, Train Acc: 0.885897 | Val Loss: 0.107359, Val Acc: 0.783505\n",
      "Epoch 20273 - Train Loss: 0.078104, Train Acc: 0.885897 | Val Loss: 0.107358, Val Acc: 0.783505\n",
      "Epoch 20274 - Train Loss: 0.078101, Train Acc: 0.885897 | Val Loss: 0.107357, Val Acc: 0.783505\n",
      "Epoch 20275 - Train Loss: 0.078099, Train Acc: 0.885897 | Val Loss: 0.107356, Val Acc: 0.783505\n",
      "Epoch 20276 - Train Loss: 0.078097, Train Acc: 0.885897 | Val Loss: 0.107355, Val Acc: 0.783505\n",
      "Epoch 20277 - Train Loss: 0.078095, Train Acc: 0.885897 | Val Loss: 0.107354, Val Acc: 0.783505\n",
      "Epoch 20278 - Train Loss: 0.078093, Train Acc: 0.885897 | Val Loss: 0.107354, Val Acc: 0.783505\n",
      "Epoch 20279 - Train Loss: 0.078091, Train Acc: 0.885897 | Val Loss: 0.107353, Val Acc: 0.783505\n",
      "Epoch 20280 - Train Loss: 0.078089, Train Acc: 0.885897 | Val Loss: 0.107352, Val Acc: 0.783505\n",
      "Epoch 20281 - Train Loss: 0.078087, Train Acc: 0.885897 | Val Loss: 0.107351, Val Acc: 0.783505\n",
      "Epoch 20282 - Train Loss: 0.078085, Train Acc: 0.885897 | Val Loss: 0.107350, Val Acc: 0.783505\n",
      "Epoch 20283 - Train Loss: 0.078083, Train Acc: 0.885897 | Val Loss: 0.107349, Val Acc: 0.783505\n",
      "Epoch 20284 - Train Loss: 0.078081, Train Acc: 0.885897 | Val Loss: 0.107348, Val Acc: 0.783505\n",
      "Epoch 20285 - Train Loss: 0.078079, Train Acc: 0.885897 | Val Loss: 0.107348, Val Acc: 0.783505\n",
      "Epoch 20286 - Train Loss: 0.078077, Train Acc: 0.885897 | Val Loss: 0.107347, Val Acc: 0.783505\n",
      "Epoch 20287 - Train Loss: 0.078075, Train Acc: 0.885897 | Val Loss: 0.107346, Val Acc: 0.783505\n",
      "Epoch 20288 - Train Loss: 0.078072, Train Acc: 0.885897 | Val Loss: 0.107345, Val Acc: 0.783505\n",
      "Epoch 20289 - Train Loss: 0.078070, Train Acc: 0.885897 | Val Loss: 0.107344, Val Acc: 0.783505\n",
      "Epoch 20290 - Train Loss: 0.078068, Train Acc: 0.885897 | Val Loss: 0.107343, Val Acc: 0.783505\n",
      "Epoch 20291 - Train Loss: 0.078066, Train Acc: 0.885897 | Val Loss: 0.107343, Val Acc: 0.783505\n",
      "Epoch 20292 - Train Loss: 0.078064, Train Acc: 0.885897 | Val Loss: 0.107342, Val Acc: 0.783505\n",
      "Epoch 20293 - Train Loss: 0.078062, Train Acc: 0.885897 | Val Loss: 0.107341, Val Acc: 0.783505\n",
      "Epoch 20294 - Train Loss: 0.078060, Train Acc: 0.885897 | Val Loss: 0.107340, Val Acc: 0.783505\n",
      "Epoch 20295 - Train Loss: 0.078058, Train Acc: 0.885897 | Val Loss: 0.107339, Val Acc: 0.783505\n",
      "Epoch 20296 - Train Loss: 0.078056, Train Acc: 0.885897 | Val Loss: 0.107338, Val Acc: 0.783505\n",
      "Epoch 20297 - Train Loss: 0.078054, Train Acc: 0.885897 | Val Loss: 0.107338, Val Acc: 0.783505\n",
      "Epoch 20298 - Train Loss: 0.078052, Train Acc: 0.885897 | Val Loss: 0.107337, Val Acc: 0.783505\n",
      "Epoch 20299 - Train Loss: 0.078050, Train Acc: 0.885897 | Val Loss: 0.107336, Val Acc: 0.783505\n",
      "Epoch 20300 - Train Loss: 0.078048, Train Acc: 0.885897 | Val Loss: 0.107335, Val Acc: 0.783505\n",
      "Epoch 20301 - Train Loss: 0.078046, Train Acc: 0.885897 | Val Loss: 0.107334, Val Acc: 0.783505\n",
      "Epoch 20302 - Train Loss: 0.078043, Train Acc: 0.885897 | Val Loss: 0.107333, Val Acc: 0.783505\n",
      "Epoch 20303 - Train Loss: 0.078041, Train Acc: 0.885897 | Val Loss: 0.107333, Val Acc: 0.783505\n",
      "Epoch 20304 - Train Loss: 0.078039, Train Acc: 0.885897 | Val Loss: 0.107332, Val Acc: 0.783505\n",
      "Epoch 20305 - Train Loss: 0.078037, Train Acc: 0.885897 | Val Loss: 0.107331, Val Acc: 0.783505\n",
      "Epoch 20306 - Train Loss: 0.078035, Train Acc: 0.885897 | Val Loss: 0.107330, Val Acc: 0.783505\n",
      "Epoch 20307 - Train Loss: 0.078033, Train Acc: 0.885897 | Val Loss: 0.107329, Val Acc: 0.783505\n",
      "Epoch 20308 - Train Loss: 0.078031, Train Acc: 0.885897 | Val Loss: 0.107328, Val Acc: 0.783505\n",
      "Epoch 20309 - Train Loss: 0.078029, Train Acc: 0.885897 | Val Loss: 0.107328, Val Acc: 0.783505\n",
      "Epoch 20310 - Train Loss: 0.078027, Train Acc: 0.885897 | Val Loss: 0.107327, Val Acc: 0.783505\n",
      "Epoch 20311 - Train Loss: 0.078025, Train Acc: 0.885897 | Val Loss: 0.107326, Val Acc: 0.783505\n",
      "Epoch 20312 - Train Loss: 0.078023, Train Acc: 0.885897 | Val Loss: 0.107325, Val Acc: 0.783505\n",
      "Epoch 20313 - Train Loss: 0.078021, Train Acc: 0.885897 | Val Loss: 0.107324, Val Acc: 0.783505\n",
      "Epoch 20314 - Train Loss: 0.078019, Train Acc: 0.885897 | Val Loss: 0.107323, Val Acc: 0.783505\n",
      "Epoch 20315 - Train Loss: 0.078017, Train Acc: 0.885897 | Val Loss: 0.107323, Val Acc: 0.783505\n",
      "Epoch 20316 - Train Loss: 0.078015, Train Acc: 0.885897 | Val Loss: 0.107322, Val Acc: 0.783505\n",
      "Epoch 20317 - Train Loss: 0.078012, Train Acc: 0.885897 | Val Loss: 0.107321, Val Acc: 0.783505\n",
      "Epoch 20318 - Train Loss: 0.078010, Train Acc: 0.885897 | Val Loss: 0.107320, Val Acc: 0.783505\n",
      "Epoch 20319 - Train Loss: 0.078008, Train Acc: 0.885897 | Val Loss: 0.107319, Val Acc: 0.783505\n",
      "Epoch 20320 - Train Loss: 0.078006, Train Acc: 0.885897 | Val Loss: 0.107319, Val Acc: 0.783505\n",
      "Epoch 20321 - Train Loss: 0.078004, Train Acc: 0.885897 | Val Loss: 0.107318, Val Acc: 0.783505\n",
      "Epoch 20322 - Train Loss: 0.078002, Train Acc: 0.885897 | Val Loss: 0.107317, Val Acc: 0.783505\n",
      "Epoch 20323 - Train Loss: 0.078000, Train Acc: 0.885897 | Val Loss: 0.107316, Val Acc: 0.783505\n",
      "Epoch 20324 - Train Loss: 0.077998, Train Acc: 0.885897 | Val Loss: 0.107315, Val Acc: 0.783505\n",
      "Epoch 20325 - Train Loss: 0.077996, Train Acc: 0.885897 | Val Loss: 0.107314, Val Acc: 0.783505\n",
      "Epoch 20326 - Train Loss: 0.077994, Train Acc: 0.885897 | Val Loss: 0.107314, Val Acc: 0.783505\n",
      "Epoch 20327 - Train Loss: 0.077992, Train Acc: 0.885897 | Val Loss: 0.107313, Val Acc: 0.783505\n",
      "Epoch 20328 - Train Loss: 0.077990, Train Acc: 0.885897 | Val Loss: 0.107312, Val Acc: 0.783505\n",
      "Epoch 20329 - Train Loss: 0.077988, Train Acc: 0.885897 | Val Loss: 0.107311, Val Acc: 0.783505\n",
      "Epoch 20330 - Train Loss: 0.077986, Train Acc: 0.885897 | Val Loss: 0.107310, Val Acc: 0.783505\n",
      "Epoch 20331 - Train Loss: 0.077984, Train Acc: 0.885897 | Val Loss: 0.107309, Val Acc: 0.783505\n",
      "Epoch 20332 - Train Loss: 0.077982, Train Acc: 0.885897 | Val Loss: 0.107309, Val Acc: 0.783505\n",
      "Epoch 20333 - Train Loss: 0.077979, Train Acc: 0.885897 | Val Loss: 0.107308, Val Acc: 0.783505\n",
      "Epoch 20334 - Train Loss: 0.077977, Train Acc: 0.885897 | Val Loss: 0.107307, Val Acc: 0.783505\n",
      "Epoch 20335 - Train Loss: 0.077975, Train Acc: 0.885897 | Val Loss: 0.107306, Val Acc: 0.783505\n",
      "Epoch 20336 - Train Loss: 0.077973, Train Acc: 0.885897 | Val Loss: 0.107305, Val Acc: 0.783505\n",
      "Epoch 20337 - Train Loss: 0.077971, Train Acc: 0.885897 | Val Loss: 0.107304, Val Acc: 0.783505\n",
      "Epoch 20338 - Train Loss: 0.077969, Train Acc: 0.885897 | Val Loss: 0.107304, Val Acc: 0.783505\n",
      "Epoch 20339 - Train Loss: 0.077967, Train Acc: 0.885897 | Val Loss: 0.107303, Val Acc: 0.783505\n",
      "Epoch 20340 - Train Loss: 0.077965, Train Acc: 0.885897 | Val Loss: 0.107302, Val Acc: 0.783505\n",
      "Epoch 20341 - Train Loss: 0.077963, Train Acc: 0.885897 | Val Loss: 0.107301, Val Acc: 0.783505\n",
      "Epoch 20342 - Train Loss: 0.077961, Train Acc: 0.885897 | Val Loss: 0.107300, Val Acc: 0.783505\n",
      "Epoch 20343 - Train Loss: 0.077959, Train Acc: 0.885897 | Val Loss: 0.107299, Val Acc: 0.793814\n",
      "Epoch 20344 - Train Loss: 0.077957, Train Acc: 0.885897 | Val Loss: 0.107299, Val Acc: 0.793814\n",
      "Epoch 20345 - Train Loss: 0.077955, Train Acc: 0.885897 | Val Loss: 0.107298, Val Acc: 0.793814\n",
      "Epoch 20346 - Train Loss: 0.077953, Train Acc: 0.885897 | Val Loss: 0.107297, Val Acc: 0.793814\n",
      "Epoch 20347 - Train Loss: 0.077951, Train Acc: 0.885897 | Val Loss: 0.107296, Val Acc: 0.793814\n",
      "Epoch 20348 - Train Loss: 0.077949, Train Acc: 0.885897 | Val Loss: 0.107295, Val Acc: 0.793814\n",
      "Epoch 20349 - Train Loss: 0.077946, Train Acc: 0.885897 | Val Loss: 0.107295, Val Acc: 0.793814\n",
      "Epoch 20350 - Train Loss: 0.077944, Train Acc: 0.885897 | Val Loss: 0.107294, Val Acc: 0.793814\n",
      "Epoch 20351 - Train Loss: 0.077942, Train Acc: 0.885897 | Val Loss: 0.107293, Val Acc: 0.793814\n",
      "Epoch 20352 - Train Loss: 0.077940, Train Acc: 0.885897 | Val Loss: 0.107292, Val Acc: 0.793814\n",
      "Epoch 20353 - Train Loss: 0.077938, Train Acc: 0.885897 | Val Loss: 0.107291, Val Acc: 0.793814\n",
      "Epoch 20354 - Train Loss: 0.077936, Train Acc: 0.885897 | Val Loss: 0.107290, Val Acc: 0.793814\n",
      "Epoch 20355 - Train Loss: 0.077934, Train Acc: 0.885897 | Val Loss: 0.107290, Val Acc: 0.793814\n",
      "Epoch 20356 - Train Loss: 0.077932, Train Acc: 0.885897 | Val Loss: 0.107289, Val Acc: 0.793814\n",
      "Epoch 20357 - Train Loss: 0.077930, Train Acc: 0.885897 | Val Loss: 0.107288, Val Acc: 0.793814\n",
      "Epoch 20358 - Train Loss: 0.077928, Train Acc: 0.885897 | Val Loss: 0.107287, Val Acc: 0.793814\n",
      "Epoch 20359 - Train Loss: 0.077926, Train Acc: 0.885897 | Val Loss: 0.107286, Val Acc: 0.793814\n",
      "Epoch 20360 - Train Loss: 0.077924, Train Acc: 0.885897 | Val Loss: 0.107286, Val Acc: 0.793814\n",
      "Epoch 20361 - Train Loss: 0.077922, Train Acc: 0.885897 | Val Loss: 0.107285, Val Acc: 0.793814\n",
      "Epoch 20362 - Train Loss: 0.077920, Train Acc: 0.885897 | Val Loss: 0.107284, Val Acc: 0.793814\n",
      "Epoch 20363 - Train Loss: 0.077918, Train Acc: 0.885897 | Val Loss: 0.107283, Val Acc: 0.793814\n",
      "Epoch 20364 - Train Loss: 0.077916, Train Acc: 0.885897 | Val Loss: 0.107282, Val Acc: 0.793814\n",
      "Epoch 20365 - Train Loss: 0.077914, Train Acc: 0.885897 | Val Loss: 0.107281, Val Acc: 0.793814\n",
      "Epoch 20366 - Train Loss: 0.077912, Train Acc: 0.885897 | Val Loss: 0.107281, Val Acc: 0.793814\n",
      "Epoch 20367 - Train Loss: 0.077909, Train Acc: 0.885897 | Val Loss: 0.107280, Val Acc: 0.793814\n",
      "Epoch 20368 - Train Loss: 0.077907, Train Acc: 0.885897 | Val Loss: 0.107279, Val Acc: 0.793814\n",
      "Epoch 20369 - Train Loss: 0.077905, Train Acc: 0.885897 | Val Loss: 0.107278, Val Acc: 0.793814\n",
      "Epoch 20370 - Train Loss: 0.077903, Train Acc: 0.885897 | Val Loss: 0.107277, Val Acc: 0.793814\n",
      "Epoch 20371 - Train Loss: 0.077901, Train Acc: 0.885897 | Val Loss: 0.107276, Val Acc: 0.793814\n",
      "Epoch 20372 - Train Loss: 0.077899, Train Acc: 0.885897 | Val Loss: 0.107276, Val Acc: 0.793814\n",
      "Epoch 20373 - Train Loss: 0.077897, Train Acc: 0.885897 | Val Loss: 0.107275, Val Acc: 0.793814\n",
      "Epoch 20374 - Train Loss: 0.077895, Train Acc: 0.885897 | Val Loss: 0.107274, Val Acc: 0.793814\n",
      "Epoch 20375 - Train Loss: 0.077893, Train Acc: 0.885897 | Val Loss: 0.107273, Val Acc: 0.793814\n",
      "Epoch 20376 - Train Loss: 0.077891, Train Acc: 0.885897 | Val Loss: 0.107272, Val Acc: 0.793814\n",
      "Epoch 20377 - Train Loss: 0.077889, Train Acc: 0.885897 | Val Loss: 0.107272, Val Acc: 0.793814\n",
      "Epoch 20378 - Train Loss: 0.077887, Train Acc: 0.885897 | Val Loss: 0.107271, Val Acc: 0.793814\n",
      "Epoch 20379 - Train Loss: 0.077885, Train Acc: 0.885897 | Val Loss: 0.107270, Val Acc: 0.793814\n",
      "Epoch 20380 - Train Loss: 0.077883, Train Acc: 0.885897 | Val Loss: 0.107269, Val Acc: 0.793814\n",
      "Epoch 20381 - Train Loss: 0.077881, Train Acc: 0.885897 | Val Loss: 0.107268, Val Acc: 0.793814\n",
      "Epoch 20382 - Train Loss: 0.077879, Train Acc: 0.885897 | Val Loss: 0.107268, Val Acc: 0.793814\n",
      "Epoch 20383 - Train Loss: 0.077877, Train Acc: 0.885897 | Val Loss: 0.107267, Val Acc: 0.793814\n",
      "Epoch 20384 - Train Loss: 0.077875, Train Acc: 0.885897 | Val Loss: 0.107266, Val Acc: 0.793814\n",
      "Epoch 20385 - Train Loss: 0.077873, Train Acc: 0.885897 | Val Loss: 0.107265, Val Acc: 0.793814\n",
      "Epoch 20386 - Train Loss: 0.077870, Train Acc: 0.885897 | Val Loss: 0.107264, Val Acc: 0.793814\n",
      "Epoch 20387 - Train Loss: 0.077868, Train Acc: 0.885897 | Val Loss: 0.107263, Val Acc: 0.793814\n",
      "Epoch 20388 - Train Loss: 0.077866, Train Acc: 0.885897 | Val Loss: 0.107263, Val Acc: 0.793814\n",
      "Epoch 20389 - Train Loss: 0.077864, Train Acc: 0.885897 | Val Loss: 0.107262, Val Acc: 0.793814\n",
      "Epoch 20390 - Train Loss: 0.077862, Train Acc: 0.885897 | Val Loss: 0.107261, Val Acc: 0.793814\n",
      "Epoch 20391 - Train Loss: 0.077860, Train Acc: 0.885897 | Val Loss: 0.107260, Val Acc: 0.793814\n",
      "Epoch 20392 - Train Loss: 0.077858, Train Acc: 0.885897 | Val Loss: 0.107259, Val Acc: 0.793814\n",
      "Epoch 20393 - Train Loss: 0.077856, Train Acc: 0.885897 | Val Loss: 0.107259, Val Acc: 0.793814\n",
      "Epoch 20394 - Train Loss: 0.077854, Train Acc: 0.885897 | Val Loss: 0.107258, Val Acc: 0.793814\n",
      "Epoch 20395 - Train Loss: 0.077852, Train Acc: 0.885897 | Val Loss: 0.107257, Val Acc: 0.793814\n",
      "Epoch 20396 - Train Loss: 0.077850, Train Acc: 0.885897 | Val Loss: 0.107256, Val Acc: 0.793814\n",
      "Epoch 20397 - Train Loss: 0.077848, Train Acc: 0.885897 | Val Loss: 0.107255, Val Acc: 0.793814\n",
      "Epoch 20398 - Train Loss: 0.077846, Train Acc: 0.885897 | Val Loss: 0.107254, Val Acc: 0.793814\n",
      "Epoch 20399 - Train Loss: 0.077844, Train Acc: 0.885897 | Val Loss: 0.107254, Val Acc: 0.793814\n",
      "Epoch 20400 - Train Loss: 0.077842, Train Acc: 0.885897 | Val Loss: 0.107253, Val Acc: 0.793814\n",
      "Epoch 20401 - Train Loss: 0.077840, Train Acc: 0.885897 | Val Loss: 0.107252, Val Acc: 0.793814\n",
      "Epoch 20402 - Train Loss: 0.077838, Train Acc: 0.885897 | Val Loss: 0.107251, Val Acc: 0.793814\n",
      "Epoch 20403 - Train Loss: 0.077836, Train Acc: 0.885897 | Val Loss: 0.107250, Val Acc: 0.793814\n",
      "Epoch 20404 - Train Loss: 0.077834, Train Acc: 0.885897 | Val Loss: 0.107250, Val Acc: 0.793814\n",
      "Epoch 20405 - Train Loss: 0.077832, Train Acc: 0.885897 | Val Loss: 0.107249, Val Acc: 0.793814\n",
      "Epoch 20406 - Train Loss: 0.077829, Train Acc: 0.885897 | Val Loss: 0.107248, Val Acc: 0.793814\n",
      "Epoch 20407 - Train Loss: 0.077827, Train Acc: 0.885897 | Val Loss: 0.107247, Val Acc: 0.793814\n",
      "Epoch 20408 - Train Loss: 0.077825, Train Acc: 0.885897 | Val Loss: 0.107246, Val Acc: 0.793814\n",
      "Epoch 20409 - Train Loss: 0.077823, Train Acc: 0.885897 | Val Loss: 0.107245, Val Acc: 0.793814\n",
      "Epoch 20410 - Train Loss: 0.077821, Train Acc: 0.885897 | Val Loss: 0.107245, Val Acc: 0.793814\n",
      "Epoch 20411 - Train Loss: 0.077819, Train Acc: 0.885897 | Val Loss: 0.107244, Val Acc: 0.793814\n",
      "Epoch 20412 - Train Loss: 0.077817, Train Acc: 0.885897 | Val Loss: 0.107243, Val Acc: 0.793814\n",
      "Epoch 20413 - Train Loss: 0.077815, Train Acc: 0.885897 | Val Loss: 0.107242, Val Acc: 0.793814\n",
      "Epoch 20414 - Train Loss: 0.077813, Train Acc: 0.885897 | Val Loss: 0.107241, Val Acc: 0.793814\n",
      "Epoch 20415 - Train Loss: 0.077811, Train Acc: 0.885897 | Val Loss: 0.107241, Val Acc: 0.793814\n",
      "Epoch 20416 - Train Loss: 0.077809, Train Acc: 0.885897 | Val Loss: 0.107240, Val Acc: 0.793814\n",
      "Epoch 20417 - Train Loss: 0.077807, Train Acc: 0.885897 | Val Loss: 0.107239, Val Acc: 0.793814\n",
      "Epoch 20418 - Train Loss: 0.077805, Train Acc: 0.885897 | Val Loss: 0.107238, Val Acc: 0.793814\n",
      "Epoch 20419 - Train Loss: 0.077803, Train Acc: 0.885897 | Val Loss: 0.107237, Val Acc: 0.793814\n",
      "Epoch 20420 - Train Loss: 0.077801, Train Acc: 0.885897 | Val Loss: 0.107237, Val Acc: 0.793814\n",
      "Epoch 20421 - Train Loss: 0.077799, Train Acc: 0.885897 | Val Loss: 0.107236, Val Acc: 0.793814\n",
      "Epoch 20422 - Train Loss: 0.077797, Train Acc: 0.885897 | Val Loss: 0.107235, Val Acc: 0.793814\n",
      "Epoch 20423 - Train Loss: 0.077795, Train Acc: 0.885897 | Val Loss: 0.107234, Val Acc: 0.793814\n",
      "Epoch 20424 - Train Loss: 0.077793, Train Acc: 0.885897 | Val Loss: 0.107233, Val Acc: 0.793814\n",
      "Epoch 20425 - Train Loss: 0.077791, Train Acc: 0.885897 | Val Loss: 0.107233, Val Acc: 0.793814\n",
      "Epoch 20426 - Train Loss: 0.077789, Train Acc: 0.885897 | Val Loss: 0.107232, Val Acc: 0.793814\n",
      "Epoch 20427 - Train Loss: 0.077787, Train Acc: 0.885897 | Val Loss: 0.107231, Val Acc: 0.793814\n",
      "Epoch 20428 - Train Loss: 0.077784, Train Acc: 0.885897 | Val Loss: 0.107230, Val Acc: 0.793814\n",
      "Epoch 20429 - Train Loss: 0.077782, Train Acc: 0.885897 | Val Loss: 0.107229, Val Acc: 0.793814\n",
      "Epoch 20430 - Train Loss: 0.077780, Train Acc: 0.885897 | Val Loss: 0.107229, Val Acc: 0.793814\n",
      "Epoch 20431 - Train Loss: 0.077778, Train Acc: 0.885897 | Val Loss: 0.107228, Val Acc: 0.793814\n",
      "Epoch 20432 - Train Loss: 0.077776, Train Acc: 0.885897 | Val Loss: 0.107227, Val Acc: 0.793814\n",
      "Epoch 20433 - Train Loss: 0.077774, Train Acc: 0.885897 | Val Loss: 0.107226, Val Acc: 0.793814\n",
      "Epoch 20434 - Train Loss: 0.077772, Train Acc: 0.885897 | Val Loss: 0.107225, Val Acc: 0.793814\n",
      "Epoch 20435 - Train Loss: 0.077770, Train Acc: 0.885897 | Val Loss: 0.107224, Val Acc: 0.793814\n",
      "Epoch 20436 - Train Loss: 0.077768, Train Acc: 0.885897 | Val Loss: 0.107224, Val Acc: 0.793814\n",
      "Epoch 20437 - Train Loss: 0.077766, Train Acc: 0.885897 | Val Loss: 0.107223, Val Acc: 0.793814\n",
      "Epoch 20438 - Train Loss: 0.077764, Train Acc: 0.885897 | Val Loss: 0.107222, Val Acc: 0.793814\n",
      "Epoch 20439 - Train Loss: 0.077762, Train Acc: 0.885897 | Val Loss: 0.107221, Val Acc: 0.793814\n",
      "Epoch 20440 - Train Loss: 0.077760, Train Acc: 0.885897 | Val Loss: 0.107220, Val Acc: 0.793814\n",
      "Epoch 20441 - Train Loss: 0.077758, Train Acc: 0.885897 | Val Loss: 0.107220, Val Acc: 0.793814\n",
      "Epoch 20442 - Train Loss: 0.077756, Train Acc: 0.885897 | Val Loss: 0.107219, Val Acc: 0.793814\n",
      "Epoch 20443 - Train Loss: 0.077754, Train Acc: 0.885897 | Val Loss: 0.107218, Val Acc: 0.793814\n",
      "Epoch 20444 - Train Loss: 0.077752, Train Acc: 0.885897 | Val Loss: 0.107217, Val Acc: 0.793814\n",
      "Epoch 20445 - Train Loss: 0.077750, Train Acc: 0.885897 | Val Loss: 0.107216, Val Acc: 0.793814\n",
      "Epoch 20446 - Train Loss: 0.077748, Train Acc: 0.885897 | Val Loss: 0.107216, Val Acc: 0.793814\n",
      "Epoch 20447 - Train Loss: 0.077746, Train Acc: 0.885897 | Val Loss: 0.107215, Val Acc: 0.793814\n",
      "Epoch 20448 - Train Loss: 0.077744, Train Acc: 0.885897 | Val Loss: 0.107214, Val Acc: 0.793814\n",
      "Epoch 20449 - Train Loss: 0.077742, Train Acc: 0.885897 | Val Loss: 0.107213, Val Acc: 0.793814\n",
      "Epoch 20450 - Train Loss: 0.077740, Train Acc: 0.885897 | Val Loss: 0.107212, Val Acc: 0.793814\n",
      "Epoch 20451 - Train Loss: 0.077738, Train Acc: 0.885897 | Val Loss: 0.107212, Val Acc: 0.793814\n",
      "Epoch 20452 - Train Loss: 0.077736, Train Acc: 0.885897 | Val Loss: 0.107211, Val Acc: 0.793814\n",
      "Epoch 20453 - Train Loss: 0.077733, Train Acc: 0.885897 | Val Loss: 0.107210, Val Acc: 0.793814\n",
      "Epoch 20454 - Train Loss: 0.077731, Train Acc: 0.885897 | Val Loss: 0.107209, Val Acc: 0.793814\n",
      "Epoch 20455 - Train Loss: 0.077729, Train Acc: 0.885897 | Val Loss: 0.107208, Val Acc: 0.793814\n",
      "Epoch 20456 - Train Loss: 0.077727, Train Acc: 0.885897 | Val Loss: 0.107208, Val Acc: 0.793814\n",
      "Epoch 20457 - Train Loss: 0.077725, Train Acc: 0.885897 | Val Loss: 0.107207, Val Acc: 0.793814\n",
      "Epoch 20458 - Train Loss: 0.077723, Train Acc: 0.885897 | Val Loss: 0.107206, Val Acc: 0.793814\n",
      "Epoch 20459 - Train Loss: 0.077721, Train Acc: 0.885897 | Val Loss: 0.107205, Val Acc: 0.793814\n",
      "Epoch 20460 - Train Loss: 0.077719, Train Acc: 0.885897 | Val Loss: 0.107204, Val Acc: 0.793814\n",
      "Epoch 20461 - Train Loss: 0.077717, Train Acc: 0.885897 | Val Loss: 0.107204, Val Acc: 0.793814\n",
      "Epoch 20462 - Train Loss: 0.077715, Train Acc: 0.885897 | Val Loss: 0.107203, Val Acc: 0.793814\n",
      "Epoch 20463 - Train Loss: 0.077713, Train Acc: 0.885897 | Val Loss: 0.107202, Val Acc: 0.793814\n",
      "Epoch 20464 - Train Loss: 0.077711, Train Acc: 0.885897 | Val Loss: 0.107201, Val Acc: 0.793814\n",
      "Epoch 20465 - Train Loss: 0.077709, Train Acc: 0.885897 | Val Loss: 0.107200, Val Acc: 0.793814\n",
      "Epoch 20466 - Train Loss: 0.077707, Train Acc: 0.885897 | Val Loss: 0.107200, Val Acc: 0.793814\n",
      "Epoch 20467 - Train Loss: 0.077705, Train Acc: 0.885897 | Val Loss: 0.107199, Val Acc: 0.793814\n",
      "Epoch 20468 - Train Loss: 0.077703, Train Acc: 0.885897 | Val Loss: 0.107198, Val Acc: 0.793814\n",
      "Epoch 20469 - Train Loss: 0.077701, Train Acc: 0.885897 | Val Loss: 0.107197, Val Acc: 0.793814\n",
      "Epoch 20470 - Train Loss: 0.077699, Train Acc: 0.885897 | Val Loss: 0.107196, Val Acc: 0.793814\n",
      "Epoch 20471 - Train Loss: 0.077697, Train Acc: 0.885897 | Val Loss: 0.107196, Val Acc: 0.793814\n",
      "Epoch 20472 - Train Loss: 0.077695, Train Acc: 0.885897 | Val Loss: 0.107195, Val Acc: 0.793814\n",
      "Epoch 20473 - Train Loss: 0.077693, Train Acc: 0.885897 | Val Loss: 0.107194, Val Acc: 0.793814\n",
      "Epoch 20474 - Train Loss: 0.077691, Train Acc: 0.885897 | Val Loss: 0.107193, Val Acc: 0.793814\n",
      "Epoch 20475 - Train Loss: 0.077689, Train Acc: 0.885897 | Val Loss: 0.107192, Val Acc: 0.793814\n",
      "Epoch 20476 - Train Loss: 0.077687, Train Acc: 0.885897 | Val Loss: 0.107192, Val Acc: 0.793814\n",
      "Epoch 20477 - Train Loss: 0.077685, Train Acc: 0.885897 | Val Loss: 0.107191, Val Acc: 0.793814\n",
      "Epoch 20478 - Train Loss: 0.077683, Train Acc: 0.885897 | Val Loss: 0.107190, Val Acc: 0.793814\n",
      "Epoch 20479 - Train Loss: 0.077681, Train Acc: 0.885897 | Val Loss: 0.107189, Val Acc: 0.793814\n",
      "Epoch 20480 - Train Loss: 0.077679, Train Acc: 0.885897 | Val Loss: 0.107188, Val Acc: 0.793814\n",
      "Epoch 20481 - Train Loss: 0.077676, Train Acc: 0.885897 | Val Loss: 0.107188, Val Acc: 0.793814\n",
      "Epoch 20482 - Train Loss: 0.077674, Train Acc: 0.885897 | Val Loss: 0.107187, Val Acc: 0.793814\n",
      "Epoch 20483 - Train Loss: 0.077672, Train Acc: 0.885897 | Val Loss: 0.107186, Val Acc: 0.793814\n",
      "Epoch 20484 - Train Loss: 0.077670, Train Acc: 0.885897 | Val Loss: 0.107185, Val Acc: 0.793814\n",
      "Epoch 20485 - Train Loss: 0.077668, Train Acc: 0.885897 | Val Loss: 0.107184, Val Acc: 0.793814\n",
      "Epoch 20486 - Train Loss: 0.077666, Train Acc: 0.885897 | Val Loss: 0.107184, Val Acc: 0.793814\n",
      "Epoch 20487 - Train Loss: 0.077664, Train Acc: 0.885897 | Val Loss: 0.107183, Val Acc: 0.793814\n",
      "Epoch 20488 - Train Loss: 0.077662, Train Acc: 0.885897 | Val Loss: 0.107182, Val Acc: 0.793814\n",
      "Epoch 20489 - Train Loss: 0.077660, Train Acc: 0.885897 | Val Loss: 0.107181, Val Acc: 0.793814\n",
      "Epoch 20490 - Train Loss: 0.077658, Train Acc: 0.885897 | Val Loss: 0.107180, Val Acc: 0.793814\n",
      "Epoch 20491 - Train Loss: 0.077656, Train Acc: 0.885897 | Val Loss: 0.107180, Val Acc: 0.793814\n",
      "Epoch 20492 - Train Loss: 0.077654, Train Acc: 0.885897 | Val Loss: 0.107179, Val Acc: 0.793814\n",
      "Epoch 20493 - Train Loss: 0.077652, Train Acc: 0.885897 | Val Loss: 0.107178, Val Acc: 0.793814\n",
      "Epoch 20494 - Train Loss: 0.077650, Train Acc: 0.885897 | Val Loss: 0.107177, Val Acc: 0.793814\n",
      "Epoch 20495 - Train Loss: 0.077648, Train Acc: 0.885897 | Val Loss: 0.107176, Val Acc: 0.793814\n",
      "Epoch 20496 - Train Loss: 0.077646, Train Acc: 0.885897 | Val Loss: 0.107176, Val Acc: 0.793814\n",
      "Epoch 20497 - Train Loss: 0.077644, Train Acc: 0.885897 | Val Loss: 0.107175, Val Acc: 0.793814\n",
      "Epoch 20498 - Train Loss: 0.077642, Train Acc: 0.885897 | Val Loss: 0.107174, Val Acc: 0.793814\n",
      "Epoch 20499 - Train Loss: 0.077640, Train Acc: 0.885897 | Val Loss: 0.107173, Val Acc: 0.793814\n",
      "Epoch 20500 - Train Loss: 0.077638, Train Acc: 0.885897 | Val Loss: 0.107172, Val Acc: 0.793814\n",
      "Epoch 20501 - Train Loss: 0.077636, Train Acc: 0.885897 | Val Loss: 0.107172, Val Acc: 0.793814\n",
      "Epoch 20502 - Train Loss: 0.077634, Train Acc: 0.885897 | Val Loss: 0.107171, Val Acc: 0.793814\n",
      "Epoch 20503 - Train Loss: 0.077632, Train Acc: 0.885897 | Val Loss: 0.107170, Val Acc: 0.793814\n",
      "Epoch 20504 - Train Loss: 0.077630, Train Acc: 0.885897 | Val Loss: 0.107169, Val Acc: 0.793814\n",
      "Epoch 20505 - Train Loss: 0.077628, Train Acc: 0.885897 | Val Loss: 0.107168, Val Acc: 0.793814\n",
      "Epoch 20506 - Train Loss: 0.077626, Train Acc: 0.885897 | Val Loss: 0.107168, Val Acc: 0.793814\n",
      "Epoch 20507 - Train Loss: 0.077624, Train Acc: 0.885897 | Val Loss: 0.107167, Val Acc: 0.793814\n",
      "Epoch 20508 - Train Loss: 0.077622, Train Acc: 0.885897 | Val Loss: 0.107166, Val Acc: 0.793814\n",
      "Epoch 20509 - Train Loss: 0.077620, Train Acc: 0.885897 | Val Loss: 0.107165, Val Acc: 0.793814\n",
      "Epoch 20510 - Train Loss: 0.077618, Train Acc: 0.885897 | Val Loss: 0.107165, Val Acc: 0.793814\n",
      "Epoch 20511 - Train Loss: 0.077616, Train Acc: 0.885897 | Val Loss: 0.107164, Val Acc: 0.793814\n",
      "Epoch 20512 - Train Loss: 0.077614, Train Acc: 0.885897 | Val Loss: 0.107163, Val Acc: 0.793814\n",
      "Epoch 20513 - Train Loss: 0.077612, Train Acc: 0.885897 | Val Loss: 0.107162, Val Acc: 0.793814\n",
      "Epoch 20514 - Train Loss: 0.077610, Train Acc: 0.885897 | Val Loss: 0.107161, Val Acc: 0.793814\n",
      "Epoch 20515 - Train Loss: 0.077607, Train Acc: 0.885897 | Val Loss: 0.107161, Val Acc: 0.793814\n",
      "Epoch 20516 - Train Loss: 0.077605, Train Acc: 0.885897 | Val Loss: 0.107160, Val Acc: 0.793814\n",
      "Epoch 20517 - Train Loss: 0.077603, Train Acc: 0.885897 | Val Loss: 0.107159, Val Acc: 0.793814\n",
      "Epoch 20518 - Train Loss: 0.077601, Train Acc: 0.885897 | Val Loss: 0.107158, Val Acc: 0.793814\n",
      "Epoch 20519 - Train Loss: 0.077599, Train Acc: 0.885897 | Val Loss: 0.107157, Val Acc: 0.793814\n",
      "Epoch 20520 - Train Loss: 0.077597, Train Acc: 0.885897 | Val Loss: 0.107157, Val Acc: 0.793814\n",
      "Epoch 20521 - Train Loss: 0.077595, Train Acc: 0.885897 | Val Loss: 0.107156, Val Acc: 0.793814\n",
      "Epoch 20522 - Train Loss: 0.077593, Train Acc: 0.885897 | Val Loss: 0.107155, Val Acc: 0.793814\n",
      "Epoch 20523 - Train Loss: 0.077591, Train Acc: 0.885897 | Val Loss: 0.107154, Val Acc: 0.793814\n",
      "Epoch 20524 - Train Loss: 0.077589, Train Acc: 0.885897 | Val Loss: 0.107153, Val Acc: 0.793814\n",
      "Epoch 20525 - Train Loss: 0.077587, Train Acc: 0.885897 | Val Loss: 0.107153, Val Acc: 0.793814\n",
      "Epoch 20526 - Train Loss: 0.077585, Train Acc: 0.885897 | Val Loss: 0.107152, Val Acc: 0.793814\n",
      "Epoch 20527 - Train Loss: 0.077583, Train Acc: 0.887179 | Val Loss: 0.107151, Val Acc: 0.793814\n",
      "Epoch 20528 - Train Loss: 0.077581, Train Acc: 0.887179 | Val Loss: 0.107150, Val Acc: 0.793814\n",
      "Epoch 20529 - Train Loss: 0.077579, Train Acc: 0.887179 | Val Loss: 0.107149, Val Acc: 0.793814\n",
      "Epoch 20530 - Train Loss: 0.077577, Train Acc: 0.887179 | Val Loss: 0.107149, Val Acc: 0.793814\n",
      "Epoch 20531 - Train Loss: 0.077575, Train Acc: 0.887179 | Val Loss: 0.107148, Val Acc: 0.793814\n",
      "Epoch 20532 - Train Loss: 0.077573, Train Acc: 0.887179 | Val Loss: 0.107147, Val Acc: 0.793814\n",
      "Epoch 20533 - Train Loss: 0.077571, Train Acc: 0.887179 | Val Loss: 0.107146, Val Acc: 0.793814\n",
      "Epoch 20534 - Train Loss: 0.077569, Train Acc: 0.887179 | Val Loss: 0.107146, Val Acc: 0.793814\n",
      "Epoch 20535 - Train Loss: 0.077567, Train Acc: 0.887179 | Val Loss: 0.107145, Val Acc: 0.793814\n",
      "Epoch 20536 - Train Loss: 0.077565, Train Acc: 0.887179 | Val Loss: 0.107144, Val Acc: 0.793814\n",
      "Epoch 20537 - Train Loss: 0.077563, Train Acc: 0.887179 | Val Loss: 0.107143, Val Acc: 0.793814\n",
      "Epoch 20538 - Train Loss: 0.077561, Train Acc: 0.887179 | Val Loss: 0.107142, Val Acc: 0.793814\n",
      "Epoch 20539 - Train Loss: 0.077559, Train Acc: 0.887179 | Val Loss: 0.107142, Val Acc: 0.793814\n",
      "Epoch 20540 - Train Loss: 0.077557, Train Acc: 0.887179 | Val Loss: 0.107141, Val Acc: 0.793814\n",
      "Epoch 20541 - Train Loss: 0.077555, Train Acc: 0.887179 | Val Loss: 0.107140, Val Acc: 0.793814\n",
      "Epoch 20542 - Train Loss: 0.077553, Train Acc: 0.887179 | Val Loss: 0.107139, Val Acc: 0.793814\n",
      "Epoch 20543 - Train Loss: 0.077551, Train Acc: 0.887179 | Val Loss: 0.107138, Val Acc: 0.793814\n",
      "Epoch 20544 - Train Loss: 0.077549, Train Acc: 0.887179 | Val Loss: 0.107138, Val Acc: 0.793814\n",
      "Epoch 20545 - Train Loss: 0.077547, Train Acc: 0.887179 | Val Loss: 0.107137, Val Acc: 0.793814\n",
      "Epoch 20546 - Train Loss: 0.077545, Train Acc: 0.887179 | Val Loss: 0.107136, Val Acc: 0.793814\n",
      "Epoch 20547 - Train Loss: 0.077543, Train Acc: 0.887179 | Val Loss: 0.107135, Val Acc: 0.793814\n",
      "Epoch 20548 - Train Loss: 0.077541, Train Acc: 0.887179 | Val Loss: 0.107134, Val Acc: 0.793814\n",
      "Epoch 20549 - Train Loss: 0.077539, Train Acc: 0.887179 | Val Loss: 0.107134, Val Acc: 0.793814\n",
      "Epoch 20550 - Train Loss: 0.077537, Train Acc: 0.887179 | Val Loss: 0.107133, Val Acc: 0.793814\n",
      "Epoch 20551 - Train Loss: 0.077535, Train Acc: 0.887179 | Val Loss: 0.107132, Val Acc: 0.793814\n",
      "Epoch 20552 - Train Loss: 0.077533, Train Acc: 0.887179 | Val Loss: 0.107131, Val Acc: 0.793814\n",
      "Epoch 20553 - Train Loss: 0.077531, Train Acc: 0.887179 | Val Loss: 0.107131, Val Acc: 0.793814\n",
      "Epoch 20554 - Train Loss: 0.077529, Train Acc: 0.887179 | Val Loss: 0.107130, Val Acc: 0.793814\n",
      "Epoch 20555 - Train Loss: 0.077527, Train Acc: 0.887179 | Val Loss: 0.107129, Val Acc: 0.793814\n",
      "Epoch 20556 - Train Loss: 0.077525, Train Acc: 0.887179 | Val Loss: 0.107128, Val Acc: 0.793814\n",
      "Epoch 20557 - Train Loss: 0.077523, Train Acc: 0.887179 | Val Loss: 0.107127, Val Acc: 0.793814\n",
      "Epoch 20558 - Train Loss: 0.077521, Train Acc: 0.887179 | Val Loss: 0.107127, Val Acc: 0.793814\n",
      "Epoch 20559 - Train Loss: 0.077519, Train Acc: 0.887179 | Val Loss: 0.107126, Val Acc: 0.793814\n",
      "Epoch 20560 - Train Loss: 0.077517, Train Acc: 0.887179 | Val Loss: 0.107125, Val Acc: 0.793814\n",
      "Epoch 20561 - Train Loss: 0.077515, Train Acc: 0.887179 | Val Loss: 0.107124, Val Acc: 0.793814\n",
      "Epoch 20562 - Train Loss: 0.077512, Train Acc: 0.887179 | Val Loss: 0.107123, Val Acc: 0.793814\n",
      "Epoch 20563 - Train Loss: 0.077510, Train Acc: 0.887179 | Val Loss: 0.107123, Val Acc: 0.793814\n",
      "Epoch 20564 - Train Loss: 0.077508, Train Acc: 0.887179 | Val Loss: 0.107122, Val Acc: 0.793814\n",
      "Epoch 20565 - Train Loss: 0.077506, Train Acc: 0.887179 | Val Loss: 0.107121, Val Acc: 0.793814\n",
      "Epoch 20566 - Train Loss: 0.077504, Train Acc: 0.887179 | Val Loss: 0.107120, Val Acc: 0.793814\n",
      "Epoch 20567 - Train Loss: 0.077502, Train Acc: 0.887179 | Val Loss: 0.107120, Val Acc: 0.793814\n",
      "Epoch 20568 - Train Loss: 0.077500, Train Acc: 0.887179 | Val Loss: 0.107119, Val Acc: 0.793814\n",
      "Epoch 20569 - Train Loss: 0.077498, Train Acc: 0.887179 | Val Loss: 0.107118, Val Acc: 0.793814\n",
      "Epoch 20570 - Train Loss: 0.077496, Train Acc: 0.887179 | Val Loss: 0.107117, Val Acc: 0.793814\n",
      "Epoch 20571 - Train Loss: 0.077494, Train Acc: 0.887179 | Val Loss: 0.107116, Val Acc: 0.793814\n",
      "Epoch 20572 - Train Loss: 0.077492, Train Acc: 0.887179 | Val Loss: 0.107116, Val Acc: 0.793814\n",
      "Epoch 20573 - Train Loss: 0.077490, Train Acc: 0.887179 | Val Loss: 0.107115, Val Acc: 0.793814\n",
      "Epoch 20574 - Train Loss: 0.077488, Train Acc: 0.887179 | Val Loss: 0.107114, Val Acc: 0.793814\n",
      "Epoch 20575 - Train Loss: 0.077486, Train Acc: 0.887179 | Val Loss: 0.107113, Val Acc: 0.793814\n",
      "Epoch 20576 - Train Loss: 0.077484, Train Acc: 0.887179 | Val Loss: 0.107113, Val Acc: 0.793814\n",
      "Epoch 20577 - Train Loss: 0.077482, Train Acc: 0.887179 | Val Loss: 0.107112, Val Acc: 0.793814\n",
      "Epoch 20578 - Train Loss: 0.077480, Train Acc: 0.887179 | Val Loss: 0.107111, Val Acc: 0.793814\n",
      "Epoch 20579 - Train Loss: 0.077478, Train Acc: 0.887179 | Val Loss: 0.107110, Val Acc: 0.793814\n",
      "Epoch 20580 - Train Loss: 0.077476, Train Acc: 0.887179 | Val Loss: 0.107109, Val Acc: 0.793814\n",
      "Epoch 20581 - Train Loss: 0.077474, Train Acc: 0.887179 | Val Loss: 0.107109, Val Acc: 0.793814\n",
      "Epoch 20582 - Train Loss: 0.077472, Train Acc: 0.887179 | Val Loss: 0.107108, Val Acc: 0.793814\n",
      "Epoch 20583 - Train Loss: 0.077470, Train Acc: 0.887179 | Val Loss: 0.107107, Val Acc: 0.793814\n",
      "Epoch 20584 - Train Loss: 0.077468, Train Acc: 0.887179 | Val Loss: 0.107106, Val Acc: 0.793814\n",
      "Epoch 20585 - Train Loss: 0.077466, Train Acc: 0.887179 | Val Loss: 0.107106, Val Acc: 0.793814\n",
      "Epoch 20586 - Train Loss: 0.077464, Train Acc: 0.887179 | Val Loss: 0.107105, Val Acc: 0.793814\n",
      "Epoch 20587 - Train Loss: 0.077462, Train Acc: 0.887179 | Val Loss: 0.107104, Val Acc: 0.793814\n",
      "Epoch 20588 - Train Loss: 0.077460, Train Acc: 0.887179 | Val Loss: 0.107103, Val Acc: 0.793814\n",
      "Epoch 20589 - Train Loss: 0.077458, Train Acc: 0.887179 | Val Loss: 0.107102, Val Acc: 0.793814\n",
      "Epoch 20590 - Train Loss: 0.077456, Train Acc: 0.887179 | Val Loss: 0.107102, Val Acc: 0.793814\n",
      "Epoch 20591 - Train Loss: 0.077454, Train Acc: 0.887179 | Val Loss: 0.107101, Val Acc: 0.793814\n",
      "Epoch 20592 - Train Loss: 0.077452, Train Acc: 0.887179 | Val Loss: 0.107100, Val Acc: 0.793814\n",
      "Epoch 20593 - Train Loss: 0.077450, Train Acc: 0.887179 | Val Loss: 0.107099, Val Acc: 0.793814\n",
      "Epoch 20594 - Train Loss: 0.077448, Train Acc: 0.887179 | Val Loss: 0.107099, Val Acc: 0.793814\n",
      "Epoch 20595 - Train Loss: 0.077446, Train Acc: 0.887179 | Val Loss: 0.107098, Val Acc: 0.793814\n",
      "Epoch 20596 - Train Loss: 0.077444, Train Acc: 0.887179 | Val Loss: 0.107097, Val Acc: 0.793814\n",
      "Epoch 20597 - Train Loss: 0.077442, Train Acc: 0.887179 | Val Loss: 0.107096, Val Acc: 0.793814\n",
      "Epoch 20598 - Train Loss: 0.077440, Train Acc: 0.887179 | Val Loss: 0.107095, Val Acc: 0.793814\n",
      "Epoch 20599 - Train Loss: 0.077438, Train Acc: 0.887179 | Val Loss: 0.107095, Val Acc: 0.793814\n",
      "Epoch 20600 - Train Loss: 0.077436, Train Acc: 0.887179 | Val Loss: 0.107094, Val Acc: 0.793814\n",
      "Epoch 20601 - Train Loss: 0.077434, Train Acc: 0.887179 | Val Loss: 0.107093, Val Acc: 0.793814\n",
      "Epoch 20602 - Train Loss: 0.077432, Train Acc: 0.887179 | Val Loss: 0.107092, Val Acc: 0.793814\n",
      "Epoch 20603 - Train Loss: 0.077430, Train Acc: 0.887179 | Val Loss: 0.107092, Val Acc: 0.793814\n",
      "Epoch 20604 - Train Loss: 0.077428, Train Acc: 0.887179 | Val Loss: 0.107091, Val Acc: 0.793814\n",
      "Epoch 20605 - Train Loss: 0.077426, Train Acc: 0.887179 | Val Loss: 0.107090, Val Acc: 0.793814\n",
      "Epoch 20606 - Train Loss: 0.077424, Train Acc: 0.887179 | Val Loss: 0.107089, Val Acc: 0.793814\n",
      "Epoch 20607 - Train Loss: 0.077422, Train Acc: 0.887179 | Val Loss: 0.107088, Val Acc: 0.793814\n",
      "Epoch 20608 - Train Loss: 0.077420, Train Acc: 0.887179 | Val Loss: 0.107088, Val Acc: 0.793814\n",
      "Epoch 20609 - Train Loss: 0.077418, Train Acc: 0.887179 | Val Loss: 0.107087, Val Acc: 0.793814\n",
      "Epoch 20610 - Train Loss: 0.077416, Train Acc: 0.887179 | Val Loss: 0.107086, Val Acc: 0.793814\n",
      "Epoch 20611 - Train Loss: 0.077414, Train Acc: 0.887179 | Val Loss: 0.107085, Val Acc: 0.793814\n",
      "Epoch 20612 - Train Loss: 0.077412, Train Acc: 0.887179 | Val Loss: 0.107085, Val Acc: 0.793814\n",
      "Epoch 20613 - Train Loss: 0.077410, Train Acc: 0.887179 | Val Loss: 0.107084, Val Acc: 0.793814\n",
      "Epoch 20614 - Train Loss: 0.077408, Train Acc: 0.887179 | Val Loss: 0.107083, Val Acc: 0.793814\n",
      "Epoch 20615 - Train Loss: 0.077406, Train Acc: 0.887179 | Val Loss: 0.107082, Val Acc: 0.793814\n",
      "Epoch 20616 - Train Loss: 0.077404, Train Acc: 0.887179 | Val Loss: 0.107081, Val Acc: 0.793814\n",
      "Epoch 20617 - Train Loss: 0.077402, Train Acc: 0.887179 | Val Loss: 0.107081, Val Acc: 0.793814\n",
      "Epoch 20618 - Train Loss: 0.077400, Train Acc: 0.887179 | Val Loss: 0.107080, Val Acc: 0.793814\n",
      "Epoch 20619 - Train Loss: 0.077398, Train Acc: 0.887179 | Val Loss: 0.107079, Val Acc: 0.793814\n",
      "Epoch 20620 - Train Loss: 0.077396, Train Acc: 0.887179 | Val Loss: 0.107078, Val Acc: 0.793814\n",
      "Epoch 20621 - Train Loss: 0.077394, Train Acc: 0.887179 | Val Loss: 0.107078, Val Acc: 0.793814\n",
      "Epoch 20622 - Train Loss: 0.077392, Train Acc: 0.887179 | Val Loss: 0.107077, Val Acc: 0.793814\n",
      "Epoch 20623 - Train Loss: 0.077390, Train Acc: 0.887179 | Val Loss: 0.107076, Val Acc: 0.793814\n",
      "Epoch 20624 - Train Loss: 0.077388, Train Acc: 0.887179 | Val Loss: 0.107075, Val Acc: 0.793814\n",
      "Epoch 20625 - Train Loss: 0.077386, Train Acc: 0.887179 | Val Loss: 0.107075, Val Acc: 0.793814\n",
      "Epoch 20626 - Train Loss: 0.077384, Train Acc: 0.887179 | Val Loss: 0.107074, Val Acc: 0.793814\n",
      "Epoch 20627 - Train Loss: 0.077382, Train Acc: 0.887179 | Val Loss: 0.107073, Val Acc: 0.793814\n",
      "Epoch 20628 - Train Loss: 0.077380, Train Acc: 0.887179 | Val Loss: 0.107072, Val Acc: 0.793814\n",
      "Epoch 20629 - Train Loss: 0.077378, Train Acc: 0.887179 | Val Loss: 0.107071, Val Acc: 0.793814\n",
      "Epoch 20630 - Train Loss: 0.077376, Train Acc: 0.887179 | Val Loss: 0.107071, Val Acc: 0.793814\n",
      "Epoch 20631 - Train Loss: 0.077374, Train Acc: 0.887179 | Val Loss: 0.107070, Val Acc: 0.793814\n",
      "Epoch 20632 - Train Loss: 0.077372, Train Acc: 0.887179 | Val Loss: 0.107069, Val Acc: 0.793814\n",
      "Epoch 20633 - Train Loss: 0.077370, Train Acc: 0.887179 | Val Loss: 0.107068, Val Acc: 0.793814\n",
      "Epoch 20634 - Train Loss: 0.077368, Train Acc: 0.887179 | Val Loss: 0.107068, Val Acc: 0.793814\n",
      "Epoch 20635 - Train Loss: 0.077366, Train Acc: 0.887179 | Val Loss: 0.107067, Val Acc: 0.793814\n",
      "Epoch 20636 - Train Loss: 0.077364, Train Acc: 0.887179 | Val Loss: 0.107066, Val Acc: 0.793814\n",
      "Epoch 20637 - Train Loss: 0.077362, Train Acc: 0.887179 | Val Loss: 0.107065, Val Acc: 0.793814\n",
      "Epoch 20638 - Train Loss: 0.077360, Train Acc: 0.887179 | Val Loss: 0.107064, Val Acc: 0.793814\n",
      "Epoch 20639 - Train Loss: 0.077358, Train Acc: 0.887179 | Val Loss: 0.107064, Val Acc: 0.793814\n",
      "Epoch 20640 - Train Loss: 0.077356, Train Acc: 0.887179 | Val Loss: 0.107063, Val Acc: 0.793814\n",
      "Epoch 20641 - Train Loss: 0.077354, Train Acc: 0.887179 | Val Loss: 0.107062, Val Acc: 0.793814\n",
      "Epoch 20642 - Train Loss: 0.077352, Train Acc: 0.887179 | Val Loss: 0.107061, Val Acc: 0.793814\n",
      "Epoch 20643 - Train Loss: 0.077350, Train Acc: 0.887179 | Val Loss: 0.107061, Val Acc: 0.793814\n",
      "Epoch 20644 - Train Loss: 0.077348, Train Acc: 0.887179 | Val Loss: 0.107060, Val Acc: 0.793814\n",
      "Epoch 20645 - Train Loss: 0.077346, Train Acc: 0.887179 | Val Loss: 0.107059, Val Acc: 0.793814\n",
      "Epoch 20646 - Train Loss: 0.077344, Train Acc: 0.887179 | Val Loss: 0.107058, Val Acc: 0.793814\n",
      "Epoch 20647 - Train Loss: 0.077342, Train Acc: 0.887179 | Val Loss: 0.107058, Val Acc: 0.793814\n",
      "Epoch 20648 - Train Loss: 0.077340, Train Acc: 0.887179 | Val Loss: 0.107057, Val Acc: 0.793814\n",
      "Epoch 20649 - Train Loss: 0.077338, Train Acc: 0.887179 | Val Loss: 0.107056, Val Acc: 0.793814\n",
      "Epoch 20650 - Train Loss: 0.077336, Train Acc: 0.887179 | Val Loss: 0.107055, Val Acc: 0.793814\n",
      "Epoch 20651 - Train Loss: 0.077334, Train Acc: 0.887179 | Val Loss: 0.107055, Val Acc: 0.793814\n",
      "Epoch 20652 - Train Loss: 0.077332, Train Acc: 0.887179 | Val Loss: 0.107054, Val Acc: 0.793814\n",
      "Epoch 20653 - Train Loss: 0.077330, Train Acc: 0.887179 | Val Loss: 0.107053, Val Acc: 0.793814\n",
      "Epoch 20654 - Train Loss: 0.077328, Train Acc: 0.887179 | Val Loss: 0.107052, Val Acc: 0.793814\n",
      "Epoch 20655 - Train Loss: 0.077326, Train Acc: 0.887179 | Val Loss: 0.107051, Val Acc: 0.793814\n",
      "Epoch 20656 - Train Loss: 0.077324, Train Acc: 0.887179 | Val Loss: 0.107051, Val Acc: 0.793814\n",
      "Epoch 20657 - Train Loss: 0.077322, Train Acc: 0.887179 | Val Loss: 0.107050, Val Acc: 0.793814\n",
      "Epoch 20658 - Train Loss: 0.077320, Train Acc: 0.887179 | Val Loss: 0.107049, Val Acc: 0.793814\n",
      "Epoch 20659 - Train Loss: 0.077318, Train Acc: 0.887179 | Val Loss: 0.107048, Val Acc: 0.793814\n",
      "Epoch 20660 - Train Loss: 0.077316, Train Acc: 0.887179 | Val Loss: 0.107048, Val Acc: 0.793814\n",
      "Epoch 20661 - Train Loss: 0.077314, Train Acc: 0.887179 | Val Loss: 0.107047, Val Acc: 0.793814\n",
      "Epoch 20662 - Train Loss: 0.077312, Train Acc: 0.887179 | Val Loss: 0.107046, Val Acc: 0.793814\n",
      "Epoch 20663 - Train Loss: 0.077310, Train Acc: 0.887179 | Val Loss: 0.107045, Val Acc: 0.793814\n",
      "Epoch 20664 - Train Loss: 0.077308, Train Acc: 0.887179 | Val Loss: 0.107045, Val Acc: 0.793814\n",
      "Epoch 20665 - Train Loss: 0.077306, Train Acc: 0.887179 | Val Loss: 0.107044, Val Acc: 0.793814\n",
      "Epoch 20666 - Train Loss: 0.077304, Train Acc: 0.887179 | Val Loss: 0.107043, Val Acc: 0.793814\n",
      "Epoch 20667 - Train Loss: 0.077302, Train Acc: 0.887179 | Val Loss: 0.107042, Val Acc: 0.793814\n",
      "Epoch 20668 - Train Loss: 0.077300, Train Acc: 0.887179 | Val Loss: 0.107042, Val Acc: 0.793814\n",
      "Epoch 20669 - Train Loss: 0.077298, Train Acc: 0.887179 | Val Loss: 0.107041, Val Acc: 0.793814\n",
      "Epoch 20670 - Train Loss: 0.077296, Train Acc: 0.887179 | Val Loss: 0.107040, Val Acc: 0.793814\n",
      "Epoch 20671 - Train Loss: 0.077294, Train Acc: 0.887179 | Val Loss: 0.107039, Val Acc: 0.793814\n",
      "Epoch 20672 - Train Loss: 0.077292, Train Acc: 0.887179 | Val Loss: 0.107039, Val Acc: 0.793814\n",
      "Epoch 20673 - Train Loss: 0.077290, Train Acc: 0.887179 | Val Loss: 0.107038, Val Acc: 0.793814\n",
      "Epoch 20674 - Train Loss: 0.077288, Train Acc: 0.887179 | Val Loss: 0.107037, Val Acc: 0.793814\n",
      "Epoch 20675 - Train Loss: 0.077286, Train Acc: 0.887179 | Val Loss: 0.107036, Val Acc: 0.793814\n",
      "Epoch 20676 - Train Loss: 0.077284, Train Acc: 0.887179 | Val Loss: 0.107035, Val Acc: 0.793814\n",
      "Epoch 20677 - Train Loss: 0.077282, Train Acc: 0.887179 | Val Loss: 0.107035, Val Acc: 0.793814\n",
      "Epoch 20678 - Train Loss: 0.077280, Train Acc: 0.887179 | Val Loss: 0.107034, Val Acc: 0.793814\n",
      "Epoch 20679 - Train Loss: 0.077278, Train Acc: 0.887179 | Val Loss: 0.107033, Val Acc: 0.793814\n",
      "Epoch 20680 - Train Loss: 0.077276, Train Acc: 0.887179 | Val Loss: 0.107032, Val Acc: 0.793814\n",
      "Epoch 20681 - Train Loss: 0.077274, Train Acc: 0.887179 | Val Loss: 0.107032, Val Acc: 0.793814\n",
      "Epoch 20682 - Train Loss: 0.077272, Train Acc: 0.887179 | Val Loss: 0.107031, Val Acc: 0.793814\n",
      "Epoch 20683 - Train Loss: 0.077270, Train Acc: 0.887179 | Val Loss: 0.107030, Val Acc: 0.793814\n",
      "Epoch 20684 - Train Loss: 0.077268, Train Acc: 0.887179 | Val Loss: 0.107029, Val Acc: 0.793814\n",
      "Epoch 20685 - Train Loss: 0.077266, Train Acc: 0.887179 | Val Loss: 0.107029, Val Acc: 0.793814\n",
      "Epoch 20686 - Train Loss: 0.077264, Train Acc: 0.887179 | Val Loss: 0.107028, Val Acc: 0.793814\n",
      "Epoch 20687 - Train Loss: 0.077262, Train Acc: 0.887179 | Val Loss: 0.107027, Val Acc: 0.793814\n",
      "Epoch 20688 - Train Loss: 0.077260, Train Acc: 0.887179 | Val Loss: 0.107026, Val Acc: 0.793814\n",
      "Epoch 20689 - Train Loss: 0.077258, Train Acc: 0.887179 | Val Loss: 0.107025, Val Acc: 0.793814\n",
      "Epoch 20690 - Train Loss: 0.077256, Train Acc: 0.887179 | Val Loss: 0.107025, Val Acc: 0.793814\n",
      "Epoch 20691 - Train Loss: 0.077254, Train Acc: 0.887179 | Val Loss: 0.107024, Val Acc: 0.793814\n",
      "Epoch 20692 - Train Loss: 0.077252, Train Acc: 0.887179 | Val Loss: 0.107023, Val Acc: 0.793814\n",
      "Epoch 20693 - Train Loss: 0.077250, Train Acc: 0.887179 | Val Loss: 0.107022, Val Acc: 0.793814\n",
      "Epoch 20694 - Train Loss: 0.077248, Train Acc: 0.887179 | Val Loss: 0.107022, Val Acc: 0.793814\n",
      "Epoch 20695 - Train Loss: 0.077246, Train Acc: 0.887179 | Val Loss: 0.107021, Val Acc: 0.793814\n",
      "Epoch 20696 - Train Loss: 0.077244, Train Acc: 0.887179 | Val Loss: 0.107020, Val Acc: 0.793814\n",
      "Epoch 20697 - Train Loss: 0.077242, Train Acc: 0.887179 | Val Loss: 0.107019, Val Acc: 0.793814\n",
      "Epoch 20698 - Train Loss: 0.077240, Train Acc: 0.887179 | Val Loss: 0.107019, Val Acc: 0.793814\n",
      "Epoch 20699 - Train Loss: 0.077238, Train Acc: 0.887179 | Val Loss: 0.107018, Val Acc: 0.793814\n",
      "Epoch 20700 - Train Loss: 0.077236, Train Acc: 0.887179 | Val Loss: 0.107017, Val Acc: 0.793814\n",
      "Epoch 20701 - Train Loss: 0.077234, Train Acc: 0.887179 | Val Loss: 0.107016, Val Acc: 0.793814\n",
      "Epoch 20702 - Train Loss: 0.077232, Train Acc: 0.887179 | Val Loss: 0.107016, Val Acc: 0.793814\n",
      "Epoch 20703 - Train Loss: 0.077230, Train Acc: 0.887179 | Val Loss: 0.107015, Val Acc: 0.793814\n",
      "Epoch 20704 - Train Loss: 0.077228, Train Acc: 0.887179 | Val Loss: 0.107014, Val Acc: 0.793814\n",
      "Epoch 20705 - Train Loss: 0.077226, Train Acc: 0.887179 | Val Loss: 0.107013, Val Acc: 0.793814\n",
      "Epoch 20706 - Train Loss: 0.077224, Train Acc: 0.887179 | Val Loss: 0.107013, Val Acc: 0.793814\n",
      "Epoch 20707 - Train Loss: 0.077222, Train Acc: 0.887179 | Val Loss: 0.107012, Val Acc: 0.793814\n",
      "Epoch 20708 - Train Loss: 0.077220, Train Acc: 0.887179 | Val Loss: 0.107011, Val Acc: 0.793814\n",
      "Epoch 20709 - Train Loss: 0.077218, Train Acc: 0.887179 | Val Loss: 0.107010, Val Acc: 0.793814\n",
      "Epoch 20710 - Train Loss: 0.077216, Train Acc: 0.887179 | Val Loss: 0.107010, Val Acc: 0.793814\n",
      "Epoch 20711 - Train Loss: 0.077214, Train Acc: 0.887179 | Val Loss: 0.107009, Val Acc: 0.793814\n",
      "Epoch 20712 - Train Loss: 0.077212, Train Acc: 0.887179 | Val Loss: 0.107008, Val Acc: 0.793814\n",
      "Epoch 20713 - Train Loss: 0.077210, Train Acc: 0.887179 | Val Loss: 0.107007, Val Acc: 0.793814\n",
      "Epoch 20714 - Train Loss: 0.077208, Train Acc: 0.887179 | Val Loss: 0.107007, Val Acc: 0.793814\n",
      "Epoch 20715 - Train Loss: 0.077206, Train Acc: 0.887179 | Val Loss: 0.107006, Val Acc: 0.793814\n",
      "Epoch 20716 - Train Loss: 0.077204, Train Acc: 0.887179 | Val Loss: 0.107005, Val Acc: 0.793814\n",
      "Epoch 20717 - Train Loss: 0.077202, Train Acc: 0.887179 | Val Loss: 0.107004, Val Acc: 0.793814\n",
      "Epoch 20718 - Train Loss: 0.077200, Train Acc: 0.887179 | Val Loss: 0.107004, Val Acc: 0.793814\n",
      "Epoch 20719 - Train Loss: 0.077198, Train Acc: 0.887179 | Val Loss: 0.107003, Val Acc: 0.793814\n",
      "Epoch 20720 - Train Loss: 0.077196, Train Acc: 0.887179 | Val Loss: 0.107002, Val Acc: 0.793814\n",
      "Epoch 20721 - Train Loss: 0.077194, Train Acc: 0.887179 | Val Loss: 0.107001, Val Acc: 0.793814\n",
      "Epoch 20722 - Train Loss: 0.077192, Train Acc: 0.887179 | Val Loss: 0.107000, Val Acc: 0.793814\n",
      "Epoch 20723 - Train Loss: 0.077190, Train Acc: 0.887179 | Val Loss: 0.107000, Val Acc: 0.793814\n",
      "Epoch 20724 - Train Loss: 0.077188, Train Acc: 0.887179 | Val Loss: 0.106999, Val Acc: 0.793814\n",
      "Epoch 20725 - Train Loss: 0.077186, Train Acc: 0.887179 | Val Loss: 0.106998, Val Acc: 0.793814\n",
      "Epoch 20726 - Train Loss: 0.077184, Train Acc: 0.887179 | Val Loss: 0.106998, Val Acc: 0.793814\n",
      "Epoch 20727 - Train Loss: 0.077182, Train Acc: 0.887179 | Val Loss: 0.106997, Val Acc: 0.793814\n",
      "Epoch 20728 - Train Loss: 0.077180, Train Acc: 0.887179 | Val Loss: 0.106996, Val Acc: 0.793814\n",
      "Epoch 20729 - Train Loss: 0.077178, Train Acc: 0.887179 | Val Loss: 0.106995, Val Acc: 0.793814\n",
      "Epoch 20730 - Train Loss: 0.077176, Train Acc: 0.887179 | Val Loss: 0.106994, Val Acc: 0.793814\n",
      "Epoch 20731 - Train Loss: 0.077174, Train Acc: 0.887179 | Val Loss: 0.106994, Val Acc: 0.793814\n",
      "Epoch 20732 - Train Loss: 0.077172, Train Acc: 0.887179 | Val Loss: 0.106993, Val Acc: 0.793814\n",
      "Epoch 20733 - Train Loss: 0.077170, Train Acc: 0.887179 | Val Loss: 0.106992, Val Acc: 0.793814\n",
      "Epoch 20734 - Train Loss: 0.077168, Train Acc: 0.887179 | Val Loss: 0.106992, Val Acc: 0.793814\n",
      "Epoch 20735 - Train Loss: 0.077166, Train Acc: 0.887179 | Val Loss: 0.106991, Val Acc: 0.793814\n",
      "Epoch 20736 - Train Loss: 0.077165, Train Acc: 0.887179 | Val Loss: 0.106990, Val Acc: 0.793814\n",
      "Epoch 20737 - Train Loss: 0.077163, Train Acc: 0.887179 | Val Loss: 0.106989, Val Acc: 0.793814\n",
      "Epoch 20738 - Train Loss: 0.077161, Train Acc: 0.887179 | Val Loss: 0.106988, Val Acc: 0.793814\n",
      "Epoch 20739 - Train Loss: 0.077159, Train Acc: 0.887179 | Val Loss: 0.106988, Val Acc: 0.793814\n",
      "Epoch 20740 - Train Loss: 0.077157, Train Acc: 0.887179 | Val Loss: 0.106987, Val Acc: 0.793814\n",
      "Epoch 20741 - Train Loss: 0.077155, Train Acc: 0.887179 | Val Loss: 0.106986, Val Acc: 0.793814\n",
      "Epoch 20742 - Train Loss: 0.077153, Train Acc: 0.887179 | Val Loss: 0.106986, Val Acc: 0.793814\n",
      "Epoch 20743 - Train Loss: 0.077151, Train Acc: 0.887179 | Val Loss: 0.106985, Val Acc: 0.793814\n",
      "Epoch 20744 - Train Loss: 0.077149, Train Acc: 0.887179 | Val Loss: 0.106984, Val Acc: 0.793814\n",
      "Epoch 20745 - Train Loss: 0.077147, Train Acc: 0.887179 | Val Loss: 0.106983, Val Acc: 0.793814\n",
      "Epoch 20746 - Train Loss: 0.077145, Train Acc: 0.887179 | Val Loss: 0.106982, Val Acc: 0.793814\n",
      "Epoch 20747 - Train Loss: 0.077143, Train Acc: 0.887179 | Val Loss: 0.106982, Val Acc: 0.793814\n",
      "Epoch 20748 - Train Loss: 0.077141, Train Acc: 0.887179 | Val Loss: 0.106981, Val Acc: 0.793814\n",
      "Epoch 20749 - Train Loss: 0.077139, Train Acc: 0.887179 | Val Loss: 0.106980, Val Acc: 0.793814\n",
      "Epoch 20750 - Train Loss: 0.077137, Train Acc: 0.887179 | Val Loss: 0.106980, Val Acc: 0.793814\n",
      "Epoch 20751 - Train Loss: 0.077135, Train Acc: 0.887179 | Val Loss: 0.106979, Val Acc: 0.793814\n",
      "Epoch 20752 - Train Loss: 0.077133, Train Acc: 0.887179 | Val Loss: 0.106978, Val Acc: 0.793814\n",
      "Epoch 20753 - Train Loss: 0.077131, Train Acc: 0.887179 | Val Loss: 0.106977, Val Acc: 0.793814\n",
      "Epoch 20754 - Train Loss: 0.077129, Train Acc: 0.887179 | Val Loss: 0.106976, Val Acc: 0.793814\n",
      "Epoch 20755 - Train Loss: 0.077127, Train Acc: 0.887179 | Val Loss: 0.106976, Val Acc: 0.793814\n",
      "Epoch 20756 - Train Loss: 0.077125, Train Acc: 0.887179 | Val Loss: 0.106975, Val Acc: 0.793814\n",
      "Epoch 20757 - Train Loss: 0.077123, Train Acc: 0.887179 | Val Loss: 0.106974, Val Acc: 0.793814\n",
      "Epoch 20758 - Train Loss: 0.077121, Train Acc: 0.887179 | Val Loss: 0.106973, Val Acc: 0.793814\n",
      "Epoch 20759 - Train Loss: 0.077119, Train Acc: 0.887179 | Val Loss: 0.106973, Val Acc: 0.793814\n",
      "Epoch 20760 - Train Loss: 0.077117, Train Acc: 0.887179 | Val Loss: 0.106972, Val Acc: 0.793814\n",
      "Epoch 20761 - Train Loss: 0.077115, Train Acc: 0.887179 | Val Loss: 0.106971, Val Acc: 0.793814\n",
      "Epoch 20762 - Train Loss: 0.077113, Train Acc: 0.887179 | Val Loss: 0.106971, Val Acc: 0.793814\n",
      "Epoch 20763 - Train Loss: 0.077111, Train Acc: 0.887179 | Val Loss: 0.106970, Val Acc: 0.793814\n",
      "Epoch 20764 - Train Loss: 0.077109, Train Acc: 0.887179 | Val Loss: 0.106969, Val Acc: 0.793814\n",
      "Epoch 20765 - Train Loss: 0.077107, Train Acc: 0.887179 | Val Loss: 0.106968, Val Acc: 0.793814\n",
      "Epoch 20766 - Train Loss: 0.077105, Train Acc: 0.887179 | Val Loss: 0.106968, Val Acc: 0.793814\n",
      "Epoch 20767 - Train Loss: 0.077103, Train Acc: 0.887179 | Val Loss: 0.106967, Val Acc: 0.793814\n",
      "Epoch 20768 - Train Loss: 0.077101, Train Acc: 0.887179 | Val Loss: 0.106966, Val Acc: 0.793814\n",
      "Epoch 20769 - Train Loss: 0.077099, Train Acc: 0.887179 | Val Loss: 0.106965, Val Acc: 0.793814\n",
      "Epoch 20770 - Train Loss: 0.077097, Train Acc: 0.887179 | Val Loss: 0.106965, Val Acc: 0.793814\n",
      "Epoch 20771 - Train Loss: 0.077095, Train Acc: 0.887179 | Val Loss: 0.106964, Val Acc: 0.793814\n",
      "Epoch 20772 - Train Loss: 0.077093, Train Acc: 0.887179 | Val Loss: 0.106963, Val Acc: 0.793814\n",
      "Epoch 20773 - Train Loss: 0.077091, Train Acc: 0.887179 | Val Loss: 0.106962, Val Acc: 0.793814\n",
      "Epoch 20774 - Train Loss: 0.077089, Train Acc: 0.887179 | Val Loss: 0.106962, Val Acc: 0.793814\n",
      "Epoch 20775 - Train Loss: 0.077087, Train Acc: 0.887179 | Val Loss: 0.106961, Val Acc: 0.793814\n",
      "Epoch 20776 - Train Loss: 0.077085, Train Acc: 0.887179 | Val Loss: 0.106960, Val Acc: 0.793814\n",
      "Epoch 20777 - Train Loss: 0.077083, Train Acc: 0.887179 | Val Loss: 0.106959, Val Acc: 0.793814\n",
      "Epoch 20778 - Train Loss: 0.077081, Train Acc: 0.887179 | Val Loss: 0.106959, Val Acc: 0.793814\n",
      "Epoch 20779 - Train Loss: 0.077079, Train Acc: 0.887179 | Val Loss: 0.106958, Val Acc: 0.793814\n",
      "Epoch 20780 - Train Loss: 0.077077, Train Acc: 0.887179 | Val Loss: 0.106957, Val Acc: 0.793814\n",
      "Epoch 20781 - Train Loss: 0.077075, Train Acc: 0.887179 | Val Loss: 0.106956, Val Acc: 0.793814\n",
      "Epoch 20782 - Train Loss: 0.077073, Train Acc: 0.887179 | Val Loss: 0.106956, Val Acc: 0.793814\n",
      "Epoch 20783 - Train Loss: 0.077071, Train Acc: 0.887179 | Val Loss: 0.106955, Val Acc: 0.793814\n",
      "Epoch 20784 - Train Loss: 0.077070, Train Acc: 0.887179 | Val Loss: 0.106954, Val Acc: 0.793814\n",
      "Epoch 20785 - Train Loss: 0.077068, Train Acc: 0.887179 | Val Loss: 0.106953, Val Acc: 0.793814\n",
      "Epoch 20786 - Train Loss: 0.077066, Train Acc: 0.887179 | Val Loss: 0.106953, Val Acc: 0.793814\n",
      "Epoch 20787 - Train Loss: 0.077064, Train Acc: 0.887179 | Val Loss: 0.106952, Val Acc: 0.793814\n",
      "Epoch 20788 - Train Loss: 0.077062, Train Acc: 0.887179 | Val Loss: 0.106951, Val Acc: 0.793814\n",
      "Epoch 20789 - Train Loss: 0.077060, Train Acc: 0.887179 | Val Loss: 0.106950, Val Acc: 0.793814\n",
      "Epoch 20790 - Train Loss: 0.077058, Train Acc: 0.887179 | Val Loss: 0.106950, Val Acc: 0.793814\n",
      "Epoch 20791 - Train Loss: 0.077056, Train Acc: 0.887179 | Val Loss: 0.106949, Val Acc: 0.793814\n",
      "Epoch 20792 - Train Loss: 0.077054, Train Acc: 0.887179 | Val Loss: 0.106948, Val Acc: 0.793814\n",
      "Epoch 20793 - Train Loss: 0.077052, Train Acc: 0.887179 | Val Loss: 0.106947, Val Acc: 0.793814\n",
      "Epoch 20794 - Train Loss: 0.077050, Train Acc: 0.887179 | Val Loss: 0.106947, Val Acc: 0.793814\n",
      "Epoch 20795 - Train Loss: 0.077048, Train Acc: 0.887179 | Val Loss: 0.106946, Val Acc: 0.793814\n",
      "Epoch 20796 - Train Loss: 0.077046, Train Acc: 0.887179 | Val Loss: 0.106945, Val Acc: 0.793814\n",
      "Epoch 20797 - Train Loss: 0.077044, Train Acc: 0.887179 | Val Loss: 0.106944, Val Acc: 0.793814\n",
      "Epoch 20798 - Train Loss: 0.077042, Train Acc: 0.887179 | Val Loss: 0.106944, Val Acc: 0.793814\n",
      "Epoch 20799 - Train Loss: 0.077040, Train Acc: 0.887179 | Val Loss: 0.106943, Val Acc: 0.793814\n",
      "Epoch 20800 - Train Loss: 0.077038, Train Acc: 0.887179 | Val Loss: 0.106942, Val Acc: 0.793814\n",
      "Epoch 20801 - Train Loss: 0.077036, Train Acc: 0.887179 | Val Loss: 0.106942, Val Acc: 0.793814\n",
      "Epoch 20802 - Train Loss: 0.077034, Train Acc: 0.887179 | Val Loss: 0.106941, Val Acc: 0.793814\n",
      "Epoch 20803 - Train Loss: 0.077032, Train Acc: 0.887179 | Val Loss: 0.106940, Val Acc: 0.793814\n",
      "Epoch 20804 - Train Loss: 0.077030, Train Acc: 0.887179 | Val Loss: 0.106939, Val Acc: 0.793814\n",
      "Epoch 20805 - Train Loss: 0.077028, Train Acc: 0.887179 | Val Loss: 0.106939, Val Acc: 0.793814\n",
      "Epoch 20806 - Train Loss: 0.077026, Train Acc: 0.887179 | Val Loss: 0.106938, Val Acc: 0.793814\n",
      "Epoch 20807 - Train Loss: 0.077024, Train Acc: 0.887179 | Val Loss: 0.106937, Val Acc: 0.793814\n",
      "Epoch 20808 - Train Loss: 0.077022, Train Acc: 0.887179 | Val Loss: 0.106936, Val Acc: 0.793814\n",
      "Epoch 20809 - Train Loss: 0.077020, Train Acc: 0.887179 | Val Loss: 0.106936, Val Acc: 0.793814\n",
      "Epoch 20810 - Train Loss: 0.077018, Train Acc: 0.887179 | Val Loss: 0.106935, Val Acc: 0.793814\n",
      "Epoch 20811 - Train Loss: 0.077016, Train Acc: 0.887179 | Val Loss: 0.106934, Val Acc: 0.793814\n",
      "Epoch 20812 - Train Loss: 0.077014, Train Acc: 0.887179 | Val Loss: 0.106933, Val Acc: 0.793814\n",
      "Epoch 20813 - Train Loss: 0.077012, Train Acc: 0.887179 | Val Loss: 0.106933, Val Acc: 0.793814\n",
      "Epoch 20814 - Train Loss: 0.077010, Train Acc: 0.887179 | Val Loss: 0.106932, Val Acc: 0.793814\n",
      "Epoch 20815 - Train Loss: 0.077008, Train Acc: 0.887179 | Val Loss: 0.106931, Val Acc: 0.793814\n",
      "Epoch 20816 - Train Loss: 0.077006, Train Acc: 0.887179 | Val Loss: 0.106930, Val Acc: 0.793814\n",
      "Epoch 20817 - Train Loss: 0.077004, Train Acc: 0.887179 | Val Loss: 0.106930, Val Acc: 0.793814\n",
      "Epoch 20818 - Train Loss: 0.077002, Train Acc: 0.887179 | Val Loss: 0.106929, Val Acc: 0.793814\n",
      "Epoch 20819 - Train Loss: 0.077001, Train Acc: 0.887179 | Val Loss: 0.106928, Val Acc: 0.793814\n",
      "Epoch 20820 - Train Loss: 0.076999, Train Acc: 0.887179 | Val Loss: 0.106927, Val Acc: 0.793814\n",
      "Epoch 20821 - Train Loss: 0.076997, Train Acc: 0.887179 | Val Loss: 0.106927, Val Acc: 0.793814\n",
      "Epoch 20822 - Train Loss: 0.076995, Train Acc: 0.887179 | Val Loss: 0.106926, Val Acc: 0.793814\n",
      "Epoch 20823 - Train Loss: 0.076993, Train Acc: 0.887179 | Val Loss: 0.106925, Val Acc: 0.793814\n",
      "Epoch 20824 - Train Loss: 0.076991, Train Acc: 0.887179 | Val Loss: 0.106925, Val Acc: 0.793814\n",
      "Epoch 20825 - Train Loss: 0.076989, Train Acc: 0.887179 | Val Loss: 0.106924, Val Acc: 0.793814\n",
      "Epoch 20826 - Train Loss: 0.076987, Train Acc: 0.887179 | Val Loss: 0.106923, Val Acc: 0.793814\n",
      "Epoch 20827 - Train Loss: 0.076985, Train Acc: 0.887179 | Val Loss: 0.106922, Val Acc: 0.793814\n",
      "Epoch 20828 - Train Loss: 0.076983, Train Acc: 0.887179 | Val Loss: 0.106922, Val Acc: 0.793814\n",
      "Epoch 20829 - Train Loss: 0.076981, Train Acc: 0.887179 | Val Loss: 0.106921, Val Acc: 0.793814\n",
      "Epoch 20830 - Train Loss: 0.076979, Train Acc: 0.887179 | Val Loss: 0.106920, Val Acc: 0.793814\n",
      "Epoch 20831 - Train Loss: 0.076977, Train Acc: 0.887179 | Val Loss: 0.106919, Val Acc: 0.793814\n",
      "Epoch 20832 - Train Loss: 0.076975, Train Acc: 0.887179 | Val Loss: 0.106919, Val Acc: 0.793814\n",
      "Epoch 20833 - Train Loss: 0.076973, Train Acc: 0.887179 | Val Loss: 0.106918, Val Acc: 0.793814\n",
      "Epoch 20834 - Train Loss: 0.076971, Train Acc: 0.887179 | Val Loss: 0.106917, Val Acc: 0.793814\n",
      "Epoch 20835 - Train Loss: 0.076969, Train Acc: 0.887179 | Val Loss: 0.106916, Val Acc: 0.793814\n",
      "Epoch 20836 - Train Loss: 0.076967, Train Acc: 0.887179 | Val Loss: 0.106916, Val Acc: 0.793814\n",
      "Epoch 20837 - Train Loss: 0.076965, Train Acc: 0.887179 | Val Loss: 0.106915, Val Acc: 0.793814\n",
      "Epoch 20838 - Train Loss: 0.076963, Train Acc: 0.887179 | Val Loss: 0.106914, Val Acc: 0.793814\n",
      "Epoch 20839 - Train Loss: 0.076961, Train Acc: 0.887179 | Val Loss: 0.106913, Val Acc: 0.793814\n",
      "Epoch 20840 - Train Loss: 0.076959, Train Acc: 0.887179 | Val Loss: 0.106913, Val Acc: 0.793814\n",
      "Epoch 20841 - Train Loss: 0.076957, Train Acc: 0.887179 | Val Loss: 0.106912, Val Acc: 0.793814\n",
      "Epoch 20842 - Train Loss: 0.076955, Train Acc: 0.887179 | Val Loss: 0.106911, Val Acc: 0.793814\n",
      "Epoch 20843 - Train Loss: 0.076953, Train Acc: 0.887179 | Val Loss: 0.106911, Val Acc: 0.793814\n",
      "Epoch 20844 - Train Loss: 0.076951, Train Acc: 0.887179 | Val Loss: 0.106910, Val Acc: 0.793814\n",
      "Epoch 20845 - Train Loss: 0.076949, Train Acc: 0.887179 | Val Loss: 0.106909, Val Acc: 0.793814\n",
      "Epoch 20846 - Train Loss: 0.076947, Train Acc: 0.887179 | Val Loss: 0.106908, Val Acc: 0.793814\n",
      "Epoch 20847 - Train Loss: 0.076946, Train Acc: 0.887179 | Val Loss: 0.106908, Val Acc: 0.793814\n",
      "Epoch 20848 - Train Loss: 0.076944, Train Acc: 0.887179 | Val Loss: 0.106907, Val Acc: 0.793814\n",
      "Epoch 20849 - Train Loss: 0.076942, Train Acc: 0.887179 | Val Loss: 0.106906, Val Acc: 0.793814\n",
      "Epoch 20850 - Train Loss: 0.076940, Train Acc: 0.887179 | Val Loss: 0.106905, Val Acc: 0.793814\n",
      "Epoch 20851 - Train Loss: 0.076938, Train Acc: 0.887179 | Val Loss: 0.106905, Val Acc: 0.793814\n",
      "Epoch 20852 - Train Loss: 0.076936, Train Acc: 0.887179 | Val Loss: 0.106904, Val Acc: 0.793814\n",
      "Epoch 20853 - Train Loss: 0.076934, Train Acc: 0.887179 | Val Loss: 0.106903, Val Acc: 0.793814\n",
      "Epoch 20854 - Train Loss: 0.076932, Train Acc: 0.887179 | Val Loss: 0.106902, Val Acc: 0.793814\n",
      "Epoch 20855 - Train Loss: 0.076930, Train Acc: 0.887179 | Val Loss: 0.106902, Val Acc: 0.793814\n",
      "Epoch 20856 - Train Loss: 0.076928, Train Acc: 0.887179 | Val Loss: 0.106901, Val Acc: 0.793814\n",
      "Epoch 20857 - Train Loss: 0.076926, Train Acc: 0.887179 | Val Loss: 0.106900, Val Acc: 0.793814\n",
      "Epoch 20858 - Train Loss: 0.076924, Train Acc: 0.887179 | Val Loss: 0.106900, Val Acc: 0.793814\n",
      "Epoch 20859 - Train Loss: 0.076922, Train Acc: 0.887179 | Val Loss: 0.106899, Val Acc: 0.793814\n",
      "Epoch 20860 - Train Loss: 0.076920, Train Acc: 0.887179 | Val Loss: 0.106898, Val Acc: 0.793814\n",
      "Epoch 20861 - Train Loss: 0.076918, Train Acc: 0.887179 | Val Loss: 0.106897, Val Acc: 0.793814\n",
      "Epoch 20862 - Train Loss: 0.076916, Train Acc: 0.887179 | Val Loss: 0.106897, Val Acc: 0.793814\n",
      "Epoch 20863 - Train Loss: 0.076914, Train Acc: 0.887179 | Val Loss: 0.106896, Val Acc: 0.793814\n",
      "Epoch 20864 - Train Loss: 0.076912, Train Acc: 0.887179 | Val Loss: 0.106895, Val Acc: 0.793814\n",
      "Epoch 20865 - Train Loss: 0.076910, Train Acc: 0.887179 | Val Loss: 0.106894, Val Acc: 0.793814\n",
      "Epoch 20866 - Train Loss: 0.076908, Train Acc: 0.887179 | Val Loss: 0.106894, Val Acc: 0.793814\n",
      "Epoch 20867 - Train Loss: 0.076906, Train Acc: 0.887179 | Val Loss: 0.106893, Val Acc: 0.793814\n",
      "Epoch 20868 - Train Loss: 0.076904, Train Acc: 0.887179 | Val Loss: 0.106892, Val Acc: 0.793814\n",
      "Epoch 20869 - Train Loss: 0.076902, Train Acc: 0.887179 | Val Loss: 0.106892, Val Acc: 0.793814\n",
      "Epoch 20870 - Train Loss: 0.076900, Train Acc: 0.887179 | Val Loss: 0.106891, Val Acc: 0.793814\n",
      "Epoch 20871 - Train Loss: 0.076898, Train Acc: 0.887179 | Val Loss: 0.106890, Val Acc: 0.793814\n",
      "Epoch 20872 - Train Loss: 0.076896, Train Acc: 0.887179 | Val Loss: 0.106889, Val Acc: 0.793814\n",
      "Epoch 20873 - Train Loss: 0.076895, Train Acc: 0.887179 | Val Loss: 0.106889, Val Acc: 0.793814\n",
      "Epoch 20874 - Train Loss: 0.076893, Train Acc: 0.887179 | Val Loss: 0.106888, Val Acc: 0.793814\n",
      "Epoch 20875 - Train Loss: 0.076891, Train Acc: 0.887179 | Val Loss: 0.106887, Val Acc: 0.793814\n",
      "Epoch 20876 - Train Loss: 0.076889, Train Acc: 0.887179 | Val Loss: 0.106886, Val Acc: 0.793814\n",
      "Epoch 20877 - Train Loss: 0.076887, Train Acc: 0.887179 | Val Loss: 0.106886, Val Acc: 0.793814\n",
      "Epoch 20878 - Train Loss: 0.076885, Train Acc: 0.887179 | Val Loss: 0.106885, Val Acc: 0.793814\n",
      "Epoch 20879 - Train Loss: 0.076883, Train Acc: 0.887179 | Val Loss: 0.106884, Val Acc: 0.793814\n",
      "Epoch 20880 - Train Loss: 0.076881, Train Acc: 0.887179 | Val Loss: 0.106884, Val Acc: 0.793814\n",
      "Epoch 20881 - Train Loss: 0.076879, Train Acc: 0.887179 | Val Loss: 0.106883, Val Acc: 0.793814\n",
      "Epoch 20882 - Train Loss: 0.076877, Train Acc: 0.887179 | Val Loss: 0.106882, Val Acc: 0.793814\n",
      "Epoch 20883 - Train Loss: 0.076875, Train Acc: 0.887179 | Val Loss: 0.106881, Val Acc: 0.793814\n",
      "Epoch 20884 - Train Loss: 0.076873, Train Acc: 0.887179 | Val Loss: 0.106881, Val Acc: 0.793814\n",
      "Epoch 20885 - Train Loss: 0.076871, Train Acc: 0.887179 | Val Loss: 0.106880, Val Acc: 0.793814\n",
      "Epoch 20886 - Train Loss: 0.076869, Train Acc: 0.887179 | Val Loss: 0.106879, Val Acc: 0.793814\n",
      "Epoch 20887 - Train Loss: 0.076867, Train Acc: 0.887179 | Val Loss: 0.106878, Val Acc: 0.793814\n",
      "Epoch 20888 - Train Loss: 0.076865, Train Acc: 0.887179 | Val Loss: 0.106878, Val Acc: 0.793814\n",
      "Epoch 20889 - Train Loss: 0.076863, Train Acc: 0.887179 | Val Loss: 0.106877, Val Acc: 0.793814\n",
      "Epoch 20890 - Train Loss: 0.076861, Train Acc: 0.887179 | Val Loss: 0.106876, Val Acc: 0.793814\n",
      "Epoch 20891 - Train Loss: 0.076859, Train Acc: 0.887179 | Val Loss: 0.106876, Val Acc: 0.793814\n",
      "Epoch 20892 - Train Loss: 0.076857, Train Acc: 0.887179 | Val Loss: 0.106875, Val Acc: 0.793814\n",
      "Epoch 20893 - Train Loss: 0.076855, Train Acc: 0.887179 | Val Loss: 0.106874, Val Acc: 0.793814\n",
      "Epoch 20894 - Train Loss: 0.076853, Train Acc: 0.887179 | Val Loss: 0.106873, Val Acc: 0.793814\n",
      "Epoch 20895 - Train Loss: 0.076852, Train Acc: 0.887179 | Val Loss: 0.106873, Val Acc: 0.793814\n",
      "Epoch 20896 - Train Loss: 0.076850, Train Acc: 0.887179 | Val Loss: 0.106872, Val Acc: 0.793814\n",
      "Epoch 20897 - Train Loss: 0.076848, Train Acc: 0.887179 | Val Loss: 0.106871, Val Acc: 0.793814\n",
      "Epoch 20898 - Train Loss: 0.076846, Train Acc: 0.887179 | Val Loss: 0.106870, Val Acc: 0.793814\n",
      "Epoch 20899 - Train Loss: 0.076844, Train Acc: 0.887179 | Val Loss: 0.106870, Val Acc: 0.793814\n",
      "Epoch 20900 - Train Loss: 0.076842, Train Acc: 0.887179 | Val Loss: 0.106869, Val Acc: 0.793814\n",
      "Epoch 20901 - Train Loss: 0.076840, Train Acc: 0.887179 | Val Loss: 0.106868, Val Acc: 0.793814\n",
      "Epoch 20902 - Train Loss: 0.076838, Train Acc: 0.887179 | Val Loss: 0.106868, Val Acc: 0.793814\n",
      "Epoch 20903 - Train Loss: 0.076836, Train Acc: 0.887179 | Val Loss: 0.106867, Val Acc: 0.793814\n",
      "Epoch 20904 - Train Loss: 0.076834, Train Acc: 0.887179 | Val Loss: 0.106866, Val Acc: 0.793814\n",
      "Epoch 20905 - Train Loss: 0.076832, Train Acc: 0.887179 | Val Loss: 0.106865, Val Acc: 0.793814\n",
      "Epoch 20906 - Train Loss: 0.076830, Train Acc: 0.887179 | Val Loss: 0.106865, Val Acc: 0.793814\n",
      "Epoch 20907 - Train Loss: 0.076828, Train Acc: 0.887179 | Val Loss: 0.106864, Val Acc: 0.793814\n",
      "Epoch 20908 - Train Loss: 0.076826, Train Acc: 0.887179 | Val Loss: 0.106863, Val Acc: 0.793814\n",
      "Epoch 20909 - Train Loss: 0.076824, Train Acc: 0.887179 | Val Loss: 0.106862, Val Acc: 0.793814\n",
      "Epoch 20910 - Train Loss: 0.076822, Train Acc: 0.887179 | Val Loss: 0.106862, Val Acc: 0.793814\n",
      "Epoch 20911 - Train Loss: 0.076820, Train Acc: 0.887179 | Val Loss: 0.106861, Val Acc: 0.793814\n",
      "Epoch 20912 - Train Loss: 0.076818, Train Acc: 0.887179 | Val Loss: 0.106860, Val Acc: 0.793814\n",
      "Epoch 20913 - Train Loss: 0.076816, Train Acc: 0.887179 | Val Loss: 0.106860, Val Acc: 0.793814\n",
      "Epoch 20914 - Train Loss: 0.076814, Train Acc: 0.887179 | Val Loss: 0.106859, Val Acc: 0.793814\n",
      "Epoch 20915 - Train Loss: 0.076812, Train Acc: 0.887179 | Val Loss: 0.106858, Val Acc: 0.793814\n",
      "Epoch 20916 - Train Loss: 0.076811, Train Acc: 0.887179 | Val Loss: 0.106857, Val Acc: 0.793814\n",
      "Epoch 20917 - Train Loss: 0.076809, Train Acc: 0.887179 | Val Loss: 0.106857, Val Acc: 0.793814\n",
      "Epoch 20918 - Train Loss: 0.076807, Train Acc: 0.887179 | Val Loss: 0.106856, Val Acc: 0.793814\n",
      "Epoch 20919 - Train Loss: 0.076805, Train Acc: 0.887179 | Val Loss: 0.106855, Val Acc: 0.793814\n",
      "Epoch 20920 - Train Loss: 0.076803, Train Acc: 0.887179 | Val Loss: 0.106855, Val Acc: 0.793814\n",
      "Epoch 20921 - Train Loss: 0.076801, Train Acc: 0.887179 | Val Loss: 0.106854, Val Acc: 0.793814\n",
      "Epoch 20922 - Train Loss: 0.076799, Train Acc: 0.887179 | Val Loss: 0.106853, Val Acc: 0.793814\n",
      "Epoch 20923 - Train Loss: 0.076797, Train Acc: 0.887179 | Val Loss: 0.106852, Val Acc: 0.793814\n",
      "Epoch 20924 - Train Loss: 0.076795, Train Acc: 0.887179 | Val Loss: 0.106852, Val Acc: 0.793814\n",
      "Epoch 20925 - Train Loss: 0.076793, Train Acc: 0.887179 | Val Loss: 0.106851, Val Acc: 0.793814\n",
      "Epoch 20926 - Train Loss: 0.076791, Train Acc: 0.887179 | Val Loss: 0.106850, Val Acc: 0.793814\n",
      "Epoch 20927 - Train Loss: 0.076789, Train Acc: 0.887179 | Val Loss: 0.106850, Val Acc: 0.793814\n",
      "Epoch 20928 - Train Loss: 0.076787, Train Acc: 0.887179 | Val Loss: 0.106849, Val Acc: 0.793814\n",
      "Epoch 20929 - Train Loss: 0.076785, Train Acc: 0.887179 | Val Loss: 0.106848, Val Acc: 0.793814\n",
      "Epoch 20930 - Train Loss: 0.076783, Train Acc: 0.887179 | Val Loss: 0.106847, Val Acc: 0.793814\n",
      "Epoch 20931 - Train Loss: 0.076781, Train Acc: 0.887179 | Val Loss: 0.106847, Val Acc: 0.793814\n",
      "Epoch 20932 - Train Loss: 0.076779, Train Acc: 0.887179 | Val Loss: 0.106846, Val Acc: 0.793814\n",
      "Epoch 20933 - Train Loss: 0.076777, Train Acc: 0.887179 | Val Loss: 0.106845, Val Acc: 0.793814\n",
      "Epoch 20934 - Train Loss: 0.076775, Train Acc: 0.887179 | Val Loss: 0.106845, Val Acc: 0.793814\n",
      "Epoch 20935 - Train Loss: 0.076774, Train Acc: 0.887179 | Val Loss: 0.106844, Val Acc: 0.793814\n",
      "Epoch 20936 - Train Loss: 0.076772, Train Acc: 0.887179 | Val Loss: 0.106843, Val Acc: 0.793814\n",
      "Epoch 20937 - Train Loss: 0.076770, Train Acc: 0.887179 | Val Loss: 0.106842, Val Acc: 0.793814\n",
      "Epoch 20938 - Train Loss: 0.076768, Train Acc: 0.887179 | Val Loss: 0.106842, Val Acc: 0.793814\n",
      "Epoch 20939 - Train Loss: 0.076766, Train Acc: 0.887179 | Val Loss: 0.106841, Val Acc: 0.793814\n",
      "Epoch 20940 - Train Loss: 0.076764, Train Acc: 0.887179 | Val Loss: 0.106840, Val Acc: 0.793814\n",
      "Epoch 20941 - Train Loss: 0.076762, Train Acc: 0.887179 | Val Loss: 0.106839, Val Acc: 0.793814\n",
      "Epoch 20942 - Train Loss: 0.076760, Train Acc: 0.887179 | Val Loss: 0.106839, Val Acc: 0.793814\n",
      "Epoch 20943 - Train Loss: 0.076758, Train Acc: 0.887179 | Val Loss: 0.106838, Val Acc: 0.793814\n",
      "Epoch 20944 - Train Loss: 0.076756, Train Acc: 0.887179 | Val Loss: 0.106837, Val Acc: 0.793814\n",
      "Epoch 20945 - Train Loss: 0.076754, Train Acc: 0.887179 | Val Loss: 0.106837, Val Acc: 0.793814\n",
      "Epoch 20946 - Train Loss: 0.076752, Train Acc: 0.887179 | Val Loss: 0.106836, Val Acc: 0.793814\n",
      "Epoch 20947 - Train Loss: 0.076750, Train Acc: 0.887179 | Val Loss: 0.106835, Val Acc: 0.793814\n",
      "Epoch 20948 - Train Loss: 0.076748, Train Acc: 0.887179 | Val Loss: 0.106835, Val Acc: 0.793814\n",
      "Epoch 20949 - Train Loss: 0.076746, Train Acc: 0.887179 | Val Loss: 0.106834, Val Acc: 0.793814\n",
      "Epoch 20950 - Train Loss: 0.076744, Train Acc: 0.887179 | Val Loss: 0.106833, Val Acc: 0.793814\n",
      "Epoch 20951 - Train Loss: 0.076742, Train Acc: 0.887179 | Val Loss: 0.106832, Val Acc: 0.793814\n",
      "Epoch 20952 - Train Loss: 0.076740, Train Acc: 0.887179 | Val Loss: 0.106832, Val Acc: 0.793814\n",
      "Epoch 20953 - Train Loss: 0.076739, Train Acc: 0.887179 | Val Loss: 0.106831, Val Acc: 0.793814\n",
      "Epoch 20954 - Train Loss: 0.076737, Train Acc: 0.887179 | Val Loss: 0.106830, Val Acc: 0.793814\n",
      "Epoch 20955 - Train Loss: 0.076735, Train Acc: 0.887179 | Val Loss: 0.106830, Val Acc: 0.793814\n",
      "Epoch 20956 - Train Loss: 0.076733, Train Acc: 0.887179 | Val Loss: 0.106829, Val Acc: 0.793814\n",
      "Epoch 20957 - Train Loss: 0.076731, Train Acc: 0.887179 | Val Loss: 0.106828, Val Acc: 0.793814\n",
      "Epoch 20958 - Train Loss: 0.076729, Train Acc: 0.887179 | Val Loss: 0.106827, Val Acc: 0.793814\n",
      "Epoch 20959 - Train Loss: 0.076727, Train Acc: 0.887179 | Val Loss: 0.106827, Val Acc: 0.793814\n",
      "Epoch 20960 - Train Loss: 0.076725, Train Acc: 0.887179 | Val Loss: 0.106826, Val Acc: 0.793814\n",
      "Epoch 20961 - Train Loss: 0.076723, Train Acc: 0.887179 | Val Loss: 0.106825, Val Acc: 0.793814\n",
      "Epoch 20962 - Train Loss: 0.076721, Train Acc: 0.887179 | Val Loss: 0.106825, Val Acc: 0.793814\n",
      "Epoch 20963 - Train Loss: 0.076719, Train Acc: 0.887179 | Val Loss: 0.106824, Val Acc: 0.793814\n",
      "Epoch 20964 - Train Loss: 0.076717, Train Acc: 0.887179 | Val Loss: 0.106823, Val Acc: 0.793814\n",
      "Epoch 20965 - Train Loss: 0.076715, Train Acc: 0.887179 | Val Loss: 0.106822, Val Acc: 0.793814\n",
      "Epoch 20966 - Train Loss: 0.076713, Train Acc: 0.887179 | Val Loss: 0.106822, Val Acc: 0.793814\n",
      "Epoch 20967 - Train Loss: 0.076711, Train Acc: 0.887179 | Val Loss: 0.106821, Val Acc: 0.793814\n",
      "Epoch 20968 - Train Loss: 0.076709, Train Acc: 0.887179 | Val Loss: 0.106820, Val Acc: 0.793814\n",
      "Epoch 20969 - Train Loss: 0.076707, Train Acc: 0.887179 | Val Loss: 0.106820, Val Acc: 0.793814\n",
      "Epoch 20970 - Train Loss: 0.076706, Train Acc: 0.887179 | Val Loss: 0.106819, Val Acc: 0.793814\n",
      "Epoch 20971 - Train Loss: 0.076704, Train Acc: 0.887179 | Val Loss: 0.106818, Val Acc: 0.793814\n",
      "Epoch 20972 - Train Loss: 0.076702, Train Acc: 0.887179 | Val Loss: 0.106817, Val Acc: 0.793814\n",
      "Epoch 20973 - Train Loss: 0.076700, Train Acc: 0.887179 | Val Loss: 0.106817, Val Acc: 0.793814\n",
      "Epoch 20974 - Train Loss: 0.076698, Train Acc: 0.887179 | Val Loss: 0.106816, Val Acc: 0.793814\n",
      "Epoch 20975 - Train Loss: 0.076696, Train Acc: 0.887179 | Val Loss: 0.106815, Val Acc: 0.793814\n",
      "Epoch 20976 - Train Loss: 0.076694, Train Acc: 0.887179 | Val Loss: 0.106815, Val Acc: 0.793814\n",
      "Epoch 20977 - Train Loss: 0.076692, Train Acc: 0.887179 | Val Loss: 0.106814, Val Acc: 0.793814\n",
      "Epoch 20978 - Train Loss: 0.076690, Train Acc: 0.887179 | Val Loss: 0.106813, Val Acc: 0.793814\n",
      "Epoch 20979 - Train Loss: 0.076688, Train Acc: 0.887179 | Val Loss: 0.106812, Val Acc: 0.793814\n",
      "Epoch 20980 - Train Loss: 0.076686, Train Acc: 0.887179 | Val Loss: 0.106812, Val Acc: 0.793814\n",
      "Epoch 20981 - Train Loss: 0.076684, Train Acc: 0.887179 | Val Loss: 0.106811, Val Acc: 0.793814\n",
      "Epoch 20982 - Train Loss: 0.076682, Train Acc: 0.887179 | Val Loss: 0.106810, Val Acc: 0.793814\n",
      "Epoch 20983 - Train Loss: 0.076680, Train Acc: 0.887179 | Val Loss: 0.106810, Val Acc: 0.793814\n",
      "Epoch 20984 - Train Loss: 0.076678, Train Acc: 0.887179 | Val Loss: 0.106809, Val Acc: 0.793814\n",
      "Epoch 20985 - Train Loss: 0.076676, Train Acc: 0.887179 | Val Loss: 0.106808, Val Acc: 0.793814\n",
      "Epoch 20986 - Train Loss: 0.076674, Train Acc: 0.887179 | Val Loss: 0.106807, Val Acc: 0.793814\n",
      "Epoch 20987 - Train Loss: 0.076673, Train Acc: 0.887179 | Val Loss: 0.106807, Val Acc: 0.793814\n",
      "Epoch 20988 - Train Loss: 0.076671, Train Acc: 0.887179 | Val Loss: 0.106806, Val Acc: 0.793814\n",
      "Epoch 20989 - Train Loss: 0.076669, Train Acc: 0.887179 | Val Loss: 0.106805, Val Acc: 0.793814\n",
      "Epoch 20990 - Train Loss: 0.076667, Train Acc: 0.887179 | Val Loss: 0.106805, Val Acc: 0.793814\n",
      "Epoch 20991 - Train Loss: 0.076665, Train Acc: 0.887179 | Val Loss: 0.106804, Val Acc: 0.793814\n",
      "Epoch 20992 - Train Loss: 0.076663, Train Acc: 0.887179 | Val Loss: 0.106803, Val Acc: 0.793814\n",
      "Epoch 20993 - Train Loss: 0.076661, Train Acc: 0.887179 | Val Loss: 0.106803, Val Acc: 0.793814\n",
      "Epoch 20994 - Train Loss: 0.076659, Train Acc: 0.887179 | Val Loss: 0.106802, Val Acc: 0.793814\n",
      "Epoch 20995 - Train Loss: 0.076657, Train Acc: 0.887179 | Val Loss: 0.106801, Val Acc: 0.793814\n",
      "Epoch 20996 - Train Loss: 0.076655, Train Acc: 0.887179 | Val Loss: 0.106800, Val Acc: 0.793814\n",
      "Epoch 20997 - Train Loss: 0.076653, Train Acc: 0.887179 | Val Loss: 0.106800, Val Acc: 0.793814\n",
      "Epoch 20998 - Train Loss: 0.076651, Train Acc: 0.887179 | Val Loss: 0.106799, Val Acc: 0.793814\n",
      "Epoch 20999 - Train Loss: 0.076649, Train Acc: 0.887179 | Val Loss: 0.106798, Val Acc: 0.793814\n",
      "Epoch 21000 - Train Loss: 0.076647, Train Acc: 0.887179 | Val Loss: 0.106798, Val Acc: 0.793814\n",
      "Epoch 21001 - Train Loss: 0.076645, Train Acc: 0.887179 | Val Loss: 0.106797, Val Acc: 0.793814\n",
      "Epoch 21002 - Train Loss: 0.076644, Train Acc: 0.887179 | Val Loss: 0.106796, Val Acc: 0.793814\n",
      "Epoch 21003 - Train Loss: 0.076642, Train Acc: 0.887179 | Val Loss: 0.106795, Val Acc: 0.793814\n",
      "Epoch 21004 - Train Loss: 0.076640, Train Acc: 0.887179 | Val Loss: 0.106795, Val Acc: 0.793814\n",
      "Epoch 21005 - Train Loss: 0.076638, Train Acc: 0.887179 | Val Loss: 0.106794, Val Acc: 0.793814\n",
      "Epoch 21006 - Train Loss: 0.076636, Train Acc: 0.887179 | Val Loss: 0.106793, Val Acc: 0.793814\n",
      "Epoch 21007 - Train Loss: 0.076634, Train Acc: 0.887179 | Val Loss: 0.106793, Val Acc: 0.793814\n",
      "Epoch 21008 - Train Loss: 0.076632, Train Acc: 0.887179 | Val Loss: 0.106792, Val Acc: 0.793814\n",
      "Epoch 21009 - Train Loss: 0.076630, Train Acc: 0.887179 | Val Loss: 0.106791, Val Acc: 0.793814\n",
      "Epoch 21010 - Train Loss: 0.076628, Train Acc: 0.887179 | Val Loss: 0.106790, Val Acc: 0.793814\n",
      "Epoch 21011 - Train Loss: 0.076626, Train Acc: 0.887179 | Val Loss: 0.106790, Val Acc: 0.793814\n",
      "Epoch 21012 - Train Loss: 0.076624, Train Acc: 0.887179 | Val Loss: 0.106789, Val Acc: 0.793814\n",
      "Epoch 21013 - Train Loss: 0.076622, Train Acc: 0.887179 | Val Loss: 0.106788, Val Acc: 0.793814\n",
      "Epoch 21014 - Train Loss: 0.076620, Train Acc: 0.887179 | Val Loss: 0.106788, Val Acc: 0.793814\n",
      "Epoch 21015 - Train Loss: 0.076618, Train Acc: 0.887179 | Val Loss: 0.106787, Val Acc: 0.793814\n",
      "Epoch 21016 - Train Loss: 0.076616, Train Acc: 0.887179 | Val Loss: 0.106786, Val Acc: 0.793814\n",
      "Epoch 21017 - Train Loss: 0.076615, Train Acc: 0.887179 | Val Loss: 0.106786, Val Acc: 0.793814\n",
      "Epoch 21018 - Train Loss: 0.076613, Train Acc: 0.887179 | Val Loss: 0.106785, Val Acc: 0.793814\n",
      "Epoch 21019 - Train Loss: 0.076611, Train Acc: 0.887179 | Val Loss: 0.106784, Val Acc: 0.793814\n",
      "Epoch 21020 - Train Loss: 0.076609, Train Acc: 0.887179 | Val Loss: 0.106783, Val Acc: 0.793814\n",
      "Epoch 21021 - Train Loss: 0.076607, Train Acc: 0.887179 | Val Loss: 0.106783, Val Acc: 0.793814\n",
      "Epoch 21022 - Train Loss: 0.076605, Train Acc: 0.887179 | Val Loss: 0.106782, Val Acc: 0.793814\n",
      "Epoch 21023 - Train Loss: 0.076603, Train Acc: 0.887179 | Val Loss: 0.106781, Val Acc: 0.793814\n",
      "Epoch 21024 - Train Loss: 0.076601, Train Acc: 0.887179 | Val Loss: 0.106781, Val Acc: 0.793814\n",
      "Epoch 21025 - Train Loss: 0.076599, Train Acc: 0.887179 | Val Loss: 0.106780, Val Acc: 0.793814\n",
      "Epoch 21026 - Train Loss: 0.076597, Train Acc: 0.887179 | Val Loss: 0.106779, Val Acc: 0.793814\n",
      "Epoch 21027 - Train Loss: 0.076595, Train Acc: 0.887179 | Val Loss: 0.106779, Val Acc: 0.793814\n",
      "Epoch 21028 - Train Loss: 0.076593, Train Acc: 0.887179 | Val Loss: 0.106778, Val Acc: 0.793814\n",
      "Epoch 21029 - Train Loss: 0.076591, Train Acc: 0.887179 | Val Loss: 0.106777, Val Acc: 0.793814\n",
      "Epoch 21030 - Train Loss: 0.076589, Train Acc: 0.887179 | Val Loss: 0.106777, Val Acc: 0.793814\n",
      "Epoch 21031 - Train Loss: 0.076588, Train Acc: 0.887179 | Val Loss: 0.106776, Val Acc: 0.793814\n",
      "Epoch 21032 - Train Loss: 0.076586, Train Acc: 0.887179 | Val Loss: 0.106775, Val Acc: 0.793814\n",
      "Epoch 21033 - Train Loss: 0.076584, Train Acc: 0.887179 | Val Loss: 0.106774, Val Acc: 0.793814\n",
      "Epoch 21034 - Train Loss: 0.076582, Train Acc: 0.887179 | Val Loss: 0.106774, Val Acc: 0.793814\n",
      "Epoch 21035 - Train Loss: 0.076580, Train Acc: 0.887179 | Val Loss: 0.106773, Val Acc: 0.793814\n",
      "Epoch 21036 - Train Loss: 0.076578, Train Acc: 0.887179 | Val Loss: 0.106772, Val Acc: 0.793814\n",
      "Epoch 21037 - Train Loss: 0.076576, Train Acc: 0.887179 | Val Loss: 0.106772, Val Acc: 0.793814\n",
      "Epoch 21038 - Train Loss: 0.076574, Train Acc: 0.887179 | Val Loss: 0.106771, Val Acc: 0.793814\n",
      "Epoch 21039 - Train Loss: 0.076572, Train Acc: 0.887179 | Val Loss: 0.106770, Val Acc: 0.793814\n",
      "Epoch 21040 - Train Loss: 0.076570, Train Acc: 0.887179 | Val Loss: 0.106769, Val Acc: 0.793814\n",
      "Epoch 21041 - Train Loss: 0.076568, Train Acc: 0.887179 | Val Loss: 0.106769, Val Acc: 0.793814\n",
      "Epoch 21042 - Train Loss: 0.076566, Train Acc: 0.887179 | Val Loss: 0.106768, Val Acc: 0.793814\n",
      "Epoch 21043 - Train Loss: 0.076564, Train Acc: 0.887179 | Val Loss: 0.106767, Val Acc: 0.793814\n",
      "Epoch 21044 - Train Loss: 0.076562, Train Acc: 0.887179 | Val Loss: 0.106767, Val Acc: 0.793814\n",
      "Epoch 21045 - Train Loss: 0.076561, Train Acc: 0.887179 | Val Loss: 0.106766, Val Acc: 0.793814\n",
      "Epoch 21046 - Train Loss: 0.076559, Train Acc: 0.887179 | Val Loss: 0.106765, Val Acc: 0.793814\n",
      "Epoch 21047 - Train Loss: 0.076557, Train Acc: 0.887179 | Val Loss: 0.106765, Val Acc: 0.793814\n",
      "Epoch 21048 - Train Loss: 0.076555, Train Acc: 0.887179 | Val Loss: 0.106764, Val Acc: 0.793814\n",
      "Epoch 21049 - Train Loss: 0.076553, Train Acc: 0.887179 | Val Loss: 0.106763, Val Acc: 0.793814\n",
      "Epoch 21050 - Train Loss: 0.076551, Train Acc: 0.887179 | Val Loss: 0.106763, Val Acc: 0.793814\n",
      "Epoch 21051 - Train Loss: 0.076549, Train Acc: 0.887179 | Val Loss: 0.106762, Val Acc: 0.793814\n",
      "Epoch 21052 - Train Loss: 0.076547, Train Acc: 0.887179 | Val Loss: 0.106761, Val Acc: 0.793814\n",
      "Epoch 21053 - Train Loss: 0.076545, Train Acc: 0.887179 | Val Loss: 0.106760, Val Acc: 0.793814\n",
      "Epoch 21054 - Train Loss: 0.076543, Train Acc: 0.887179 | Val Loss: 0.106760, Val Acc: 0.793814\n",
      "Epoch 21055 - Train Loss: 0.076541, Train Acc: 0.887179 | Val Loss: 0.106759, Val Acc: 0.793814\n",
      "Epoch 21056 - Train Loss: 0.076539, Train Acc: 0.887179 | Val Loss: 0.106758, Val Acc: 0.793814\n",
      "Epoch 21057 - Train Loss: 0.076537, Train Acc: 0.887179 | Val Loss: 0.106758, Val Acc: 0.793814\n",
      "Epoch 21058 - Train Loss: 0.076535, Train Acc: 0.887179 | Val Loss: 0.106757, Val Acc: 0.793814\n",
      "Epoch 21059 - Train Loss: 0.076534, Train Acc: 0.887179 | Val Loss: 0.106756, Val Acc: 0.793814\n",
      "Epoch 21060 - Train Loss: 0.076532, Train Acc: 0.887179 | Val Loss: 0.106756, Val Acc: 0.793814\n",
      "Epoch 21061 - Train Loss: 0.076530, Train Acc: 0.887179 | Val Loss: 0.106755, Val Acc: 0.793814\n",
      "Epoch 21062 - Train Loss: 0.076528, Train Acc: 0.887179 | Val Loss: 0.106754, Val Acc: 0.793814\n",
      "Epoch 21063 - Train Loss: 0.076526, Train Acc: 0.887179 | Val Loss: 0.106753, Val Acc: 0.793814\n",
      "Epoch 21064 - Train Loss: 0.076524, Train Acc: 0.887179 | Val Loss: 0.106753, Val Acc: 0.793814\n",
      "Epoch 21065 - Train Loss: 0.076522, Train Acc: 0.887179 | Val Loss: 0.106752, Val Acc: 0.793814\n",
      "Epoch 21066 - Train Loss: 0.076520, Train Acc: 0.887179 | Val Loss: 0.106751, Val Acc: 0.793814\n",
      "Epoch 21067 - Train Loss: 0.076518, Train Acc: 0.887179 | Val Loss: 0.106751, Val Acc: 0.793814\n",
      "Epoch 21068 - Train Loss: 0.076516, Train Acc: 0.887179 | Val Loss: 0.106750, Val Acc: 0.793814\n",
      "Epoch 21069 - Train Loss: 0.076514, Train Acc: 0.887179 | Val Loss: 0.106749, Val Acc: 0.793814\n",
      "Epoch 21070 - Train Loss: 0.076512, Train Acc: 0.887179 | Val Loss: 0.106749, Val Acc: 0.793814\n",
      "Epoch 21071 - Train Loss: 0.076510, Train Acc: 0.887179 | Val Loss: 0.106748, Val Acc: 0.793814\n",
      "Epoch 21072 - Train Loss: 0.076509, Train Acc: 0.887179 | Val Loss: 0.106747, Val Acc: 0.793814\n",
      "Epoch 21073 - Train Loss: 0.076507, Train Acc: 0.887179 | Val Loss: 0.106747, Val Acc: 0.793814\n",
      "Epoch 21074 - Train Loss: 0.076505, Train Acc: 0.887179 | Val Loss: 0.106746, Val Acc: 0.793814\n",
      "Epoch 21075 - Train Loss: 0.076503, Train Acc: 0.887179 | Val Loss: 0.106745, Val Acc: 0.793814\n",
      "Epoch 21076 - Train Loss: 0.076501, Train Acc: 0.887179 | Val Loss: 0.106744, Val Acc: 0.793814\n",
      "Epoch 21077 - Train Loss: 0.076499, Train Acc: 0.887179 | Val Loss: 0.106744, Val Acc: 0.793814\n",
      "Epoch 21078 - Train Loss: 0.076497, Train Acc: 0.887179 | Val Loss: 0.106743, Val Acc: 0.793814\n",
      "Epoch 21079 - Train Loss: 0.076495, Train Acc: 0.887179 | Val Loss: 0.106742, Val Acc: 0.793814\n",
      "Epoch 21080 - Train Loss: 0.076493, Train Acc: 0.887179 | Val Loss: 0.106742, Val Acc: 0.793814\n",
      "Epoch 21081 - Train Loss: 0.076491, Train Acc: 0.887179 | Val Loss: 0.106741, Val Acc: 0.793814\n",
      "Epoch 21082 - Train Loss: 0.076489, Train Acc: 0.887179 | Val Loss: 0.106740, Val Acc: 0.793814\n",
      "Epoch 21083 - Train Loss: 0.076487, Train Acc: 0.887179 | Val Loss: 0.106740, Val Acc: 0.793814\n",
      "Epoch 21084 - Train Loss: 0.076486, Train Acc: 0.887179 | Val Loss: 0.106739, Val Acc: 0.793814\n",
      "Epoch 21085 - Train Loss: 0.076484, Train Acc: 0.887179 | Val Loss: 0.106738, Val Acc: 0.793814\n",
      "Epoch 21086 - Train Loss: 0.076482, Train Acc: 0.887179 | Val Loss: 0.106738, Val Acc: 0.793814\n",
      "Epoch 21087 - Train Loss: 0.076480, Train Acc: 0.887179 | Val Loss: 0.106737, Val Acc: 0.793814\n",
      "Epoch 21088 - Train Loss: 0.076478, Train Acc: 0.887179 | Val Loss: 0.106736, Val Acc: 0.793814\n",
      "Epoch 21089 - Train Loss: 0.076476, Train Acc: 0.887179 | Val Loss: 0.106735, Val Acc: 0.793814\n",
      "Epoch 21090 - Train Loss: 0.076474, Train Acc: 0.887179 | Val Loss: 0.106735, Val Acc: 0.793814\n",
      "Epoch 21091 - Train Loss: 0.076472, Train Acc: 0.887179 | Val Loss: 0.106734, Val Acc: 0.793814\n",
      "Epoch 21092 - Train Loss: 0.076470, Train Acc: 0.887179 | Val Loss: 0.106733, Val Acc: 0.793814\n",
      "Epoch 21093 - Train Loss: 0.076468, Train Acc: 0.887179 | Val Loss: 0.106733, Val Acc: 0.793814\n",
      "Epoch 21094 - Train Loss: 0.076466, Train Acc: 0.887179 | Val Loss: 0.106732, Val Acc: 0.793814\n",
      "Epoch 21095 - Train Loss: 0.076464, Train Acc: 0.887179 | Val Loss: 0.106731, Val Acc: 0.793814\n",
      "Epoch 21096 - Train Loss: 0.076463, Train Acc: 0.887179 | Val Loss: 0.106731, Val Acc: 0.793814\n",
      "Epoch 21097 - Train Loss: 0.076461, Train Acc: 0.887179 | Val Loss: 0.106730, Val Acc: 0.793814\n",
      "Epoch 21098 - Train Loss: 0.076459, Train Acc: 0.887179 | Val Loss: 0.106729, Val Acc: 0.793814\n",
      "Epoch 21099 - Train Loss: 0.076457, Train Acc: 0.887179 | Val Loss: 0.106729, Val Acc: 0.793814\n",
      "Epoch 21100 - Train Loss: 0.076455, Train Acc: 0.887179 | Val Loss: 0.106728, Val Acc: 0.793814\n",
      "Epoch 21101 - Train Loss: 0.076453, Train Acc: 0.887179 | Val Loss: 0.106727, Val Acc: 0.793814\n",
      "Epoch 21102 - Train Loss: 0.076451, Train Acc: 0.887179 | Val Loss: 0.106727, Val Acc: 0.793814\n",
      "Epoch 21103 - Train Loss: 0.076449, Train Acc: 0.887179 | Val Loss: 0.106726, Val Acc: 0.793814\n",
      "Epoch 21104 - Train Loss: 0.076447, Train Acc: 0.887179 | Val Loss: 0.106725, Val Acc: 0.793814\n",
      "Epoch 21105 - Train Loss: 0.076445, Train Acc: 0.887179 | Val Loss: 0.106724, Val Acc: 0.793814\n",
      "Epoch 21106 - Train Loss: 0.076443, Train Acc: 0.887179 | Val Loss: 0.106724, Val Acc: 0.793814\n",
      "Epoch 21107 - Train Loss: 0.076441, Train Acc: 0.887179 | Val Loss: 0.106723, Val Acc: 0.793814\n",
      "Epoch 21108 - Train Loss: 0.076440, Train Acc: 0.887179 | Val Loss: 0.106722, Val Acc: 0.793814\n",
      "Epoch 21109 - Train Loss: 0.076438, Train Acc: 0.887179 | Val Loss: 0.106722, Val Acc: 0.793814\n",
      "Epoch 21110 - Train Loss: 0.076436, Train Acc: 0.887179 | Val Loss: 0.106721, Val Acc: 0.793814\n",
      "Epoch 21111 - Train Loss: 0.076434, Train Acc: 0.887179 | Val Loss: 0.106720, Val Acc: 0.793814\n",
      "Epoch 21112 - Train Loss: 0.076432, Train Acc: 0.887179 | Val Loss: 0.106720, Val Acc: 0.793814\n",
      "Epoch 21113 - Train Loss: 0.076430, Train Acc: 0.887179 | Val Loss: 0.106719, Val Acc: 0.793814\n",
      "Epoch 21114 - Train Loss: 0.076428, Train Acc: 0.887179 | Val Loss: 0.106718, Val Acc: 0.793814\n",
      "Epoch 21115 - Train Loss: 0.076426, Train Acc: 0.887179 | Val Loss: 0.106718, Val Acc: 0.793814\n",
      "Epoch 21116 - Train Loss: 0.076424, Train Acc: 0.887179 | Val Loss: 0.106717, Val Acc: 0.793814\n",
      "Epoch 21117 - Train Loss: 0.076422, Train Acc: 0.887179 | Val Loss: 0.106716, Val Acc: 0.793814\n",
      "Epoch 21118 - Train Loss: 0.076420, Train Acc: 0.887179 | Val Loss: 0.106716, Val Acc: 0.793814\n",
      "Epoch 21119 - Train Loss: 0.076418, Train Acc: 0.887179 | Val Loss: 0.106715, Val Acc: 0.793814\n",
      "Epoch 21120 - Train Loss: 0.076417, Train Acc: 0.887179 | Val Loss: 0.106714, Val Acc: 0.793814\n",
      "Epoch 21121 - Train Loss: 0.076415, Train Acc: 0.887179 | Val Loss: 0.106713, Val Acc: 0.793814\n",
      "Epoch 21122 - Train Loss: 0.076413, Train Acc: 0.887179 | Val Loss: 0.106713, Val Acc: 0.793814\n",
      "Epoch 21123 - Train Loss: 0.076411, Train Acc: 0.887179 | Val Loss: 0.106712, Val Acc: 0.793814\n",
      "Epoch 21124 - Train Loss: 0.076409, Train Acc: 0.887179 | Val Loss: 0.106711, Val Acc: 0.793814\n",
      "Epoch 21125 - Train Loss: 0.076407, Train Acc: 0.887179 | Val Loss: 0.106711, Val Acc: 0.793814\n",
      "Epoch 21126 - Train Loss: 0.076405, Train Acc: 0.887179 | Val Loss: 0.106710, Val Acc: 0.793814\n",
      "Epoch 21127 - Train Loss: 0.076403, Train Acc: 0.887179 | Val Loss: 0.106709, Val Acc: 0.793814\n",
      "Epoch 21128 - Train Loss: 0.076401, Train Acc: 0.887179 | Val Loss: 0.106709, Val Acc: 0.793814\n",
      "Epoch 21129 - Train Loss: 0.076399, Train Acc: 0.887179 | Val Loss: 0.106708, Val Acc: 0.793814\n",
      "Epoch 21130 - Train Loss: 0.076397, Train Acc: 0.887179 | Val Loss: 0.106707, Val Acc: 0.793814\n",
      "Epoch 21131 - Train Loss: 0.076396, Train Acc: 0.887179 | Val Loss: 0.106707, Val Acc: 0.793814\n",
      "Epoch 21132 - Train Loss: 0.076394, Train Acc: 0.887179 | Val Loss: 0.106706, Val Acc: 0.793814\n",
      "Epoch 21133 - Train Loss: 0.076392, Train Acc: 0.887179 | Val Loss: 0.106705, Val Acc: 0.793814\n",
      "Epoch 21134 - Train Loss: 0.076390, Train Acc: 0.887179 | Val Loss: 0.106705, Val Acc: 0.793814\n",
      "Epoch 21135 - Train Loss: 0.076388, Train Acc: 0.887179 | Val Loss: 0.106704, Val Acc: 0.793814\n",
      "Epoch 21136 - Train Loss: 0.076386, Train Acc: 0.887179 | Val Loss: 0.106703, Val Acc: 0.793814\n",
      "Epoch 21137 - Train Loss: 0.076384, Train Acc: 0.887179 | Val Loss: 0.106702, Val Acc: 0.793814\n",
      "Epoch 21138 - Train Loss: 0.076382, Train Acc: 0.887179 | Val Loss: 0.106702, Val Acc: 0.793814\n",
      "Epoch 21139 - Train Loss: 0.076380, Train Acc: 0.887179 | Val Loss: 0.106701, Val Acc: 0.793814\n",
      "Epoch 21140 - Train Loss: 0.076378, Train Acc: 0.887179 | Val Loss: 0.106700, Val Acc: 0.793814\n",
      "Epoch 21141 - Train Loss: 0.076376, Train Acc: 0.887179 | Val Loss: 0.106700, Val Acc: 0.793814\n",
      "Epoch 21142 - Train Loss: 0.076375, Train Acc: 0.887179 | Val Loss: 0.106699, Val Acc: 0.793814\n",
      "Epoch 21143 - Train Loss: 0.076373, Train Acc: 0.887179 | Val Loss: 0.106698, Val Acc: 0.793814\n",
      "Epoch 21144 - Train Loss: 0.076371, Train Acc: 0.887179 | Val Loss: 0.106698, Val Acc: 0.793814\n",
      "Epoch 21145 - Train Loss: 0.076369, Train Acc: 0.887179 | Val Loss: 0.106697, Val Acc: 0.793814\n",
      "Epoch 21146 - Train Loss: 0.076367, Train Acc: 0.887179 | Val Loss: 0.106696, Val Acc: 0.793814\n",
      "Epoch 21147 - Train Loss: 0.076365, Train Acc: 0.887179 | Val Loss: 0.106696, Val Acc: 0.793814\n",
      "Epoch 21148 - Train Loss: 0.076363, Train Acc: 0.887179 | Val Loss: 0.106695, Val Acc: 0.793814\n",
      "Epoch 21149 - Train Loss: 0.076361, Train Acc: 0.887179 | Val Loss: 0.106694, Val Acc: 0.793814\n",
      "Epoch 21150 - Train Loss: 0.076359, Train Acc: 0.887179 | Val Loss: 0.106694, Val Acc: 0.793814\n",
      "Epoch 21151 - Train Loss: 0.076357, Train Acc: 0.887179 | Val Loss: 0.106693, Val Acc: 0.793814\n",
      "Epoch 21152 - Train Loss: 0.076355, Train Acc: 0.887179 | Val Loss: 0.106692, Val Acc: 0.793814\n",
      "Epoch 21153 - Train Loss: 0.076354, Train Acc: 0.887179 | Val Loss: 0.106692, Val Acc: 0.793814\n",
      "Epoch 21154 - Train Loss: 0.076352, Train Acc: 0.887179 | Val Loss: 0.106691, Val Acc: 0.793814\n",
      "Epoch 21155 - Train Loss: 0.076350, Train Acc: 0.887179 | Val Loss: 0.106690, Val Acc: 0.793814\n",
      "Epoch 21156 - Train Loss: 0.076348, Train Acc: 0.887179 | Val Loss: 0.106689, Val Acc: 0.793814\n",
      "Epoch 21157 - Train Loss: 0.076346, Train Acc: 0.887179 | Val Loss: 0.106689, Val Acc: 0.793814\n",
      "Epoch 21158 - Train Loss: 0.076344, Train Acc: 0.887179 | Val Loss: 0.106688, Val Acc: 0.793814\n",
      "Epoch 21159 - Train Loss: 0.076342, Train Acc: 0.887179 | Val Loss: 0.106687, Val Acc: 0.793814\n",
      "Epoch 21160 - Train Loss: 0.076340, Train Acc: 0.887179 | Val Loss: 0.106687, Val Acc: 0.793814\n",
      "Epoch 21161 - Train Loss: 0.076338, Train Acc: 0.887179 | Val Loss: 0.106686, Val Acc: 0.793814\n",
      "Epoch 21162 - Train Loss: 0.076336, Train Acc: 0.887179 | Val Loss: 0.106685, Val Acc: 0.793814\n",
      "Epoch 21163 - Train Loss: 0.076334, Train Acc: 0.887179 | Val Loss: 0.106685, Val Acc: 0.793814\n",
      "Epoch 21164 - Train Loss: 0.076333, Train Acc: 0.887179 | Val Loss: 0.106684, Val Acc: 0.793814\n",
      "Epoch 21165 - Train Loss: 0.076331, Train Acc: 0.887179 | Val Loss: 0.106683, Val Acc: 0.793814\n",
      "Epoch 21166 - Train Loss: 0.076329, Train Acc: 0.887179 | Val Loss: 0.106683, Val Acc: 0.793814\n",
      "Epoch 21167 - Train Loss: 0.076327, Train Acc: 0.887179 | Val Loss: 0.106682, Val Acc: 0.793814\n",
      "Epoch 21168 - Train Loss: 0.076325, Train Acc: 0.887179 | Val Loss: 0.106681, Val Acc: 0.793814\n",
      "Epoch 21169 - Train Loss: 0.076323, Train Acc: 0.887179 | Val Loss: 0.106681, Val Acc: 0.793814\n",
      "Epoch 21170 - Train Loss: 0.076321, Train Acc: 0.887179 | Val Loss: 0.106680, Val Acc: 0.793814\n",
      "Epoch 21171 - Train Loss: 0.076319, Train Acc: 0.887179 | Val Loss: 0.106679, Val Acc: 0.793814\n",
      "Epoch 21172 - Train Loss: 0.076317, Train Acc: 0.887179 | Val Loss: 0.106679, Val Acc: 0.793814\n",
      "Epoch 21173 - Train Loss: 0.076315, Train Acc: 0.887179 | Val Loss: 0.106678, Val Acc: 0.793814\n",
      "Epoch 21174 - Train Loss: 0.076313, Train Acc: 0.887179 | Val Loss: 0.106677, Val Acc: 0.793814\n",
      "Epoch 21175 - Train Loss: 0.076312, Train Acc: 0.887179 | Val Loss: 0.106677, Val Acc: 0.793814\n",
      "Epoch 21176 - Train Loss: 0.076310, Train Acc: 0.887179 | Val Loss: 0.106676, Val Acc: 0.793814\n",
      "Epoch 21177 - Train Loss: 0.076308, Train Acc: 0.887179 | Val Loss: 0.106675, Val Acc: 0.793814\n",
      "Epoch 21178 - Train Loss: 0.076306, Train Acc: 0.887179 | Val Loss: 0.106675, Val Acc: 0.793814\n",
      "Epoch 21179 - Train Loss: 0.076304, Train Acc: 0.887179 | Val Loss: 0.106674, Val Acc: 0.793814\n",
      "Epoch 21180 - Train Loss: 0.076302, Train Acc: 0.887179 | Val Loss: 0.106673, Val Acc: 0.793814\n",
      "Epoch 21181 - Train Loss: 0.076300, Train Acc: 0.887179 | Val Loss: 0.106672, Val Acc: 0.793814\n",
      "Epoch 21182 - Train Loss: 0.076298, Train Acc: 0.887179 | Val Loss: 0.106672, Val Acc: 0.793814\n",
      "Epoch 21183 - Train Loss: 0.076296, Train Acc: 0.887179 | Val Loss: 0.106671, Val Acc: 0.793814\n",
      "Epoch 21184 - Train Loss: 0.076294, Train Acc: 0.887179 | Val Loss: 0.106670, Val Acc: 0.793814\n",
      "Epoch 21185 - Train Loss: 0.076293, Train Acc: 0.887179 | Val Loss: 0.106670, Val Acc: 0.793814\n",
      "Epoch 21186 - Train Loss: 0.076291, Train Acc: 0.887179 | Val Loss: 0.106669, Val Acc: 0.793814\n",
      "Epoch 21187 - Train Loss: 0.076289, Train Acc: 0.887179 | Val Loss: 0.106668, Val Acc: 0.793814\n",
      "Epoch 21188 - Train Loss: 0.076287, Train Acc: 0.887179 | Val Loss: 0.106668, Val Acc: 0.793814\n",
      "Epoch 21189 - Train Loss: 0.076285, Train Acc: 0.887179 | Val Loss: 0.106667, Val Acc: 0.793814\n",
      "Epoch 21190 - Train Loss: 0.076283, Train Acc: 0.887179 | Val Loss: 0.106666, Val Acc: 0.793814\n",
      "Epoch 21191 - Train Loss: 0.076281, Train Acc: 0.887179 | Val Loss: 0.106666, Val Acc: 0.793814\n",
      "Epoch 21192 - Train Loss: 0.076279, Train Acc: 0.887179 | Val Loss: 0.106665, Val Acc: 0.793814\n",
      "Epoch 21193 - Train Loss: 0.076277, Train Acc: 0.887179 | Val Loss: 0.106664, Val Acc: 0.793814\n",
      "Epoch 21194 - Train Loss: 0.076275, Train Acc: 0.887179 | Val Loss: 0.106664, Val Acc: 0.793814\n",
      "Epoch 21195 - Train Loss: 0.076274, Train Acc: 0.887179 | Val Loss: 0.106663, Val Acc: 0.793814\n",
      "Epoch 21196 - Train Loss: 0.076272, Train Acc: 0.887179 | Val Loss: 0.106662, Val Acc: 0.793814\n",
      "Epoch 21197 - Train Loss: 0.076270, Train Acc: 0.887179 | Val Loss: 0.106662, Val Acc: 0.793814\n",
      "Epoch 21198 - Train Loss: 0.076268, Train Acc: 0.887179 | Val Loss: 0.106661, Val Acc: 0.793814\n",
      "Epoch 21199 - Train Loss: 0.076266, Train Acc: 0.887179 | Val Loss: 0.106660, Val Acc: 0.793814\n",
      "Epoch 21200 - Train Loss: 0.076264, Train Acc: 0.887179 | Val Loss: 0.106660, Val Acc: 0.793814\n",
      "Epoch 21201 - Train Loss: 0.076262, Train Acc: 0.887179 | Val Loss: 0.106659, Val Acc: 0.793814\n",
      "Epoch 21202 - Train Loss: 0.076260, Train Acc: 0.887179 | Val Loss: 0.106658, Val Acc: 0.793814\n",
      "Epoch 21203 - Train Loss: 0.076258, Train Acc: 0.887179 | Val Loss: 0.106658, Val Acc: 0.793814\n",
      "Epoch 21204 - Train Loss: 0.076256, Train Acc: 0.887179 | Val Loss: 0.106657, Val Acc: 0.793814\n",
      "Epoch 21205 - Train Loss: 0.076255, Train Acc: 0.887179 | Val Loss: 0.106656, Val Acc: 0.793814\n",
      "Epoch 21206 - Train Loss: 0.076253, Train Acc: 0.887179 | Val Loss: 0.106656, Val Acc: 0.793814\n",
      "Epoch 21207 - Train Loss: 0.076251, Train Acc: 0.887179 | Val Loss: 0.106655, Val Acc: 0.793814\n",
      "Epoch 21208 - Train Loss: 0.076249, Train Acc: 0.887179 | Val Loss: 0.106654, Val Acc: 0.793814\n",
      "Epoch 21209 - Train Loss: 0.076247, Train Acc: 0.887179 | Val Loss: 0.106654, Val Acc: 0.793814\n",
      "Epoch 21210 - Train Loss: 0.076245, Train Acc: 0.887179 | Val Loss: 0.106653, Val Acc: 0.793814\n",
      "Epoch 21211 - Train Loss: 0.076243, Train Acc: 0.887179 | Val Loss: 0.106652, Val Acc: 0.793814\n",
      "Epoch 21212 - Train Loss: 0.076241, Train Acc: 0.887179 | Val Loss: 0.106651, Val Acc: 0.793814\n",
      "Epoch 21213 - Train Loss: 0.076239, Train Acc: 0.887179 | Val Loss: 0.106651, Val Acc: 0.793814\n",
      "Epoch 21214 - Train Loss: 0.076237, Train Acc: 0.887179 | Val Loss: 0.106650, Val Acc: 0.793814\n",
      "Epoch 21215 - Train Loss: 0.076236, Train Acc: 0.887179 | Val Loss: 0.106650, Val Acc: 0.793814\n",
      "Epoch 21216 - Train Loss: 0.076234, Train Acc: 0.887179 | Val Loss: 0.106649, Val Acc: 0.793814\n",
      "Epoch 21217 - Train Loss: 0.076232, Train Acc: 0.887179 | Val Loss: 0.106648, Val Acc: 0.793814\n",
      "Epoch 21218 - Train Loss: 0.076230, Train Acc: 0.887179 | Val Loss: 0.106647, Val Acc: 0.793814\n",
      "Epoch 21219 - Train Loss: 0.076228, Train Acc: 0.887179 | Val Loss: 0.106647, Val Acc: 0.793814\n",
      "Epoch 21220 - Train Loss: 0.076226, Train Acc: 0.887179 | Val Loss: 0.106646, Val Acc: 0.793814\n",
      "Epoch 21221 - Train Loss: 0.076224, Train Acc: 0.887179 | Val Loss: 0.106645, Val Acc: 0.793814\n",
      "Epoch 21222 - Train Loss: 0.076222, Train Acc: 0.887179 | Val Loss: 0.106645, Val Acc: 0.793814\n",
      "Epoch 21223 - Train Loss: 0.076220, Train Acc: 0.887179 | Val Loss: 0.106644, Val Acc: 0.793814\n",
      "Epoch 21224 - Train Loss: 0.076219, Train Acc: 0.887179 | Val Loss: 0.106644, Val Acc: 0.793814\n",
      "Epoch 21225 - Train Loss: 0.076217, Train Acc: 0.887179 | Val Loss: 0.106643, Val Acc: 0.793814\n",
      "Epoch 21226 - Train Loss: 0.076215, Train Acc: 0.887179 | Val Loss: 0.106642, Val Acc: 0.793814\n",
      "Epoch 21227 - Train Loss: 0.076213, Train Acc: 0.887179 | Val Loss: 0.106641, Val Acc: 0.793814\n",
      "Epoch 21228 - Train Loss: 0.076211, Train Acc: 0.887179 | Val Loss: 0.106641, Val Acc: 0.793814\n",
      "Epoch 21229 - Train Loss: 0.076209, Train Acc: 0.887179 | Val Loss: 0.106640, Val Acc: 0.793814\n",
      "Epoch 21230 - Train Loss: 0.076207, Train Acc: 0.887179 | Val Loss: 0.106639, Val Acc: 0.793814\n",
      "Epoch 21231 - Train Loss: 0.076205, Train Acc: 0.887179 | Val Loss: 0.106639, Val Acc: 0.793814\n",
      "Epoch 21232 - Train Loss: 0.076203, Train Acc: 0.887179 | Val Loss: 0.106638, Val Acc: 0.793814\n",
      "Epoch 21233 - Train Loss: 0.076201, Train Acc: 0.887179 | Val Loss: 0.106637, Val Acc: 0.793814\n",
      "Epoch 21234 - Train Loss: 0.076200, Train Acc: 0.887179 | Val Loss: 0.106637, Val Acc: 0.793814\n",
      "Epoch 21235 - Train Loss: 0.076198, Train Acc: 0.887179 | Val Loss: 0.106636, Val Acc: 0.793814\n",
      "Epoch 21236 - Train Loss: 0.076196, Train Acc: 0.887179 | Val Loss: 0.106635, Val Acc: 0.793814\n",
      "Epoch 21237 - Train Loss: 0.076194, Train Acc: 0.887179 | Val Loss: 0.106635, Val Acc: 0.793814\n",
      "Epoch 21238 - Train Loss: 0.076192, Train Acc: 0.887179 | Val Loss: 0.106634, Val Acc: 0.793814\n",
      "Epoch 21239 - Train Loss: 0.076190, Train Acc: 0.887179 | Val Loss: 0.106633, Val Acc: 0.793814\n",
      "Epoch 21240 - Train Loss: 0.076188, Train Acc: 0.887179 | Val Loss: 0.106633, Val Acc: 0.793814\n",
      "Epoch 21241 - Train Loss: 0.076186, Train Acc: 0.887179 | Val Loss: 0.106632, Val Acc: 0.793814\n",
      "Epoch 21242 - Train Loss: 0.076184, Train Acc: 0.887179 | Val Loss: 0.106631, Val Acc: 0.793814\n",
      "Epoch 21243 - Train Loss: 0.076183, Train Acc: 0.887179 | Val Loss: 0.106631, Val Acc: 0.793814\n",
      "Epoch 21244 - Train Loss: 0.076181, Train Acc: 0.887179 | Val Loss: 0.106630, Val Acc: 0.793814\n",
      "Epoch 21245 - Train Loss: 0.076179, Train Acc: 0.887179 | Val Loss: 0.106629, Val Acc: 0.793814\n",
      "Epoch 21246 - Train Loss: 0.076177, Train Acc: 0.887179 | Val Loss: 0.106629, Val Acc: 0.793814\n",
      "Epoch 21247 - Train Loss: 0.076175, Train Acc: 0.887179 | Val Loss: 0.106628, Val Acc: 0.793814\n",
      "Epoch 21248 - Train Loss: 0.076173, Train Acc: 0.887179 | Val Loss: 0.106627, Val Acc: 0.793814\n",
      "Epoch 21249 - Train Loss: 0.076171, Train Acc: 0.887179 | Val Loss: 0.106627, Val Acc: 0.793814\n",
      "Epoch 21250 - Train Loss: 0.076169, Train Acc: 0.887179 | Val Loss: 0.106626, Val Acc: 0.793814\n",
      "Epoch 21251 - Train Loss: 0.076167, Train Acc: 0.887179 | Val Loss: 0.106625, Val Acc: 0.793814\n",
      "Epoch 21252 - Train Loss: 0.076166, Train Acc: 0.887179 | Val Loss: 0.106625, Val Acc: 0.793814\n",
      "Epoch 21253 - Train Loss: 0.076164, Train Acc: 0.887179 | Val Loss: 0.106624, Val Acc: 0.793814\n",
      "Epoch 21254 - Train Loss: 0.076162, Train Acc: 0.887179 | Val Loss: 0.106623, Val Acc: 0.793814\n",
      "Epoch 21255 - Train Loss: 0.076160, Train Acc: 0.887179 | Val Loss: 0.106623, Val Acc: 0.793814\n",
      "Epoch 21256 - Train Loss: 0.076158, Train Acc: 0.887179 | Val Loss: 0.106622, Val Acc: 0.793814\n",
      "Epoch 21257 - Train Loss: 0.076156, Train Acc: 0.887179 | Val Loss: 0.106622, Val Acc: 0.793814\n",
      "Epoch 21258 - Train Loss: 0.076154, Train Acc: 0.887179 | Val Loss: 0.106621, Val Acc: 0.793814\n",
      "Epoch 21259 - Train Loss: 0.076152, Train Acc: 0.887179 | Val Loss: 0.106620, Val Acc: 0.793814\n",
      "Epoch 21260 - Train Loss: 0.076150, Train Acc: 0.887179 | Val Loss: 0.106619, Val Acc: 0.793814\n",
      "Epoch 21261 - Train Loss: 0.076149, Train Acc: 0.887179 | Val Loss: 0.106619, Val Acc: 0.793814\n",
      "Epoch 21262 - Train Loss: 0.076147, Train Acc: 0.887179 | Val Loss: 0.106618, Val Acc: 0.793814\n",
      "Epoch 21263 - Train Loss: 0.076145, Train Acc: 0.887179 | Val Loss: 0.106617, Val Acc: 0.793814\n",
      "Epoch 21264 - Train Loss: 0.076143, Train Acc: 0.887179 | Val Loss: 0.106617, Val Acc: 0.793814\n",
      "Epoch 21265 - Train Loss: 0.076141, Train Acc: 0.887179 | Val Loss: 0.106616, Val Acc: 0.793814\n",
      "Epoch 21266 - Train Loss: 0.076139, Train Acc: 0.887179 | Val Loss: 0.106616, Val Acc: 0.793814\n",
      "Epoch 21267 - Train Loss: 0.076137, Train Acc: 0.887179 | Val Loss: 0.106615, Val Acc: 0.793814\n",
      "Epoch 21268 - Train Loss: 0.076135, Train Acc: 0.887179 | Val Loss: 0.106614, Val Acc: 0.793814\n",
      "Epoch 21269 - Train Loss: 0.076133, Train Acc: 0.887179 | Val Loss: 0.106613, Val Acc: 0.793814\n",
      "Epoch 21270 - Train Loss: 0.076132, Train Acc: 0.887179 | Val Loss: 0.106613, Val Acc: 0.793814\n",
      "Epoch 21271 - Train Loss: 0.076130, Train Acc: 0.887179 | Val Loss: 0.106612, Val Acc: 0.793814\n",
      "Epoch 21272 - Train Loss: 0.076128, Train Acc: 0.887179 | Val Loss: 0.106611, Val Acc: 0.793814\n",
      "Epoch 21273 - Train Loss: 0.076126, Train Acc: 0.887179 | Val Loss: 0.106611, Val Acc: 0.793814\n",
      "Epoch 21274 - Train Loss: 0.076124, Train Acc: 0.887179 | Val Loss: 0.106610, Val Acc: 0.793814\n",
      "Epoch 21275 - Train Loss: 0.076122, Train Acc: 0.887179 | Val Loss: 0.106610, Val Acc: 0.793814\n",
      "Epoch 21276 - Train Loss: 0.076120, Train Acc: 0.887179 | Val Loss: 0.106609, Val Acc: 0.793814\n",
      "Epoch 21277 - Train Loss: 0.076118, Train Acc: 0.887179 | Val Loss: 0.106608, Val Acc: 0.793814\n",
      "Epoch 21278 - Train Loss: 0.076116, Train Acc: 0.887179 | Val Loss: 0.106607, Val Acc: 0.793814\n",
      "Epoch 21279 - Train Loss: 0.076115, Train Acc: 0.887179 | Val Loss: 0.106607, Val Acc: 0.793814\n",
      "Epoch 21280 - Train Loss: 0.076113, Train Acc: 0.887179 | Val Loss: 0.106606, Val Acc: 0.793814\n",
      "Epoch 21281 - Train Loss: 0.076111, Train Acc: 0.887179 | Val Loss: 0.106606, Val Acc: 0.793814\n",
      "Epoch 21282 - Train Loss: 0.076109, Train Acc: 0.887179 | Val Loss: 0.106605, Val Acc: 0.793814\n",
      "Epoch 21283 - Train Loss: 0.076107, Train Acc: 0.887179 | Val Loss: 0.106604, Val Acc: 0.793814\n",
      "Epoch 21284 - Train Loss: 0.076105, Train Acc: 0.887179 | Val Loss: 0.106604, Val Acc: 0.793814\n",
      "Epoch 21285 - Train Loss: 0.076103, Train Acc: 0.887179 | Val Loss: 0.106603, Val Acc: 0.793814\n",
      "Epoch 21286 - Train Loss: 0.076101, Train Acc: 0.887179 | Val Loss: 0.106602, Val Acc: 0.793814\n",
      "Epoch 21287 - Train Loss: 0.076099, Train Acc: 0.887179 | Val Loss: 0.106602, Val Acc: 0.793814\n",
      "Epoch 21288 - Train Loss: 0.076098, Train Acc: 0.887179 | Val Loss: 0.106601, Val Acc: 0.793814\n",
      "Epoch 21289 - Train Loss: 0.076096, Train Acc: 0.887179 | Val Loss: 0.106600, Val Acc: 0.793814\n",
      "Epoch 21290 - Train Loss: 0.076094, Train Acc: 0.887179 | Val Loss: 0.106600, Val Acc: 0.793814\n",
      "Epoch 21291 - Train Loss: 0.076092, Train Acc: 0.887179 | Val Loss: 0.106599, Val Acc: 0.793814\n",
      "Epoch 21292 - Train Loss: 0.076090, Train Acc: 0.887179 | Val Loss: 0.106598, Val Acc: 0.793814\n",
      "Epoch 21293 - Train Loss: 0.076088, Train Acc: 0.887179 | Val Loss: 0.106598, Val Acc: 0.793814\n",
      "Epoch 21294 - Train Loss: 0.076086, Train Acc: 0.887179 | Val Loss: 0.106597, Val Acc: 0.793814\n",
      "Epoch 21295 - Train Loss: 0.076084, Train Acc: 0.887179 | Val Loss: 0.106596, Val Acc: 0.793814\n",
      "Epoch 21296 - Train Loss: 0.076083, Train Acc: 0.887179 | Val Loss: 0.106596, Val Acc: 0.793814\n",
      "Epoch 21297 - Train Loss: 0.076081, Train Acc: 0.887179 | Val Loss: 0.106595, Val Acc: 0.793814\n",
      "Epoch 21298 - Train Loss: 0.076079, Train Acc: 0.887179 | Val Loss: 0.106594, Val Acc: 0.793814\n",
      "Epoch 21299 - Train Loss: 0.076077, Train Acc: 0.887179 | Val Loss: 0.106594, Val Acc: 0.793814\n",
      "Epoch 21300 - Train Loss: 0.076075, Train Acc: 0.887179 | Val Loss: 0.106593, Val Acc: 0.793814\n",
      "Epoch 21301 - Train Loss: 0.076073, Train Acc: 0.887179 | Val Loss: 0.106592, Val Acc: 0.793814\n",
      "Epoch 21302 - Train Loss: 0.076071, Train Acc: 0.887179 | Val Loss: 0.106592, Val Acc: 0.793814\n",
      "Epoch 21303 - Train Loss: 0.076069, Train Acc: 0.887179 | Val Loss: 0.106591, Val Acc: 0.793814\n",
      "Epoch 21304 - Train Loss: 0.076067, Train Acc: 0.887179 | Val Loss: 0.106590, Val Acc: 0.793814\n",
      "Epoch 21305 - Train Loss: 0.076066, Train Acc: 0.887179 | Val Loss: 0.106590, Val Acc: 0.793814\n",
      "Epoch 21306 - Train Loss: 0.076064, Train Acc: 0.887179 | Val Loss: 0.106589, Val Acc: 0.793814\n",
      "Epoch 21307 - Train Loss: 0.076062, Train Acc: 0.887179 | Val Loss: 0.106588, Val Acc: 0.793814\n",
      "Epoch 21308 - Train Loss: 0.076060, Train Acc: 0.887179 | Val Loss: 0.106588, Val Acc: 0.793814\n",
      "Epoch 21309 - Train Loss: 0.076058, Train Acc: 0.887179 | Val Loss: 0.106587, Val Acc: 0.793814\n",
      "Epoch 21310 - Train Loss: 0.076056, Train Acc: 0.887179 | Val Loss: 0.106586, Val Acc: 0.793814\n",
      "Epoch 21311 - Train Loss: 0.076054, Train Acc: 0.887179 | Val Loss: 0.106586, Val Acc: 0.793814\n",
      "Epoch 21312 - Train Loss: 0.076052, Train Acc: 0.887179 | Val Loss: 0.106585, Val Acc: 0.793814\n",
      "Epoch 21313 - Train Loss: 0.076051, Train Acc: 0.887179 | Val Loss: 0.106584, Val Acc: 0.793814\n",
      "Epoch 21314 - Train Loss: 0.076049, Train Acc: 0.887179 | Val Loss: 0.106584, Val Acc: 0.793814\n",
      "Epoch 21315 - Train Loss: 0.076047, Train Acc: 0.887179 | Val Loss: 0.106583, Val Acc: 0.793814\n",
      "Epoch 21316 - Train Loss: 0.076045, Train Acc: 0.887179 | Val Loss: 0.106582, Val Acc: 0.793814\n",
      "Epoch 21317 - Train Loss: 0.076043, Train Acc: 0.887179 | Val Loss: 0.106582, Val Acc: 0.793814\n",
      "Epoch 21318 - Train Loss: 0.076041, Train Acc: 0.887179 | Val Loss: 0.106581, Val Acc: 0.793814\n",
      "Epoch 21319 - Train Loss: 0.076039, Train Acc: 0.887179 | Val Loss: 0.106581, Val Acc: 0.793814\n",
      "Epoch 21320 - Train Loss: 0.076037, Train Acc: 0.887179 | Val Loss: 0.106580, Val Acc: 0.793814\n",
      "Epoch 21321 - Train Loss: 0.076035, Train Acc: 0.887179 | Val Loss: 0.106579, Val Acc: 0.793814\n",
      "Epoch 21322 - Train Loss: 0.076034, Train Acc: 0.887179 | Val Loss: 0.106578, Val Acc: 0.793814\n",
      "Epoch 21323 - Train Loss: 0.076032, Train Acc: 0.887179 | Val Loss: 0.106578, Val Acc: 0.793814\n",
      "Epoch 21324 - Train Loss: 0.076030, Train Acc: 0.887179 | Val Loss: 0.106577, Val Acc: 0.793814\n",
      "Epoch 21325 - Train Loss: 0.076028, Train Acc: 0.887179 | Val Loss: 0.106577, Val Acc: 0.793814\n",
      "Epoch 21326 - Train Loss: 0.076026, Train Acc: 0.887179 | Val Loss: 0.106576, Val Acc: 0.793814\n",
      "Epoch 21327 - Train Loss: 0.076024, Train Acc: 0.887179 | Val Loss: 0.106575, Val Acc: 0.793814\n",
      "Epoch 21328 - Train Loss: 0.076022, Train Acc: 0.887179 | Val Loss: 0.106575, Val Acc: 0.793814\n",
      "Epoch 21329 - Train Loss: 0.076020, Train Acc: 0.887179 | Val Loss: 0.106574, Val Acc: 0.793814\n",
      "Epoch 21330 - Train Loss: 0.076019, Train Acc: 0.887179 | Val Loss: 0.106573, Val Acc: 0.793814\n",
      "Epoch 21331 - Train Loss: 0.076017, Train Acc: 0.887179 | Val Loss: 0.106573, Val Acc: 0.793814\n",
      "Epoch 21332 - Train Loss: 0.076015, Train Acc: 0.887179 | Val Loss: 0.106572, Val Acc: 0.793814\n",
      "Epoch 21333 - Train Loss: 0.076013, Train Acc: 0.887179 | Val Loss: 0.106571, Val Acc: 0.793814\n",
      "Epoch 21334 - Train Loss: 0.076011, Train Acc: 0.887179 | Val Loss: 0.106571, Val Acc: 0.793814\n",
      "Epoch 21335 - Train Loss: 0.076009, Train Acc: 0.887179 | Val Loss: 0.106570, Val Acc: 0.793814\n",
      "Epoch 21336 - Train Loss: 0.076007, Train Acc: 0.887179 | Val Loss: 0.106569, Val Acc: 0.793814\n",
      "Epoch 21337 - Train Loss: 0.076005, Train Acc: 0.887179 | Val Loss: 0.106569, Val Acc: 0.793814\n",
      "Epoch 21338 - Train Loss: 0.076004, Train Acc: 0.887179 | Val Loss: 0.106568, Val Acc: 0.793814\n",
      "Epoch 21339 - Train Loss: 0.076002, Train Acc: 0.887179 | Val Loss: 0.106567, Val Acc: 0.793814\n",
      "Epoch 21340 - Train Loss: 0.076000, Train Acc: 0.887179 | Val Loss: 0.106567, Val Acc: 0.793814\n",
      "Epoch 21341 - Train Loss: 0.075998, Train Acc: 0.887179 | Val Loss: 0.106566, Val Acc: 0.793814\n",
      "Epoch 21342 - Train Loss: 0.075996, Train Acc: 0.887179 | Val Loss: 0.106565, Val Acc: 0.793814\n",
      "Epoch 21343 - Train Loss: 0.075994, Train Acc: 0.887179 | Val Loss: 0.106565, Val Acc: 0.793814\n",
      "Epoch 21344 - Train Loss: 0.075992, Train Acc: 0.887179 | Val Loss: 0.106564, Val Acc: 0.793814\n",
      "Epoch 21345 - Train Loss: 0.075990, Train Acc: 0.887179 | Val Loss: 0.106564, Val Acc: 0.793814\n",
      "Epoch 21346 - Train Loss: 0.075989, Train Acc: 0.887179 | Val Loss: 0.106563, Val Acc: 0.793814\n",
      "Epoch 21347 - Train Loss: 0.075987, Train Acc: 0.887179 | Val Loss: 0.106562, Val Acc: 0.793814\n",
      "Epoch 21348 - Train Loss: 0.075985, Train Acc: 0.887179 | Val Loss: 0.106562, Val Acc: 0.793814\n",
      "Epoch 21349 - Train Loss: 0.075983, Train Acc: 0.887179 | Val Loss: 0.106561, Val Acc: 0.793814\n",
      "Epoch 21350 - Train Loss: 0.075981, Train Acc: 0.887179 | Val Loss: 0.106560, Val Acc: 0.793814\n",
      "Epoch 21351 - Train Loss: 0.075979, Train Acc: 0.887179 | Val Loss: 0.106560, Val Acc: 0.793814\n",
      "Epoch 21352 - Train Loss: 0.075977, Train Acc: 0.887179 | Val Loss: 0.106559, Val Acc: 0.793814\n",
      "Epoch 21353 - Train Loss: 0.075975, Train Acc: 0.887179 | Val Loss: 0.106558, Val Acc: 0.793814\n",
      "Epoch 21354 - Train Loss: 0.075974, Train Acc: 0.887179 | Val Loss: 0.106558, Val Acc: 0.793814\n",
      "Epoch 21355 - Train Loss: 0.075972, Train Acc: 0.887179 | Val Loss: 0.106557, Val Acc: 0.793814\n",
      "Epoch 21356 - Train Loss: 0.075970, Train Acc: 0.887179 | Val Loss: 0.106556, Val Acc: 0.793814\n",
      "Epoch 21357 - Train Loss: 0.075968, Train Acc: 0.887179 | Val Loss: 0.106556, Val Acc: 0.793814\n",
      "Epoch 21358 - Train Loss: 0.075966, Train Acc: 0.887179 | Val Loss: 0.106555, Val Acc: 0.793814\n",
      "Epoch 21359 - Train Loss: 0.075964, Train Acc: 0.887179 | Val Loss: 0.106554, Val Acc: 0.793814\n",
      "Epoch 21360 - Train Loss: 0.075962, Train Acc: 0.887179 | Val Loss: 0.106554, Val Acc: 0.793814\n",
      "Epoch 21361 - Train Loss: 0.075960, Train Acc: 0.887179 | Val Loss: 0.106553, Val Acc: 0.793814\n",
      "Epoch 21362 - Train Loss: 0.075959, Train Acc: 0.887179 | Val Loss: 0.106552, Val Acc: 0.793814\n",
      "Epoch 21363 - Train Loss: 0.075957, Train Acc: 0.887179 | Val Loss: 0.106552, Val Acc: 0.793814\n",
      "Epoch 21364 - Train Loss: 0.075955, Train Acc: 0.887179 | Val Loss: 0.106551, Val Acc: 0.793814\n",
      "Epoch 21365 - Train Loss: 0.075953, Train Acc: 0.887179 | Val Loss: 0.106550, Val Acc: 0.793814\n",
      "Epoch 21366 - Train Loss: 0.075951, Train Acc: 0.887179 | Val Loss: 0.106550, Val Acc: 0.793814\n",
      "Epoch 21367 - Train Loss: 0.075949, Train Acc: 0.887179 | Val Loss: 0.106549, Val Acc: 0.793814\n",
      "Epoch 21368 - Train Loss: 0.075947, Train Acc: 0.887179 | Val Loss: 0.106549, Val Acc: 0.793814\n",
      "Epoch 21369 - Train Loss: 0.075946, Train Acc: 0.887179 | Val Loss: 0.106548, Val Acc: 0.793814\n",
      "Epoch 21370 - Train Loss: 0.075944, Train Acc: 0.887179 | Val Loss: 0.106547, Val Acc: 0.793814\n",
      "Epoch 21371 - Train Loss: 0.075942, Train Acc: 0.887179 | Val Loss: 0.106547, Val Acc: 0.793814\n",
      "Epoch 21372 - Train Loss: 0.075940, Train Acc: 0.887179 | Val Loss: 0.106546, Val Acc: 0.793814\n",
      "Epoch 21373 - Train Loss: 0.075938, Train Acc: 0.887179 | Val Loss: 0.106545, Val Acc: 0.793814\n",
      "Epoch 21374 - Train Loss: 0.075936, Train Acc: 0.887179 | Val Loss: 0.106545, Val Acc: 0.793814\n",
      "Epoch 21375 - Train Loss: 0.075934, Train Acc: 0.887179 | Val Loss: 0.106544, Val Acc: 0.793814\n",
      "Epoch 21376 - Train Loss: 0.075932, Train Acc: 0.887179 | Val Loss: 0.106543, Val Acc: 0.793814\n",
      "Epoch 21377 - Train Loss: 0.075931, Train Acc: 0.887179 | Val Loss: 0.106543, Val Acc: 0.793814\n",
      "Epoch 21378 - Train Loss: 0.075929, Train Acc: 0.887179 | Val Loss: 0.106542, Val Acc: 0.793814\n",
      "Epoch 21379 - Train Loss: 0.075927, Train Acc: 0.887179 | Val Loss: 0.106541, Val Acc: 0.793814\n",
      "Epoch 21380 - Train Loss: 0.075925, Train Acc: 0.887179 | Val Loss: 0.106541, Val Acc: 0.793814\n",
      "Epoch 21381 - Train Loss: 0.075923, Train Acc: 0.887179 | Val Loss: 0.106540, Val Acc: 0.793814\n",
      "Epoch 21382 - Train Loss: 0.075921, Train Acc: 0.887179 | Val Loss: 0.106540, Val Acc: 0.793814\n",
      "Epoch 21383 - Train Loss: 0.075919, Train Acc: 0.887179 | Val Loss: 0.106539, Val Acc: 0.793814\n",
      "Epoch 21384 - Train Loss: 0.075917, Train Acc: 0.887179 | Val Loss: 0.106538, Val Acc: 0.793814\n",
      "Epoch 21385 - Train Loss: 0.075916, Train Acc: 0.887179 | Val Loss: 0.106538, Val Acc: 0.793814\n",
      "Epoch 21386 - Train Loss: 0.075914, Train Acc: 0.887179 | Val Loss: 0.106537, Val Acc: 0.793814\n",
      "Epoch 21387 - Train Loss: 0.075912, Train Acc: 0.887179 | Val Loss: 0.106536, Val Acc: 0.793814\n",
      "Epoch 21388 - Train Loss: 0.075910, Train Acc: 0.887179 | Val Loss: 0.106536, Val Acc: 0.793814\n",
      "Epoch 21389 - Train Loss: 0.075908, Train Acc: 0.887179 | Val Loss: 0.106535, Val Acc: 0.793814\n",
      "Epoch 21390 - Train Loss: 0.075906, Train Acc: 0.887179 | Val Loss: 0.106534, Val Acc: 0.793814\n",
      "Epoch 21391 - Train Loss: 0.075904, Train Acc: 0.887179 | Val Loss: 0.106534, Val Acc: 0.793814\n",
      "Epoch 21392 - Train Loss: 0.075903, Train Acc: 0.887179 | Val Loss: 0.106533, Val Acc: 0.793814\n",
      "Epoch 21393 - Train Loss: 0.075901, Train Acc: 0.887179 | Val Loss: 0.106533, Val Acc: 0.793814\n",
      "Epoch 21394 - Train Loss: 0.075899, Train Acc: 0.887179 | Val Loss: 0.106532, Val Acc: 0.793814\n",
      "Epoch 21395 - Train Loss: 0.075897, Train Acc: 0.887179 | Val Loss: 0.106531, Val Acc: 0.793814\n",
      "Epoch 21396 - Train Loss: 0.075895, Train Acc: 0.887179 | Val Loss: 0.106530, Val Acc: 0.793814\n",
      "Epoch 21397 - Train Loss: 0.075893, Train Acc: 0.887179 | Val Loss: 0.106530, Val Acc: 0.793814\n",
      "Epoch 21398 - Train Loss: 0.075891, Train Acc: 0.887179 | Val Loss: 0.106529, Val Acc: 0.793814\n",
      "Epoch 21399 - Train Loss: 0.075889, Train Acc: 0.887179 | Val Loss: 0.106529, Val Acc: 0.793814\n",
      "Epoch 21400 - Train Loss: 0.075888, Train Acc: 0.887179 | Val Loss: 0.106528, Val Acc: 0.793814\n",
      "Epoch 21401 - Train Loss: 0.075886, Train Acc: 0.887179 | Val Loss: 0.106527, Val Acc: 0.793814\n",
      "Epoch 21402 - Train Loss: 0.075884, Train Acc: 0.887179 | Val Loss: 0.106527, Val Acc: 0.793814\n",
      "Epoch 21403 - Train Loss: 0.075882, Train Acc: 0.887179 | Val Loss: 0.106526, Val Acc: 0.793814\n",
      "Epoch 21404 - Train Loss: 0.075880, Train Acc: 0.887179 | Val Loss: 0.106525, Val Acc: 0.793814\n",
      "Epoch 21405 - Train Loss: 0.075878, Train Acc: 0.887179 | Val Loss: 0.106525, Val Acc: 0.793814\n",
      "Epoch 21406 - Train Loss: 0.075876, Train Acc: 0.887179 | Val Loss: 0.106524, Val Acc: 0.793814\n",
      "Epoch 21407 - Train Loss: 0.075875, Train Acc: 0.887179 | Val Loss: 0.106523, Val Acc: 0.793814\n",
      "Epoch 21408 - Train Loss: 0.075873, Train Acc: 0.887179 | Val Loss: 0.106523, Val Acc: 0.793814\n",
      "Epoch 21409 - Train Loss: 0.075871, Train Acc: 0.887179 | Val Loss: 0.106522, Val Acc: 0.793814\n",
      "Epoch 21410 - Train Loss: 0.075869, Train Acc: 0.887179 | Val Loss: 0.106522, Val Acc: 0.793814\n",
      "Epoch 21411 - Train Loss: 0.075867, Train Acc: 0.887179 | Val Loss: 0.106521, Val Acc: 0.793814\n",
      "Epoch 21412 - Train Loss: 0.075865, Train Acc: 0.887179 | Val Loss: 0.106520, Val Acc: 0.793814\n",
      "Epoch 21413 - Train Loss: 0.075863, Train Acc: 0.887179 | Val Loss: 0.106520, Val Acc: 0.793814\n",
      "Epoch 21414 - Train Loss: 0.075862, Train Acc: 0.887179 | Val Loss: 0.106519, Val Acc: 0.793814\n",
      "Epoch 21415 - Train Loss: 0.075860, Train Acc: 0.887179 | Val Loss: 0.106518, Val Acc: 0.793814\n",
      "Epoch 21416 - Train Loss: 0.075858, Train Acc: 0.887179 | Val Loss: 0.106518, Val Acc: 0.793814\n",
      "Epoch 21417 - Train Loss: 0.075856, Train Acc: 0.887179 | Val Loss: 0.106517, Val Acc: 0.793814\n",
      "Epoch 21418 - Train Loss: 0.075854, Train Acc: 0.887179 | Val Loss: 0.106516, Val Acc: 0.793814\n",
      "Epoch 21419 - Train Loss: 0.075852, Train Acc: 0.887179 | Val Loss: 0.106516, Val Acc: 0.793814\n",
      "Epoch 21420 - Train Loss: 0.075850, Train Acc: 0.887179 | Val Loss: 0.106515, Val Acc: 0.793814\n",
      "Epoch 21421 - Train Loss: 0.075848, Train Acc: 0.887179 | Val Loss: 0.106515, Val Acc: 0.793814\n",
      "Epoch 21422 - Train Loss: 0.075847, Train Acc: 0.887179 | Val Loss: 0.106514, Val Acc: 0.793814\n",
      "Epoch 21423 - Train Loss: 0.075845, Train Acc: 0.887179 | Val Loss: 0.106513, Val Acc: 0.793814\n",
      "Epoch 21424 - Train Loss: 0.075843, Train Acc: 0.887179 | Val Loss: 0.106512, Val Acc: 0.793814\n",
      "Epoch 21425 - Train Loss: 0.075841, Train Acc: 0.887179 | Val Loss: 0.106512, Val Acc: 0.793814\n",
      "Epoch 21426 - Train Loss: 0.075839, Train Acc: 0.887179 | Val Loss: 0.106511, Val Acc: 0.793814\n",
      "Epoch 21427 - Train Loss: 0.075837, Train Acc: 0.887179 | Val Loss: 0.106511, Val Acc: 0.793814\n",
      "Epoch 21428 - Train Loss: 0.075835, Train Acc: 0.887179 | Val Loss: 0.106510, Val Acc: 0.793814\n",
      "Epoch 21429 - Train Loss: 0.075834, Train Acc: 0.887179 | Val Loss: 0.106509, Val Acc: 0.793814\n",
      "Epoch 21430 - Train Loss: 0.075832, Train Acc: 0.887179 | Val Loss: 0.106509, Val Acc: 0.793814\n",
      "Epoch 21431 - Train Loss: 0.075830, Train Acc: 0.887179 | Val Loss: 0.106508, Val Acc: 0.793814\n",
      "Epoch 21432 - Train Loss: 0.075828, Train Acc: 0.887179 | Val Loss: 0.106507, Val Acc: 0.793814\n",
      "Epoch 21433 - Train Loss: 0.075826, Train Acc: 0.887179 | Val Loss: 0.106507, Val Acc: 0.793814\n",
      "Epoch 21434 - Train Loss: 0.075824, Train Acc: 0.887179 | Val Loss: 0.106506, Val Acc: 0.793814\n",
      "Epoch 21435 - Train Loss: 0.075822, Train Acc: 0.887179 | Val Loss: 0.106505, Val Acc: 0.793814\n",
      "Epoch 21436 - Train Loss: 0.075821, Train Acc: 0.887179 | Val Loss: 0.106505, Val Acc: 0.793814\n",
      "Epoch 21437 - Train Loss: 0.075819, Train Acc: 0.887179 | Val Loss: 0.106504, Val Acc: 0.793814\n",
      "Epoch 21438 - Train Loss: 0.075817, Train Acc: 0.887179 | Val Loss: 0.106504, Val Acc: 0.793814\n",
      "Epoch 21439 - Train Loss: 0.075815, Train Acc: 0.887179 | Val Loss: 0.106503, Val Acc: 0.793814\n",
      "Epoch 21440 - Train Loss: 0.075813, Train Acc: 0.887179 | Val Loss: 0.106502, Val Acc: 0.793814\n",
      "Epoch 21441 - Train Loss: 0.075811, Train Acc: 0.887179 | Val Loss: 0.106502, Val Acc: 0.793814\n",
      "Epoch 21442 - Train Loss: 0.075809, Train Acc: 0.887179 | Val Loss: 0.106501, Val Acc: 0.793814\n",
      "Epoch 21443 - Train Loss: 0.075808, Train Acc: 0.887179 | Val Loss: 0.106500, Val Acc: 0.793814\n",
      "Epoch 21444 - Train Loss: 0.075806, Train Acc: 0.887179 | Val Loss: 0.106500, Val Acc: 0.793814\n",
      "Epoch 21445 - Train Loss: 0.075804, Train Acc: 0.887179 | Val Loss: 0.106499, Val Acc: 0.793814\n",
      "Epoch 21446 - Train Loss: 0.075802, Train Acc: 0.887179 | Val Loss: 0.106498, Val Acc: 0.793814\n",
      "Epoch 21447 - Train Loss: 0.075800, Train Acc: 0.887179 | Val Loss: 0.106498, Val Acc: 0.793814\n",
      "Epoch 21448 - Train Loss: 0.075798, Train Acc: 0.887179 | Val Loss: 0.106497, Val Acc: 0.793814\n",
      "Epoch 21449 - Train Loss: 0.075796, Train Acc: 0.887179 | Val Loss: 0.106497, Val Acc: 0.793814\n",
      "Epoch 21450 - Train Loss: 0.075795, Train Acc: 0.887179 | Val Loss: 0.106496, Val Acc: 0.793814\n",
      "Epoch 21451 - Train Loss: 0.075793, Train Acc: 0.887179 | Val Loss: 0.106495, Val Acc: 0.793814\n",
      "Epoch 21452 - Train Loss: 0.075791, Train Acc: 0.887179 | Val Loss: 0.106495, Val Acc: 0.793814\n",
      "Epoch 21453 - Train Loss: 0.075789, Train Acc: 0.887179 | Val Loss: 0.106494, Val Acc: 0.793814\n",
      "Epoch 21454 - Train Loss: 0.075787, Train Acc: 0.887179 | Val Loss: 0.106493, Val Acc: 0.793814\n",
      "Epoch 21455 - Train Loss: 0.075785, Train Acc: 0.887179 | Val Loss: 0.106493, Val Acc: 0.793814\n",
      "Epoch 21456 - Train Loss: 0.075783, Train Acc: 0.887179 | Val Loss: 0.106492, Val Acc: 0.793814\n",
      "Epoch 21457 - Train Loss: 0.075782, Train Acc: 0.887179 | Val Loss: 0.106492, Val Acc: 0.793814\n",
      "Epoch 21458 - Train Loss: 0.075780, Train Acc: 0.887179 | Val Loss: 0.106491, Val Acc: 0.793814\n",
      "Epoch 21459 - Train Loss: 0.075778, Train Acc: 0.887179 | Val Loss: 0.106490, Val Acc: 0.793814\n",
      "Epoch 21460 - Train Loss: 0.075776, Train Acc: 0.887179 | Val Loss: 0.106490, Val Acc: 0.793814\n",
      "Epoch 21461 - Train Loss: 0.075774, Train Acc: 0.887179 | Val Loss: 0.106489, Val Acc: 0.793814\n",
      "Epoch 21462 - Train Loss: 0.075772, Train Acc: 0.887179 | Val Loss: 0.106488, Val Acc: 0.793814\n",
      "Epoch 21463 - Train Loss: 0.075770, Train Acc: 0.887179 | Val Loss: 0.106488, Val Acc: 0.793814\n",
      "Epoch 21464 - Train Loss: 0.075769, Train Acc: 0.887179 | Val Loss: 0.106487, Val Acc: 0.793814\n",
      "Epoch 21465 - Train Loss: 0.075767, Train Acc: 0.887179 | Val Loss: 0.106486, Val Acc: 0.793814\n",
      "Epoch 21466 - Train Loss: 0.075765, Train Acc: 0.887179 | Val Loss: 0.106486, Val Acc: 0.793814\n",
      "Epoch 21467 - Train Loss: 0.075763, Train Acc: 0.887179 | Val Loss: 0.106485, Val Acc: 0.793814\n",
      "Epoch 21468 - Train Loss: 0.075761, Train Acc: 0.887179 | Val Loss: 0.106485, Val Acc: 0.793814\n",
      "Epoch 21469 - Train Loss: 0.075759, Train Acc: 0.887179 | Val Loss: 0.106484, Val Acc: 0.793814\n",
      "Epoch 21470 - Train Loss: 0.075757, Train Acc: 0.887179 | Val Loss: 0.106483, Val Acc: 0.793814\n",
      "Epoch 21471 - Train Loss: 0.075756, Train Acc: 0.887179 | Val Loss: 0.106483, Val Acc: 0.793814\n",
      "Epoch 21472 - Train Loss: 0.075754, Train Acc: 0.887179 | Val Loss: 0.106482, Val Acc: 0.793814\n",
      "Epoch 21473 - Train Loss: 0.075752, Train Acc: 0.887179 | Val Loss: 0.106481, Val Acc: 0.793814\n",
      "Epoch 21474 - Train Loss: 0.075750, Train Acc: 0.887179 | Val Loss: 0.106481, Val Acc: 0.793814\n",
      "Epoch 21475 - Train Loss: 0.075748, Train Acc: 0.887179 | Val Loss: 0.106480, Val Acc: 0.793814\n",
      "Epoch 21476 - Train Loss: 0.075746, Train Acc: 0.887179 | Val Loss: 0.106479, Val Acc: 0.793814\n",
      "Epoch 21477 - Train Loss: 0.075744, Train Acc: 0.887179 | Val Loss: 0.106479, Val Acc: 0.793814\n",
      "Epoch 21478 - Train Loss: 0.075743, Train Acc: 0.887179 | Val Loss: 0.106478, Val Acc: 0.793814\n",
      "Epoch 21479 - Train Loss: 0.075741, Train Acc: 0.887179 | Val Loss: 0.106478, Val Acc: 0.793814\n",
      "Epoch 21480 - Train Loss: 0.075739, Train Acc: 0.887179 | Val Loss: 0.106477, Val Acc: 0.793814\n",
      "Epoch 21481 - Train Loss: 0.075737, Train Acc: 0.887179 | Val Loss: 0.106476, Val Acc: 0.793814\n",
      "Epoch 21482 - Train Loss: 0.075735, Train Acc: 0.887179 | Val Loss: 0.106476, Val Acc: 0.793814\n",
      "Epoch 21483 - Train Loss: 0.075733, Train Acc: 0.887179 | Val Loss: 0.106475, Val Acc: 0.793814\n",
      "Epoch 21484 - Train Loss: 0.075732, Train Acc: 0.887179 | Val Loss: 0.106474, Val Acc: 0.793814\n",
      "Epoch 21485 - Train Loss: 0.075730, Train Acc: 0.887179 | Val Loss: 0.106474, Val Acc: 0.793814\n",
      "Epoch 21486 - Train Loss: 0.075728, Train Acc: 0.887179 | Val Loss: 0.106473, Val Acc: 0.793814\n",
      "Epoch 21487 - Train Loss: 0.075726, Train Acc: 0.887179 | Val Loss: 0.106473, Val Acc: 0.793814\n",
      "Epoch 21488 - Train Loss: 0.075724, Train Acc: 0.887179 | Val Loss: 0.106472, Val Acc: 0.793814\n",
      "Epoch 21489 - Train Loss: 0.075722, Train Acc: 0.887179 | Val Loss: 0.106471, Val Acc: 0.793814\n",
      "Epoch 21490 - Train Loss: 0.075720, Train Acc: 0.887179 | Val Loss: 0.106471, Val Acc: 0.793814\n",
      "Epoch 21491 - Train Loss: 0.075719, Train Acc: 0.887179 | Val Loss: 0.106470, Val Acc: 0.793814\n",
      "Epoch 21492 - Train Loss: 0.075717, Train Acc: 0.887179 | Val Loss: 0.106469, Val Acc: 0.793814\n",
      "Epoch 21493 - Train Loss: 0.075715, Train Acc: 0.887179 | Val Loss: 0.106469, Val Acc: 0.793814\n",
      "Epoch 21494 - Train Loss: 0.075713, Train Acc: 0.887179 | Val Loss: 0.106468, Val Acc: 0.793814\n",
      "Epoch 21495 - Train Loss: 0.075711, Train Acc: 0.887179 | Val Loss: 0.106468, Val Acc: 0.793814\n",
      "Epoch 21496 - Train Loss: 0.075709, Train Acc: 0.887179 | Val Loss: 0.106467, Val Acc: 0.793814\n",
      "Epoch 21497 - Train Loss: 0.075707, Train Acc: 0.887179 | Val Loss: 0.106466, Val Acc: 0.793814\n",
      "Epoch 21498 - Train Loss: 0.075706, Train Acc: 0.887179 | Val Loss: 0.106466, Val Acc: 0.793814\n",
      "Epoch 21499 - Train Loss: 0.075704, Train Acc: 0.887179 | Val Loss: 0.106465, Val Acc: 0.793814\n",
      "Epoch 21500 - Train Loss: 0.075702, Train Acc: 0.887179 | Val Loss: 0.106464, Val Acc: 0.793814\n",
      "Epoch 21501 - Train Loss: 0.075700, Train Acc: 0.887179 | Val Loss: 0.106464, Val Acc: 0.793814\n",
      "Epoch 21502 - Train Loss: 0.075698, Train Acc: 0.887179 | Val Loss: 0.106463, Val Acc: 0.793814\n",
      "Epoch 21503 - Train Loss: 0.075696, Train Acc: 0.887179 | Val Loss: 0.106462, Val Acc: 0.793814\n",
      "Epoch 21504 - Train Loss: 0.075695, Train Acc: 0.887179 | Val Loss: 0.106462, Val Acc: 0.793814\n",
      "Epoch 21505 - Train Loss: 0.075693, Train Acc: 0.887179 | Val Loss: 0.106461, Val Acc: 0.793814\n",
      "Epoch 21506 - Train Loss: 0.075691, Train Acc: 0.887179 | Val Loss: 0.106461, Val Acc: 0.793814\n",
      "Epoch 21507 - Train Loss: 0.075689, Train Acc: 0.887179 | Val Loss: 0.106460, Val Acc: 0.793814\n",
      "Epoch 21508 - Train Loss: 0.075687, Train Acc: 0.887179 | Val Loss: 0.106459, Val Acc: 0.793814\n",
      "Epoch 21509 - Train Loss: 0.075685, Train Acc: 0.887179 | Val Loss: 0.106459, Val Acc: 0.793814\n",
      "Epoch 21510 - Train Loss: 0.075683, Train Acc: 0.887179 | Val Loss: 0.106458, Val Acc: 0.793814\n",
      "Epoch 21511 - Train Loss: 0.075682, Train Acc: 0.887179 | Val Loss: 0.106457, Val Acc: 0.793814\n",
      "Epoch 21512 - Train Loss: 0.075680, Train Acc: 0.887179 | Val Loss: 0.106457, Val Acc: 0.793814\n",
      "Epoch 21513 - Train Loss: 0.075678, Train Acc: 0.887179 | Val Loss: 0.106456, Val Acc: 0.793814\n",
      "Epoch 21514 - Train Loss: 0.075676, Train Acc: 0.887179 | Val Loss: 0.106456, Val Acc: 0.793814\n",
      "Epoch 21515 - Train Loss: 0.075674, Train Acc: 0.887179 | Val Loss: 0.106455, Val Acc: 0.793814\n",
      "Epoch 21516 - Train Loss: 0.075672, Train Acc: 0.887179 | Val Loss: 0.106454, Val Acc: 0.793814\n",
      "Epoch 21517 - Train Loss: 0.075671, Train Acc: 0.887179 | Val Loss: 0.106454, Val Acc: 0.793814\n",
      "Epoch 21518 - Train Loss: 0.075669, Train Acc: 0.887179 | Val Loss: 0.106453, Val Acc: 0.793814\n",
      "Epoch 21519 - Train Loss: 0.075667, Train Acc: 0.887179 | Val Loss: 0.106452, Val Acc: 0.793814\n",
      "Epoch 21520 - Train Loss: 0.075665, Train Acc: 0.887179 | Val Loss: 0.106452, Val Acc: 0.793814\n",
      "Epoch 21521 - Train Loss: 0.075663, Train Acc: 0.887179 | Val Loss: 0.106451, Val Acc: 0.793814\n",
      "Epoch 21522 - Train Loss: 0.075661, Train Acc: 0.887179 | Val Loss: 0.106451, Val Acc: 0.793814\n",
      "Epoch 21523 - Train Loss: 0.075659, Train Acc: 0.887179 | Val Loss: 0.106450, Val Acc: 0.793814\n",
      "Epoch 21524 - Train Loss: 0.075658, Train Acc: 0.887179 | Val Loss: 0.106449, Val Acc: 0.793814\n",
      "Epoch 21525 - Train Loss: 0.075656, Train Acc: 0.887179 | Val Loss: 0.106449, Val Acc: 0.793814\n",
      "Epoch 21526 - Train Loss: 0.075654, Train Acc: 0.887179 | Val Loss: 0.106448, Val Acc: 0.793814\n",
      "Epoch 21527 - Train Loss: 0.075652, Train Acc: 0.887179 | Val Loss: 0.106448, Val Acc: 0.793814\n",
      "Epoch 21528 - Train Loss: 0.075650, Train Acc: 0.887179 | Val Loss: 0.106447, Val Acc: 0.793814\n",
      "Epoch 21529 - Train Loss: 0.075648, Train Acc: 0.887179 | Val Loss: 0.106446, Val Acc: 0.793814\n",
      "Epoch 21530 - Train Loss: 0.075647, Train Acc: 0.887179 | Val Loss: 0.106446, Val Acc: 0.793814\n",
      "Epoch 21531 - Train Loss: 0.075645, Train Acc: 0.887179 | Val Loss: 0.106445, Val Acc: 0.793814\n",
      "Epoch 21532 - Train Loss: 0.075643, Train Acc: 0.887179 | Val Loss: 0.106444, Val Acc: 0.793814\n",
      "Epoch 21533 - Train Loss: 0.075641, Train Acc: 0.887179 | Val Loss: 0.106444, Val Acc: 0.793814\n",
      "Epoch 21534 - Train Loss: 0.075639, Train Acc: 0.887179 | Val Loss: 0.106443, Val Acc: 0.793814\n",
      "Epoch 21535 - Train Loss: 0.075637, Train Acc: 0.887179 | Val Loss: 0.106442, Val Acc: 0.793814\n",
      "Epoch 21536 - Train Loss: 0.075636, Train Acc: 0.887179 | Val Loss: 0.106442, Val Acc: 0.793814\n",
      "Epoch 21537 - Train Loss: 0.075634, Train Acc: 0.887179 | Val Loss: 0.106441, Val Acc: 0.793814\n",
      "Epoch 21538 - Train Loss: 0.075632, Train Acc: 0.887179 | Val Loss: 0.106441, Val Acc: 0.793814\n",
      "Epoch 21539 - Train Loss: 0.075630, Train Acc: 0.887179 | Val Loss: 0.106440, Val Acc: 0.793814\n",
      "Epoch 21540 - Train Loss: 0.075628, Train Acc: 0.887179 | Val Loss: 0.106439, Val Acc: 0.793814\n",
      "Epoch 21541 - Train Loss: 0.075626, Train Acc: 0.887179 | Val Loss: 0.106439, Val Acc: 0.793814\n",
      "Epoch 21542 - Train Loss: 0.075624, Train Acc: 0.887179 | Val Loss: 0.106438, Val Acc: 0.793814\n",
      "Epoch 21543 - Train Loss: 0.075623, Train Acc: 0.887179 | Val Loss: 0.106438, Val Acc: 0.793814\n",
      "Epoch 21544 - Train Loss: 0.075621, Train Acc: 0.887179 | Val Loss: 0.106437, Val Acc: 0.793814\n",
      "Epoch 21545 - Train Loss: 0.075619, Train Acc: 0.887179 | Val Loss: 0.106436, Val Acc: 0.793814\n",
      "Epoch 21546 - Train Loss: 0.075617, Train Acc: 0.887179 | Val Loss: 0.106436, Val Acc: 0.793814\n",
      "Epoch 21547 - Train Loss: 0.075615, Train Acc: 0.887179 | Val Loss: 0.106435, Val Acc: 0.793814\n",
      "Epoch 21548 - Train Loss: 0.075613, Train Acc: 0.887179 | Val Loss: 0.106434, Val Acc: 0.793814\n",
      "Epoch 21549 - Train Loss: 0.075612, Train Acc: 0.887179 | Val Loss: 0.106434, Val Acc: 0.793814\n",
      "Epoch 21550 - Train Loss: 0.075610, Train Acc: 0.887179 | Val Loss: 0.106433, Val Acc: 0.793814\n",
      "Epoch 21551 - Train Loss: 0.075608, Train Acc: 0.887179 | Val Loss: 0.106433, Val Acc: 0.793814\n",
      "Epoch 21552 - Train Loss: 0.075606, Train Acc: 0.887179 | Val Loss: 0.106432, Val Acc: 0.793814\n",
      "Epoch 21553 - Train Loss: 0.075604, Train Acc: 0.887179 | Val Loss: 0.106431, Val Acc: 0.793814\n",
      "Epoch 21554 - Train Loss: 0.075602, Train Acc: 0.887179 | Val Loss: 0.106431, Val Acc: 0.793814\n",
      "Epoch 21555 - Train Loss: 0.075601, Train Acc: 0.887179 | Val Loss: 0.106430, Val Acc: 0.793814\n",
      "Epoch 21556 - Train Loss: 0.075599, Train Acc: 0.887179 | Val Loss: 0.106429, Val Acc: 0.793814\n",
      "Epoch 21557 - Train Loss: 0.075597, Train Acc: 0.887179 | Val Loss: 0.106429, Val Acc: 0.793814\n",
      "Epoch 21558 - Train Loss: 0.075595, Train Acc: 0.887179 | Val Loss: 0.106428, Val Acc: 0.793814\n",
      "Epoch 21559 - Train Loss: 0.075593, Train Acc: 0.887179 | Val Loss: 0.106428, Val Acc: 0.793814\n",
      "Epoch 21560 - Train Loss: 0.075591, Train Acc: 0.887179 | Val Loss: 0.106427, Val Acc: 0.793814\n",
      "Epoch 21561 - Train Loss: 0.075589, Train Acc: 0.887179 | Val Loss: 0.106426, Val Acc: 0.793814\n",
      "Epoch 21562 - Train Loss: 0.075588, Train Acc: 0.887179 | Val Loss: 0.106426, Val Acc: 0.793814\n",
      "Epoch 21563 - Train Loss: 0.075586, Train Acc: 0.887179 | Val Loss: 0.106425, Val Acc: 0.793814\n",
      "Epoch 21564 - Train Loss: 0.075584, Train Acc: 0.887179 | Val Loss: 0.106425, Val Acc: 0.793814\n",
      "Epoch 21565 - Train Loss: 0.075582, Train Acc: 0.887179 | Val Loss: 0.106424, Val Acc: 0.793814\n",
      "Epoch 21566 - Train Loss: 0.075580, Train Acc: 0.887179 | Val Loss: 0.106423, Val Acc: 0.793814\n",
      "Epoch 21567 - Train Loss: 0.075578, Train Acc: 0.887179 | Val Loss: 0.106423, Val Acc: 0.793814\n",
      "Epoch 21568 - Train Loss: 0.075577, Train Acc: 0.887179 | Val Loss: 0.106422, Val Acc: 0.793814\n",
      "Epoch 21569 - Train Loss: 0.075575, Train Acc: 0.887179 | Val Loss: 0.106421, Val Acc: 0.793814\n",
      "Epoch 21570 - Train Loss: 0.075573, Train Acc: 0.887179 | Val Loss: 0.106421, Val Acc: 0.793814\n",
      "Epoch 21571 - Train Loss: 0.075571, Train Acc: 0.887179 | Val Loss: 0.106420, Val Acc: 0.793814\n",
      "Epoch 21572 - Train Loss: 0.075569, Train Acc: 0.887179 | Val Loss: 0.106420, Val Acc: 0.793814\n",
      "Epoch 21573 - Train Loss: 0.075567, Train Acc: 0.887179 | Val Loss: 0.106419, Val Acc: 0.793814\n",
      "Epoch 21574 - Train Loss: 0.075566, Train Acc: 0.887179 | Val Loss: 0.106418, Val Acc: 0.793814\n",
      "Epoch 21575 - Train Loss: 0.075564, Train Acc: 0.887179 | Val Loss: 0.106418, Val Acc: 0.793814\n",
      "Epoch 21576 - Train Loss: 0.075562, Train Acc: 0.887179 | Val Loss: 0.106417, Val Acc: 0.793814\n",
      "Epoch 21577 - Train Loss: 0.075560, Train Acc: 0.887179 | Val Loss: 0.106416, Val Acc: 0.793814\n",
      "Epoch 21578 - Train Loss: 0.075558, Train Acc: 0.887179 | Val Loss: 0.106416, Val Acc: 0.793814\n",
      "Epoch 21579 - Train Loss: 0.075556, Train Acc: 0.887179 | Val Loss: 0.106415, Val Acc: 0.793814\n",
      "Epoch 21580 - Train Loss: 0.075555, Train Acc: 0.887179 | Val Loss: 0.106415, Val Acc: 0.793814\n",
      "Epoch 21581 - Train Loss: 0.075553, Train Acc: 0.887179 | Val Loss: 0.106414, Val Acc: 0.793814\n",
      "Epoch 21582 - Train Loss: 0.075551, Train Acc: 0.887179 | Val Loss: 0.106413, Val Acc: 0.793814\n",
      "Epoch 21583 - Train Loss: 0.075549, Train Acc: 0.887179 | Val Loss: 0.106413, Val Acc: 0.793814\n",
      "Epoch 21584 - Train Loss: 0.075547, Train Acc: 0.887179 | Val Loss: 0.106412, Val Acc: 0.793814\n",
      "Epoch 21585 - Train Loss: 0.075545, Train Acc: 0.887179 | Val Loss: 0.106412, Val Acc: 0.793814\n",
      "Epoch 21586 - Train Loss: 0.075544, Train Acc: 0.887179 | Val Loss: 0.106411, Val Acc: 0.793814\n",
      "Epoch 21587 - Train Loss: 0.075542, Train Acc: 0.887179 | Val Loss: 0.106410, Val Acc: 0.793814\n",
      "Epoch 21588 - Train Loss: 0.075540, Train Acc: 0.887179 | Val Loss: 0.106410, Val Acc: 0.793814\n",
      "Epoch 21589 - Train Loss: 0.075538, Train Acc: 0.887179 | Val Loss: 0.106409, Val Acc: 0.793814\n",
      "Epoch 21590 - Train Loss: 0.075536, Train Acc: 0.887179 | Val Loss: 0.106409, Val Acc: 0.793814\n",
      "Epoch 21591 - Train Loss: 0.075534, Train Acc: 0.887179 | Val Loss: 0.106408, Val Acc: 0.793814\n",
      "Epoch 21592 - Train Loss: 0.075533, Train Acc: 0.887179 | Val Loss: 0.106407, Val Acc: 0.793814\n",
      "Epoch 21593 - Train Loss: 0.075531, Train Acc: 0.887179 | Val Loss: 0.106407, Val Acc: 0.793814\n",
      "Epoch 21594 - Train Loss: 0.075529, Train Acc: 0.887179 | Val Loss: 0.106406, Val Acc: 0.793814\n",
      "Epoch 21595 - Train Loss: 0.075527, Train Acc: 0.887179 | Val Loss: 0.106405, Val Acc: 0.793814\n",
      "Epoch 21596 - Train Loss: 0.075525, Train Acc: 0.887179 | Val Loss: 0.106405, Val Acc: 0.793814\n",
      "Epoch 21597 - Train Loss: 0.075523, Train Acc: 0.887179 | Val Loss: 0.106404, Val Acc: 0.793814\n",
      "Epoch 21598 - Train Loss: 0.075522, Train Acc: 0.887179 | Val Loss: 0.106404, Val Acc: 0.793814\n",
      "Epoch 21599 - Train Loss: 0.075520, Train Acc: 0.887179 | Val Loss: 0.106403, Val Acc: 0.793814\n",
      "Epoch 21600 - Train Loss: 0.075518, Train Acc: 0.887179 | Val Loss: 0.106402, Val Acc: 0.793814\n",
      "Epoch 21601 - Train Loss: 0.075516, Train Acc: 0.887179 | Val Loss: 0.106402, Val Acc: 0.793814\n",
      "Epoch 21602 - Train Loss: 0.075514, Train Acc: 0.887179 | Val Loss: 0.106401, Val Acc: 0.793814\n",
      "Epoch 21603 - Train Loss: 0.075512, Train Acc: 0.887179 | Val Loss: 0.106400, Val Acc: 0.793814\n",
      "Epoch 21604 - Train Loss: 0.075511, Train Acc: 0.887179 | Val Loss: 0.106400, Val Acc: 0.793814\n",
      "Epoch 21605 - Train Loss: 0.075509, Train Acc: 0.887179 | Val Loss: 0.106399, Val Acc: 0.793814\n",
      "Epoch 21606 - Train Loss: 0.075507, Train Acc: 0.887179 | Val Loss: 0.106399, Val Acc: 0.793814\n",
      "Epoch 21607 - Train Loss: 0.075505, Train Acc: 0.887179 | Val Loss: 0.106398, Val Acc: 0.793814\n",
      "Epoch 21608 - Train Loss: 0.075503, Train Acc: 0.887179 | Val Loss: 0.106397, Val Acc: 0.793814\n",
      "Epoch 21609 - Train Loss: 0.075501, Train Acc: 0.887179 | Val Loss: 0.106397, Val Acc: 0.793814\n",
      "Epoch 21610 - Train Loss: 0.075500, Train Acc: 0.887179 | Val Loss: 0.106396, Val Acc: 0.793814\n",
      "Epoch 21611 - Train Loss: 0.075498, Train Acc: 0.887179 | Val Loss: 0.106396, Val Acc: 0.793814\n",
      "Epoch 21612 - Train Loss: 0.075496, Train Acc: 0.887179 | Val Loss: 0.106395, Val Acc: 0.793814\n",
      "Epoch 21613 - Train Loss: 0.075494, Train Acc: 0.887179 | Val Loss: 0.106394, Val Acc: 0.793814\n",
      "Epoch 21614 - Train Loss: 0.075492, Train Acc: 0.887179 | Val Loss: 0.106394, Val Acc: 0.793814\n",
      "Epoch 21615 - Train Loss: 0.075490, Train Acc: 0.887179 | Val Loss: 0.106393, Val Acc: 0.793814\n",
      "Epoch 21616 - Train Loss: 0.075489, Train Acc: 0.887179 | Val Loss: 0.106393, Val Acc: 0.793814\n",
      "Epoch 21617 - Train Loss: 0.075487, Train Acc: 0.887179 | Val Loss: 0.106392, Val Acc: 0.793814\n",
      "Epoch 21618 - Train Loss: 0.075485, Train Acc: 0.887179 | Val Loss: 0.106391, Val Acc: 0.793814\n",
      "Epoch 21619 - Train Loss: 0.075483, Train Acc: 0.887179 | Val Loss: 0.106391, Val Acc: 0.793814\n",
      "Epoch 21620 - Train Loss: 0.075481, Train Acc: 0.887179 | Val Loss: 0.106390, Val Acc: 0.793814\n",
      "Epoch 21621 - Train Loss: 0.075480, Train Acc: 0.887179 | Val Loss: 0.106389, Val Acc: 0.793814\n",
      "Epoch 21622 - Train Loss: 0.075478, Train Acc: 0.887179 | Val Loss: 0.106389, Val Acc: 0.793814\n",
      "Epoch 21623 - Train Loss: 0.075476, Train Acc: 0.887179 | Val Loss: 0.106388, Val Acc: 0.793814\n",
      "Epoch 21624 - Train Loss: 0.075474, Train Acc: 0.887179 | Val Loss: 0.106388, Val Acc: 0.793814\n",
      "Epoch 21625 - Train Loss: 0.075472, Train Acc: 0.887179 | Val Loss: 0.106387, Val Acc: 0.793814\n",
      "Epoch 21626 - Train Loss: 0.075470, Train Acc: 0.887179 | Val Loss: 0.106386, Val Acc: 0.793814\n",
      "Epoch 21627 - Train Loss: 0.075469, Train Acc: 0.887179 | Val Loss: 0.106386, Val Acc: 0.793814\n",
      "Epoch 21628 - Train Loss: 0.075467, Train Acc: 0.887179 | Val Loss: 0.106385, Val Acc: 0.793814\n",
      "Epoch 21629 - Train Loss: 0.075465, Train Acc: 0.887179 | Val Loss: 0.106384, Val Acc: 0.793814\n",
      "Epoch 21630 - Train Loss: 0.075463, Train Acc: 0.887179 | Val Loss: 0.106384, Val Acc: 0.793814\n",
      "Epoch 21631 - Train Loss: 0.075461, Train Acc: 0.887179 | Val Loss: 0.106383, Val Acc: 0.793814\n",
      "Epoch 21632 - Train Loss: 0.075459, Train Acc: 0.887179 | Val Loss: 0.106383, Val Acc: 0.793814\n",
      "Epoch 21633 - Train Loss: 0.075458, Train Acc: 0.887179 | Val Loss: 0.106382, Val Acc: 0.793814\n",
      "Epoch 21634 - Train Loss: 0.075456, Train Acc: 0.887179 | Val Loss: 0.106381, Val Acc: 0.793814\n",
      "Epoch 21635 - Train Loss: 0.075454, Train Acc: 0.887179 | Val Loss: 0.106381, Val Acc: 0.793814\n",
      "Epoch 21636 - Train Loss: 0.075452, Train Acc: 0.887179 | Val Loss: 0.106380, Val Acc: 0.793814\n",
      "Epoch 21637 - Train Loss: 0.075450, Train Acc: 0.887179 | Val Loss: 0.106380, Val Acc: 0.793814\n",
      "Epoch 21638 - Train Loss: 0.075448, Train Acc: 0.887179 | Val Loss: 0.106379, Val Acc: 0.793814\n",
      "Epoch 21639 - Train Loss: 0.075447, Train Acc: 0.887179 | Val Loss: 0.106378, Val Acc: 0.793814\n",
      "Epoch 21640 - Train Loss: 0.075445, Train Acc: 0.887179 | Val Loss: 0.106378, Val Acc: 0.793814\n",
      "Epoch 21641 - Train Loss: 0.075443, Train Acc: 0.887179 | Val Loss: 0.106377, Val Acc: 0.793814\n",
      "Epoch 21642 - Train Loss: 0.075441, Train Acc: 0.887179 | Val Loss: 0.106376, Val Acc: 0.793814\n",
      "Epoch 21643 - Train Loss: 0.075439, Train Acc: 0.887179 | Val Loss: 0.106376, Val Acc: 0.793814\n",
      "Epoch 21644 - Train Loss: 0.075438, Train Acc: 0.887179 | Val Loss: 0.106375, Val Acc: 0.793814\n",
      "Epoch 21645 - Train Loss: 0.075436, Train Acc: 0.887179 | Val Loss: 0.106375, Val Acc: 0.793814\n",
      "Epoch 21646 - Train Loss: 0.075434, Train Acc: 0.887179 | Val Loss: 0.106374, Val Acc: 0.793814\n",
      "Epoch 21647 - Train Loss: 0.075432, Train Acc: 0.887179 | Val Loss: 0.106373, Val Acc: 0.793814\n",
      "Epoch 21648 - Train Loss: 0.075430, Train Acc: 0.887179 | Val Loss: 0.106373, Val Acc: 0.793814\n",
      "Epoch 21649 - Train Loss: 0.075428, Train Acc: 0.887179 | Val Loss: 0.106372, Val Acc: 0.793814\n",
      "Epoch 21650 - Train Loss: 0.075427, Train Acc: 0.887179 | Val Loss: 0.106372, Val Acc: 0.793814\n",
      "Epoch 21651 - Train Loss: 0.075425, Train Acc: 0.887179 | Val Loss: 0.106371, Val Acc: 0.793814\n",
      "Epoch 21652 - Train Loss: 0.075423, Train Acc: 0.887179 | Val Loss: 0.106370, Val Acc: 0.793814\n",
      "Epoch 21653 - Train Loss: 0.075421, Train Acc: 0.887179 | Val Loss: 0.106370, Val Acc: 0.793814\n",
      "Epoch 21654 - Train Loss: 0.075419, Train Acc: 0.887179 | Val Loss: 0.106369, Val Acc: 0.793814\n",
      "Epoch 21655 - Train Loss: 0.075417, Train Acc: 0.887179 | Val Loss: 0.106369, Val Acc: 0.793814\n",
      "Epoch 21656 - Train Loss: 0.075416, Train Acc: 0.887179 | Val Loss: 0.106368, Val Acc: 0.793814\n",
      "Epoch 21657 - Train Loss: 0.075414, Train Acc: 0.887179 | Val Loss: 0.106367, Val Acc: 0.793814\n",
      "Epoch 21658 - Train Loss: 0.075412, Train Acc: 0.887179 | Val Loss: 0.106367, Val Acc: 0.793814\n",
      "Epoch 21659 - Train Loss: 0.075410, Train Acc: 0.887179 | Val Loss: 0.106366, Val Acc: 0.793814\n",
      "Epoch 21660 - Train Loss: 0.075408, Train Acc: 0.887179 | Val Loss: 0.106365, Val Acc: 0.793814\n",
      "Epoch 21661 - Train Loss: 0.075407, Train Acc: 0.887179 | Val Loss: 0.106365, Val Acc: 0.793814\n",
      "Epoch 21662 - Train Loss: 0.075405, Train Acc: 0.887179 | Val Loss: 0.106364, Val Acc: 0.793814\n",
      "Epoch 21663 - Train Loss: 0.075403, Train Acc: 0.887179 | Val Loss: 0.106364, Val Acc: 0.793814\n",
      "Epoch 21664 - Train Loss: 0.075401, Train Acc: 0.887179 | Val Loss: 0.106363, Val Acc: 0.793814\n",
      "Epoch 21665 - Train Loss: 0.075399, Train Acc: 0.887179 | Val Loss: 0.106362, Val Acc: 0.793814\n",
      "Epoch 21666 - Train Loss: 0.075397, Train Acc: 0.887179 | Val Loss: 0.106362, Val Acc: 0.793814\n",
      "Epoch 21667 - Train Loss: 0.075396, Train Acc: 0.887179 | Val Loss: 0.106361, Val Acc: 0.793814\n",
      "Epoch 21668 - Train Loss: 0.075394, Train Acc: 0.887179 | Val Loss: 0.106361, Val Acc: 0.793814\n",
      "Epoch 21669 - Train Loss: 0.075392, Train Acc: 0.887179 | Val Loss: 0.106360, Val Acc: 0.793814\n",
      "Epoch 21670 - Train Loss: 0.075390, Train Acc: 0.887179 | Val Loss: 0.106359, Val Acc: 0.793814\n",
      "Epoch 21671 - Train Loss: 0.075388, Train Acc: 0.887179 | Val Loss: 0.106359, Val Acc: 0.793814\n",
      "Epoch 21672 - Train Loss: 0.075387, Train Acc: 0.887179 | Val Loss: 0.106358, Val Acc: 0.793814\n",
      "Epoch 21673 - Train Loss: 0.075385, Train Acc: 0.887179 | Val Loss: 0.106357, Val Acc: 0.793814\n",
      "Epoch 21674 - Train Loss: 0.075383, Train Acc: 0.887179 | Val Loss: 0.106357, Val Acc: 0.793814\n",
      "Epoch 21675 - Train Loss: 0.075381, Train Acc: 0.887179 | Val Loss: 0.106356, Val Acc: 0.793814\n",
      "Epoch 21676 - Train Loss: 0.075379, Train Acc: 0.887179 | Val Loss: 0.106356, Val Acc: 0.793814\n",
      "Epoch 21677 - Train Loss: 0.075377, Train Acc: 0.887179 | Val Loss: 0.106355, Val Acc: 0.793814\n",
      "Epoch 21678 - Train Loss: 0.075376, Train Acc: 0.887179 | Val Loss: 0.106354, Val Acc: 0.793814\n",
      "Epoch 21679 - Train Loss: 0.075374, Train Acc: 0.887179 | Val Loss: 0.106354, Val Acc: 0.793814\n",
      "Epoch 21680 - Train Loss: 0.075372, Train Acc: 0.887179 | Val Loss: 0.106353, Val Acc: 0.793814\n",
      "Epoch 21681 - Train Loss: 0.075370, Train Acc: 0.887179 | Val Loss: 0.106353, Val Acc: 0.793814\n",
      "Epoch 21682 - Train Loss: 0.075368, Train Acc: 0.887179 | Val Loss: 0.106352, Val Acc: 0.793814\n",
      "Epoch 21683 - Train Loss: 0.075366, Train Acc: 0.887179 | Val Loss: 0.106351, Val Acc: 0.793814\n",
      "Epoch 21684 - Train Loss: 0.075365, Train Acc: 0.887179 | Val Loss: 0.106351, Val Acc: 0.793814\n",
      "Epoch 21685 - Train Loss: 0.075363, Train Acc: 0.887179 | Val Loss: 0.106350, Val Acc: 0.793814\n",
      "Epoch 21686 - Train Loss: 0.075361, Train Acc: 0.887179 | Val Loss: 0.106350, Val Acc: 0.793814\n",
      "Epoch 21687 - Train Loss: 0.075359, Train Acc: 0.887179 | Val Loss: 0.106349, Val Acc: 0.793814\n",
      "Epoch 21688 - Train Loss: 0.075357, Train Acc: 0.887179 | Val Loss: 0.106348, Val Acc: 0.793814\n",
      "Epoch 21689 - Train Loss: 0.075356, Train Acc: 0.887179 | Val Loss: 0.106348, Val Acc: 0.793814\n",
      "Epoch 21690 - Train Loss: 0.075354, Train Acc: 0.887179 | Val Loss: 0.106347, Val Acc: 0.793814\n",
      "Epoch 21691 - Train Loss: 0.075352, Train Acc: 0.887179 | Val Loss: 0.106347, Val Acc: 0.793814\n",
      "Epoch 21692 - Train Loss: 0.075350, Train Acc: 0.887179 | Val Loss: 0.106346, Val Acc: 0.793814\n",
      "Epoch 21693 - Train Loss: 0.075348, Train Acc: 0.887179 | Val Loss: 0.106345, Val Acc: 0.793814\n",
      "Epoch 21694 - Train Loss: 0.075347, Train Acc: 0.887179 | Val Loss: 0.106345, Val Acc: 0.793814\n",
      "Epoch 21695 - Train Loss: 0.075345, Train Acc: 0.887179 | Val Loss: 0.106344, Val Acc: 0.793814\n",
      "Epoch 21696 - Train Loss: 0.075343, Train Acc: 0.887179 | Val Loss: 0.106344, Val Acc: 0.793814\n",
      "Epoch 21697 - Train Loss: 0.075341, Train Acc: 0.887179 | Val Loss: 0.106343, Val Acc: 0.793814\n",
      "Epoch 21698 - Train Loss: 0.075339, Train Acc: 0.887179 | Val Loss: 0.106342, Val Acc: 0.793814\n",
      "Epoch 21699 - Train Loss: 0.075337, Train Acc: 0.887179 | Val Loss: 0.106342, Val Acc: 0.793814\n",
      "Epoch 21700 - Train Loss: 0.075336, Train Acc: 0.887179 | Val Loss: 0.106341, Val Acc: 0.793814\n",
      "Epoch 21701 - Train Loss: 0.075334, Train Acc: 0.887179 | Val Loss: 0.106341, Val Acc: 0.793814\n",
      "Epoch 21702 - Train Loss: 0.075332, Train Acc: 0.887179 | Val Loss: 0.106340, Val Acc: 0.793814\n",
      "Epoch 21703 - Train Loss: 0.075330, Train Acc: 0.887179 | Val Loss: 0.106339, Val Acc: 0.793814\n",
      "Epoch 21704 - Train Loss: 0.075328, Train Acc: 0.887179 | Val Loss: 0.106339, Val Acc: 0.793814\n",
      "Epoch 21705 - Train Loss: 0.075327, Train Acc: 0.887179 | Val Loss: 0.106338, Val Acc: 0.793814\n",
      "Epoch 21706 - Train Loss: 0.075325, Train Acc: 0.887179 | Val Loss: 0.106338, Val Acc: 0.793814\n",
      "Epoch 21707 - Train Loss: 0.075323, Train Acc: 0.887179 | Val Loss: 0.106337, Val Acc: 0.793814\n",
      "Epoch 21708 - Train Loss: 0.075321, Train Acc: 0.887179 | Val Loss: 0.106336, Val Acc: 0.793814\n",
      "Epoch 21709 - Train Loss: 0.075319, Train Acc: 0.887179 | Val Loss: 0.106336, Val Acc: 0.793814\n",
      "Epoch 21710 - Train Loss: 0.075317, Train Acc: 0.887179 | Val Loss: 0.106335, Val Acc: 0.793814\n",
      "Epoch 21711 - Train Loss: 0.075316, Train Acc: 0.887179 | Val Loss: 0.106335, Val Acc: 0.793814\n",
      "Epoch 21712 - Train Loss: 0.075314, Train Acc: 0.887179 | Val Loss: 0.106334, Val Acc: 0.793814\n",
      "Epoch 21713 - Train Loss: 0.075312, Train Acc: 0.887179 | Val Loss: 0.106333, Val Acc: 0.793814\n",
      "Epoch 21714 - Train Loss: 0.075310, Train Acc: 0.887179 | Val Loss: 0.106333, Val Acc: 0.793814\n",
      "Epoch 21715 - Train Loss: 0.075308, Train Acc: 0.887179 | Val Loss: 0.106332, Val Acc: 0.793814\n",
      "Epoch 21716 - Train Loss: 0.075307, Train Acc: 0.887179 | Val Loss: 0.106332, Val Acc: 0.793814\n",
      "Epoch 21717 - Train Loss: 0.075305, Train Acc: 0.887179 | Val Loss: 0.106331, Val Acc: 0.793814\n",
      "Epoch 21718 - Train Loss: 0.075303, Train Acc: 0.887179 | Val Loss: 0.106330, Val Acc: 0.793814\n",
      "Epoch 21719 - Train Loss: 0.075301, Train Acc: 0.887179 | Val Loss: 0.106330, Val Acc: 0.793814\n",
      "Epoch 21720 - Train Loss: 0.075299, Train Acc: 0.887179 | Val Loss: 0.106329, Val Acc: 0.793814\n",
      "Epoch 21721 - Train Loss: 0.075298, Train Acc: 0.887179 | Val Loss: 0.106329, Val Acc: 0.793814\n",
      "Epoch 21722 - Train Loss: 0.075296, Train Acc: 0.887179 | Val Loss: 0.106328, Val Acc: 0.793814\n",
      "Epoch 21723 - Train Loss: 0.075294, Train Acc: 0.887179 | Val Loss: 0.106327, Val Acc: 0.793814\n",
      "Epoch 21724 - Train Loss: 0.075292, Train Acc: 0.887179 | Val Loss: 0.106327, Val Acc: 0.793814\n",
      "Epoch 21725 - Train Loss: 0.075290, Train Acc: 0.887179 | Val Loss: 0.106326, Val Acc: 0.793814\n",
      "Epoch 21726 - Train Loss: 0.075288, Train Acc: 0.887179 | Val Loss: 0.106326, Val Acc: 0.793814\n",
      "Epoch 21727 - Train Loss: 0.075287, Train Acc: 0.887179 | Val Loss: 0.106325, Val Acc: 0.793814\n",
      "Epoch 21728 - Train Loss: 0.075285, Train Acc: 0.887179 | Val Loss: 0.106324, Val Acc: 0.793814\n",
      "Epoch 21729 - Train Loss: 0.075283, Train Acc: 0.887179 | Val Loss: 0.106324, Val Acc: 0.793814\n",
      "Epoch 21730 - Train Loss: 0.075281, Train Acc: 0.887179 | Val Loss: 0.106323, Val Acc: 0.793814\n",
      "Epoch 21731 - Train Loss: 0.075279, Train Acc: 0.887179 | Val Loss: 0.106323, Val Acc: 0.793814\n",
      "Epoch 21732 - Train Loss: 0.075278, Train Acc: 0.887179 | Val Loss: 0.106322, Val Acc: 0.793814\n",
      "Epoch 21733 - Train Loss: 0.075276, Train Acc: 0.887179 | Val Loss: 0.106321, Val Acc: 0.793814\n",
      "Epoch 21734 - Train Loss: 0.075274, Train Acc: 0.887179 | Val Loss: 0.106321, Val Acc: 0.793814\n",
      "Epoch 21735 - Train Loss: 0.075272, Train Acc: 0.887179 | Val Loss: 0.106320, Val Acc: 0.793814\n",
      "Epoch 21736 - Train Loss: 0.075270, Train Acc: 0.887179 | Val Loss: 0.106320, Val Acc: 0.793814\n",
      "Epoch 21737 - Train Loss: 0.075269, Train Acc: 0.887179 | Val Loss: 0.106319, Val Acc: 0.793814\n",
      "Epoch 21738 - Train Loss: 0.075267, Train Acc: 0.887179 | Val Loss: 0.106318, Val Acc: 0.793814\n",
      "Epoch 21739 - Train Loss: 0.075265, Train Acc: 0.887179 | Val Loss: 0.106318, Val Acc: 0.793814\n",
      "Epoch 21740 - Train Loss: 0.075263, Train Acc: 0.887179 | Val Loss: 0.106317, Val Acc: 0.793814\n",
      "Epoch 21741 - Train Loss: 0.075261, Train Acc: 0.887179 | Val Loss: 0.106317, Val Acc: 0.793814\n",
      "Epoch 21742 - Train Loss: 0.075260, Train Acc: 0.887179 | Val Loss: 0.106316, Val Acc: 0.793814\n",
      "Epoch 21743 - Train Loss: 0.075258, Train Acc: 0.887179 | Val Loss: 0.106315, Val Acc: 0.793814\n",
      "Epoch 21744 - Train Loss: 0.075256, Train Acc: 0.887179 | Val Loss: 0.106315, Val Acc: 0.793814\n",
      "Epoch 21745 - Train Loss: 0.075254, Train Acc: 0.887179 | Val Loss: 0.106314, Val Acc: 0.793814\n",
      "Epoch 21746 - Train Loss: 0.075252, Train Acc: 0.887179 | Val Loss: 0.106314, Val Acc: 0.793814\n",
      "Epoch 21747 - Train Loss: 0.075250, Train Acc: 0.887179 | Val Loss: 0.106313, Val Acc: 0.793814\n",
      "Epoch 21748 - Train Loss: 0.075249, Train Acc: 0.887179 | Val Loss: 0.106312, Val Acc: 0.793814\n",
      "Epoch 21749 - Train Loss: 0.075247, Train Acc: 0.887179 | Val Loss: 0.106312, Val Acc: 0.793814\n",
      "Epoch 21750 - Train Loss: 0.075245, Train Acc: 0.887179 | Val Loss: 0.106311, Val Acc: 0.793814\n",
      "Epoch 21751 - Train Loss: 0.075243, Train Acc: 0.887179 | Val Loss: 0.106311, Val Acc: 0.793814\n",
      "Epoch 21752 - Train Loss: 0.075241, Train Acc: 0.887179 | Val Loss: 0.106310, Val Acc: 0.793814\n",
      "Epoch 21753 - Train Loss: 0.075240, Train Acc: 0.887179 | Val Loss: 0.106309, Val Acc: 0.793814\n",
      "Epoch 21754 - Train Loss: 0.075238, Train Acc: 0.887179 | Val Loss: 0.106309, Val Acc: 0.793814\n",
      "Epoch 21755 - Train Loss: 0.075236, Train Acc: 0.887179 | Val Loss: 0.106308, Val Acc: 0.793814\n",
      "Epoch 21756 - Train Loss: 0.075234, Train Acc: 0.887179 | Val Loss: 0.106308, Val Acc: 0.793814\n",
      "Epoch 21757 - Train Loss: 0.075232, Train Acc: 0.887179 | Val Loss: 0.106307, Val Acc: 0.793814\n",
      "Epoch 21758 - Train Loss: 0.075231, Train Acc: 0.887179 | Val Loss: 0.106307, Val Acc: 0.793814\n",
      "Epoch 21759 - Train Loss: 0.075229, Train Acc: 0.887179 | Val Loss: 0.106306, Val Acc: 0.793814\n",
      "Epoch 21760 - Train Loss: 0.075227, Train Acc: 0.887179 | Val Loss: 0.106305, Val Acc: 0.793814\n",
      "Epoch 21761 - Train Loss: 0.075225, Train Acc: 0.887179 | Val Loss: 0.106305, Val Acc: 0.793814\n",
      "Epoch 21762 - Train Loss: 0.075223, Train Acc: 0.887179 | Val Loss: 0.106304, Val Acc: 0.793814\n",
      "Epoch 21763 - Train Loss: 0.075222, Train Acc: 0.887179 | Val Loss: 0.106304, Val Acc: 0.793814\n",
      "Epoch 21764 - Train Loss: 0.075220, Train Acc: 0.887179 | Val Loss: 0.106303, Val Acc: 0.793814\n",
      "Epoch 21765 - Train Loss: 0.075218, Train Acc: 0.887179 | Val Loss: 0.106302, Val Acc: 0.793814\n",
      "Epoch 21766 - Train Loss: 0.075216, Train Acc: 0.887179 | Val Loss: 0.106302, Val Acc: 0.793814\n",
      "Epoch 21767 - Train Loss: 0.075214, Train Acc: 0.887179 | Val Loss: 0.106301, Val Acc: 0.793814\n",
      "Epoch 21768 - Train Loss: 0.075213, Train Acc: 0.887179 | Val Loss: 0.106301, Val Acc: 0.793814\n",
      "Epoch 21769 - Train Loss: 0.075211, Train Acc: 0.887179 | Val Loss: 0.106300, Val Acc: 0.793814\n",
      "Epoch 21770 - Train Loss: 0.075209, Train Acc: 0.887179 | Val Loss: 0.106299, Val Acc: 0.793814\n",
      "Epoch 21771 - Train Loss: 0.075207, Train Acc: 0.887179 | Val Loss: 0.106299, Val Acc: 0.793814\n",
      "Epoch 21772 - Train Loss: 0.075205, Train Acc: 0.887179 | Val Loss: 0.106298, Val Acc: 0.793814\n",
      "Epoch 21773 - Train Loss: 0.075204, Train Acc: 0.887179 | Val Loss: 0.106298, Val Acc: 0.793814\n",
      "Epoch 21774 - Train Loss: 0.075202, Train Acc: 0.887179 | Val Loss: 0.106297, Val Acc: 0.793814\n",
      "Epoch 21775 - Train Loss: 0.075200, Train Acc: 0.887179 | Val Loss: 0.106296, Val Acc: 0.793814\n",
      "Epoch 21776 - Train Loss: 0.075198, Train Acc: 0.887179 | Val Loss: 0.106296, Val Acc: 0.793814\n",
      "Epoch 21777 - Train Loss: 0.075196, Train Acc: 0.887179 | Val Loss: 0.106295, Val Acc: 0.793814\n",
      "Epoch 21778 - Train Loss: 0.075195, Train Acc: 0.887179 | Val Loss: 0.106295, Val Acc: 0.793814\n",
      "Epoch 21779 - Train Loss: 0.075193, Train Acc: 0.887179 | Val Loss: 0.106294, Val Acc: 0.793814\n",
      "Epoch 21780 - Train Loss: 0.075191, Train Acc: 0.887179 | Val Loss: 0.106293, Val Acc: 0.793814\n",
      "Epoch 21781 - Train Loss: 0.075189, Train Acc: 0.887179 | Val Loss: 0.106293, Val Acc: 0.793814\n",
      "Epoch 21782 - Train Loss: 0.075187, Train Acc: 0.887179 | Val Loss: 0.106292, Val Acc: 0.793814\n",
      "Epoch 21783 - Train Loss: 0.075186, Train Acc: 0.887179 | Val Loss: 0.106292, Val Acc: 0.793814\n",
      "Epoch 21784 - Train Loss: 0.075184, Train Acc: 0.887179 | Val Loss: 0.106291, Val Acc: 0.793814\n",
      "Epoch 21785 - Train Loss: 0.075182, Train Acc: 0.887179 | Val Loss: 0.106291, Val Acc: 0.793814\n",
      "Epoch 21786 - Train Loss: 0.075180, Train Acc: 0.887179 | Val Loss: 0.106290, Val Acc: 0.793814\n",
      "Epoch 21787 - Train Loss: 0.075178, Train Acc: 0.887179 | Val Loss: 0.106289, Val Acc: 0.793814\n",
      "Epoch 21788 - Train Loss: 0.075177, Train Acc: 0.887179 | Val Loss: 0.106289, Val Acc: 0.793814\n",
      "Epoch 21789 - Train Loss: 0.075175, Train Acc: 0.887179 | Val Loss: 0.106288, Val Acc: 0.793814\n",
      "Epoch 21790 - Train Loss: 0.075173, Train Acc: 0.887179 | Val Loss: 0.106288, Val Acc: 0.793814\n",
      "Epoch 21791 - Train Loss: 0.075171, Train Acc: 0.887179 | Val Loss: 0.106287, Val Acc: 0.793814\n",
      "Epoch 21792 - Train Loss: 0.075169, Train Acc: 0.887179 | Val Loss: 0.106286, Val Acc: 0.793814\n",
      "Epoch 21793 - Train Loss: 0.075168, Train Acc: 0.887179 | Val Loss: 0.106286, Val Acc: 0.793814\n",
      "Epoch 21794 - Train Loss: 0.075166, Train Acc: 0.887179 | Val Loss: 0.106285, Val Acc: 0.793814\n",
      "Epoch 21795 - Train Loss: 0.075164, Train Acc: 0.887179 | Val Loss: 0.106285, Val Acc: 0.793814\n",
      "Epoch 21796 - Train Loss: 0.075162, Train Acc: 0.887179 | Val Loss: 0.106284, Val Acc: 0.793814\n",
      "Epoch 21797 - Train Loss: 0.075160, Train Acc: 0.887179 | Val Loss: 0.106283, Val Acc: 0.793814\n",
      "Epoch 21798 - Train Loss: 0.075159, Train Acc: 0.887179 | Val Loss: 0.106283, Val Acc: 0.793814\n",
      "Epoch 21799 - Train Loss: 0.075157, Train Acc: 0.887179 | Val Loss: 0.106282, Val Acc: 0.793814\n",
      "Epoch 21800 - Train Loss: 0.075155, Train Acc: 0.887179 | Val Loss: 0.106282, Val Acc: 0.793814\n",
      "Epoch 21801 - Train Loss: 0.075153, Train Acc: 0.887179 | Val Loss: 0.106281, Val Acc: 0.793814\n",
      "Epoch 21802 - Train Loss: 0.075151, Train Acc: 0.887179 | Val Loss: 0.106280, Val Acc: 0.793814\n",
      "Epoch 21803 - Train Loss: 0.075150, Train Acc: 0.887179 | Val Loss: 0.106280, Val Acc: 0.793814\n",
      "Epoch 21804 - Train Loss: 0.075148, Train Acc: 0.887179 | Val Loss: 0.106279, Val Acc: 0.793814\n",
      "Epoch 21805 - Train Loss: 0.075146, Train Acc: 0.887179 | Val Loss: 0.106279, Val Acc: 0.793814\n",
      "Epoch 21806 - Train Loss: 0.075144, Train Acc: 0.887179 | Val Loss: 0.106278, Val Acc: 0.793814\n",
      "Epoch 21807 - Train Loss: 0.075142, Train Acc: 0.887179 | Val Loss: 0.106278, Val Acc: 0.793814\n",
      "Epoch 21808 - Train Loss: 0.075141, Train Acc: 0.887179 | Val Loss: 0.106277, Val Acc: 0.793814\n",
      "Epoch 21809 - Train Loss: 0.075139, Train Acc: 0.887179 | Val Loss: 0.106277, Val Acc: 0.793814\n",
      "Epoch 21810 - Train Loss: 0.075137, Train Acc: 0.887179 | Val Loss: 0.106276, Val Acc: 0.793814\n",
      "Epoch 21811 - Train Loss: 0.075135, Train Acc: 0.887179 | Val Loss: 0.106275, Val Acc: 0.793814\n",
      "Epoch 21812 - Train Loss: 0.075133, Train Acc: 0.887179 | Val Loss: 0.106275, Val Acc: 0.793814\n",
      "Epoch 21813 - Train Loss: 0.075132, Train Acc: 0.887179 | Val Loss: 0.106274, Val Acc: 0.793814\n",
      "Epoch 21814 - Train Loss: 0.075130, Train Acc: 0.887179 | Val Loss: 0.106274, Val Acc: 0.793814\n",
      "Epoch 21815 - Train Loss: 0.075128, Train Acc: 0.887179 | Val Loss: 0.106273, Val Acc: 0.793814\n",
      "Epoch 21816 - Train Loss: 0.075126, Train Acc: 0.887179 | Val Loss: 0.106272, Val Acc: 0.793814\n",
      "Epoch 21817 - Train Loss: 0.075124, Train Acc: 0.887179 | Val Loss: 0.106272, Val Acc: 0.793814\n",
      "Epoch 21818 - Train Loss: 0.075123, Train Acc: 0.887179 | Val Loss: 0.106271, Val Acc: 0.793814\n",
      "Epoch 21819 - Train Loss: 0.075121, Train Acc: 0.887179 | Val Loss: 0.106271, Val Acc: 0.793814\n",
      "Epoch 21820 - Train Loss: 0.075119, Train Acc: 0.887179 | Val Loss: 0.106270, Val Acc: 0.793814\n",
      "Epoch 21821 - Train Loss: 0.075117, Train Acc: 0.887179 | Val Loss: 0.106269, Val Acc: 0.793814\n",
      "Epoch 21822 - Train Loss: 0.075115, Train Acc: 0.887179 | Val Loss: 0.106269, Val Acc: 0.793814\n",
      "Epoch 21823 - Train Loss: 0.075114, Train Acc: 0.887179 | Val Loss: 0.106268, Val Acc: 0.793814\n",
      "Epoch 21824 - Train Loss: 0.075112, Train Acc: 0.887179 | Val Loss: 0.106268, Val Acc: 0.793814\n",
      "Epoch 21825 - Train Loss: 0.075110, Train Acc: 0.887179 | Val Loss: 0.106267, Val Acc: 0.793814\n",
      "Epoch 21826 - Train Loss: 0.075108, Train Acc: 0.887179 | Val Loss: 0.106267, Val Acc: 0.793814\n",
      "Epoch 21827 - Train Loss: 0.075106, Train Acc: 0.887179 | Val Loss: 0.106266, Val Acc: 0.793814\n",
      "Epoch 21828 - Train Loss: 0.075105, Train Acc: 0.887179 | Val Loss: 0.106265, Val Acc: 0.793814\n",
      "Epoch 21829 - Train Loss: 0.075103, Train Acc: 0.887179 | Val Loss: 0.106265, Val Acc: 0.793814\n",
      "Epoch 21830 - Train Loss: 0.075101, Train Acc: 0.887179 | Val Loss: 0.106264, Val Acc: 0.793814\n",
      "Epoch 21831 - Train Loss: 0.075099, Train Acc: 0.887179 | Val Loss: 0.106264, Val Acc: 0.793814\n",
      "Epoch 21832 - Train Loss: 0.075097, Train Acc: 0.887179 | Val Loss: 0.106263, Val Acc: 0.793814\n",
      "Epoch 21833 - Train Loss: 0.075096, Train Acc: 0.887179 | Val Loss: 0.106262, Val Acc: 0.793814\n",
      "Epoch 21834 - Train Loss: 0.075094, Train Acc: 0.887179 | Val Loss: 0.106262, Val Acc: 0.793814\n",
      "Epoch 21835 - Train Loss: 0.075092, Train Acc: 0.887179 | Val Loss: 0.106261, Val Acc: 0.793814\n",
      "Epoch 21836 - Train Loss: 0.075090, Train Acc: 0.887179 | Val Loss: 0.106261, Val Acc: 0.793814\n",
      "Epoch 21837 - Train Loss: 0.075088, Train Acc: 0.887179 | Val Loss: 0.106260, Val Acc: 0.793814\n",
      "Epoch 21838 - Train Loss: 0.075087, Train Acc: 0.887179 | Val Loss: 0.106260, Val Acc: 0.793814\n",
      "Epoch 21839 - Train Loss: 0.075085, Train Acc: 0.887179 | Val Loss: 0.106259, Val Acc: 0.793814\n",
      "Epoch 21840 - Train Loss: 0.075083, Train Acc: 0.887179 | Val Loss: 0.106258, Val Acc: 0.793814\n",
      "Epoch 21841 - Train Loss: 0.075081, Train Acc: 0.887179 | Val Loss: 0.106258, Val Acc: 0.793814\n",
      "Epoch 21842 - Train Loss: 0.075080, Train Acc: 0.887179 | Val Loss: 0.106257, Val Acc: 0.793814\n",
      "Epoch 21843 - Train Loss: 0.075078, Train Acc: 0.887179 | Val Loss: 0.106257, Val Acc: 0.793814\n",
      "Epoch 21844 - Train Loss: 0.075076, Train Acc: 0.887179 | Val Loss: 0.106256, Val Acc: 0.793814\n",
      "Epoch 21845 - Train Loss: 0.075074, Train Acc: 0.887179 | Val Loss: 0.106256, Val Acc: 0.793814\n",
      "Epoch 21846 - Train Loss: 0.075072, Train Acc: 0.887179 | Val Loss: 0.106255, Val Acc: 0.793814\n",
      "Epoch 21847 - Train Loss: 0.075071, Train Acc: 0.887179 | Val Loss: 0.106254, Val Acc: 0.793814\n",
      "Epoch 21848 - Train Loss: 0.075069, Train Acc: 0.887179 | Val Loss: 0.106254, Val Acc: 0.793814\n",
      "Epoch 21849 - Train Loss: 0.075067, Train Acc: 0.887179 | Val Loss: 0.106253, Val Acc: 0.793814\n",
      "Epoch 21850 - Train Loss: 0.075065, Train Acc: 0.887179 | Val Loss: 0.106253, Val Acc: 0.793814\n",
      "Epoch 21851 - Train Loss: 0.075063, Train Acc: 0.887179 | Val Loss: 0.106252, Val Acc: 0.793814\n",
      "Epoch 21852 - Train Loss: 0.075062, Train Acc: 0.887179 | Val Loss: 0.106251, Val Acc: 0.793814\n",
      "Epoch 21853 - Train Loss: 0.075060, Train Acc: 0.887179 | Val Loss: 0.106251, Val Acc: 0.793814\n",
      "Epoch 21854 - Train Loss: 0.075058, Train Acc: 0.887179 | Val Loss: 0.106250, Val Acc: 0.793814\n",
      "Epoch 21855 - Train Loss: 0.075056, Train Acc: 0.887179 | Val Loss: 0.106250, Val Acc: 0.793814\n",
      "Epoch 21856 - Train Loss: 0.075054, Train Acc: 0.887179 | Val Loss: 0.106249, Val Acc: 0.793814\n",
      "Epoch 21857 - Train Loss: 0.075053, Train Acc: 0.887179 | Val Loss: 0.106249, Val Acc: 0.793814\n",
      "Epoch 21858 - Train Loss: 0.075051, Train Acc: 0.887179 | Val Loss: 0.106248, Val Acc: 0.793814\n",
      "Epoch 21859 - Train Loss: 0.075049, Train Acc: 0.887179 | Val Loss: 0.106247, Val Acc: 0.793814\n",
      "Epoch 21860 - Train Loss: 0.075047, Train Acc: 0.887179 | Val Loss: 0.106247, Val Acc: 0.793814\n",
      "Epoch 21861 - Train Loss: 0.075045, Train Acc: 0.887179 | Val Loss: 0.106246, Val Acc: 0.793814\n",
      "Epoch 21862 - Train Loss: 0.075044, Train Acc: 0.887179 | Val Loss: 0.106246, Val Acc: 0.793814\n",
      "Epoch 21863 - Train Loss: 0.075042, Train Acc: 0.887179 | Val Loss: 0.106245, Val Acc: 0.793814\n",
      "Epoch 21864 - Train Loss: 0.075040, Train Acc: 0.887179 | Val Loss: 0.106245, Val Acc: 0.793814\n",
      "Epoch 21865 - Train Loss: 0.075038, Train Acc: 0.887179 | Val Loss: 0.106244, Val Acc: 0.793814\n",
      "Epoch 21866 - Train Loss: 0.075037, Train Acc: 0.887179 | Val Loss: 0.106243, Val Acc: 0.793814\n",
      "Epoch 21867 - Train Loss: 0.075035, Train Acc: 0.887179 | Val Loss: 0.106243, Val Acc: 0.793814\n",
      "Epoch 21868 - Train Loss: 0.075033, Train Acc: 0.887179 | Val Loss: 0.106242, Val Acc: 0.793814\n",
      "Epoch 21869 - Train Loss: 0.075031, Train Acc: 0.887179 | Val Loss: 0.106242, Val Acc: 0.793814\n",
      "Epoch 21870 - Train Loss: 0.075029, Train Acc: 0.887179 | Val Loss: 0.106241, Val Acc: 0.793814\n",
      "Epoch 21871 - Train Loss: 0.075028, Train Acc: 0.887179 | Val Loss: 0.106241, Val Acc: 0.793814\n",
      "Epoch 21872 - Train Loss: 0.075026, Train Acc: 0.887179 | Val Loss: 0.106240, Val Acc: 0.793814\n",
      "Epoch 21873 - Train Loss: 0.075024, Train Acc: 0.887179 | Val Loss: 0.106239, Val Acc: 0.793814\n",
      "Epoch 21874 - Train Loss: 0.075022, Train Acc: 0.887179 | Val Loss: 0.106239, Val Acc: 0.793814\n",
      "Epoch 21875 - Train Loss: 0.075020, Train Acc: 0.887179 | Val Loss: 0.106238, Val Acc: 0.793814\n",
      "Epoch 21876 - Train Loss: 0.075019, Train Acc: 0.887179 | Val Loss: 0.106238, Val Acc: 0.793814\n",
      "Epoch 21877 - Train Loss: 0.075017, Train Acc: 0.887179 | Val Loss: 0.106237, Val Acc: 0.793814\n",
      "Epoch 21878 - Train Loss: 0.075015, Train Acc: 0.887179 | Val Loss: 0.106236, Val Acc: 0.793814\n",
      "Epoch 21879 - Train Loss: 0.075013, Train Acc: 0.887179 | Val Loss: 0.106236, Val Acc: 0.793814\n",
      "Epoch 21880 - Train Loss: 0.075012, Train Acc: 0.887179 | Val Loss: 0.106235, Val Acc: 0.793814\n",
      "Epoch 21881 - Train Loss: 0.075010, Train Acc: 0.887179 | Val Loss: 0.106235, Val Acc: 0.793814\n",
      "Epoch 21882 - Train Loss: 0.075008, Train Acc: 0.887179 | Val Loss: 0.106234, Val Acc: 0.793814\n",
      "Epoch 21883 - Train Loss: 0.075006, Train Acc: 0.887179 | Val Loss: 0.106234, Val Acc: 0.793814\n",
      "Epoch 21884 - Train Loss: 0.075004, Train Acc: 0.887179 | Val Loss: 0.106233, Val Acc: 0.793814\n",
      "Epoch 21885 - Train Loss: 0.075003, Train Acc: 0.887179 | Val Loss: 0.106232, Val Acc: 0.793814\n",
      "Epoch 21886 - Train Loss: 0.075001, Train Acc: 0.887179 | Val Loss: 0.106232, Val Acc: 0.793814\n",
      "Epoch 21887 - Train Loss: 0.074999, Train Acc: 0.887179 | Val Loss: 0.106231, Val Acc: 0.793814\n",
      "Epoch 21888 - Train Loss: 0.074997, Train Acc: 0.887179 | Val Loss: 0.106231, Val Acc: 0.793814\n",
      "Epoch 21889 - Train Loss: 0.074995, Train Acc: 0.887179 | Val Loss: 0.106230, Val Acc: 0.793814\n",
      "Epoch 21890 - Train Loss: 0.074994, Train Acc: 0.887179 | Val Loss: 0.106230, Val Acc: 0.793814\n",
      "Epoch 21891 - Train Loss: 0.074992, Train Acc: 0.887179 | Val Loss: 0.106229, Val Acc: 0.793814\n",
      "Epoch 21892 - Train Loss: 0.074990, Train Acc: 0.887179 | Val Loss: 0.106228, Val Acc: 0.793814\n",
      "Epoch 21893 - Train Loss: 0.074988, Train Acc: 0.887179 | Val Loss: 0.106228, Val Acc: 0.793814\n",
      "Epoch 21894 - Train Loss: 0.074987, Train Acc: 0.887179 | Val Loss: 0.106227, Val Acc: 0.793814\n",
      "Epoch 21895 - Train Loss: 0.074985, Train Acc: 0.887179 | Val Loss: 0.106227, Val Acc: 0.793814\n",
      "Epoch 21896 - Train Loss: 0.074983, Train Acc: 0.887179 | Val Loss: 0.106226, Val Acc: 0.793814\n",
      "Epoch 21897 - Train Loss: 0.074981, Train Acc: 0.887179 | Val Loss: 0.106226, Val Acc: 0.793814\n",
      "Epoch 21898 - Train Loss: 0.074979, Train Acc: 0.887179 | Val Loss: 0.106225, Val Acc: 0.793814\n",
      "Epoch 21899 - Train Loss: 0.074978, Train Acc: 0.887179 | Val Loss: 0.106224, Val Acc: 0.793814\n",
      "Epoch 21900 - Train Loss: 0.074976, Train Acc: 0.887179 | Val Loss: 0.106224, Val Acc: 0.793814\n",
      "Epoch 21901 - Train Loss: 0.074974, Train Acc: 0.887179 | Val Loss: 0.106223, Val Acc: 0.793814\n",
      "Epoch 21902 - Train Loss: 0.074972, Train Acc: 0.887179 | Val Loss: 0.106223, Val Acc: 0.793814\n",
      "Epoch 21903 - Train Loss: 0.074970, Train Acc: 0.887179 | Val Loss: 0.106222, Val Acc: 0.793814\n",
      "Epoch 21904 - Train Loss: 0.074969, Train Acc: 0.887179 | Val Loss: 0.106222, Val Acc: 0.793814\n",
      "Epoch 21905 - Train Loss: 0.074967, Train Acc: 0.887179 | Val Loss: 0.106221, Val Acc: 0.793814\n",
      "Epoch 21906 - Train Loss: 0.074965, Train Acc: 0.887179 | Val Loss: 0.106220, Val Acc: 0.793814\n",
      "Epoch 21907 - Train Loss: 0.074963, Train Acc: 0.887179 | Val Loss: 0.106220, Val Acc: 0.793814\n",
      "Epoch 21908 - Train Loss: 0.074962, Train Acc: 0.887179 | Val Loss: 0.106219, Val Acc: 0.793814\n",
      "Epoch 21909 - Train Loss: 0.074960, Train Acc: 0.887179 | Val Loss: 0.106219, Val Acc: 0.793814\n",
      "Epoch 21910 - Train Loss: 0.074958, Train Acc: 0.887179 | Val Loss: 0.106218, Val Acc: 0.793814\n",
      "Epoch 21911 - Train Loss: 0.074956, Train Acc: 0.887179 | Val Loss: 0.106218, Val Acc: 0.793814\n",
      "Epoch 21912 - Train Loss: 0.074954, Train Acc: 0.887179 | Val Loss: 0.106217, Val Acc: 0.793814\n",
      "Epoch 21913 - Train Loss: 0.074953, Train Acc: 0.887179 | Val Loss: 0.106216, Val Acc: 0.793814\n",
      "Epoch 21914 - Train Loss: 0.074951, Train Acc: 0.887179 | Val Loss: 0.106216, Val Acc: 0.793814\n",
      "Epoch 21915 - Train Loss: 0.074949, Train Acc: 0.887179 | Val Loss: 0.106215, Val Acc: 0.793814\n",
      "Epoch 21916 - Train Loss: 0.074947, Train Acc: 0.887179 | Val Loss: 0.106215, Val Acc: 0.793814\n",
      "Epoch 21917 - Train Loss: 0.074946, Train Acc: 0.887179 | Val Loss: 0.106214, Val Acc: 0.793814\n",
      "Epoch 21918 - Train Loss: 0.074944, Train Acc: 0.887179 | Val Loss: 0.106214, Val Acc: 0.793814\n",
      "Epoch 21919 - Train Loss: 0.074942, Train Acc: 0.887179 | Val Loss: 0.106213, Val Acc: 0.793814\n",
      "Epoch 21920 - Train Loss: 0.074940, Train Acc: 0.887179 | Val Loss: 0.106212, Val Acc: 0.793814\n",
      "Epoch 21921 - Train Loss: 0.074938, Train Acc: 0.887179 | Val Loss: 0.106212, Val Acc: 0.793814\n",
      "Epoch 21922 - Train Loss: 0.074937, Train Acc: 0.887179 | Val Loss: 0.106211, Val Acc: 0.793814\n",
      "Epoch 21923 - Train Loss: 0.074935, Train Acc: 0.887179 | Val Loss: 0.106211, Val Acc: 0.793814\n",
      "Epoch 21924 - Train Loss: 0.074933, Train Acc: 0.887179 | Val Loss: 0.106210, Val Acc: 0.793814\n",
      "Epoch 21925 - Train Loss: 0.074931, Train Acc: 0.887179 | Val Loss: 0.106210, Val Acc: 0.793814\n",
      "Epoch 21926 - Train Loss: 0.074930, Train Acc: 0.887179 | Val Loss: 0.106209, Val Acc: 0.793814\n",
      "Epoch 21927 - Train Loss: 0.074928, Train Acc: 0.887179 | Val Loss: 0.106209, Val Acc: 0.793814\n",
      "Epoch 21928 - Train Loss: 0.074926, Train Acc: 0.887179 | Val Loss: 0.106208, Val Acc: 0.793814\n",
      "Epoch 21929 - Train Loss: 0.074924, Train Acc: 0.887179 | Val Loss: 0.106207, Val Acc: 0.793814\n",
      "Epoch 21930 - Train Loss: 0.074922, Train Acc: 0.887179 | Val Loss: 0.106207, Val Acc: 0.793814\n",
      "Epoch 21931 - Train Loss: 0.074921, Train Acc: 0.887179 | Val Loss: 0.106206, Val Acc: 0.793814\n",
      "Epoch 21932 - Train Loss: 0.074919, Train Acc: 0.887179 | Val Loss: 0.106206, Val Acc: 0.793814\n",
      "Epoch 21933 - Train Loss: 0.074917, Train Acc: 0.887179 | Val Loss: 0.106205, Val Acc: 0.793814\n",
      "Epoch 21934 - Train Loss: 0.074915, Train Acc: 0.887179 | Val Loss: 0.106205, Val Acc: 0.793814\n",
      "Epoch 21935 - Train Loss: 0.074914, Train Acc: 0.887179 | Val Loss: 0.106204, Val Acc: 0.793814\n",
      "Epoch 21936 - Train Loss: 0.074912, Train Acc: 0.887179 | Val Loss: 0.106203, Val Acc: 0.793814\n",
      "Epoch 21937 - Train Loss: 0.074910, Train Acc: 0.887179 | Val Loss: 0.106203, Val Acc: 0.793814\n",
      "Epoch 21938 - Train Loss: 0.074908, Train Acc: 0.887179 | Val Loss: 0.106202, Val Acc: 0.793814\n",
      "Epoch 21939 - Train Loss: 0.074906, Train Acc: 0.887179 | Val Loss: 0.106202, Val Acc: 0.793814\n",
      "Epoch 21940 - Train Loss: 0.074905, Train Acc: 0.887179 | Val Loss: 0.106201, Val Acc: 0.793814\n",
      "Epoch 21941 - Train Loss: 0.074903, Train Acc: 0.887179 | Val Loss: 0.106200, Val Acc: 0.793814\n",
      "Epoch 21942 - Train Loss: 0.074901, Train Acc: 0.887179 | Val Loss: 0.106200, Val Acc: 0.793814\n",
      "Epoch 21943 - Train Loss: 0.074899, Train Acc: 0.887179 | Val Loss: 0.106199, Val Acc: 0.793814\n",
      "Epoch 21944 - Train Loss: 0.074898, Train Acc: 0.887179 | Val Loss: 0.106199, Val Acc: 0.793814\n",
      "Epoch 21945 - Train Loss: 0.074896, Train Acc: 0.887179 | Val Loss: 0.106198, Val Acc: 0.793814\n",
      "Epoch 21946 - Train Loss: 0.074894, Train Acc: 0.887179 | Val Loss: 0.106198, Val Acc: 0.793814\n",
      "Epoch 21947 - Train Loss: 0.074892, Train Acc: 0.887179 | Val Loss: 0.106197, Val Acc: 0.793814\n",
      "Epoch 21948 - Train Loss: 0.074890, Train Acc: 0.887179 | Val Loss: 0.106197, Val Acc: 0.793814\n",
      "Epoch 21949 - Train Loss: 0.074889, Train Acc: 0.887179 | Val Loss: 0.106196, Val Acc: 0.793814\n",
      "Epoch 21950 - Train Loss: 0.074887, Train Acc: 0.887179 | Val Loss: 0.106195, Val Acc: 0.793814\n",
      "Epoch 21951 - Train Loss: 0.074885, Train Acc: 0.887179 | Val Loss: 0.106195, Val Acc: 0.793814\n",
      "Epoch 21952 - Train Loss: 0.074883, Train Acc: 0.887179 | Val Loss: 0.106194, Val Acc: 0.793814\n",
      "Epoch 21953 - Train Loss: 0.074882, Train Acc: 0.887179 | Val Loss: 0.106194, Val Acc: 0.793814\n",
      "Epoch 21954 - Train Loss: 0.074880, Train Acc: 0.887179 | Val Loss: 0.106193, Val Acc: 0.793814\n",
      "Epoch 21955 - Train Loss: 0.074878, Train Acc: 0.887179 | Val Loss: 0.106193, Val Acc: 0.793814\n",
      "Epoch 21956 - Train Loss: 0.074876, Train Acc: 0.887179 | Val Loss: 0.106192, Val Acc: 0.793814\n",
      "Epoch 21957 - Train Loss: 0.074874, Train Acc: 0.887179 | Val Loss: 0.106192, Val Acc: 0.793814\n",
      "Epoch 21958 - Train Loss: 0.074873, Train Acc: 0.887179 | Val Loss: 0.106191, Val Acc: 0.793814\n",
      "Epoch 21959 - Train Loss: 0.074871, Train Acc: 0.887179 | Val Loss: 0.106190, Val Acc: 0.793814\n",
      "Epoch 21960 - Train Loss: 0.074869, Train Acc: 0.887179 | Val Loss: 0.106190, Val Acc: 0.793814\n",
      "Epoch 21961 - Train Loss: 0.074867, Train Acc: 0.887179 | Val Loss: 0.106189, Val Acc: 0.793814\n",
      "Epoch 21962 - Train Loss: 0.074866, Train Acc: 0.887179 | Val Loss: 0.106189, Val Acc: 0.793814\n",
      "Epoch 21963 - Train Loss: 0.074864, Train Acc: 0.887179 | Val Loss: 0.106188, Val Acc: 0.793814\n",
      "Epoch 21964 - Train Loss: 0.074862, Train Acc: 0.887179 | Val Loss: 0.106188, Val Acc: 0.793814\n",
      "Epoch 21965 - Train Loss: 0.074860, Train Acc: 0.887179 | Val Loss: 0.106187, Val Acc: 0.793814\n",
      "Epoch 21966 - Train Loss: 0.074858, Train Acc: 0.887179 | Val Loss: 0.106187, Val Acc: 0.793814\n",
      "Epoch 21967 - Train Loss: 0.074857, Train Acc: 0.887179 | Val Loss: 0.106186, Val Acc: 0.793814\n",
      "Epoch 21968 - Train Loss: 0.074855, Train Acc: 0.887179 | Val Loss: 0.106185, Val Acc: 0.793814\n",
      "Epoch 21969 - Train Loss: 0.074853, Train Acc: 0.887179 | Val Loss: 0.106185, Val Acc: 0.793814\n",
      "Epoch 21970 - Train Loss: 0.074851, Train Acc: 0.887179 | Val Loss: 0.106184, Val Acc: 0.793814\n",
      "Epoch 21971 - Train Loss: 0.074850, Train Acc: 0.887179 | Val Loss: 0.106184, Val Acc: 0.793814\n",
      "Epoch 21972 - Train Loss: 0.074848, Train Acc: 0.887179 | Val Loss: 0.106183, Val Acc: 0.793814\n",
      "Epoch 21973 - Train Loss: 0.074846, Train Acc: 0.887179 | Val Loss: 0.106183, Val Acc: 0.793814\n",
      "Epoch 21974 - Train Loss: 0.074844, Train Acc: 0.887179 | Val Loss: 0.106182, Val Acc: 0.793814\n",
      "Epoch 21975 - Train Loss: 0.074843, Train Acc: 0.887179 | Val Loss: 0.106181, Val Acc: 0.793814\n",
      "Epoch 21976 - Train Loss: 0.074841, Train Acc: 0.887179 | Val Loss: 0.106181, Val Acc: 0.793814\n",
      "Epoch 21977 - Train Loss: 0.074839, Train Acc: 0.887179 | Val Loss: 0.106180, Val Acc: 0.793814\n",
      "Epoch 21978 - Train Loss: 0.074837, Train Acc: 0.887179 | Val Loss: 0.106180, Val Acc: 0.793814\n",
      "Epoch 21979 - Train Loss: 0.074835, Train Acc: 0.887179 | Val Loss: 0.106179, Val Acc: 0.793814\n",
      "Epoch 21980 - Train Loss: 0.074834, Train Acc: 0.887179 | Val Loss: 0.106179, Val Acc: 0.793814\n",
      "Epoch 21981 - Train Loss: 0.074832, Train Acc: 0.887179 | Val Loss: 0.106178, Val Acc: 0.793814\n",
      "Epoch 21982 - Train Loss: 0.074830, Train Acc: 0.887179 | Val Loss: 0.106178, Val Acc: 0.793814\n",
      "Epoch 21983 - Train Loss: 0.074828, Train Acc: 0.887179 | Val Loss: 0.106177, Val Acc: 0.793814\n",
      "Epoch 21984 - Train Loss: 0.074827, Train Acc: 0.887179 | Val Loss: 0.106176, Val Acc: 0.793814\n",
      "Epoch 21985 - Train Loss: 0.074825, Train Acc: 0.887179 | Val Loss: 0.106176, Val Acc: 0.793814\n",
      "Epoch 21986 - Train Loss: 0.074823, Train Acc: 0.887179 | Val Loss: 0.106175, Val Acc: 0.793814\n",
      "Epoch 21987 - Train Loss: 0.074821, Train Acc: 0.887179 | Val Loss: 0.106175, Val Acc: 0.793814\n",
      "Epoch 21988 - Train Loss: 0.074820, Train Acc: 0.887179 | Val Loss: 0.106174, Val Acc: 0.793814\n",
      "Epoch 21989 - Train Loss: 0.074818, Train Acc: 0.887179 | Val Loss: 0.106174, Val Acc: 0.793814\n",
      "Epoch 21990 - Train Loss: 0.074816, Train Acc: 0.887179 | Val Loss: 0.106173, Val Acc: 0.793814\n",
      "Epoch 21991 - Train Loss: 0.074814, Train Acc: 0.887179 | Val Loss: 0.106172, Val Acc: 0.793814\n",
      "Epoch 21992 - Train Loss: 0.074812, Train Acc: 0.887179 | Val Loss: 0.106172, Val Acc: 0.793814\n",
      "Epoch 21993 - Train Loss: 0.074811, Train Acc: 0.887179 | Val Loss: 0.106171, Val Acc: 0.793814\n",
      "Epoch 21994 - Train Loss: 0.074809, Train Acc: 0.887179 | Val Loss: 0.106171, Val Acc: 0.793814\n",
      "Epoch 21995 - Train Loss: 0.074807, Train Acc: 0.887179 | Val Loss: 0.106170, Val Acc: 0.793814\n",
      "Epoch 21996 - Train Loss: 0.074805, Train Acc: 0.887179 | Val Loss: 0.106170, Val Acc: 0.793814\n",
      "Epoch 21997 - Train Loss: 0.074804, Train Acc: 0.887179 | Val Loss: 0.106169, Val Acc: 0.793814\n",
      "Epoch 21998 - Train Loss: 0.074802, Train Acc: 0.887179 | Val Loss: 0.106169, Val Acc: 0.793814\n",
      "Epoch 21999 - Train Loss: 0.074800, Train Acc: 0.887179 | Val Loss: 0.106168, Val Acc: 0.793814\n",
      "Epoch 22000 - Train Loss: 0.074798, Train Acc: 0.887179 | Val Loss: 0.106167, Val Acc: 0.793814\n",
      "Epoch 22001 - Train Loss: 0.074797, Train Acc: 0.887179 | Val Loss: 0.106167, Val Acc: 0.793814\n",
      "Epoch 22002 - Train Loss: 0.074795, Train Acc: 0.887179 | Val Loss: 0.106166, Val Acc: 0.793814\n",
      "Epoch 22003 - Train Loss: 0.074793, Train Acc: 0.887179 | Val Loss: 0.106166, Val Acc: 0.793814\n",
      "Epoch 22004 - Train Loss: 0.074791, Train Acc: 0.887179 | Val Loss: 0.106165, Val Acc: 0.793814\n",
      "Epoch 22005 - Train Loss: 0.074789, Train Acc: 0.887179 | Val Loss: 0.106165, Val Acc: 0.793814\n",
      "Epoch 22006 - Train Loss: 0.074788, Train Acc: 0.887179 | Val Loss: 0.106164, Val Acc: 0.793814\n",
      "Epoch 22007 - Train Loss: 0.074786, Train Acc: 0.887179 | Val Loss: 0.106164, Val Acc: 0.793814\n",
      "Epoch 22008 - Train Loss: 0.074784, Train Acc: 0.887179 | Val Loss: 0.106163, Val Acc: 0.793814\n",
      "Epoch 22009 - Train Loss: 0.074782, Train Acc: 0.887179 | Val Loss: 0.106163, Val Acc: 0.793814\n",
      "Epoch 22010 - Train Loss: 0.074781, Train Acc: 0.887179 | Val Loss: 0.106162, Val Acc: 0.793814\n",
      "Epoch 22011 - Train Loss: 0.074779, Train Acc: 0.887179 | Val Loss: 0.106161, Val Acc: 0.793814\n",
      "Epoch 22012 - Train Loss: 0.074777, Train Acc: 0.887179 | Val Loss: 0.106161, Val Acc: 0.793814\n",
      "Epoch 22013 - Train Loss: 0.074775, Train Acc: 0.887179 | Val Loss: 0.106160, Val Acc: 0.793814\n",
      "Epoch 22014 - Train Loss: 0.074774, Train Acc: 0.887179 | Val Loss: 0.106160, Val Acc: 0.793814\n",
      "Epoch 22015 - Train Loss: 0.074772, Train Acc: 0.887179 | Val Loss: 0.106159, Val Acc: 0.793814\n",
      "Epoch 22016 - Train Loss: 0.074770, Train Acc: 0.887179 | Val Loss: 0.106159, Val Acc: 0.793814\n",
      "Epoch 22017 - Train Loss: 0.074768, Train Acc: 0.887179 | Val Loss: 0.106158, Val Acc: 0.793814\n",
      "Epoch 22018 - Train Loss: 0.074767, Train Acc: 0.887179 | Val Loss: 0.106158, Val Acc: 0.793814\n",
      "Epoch 22019 - Train Loss: 0.074765, Train Acc: 0.887179 | Val Loss: 0.106157, Val Acc: 0.793814\n",
      "Epoch 22020 - Train Loss: 0.074763, Train Acc: 0.887179 | Val Loss: 0.106156, Val Acc: 0.793814\n",
      "Epoch 22021 - Train Loss: 0.074761, Train Acc: 0.887179 | Val Loss: 0.106156, Val Acc: 0.793814\n",
      "Epoch 22022 - Train Loss: 0.074759, Train Acc: 0.887179 | Val Loss: 0.106155, Val Acc: 0.793814\n",
      "Epoch 22023 - Train Loss: 0.074758, Train Acc: 0.887179 | Val Loss: 0.106155, Val Acc: 0.793814\n",
      "Epoch 22024 - Train Loss: 0.074756, Train Acc: 0.887179 | Val Loss: 0.106154, Val Acc: 0.793814\n",
      "Epoch 22025 - Train Loss: 0.074754, Train Acc: 0.887179 | Val Loss: 0.106154, Val Acc: 0.793814\n",
      "Epoch 22026 - Train Loss: 0.074752, Train Acc: 0.887179 | Val Loss: 0.106153, Val Acc: 0.793814\n",
      "Epoch 22027 - Train Loss: 0.074751, Train Acc: 0.887179 | Val Loss: 0.106153, Val Acc: 0.793814\n",
      "Epoch 22028 - Train Loss: 0.074749, Train Acc: 0.887179 | Val Loss: 0.106152, Val Acc: 0.793814\n",
      "Epoch 22029 - Train Loss: 0.074747, Train Acc: 0.887179 | Val Loss: 0.106151, Val Acc: 0.793814\n",
      "Epoch 22030 - Train Loss: 0.074745, Train Acc: 0.887179 | Val Loss: 0.106151, Val Acc: 0.793814\n",
      "Epoch 22031 - Train Loss: 0.074744, Train Acc: 0.887179 | Val Loss: 0.106150, Val Acc: 0.793814\n",
      "Epoch 22032 - Train Loss: 0.074742, Train Acc: 0.887179 | Val Loss: 0.106150, Val Acc: 0.793814\n",
      "Epoch 22033 - Train Loss: 0.074740, Train Acc: 0.887179 | Val Loss: 0.106149, Val Acc: 0.793814\n",
      "Epoch 22034 - Train Loss: 0.074738, Train Acc: 0.887179 | Val Loss: 0.106149, Val Acc: 0.793814\n",
      "Epoch 22035 - Train Loss: 0.074737, Train Acc: 0.887179 | Val Loss: 0.106148, Val Acc: 0.793814\n",
      "Epoch 22036 - Train Loss: 0.074735, Train Acc: 0.887179 | Val Loss: 0.106148, Val Acc: 0.793814\n",
      "Epoch 22037 - Train Loss: 0.074733, Train Acc: 0.887179 | Val Loss: 0.106147, Val Acc: 0.793814\n",
      "Epoch 22038 - Train Loss: 0.074731, Train Acc: 0.887179 | Val Loss: 0.106146, Val Acc: 0.793814\n",
      "Epoch 22039 - Train Loss: 0.074730, Train Acc: 0.887179 | Val Loss: 0.106146, Val Acc: 0.793814\n",
      "Epoch 22040 - Train Loss: 0.074728, Train Acc: 0.887179 | Val Loss: 0.106145, Val Acc: 0.793814\n",
      "Epoch 22041 - Train Loss: 0.074726, Train Acc: 0.887179 | Val Loss: 0.106145, Val Acc: 0.793814\n",
      "Epoch 22042 - Train Loss: 0.074724, Train Acc: 0.887179 | Val Loss: 0.106144, Val Acc: 0.793814\n",
      "Epoch 22043 - Train Loss: 0.074722, Train Acc: 0.887179 | Val Loss: 0.106144, Val Acc: 0.793814\n",
      "Epoch 22044 - Train Loss: 0.074721, Train Acc: 0.887179 | Val Loss: 0.106143, Val Acc: 0.793814\n",
      "Epoch 22045 - Train Loss: 0.074719, Train Acc: 0.887179 | Val Loss: 0.106143, Val Acc: 0.793814\n",
      "Epoch 22046 - Train Loss: 0.074717, Train Acc: 0.887179 | Val Loss: 0.106142, Val Acc: 0.793814\n",
      "Epoch 22047 - Train Loss: 0.074715, Train Acc: 0.887179 | Val Loss: 0.106141, Val Acc: 0.793814\n",
      "Epoch 22048 - Train Loss: 0.074714, Train Acc: 0.887179 | Val Loss: 0.106141, Val Acc: 0.793814\n",
      "Epoch 22049 - Train Loss: 0.074712, Train Acc: 0.887179 | Val Loss: 0.106140, Val Acc: 0.793814\n",
      "Epoch 22050 - Train Loss: 0.074710, Train Acc: 0.887179 | Val Loss: 0.106140, Val Acc: 0.793814\n",
      "Epoch 22051 - Train Loss: 0.074708, Train Acc: 0.887179 | Val Loss: 0.106139, Val Acc: 0.793814\n",
      "Epoch 22052 - Train Loss: 0.074707, Train Acc: 0.887179 | Val Loss: 0.106139, Val Acc: 0.793814\n",
      "Epoch 22053 - Train Loss: 0.074705, Train Acc: 0.887179 | Val Loss: 0.106138, Val Acc: 0.793814\n",
      "Epoch 22054 - Train Loss: 0.074703, Train Acc: 0.887179 | Val Loss: 0.106138, Val Acc: 0.793814\n",
      "Epoch 22055 - Train Loss: 0.074701, Train Acc: 0.887179 | Val Loss: 0.106137, Val Acc: 0.793814\n",
      "Epoch 22056 - Train Loss: 0.074700, Train Acc: 0.887179 | Val Loss: 0.106136, Val Acc: 0.793814\n",
      "Epoch 22057 - Train Loss: 0.074698, Train Acc: 0.887179 | Val Loss: 0.106136, Val Acc: 0.793814\n",
      "Epoch 22058 - Train Loss: 0.074696, Train Acc: 0.887179 | Val Loss: 0.106135, Val Acc: 0.793814\n",
      "Epoch 22059 - Train Loss: 0.074694, Train Acc: 0.887179 | Val Loss: 0.106135, Val Acc: 0.793814\n",
      "Epoch 22060 - Train Loss: 0.074693, Train Acc: 0.887179 | Val Loss: 0.106134, Val Acc: 0.793814\n",
      "Epoch 22061 - Train Loss: 0.074691, Train Acc: 0.887179 | Val Loss: 0.106134, Val Acc: 0.793814\n",
      "Epoch 22062 - Train Loss: 0.074689, Train Acc: 0.887179 | Val Loss: 0.106133, Val Acc: 0.793814\n",
      "Epoch 22063 - Train Loss: 0.074687, Train Acc: 0.887179 | Val Loss: 0.106133, Val Acc: 0.793814\n",
      "Epoch 22064 - Train Loss: 0.074686, Train Acc: 0.887179 | Val Loss: 0.106132, Val Acc: 0.793814\n",
      "Epoch 22065 - Train Loss: 0.074684, Train Acc: 0.887179 | Val Loss: 0.106132, Val Acc: 0.793814\n",
      "Epoch 22066 - Train Loss: 0.074682, Train Acc: 0.887179 | Val Loss: 0.106131, Val Acc: 0.793814\n",
      "Epoch 22067 - Train Loss: 0.074680, Train Acc: 0.887179 | Val Loss: 0.106130, Val Acc: 0.793814\n",
      "Epoch 22068 - Train Loss: 0.074678, Train Acc: 0.887179 | Val Loss: 0.106130, Val Acc: 0.793814\n",
      "Epoch 22069 - Train Loss: 0.074677, Train Acc: 0.887179 | Val Loss: 0.106129, Val Acc: 0.793814\n",
      "Epoch 22070 - Train Loss: 0.074675, Train Acc: 0.887179 | Val Loss: 0.106129, Val Acc: 0.793814\n",
      "Epoch 22071 - Train Loss: 0.074673, Train Acc: 0.887179 | Val Loss: 0.106128, Val Acc: 0.793814\n",
      "Epoch 22072 - Train Loss: 0.074671, Train Acc: 0.887179 | Val Loss: 0.106128, Val Acc: 0.793814\n",
      "Epoch 22073 - Train Loss: 0.074670, Train Acc: 0.887179 | Val Loss: 0.106127, Val Acc: 0.793814\n",
      "Epoch 22074 - Train Loss: 0.074668, Train Acc: 0.887179 | Val Loss: 0.106127, Val Acc: 0.793814\n",
      "Epoch 22075 - Train Loss: 0.074666, Train Acc: 0.887179 | Val Loss: 0.106126, Val Acc: 0.793814\n",
      "Epoch 22076 - Train Loss: 0.074664, Train Acc: 0.887179 | Val Loss: 0.106125, Val Acc: 0.793814\n",
      "Epoch 22077 - Train Loss: 0.074663, Train Acc: 0.887179 | Val Loss: 0.106125, Val Acc: 0.793814\n",
      "Epoch 22078 - Train Loss: 0.074661, Train Acc: 0.887179 | Val Loss: 0.106124, Val Acc: 0.793814\n",
      "Epoch 22079 - Train Loss: 0.074659, Train Acc: 0.887179 | Val Loss: 0.106124, Val Acc: 0.793814\n",
      "Epoch 22080 - Train Loss: 0.074657, Train Acc: 0.887179 | Val Loss: 0.106123, Val Acc: 0.793814\n",
      "Epoch 22081 - Train Loss: 0.074656, Train Acc: 0.887179 | Val Loss: 0.106123, Val Acc: 0.793814\n",
      "Epoch 22082 - Train Loss: 0.074654, Train Acc: 0.887179 | Val Loss: 0.106122, Val Acc: 0.793814\n",
      "Epoch 22083 - Train Loss: 0.074652, Train Acc: 0.887179 | Val Loss: 0.106121, Val Acc: 0.793814\n",
      "Epoch 22084 - Train Loss: 0.074650, Train Acc: 0.887179 | Val Loss: 0.106121, Val Acc: 0.793814\n",
      "Epoch 22085 - Train Loss: 0.074649, Train Acc: 0.887179 | Val Loss: 0.106120, Val Acc: 0.793814\n",
      "Epoch 22086 - Train Loss: 0.074647, Train Acc: 0.887179 | Val Loss: 0.106120, Val Acc: 0.793814\n",
      "Epoch 22087 - Train Loss: 0.074645, Train Acc: 0.887179 | Val Loss: 0.106119, Val Acc: 0.793814\n",
      "Epoch 22088 - Train Loss: 0.074643, Train Acc: 0.887179 | Val Loss: 0.106119, Val Acc: 0.793814\n",
      "Epoch 22089 - Train Loss: 0.074642, Train Acc: 0.887179 | Val Loss: 0.106118, Val Acc: 0.793814\n",
      "Epoch 22090 - Train Loss: 0.074640, Train Acc: 0.887179 | Val Loss: 0.106118, Val Acc: 0.793814\n",
      "Epoch 22091 - Train Loss: 0.074638, Train Acc: 0.887179 | Val Loss: 0.106117, Val Acc: 0.793814\n",
      "Epoch 22092 - Train Loss: 0.074636, Train Acc: 0.887179 | Val Loss: 0.106117, Val Acc: 0.793814\n",
      "Epoch 22093 - Train Loss: 0.074635, Train Acc: 0.887179 | Val Loss: 0.106116, Val Acc: 0.793814\n",
      "Epoch 22094 - Train Loss: 0.074633, Train Acc: 0.887179 | Val Loss: 0.106115, Val Acc: 0.793814\n",
      "Epoch 22095 - Train Loss: 0.074631, Train Acc: 0.887179 | Val Loss: 0.106115, Val Acc: 0.793814\n",
      "Epoch 22096 - Train Loss: 0.074629, Train Acc: 0.887179 | Val Loss: 0.106114, Val Acc: 0.793814\n",
      "Epoch 22097 - Train Loss: 0.074628, Train Acc: 0.887179 | Val Loss: 0.106114, Val Acc: 0.793814\n",
      "Epoch 22098 - Train Loss: 0.074626, Train Acc: 0.887179 | Val Loss: 0.106113, Val Acc: 0.793814\n",
      "Epoch 22099 - Train Loss: 0.074624, Train Acc: 0.887179 | Val Loss: 0.106113, Val Acc: 0.793814\n",
      "Epoch 22100 - Train Loss: 0.074622, Train Acc: 0.887179 | Val Loss: 0.106112, Val Acc: 0.793814\n",
      "Epoch 22101 - Train Loss: 0.074621, Train Acc: 0.887179 | Val Loss: 0.106112, Val Acc: 0.793814\n",
      "Epoch 22102 - Train Loss: 0.074619, Train Acc: 0.887179 | Val Loss: 0.106111, Val Acc: 0.793814\n",
      "Epoch 22103 - Train Loss: 0.074617, Train Acc: 0.887179 | Val Loss: 0.106110, Val Acc: 0.793814\n",
      "Epoch 22104 - Train Loss: 0.074615, Train Acc: 0.887179 | Val Loss: 0.106110, Val Acc: 0.793814\n",
      "Epoch 22105 - Train Loss: 0.074614, Train Acc: 0.887179 | Val Loss: 0.106109, Val Acc: 0.793814\n",
      "Epoch 22106 - Train Loss: 0.074612, Train Acc: 0.887179 | Val Loss: 0.106109, Val Acc: 0.793814\n",
      "Epoch 22107 - Train Loss: 0.074610, Train Acc: 0.887179 | Val Loss: 0.106108, Val Acc: 0.793814\n",
      "Epoch 22108 - Train Loss: 0.074608, Train Acc: 0.887179 | Val Loss: 0.106108, Val Acc: 0.793814\n",
      "Epoch 22109 - Train Loss: 0.074607, Train Acc: 0.887179 | Val Loss: 0.106107, Val Acc: 0.793814\n",
      "Epoch 22110 - Train Loss: 0.074605, Train Acc: 0.887179 | Val Loss: 0.106107, Val Acc: 0.793814\n",
      "Epoch 22111 - Train Loss: 0.074603, Train Acc: 0.887179 | Val Loss: 0.106106, Val Acc: 0.793814\n",
      "Epoch 22112 - Train Loss: 0.074601, Train Acc: 0.887179 | Val Loss: 0.106106, Val Acc: 0.793814\n",
      "Epoch 22113 - Train Loss: 0.074600, Train Acc: 0.887179 | Val Loss: 0.106105, Val Acc: 0.793814\n",
      "Epoch 22114 - Train Loss: 0.074598, Train Acc: 0.887179 | Val Loss: 0.106105, Val Acc: 0.793814\n",
      "Epoch 22115 - Train Loss: 0.074596, Train Acc: 0.887179 | Val Loss: 0.106104, Val Acc: 0.793814\n",
      "Epoch 22116 - Train Loss: 0.074594, Train Acc: 0.887179 | Val Loss: 0.106103, Val Acc: 0.793814\n",
      "Epoch 22117 - Train Loss: 0.074593, Train Acc: 0.887179 | Val Loss: 0.106103, Val Acc: 0.793814\n",
      "Epoch 22118 - Train Loss: 0.074591, Train Acc: 0.887179 | Val Loss: 0.106102, Val Acc: 0.793814\n",
      "Epoch 22119 - Train Loss: 0.074589, Train Acc: 0.887179 | Val Loss: 0.106102, Val Acc: 0.793814\n",
      "Epoch 22120 - Train Loss: 0.074587, Train Acc: 0.887179 | Val Loss: 0.106101, Val Acc: 0.793814\n",
      "Epoch 22121 - Train Loss: 0.074586, Train Acc: 0.887179 | Val Loss: 0.106101, Val Acc: 0.793814\n",
      "Epoch 22122 - Train Loss: 0.074584, Train Acc: 0.887179 | Val Loss: 0.106100, Val Acc: 0.793814\n",
      "Epoch 22123 - Train Loss: 0.074582, Train Acc: 0.887179 | Val Loss: 0.106100, Val Acc: 0.793814\n",
      "Epoch 22124 - Train Loss: 0.074580, Train Acc: 0.887179 | Val Loss: 0.106099, Val Acc: 0.793814\n",
      "Epoch 22125 - Train Loss: 0.074579, Train Acc: 0.887179 | Val Loss: 0.106099, Val Acc: 0.793814\n",
      "Epoch 22126 - Train Loss: 0.074577, Train Acc: 0.887179 | Val Loss: 0.106098, Val Acc: 0.793814\n",
      "Epoch 22127 - Train Loss: 0.074575, Train Acc: 0.887179 | Val Loss: 0.106097, Val Acc: 0.793814\n",
      "Epoch 22128 - Train Loss: 0.074573, Train Acc: 0.887179 | Val Loss: 0.106097, Val Acc: 0.793814\n",
      "Epoch 22129 - Train Loss: 0.074572, Train Acc: 0.887179 | Val Loss: 0.106096, Val Acc: 0.793814\n",
      "Epoch 22130 - Train Loss: 0.074570, Train Acc: 0.887179 | Val Loss: 0.106096, Val Acc: 0.793814\n",
      "Epoch 22131 - Train Loss: 0.074568, Train Acc: 0.887179 | Val Loss: 0.106095, Val Acc: 0.793814\n",
      "Epoch 22132 - Train Loss: 0.074566, Train Acc: 0.887179 | Val Loss: 0.106095, Val Acc: 0.793814\n",
      "Epoch 22133 - Train Loss: 0.074565, Train Acc: 0.887179 | Val Loss: 0.106094, Val Acc: 0.793814\n",
      "Epoch 22134 - Train Loss: 0.074563, Train Acc: 0.887179 | Val Loss: 0.106094, Val Acc: 0.793814\n",
      "Epoch 22135 - Train Loss: 0.074561, Train Acc: 0.887179 | Val Loss: 0.106093, Val Acc: 0.793814\n",
      "Epoch 22136 - Train Loss: 0.074559, Train Acc: 0.887179 | Val Loss: 0.106092, Val Acc: 0.793814\n",
      "Epoch 22137 - Train Loss: 0.074558, Train Acc: 0.887179 | Val Loss: 0.106092, Val Acc: 0.793814\n",
      "Epoch 22138 - Train Loss: 0.074556, Train Acc: 0.887179 | Val Loss: 0.106091, Val Acc: 0.793814\n",
      "Epoch 22139 - Train Loss: 0.074554, Train Acc: 0.887179 | Val Loss: 0.106091, Val Acc: 0.793814\n",
      "Epoch 22140 - Train Loss: 0.074552, Train Acc: 0.887179 | Val Loss: 0.106090, Val Acc: 0.793814\n",
      "Epoch 22141 - Train Loss: 0.074551, Train Acc: 0.887179 | Val Loss: 0.106090, Val Acc: 0.793814\n",
      "Epoch 22142 - Train Loss: 0.074549, Train Acc: 0.887179 | Val Loss: 0.106089, Val Acc: 0.793814\n",
      "Epoch 22143 - Train Loss: 0.074547, Train Acc: 0.887179 | Val Loss: 0.106089, Val Acc: 0.793814\n",
      "Epoch 22144 - Train Loss: 0.074545, Train Acc: 0.887179 | Val Loss: 0.106088, Val Acc: 0.793814\n",
      "Epoch 22145 - Train Loss: 0.074544, Train Acc: 0.887179 | Val Loss: 0.106088, Val Acc: 0.793814\n",
      "Epoch 22146 - Train Loss: 0.074542, Train Acc: 0.887179 | Val Loss: 0.106087, Val Acc: 0.793814\n",
      "Epoch 22147 - Train Loss: 0.074540, Train Acc: 0.887179 | Val Loss: 0.106087, Val Acc: 0.793814\n",
      "Epoch 22148 - Train Loss: 0.074538, Train Acc: 0.887179 | Val Loss: 0.106086, Val Acc: 0.793814\n",
      "Epoch 22149 - Train Loss: 0.074537, Train Acc: 0.887179 | Val Loss: 0.106085, Val Acc: 0.793814\n",
      "Epoch 22150 - Train Loss: 0.074535, Train Acc: 0.887179 | Val Loss: 0.106085, Val Acc: 0.793814\n",
      "Epoch 22151 - Train Loss: 0.074533, Train Acc: 0.887179 | Val Loss: 0.106084, Val Acc: 0.793814\n",
      "Epoch 22152 - Train Loss: 0.074531, Train Acc: 0.887179 | Val Loss: 0.106084, Val Acc: 0.793814\n",
      "Epoch 22153 - Train Loss: 0.074530, Train Acc: 0.887179 | Val Loss: 0.106083, Val Acc: 0.793814\n",
      "Epoch 22154 - Train Loss: 0.074528, Train Acc: 0.887179 | Val Loss: 0.106083, Val Acc: 0.793814\n",
      "Epoch 22155 - Train Loss: 0.074526, Train Acc: 0.887179 | Val Loss: 0.106082, Val Acc: 0.793814\n",
      "Epoch 22156 - Train Loss: 0.074524, Train Acc: 0.887179 | Val Loss: 0.106082, Val Acc: 0.793814\n",
      "Epoch 22157 - Train Loss: 0.074523, Train Acc: 0.887179 | Val Loss: 0.106081, Val Acc: 0.793814\n",
      "Epoch 22158 - Train Loss: 0.074521, Train Acc: 0.887179 | Val Loss: 0.106081, Val Acc: 0.793814\n",
      "Epoch 22159 - Train Loss: 0.074519, Train Acc: 0.887179 | Val Loss: 0.106080, Val Acc: 0.793814\n",
      "Epoch 22160 - Train Loss: 0.074518, Train Acc: 0.887179 | Val Loss: 0.106080, Val Acc: 0.793814\n",
      "Epoch 22161 - Train Loss: 0.074516, Train Acc: 0.887179 | Val Loss: 0.106079, Val Acc: 0.793814\n",
      "Epoch 22162 - Train Loss: 0.074514, Train Acc: 0.887179 | Val Loss: 0.106078, Val Acc: 0.793814\n",
      "Epoch 22163 - Train Loss: 0.074512, Train Acc: 0.887179 | Val Loss: 0.106078, Val Acc: 0.793814\n",
      "Epoch 22164 - Train Loss: 0.074511, Train Acc: 0.887179 | Val Loss: 0.106077, Val Acc: 0.793814\n",
      "Epoch 22165 - Train Loss: 0.074509, Train Acc: 0.887179 | Val Loss: 0.106077, Val Acc: 0.793814\n",
      "Epoch 22166 - Train Loss: 0.074507, Train Acc: 0.887179 | Val Loss: 0.106076, Val Acc: 0.793814\n",
      "Epoch 22167 - Train Loss: 0.074505, Train Acc: 0.887179 | Val Loss: 0.106076, Val Acc: 0.793814\n",
      "Epoch 22168 - Train Loss: 0.074504, Train Acc: 0.887179 | Val Loss: 0.106075, Val Acc: 0.793814\n",
      "Epoch 22169 - Train Loss: 0.074502, Train Acc: 0.887179 | Val Loss: 0.106075, Val Acc: 0.793814\n",
      "Epoch 22170 - Train Loss: 0.074500, Train Acc: 0.887179 | Val Loss: 0.106074, Val Acc: 0.793814\n",
      "Epoch 22171 - Train Loss: 0.074498, Train Acc: 0.887179 | Val Loss: 0.106074, Val Acc: 0.793814\n",
      "Epoch 22172 - Train Loss: 0.074497, Train Acc: 0.887179 | Val Loss: 0.106073, Val Acc: 0.793814\n",
      "Epoch 22173 - Train Loss: 0.074495, Train Acc: 0.887179 | Val Loss: 0.106073, Val Acc: 0.793814\n",
      "Epoch 22174 - Train Loss: 0.074493, Train Acc: 0.887179 | Val Loss: 0.106072, Val Acc: 0.793814\n",
      "Epoch 22175 - Train Loss: 0.074491, Train Acc: 0.887179 | Val Loss: 0.106071, Val Acc: 0.793814\n",
      "Epoch 22176 - Train Loss: 0.074490, Train Acc: 0.887179 | Val Loss: 0.106071, Val Acc: 0.793814\n",
      "Epoch 22177 - Train Loss: 0.074488, Train Acc: 0.888462 | Val Loss: 0.106070, Val Acc: 0.793814\n",
      "Epoch 22178 - Train Loss: 0.074486, Train Acc: 0.888462 | Val Loss: 0.106070, Val Acc: 0.793814\n",
      "Epoch 22179 - Train Loss: 0.074484, Train Acc: 0.888462 | Val Loss: 0.106069, Val Acc: 0.793814\n",
      "Epoch 22180 - Train Loss: 0.074483, Train Acc: 0.888462 | Val Loss: 0.106069, Val Acc: 0.793814\n",
      "Epoch 22181 - Train Loss: 0.074481, Train Acc: 0.888462 | Val Loss: 0.106068, Val Acc: 0.793814\n",
      "Epoch 22182 - Train Loss: 0.074479, Train Acc: 0.888462 | Val Loss: 0.106068, Val Acc: 0.793814\n",
      "Epoch 22183 - Train Loss: 0.074477, Train Acc: 0.888462 | Val Loss: 0.106067, Val Acc: 0.793814\n",
      "Epoch 22184 - Train Loss: 0.074476, Train Acc: 0.888462 | Val Loss: 0.106067, Val Acc: 0.793814\n",
      "Epoch 22185 - Train Loss: 0.074474, Train Acc: 0.888462 | Val Loss: 0.106066, Val Acc: 0.793814\n",
      "Epoch 22186 - Train Loss: 0.074472, Train Acc: 0.888462 | Val Loss: 0.106065, Val Acc: 0.793814\n",
      "Epoch 22187 - Train Loss: 0.074471, Train Acc: 0.888462 | Val Loss: 0.106065, Val Acc: 0.793814\n",
      "Epoch 22188 - Train Loss: 0.074469, Train Acc: 0.888462 | Val Loss: 0.106064, Val Acc: 0.793814\n",
      "Epoch 22189 - Train Loss: 0.074467, Train Acc: 0.888462 | Val Loss: 0.106064, Val Acc: 0.793814\n",
      "Epoch 22190 - Train Loss: 0.074465, Train Acc: 0.888462 | Val Loss: 0.106063, Val Acc: 0.793814\n",
      "Epoch 22191 - Train Loss: 0.074464, Train Acc: 0.888462 | Val Loss: 0.106063, Val Acc: 0.793814\n",
      "Epoch 22192 - Train Loss: 0.074462, Train Acc: 0.888462 | Val Loss: 0.106062, Val Acc: 0.793814\n",
      "Epoch 22193 - Train Loss: 0.074460, Train Acc: 0.888462 | Val Loss: 0.106062, Val Acc: 0.793814\n",
      "Epoch 22194 - Train Loss: 0.074458, Train Acc: 0.888462 | Val Loss: 0.106061, Val Acc: 0.793814\n",
      "Epoch 22195 - Train Loss: 0.074457, Train Acc: 0.888462 | Val Loss: 0.106061, Val Acc: 0.793814\n",
      "Epoch 22196 - Train Loss: 0.074455, Train Acc: 0.888462 | Val Loss: 0.106060, Val Acc: 0.793814\n",
      "Epoch 22197 - Train Loss: 0.074453, Train Acc: 0.888462 | Val Loss: 0.106060, Val Acc: 0.793814\n",
      "Epoch 22198 - Train Loss: 0.074451, Train Acc: 0.888462 | Val Loss: 0.106059, Val Acc: 0.793814\n",
      "Epoch 22199 - Train Loss: 0.074450, Train Acc: 0.888462 | Val Loss: 0.106059, Val Acc: 0.793814\n",
      "Epoch 22200 - Train Loss: 0.074448, Train Acc: 0.888462 | Val Loss: 0.106058, Val Acc: 0.793814\n",
      "Epoch 22201 - Train Loss: 0.074446, Train Acc: 0.888462 | Val Loss: 0.106058, Val Acc: 0.793814\n",
      "Epoch 22202 - Train Loss: 0.074444, Train Acc: 0.888462 | Val Loss: 0.106057, Val Acc: 0.793814\n",
      "Epoch 22203 - Train Loss: 0.074443, Train Acc: 0.888462 | Val Loss: 0.106056, Val Acc: 0.793814\n",
      "Epoch 22204 - Train Loss: 0.074441, Train Acc: 0.888462 | Val Loss: 0.106056, Val Acc: 0.793814\n",
      "Epoch 22205 - Train Loss: 0.074439, Train Acc: 0.888462 | Val Loss: 0.106055, Val Acc: 0.793814\n",
      "Epoch 22206 - Train Loss: 0.074438, Train Acc: 0.888462 | Val Loss: 0.106055, Val Acc: 0.793814\n",
      "Epoch 22207 - Train Loss: 0.074436, Train Acc: 0.888462 | Val Loss: 0.106054, Val Acc: 0.793814\n",
      "Epoch 22208 - Train Loss: 0.074434, Train Acc: 0.888462 | Val Loss: 0.106054, Val Acc: 0.793814\n",
      "Epoch 22209 - Train Loss: 0.074432, Train Acc: 0.888462 | Val Loss: 0.106053, Val Acc: 0.793814\n",
      "Epoch 22210 - Train Loss: 0.074431, Train Acc: 0.888462 | Val Loss: 0.106053, Val Acc: 0.793814\n",
      "Epoch 22211 - Train Loss: 0.074429, Train Acc: 0.888462 | Val Loss: 0.106052, Val Acc: 0.793814\n",
      "Epoch 22212 - Train Loss: 0.074427, Train Acc: 0.888462 | Val Loss: 0.106052, Val Acc: 0.793814\n",
      "Epoch 22213 - Train Loss: 0.074425, Train Acc: 0.888462 | Val Loss: 0.106051, Val Acc: 0.793814\n",
      "Epoch 22214 - Train Loss: 0.074424, Train Acc: 0.888462 | Val Loss: 0.106051, Val Acc: 0.793814\n",
      "Epoch 22215 - Train Loss: 0.074422, Train Acc: 0.888462 | Val Loss: 0.106050, Val Acc: 0.793814\n",
      "Epoch 22216 - Train Loss: 0.074420, Train Acc: 0.888462 | Val Loss: 0.106050, Val Acc: 0.793814\n",
      "Epoch 22217 - Train Loss: 0.074418, Train Acc: 0.888462 | Val Loss: 0.106049, Val Acc: 0.793814\n",
      "Epoch 22218 - Train Loss: 0.074417, Train Acc: 0.888462 | Val Loss: 0.106049, Val Acc: 0.793814\n",
      "Epoch 22219 - Train Loss: 0.074415, Train Acc: 0.888462 | Val Loss: 0.106048, Val Acc: 0.793814\n",
      "Epoch 22220 - Train Loss: 0.074413, Train Acc: 0.888462 | Val Loss: 0.106048, Val Acc: 0.793814\n",
      "Epoch 22221 - Train Loss: 0.074412, Train Acc: 0.888462 | Val Loss: 0.106047, Val Acc: 0.793814\n",
      "Epoch 22222 - Train Loss: 0.074410, Train Acc: 0.888462 | Val Loss: 0.106046, Val Acc: 0.793814\n",
      "Epoch 22223 - Train Loss: 0.074408, Train Acc: 0.888462 | Val Loss: 0.106046, Val Acc: 0.793814\n",
      "Epoch 22224 - Train Loss: 0.074406, Train Acc: 0.888462 | Val Loss: 0.106045, Val Acc: 0.793814\n",
      "Epoch 22225 - Train Loss: 0.074405, Train Acc: 0.888462 | Val Loss: 0.106045, Val Acc: 0.793814\n",
      "Epoch 22226 - Train Loss: 0.074403, Train Acc: 0.888462 | Val Loss: 0.106044, Val Acc: 0.793814\n",
      "Epoch 22227 - Train Loss: 0.074401, Train Acc: 0.888462 | Val Loss: 0.106044, Val Acc: 0.793814\n",
      "Epoch 22228 - Train Loss: 0.074399, Train Acc: 0.888462 | Val Loss: 0.106043, Val Acc: 0.793814\n",
      "Epoch 22229 - Train Loss: 0.074398, Train Acc: 0.888462 | Val Loss: 0.106043, Val Acc: 0.793814\n",
      "Epoch 22230 - Train Loss: 0.074396, Train Acc: 0.888462 | Val Loss: 0.106042, Val Acc: 0.793814\n",
      "Epoch 22231 - Train Loss: 0.074394, Train Acc: 0.888462 | Val Loss: 0.106042, Val Acc: 0.793814\n",
      "Epoch 22232 - Train Loss: 0.074392, Train Acc: 0.888462 | Val Loss: 0.106041, Val Acc: 0.793814\n",
      "Epoch 22233 - Train Loss: 0.074391, Train Acc: 0.888462 | Val Loss: 0.106041, Val Acc: 0.793814\n",
      "Epoch 22234 - Train Loss: 0.074389, Train Acc: 0.888462 | Val Loss: 0.106040, Val Acc: 0.793814\n",
      "Epoch 22235 - Train Loss: 0.074387, Train Acc: 0.888462 | Val Loss: 0.106040, Val Acc: 0.793814\n",
      "Epoch 22236 - Train Loss: 0.074386, Train Acc: 0.888462 | Val Loss: 0.106039, Val Acc: 0.793814\n",
      "Epoch 22237 - Train Loss: 0.074384, Train Acc: 0.888462 | Val Loss: 0.106038, Val Acc: 0.793814\n",
      "Epoch 22238 - Train Loss: 0.074382, Train Acc: 0.888462 | Val Loss: 0.106038, Val Acc: 0.793814\n",
      "Epoch 22239 - Train Loss: 0.074380, Train Acc: 0.888462 | Val Loss: 0.106037, Val Acc: 0.793814\n",
      "Epoch 22240 - Train Loss: 0.074379, Train Acc: 0.888462 | Val Loss: 0.106037, Val Acc: 0.793814\n",
      "Epoch 22241 - Train Loss: 0.074377, Train Acc: 0.888462 | Val Loss: 0.106036, Val Acc: 0.793814\n",
      "Epoch 22242 - Train Loss: 0.074375, Train Acc: 0.888462 | Val Loss: 0.106036, Val Acc: 0.793814\n",
      "Epoch 22243 - Train Loss: 0.074373, Train Acc: 0.888462 | Val Loss: 0.106035, Val Acc: 0.793814\n",
      "Epoch 22244 - Train Loss: 0.074372, Train Acc: 0.888462 | Val Loss: 0.106035, Val Acc: 0.793814\n",
      "Epoch 22245 - Train Loss: 0.074370, Train Acc: 0.888462 | Val Loss: 0.106034, Val Acc: 0.793814\n",
      "Epoch 22246 - Train Loss: 0.074368, Train Acc: 0.888462 | Val Loss: 0.106034, Val Acc: 0.793814\n",
      "Epoch 22247 - Train Loss: 0.074366, Train Acc: 0.888462 | Val Loss: 0.106033, Val Acc: 0.793814\n",
      "Epoch 22248 - Train Loss: 0.074365, Train Acc: 0.888462 | Val Loss: 0.106033, Val Acc: 0.793814\n",
      "Epoch 22249 - Train Loss: 0.074363, Train Acc: 0.888462 | Val Loss: 0.106032, Val Acc: 0.793814\n",
      "Epoch 22250 - Train Loss: 0.074361, Train Acc: 0.888462 | Val Loss: 0.106032, Val Acc: 0.793814\n",
      "Epoch 22251 - Train Loss: 0.074360, Train Acc: 0.888462 | Val Loss: 0.106031, Val Acc: 0.793814\n",
      "Epoch 22252 - Train Loss: 0.074358, Train Acc: 0.888462 | Val Loss: 0.106031, Val Acc: 0.793814\n",
      "Epoch 22253 - Train Loss: 0.074356, Train Acc: 0.888462 | Val Loss: 0.106030, Val Acc: 0.793814\n",
      "Epoch 22254 - Train Loss: 0.074354, Train Acc: 0.888462 | Val Loss: 0.106030, Val Acc: 0.793814\n",
      "Epoch 22255 - Train Loss: 0.074353, Train Acc: 0.888462 | Val Loss: 0.106029, Val Acc: 0.793814\n",
      "Epoch 22256 - Train Loss: 0.074351, Train Acc: 0.888462 | Val Loss: 0.106029, Val Acc: 0.793814\n",
      "Epoch 22257 - Train Loss: 0.074349, Train Acc: 0.888462 | Val Loss: 0.106028, Val Acc: 0.793814\n",
      "Epoch 22258 - Train Loss: 0.074347, Train Acc: 0.888462 | Val Loss: 0.106027, Val Acc: 0.793814\n",
      "Epoch 22259 - Train Loss: 0.074346, Train Acc: 0.888462 | Val Loss: 0.106027, Val Acc: 0.793814\n",
      "Epoch 22260 - Train Loss: 0.074344, Train Acc: 0.888462 | Val Loss: 0.106026, Val Acc: 0.793814\n",
      "Epoch 22261 - Train Loss: 0.074342, Train Acc: 0.888462 | Val Loss: 0.106026, Val Acc: 0.793814\n",
      "Epoch 22262 - Train Loss: 0.074341, Train Acc: 0.888462 | Val Loss: 0.106025, Val Acc: 0.793814\n",
      "Epoch 22263 - Train Loss: 0.074339, Train Acc: 0.888462 | Val Loss: 0.106025, Val Acc: 0.793814\n",
      "Epoch 22264 - Train Loss: 0.074337, Train Acc: 0.888462 | Val Loss: 0.106024, Val Acc: 0.793814\n",
      "Epoch 22265 - Train Loss: 0.074335, Train Acc: 0.888462 | Val Loss: 0.106024, Val Acc: 0.793814\n",
      "Epoch 22266 - Train Loss: 0.074334, Train Acc: 0.888462 | Val Loss: 0.106023, Val Acc: 0.793814\n",
      "Epoch 22267 - Train Loss: 0.074332, Train Acc: 0.888462 | Val Loss: 0.106023, Val Acc: 0.793814\n",
      "Epoch 22268 - Train Loss: 0.074330, Train Acc: 0.888462 | Val Loss: 0.106022, Val Acc: 0.793814\n",
      "Epoch 22269 - Train Loss: 0.074328, Train Acc: 0.888462 | Val Loss: 0.106022, Val Acc: 0.793814\n",
      "Epoch 22270 - Train Loss: 0.074327, Train Acc: 0.888462 | Val Loss: 0.106021, Val Acc: 0.793814\n",
      "Epoch 22271 - Train Loss: 0.074325, Train Acc: 0.888462 | Val Loss: 0.106021, Val Acc: 0.793814\n",
      "Epoch 22272 - Train Loss: 0.074323, Train Acc: 0.888462 | Val Loss: 0.106020, Val Acc: 0.793814\n",
      "Epoch 22273 - Train Loss: 0.074322, Train Acc: 0.888462 | Val Loss: 0.106020, Val Acc: 0.793814\n",
      "Epoch 22274 - Train Loss: 0.074320, Train Acc: 0.888462 | Val Loss: 0.106019, Val Acc: 0.793814\n",
      "Epoch 22275 - Train Loss: 0.074318, Train Acc: 0.888462 | Val Loss: 0.106019, Val Acc: 0.793814\n",
      "Epoch 22276 - Train Loss: 0.074316, Train Acc: 0.888462 | Val Loss: 0.106018, Val Acc: 0.793814\n",
      "Epoch 22277 - Train Loss: 0.074315, Train Acc: 0.888462 | Val Loss: 0.106018, Val Acc: 0.793814\n",
      "Epoch 22278 - Train Loss: 0.074313, Train Acc: 0.888462 | Val Loss: 0.106017, Val Acc: 0.793814\n",
      "Epoch 22279 - Train Loss: 0.074311, Train Acc: 0.888462 | Val Loss: 0.106017, Val Acc: 0.793814\n",
      "Epoch 22280 - Train Loss: 0.074310, Train Acc: 0.888462 | Val Loss: 0.106016, Val Acc: 0.793814\n",
      "Epoch 22281 - Train Loss: 0.074308, Train Acc: 0.888462 | Val Loss: 0.106015, Val Acc: 0.793814\n",
      "Epoch 22282 - Train Loss: 0.074306, Train Acc: 0.888462 | Val Loss: 0.106015, Val Acc: 0.793814\n",
      "Epoch 22283 - Train Loss: 0.074304, Train Acc: 0.888462 | Val Loss: 0.106014, Val Acc: 0.793814\n",
      "Epoch 22284 - Train Loss: 0.074303, Train Acc: 0.888462 | Val Loss: 0.106014, Val Acc: 0.793814\n",
      "Epoch 22285 - Train Loss: 0.074301, Train Acc: 0.888462 | Val Loss: 0.106013, Val Acc: 0.793814\n",
      "Epoch 22286 - Train Loss: 0.074299, Train Acc: 0.888462 | Val Loss: 0.106013, Val Acc: 0.793814\n",
      "Epoch 22287 - Train Loss: 0.074297, Train Acc: 0.888462 | Val Loss: 0.106012, Val Acc: 0.793814\n",
      "Epoch 22288 - Train Loss: 0.074296, Train Acc: 0.888462 | Val Loss: 0.106012, Val Acc: 0.793814\n",
      "Epoch 22289 - Train Loss: 0.074294, Train Acc: 0.888462 | Val Loss: 0.106011, Val Acc: 0.793814\n",
      "Epoch 22290 - Train Loss: 0.074292, Train Acc: 0.888462 | Val Loss: 0.106011, Val Acc: 0.793814\n",
      "Epoch 22291 - Train Loss: 0.074291, Train Acc: 0.888462 | Val Loss: 0.106010, Val Acc: 0.793814\n",
      "Epoch 22292 - Train Loss: 0.074289, Train Acc: 0.888462 | Val Loss: 0.106010, Val Acc: 0.793814\n",
      "Epoch 22293 - Train Loss: 0.074287, Train Acc: 0.888462 | Val Loss: 0.106009, Val Acc: 0.793814\n",
      "Epoch 22294 - Train Loss: 0.074285, Train Acc: 0.888462 | Val Loss: 0.106009, Val Acc: 0.793814\n",
      "Epoch 22295 - Train Loss: 0.074284, Train Acc: 0.888462 | Val Loss: 0.106008, Val Acc: 0.793814\n",
      "Epoch 22296 - Train Loss: 0.074282, Train Acc: 0.888462 | Val Loss: 0.106008, Val Acc: 0.793814\n",
      "Epoch 22297 - Train Loss: 0.074280, Train Acc: 0.888462 | Val Loss: 0.106007, Val Acc: 0.793814\n",
      "Epoch 22298 - Train Loss: 0.074278, Train Acc: 0.888462 | Val Loss: 0.106007, Val Acc: 0.793814\n",
      "Epoch 22299 - Train Loss: 0.074277, Train Acc: 0.888462 | Val Loss: 0.106006, Val Acc: 0.793814\n",
      "Epoch 22300 - Train Loss: 0.074275, Train Acc: 0.888462 | Val Loss: 0.106006, Val Acc: 0.793814\n",
      "Epoch 22301 - Train Loss: 0.074273, Train Acc: 0.888462 | Val Loss: 0.106005, Val Acc: 0.793814\n",
      "Epoch 22302 - Train Loss: 0.074272, Train Acc: 0.888462 | Val Loss: 0.106005, Val Acc: 0.793814\n",
      "Epoch 22303 - Train Loss: 0.074270, Train Acc: 0.888462 | Val Loss: 0.106004, Val Acc: 0.793814\n",
      "Epoch 22304 - Train Loss: 0.074268, Train Acc: 0.888462 | Val Loss: 0.106004, Val Acc: 0.793814\n",
      "Epoch 22305 - Train Loss: 0.074266, Train Acc: 0.888462 | Val Loss: 0.106003, Val Acc: 0.793814\n",
      "Epoch 22306 - Train Loss: 0.074265, Train Acc: 0.888462 | Val Loss: 0.106003, Val Acc: 0.793814\n",
      "Epoch 22307 - Train Loss: 0.074263, Train Acc: 0.888462 | Val Loss: 0.106002, Val Acc: 0.793814\n",
      "Epoch 22308 - Train Loss: 0.074261, Train Acc: 0.888462 | Val Loss: 0.106001, Val Acc: 0.793814\n",
      "Epoch 22309 - Train Loss: 0.074260, Train Acc: 0.888462 | Val Loss: 0.106001, Val Acc: 0.793814\n",
      "Epoch 22310 - Train Loss: 0.074258, Train Acc: 0.888462 | Val Loss: 0.106001, Val Acc: 0.793814\n",
      "Epoch 22311 - Train Loss: 0.074256, Train Acc: 0.888462 | Val Loss: 0.106000, Val Acc: 0.793814\n",
      "Epoch 22312 - Train Loss: 0.074254, Train Acc: 0.888462 | Val Loss: 0.105999, Val Acc: 0.793814\n",
      "Epoch 22313 - Train Loss: 0.074253, Train Acc: 0.888462 | Val Loss: 0.105999, Val Acc: 0.793814\n",
      "Epoch 22314 - Train Loss: 0.074251, Train Acc: 0.888462 | Val Loss: 0.105998, Val Acc: 0.793814\n",
      "Epoch 22315 - Train Loss: 0.074249, Train Acc: 0.888462 | Val Loss: 0.105998, Val Acc: 0.793814\n",
      "Epoch 22316 - Train Loss: 0.074248, Train Acc: 0.888462 | Val Loss: 0.105997, Val Acc: 0.793814\n",
      "Epoch 22317 - Train Loss: 0.074246, Train Acc: 0.888462 | Val Loss: 0.105997, Val Acc: 0.793814\n",
      "Epoch 22318 - Train Loss: 0.074244, Train Acc: 0.888462 | Val Loss: 0.105996, Val Acc: 0.793814\n",
      "Epoch 22319 - Train Loss: 0.074242, Train Acc: 0.888462 | Val Loss: 0.105996, Val Acc: 0.793814\n",
      "Epoch 22320 - Train Loss: 0.074241, Train Acc: 0.888462 | Val Loss: 0.105995, Val Acc: 0.793814\n",
      "Epoch 22321 - Train Loss: 0.074239, Train Acc: 0.888462 | Val Loss: 0.105995, Val Acc: 0.793814\n",
      "Epoch 22322 - Train Loss: 0.074237, Train Acc: 0.888462 | Val Loss: 0.105994, Val Acc: 0.793814\n",
      "Epoch 22323 - Train Loss: 0.074235, Train Acc: 0.888462 | Val Loss: 0.105994, Val Acc: 0.793814\n",
      "Epoch 22324 - Train Loss: 0.074234, Train Acc: 0.888462 | Val Loss: 0.105993, Val Acc: 0.793814\n",
      "Epoch 22325 - Train Loss: 0.074232, Train Acc: 0.888462 | Val Loss: 0.105993, Val Acc: 0.793814\n",
      "Epoch 22326 - Train Loss: 0.074230, Train Acc: 0.888462 | Val Loss: 0.105992, Val Acc: 0.793814\n",
      "Epoch 22327 - Train Loss: 0.074229, Train Acc: 0.888462 | Val Loss: 0.105992, Val Acc: 0.793814\n",
      "Epoch 22328 - Train Loss: 0.074227, Train Acc: 0.888462 | Val Loss: 0.105991, Val Acc: 0.793814\n",
      "Epoch 22329 - Train Loss: 0.074225, Train Acc: 0.888462 | Val Loss: 0.105991, Val Acc: 0.793814\n",
      "Epoch 22330 - Train Loss: 0.074223, Train Acc: 0.888462 | Val Loss: 0.105990, Val Acc: 0.793814\n",
      "Epoch 22331 - Train Loss: 0.074222, Train Acc: 0.888462 | Val Loss: 0.105990, Val Acc: 0.793814\n",
      "Epoch 22332 - Train Loss: 0.074220, Train Acc: 0.888462 | Val Loss: 0.105989, Val Acc: 0.793814\n",
      "Epoch 22333 - Train Loss: 0.074218, Train Acc: 0.888462 | Val Loss: 0.105989, Val Acc: 0.793814\n",
      "Epoch 22334 - Train Loss: 0.074217, Train Acc: 0.888462 | Val Loss: 0.105988, Val Acc: 0.793814\n",
      "Epoch 22335 - Train Loss: 0.074215, Train Acc: 0.888462 | Val Loss: 0.105988, Val Acc: 0.793814\n",
      "Epoch 22336 - Train Loss: 0.074213, Train Acc: 0.888462 | Val Loss: 0.105987, Val Acc: 0.793814\n",
      "Epoch 22337 - Train Loss: 0.074211, Train Acc: 0.888462 | Val Loss: 0.105987, Val Acc: 0.793814\n",
      "Epoch 22338 - Train Loss: 0.074210, Train Acc: 0.888462 | Val Loss: 0.105986, Val Acc: 0.793814\n",
      "Epoch 22339 - Train Loss: 0.074208, Train Acc: 0.888462 | Val Loss: 0.105986, Val Acc: 0.793814\n",
      "Epoch 22340 - Train Loss: 0.074206, Train Acc: 0.888462 | Val Loss: 0.105985, Val Acc: 0.793814\n",
      "Epoch 22341 - Train Loss: 0.074205, Train Acc: 0.888462 | Val Loss: 0.105984, Val Acc: 0.793814\n",
      "Epoch 22342 - Train Loss: 0.074203, Train Acc: 0.888462 | Val Loss: 0.105984, Val Acc: 0.793814\n",
      "Epoch 22343 - Train Loss: 0.074201, Train Acc: 0.888462 | Val Loss: 0.105983, Val Acc: 0.793814\n",
      "Epoch 22344 - Train Loss: 0.074199, Train Acc: 0.888462 | Val Loss: 0.105983, Val Acc: 0.793814\n",
      "Epoch 22345 - Train Loss: 0.074198, Train Acc: 0.888462 | Val Loss: 0.105982, Val Acc: 0.793814\n",
      "Epoch 22346 - Train Loss: 0.074196, Train Acc: 0.888462 | Val Loss: 0.105982, Val Acc: 0.793814\n",
      "Epoch 22347 - Train Loss: 0.074194, Train Acc: 0.888462 | Val Loss: 0.105981, Val Acc: 0.793814\n",
      "Epoch 22348 - Train Loss: 0.074193, Train Acc: 0.888462 | Val Loss: 0.105981, Val Acc: 0.793814\n",
      "Epoch 22349 - Train Loss: 0.074191, Train Acc: 0.888462 | Val Loss: 0.105980, Val Acc: 0.793814\n",
      "Epoch 22350 - Train Loss: 0.074189, Train Acc: 0.888462 | Val Loss: 0.105980, Val Acc: 0.793814\n",
      "Epoch 22351 - Train Loss: 0.074187, Train Acc: 0.888462 | Val Loss: 0.105979, Val Acc: 0.793814\n",
      "Epoch 22352 - Train Loss: 0.074186, Train Acc: 0.888462 | Val Loss: 0.105979, Val Acc: 0.793814\n",
      "Epoch 22353 - Train Loss: 0.074184, Train Acc: 0.888462 | Val Loss: 0.105978, Val Acc: 0.793814\n",
      "Epoch 22354 - Train Loss: 0.074182, Train Acc: 0.888462 | Val Loss: 0.105978, Val Acc: 0.793814\n",
      "Epoch 22355 - Train Loss: 0.074181, Train Acc: 0.888462 | Val Loss: 0.105977, Val Acc: 0.793814\n",
      "Epoch 22356 - Train Loss: 0.074179, Train Acc: 0.888462 | Val Loss: 0.105977, Val Acc: 0.793814\n",
      "Epoch 22357 - Train Loss: 0.074177, Train Acc: 0.888462 | Val Loss: 0.105976, Val Acc: 0.793814\n",
      "Epoch 22358 - Train Loss: 0.074175, Train Acc: 0.888462 | Val Loss: 0.105976, Val Acc: 0.793814\n",
      "Epoch 22359 - Train Loss: 0.074174, Train Acc: 0.888462 | Val Loss: 0.105975, Val Acc: 0.793814\n",
      "Epoch 22360 - Train Loss: 0.074172, Train Acc: 0.888462 | Val Loss: 0.105975, Val Acc: 0.793814\n",
      "Epoch 22361 - Train Loss: 0.074170, Train Acc: 0.888462 | Val Loss: 0.105974, Val Acc: 0.793814\n",
      "Epoch 22362 - Train Loss: 0.074169, Train Acc: 0.888462 | Val Loss: 0.105974, Val Acc: 0.793814\n",
      "Epoch 22363 - Train Loss: 0.074167, Train Acc: 0.888462 | Val Loss: 0.105973, Val Acc: 0.793814\n",
      "Epoch 22364 - Train Loss: 0.074165, Train Acc: 0.888462 | Val Loss: 0.105973, Val Acc: 0.793814\n",
      "Epoch 22365 - Train Loss: 0.074163, Train Acc: 0.888462 | Val Loss: 0.105972, Val Acc: 0.793814\n",
      "Epoch 22366 - Train Loss: 0.074162, Train Acc: 0.888462 | Val Loss: 0.105972, Val Acc: 0.793814\n",
      "Epoch 22367 - Train Loss: 0.074160, Train Acc: 0.888462 | Val Loss: 0.105971, Val Acc: 0.793814\n",
      "Epoch 22368 - Train Loss: 0.074158, Train Acc: 0.888462 | Val Loss: 0.105971, Val Acc: 0.793814\n",
      "Epoch 22369 - Train Loss: 0.074157, Train Acc: 0.888462 | Val Loss: 0.105970, Val Acc: 0.793814\n",
      "Epoch 22370 - Train Loss: 0.074155, Train Acc: 0.888462 | Val Loss: 0.105970, Val Acc: 0.793814\n",
      "Epoch 22371 - Train Loss: 0.074153, Train Acc: 0.888462 | Val Loss: 0.105969, Val Acc: 0.793814\n",
      "Epoch 22372 - Train Loss: 0.074151, Train Acc: 0.888462 | Val Loss: 0.105969, Val Acc: 0.793814\n",
      "Epoch 22373 - Train Loss: 0.074150, Train Acc: 0.888462 | Val Loss: 0.105968, Val Acc: 0.793814\n",
      "Epoch 22374 - Train Loss: 0.074148, Train Acc: 0.888462 | Val Loss: 0.105968, Val Acc: 0.793814\n",
      "Epoch 22375 - Train Loss: 0.074146, Train Acc: 0.888462 | Val Loss: 0.105967, Val Acc: 0.793814\n",
      "Epoch 22376 - Train Loss: 0.074145, Train Acc: 0.888462 | Val Loss: 0.105967, Val Acc: 0.793814\n",
      "Epoch 22377 - Train Loss: 0.074143, Train Acc: 0.888462 | Val Loss: 0.105966, Val Acc: 0.793814\n",
      "Epoch 22378 - Train Loss: 0.074141, Train Acc: 0.888462 | Val Loss: 0.105966, Val Acc: 0.793814\n",
      "Epoch 22379 - Train Loss: 0.074139, Train Acc: 0.888462 | Val Loss: 0.105965, Val Acc: 0.793814\n",
      "Epoch 22380 - Train Loss: 0.074138, Train Acc: 0.888462 | Val Loss: 0.105965, Val Acc: 0.793814\n",
      "Epoch 22381 - Train Loss: 0.074136, Train Acc: 0.888462 | Val Loss: 0.105964, Val Acc: 0.793814\n",
      "Epoch 22382 - Train Loss: 0.074134, Train Acc: 0.888462 | Val Loss: 0.105964, Val Acc: 0.793814\n",
      "Epoch 22383 - Train Loss: 0.074133, Train Acc: 0.888462 | Val Loss: 0.105963, Val Acc: 0.793814\n",
      "Epoch 22384 - Train Loss: 0.074131, Train Acc: 0.888462 | Val Loss: 0.105963, Val Acc: 0.793814\n",
      "Epoch 22385 - Train Loss: 0.074129, Train Acc: 0.888462 | Val Loss: 0.105962, Val Acc: 0.793814\n",
      "Epoch 22386 - Train Loss: 0.074128, Train Acc: 0.888462 | Val Loss: 0.105962, Val Acc: 0.793814\n",
      "Epoch 22387 - Train Loss: 0.074126, Train Acc: 0.888462 | Val Loss: 0.105961, Val Acc: 0.793814\n",
      "Epoch 22388 - Train Loss: 0.074124, Train Acc: 0.888462 | Val Loss: 0.105961, Val Acc: 0.793814\n",
      "Epoch 22389 - Train Loss: 0.074122, Train Acc: 0.888462 | Val Loss: 0.105960, Val Acc: 0.793814\n",
      "Epoch 22390 - Train Loss: 0.074121, Train Acc: 0.888462 | Val Loss: 0.105960, Val Acc: 0.793814\n",
      "Epoch 22391 - Train Loss: 0.074119, Train Acc: 0.888462 | Val Loss: 0.105959, Val Acc: 0.793814\n",
      "Epoch 22392 - Train Loss: 0.074117, Train Acc: 0.888462 | Val Loss: 0.105959, Val Acc: 0.793814\n",
      "Epoch 22393 - Train Loss: 0.074116, Train Acc: 0.888462 | Val Loss: 0.105958, Val Acc: 0.793814\n",
      "Epoch 22394 - Train Loss: 0.074114, Train Acc: 0.888462 | Val Loss: 0.105958, Val Acc: 0.793814\n",
      "Epoch 22395 - Train Loss: 0.074112, Train Acc: 0.888462 | Val Loss: 0.105957, Val Acc: 0.793814\n",
      "Epoch 22396 - Train Loss: 0.074110, Train Acc: 0.888462 | Val Loss: 0.105957, Val Acc: 0.793814\n",
      "Epoch 22397 - Train Loss: 0.074109, Train Acc: 0.888462 | Val Loss: 0.105956, Val Acc: 0.793814\n",
      "Epoch 22398 - Train Loss: 0.074107, Train Acc: 0.888462 | Val Loss: 0.105956, Val Acc: 0.793814\n",
      "Epoch 22399 - Train Loss: 0.074105, Train Acc: 0.888462 | Val Loss: 0.105955, Val Acc: 0.793814\n",
      "Epoch 22400 - Train Loss: 0.074104, Train Acc: 0.888462 | Val Loss: 0.105955, Val Acc: 0.793814\n",
      "Epoch 22401 - Train Loss: 0.074102, Train Acc: 0.888462 | Val Loss: 0.105954, Val Acc: 0.793814\n",
      "Epoch 22402 - Train Loss: 0.074100, Train Acc: 0.888462 | Val Loss: 0.105954, Val Acc: 0.793814\n",
      "Epoch 22403 - Train Loss: 0.074099, Train Acc: 0.888462 | Val Loss: 0.105953, Val Acc: 0.793814\n",
      "Epoch 22404 - Train Loss: 0.074097, Train Acc: 0.888462 | Val Loss: 0.105953, Val Acc: 0.793814\n",
      "Epoch 22405 - Train Loss: 0.074095, Train Acc: 0.888462 | Val Loss: 0.105952, Val Acc: 0.793814\n",
      "Epoch 22406 - Train Loss: 0.074093, Train Acc: 0.888462 | Val Loss: 0.105952, Val Acc: 0.793814\n",
      "Epoch 22407 - Train Loss: 0.074092, Train Acc: 0.888462 | Val Loss: 0.105951, Val Acc: 0.793814\n",
      "Epoch 22408 - Train Loss: 0.074090, Train Acc: 0.888462 | Val Loss: 0.105951, Val Acc: 0.793814\n",
      "Epoch 22409 - Train Loss: 0.074088, Train Acc: 0.888462 | Val Loss: 0.105950, Val Acc: 0.793814\n",
      "Epoch 22410 - Train Loss: 0.074087, Train Acc: 0.888462 | Val Loss: 0.105949, Val Acc: 0.793814\n",
      "Epoch 22411 - Train Loss: 0.074085, Train Acc: 0.888462 | Val Loss: 0.105949, Val Acc: 0.793814\n",
      "Epoch 22412 - Train Loss: 0.074083, Train Acc: 0.888462 | Val Loss: 0.105949, Val Acc: 0.793814\n",
      "Epoch 22413 - Train Loss: 0.074081, Train Acc: 0.888462 | Val Loss: 0.105948, Val Acc: 0.793814\n",
      "Epoch 22414 - Train Loss: 0.074080, Train Acc: 0.888462 | Val Loss: 0.105947, Val Acc: 0.793814\n",
      "Epoch 22415 - Train Loss: 0.074078, Train Acc: 0.888462 | Val Loss: 0.105947, Val Acc: 0.793814\n",
      "Epoch 22416 - Train Loss: 0.074076, Train Acc: 0.888462 | Val Loss: 0.105947, Val Acc: 0.793814\n",
      "Epoch 22417 - Train Loss: 0.074075, Train Acc: 0.888462 | Val Loss: 0.105946, Val Acc: 0.793814\n",
      "Epoch 22418 - Train Loss: 0.074073, Train Acc: 0.888462 | Val Loss: 0.105945, Val Acc: 0.793814\n",
      "Epoch 22419 - Train Loss: 0.074071, Train Acc: 0.888462 | Val Loss: 0.105945, Val Acc: 0.793814\n",
      "Epoch 22420 - Train Loss: 0.074070, Train Acc: 0.888462 | Val Loss: 0.105945, Val Acc: 0.793814\n",
      "Epoch 22421 - Train Loss: 0.074068, Train Acc: 0.888462 | Val Loss: 0.105944, Val Acc: 0.793814\n",
      "Epoch 22422 - Train Loss: 0.074066, Train Acc: 0.888462 | Val Loss: 0.105943, Val Acc: 0.793814\n",
      "Epoch 22423 - Train Loss: 0.074064, Train Acc: 0.888462 | Val Loss: 0.105943, Val Acc: 0.793814\n",
      "Epoch 22424 - Train Loss: 0.074063, Train Acc: 0.888462 | Val Loss: 0.105943, Val Acc: 0.793814\n",
      "Epoch 22425 - Train Loss: 0.074061, Train Acc: 0.888462 | Val Loss: 0.105942, Val Acc: 0.793814\n",
      "Epoch 22426 - Train Loss: 0.074059, Train Acc: 0.888462 | Val Loss: 0.105941, Val Acc: 0.793814\n",
      "Epoch 22427 - Train Loss: 0.074058, Train Acc: 0.888462 | Val Loss: 0.105941, Val Acc: 0.793814\n",
      "Epoch 22428 - Train Loss: 0.074056, Train Acc: 0.888462 | Val Loss: 0.105940, Val Acc: 0.793814\n",
      "Epoch 22429 - Train Loss: 0.074054, Train Acc: 0.888462 | Val Loss: 0.105940, Val Acc: 0.793814\n",
      "Epoch 22430 - Train Loss: 0.074052, Train Acc: 0.888462 | Val Loss: 0.105940, Val Acc: 0.793814\n",
      "Epoch 22431 - Train Loss: 0.074051, Train Acc: 0.888462 | Val Loss: 0.105939, Val Acc: 0.793814\n",
      "Epoch 22432 - Train Loss: 0.074049, Train Acc: 0.888462 | Val Loss: 0.105939, Val Acc: 0.793814\n",
      "Epoch 22433 - Train Loss: 0.074047, Train Acc: 0.888462 | Val Loss: 0.105938, Val Acc: 0.793814\n",
      "Epoch 22434 - Train Loss: 0.074046, Train Acc: 0.888462 | Val Loss: 0.105938, Val Acc: 0.793814\n",
      "Epoch 22435 - Train Loss: 0.074044, Train Acc: 0.888462 | Val Loss: 0.105937, Val Acc: 0.793814\n",
      "Epoch 22436 - Train Loss: 0.074042, Train Acc: 0.888462 | Val Loss: 0.105936, Val Acc: 0.793814\n",
      "Epoch 22437 - Train Loss: 0.074041, Train Acc: 0.888462 | Val Loss: 0.105936, Val Acc: 0.793814\n",
      "Epoch 22438 - Train Loss: 0.074039, Train Acc: 0.888462 | Val Loss: 0.105935, Val Acc: 0.793814\n",
      "Epoch 22439 - Train Loss: 0.074037, Train Acc: 0.888462 | Val Loss: 0.105935, Val Acc: 0.793814\n",
      "Epoch 22440 - Train Loss: 0.074035, Train Acc: 0.888462 | Val Loss: 0.105934, Val Acc: 0.793814\n",
      "Epoch 22441 - Train Loss: 0.074034, Train Acc: 0.888462 | Val Loss: 0.105934, Val Acc: 0.793814\n",
      "Epoch 22442 - Train Loss: 0.074032, Train Acc: 0.888462 | Val Loss: 0.105934, Val Acc: 0.793814\n",
      "Epoch 22443 - Train Loss: 0.074030, Train Acc: 0.888462 | Val Loss: 0.105933, Val Acc: 0.793814\n",
      "Epoch 22444 - Train Loss: 0.074029, Train Acc: 0.888462 | Val Loss: 0.105933, Val Acc: 0.793814\n",
      "Epoch 22445 - Train Loss: 0.074027, Train Acc: 0.888462 | Val Loss: 0.105932, Val Acc: 0.793814\n",
      "Epoch 22446 - Train Loss: 0.074025, Train Acc: 0.888462 | Val Loss: 0.105932, Val Acc: 0.793814\n",
      "Epoch 22447 - Train Loss: 0.074024, Train Acc: 0.888462 | Val Loss: 0.105931, Val Acc: 0.793814\n",
      "Epoch 22448 - Train Loss: 0.074022, Train Acc: 0.888462 | Val Loss: 0.105931, Val Acc: 0.793814\n",
      "Epoch 22449 - Train Loss: 0.074020, Train Acc: 0.888462 | Val Loss: 0.105930, Val Acc: 0.793814\n",
      "Epoch 22450 - Train Loss: 0.074018, Train Acc: 0.888462 | Val Loss: 0.105930, Val Acc: 0.793814\n",
      "Epoch 22451 - Train Loss: 0.074017, Train Acc: 0.888462 | Val Loss: 0.105929, Val Acc: 0.793814\n",
      "Epoch 22452 - Train Loss: 0.074015, Train Acc: 0.888462 | Val Loss: 0.105929, Val Acc: 0.793814\n",
      "Epoch 22453 - Train Loss: 0.074013, Train Acc: 0.888462 | Val Loss: 0.105928, Val Acc: 0.793814\n",
      "Epoch 22454 - Train Loss: 0.074012, Train Acc: 0.888462 | Val Loss: 0.105928, Val Acc: 0.793814\n",
      "Epoch 22455 - Train Loss: 0.074010, Train Acc: 0.888462 | Val Loss: 0.105927, Val Acc: 0.793814\n",
      "Epoch 22456 - Train Loss: 0.074008, Train Acc: 0.888462 | Val Loss: 0.105927, Val Acc: 0.793814\n",
      "Epoch 22457 - Train Loss: 0.074007, Train Acc: 0.888462 | Val Loss: 0.105926, Val Acc: 0.793814\n",
      "Epoch 22458 - Train Loss: 0.074005, Train Acc: 0.888462 | Val Loss: 0.105926, Val Acc: 0.793814\n",
      "Epoch 22459 - Train Loss: 0.074003, Train Acc: 0.888462 | Val Loss: 0.105925, Val Acc: 0.793814\n",
      "Epoch 22460 - Train Loss: 0.074001, Train Acc: 0.888462 | Val Loss: 0.105925, Val Acc: 0.793814\n",
      "Epoch 22461 - Train Loss: 0.074000, Train Acc: 0.888462 | Val Loss: 0.105924, Val Acc: 0.793814\n",
      "Epoch 22462 - Train Loss: 0.073998, Train Acc: 0.888462 | Val Loss: 0.105924, Val Acc: 0.793814\n",
      "Epoch 22463 - Train Loss: 0.073996, Train Acc: 0.888462 | Val Loss: 0.105923, Val Acc: 0.793814\n",
      "Epoch 22464 - Train Loss: 0.073995, Train Acc: 0.888462 | Val Loss: 0.105923, Val Acc: 0.793814\n",
      "Epoch 22465 - Train Loss: 0.073993, Train Acc: 0.888462 | Val Loss: 0.105922, Val Acc: 0.793814\n",
      "Epoch 22466 - Train Loss: 0.073991, Train Acc: 0.888462 | Val Loss: 0.105922, Val Acc: 0.793814\n",
      "Epoch 22467 - Train Loss: 0.073990, Train Acc: 0.888462 | Val Loss: 0.105921, Val Acc: 0.793814\n",
      "Epoch 22468 - Train Loss: 0.073988, Train Acc: 0.888462 | Val Loss: 0.105921, Val Acc: 0.793814\n",
      "Epoch 22469 - Train Loss: 0.073986, Train Acc: 0.888462 | Val Loss: 0.105920, Val Acc: 0.793814\n",
      "Epoch 22470 - Train Loss: 0.073984, Train Acc: 0.888462 | Val Loss: 0.105920, Val Acc: 0.793814\n",
      "Epoch 22471 - Train Loss: 0.073983, Train Acc: 0.888462 | Val Loss: 0.105919, Val Acc: 0.793814\n",
      "Epoch 22472 - Train Loss: 0.073981, Train Acc: 0.888462 | Val Loss: 0.105919, Val Acc: 0.793814\n",
      "Epoch 22473 - Train Loss: 0.073979, Train Acc: 0.888462 | Val Loss: 0.105918, Val Acc: 0.793814\n",
      "Epoch 22474 - Train Loss: 0.073978, Train Acc: 0.888462 | Val Loss: 0.105918, Val Acc: 0.793814\n",
      "Epoch 22475 - Train Loss: 0.073976, Train Acc: 0.888462 | Val Loss: 0.105917, Val Acc: 0.793814\n",
      "Epoch 22476 - Train Loss: 0.073974, Train Acc: 0.888462 | Val Loss: 0.105917, Val Acc: 0.793814\n",
      "Epoch 22477 - Train Loss: 0.073973, Train Acc: 0.888462 | Val Loss: 0.105916, Val Acc: 0.793814\n",
      "Epoch 22478 - Train Loss: 0.073971, Train Acc: 0.888462 | Val Loss: 0.105916, Val Acc: 0.793814\n",
      "Epoch 22479 - Train Loss: 0.073969, Train Acc: 0.888462 | Val Loss: 0.105915, Val Acc: 0.793814\n",
      "Epoch 22480 - Train Loss: 0.073968, Train Acc: 0.888462 | Val Loss: 0.105915, Val Acc: 0.793814\n",
      "Epoch 22481 - Train Loss: 0.073966, Train Acc: 0.888462 | Val Loss: 0.105914, Val Acc: 0.793814\n",
      "Epoch 22482 - Train Loss: 0.073964, Train Acc: 0.888462 | Val Loss: 0.105914, Val Acc: 0.793814\n",
      "Epoch 22483 - Train Loss: 0.073962, Train Acc: 0.888462 | Val Loss: 0.105913, Val Acc: 0.793814\n",
      "Epoch 22484 - Train Loss: 0.073961, Train Acc: 0.888462 | Val Loss: 0.105913, Val Acc: 0.793814\n",
      "Epoch 22485 - Train Loss: 0.073959, Train Acc: 0.888462 | Val Loss: 0.105912, Val Acc: 0.793814\n",
      "Epoch 22486 - Train Loss: 0.073957, Train Acc: 0.888462 | Val Loss: 0.105912, Val Acc: 0.793814\n",
      "Epoch 22487 - Train Loss: 0.073956, Train Acc: 0.888462 | Val Loss: 0.105911, Val Acc: 0.793814\n",
      "Epoch 22488 - Train Loss: 0.073954, Train Acc: 0.888462 | Val Loss: 0.105911, Val Acc: 0.793814\n",
      "Epoch 22489 - Train Loss: 0.073952, Train Acc: 0.888462 | Val Loss: 0.105910, Val Acc: 0.793814\n",
      "Epoch 22490 - Train Loss: 0.073951, Train Acc: 0.888462 | Val Loss: 0.105910, Val Acc: 0.793814\n",
      "Epoch 22491 - Train Loss: 0.073949, Train Acc: 0.888462 | Val Loss: 0.105909, Val Acc: 0.793814\n",
      "Epoch 22492 - Train Loss: 0.073947, Train Acc: 0.888462 | Val Loss: 0.105909, Val Acc: 0.793814\n",
      "Epoch 22493 - Train Loss: 0.073946, Train Acc: 0.888462 | Val Loss: 0.105908, Val Acc: 0.793814\n",
      "Epoch 22494 - Train Loss: 0.073944, Train Acc: 0.888462 | Val Loss: 0.105908, Val Acc: 0.793814\n",
      "Epoch 22495 - Train Loss: 0.073942, Train Acc: 0.888462 | Val Loss: 0.105907, Val Acc: 0.793814\n",
      "Epoch 22496 - Train Loss: 0.073940, Train Acc: 0.888462 | Val Loss: 0.105907, Val Acc: 0.793814\n",
      "Epoch 22497 - Train Loss: 0.073939, Train Acc: 0.888462 | Val Loss: 0.105906, Val Acc: 0.793814\n",
      "Epoch 22498 - Train Loss: 0.073937, Train Acc: 0.888462 | Val Loss: 0.105906, Val Acc: 0.793814\n",
      "Epoch 22499 - Train Loss: 0.073935, Train Acc: 0.888462 | Val Loss: 0.105905, Val Acc: 0.793814\n",
      "Epoch 22500 - Train Loss: 0.073934, Train Acc: 0.888462 | Val Loss: 0.105905, Val Acc: 0.793814\n",
      "Epoch 22501 - Train Loss: 0.073932, Train Acc: 0.888462 | Val Loss: 0.105904, Val Acc: 0.793814\n",
      "Epoch 22502 - Train Loss: 0.073930, Train Acc: 0.888462 | Val Loss: 0.105904, Val Acc: 0.793814\n",
      "Epoch 22503 - Train Loss: 0.073929, Train Acc: 0.888462 | Val Loss: 0.105903, Val Acc: 0.793814\n",
      "Epoch 22504 - Train Loss: 0.073927, Train Acc: 0.888462 | Val Loss: 0.105903, Val Acc: 0.793814\n",
      "Epoch 22505 - Train Loss: 0.073925, Train Acc: 0.888462 | Val Loss: 0.105903, Val Acc: 0.793814\n",
      "Epoch 22506 - Train Loss: 0.073924, Train Acc: 0.888462 | Val Loss: 0.105902, Val Acc: 0.793814\n",
      "Epoch 22507 - Train Loss: 0.073922, Train Acc: 0.888462 | Val Loss: 0.105902, Val Acc: 0.793814\n",
      "Epoch 22508 - Train Loss: 0.073920, Train Acc: 0.888462 | Val Loss: 0.105901, Val Acc: 0.793814\n",
      "Epoch 22509 - Train Loss: 0.073918, Train Acc: 0.888462 | Val Loss: 0.105901, Val Acc: 0.793814\n",
      "Epoch 22510 - Train Loss: 0.073917, Train Acc: 0.888462 | Val Loss: 0.105900, Val Acc: 0.793814\n",
      "Epoch 22511 - Train Loss: 0.073915, Train Acc: 0.888462 | Val Loss: 0.105900, Val Acc: 0.793814\n",
      "Epoch 22512 - Train Loss: 0.073913, Train Acc: 0.888462 | Val Loss: 0.105899, Val Acc: 0.793814\n",
      "Epoch 22513 - Train Loss: 0.073912, Train Acc: 0.888462 | Val Loss: 0.105899, Val Acc: 0.793814\n",
      "Epoch 22514 - Train Loss: 0.073910, Train Acc: 0.888462 | Val Loss: 0.105898, Val Acc: 0.793814\n",
      "Epoch 22515 - Train Loss: 0.073908, Train Acc: 0.888462 | Val Loss: 0.105898, Val Acc: 0.793814\n",
      "Epoch 22516 - Train Loss: 0.073907, Train Acc: 0.888462 | Val Loss: 0.105897, Val Acc: 0.793814\n",
      "Epoch 22517 - Train Loss: 0.073905, Train Acc: 0.888462 | Val Loss: 0.105897, Val Acc: 0.793814\n",
      "Epoch 22518 - Train Loss: 0.073903, Train Acc: 0.888462 | Val Loss: 0.105896, Val Acc: 0.793814\n",
      "Epoch 22519 - Train Loss: 0.073902, Train Acc: 0.888462 | Val Loss: 0.105896, Val Acc: 0.793814\n",
      "Epoch 22520 - Train Loss: 0.073900, Train Acc: 0.888462 | Val Loss: 0.105895, Val Acc: 0.793814\n",
      "Epoch 22521 - Train Loss: 0.073898, Train Acc: 0.888462 | Val Loss: 0.105895, Val Acc: 0.793814\n",
      "Epoch 22522 - Train Loss: 0.073896, Train Acc: 0.888462 | Val Loss: 0.105894, Val Acc: 0.793814\n",
      "Epoch 22523 - Train Loss: 0.073895, Train Acc: 0.888462 | Val Loss: 0.105894, Val Acc: 0.793814\n",
      "Epoch 22524 - Train Loss: 0.073893, Train Acc: 0.888462 | Val Loss: 0.105893, Val Acc: 0.793814\n",
      "Epoch 22525 - Train Loss: 0.073891, Train Acc: 0.888462 | Val Loss: 0.105893, Val Acc: 0.793814\n",
      "Epoch 22526 - Train Loss: 0.073890, Train Acc: 0.888462 | Val Loss: 0.105892, Val Acc: 0.793814\n",
      "Epoch 22527 - Train Loss: 0.073888, Train Acc: 0.888462 | Val Loss: 0.105892, Val Acc: 0.793814\n",
      "Epoch 22528 - Train Loss: 0.073886, Train Acc: 0.888462 | Val Loss: 0.105891, Val Acc: 0.793814\n",
      "Epoch 22529 - Train Loss: 0.073885, Train Acc: 0.888462 | Val Loss: 0.105891, Val Acc: 0.793814\n",
      "Epoch 22530 - Train Loss: 0.073883, Train Acc: 0.888462 | Val Loss: 0.105890, Val Acc: 0.793814\n",
      "Epoch 22531 - Train Loss: 0.073881, Train Acc: 0.888462 | Val Loss: 0.105890, Val Acc: 0.793814\n",
      "Epoch 22532 - Train Loss: 0.073880, Train Acc: 0.888462 | Val Loss: 0.105889, Val Acc: 0.793814\n",
      "Epoch 22533 - Train Loss: 0.073878, Train Acc: 0.888462 | Val Loss: 0.105889, Val Acc: 0.793814\n",
      "Epoch 22534 - Train Loss: 0.073876, Train Acc: 0.888462 | Val Loss: 0.105888, Val Acc: 0.793814\n",
      "Epoch 22535 - Train Loss: 0.073875, Train Acc: 0.888462 | Val Loss: 0.105888, Val Acc: 0.793814\n",
      "Epoch 22536 - Train Loss: 0.073873, Train Acc: 0.888462 | Val Loss: 0.105887, Val Acc: 0.793814\n",
      "Epoch 22537 - Train Loss: 0.073871, Train Acc: 0.888462 | Val Loss: 0.105887, Val Acc: 0.793814\n",
      "Epoch 22538 - Train Loss: 0.073869, Train Acc: 0.888462 | Val Loss: 0.105886, Val Acc: 0.793814\n",
      "Epoch 22539 - Train Loss: 0.073868, Train Acc: 0.888462 | Val Loss: 0.105886, Val Acc: 0.793814\n",
      "Epoch 22540 - Train Loss: 0.073866, Train Acc: 0.888462 | Val Loss: 0.105885, Val Acc: 0.793814\n",
      "Epoch 22541 - Train Loss: 0.073864, Train Acc: 0.888462 | Val Loss: 0.105885, Val Acc: 0.793814\n",
      "Epoch 22542 - Train Loss: 0.073863, Train Acc: 0.888462 | Val Loss: 0.105885, Val Acc: 0.793814\n",
      "Epoch 22543 - Train Loss: 0.073861, Train Acc: 0.888462 | Val Loss: 0.105884, Val Acc: 0.793814\n",
      "Epoch 22544 - Train Loss: 0.073859, Train Acc: 0.888462 | Val Loss: 0.105884, Val Acc: 0.793814\n",
      "Epoch 22545 - Train Loss: 0.073858, Train Acc: 0.888462 | Val Loss: 0.105883, Val Acc: 0.793814\n",
      "Epoch 22546 - Train Loss: 0.073856, Train Acc: 0.888462 | Val Loss: 0.105883, Val Acc: 0.793814\n",
      "Epoch 22547 - Train Loss: 0.073854, Train Acc: 0.888462 | Val Loss: 0.105882, Val Acc: 0.793814\n",
      "Epoch 22548 - Train Loss: 0.073853, Train Acc: 0.888462 | Val Loss: 0.105882, Val Acc: 0.793814\n",
      "Epoch 22549 - Train Loss: 0.073851, Train Acc: 0.888462 | Val Loss: 0.105881, Val Acc: 0.793814\n",
      "Epoch 22550 - Train Loss: 0.073849, Train Acc: 0.888462 | Val Loss: 0.105881, Val Acc: 0.793814\n",
      "Epoch 22551 - Train Loss: 0.073848, Train Acc: 0.888462 | Val Loss: 0.105880, Val Acc: 0.793814\n",
      "Epoch 22552 - Train Loss: 0.073846, Train Acc: 0.888462 | Val Loss: 0.105880, Val Acc: 0.793814\n",
      "Epoch 22553 - Train Loss: 0.073844, Train Acc: 0.888462 | Val Loss: 0.105879, Val Acc: 0.793814\n",
      "Epoch 22554 - Train Loss: 0.073842, Train Acc: 0.888462 | Val Loss: 0.105879, Val Acc: 0.793814\n",
      "Epoch 22555 - Train Loss: 0.073841, Train Acc: 0.888462 | Val Loss: 0.105878, Val Acc: 0.793814\n",
      "Epoch 22556 - Train Loss: 0.073839, Train Acc: 0.888462 | Val Loss: 0.105878, Val Acc: 0.793814\n",
      "Epoch 22557 - Train Loss: 0.073837, Train Acc: 0.888462 | Val Loss: 0.105877, Val Acc: 0.793814\n",
      "Epoch 22558 - Train Loss: 0.073836, Train Acc: 0.888462 | Val Loss: 0.105877, Val Acc: 0.793814\n",
      "Epoch 22559 - Train Loss: 0.073834, Train Acc: 0.888462 | Val Loss: 0.105876, Val Acc: 0.793814\n",
      "Epoch 22560 - Train Loss: 0.073832, Train Acc: 0.888462 | Val Loss: 0.105876, Val Acc: 0.793814\n",
      "Epoch 22561 - Train Loss: 0.073831, Train Acc: 0.888462 | Val Loss: 0.105875, Val Acc: 0.793814\n",
      "Epoch 22562 - Train Loss: 0.073829, Train Acc: 0.888462 | Val Loss: 0.105875, Val Acc: 0.793814\n",
      "Epoch 22563 - Train Loss: 0.073827, Train Acc: 0.888462 | Val Loss: 0.105874, Val Acc: 0.793814\n",
      "Epoch 22564 - Train Loss: 0.073826, Train Acc: 0.888462 | Val Loss: 0.105874, Val Acc: 0.793814\n",
      "Epoch 22565 - Train Loss: 0.073824, Train Acc: 0.888462 | Val Loss: 0.105873, Val Acc: 0.793814\n",
      "Epoch 22566 - Train Loss: 0.073822, Train Acc: 0.888462 | Val Loss: 0.105873, Val Acc: 0.793814\n",
      "Epoch 22567 - Train Loss: 0.073821, Train Acc: 0.888462 | Val Loss: 0.105872, Val Acc: 0.793814\n",
      "Epoch 22568 - Train Loss: 0.073819, Train Acc: 0.889744 | Val Loss: 0.105872, Val Acc: 0.793814\n",
      "Epoch 22569 - Train Loss: 0.073817, Train Acc: 0.889744 | Val Loss: 0.105872, Val Acc: 0.793814\n",
      "Epoch 22570 - Train Loss: 0.073816, Train Acc: 0.889744 | Val Loss: 0.105871, Val Acc: 0.793814\n",
      "Epoch 22571 - Train Loss: 0.073814, Train Acc: 0.889744 | Val Loss: 0.105871, Val Acc: 0.793814\n",
      "Epoch 22572 - Train Loss: 0.073812, Train Acc: 0.889744 | Val Loss: 0.105870, Val Acc: 0.793814\n",
      "Epoch 22573 - Train Loss: 0.073810, Train Acc: 0.889744 | Val Loss: 0.105870, Val Acc: 0.793814\n",
      "Epoch 22574 - Train Loss: 0.073809, Train Acc: 0.889744 | Val Loss: 0.105869, Val Acc: 0.793814\n",
      "Epoch 22575 - Train Loss: 0.073807, Train Acc: 0.889744 | Val Loss: 0.105869, Val Acc: 0.793814\n",
      "Epoch 22576 - Train Loss: 0.073805, Train Acc: 0.889744 | Val Loss: 0.105868, Val Acc: 0.793814\n",
      "Epoch 22577 - Train Loss: 0.073804, Train Acc: 0.889744 | Val Loss: 0.105868, Val Acc: 0.793814\n",
      "Epoch 22578 - Train Loss: 0.073802, Train Acc: 0.889744 | Val Loss: 0.105867, Val Acc: 0.793814\n",
      "Epoch 22579 - Train Loss: 0.073800, Train Acc: 0.889744 | Val Loss: 0.105867, Val Acc: 0.793814\n",
      "Epoch 22580 - Train Loss: 0.073799, Train Acc: 0.889744 | Val Loss: 0.105866, Val Acc: 0.793814\n",
      "Epoch 22581 - Train Loss: 0.073797, Train Acc: 0.889744 | Val Loss: 0.105866, Val Acc: 0.793814\n",
      "Epoch 22582 - Train Loss: 0.073795, Train Acc: 0.889744 | Val Loss: 0.105865, Val Acc: 0.793814\n",
      "Epoch 22583 - Train Loss: 0.073794, Train Acc: 0.889744 | Val Loss: 0.105865, Val Acc: 0.793814\n",
      "Epoch 22584 - Train Loss: 0.073792, Train Acc: 0.889744 | Val Loss: 0.105864, Val Acc: 0.793814\n",
      "Epoch 22585 - Train Loss: 0.073790, Train Acc: 0.889744 | Val Loss: 0.105864, Val Acc: 0.793814\n",
      "Epoch 22586 - Train Loss: 0.073789, Train Acc: 0.889744 | Val Loss: 0.105863, Val Acc: 0.793814\n",
      "Epoch 22587 - Train Loss: 0.073787, Train Acc: 0.889744 | Val Loss: 0.105863, Val Acc: 0.793814\n",
      "Epoch 22588 - Train Loss: 0.073785, Train Acc: 0.889744 | Val Loss: 0.105863, Val Acc: 0.793814\n",
      "Epoch 22589 - Train Loss: 0.073784, Train Acc: 0.889744 | Val Loss: 0.105862, Val Acc: 0.793814\n",
      "Epoch 22590 - Train Loss: 0.073782, Train Acc: 0.889744 | Val Loss: 0.105862, Val Acc: 0.793814\n",
      "Epoch 22591 - Train Loss: 0.073780, Train Acc: 0.889744 | Val Loss: 0.105861, Val Acc: 0.793814\n",
      "Epoch 22592 - Train Loss: 0.073779, Train Acc: 0.889744 | Val Loss: 0.105861, Val Acc: 0.793814\n",
      "Epoch 22593 - Train Loss: 0.073777, Train Acc: 0.889744 | Val Loss: 0.105860, Val Acc: 0.793814\n",
      "Epoch 22594 - Train Loss: 0.073775, Train Acc: 0.889744 | Val Loss: 0.105860, Val Acc: 0.793814\n",
      "Epoch 22595 - Train Loss: 0.073774, Train Acc: 0.889744 | Val Loss: 0.105859, Val Acc: 0.793814\n",
      "Epoch 22596 - Train Loss: 0.073772, Train Acc: 0.889744 | Val Loss: 0.105859, Val Acc: 0.793814\n",
      "Epoch 22597 - Train Loss: 0.073770, Train Acc: 0.889744 | Val Loss: 0.105858, Val Acc: 0.793814\n",
      "Epoch 22598 - Train Loss: 0.073768, Train Acc: 0.889744 | Val Loss: 0.105858, Val Acc: 0.793814\n",
      "Epoch 22599 - Train Loss: 0.073767, Train Acc: 0.889744 | Val Loss: 0.105857, Val Acc: 0.793814\n",
      "Epoch 22600 - Train Loss: 0.073765, Train Acc: 0.889744 | Val Loss: 0.105857, Val Acc: 0.793814\n",
      "Epoch 22601 - Train Loss: 0.073763, Train Acc: 0.889744 | Val Loss: 0.105856, Val Acc: 0.793814\n",
      "Epoch 22602 - Train Loss: 0.073762, Train Acc: 0.889744 | Val Loss: 0.105856, Val Acc: 0.793814\n",
      "Epoch 22603 - Train Loss: 0.073760, Train Acc: 0.889744 | Val Loss: 0.105855, Val Acc: 0.793814\n",
      "Epoch 22604 - Train Loss: 0.073758, Train Acc: 0.889744 | Val Loss: 0.105855, Val Acc: 0.793814\n",
      "Epoch 22605 - Train Loss: 0.073757, Train Acc: 0.889744 | Val Loss: 0.105854, Val Acc: 0.793814\n",
      "Epoch 22606 - Train Loss: 0.073755, Train Acc: 0.889744 | Val Loss: 0.105854, Val Acc: 0.793814\n",
      "Epoch 22607 - Train Loss: 0.073753, Train Acc: 0.889744 | Val Loss: 0.105853, Val Acc: 0.793814\n",
      "Epoch 22608 - Train Loss: 0.073752, Train Acc: 0.889744 | Val Loss: 0.105853, Val Acc: 0.793814\n",
      "Epoch 22609 - Train Loss: 0.073750, Train Acc: 0.889744 | Val Loss: 0.105852, Val Acc: 0.793814\n",
      "Epoch 22610 - Train Loss: 0.073748, Train Acc: 0.889744 | Val Loss: 0.105852, Val Acc: 0.793814\n",
      "Epoch 22611 - Train Loss: 0.073747, Train Acc: 0.889744 | Val Loss: 0.105852, Val Acc: 0.793814\n",
      "Epoch 22612 - Train Loss: 0.073745, Train Acc: 0.889744 | Val Loss: 0.105851, Val Acc: 0.793814\n",
      "Epoch 22613 - Train Loss: 0.073743, Train Acc: 0.889744 | Val Loss: 0.105851, Val Acc: 0.793814\n",
      "Epoch 22614 - Train Loss: 0.073742, Train Acc: 0.889744 | Val Loss: 0.105850, Val Acc: 0.793814\n",
      "Epoch 22615 - Train Loss: 0.073740, Train Acc: 0.889744 | Val Loss: 0.105850, Val Acc: 0.793814\n",
      "Epoch 22616 - Train Loss: 0.073738, Train Acc: 0.889744 | Val Loss: 0.105849, Val Acc: 0.793814\n",
      "Epoch 22617 - Train Loss: 0.073737, Train Acc: 0.889744 | Val Loss: 0.105849, Val Acc: 0.793814\n",
      "Epoch 22618 - Train Loss: 0.073735, Train Acc: 0.889744 | Val Loss: 0.105848, Val Acc: 0.793814\n",
      "Epoch 22619 - Train Loss: 0.073733, Train Acc: 0.889744 | Val Loss: 0.105848, Val Acc: 0.793814\n",
      "Epoch 22620 - Train Loss: 0.073732, Train Acc: 0.889744 | Val Loss: 0.105847, Val Acc: 0.793814\n",
      "Epoch 22621 - Train Loss: 0.073730, Train Acc: 0.889744 | Val Loss: 0.105847, Val Acc: 0.793814\n",
      "Epoch 22622 - Train Loss: 0.073728, Train Acc: 0.889744 | Val Loss: 0.105846, Val Acc: 0.793814\n",
      "Epoch 22623 - Train Loss: 0.073727, Train Acc: 0.889744 | Val Loss: 0.105846, Val Acc: 0.793814\n",
      "Epoch 22624 - Train Loss: 0.073725, Train Acc: 0.889744 | Val Loss: 0.105845, Val Acc: 0.793814\n",
      "Epoch 22625 - Train Loss: 0.073723, Train Acc: 0.889744 | Val Loss: 0.105845, Val Acc: 0.793814\n",
      "Epoch 22626 - Train Loss: 0.073722, Train Acc: 0.889744 | Val Loss: 0.105844, Val Acc: 0.793814\n",
      "Epoch 22627 - Train Loss: 0.073720, Train Acc: 0.889744 | Val Loss: 0.105844, Val Acc: 0.793814\n",
      "Epoch 22628 - Train Loss: 0.073718, Train Acc: 0.889744 | Val Loss: 0.105843, Val Acc: 0.793814\n",
      "Epoch 22629 - Train Loss: 0.073717, Train Acc: 0.889744 | Val Loss: 0.105843, Val Acc: 0.793814\n",
      "Epoch 22630 - Train Loss: 0.073715, Train Acc: 0.889744 | Val Loss: 0.105842, Val Acc: 0.793814\n",
      "Epoch 22631 - Train Loss: 0.073713, Train Acc: 0.889744 | Val Loss: 0.105842, Val Acc: 0.793814\n",
      "Epoch 22632 - Train Loss: 0.073711, Train Acc: 0.889744 | Val Loss: 0.105842, Val Acc: 0.793814\n",
      "Epoch 22633 - Train Loss: 0.073710, Train Acc: 0.889744 | Val Loss: 0.105841, Val Acc: 0.793814\n",
      "Epoch 22634 - Train Loss: 0.073708, Train Acc: 0.889744 | Val Loss: 0.105841, Val Acc: 0.793814\n",
      "Epoch 22635 - Train Loss: 0.073706, Train Acc: 0.889744 | Val Loss: 0.105840, Val Acc: 0.793814\n",
      "Epoch 22636 - Train Loss: 0.073705, Train Acc: 0.889744 | Val Loss: 0.105840, Val Acc: 0.793814\n",
      "Epoch 22637 - Train Loss: 0.073703, Train Acc: 0.889744 | Val Loss: 0.105839, Val Acc: 0.793814\n",
      "Epoch 22638 - Train Loss: 0.073701, Train Acc: 0.889744 | Val Loss: 0.105839, Val Acc: 0.793814\n",
      "Epoch 22639 - Train Loss: 0.073700, Train Acc: 0.889744 | Val Loss: 0.105838, Val Acc: 0.793814\n",
      "Epoch 22640 - Train Loss: 0.073698, Train Acc: 0.889744 | Val Loss: 0.105838, Val Acc: 0.793814\n",
      "Epoch 22641 - Train Loss: 0.073696, Train Acc: 0.889744 | Val Loss: 0.105837, Val Acc: 0.793814\n",
      "Epoch 22642 - Train Loss: 0.073695, Train Acc: 0.889744 | Val Loss: 0.105837, Val Acc: 0.793814\n",
      "Epoch 22643 - Train Loss: 0.073693, Train Acc: 0.889744 | Val Loss: 0.105836, Val Acc: 0.793814\n",
      "Epoch 22644 - Train Loss: 0.073691, Train Acc: 0.889744 | Val Loss: 0.105836, Val Acc: 0.793814\n",
      "Epoch 22645 - Train Loss: 0.073690, Train Acc: 0.889744 | Val Loss: 0.105836, Val Acc: 0.793814\n",
      "Epoch 22646 - Train Loss: 0.073688, Train Acc: 0.889744 | Val Loss: 0.105835, Val Acc: 0.793814\n",
      "Epoch 22647 - Train Loss: 0.073686, Train Acc: 0.889744 | Val Loss: 0.105835, Val Acc: 0.793814\n",
      "Epoch 22648 - Train Loss: 0.073685, Train Acc: 0.889744 | Val Loss: 0.105834, Val Acc: 0.793814\n",
      "Epoch 22649 - Train Loss: 0.073683, Train Acc: 0.889744 | Val Loss: 0.105834, Val Acc: 0.793814\n",
      "Epoch 22650 - Train Loss: 0.073681, Train Acc: 0.889744 | Val Loss: 0.105833, Val Acc: 0.793814\n",
      "Epoch 22651 - Train Loss: 0.073680, Train Acc: 0.889744 | Val Loss: 0.105833, Val Acc: 0.793814\n",
      "Epoch 22652 - Train Loss: 0.073678, Train Acc: 0.889744 | Val Loss: 0.105832, Val Acc: 0.793814\n",
      "Epoch 22653 - Train Loss: 0.073676, Train Acc: 0.889744 | Val Loss: 0.105832, Val Acc: 0.793814\n",
      "Epoch 22654 - Train Loss: 0.073675, Train Acc: 0.889744 | Val Loss: 0.105831, Val Acc: 0.793814\n",
      "Epoch 22655 - Train Loss: 0.073673, Train Acc: 0.889744 | Val Loss: 0.105831, Val Acc: 0.793814\n",
      "Epoch 22656 - Train Loss: 0.073671, Train Acc: 0.889744 | Val Loss: 0.105830, Val Acc: 0.793814\n",
      "Epoch 22657 - Train Loss: 0.073670, Train Acc: 0.889744 | Val Loss: 0.105830, Val Acc: 0.793814\n",
      "Epoch 22658 - Train Loss: 0.073668, Train Acc: 0.889744 | Val Loss: 0.105829, Val Acc: 0.793814\n",
      "Epoch 22659 - Train Loss: 0.073666, Train Acc: 0.889744 | Val Loss: 0.105829, Val Acc: 0.793814\n",
      "Epoch 22660 - Train Loss: 0.073665, Train Acc: 0.889744 | Val Loss: 0.105828, Val Acc: 0.793814\n",
      "Epoch 22661 - Train Loss: 0.073663, Train Acc: 0.889744 | Val Loss: 0.105828, Val Acc: 0.793814\n",
      "Epoch 22662 - Train Loss: 0.073661, Train Acc: 0.889744 | Val Loss: 0.105828, Val Acc: 0.793814\n",
      "Epoch 22663 - Train Loss: 0.073660, Train Acc: 0.889744 | Val Loss: 0.105827, Val Acc: 0.793814\n",
      "Epoch 22664 - Train Loss: 0.073658, Train Acc: 0.889744 | Val Loss: 0.105827, Val Acc: 0.793814\n",
      "Epoch 22665 - Train Loss: 0.073656, Train Acc: 0.889744 | Val Loss: 0.105826, Val Acc: 0.793814\n",
      "Epoch 22666 - Train Loss: 0.073655, Train Acc: 0.889744 | Val Loss: 0.105826, Val Acc: 0.793814\n",
      "Epoch 22667 - Train Loss: 0.073653, Train Acc: 0.889744 | Val Loss: 0.105825, Val Acc: 0.793814\n",
      "Epoch 22668 - Train Loss: 0.073651, Train Acc: 0.889744 | Val Loss: 0.105825, Val Acc: 0.793814\n",
      "Epoch 22669 - Train Loss: 0.073650, Train Acc: 0.889744 | Val Loss: 0.105824, Val Acc: 0.793814\n",
      "Epoch 22670 - Train Loss: 0.073648, Train Acc: 0.889744 | Val Loss: 0.105824, Val Acc: 0.793814\n",
      "Epoch 22671 - Train Loss: 0.073646, Train Acc: 0.889744 | Val Loss: 0.105823, Val Acc: 0.793814\n",
      "Epoch 22672 - Train Loss: 0.073645, Train Acc: 0.889744 | Val Loss: 0.105823, Val Acc: 0.793814\n",
      "Epoch 22673 - Train Loss: 0.073643, Train Acc: 0.889744 | Val Loss: 0.105822, Val Acc: 0.793814\n",
      "Epoch 22674 - Train Loss: 0.073641, Train Acc: 0.889744 | Val Loss: 0.105822, Val Acc: 0.793814\n",
      "Epoch 22675 - Train Loss: 0.073640, Train Acc: 0.889744 | Val Loss: 0.105822, Val Acc: 0.793814\n",
      "Epoch 22676 - Train Loss: 0.073638, Train Acc: 0.889744 | Val Loss: 0.105821, Val Acc: 0.793814\n",
      "Epoch 22677 - Train Loss: 0.073636, Train Acc: 0.889744 | Val Loss: 0.105821, Val Acc: 0.793814\n",
      "Epoch 22678 - Train Loss: 0.073635, Train Acc: 0.889744 | Val Loss: 0.105820, Val Acc: 0.793814\n",
      "Epoch 22679 - Train Loss: 0.073633, Train Acc: 0.889744 | Val Loss: 0.105820, Val Acc: 0.793814\n",
      "Epoch 22680 - Train Loss: 0.073631, Train Acc: 0.889744 | Val Loss: 0.105819, Val Acc: 0.793814\n",
      "Epoch 22681 - Train Loss: 0.073630, Train Acc: 0.889744 | Val Loss: 0.105819, Val Acc: 0.793814\n",
      "Epoch 22682 - Train Loss: 0.073628, Train Acc: 0.889744 | Val Loss: 0.105818, Val Acc: 0.793814\n",
      "Epoch 22683 - Train Loss: 0.073626, Train Acc: 0.889744 | Val Loss: 0.105818, Val Acc: 0.793814\n",
      "Epoch 22684 - Train Loss: 0.073625, Train Acc: 0.889744 | Val Loss: 0.105817, Val Acc: 0.793814\n",
      "Epoch 22685 - Train Loss: 0.073623, Train Acc: 0.889744 | Val Loss: 0.105817, Val Acc: 0.793814\n",
      "Epoch 22686 - Train Loss: 0.073621, Train Acc: 0.889744 | Val Loss: 0.105816, Val Acc: 0.793814\n",
      "Epoch 22687 - Train Loss: 0.073620, Train Acc: 0.889744 | Val Loss: 0.105816, Val Acc: 0.793814\n",
      "Epoch 22688 - Train Loss: 0.073618, Train Acc: 0.889744 | Val Loss: 0.105815, Val Acc: 0.793814\n",
      "Epoch 22689 - Train Loss: 0.073616, Train Acc: 0.889744 | Val Loss: 0.105815, Val Acc: 0.793814\n",
      "Epoch 22690 - Train Loss: 0.073615, Train Acc: 0.889744 | Val Loss: 0.105814, Val Acc: 0.793814\n",
      "Epoch 22691 - Train Loss: 0.073613, Train Acc: 0.889744 | Val Loss: 0.105814, Val Acc: 0.793814\n",
      "Epoch 22692 - Train Loss: 0.073611, Train Acc: 0.889744 | Val Loss: 0.105814, Val Acc: 0.793814\n",
      "Epoch 22693 - Train Loss: 0.073610, Train Acc: 0.889744 | Val Loss: 0.105813, Val Acc: 0.793814\n",
      "Epoch 22694 - Train Loss: 0.073608, Train Acc: 0.889744 | Val Loss: 0.105813, Val Acc: 0.793814\n",
      "Epoch 22695 - Train Loss: 0.073606, Train Acc: 0.889744 | Val Loss: 0.105812, Val Acc: 0.793814\n",
      "Epoch 22696 - Train Loss: 0.073605, Train Acc: 0.889744 | Val Loss: 0.105812, Val Acc: 0.793814\n",
      "Epoch 22697 - Train Loss: 0.073603, Train Acc: 0.889744 | Val Loss: 0.105811, Val Acc: 0.793814\n",
      "Epoch 22698 - Train Loss: 0.073601, Train Acc: 0.889744 | Val Loss: 0.105811, Val Acc: 0.793814\n",
      "Epoch 22699 - Train Loss: 0.073600, Train Acc: 0.889744 | Val Loss: 0.105810, Val Acc: 0.793814\n",
      "Epoch 22700 - Train Loss: 0.073598, Train Acc: 0.889744 | Val Loss: 0.105810, Val Acc: 0.793814\n",
      "Epoch 22701 - Train Loss: 0.073596, Train Acc: 0.889744 | Val Loss: 0.105809, Val Acc: 0.793814\n",
      "Epoch 22702 - Train Loss: 0.073595, Train Acc: 0.889744 | Val Loss: 0.105809, Val Acc: 0.793814\n",
      "Epoch 22703 - Train Loss: 0.073593, Train Acc: 0.889744 | Val Loss: 0.105808, Val Acc: 0.793814\n",
      "Epoch 22704 - Train Loss: 0.073591, Train Acc: 0.889744 | Val Loss: 0.105808, Val Acc: 0.793814\n",
      "Epoch 22705 - Train Loss: 0.073590, Train Acc: 0.889744 | Val Loss: 0.105808, Val Acc: 0.793814\n",
      "Epoch 22706 - Train Loss: 0.073588, Train Acc: 0.889744 | Val Loss: 0.105807, Val Acc: 0.793814\n",
      "Epoch 22707 - Train Loss: 0.073586, Train Acc: 0.889744 | Val Loss: 0.105807, Val Acc: 0.793814\n",
      "Epoch 22708 - Train Loss: 0.073585, Train Acc: 0.889744 | Val Loss: 0.105806, Val Acc: 0.793814\n",
      "Epoch 22709 - Train Loss: 0.073583, Train Acc: 0.889744 | Val Loss: 0.105806, Val Acc: 0.793814\n",
      "Epoch 22710 - Train Loss: 0.073581, Train Acc: 0.889744 | Val Loss: 0.105805, Val Acc: 0.793814\n",
      "Epoch 22711 - Train Loss: 0.073580, Train Acc: 0.889744 | Val Loss: 0.105805, Val Acc: 0.793814\n",
      "Epoch 22712 - Train Loss: 0.073578, Train Acc: 0.889744 | Val Loss: 0.105804, Val Acc: 0.793814\n",
      "Epoch 22713 - Train Loss: 0.073576, Train Acc: 0.889744 | Val Loss: 0.105804, Val Acc: 0.793814\n",
      "Epoch 22714 - Train Loss: 0.073575, Train Acc: 0.889744 | Val Loss: 0.105803, Val Acc: 0.793814\n",
      "Epoch 22715 - Train Loss: 0.073573, Train Acc: 0.889744 | Val Loss: 0.105803, Val Acc: 0.793814\n",
      "Epoch 22716 - Train Loss: 0.073571, Train Acc: 0.889744 | Val Loss: 0.105803, Val Acc: 0.793814\n",
      "Epoch 22717 - Train Loss: 0.073570, Train Acc: 0.889744 | Val Loss: 0.105802, Val Acc: 0.793814\n",
      "Epoch 22718 - Train Loss: 0.073568, Train Acc: 0.889744 | Val Loss: 0.105802, Val Acc: 0.793814\n",
      "Epoch 22719 - Train Loss: 0.073566, Train Acc: 0.889744 | Val Loss: 0.105801, Val Acc: 0.793814\n",
      "Epoch 22720 - Train Loss: 0.073565, Train Acc: 0.889744 | Val Loss: 0.105801, Val Acc: 0.793814\n",
      "Epoch 22721 - Train Loss: 0.073563, Train Acc: 0.889744 | Val Loss: 0.105800, Val Acc: 0.793814\n",
      "Epoch 22722 - Train Loss: 0.073561, Train Acc: 0.889744 | Val Loss: 0.105800, Val Acc: 0.793814\n",
      "Epoch 22723 - Train Loss: 0.073560, Train Acc: 0.889744 | Val Loss: 0.105799, Val Acc: 0.793814\n",
      "Epoch 22724 - Train Loss: 0.073558, Train Acc: 0.889744 | Val Loss: 0.105799, Val Acc: 0.793814\n",
      "Epoch 22725 - Train Loss: 0.073556, Train Acc: 0.889744 | Val Loss: 0.105798, Val Acc: 0.793814\n",
      "Epoch 22726 - Train Loss: 0.073555, Train Acc: 0.889744 | Val Loss: 0.105798, Val Acc: 0.793814\n",
      "Epoch 22727 - Train Loss: 0.073553, Train Acc: 0.889744 | Val Loss: 0.105797, Val Acc: 0.793814\n",
      "Epoch 22728 - Train Loss: 0.073551, Train Acc: 0.889744 | Val Loss: 0.105797, Val Acc: 0.793814\n",
      "Epoch 22729 - Train Loss: 0.073550, Train Acc: 0.889744 | Val Loss: 0.105797, Val Acc: 0.793814\n",
      "Epoch 22730 - Train Loss: 0.073548, Train Acc: 0.889744 | Val Loss: 0.105796, Val Acc: 0.793814\n",
      "Epoch 22731 - Train Loss: 0.073546, Train Acc: 0.889744 | Val Loss: 0.105796, Val Acc: 0.793814\n",
      "Epoch 22732 - Train Loss: 0.073545, Train Acc: 0.889744 | Val Loss: 0.105795, Val Acc: 0.793814\n",
      "Epoch 22733 - Train Loss: 0.073543, Train Acc: 0.889744 | Val Loss: 0.105795, Val Acc: 0.793814\n",
      "Epoch 22734 - Train Loss: 0.073541, Train Acc: 0.889744 | Val Loss: 0.105794, Val Acc: 0.793814\n",
      "Epoch 22735 - Train Loss: 0.073540, Train Acc: 0.889744 | Val Loss: 0.105794, Val Acc: 0.793814\n",
      "Epoch 22736 - Train Loss: 0.073538, Train Acc: 0.889744 | Val Loss: 0.105793, Val Acc: 0.793814\n",
      "Epoch 22737 - Train Loss: 0.073537, Train Acc: 0.889744 | Val Loss: 0.105793, Val Acc: 0.793814\n",
      "Epoch 22738 - Train Loss: 0.073535, Train Acc: 0.889744 | Val Loss: 0.105792, Val Acc: 0.793814\n",
      "Epoch 22739 - Train Loss: 0.073533, Train Acc: 0.889744 | Val Loss: 0.105792, Val Acc: 0.793814\n",
      "Epoch 22740 - Train Loss: 0.073532, Train Acc: 0.889744 | Val Loss: 0.105792, Val Acc: 0.793814\n",
      "Epoch 22741 - Train Loss: 0.073530, Train Acc: 0.889744 | Val Loss: 0.105791, Val Acc: 0.793814\n",
      "Epoch 22742 - Train Loss: 0.073528, Train Acc: 0.889744 | Val Loss: 0.105791, Val Acc: 0.793814\n",
      "Epoch 22743 - Train Loss: 0.073527, Train Acc: 0.889744 | Val Loss: 0.105790, Val Acc: 0.793814\n",
      "Epoch 22744 - Train Loss: 0.073525, Train Acc: 0.889744 | Val Loss: 0.105790, Val Acc: 0.793814\n",
      "Epoch 22745 - Train Loss: 0.073523, Train Acc: 0.889744 | Val Loss: 0.105789, Val Acc: 0.793814\n",
      "Epoch 22746 - Train Loss: 0.073522, Train Acc: 0.889744 | Val Loss: 0.105789, Val Acc: 0.793814\n",
      "Epoch 22747 - Train Loss: 0.073520, Train Acc: 0.889744 | Val Loss: 0.105788, Val Acc: 0.793814\n",
      "Epoch 22748 - Train Loss: 0.073518, Train Acc: 0.889744 | Val Loss: 0.105788, Val Acc: 0.793814\n",
      "Epoch 22749 - Train Loss: 0.073517, Train Acc: 0.889744 | Val Loss: 0.105787, Val Acc: 0.793814\n",
      "Epoch 22750 - Train Loss: 0.073515, Train Acc: 0.889744 | Val Loss: 0.105787, Val Acc: 0.793814\n",
      "Epoch 22751 - Train Loss: 0.073513, Train Acc: 0.889744 | Val Loss: 0.105787, Val Acc: 0.793814\n",
      "Epoch 22752 - Train Loss: 0.073512, Train Acc: 0.889744 | Val Loss: 0.105786, Val Acc: 0.793814\n",
      "Epoch 22753 - Train Loss: 0.073510, Train Acc: 0.889744 | Val Loss: 0.105786, Val Acc: 0.793814\n",
      "Epoch 22754 - Train Loss: 0.073508, Train Acc: 0.889744 | Val Loss: 0.105785, Val Acc: 0.793814\n",
      "Epoch 22755 - Train Loss: 0.073507, Train Acc: 0.889744 | Val Loss: 0.105785, Val Acc: 0.793814\n",
      "Epoch 22756 - Train Loss: 0.073505, Train Acc: 0.889744 | Val Loss: 0.105784, Val Acc: 0.793814\n",
      "Epoch 22757 - Train Loss: 0.073503, Train Acc: 0.889744 | Val Loss: 0.105784, Val Acc: 0.793814\n",
      "Epoch 22758 - Train Loss: 0.073502, Train Acc: 0.889744 | Val Loss: 0.105783, Val Acc: 0.793814\n",
      "Epoch 22759 - Train Loss: 0.073500, Train Acc: 0.889744 | Val Loss: 0.105783, Val Acc: 0.793814\n",
      "Epoch 22760 - Train Loss: 0.073498, Train Acc: 0.889744 | Val Loss: 0.105782, Val Acc: 0.793814\n",
      "Epoch 22761 - Train Loss: 0.073497, Train Acc: 0.889744 | Val Loss: 0.105782, Val Acc: 0.793814\n",
      "Epoch 22762 - Train Loss: 0.073495, Train Acc: 0.889744 | Val Loss: 0.105782, Val Acc: 0.793814\n",
      "Epoch 22763 - Train Loss: 0.073493, Train Acc: 0.889744 | Val Loss: 0.105781, Val Acc: 0.793814\n",
      "Epoch 22764 - Train Loss: 0.073492, Train Acc: 0.889744 | Val Loss: 0.105781, Val Acc: 0.793814\n",
      "Epoch 22765 - Train Loss: 0.073490, Train Acc: 0.889744 | Val Loss: 0.105780, Val Acc: 0.793814\n",
      "Epoch 22766 - Train Loss: 0.073488, Train Acc: 0.889744 | Val Loss: 0.105780, Val Acc: 0.793814\n",
      "Epoch 22767 - Train Loss: 0.073487, Train Acc: 0.889744 | Val Loss: 0.105779, Val Acc: 0.793814\n",
      "Epoch 22768 - Train Loss: 0.073485, Train Acc: 0.889744 | Val Loss: 0.105779, Val Acc: 0.793814\n",
      "Epoch 22769 - Train Loss: 0.073483, Train Acc: 0.889744 | Val Loss: 0.105778, Val Acc: 0.793814\n",
      "Epoch 22770 - Train Loss: 0.073482, Train Acc: 0.889744 | Val Loss: 0.105778, Val Acc: 0.793814\n",
      "Epoch 22771 - Train Loss: 0.073480, Train Acc: 0.889744 | Val Loss: 0.105777, Val Acc: 0.793814\n",
      "Epoch 22772 - Train Loss: 0.073479, Train Acc: 0.889744 | Val Loss: 0.105777, Val Acc: 0.793814\n",
      "Epoch 22773 - Train Loss: 0.073477, Train Acc: 0.889744 | Val Loss: 0.105776, Val Acc: 0.793814\n",
      "Epoch 22774 - Train Loss: 0.073475, Train Acc: 0.889744 | Val Loss: 0.105776, Val Acc: 0.793814\n",
      "Epoch 22775 - Train Loss: 0.073474, Train Acc: 0.889744 | Val Loss: 0.105776, Val Acc: 0.793814\n",
      "Epoch 22776 - Train Loss: 0.073472, Train Acc: 0.889744 | Val Loss: 0.105775, Val Acc: 0.793814\n",
      "Epoch 22777 - Train Loss: 0.073470, Train Acc: 0.889744 | Val Loss: 0.105775, Val Acc: 0.793814\n",
      "Epoch 22778 - Train Loss: 0.073469, Train Acc: 0.889744 | Val Loss: 0.105774, Val Acc: 0.793814\n",
      "Epoch 22779 - Train Loss: 0.073467, Train Acc: 0.889744 | Val Loss: 0.105774, Val Acc: 0.793814\n",
      "Epoch 22780 - Train Loss: 0.073465, Train Acc: 0.889744 | Val Loss: 0.105773, Val Acc: 0.793814\n",
      "Epoch 22781 - Train Loss: 0.073464, Train Acc: 0.889744 | Val Loss: 0.105773, Val Acc: 0.793814\n",
      "Epoch 22782 - Train Loss: 0.073462, Train Acc: 0.889744 | Val Loss: 0.105772, Val Acc: 0.793814\n",
      "Epoch 22783 - Train Loss: 0.073460, Train Acc: 0.889744 | Val Loss: 0.105772, Val Acc: 0.793814\n",
      "Epoch 22784 - Train Loss: 0.073459, Train Acc: 0.889744 | Val Loss: 0.105771, Val Acc: 0.793814\n",
      "Epoch 22785 - Train Loss: 0.073457, Train Acc: 0.889744 | Val Loss: 0.105771, Val Acc: 0.793814\n",
      "Epoch 22786 - Train Loss: 0.073455, Train Acc: 0.889744 | Val Loss: 0.105771, Val Acc: 0.793814\n",
      "Epoch 22787 - Train Loss: 0.073454, Train Acc: 0.889744 | Val Loss: 0.105770, Val Acc: 0.793814\n",
      "Epoch 22788 - Train Loss: 0.073452, Train Acc: 0.889744 | Val Loss: 0.105770, Val Acc: 0.793814\n",
      "Epoch 22789 - Train Loss: 0.073450, Train Acc: 0.889744 | Val Loss: 0.105769, Val Acc: 0.793814\n",
      "Epoch 22790 - Train Loss: 0.073449, Train Acc: 0.889744 | Val Loss: 0.105769, Val Acc: 0.793814\n",
      "Epoch 22791 - Train Loss: 0.073447, Train Acc: 0.889744 | Val Loss: 0.105768, Val Acc: 0.793814\n",
      "Epoch 22792 - Train Loss: 0.073445, Train Acc: 0.889744 | Val Loss: 0.105768, Val Acc: 0.793814\n",
      "Epoch 22793 - Train Loss: 0.073444, Train Acc: 0.889744 | Val Loss: 0.105767, Val Acc: 0.793814\n",
      "Epoch 22794 - Train Loss: 0.073442, Train Acc: 0.889744 | Val Loss: 0.105767, Val Acc: 0.793814\n",
      "Epoch 22795 - Train Loss: 0.073441, Train Acc: 0.889744 | Val Loss: 0.105767, Val Acc: 0.793814\n",
      "Epoch 22796 - Train Loss: 0.073439, Train Acc: 0.889744 | Val Loss: 0.105766, Val Acc: 0.793814\n",
      "Epoch 22797 - Train Loss: 0.073437, Train Acc: 0.889744 | Val Loss: 0.105766, Val Acc: 0.793814\n",
      "Epoch 22798 - Train Loss: 0.073436, Train Acc: 0.889744 | Val Loss: 0.105765, Val Acc: 0.793814\n",
      "Epoch 22799 - Train Loss: 0.073434, Train Acc: 0.889744 | Val Loss: 0.105765, Val Acc: 0.793814\n",
      "Epoch 22800 - Train Loss: 0.073432, Train Acc: 0.889744 | Val Loss: 0.105764, Val Acc: 0.793814\n",
      "Epoch 22801 - Train Loss: 0.073431, Train Acc: 0.889744 | Val Loss: 0.105764, Val Acc: 0.793814\n",
      "Epoch 22802 - Train Loss: 0.073429, Train Acc: 0.889744 | Val Loss: 0.105763, Val Acc: 0.793814\n",
      "Epoch 22803 - Train Loss: 0.073427, Train Acc: 0.889744 | Val Loss: 0.105763, Val Acc: 0.793814\n",
      "Epoch 22804 - Train Loss: 0.073426, Train Acc: 0.889744 | Val Loss: 0.105763, Val Acc: 0.793814\n",
      "Epoch 22805 - Train Loss: 0.073424, Train Acc: 0.889744 | Val Loss: 0.105762, Val Acc: 0.793814\n",
      "Epoch 22806 - Train Loss: 0.073422, Train Acc: 0.889744 | Val Loss: 0.105762, Val Acc: 0.793814\n",
      "Epoch 22807 - Train Loss: 0.073421, Train Acc: 0.889744 | Val Loss: 0.105761, Val Acc: 0.793814\n",
      "Epoch 22808 - Train Loss: 0.073419, Train Acc: 0.889744 | Val Loss: 0.105761, Val Acc: 0.793814\n",
      "Epoch 22809 - Train Loss: 0.073417, Train Acc: 0.889744 | Val Loss: 0.105760, Val Acc: 0.793814\n",
      "Epoch 22810 - Train Loss: 0.073416, Train Acc: 0.889744 | Val Loss: 0.105760, Val Acc: 0.793814\n",
      "Epoch 22811 - Train Loss: 0.073414, Train Acc: 0.889744 | Val Loss: 0.105759, Val Acc: 0.793814\n",
      "Epoch 22812 - Train Loss: 0.073412, Train Acc: 0.889744 | Val Loss: 0.105759, Val Acc: 0.793814\n",
      "Epoch 22813 - Train Loss: 0.073411, Train Acc: 0.889744 | Val Loss: 0.105759, Val Acc: 0.793814\n",
      "Epoch 22814 - Train Loss: 0.073409, Train Acc: 0.889744 | Val Loss: 0.105758, Val Acc: 0.793814\n",
      "Epoch 22815 - Train Loss: 0.073408, Train Acc: 0.889744 | Val Loss: 0.105758, Val Acc: 0.793814\n",
      "Epoch 22816 - Train Loss: 0.073406, Train Acc: 0.889744 | Val Loss: 0.105757, Val Acc: 0.793814\n",
      "Epoch 22817 - Train Loss: 0.073404, Train Acc: 0.889744 | Val Loss: 0.105757, Val Acc: 0.793814\n",
      "Epoch 22818 - Train Loss: 0.073403, Train Acc: 0.889744 | Val Loss: 0.105756, Val Acc: 0.793814\n",
      "Epoch 22819 - Train Loss: 0.073401, Train Acc: 0.889744 | Val Loss: 0.105756, Val Acc: 0.793814\n",
      "Epoch 22820 - Train Loss: 0.073399, Train Acc: 0.889744 | Val Loss: 0.105755, Val Acc: 0.793814\n",
      "Epoch 22821 - Train Loss: 0.073398, Train Acc: 0.889744 | Val Loss: 0.105755, Val Acc: 0.793814\n",
      "Epoch 22822 - Train Loss: 0.073396, Train Acc: 0.889744 | Val Loss: 0.105755, Val Acc: 0.793814\n",
      "Epoch 22823 - Train Loss: 0.073394, Train Acc: 0.889744 | Val Loss: 0.105754, Val Acc: 0.793814\n",
      "Epoch 22824 - Train Loss: 0.073393, Train Acc: 0.889744 | Val Loss: 0.105754, Val Acc: 0.793814\n",
      "Epoch 22825 - Train Loss: 0.073391, Train Acc: 0.889744 | Val Loss: 0.105753, Val Acc: 0.793814\n",
      "Epoch 22826 - Train Loss: 0.073389, Train Acc: 0.889744 | Val Loss: 0.105753, Val Acc: 0.793814\n",
      "Epoch 22827 - Train Loss: 0.073388, Train Acc: 0.889744 | Val Loss: 0.105752, Val Acc: 0.793814\n",
      "Epoch 22828 - Train Loss: 0.073386, Train Acc: 0.889744 | Val Loss: 0.105752, Val Acc: 0.793814\n",
      "Epoch 22829 - Train Loss: 0.073384, Train Acc: 0.889744 | Val Loss: 0.105751, Val Acc: 0.793814\n",
      "Epoch 22830 - Train Loss: 0.073383, Train Acc: 0.891026 | Val Loss: 0.105751, Val Acc: 0.793814\n",
      "Epoch 22831 - Train Loss: 0.073381, Train Acc: 0.891026 | Val Loss: 0.105750, Val Acc: 0.793814\n",
      "Epoch 22832 - Train Loss: 0.073380, Train Acc: 0.891026 | Val Loss: 0.105750, Val Acc: 0.793814\n",
      "Epoch 22833 - Train Loss: 0.073378, Train Acc: 0.891026 | Val Loss: 0.105750, Val Acc: 0.793814\n",
      "Epoch 22834 - Train Loss: 0.073376, Train Acc: 0.891026 | Val Loss: 0.105749, Val Acc: 0.793814\n",
      "Epoch 22835 - Train Loss: 0.073375, Train Acc: 0.891026 | Val Loss: 0.105749, Val Acc: 0.793814\n",
      "Epoch 22836 - Train Loss: 0.073373, Train Acc: 0.891026 | Val Loss: 0.105748, Val Acc: 0.793814\n",
      "Epoch 22837 - Train Loss: 0.073371, Train Acc: 0.891026 | Val Loss: 0.105748, Val Acc: 0.793814\n",
      "Epoch 22838 - Train Loss: 0.073370, Train Acc: 0.891026 | Val Loss: 0.105747, Val Acc: 0.793814\n",
      "Epoch 22839 - Train Loss: 0.073368, Train Acc: 0.891026 | Val Loss: 0.105747, Val Acc: 0.793814\n",
      "Epoch 22840 - Train Loss: 0.073366, Train Acc: 0.891026 | Val Loss: 0.105746, Val Acc: 0.793814\n",
      "Epoch 22841 - Train Loss: 0.073365, Train Acc: 0.891026 | Val Loss: 0.105746, Val Acc: 0.793814\n",
      "Epoch 22842 - Train Loss: 0.073363, Train Acc: 0.891026 | Val Loss: 0.105746, Val Acc: 0.793814\n",
      "Epoch 22843 - Train Loss: 0.073361, Train Acc: 0.891026 | Val Loss: 0.105745, Val Acc: 0.793814\n",
      "Epoch 22844 - Train Loss: 0.073360, Train Acc: 0.891026 | Val Loss: 0.105745, Val Acc: 0.793814\n",
      "Epoch 22845 - Train Loss: 0.073358, Train Acc: 0.891026 | Val Loss: 0.105744, Val Acc: 0.793814\n",
      "Epoch 22846 - Train Loss: 0.073356, Train Acc: 0.891026 | Val Loss: 0.105744, Val Acc: 0.793814\n",
      "Epoch 22847 - Train Loss: 0.073355, Train Acc: 0.891026 | Val Loss: 0.105743, Val Acc: 0.793814\n",
      "Epoch 22848 - Train Loss: 0.073353, Train Acc: 0.891026 | Val Loss: 0.105743, Val Acc: 0.793814\n",
      "Epoch 22849 - Train Loss: 0.073352, Train Acc: 0.891026 | Val Loss: 0.105742, Val Acc: 0.793814\n",
      "Epoch 22850 - Train Loss: 0.073350, Train Acc: 0.891026 | Val Loss: 0.105742, Val Acc: 0.793814\n",
      "Epoch 22851 - Train Loss: 0.073348, Train Acc: 0.891026 | Val Loss: 0.105742, Val Acc: 0.793814\n",
      "Epoch 22852 - Train Loss: 0.073347, Train Acc: 0.891026 | Val Loss: 0.105741, Val Acc: 0.793814\n",
      "Epoch 22853 - Train Loss: 0.073345, Train Acc: 0.891026 | Val Loss: 0.105741, Val Acc: 0.793814\n",
      "Epoch 22854 - Train Loss: 0.073343, Train Acc: 0.891026 | Val Loss: 0.105740, Val Acc: 0.793814\n",
      "Epoch 22855 - Train Loss: 0.073342, Train Acc: 0.891026 | Val Loss: 0.105740, Val Acc: 0.793814\n",
      "Epoch 22856 - Train Loss: 0.073340, Train Acc: 0.891026 | Val Loss: 0.105739, Val Acc: 0.793814\n",
      "Epoch 22857 - Train Loss: 0.073338, Train Acc: 0.891026 | Val Loss: 0.105739, Val Acc: 0.793814\n",
      "Epoch 22858 - Train Loss: 0.073337, Train Acc: 0.891026 | Val Loss: 0.105739, Val Acc: 0.793814\n",
      "Epoch 22859 - Train Loss: 0.073335, Train Acc: 0.891026 | Val Loss: 0.105738, Val Acc: 0.793814\n",
      "Epoch 22860 - Train Loss: 0.073333, Train Acc: 0.891026 | Val Loss: 0.105738, Val Acc: 0.793814\n",
      "Epoch 22861 - Train Loss: 0.073332, Train Acc: 0.891026 | Val Loss: 0.105737, Val Acc: 0.793814\n",
      "Epoch 22862 - Train Loss: 0.073330, Train Acc: 0.891026 | Val Loss: 0.105737, Val Acc: 0.793814\n",
      "Epoch 22863 - Train Loss: 0.073329, Train Acc: 0.891026 | Val Loss: 0.105736, Val Acc: 0.793814\n",
      "Epoch 22864 - Train Loss: 0.073327, Train Acc: 0.891026 | Val Loss: 0.105736, Val Acc: 0.793814\n",
      "Epoch 22865 - Train Loss: 0.073325, Train Acc: 0.891026 | Val Loss: 0.105735, Val Acc: 0.793814\n",
      "Epoch 22866 - Train Loss: 0.073324, Train Acc: 0.891026 | Val Loss: 0.105735, Val Acc: 0.793814\n",
      "Epoch 22867 - Train Loss: 0.073322, Train Acc: 0.891026 | Val Loss: 0.105735, Val Acc: 0.793814\n",
      "Epoch 22868 - Train Loss: 0.073320, Train Acc: 0.891026 | Val Loss: 0.105734, Val Acc: 0.793814\n",
      "Epoch 22869 - Train Loss: 0.073319, Train Acc: 0.891026 | Val Loss: 0.105734, Val Acc: 0.793814\n",
      "Epoch 22870 - Train Loss: 0.073317, Train Acc: 0.891026 | Val Loss: 0.105733, Val Acc: 0.793814\n",
      "Epoch 22871 - Train Loss: 0.073315, Train Acc: 0.891026 | Val Loss: 0.105733, Val Acc: 0.793814\n",
      "Epoch 22872 - Train Loss: 0.073314, Train Acc: 0.891026 | Val Loss: 0.105732, Val Acc: 0.793814\n",
      "Epoch 22873 - Train Loss: 0.073312, Train Acc: 0.891026 | Val Loss: 0.105732, Val Acc: 0.793814\n",
      "Epoch 22874 - Train Loss: 0.073310, Train Acc: 0.891026 | Val Loss: 0.105731, Val Acc: 0.793814\n",
      "Epoch 22875 - Train Loss: 0.073309, Train Acc: 0.891026 | Val Loss: 0.105731, Val Acc: 0.793814\n",
      "Epoch 22876 - Train Loss: 0.073307, Train Acc: 0.891026 | Val Loss: 0.105731, Val Acc: 0.793814\n",
      "Epoch 22877 - Train Loss: 0.073306, Train Acc: 0.891026 | Val Loss: 0.105730, Val Acc: 0.793814\n",
      "Epoch 22878 - Train Loss: 0.073304, Train Acc: 0.891026 | Val Loss: 0.105730, Val Acc: 0.793814\n",
      "Epoch 22879 - Train Loss: 0.073302, Train Acc: 0.891026 | Val Loss: 0.105729, Val Acc: 0.793814\n",
      "Epoch 22880 - Train Loss: 0.073301, Train Acc: 0.891026 | Val Loss: 0.105729, Val Acc: 0.793814\n",
      "Epoch 22881 - Train Loss: 0.073299, Train Acc: 0.891026 | Val Loss: 0.105728, Val Acc: 0.793814\n",
      "Epoch 22882 - Train Loss: 0.073297, Train Acc: 0.891026 | Val Loss: 0.105728, Val Acc: 0.793814\n",
      "Epoch 22883 - Train Loss: 0.073296, Train Acc: 0.891026 | Val Loss: 0.105727, Val Acc: 0.793814\n",
      "Epoch 22884 - Train Loss: 0.073294, Train Acc: 0.891026 | Val Loss: 0.105727, Val Acc: 0.793814\n",
      "Epoch 22885 - Train Loss: 0.073292, Train Acc: 0.891026 | Val Loss: 0.105727, Val Acc: 0.793814\n",
      "Epoch 22886 - Train Loss: 0.073291, Train Acc: 0.891026 | Val Loss: 0.105726, Val Acc: 0.793814\n",
      "Epoch 22887 - Train Loss: 0.073289, Train Acc: 0.891026 | Val Loss: 0.105726, Val Acc: 0.793814\n",
      "Epoch 22888 - Train Loss: 0.073288, Train Acc: 0.891026 | Val Loss: 0.105725, Val Acc: 0.793814\n",
      "Epoch 22889 - Train Loss: 0.073286, Train Acc: 0.891026 | Val Loss: 0.105725, Val Acc: 0.793814\n",
      "Epoch 22890 - Train Loss: 0.073284, Train Acc: 0.891026 | Val Loss: 0.105724, Val Acc: 0.793814\n",
      "Epoch 22891 - Train Loss: 0.073283, Train Acc: 0.891026 | Val Loss: 0.105724, Val Acc: 0.793814\n",
      "Epoch 22892 - Train Loss: 0.073281, Train Acc: 0.891026 | Val Loss: 0.105724, Val Acc: 0.793814\n",
      "Epoch 22893 - Train Loss: 0.073279, Train Acc: 0.891026 | Val Loss: 0.105723, Val Acc: 0.793814\n",
      "Epoch 22894 - Train Loss: 0.073278, Train Acc: 0.891026 | Val Loss: 0.105723, Val Acc: 0.793814\n",
      "Epoch 22895 - Train Loss: 0.073276, Train Acc: 0.891026 | Val Loss: 0.105722, Val Acc: 0.793814\n",
      "Epoch 22896 - Train Loss: 0.073274, Train Acc: 0.891026 | Val Loss: 0.105722, Val Acc: 0.793814\n",
      "Epoch 22897 - Train Loss: 0.073273, Train Acc: 0.891026 | Val Loss: 0.105721, Val Acc: 0.793814\n",
      "Epoch 22898 - Train Loss: 0.073271, Train Acc: 0.891026 | Val Loss: 0.105721, Val Acc: 0.793814\n",
      "Epoch 22899 - Train Loss: 0.073270, Train Acc: 0.891026 | Val Loss: 0.105720, Val Acc: 0.793814\n",
      "Epoch 22900 - Train Loss: 0.073268, Train Acc: 0.891026 | Val Loss: 0.105720, Val Acc: 0.793814\n",
      "Epoch 22901 - Train Loss: 0.073266, Train Acc: 0.891026 | Val Loss: 0.105720, Val Acc: 0.793814\n",
      "Epoch 22902 - Train Loss: 0.073265, Train Acc: 0.891026 | Val Loss: 0.105719, Val Acc: 0.793814\n",
      "Epoch 22903 - Train Loss: 0.073263, Train Acc: 0.891026 | Val Loss: 0.105719, Val Acc: 0.793814\n",
      "Epoch 22904 - Train Loss: 0.073261, Train Acc: 0.891026 | Val Loss: 0.105718, Val Acc: 0.793814\n",
      "Epoch 22905 - Train Loss: 0.073260, Train Acc: 0.891026 | Val Loss: 0.105718, Val Acc: 0.793814\n",
      "Epoch 22906 - Train Loss: 0.073258, Train Acc: 0.891026 | Val Loss: 0.105717, Val Acc: 0.793814\n",
      "Epoch 22907 - Train Loss: 0.073256, Train Acc: 0.891026 | Val Loss: 0.105717, Val Acc: 0.793814\n",
      "Epoch 22908 - Train Loss: 0.073255, Train Acc: 0.891026 | Val Loss: 0.105717, Val Acc: 0.793814\n",
      "Epoch 22909 - Train Loss: 0.073253, Train Acc: 0.891026 | Val Loss: 0.105716, Val Acc: 0.793814\n",
      "Epoch 22910 - Train Loss: 0.073251, Train Acc: 0.891026 | Val Loss: 0.105716, Val Acc: 0.793814\n",
      "Epoch 22911 - Train Loss: 0.073250, Train Acc: 0.891026 | Val Loss: 0.105715, Val Acc: 0.793814\n",
      "Epoch 22912 - Train Loss: 0.073248, Train Acc: 0.891026 | Val Loss: 0.105715, Val Acc: 0.793814\n",
      "Epoch 22913 - Train Loss: 0.073247, Train Acc: 0.891026 | Val Loss: 0.105714, Val Acc: 0.793814\n",
      "Epoch 22914 - Train Loss: 0.073245, Train Acc: 0.891026 | Val Loss: 0.105714, Val Acc: 0.793814\n",
      "Epoch 22915 - Train Loss: 0.073243, Train Acc: 0.891026 | Val Loss: 0.105713, Val Acc: 0.793814\n",
      "Epoch 22916 - Train Loss: 0.073242, Train Acc: 0.891026 | Val Loss: 0.105713, Val Acc: 0.793814\n",
      "Epoch 22917 - Train Loss: 0.073240, Train Acc: 0.891026 | Val Loss: 0.105713, Val Acc: 0.793814\n",
      "Epoch 22918 - Train Loss: 0.073238, Train Acc: 0.891026 | Val Loss: 0.105712, Val Acc: 0.793814\n",
      "Epoch 22919 - Train Loss: 0.073237, Train Acc: 0.891026 | Val Loss: 0.105712, Val Acc: 0.793814\n",
      "Epoch 22920 - Train Loss: 0.073235, Train Acc: 0.891026 | Val Loss: 0.105711, Val Acc: 0.793814\n",
      "Epoch 22921 - Train Loss: 0.073234, Train Acc: 0.891026 | Val Loss: 0.105711, Val Acc: 0.793814\n",
      "Epoch 22922 - Train Loss: 0.073232, Train Acc: 0.891026 | Val Loss: 0.105710, Val Acc: 0.793814\n",
      "Epoch 22923 - Train Loss: 0.073230, Train Acc: 0.891026 | Val Loss: 0.105710, Val Acc: 0.793814\n",
      "Epoch 22924 - Train Loss: 0.073229, Train Acc: 0.891026 | Val Loss: 0.105710, Val Acc: 0.793814\n",
      "Epoch 22925 - Train Loss: 0.073227, Train Acc: 0.891026 | Val Loss: 0.105709, Val Acc: 0.793814\n",
      "Epoch 22926 - Train Loss: 0.073225, Train Acc: 0.891026 | Val Loss: 0.105709, Val Acc: 0.793814\n",
      "Epoch 22927 - Train Loss: 0.073224, Train Acc: 0.891026 | Val Loss: 0.105708, Val Acc: 0.793814\n",
      "Epoch 22928 - Train Loss: 0.073222, Train Acc: 0.891026 | Val Loss: 0.105708, Val Acc: 0.793814\n",
      "Epoch 22929 - Train Loss: 0.073220, Train Acc: 0.891026 | Val Loss: 0.105707, Val Acc: 0.793814\n",
      "Epoch 22930 - Train Loss: 0.073219, Train Acc: 0.891026 | Val Loss: 0.105707, Val Acc: 0.793814\n",
      "Epoch 22931 - Train Loss: 0.073217, Train Acc: 0.891026 | Val Loss: 0.105707, Val Acc: 0.793814\n",
      "Epoch 22932 - Train Loss: 0.073216, Train Acc: 0.891026 | Val Loss: 0.105706, Val Acc: 0.793814\n",
      "Epoch 22933 - Train Loss: 0.073214, Train Acc: 0.891026 | Val Loss: 0.105706, Val Acc: 0.793814\n",
      "Epoch 22934 - Train Loss: 0.073212, Train Acc: 0.892308 | Val Loss: 0.105705, Val Acc: 0.793814\n",
      "Epoch 22935 - Train Loss: 0.073211, Train Acc: 0.892308 | Val Loss: 0.105705, Val Acc: 0.793814\n",
      "Epoch 22936 - Train Loss: 0.073209, Train Acc: 0.892308 | Val Loss: 0.105705, Val Acc: 0.793814\n",
      "Epoch 22937 - Train Loss: 0.073207, Train Acc: 0.892308 | Val Loss: 0.105704, Val Acc: 0.793814\n",
      "Epoch 22938 - Train Loss: 0.073206, Train Acc: 0.892308 | Val Loss: 0.105704, Val Acc: 0.793814\n",
      "Epoch 22939 - Train Loss: 0.073204, Train Acc: 0.892308 | Val Loss: 0.105703, Val Acc: 0.793814\n",
      "Epoch 22940 - Train Loss: 0.073202, Train Acc: 0.892308 | Val Loss: 0.105703, Val Acc: 0.793814\n",
      "Epoch 22941 - Train Loss: 0.073201, Train Acc: 0.892308 | Val Loss: 0.105702, Val Acc: 0.793814\n",
      "Epoch 22942 - Train Loss: 0.073199, Train Acc: 0.892308 | Val Loss: 0.105702, Val Acc: 0.793814\n",
      "Epoch 22943 - Train Loss: 0.073198, Train Acc: 0.892308 | Val Loss: 0.105702, Val Acc: 0.793814\n",
      "Epoch 22944 - Train Loss: 0.073196, Train Acc: 0.892308 | Val Loss: 0.105701, Val Acc: 0.793814\n",
      "Epoch 22945 - Train Loss: 0.073194, Train Acc: 0.892308 | Val Loss: 0.105701, Val Acc: 0.793814\n",
      "Epoch 22946 - Train Loss: 0.073193, Train Acc: 0.892308 | Val Loss: 0.105700, Val Acc: 0.793814\n",
      "Epoch 22947 - Train Loss: 0.073191, Train Acc: 0.892308 | Val Loss: 0.105700, Val Acc: 0.793814\n",
      "Epoch 22948 - Train Loss: 0.073189, Train Acc: 0.892308 | Val Loss: 0.105699, Val Acc: 0.793814\n",
      "Epoch 22949 - Train Loss: 0.073188, Train Acc: 0.892308 | Val Loss: 0.105699, Val Acc: 0.793814\n",
      "Epoch 22950 - Train Loss: 0.073186, Train Acc: 0.892308 | Val Loss: 0.105698, Val Acc: 0.793814\n",
      "Epoch 22951 - Train Loss: 0.073185, Train Acc: 0.892308 | Val Loss: 0.105698, Val Acc: 0.793814\n",
      "Epoch 22952 - Train Loss: 0.073183, Train Acc: 0.892308 | Val Loss: 0.105698, Val Acc: 0.793814\n",
      "Epoch 22953 - Train Loss: 0.073181, Train Acc: 0.892308 | Val Loss: 0.105697, Val Acc: 0.793814\n",
      "Epoch 22954 - Train Loss: 0.073180, Train Acc: 0.892308 | Val Loss: 0.105697, Val Acc: 0.793814\n",
      "Epoch 22955 - Train Loss: 0.073178, Train Acc: 0.892308 | Val Loss: 0.105696, Val Acc: 0.793814\n",
      "Epoch 22956 - Train Loss: 0.073176, Train Acc: 0.892308 | Val Loss: 0.105696, Val Acc: 0.793814\n",
      "Epoch 22957 - Train Loss: 0.073175, Train Acc: 0.892308 | Val Loss: 0.105696, Val Acc: 0.793814\n",
      "Epoch 22958 - Train Loss: 0.073173, Train Acc: 0.892308 | Val Loss: 0.105695, Val Acc: 0.793814\n",
      "Epoch 22959 - Train Loss: 0.073172, Train Acc: 0.892308 | Val Loss: 0.105695, Val Acc: 0.793814\n",
      "Epoch 22960 - Train Loss: 0.073170, Train Acc: 0.892308 | Val Loss: 0.105694, Val Acc: 0.793814\n",
      "Epoch 22961 - Train Loss: 0.073168, Train Acc: 0.892308 | Val Loss: 0.105694, Val Acc: 0.793814\n",
      "Epoch 22962 - Train Loss: 0.073167, Train Acc: 0.892308 | Val Loss: 0.105693, Val Acc: 0.793814\n",
      "Epoch 22963 - Train Loss: 0.073165, Train Acc: 0.892308 | Val Loss: 0.105693, Val Acc: 0.793814\n",
      "Epoch 22964 - Train Loss: 0.073163, Train Acc: 0.892308 | Val Loss: 0.105693, Val Acc: 0.793814\n",
      "Epoch 22965 - Train Loss: 0.073162, Train Acc: 0.892308 | Val Loss: 0.105692, Val Acc: 0.793814\n",
      "Epoch 22966 - Train Loss: 0.073160, Train Acc: 0.892308 | Val Loss: 0.105692, Val Acc: 0.793814\n",
      "Epoch 22967 - Train Loss: 0.073158, Train Acc: 0.892308 | Val Loss: 0.105691, Val Acc: 0.793814\n",
      "Epoch 22968 - Train Loss: 0.073157, Train Acc: 0.892308 | Val Loss: 0.105691, Val Acc: 0.793814\n",
      "Epoch 22969 - Train Loss: 0.073155, Train Acc: 0.892308 | Val Loss: 0.105690, Val Acc: 0.793814\n",
      "Epoch 22970 - Train Loss: 0.073154, Train Acc: 0.892308 | Val Loss: 0.105690, Val Acc: 0.793814\n",
      "Epoch 22971 - Train Loss: 0.073152, Train Acc: 0.892308 | Val Loss: 0.105690, Val Acc: 0.793814\n",
      "Epoch 22972 - Train Loss: 0.073150, Train Acc: 0.892308 | Val Loss: 0.105689, Val Acc: 0.793814\n",
      "Epoch 22973 - Train Loss: 0.073149, Train Acc: 0.892308 | Val Loss: 0.105689, Val Acc: 0.793814\n",
      "Epoch 22974 - Train Loss: 0.073147, Train Acc: 0.892308 | Val Loss: 0.105688, Val Acc: 0.793814\n",
      "Epoch 22975 - Train Loss: 0.073145, Train Acc: 0.892308 | Val Loss: 0.105688, Val Acc: 0.793814\n",
      "Epoch 22976 - Train Loss: 0.073144, Train Acc: 0.892308 | Val Loss: 0.105687, Val Acc: 0.793814\n",
      "Epoch 22977 - Train Loss: 0.073142, Train Acc: 0.892308 | Val Loss: 0.105687, Val Acc: 0.793814\n",
      "Epoch 22978 - Train Loss: 0.073141, Train Acc: 0.892308 | Val Loss: 0.105687, Val Acc: 0.793814\n",
      "Epoch 22979 - Train Loss: 0.073139, Train Acc: 0.892308 | Val Loss: 0.105686, Val Acc: 0.793814\n",
      "Epoch 22980 - Train Loss: 0.073137, Train Acc: 0.892308 | Val Loss: 0.105686, Val Acc: 0.793814\n",
      "Epoch 22981 - Train Loss: 0.073136, Train Acc: 0.892308 | Val Loss: 0.105685, Val Acc: 0.793814\n",
      "Epoch 22982 - Train Loss: 0.073134, Train Acc: 0.892308 | Val Loss: 0.105685, Val Acc: 0.793814\n",
      "Epoch 22983 - Train Loss: 0.073132, Train Acc: 0.892308 | Val Loss: 0.105684, Val Acc: 0.793814\n",
      "Epoch 22984 - Train Loss: 0.073131, Train Acc: 0.892308 | Val Loss: 0.105684, Val Acc: 0.793814\n",
      "Epoch 22985 - Train Loss: 0.073129, Train Acc: 0.892308 | Val Loss: 0.105684, Val Acc: 0.793814\n",
      "Epoch 22986 - Train Loss: 0.073128, Train Acc: 0.892308 | Val Loss: 0.105683, Val Acc: 0.793814\n",
      "Epoch 22987 - Train Loss: 0.073126, Train Acc: 0.892308 | Val Loss: 0.105683, Val Acc: 0.793814\n",
      "Epoch 22988 - Train Loss: 0.073124, Train Acc: 0.892308 | Val Loss: 0.105682, Val Acc: 0.793814\n",
      "Epoch 22989 - Train Loss: 0.073123, Train Acc: 0.892308 | Val Loss: 0.105682, Val Acc: 0.793814\n",
      "Epoch 22990 - Train Loss: 0.073121, Train Acc: 0.892308 | Val Loss: 0.105681, Val Acc: 0.793814\n",
      "Epoch 22991 - Train Loss: 0.073119, Train Acc: 0.892308 | Val Loss: 0.105681, Val Acc: 0.793814\n",
      "Epoch 22992 - Train Loss: 0.073118, Train Acc: 0.892308 | Val Loss: 0.105681, Val Acc: 0.793814\n",
      "Epoch 22993 - Train Loss: 0.073116, Train Acc: 0.892308 | Val Loss: 0.105680, Val Acc: 0.793814\n",
      "Epoch 22994 - Train Loss: 0.073115, Train Acc: 0.892308 | Val Loss: 0.105680, Val Acc: 0.793814\n",
      "Epoch 22995 - Train Loss: 0.073113, Train Acc: 0.892308 | Val Loss: 0.105679, Val Acc: 0.793814\n",
      "Epoch 22996 - Train Loss: 0.073111, Train Acc: 0.892308 | Val Loss: 0.105679, Val Acc: 0.793814\n",
      "Epoch 22997 - Train Loss: 0.073110, Train Acc: 0.892308 | Val Loss: 0.105678, Val Acc: 0.793814\n",
      "Epoch 22998 - Train Loss: 0.073108, Train Acc: 0.892308 | Val Loss: 0.105678, Val Acc: 0.793814\n",
      "Epoch 22999 - Train Loss: 0.073106, Train Acc: 0.892308 | Val Loss: 0.105678, Val Acc: 0.793814\n",
      "Epoch 23000 - Train Loss: 0.073105, Train Acc: 0.892308 | Val Loss: 0.105677, Val Acc: 0.793814\n",
      "Epoch 23001 - Train Loss: 0.073103, Train Acc: 0.892308 | Val Loss: 0.105677, Val Acc: 0.793814\n",
      "Epoch 23002 - Train Loss: 0.073102, Train Acc: 0.892308 | Val Loss: 0.105676, Val Acc: 0.793814\n",
      "Epoch 23003 - Train Loss: 0.073100, Train Acc: 0.892308 | Val Loss: 0.105676, Val Acc: 0.793814\n",
      "Epoch 23004 - Train Loss: 0.073098, Train Acc: 0.892308 | Val Loss: 0.105675, Val Acc: 0.793814\n",
      "Epoch 23005 - Train Loss: 0.073097, Train Acc: 0.892308 | Val Loss: 0.105675, Val Acc: 0.793814\n",
      "Epoch 23006 - Train Loss: 0.073095, Train Acc: 0.892308 | Val Loss: 0.105675, Val Acc: 0.793814\n",
      "Epoch 23007 - Train Loss: 0.073093, Train Acc: 0.892308 | Val Loss: 0.105674, Val Acc: 0.793814\n",
      "Epoch 23008 - Train Loss: 0.073092, Train Acc: 0.892308 | Val Loss: 0.105674, Val Acc: 0.793814\n",
      "Epoch 23009 - Train Loss: 0.073090, Train Acc: 0.892308 | Val Loss: 0.105673, Val Acc: 0.793814\n",
      "Epoch 23010 - Train Loss: 0.073089, Train Acc: 0.892308 | Val Loss: 0.105673, Val Acc: 0.793814\n",
      "Epoch 23011 - Train Loss: 0.073087, Train Acc: 0.892308 | Val Loss: 0.105673, Val Acc: 0.793814\n",
      "Epoch 23012 - Train Loss: 0.073085, Train Acc: 0.892308 | Val Loss: 0.105672, Val Acc: 0.793814\n",
      "Epoch 23013 - Train Loss: 0.073084, Train Acc: 0.892308 | Val Loss: 0.105672, Val Acc: 0.793814\n",
      "Epoch 23014 - Train Loss: 0.073082, Train Acc: 0.892308 | Val Loss: 0.105671, Val Acc: 0.793814\n",
      "Epoch 23015 - Train Loss: 0.073080, Train Acc: 0.892308 | Val Loss: 0.105671, Val Acc: 0.793814\n",
      "Epoch 23016 - Train Loss: 0.073079, Train Acc: 0.892308 | Val Loss: 0.105670, Val Acc: 0.793814\n",
      "Epoch 23017 - Train Loss: 0.073077, Train Acc: 0.892308 | Val Loss: 0.105670, Val Acc: 0.793814\n",
      "Epoch 23018 - Train Loss: 0.073076, Train Acc: 0.892308 | Val Loss: 0.105670, Val Acc: 0.793814\n",
      "Epoch 23019 - Train Loss: 0.073074, Train Acc: 0.892308 | Val Loss: 0.105669, Val Acc: 0.793814\n",
      "Epoch 23020 - Train Loss: 0.073072, Train Acc: 0.892308 | Val Loss: 0.105669, Val Acc: 0.793814\n",
      "Epoch 23021 - Train Loss: 0.073071, Train Acc: 0.892308 | Val Loss: 0.105668, Val Acc: 0.793814\n",
      "Epoch 23022 - Train Loss: 0.073069, Train Acc: 0.892308 | Val Loss: 0.105668, Val Acc: 0.793814\n",
      "Epoch 23023 - Train Loss: 0.073068, Train Acc: 0.892308 | Val Loss: 0.105667, Val Acc: 0.793814\n",
      "Epoch 23024 - Train Loss: 0.073066, Train Acc: 0.892308 | Val Loss: 0.105667, Val Acc: 0.793814\n",
      "Epoch 23025 - Train Loss: 0.073064, Train Acc: 0.892308 | Val Loss: 0.105667, Val Acc: 0.793814\n",
      "Epoch 23026 - Train Loss: 0.073063, Train Acc: 0.892308 | Val Loss: 0.105666, Val Acc: 0.793814\n",
      "Epoch 23027 - Train Loss: 0.073061, Train Acc: 0.892308 | Val Loss: 0.105666, Val Acc: 0.793814\n",
      "Epoch 23028 - Train Loss: 0.073059, Train Acc: 0.892308 | Val Loss: 0.105665, Val Acc: 0.793814\n",
      "Epoch 23029 - Train Loss: 0.073058, Train Acc: 0.892308 | Val Loss: 0.105665, Val Acc: 0.793814\n",
      "Epoch 23030 - Train Loss: 0.073056, Train Acc: 0.892308 | Val Loss: 0.105664, Val Acc: 0.793814\n",
      "Epoch 23031 - Train Loss: 0.073055, Train Acc: 0.892308 | Val Loss: 0.105664, Val Acc: 0.793814\n",
      "Epoch 23032 - Train Loss: 0.073053, Train Acc: 0.892308 | Val Loss: 0.105664, Val Acc: 0.793814\n",
      "Epoch 23033 - Train Loss: 0.073051, Train Acc: 0.892308 | Val Loss: 0.105663, Val Acc: 0.793814\n",
      "Epoch 23034 - Train Loss: 0.073050, Train Acc: 0.892308 | Val Loss: 0.105663, Val Acc: 0.793814\n",
      "Epoch 23035 - Train Loss: 0.073048, Train Acc: 0.892308 | Val Loss: 0.105662, Val Acc: 0.793814\n",
      "Epoch 23036 - Train Loss: 0.073046, Train Acc: 0.892308 | Val Loss: 0.105662, Val Acc: 0.793814\n",
      "Epoch 23037 - Train Loss: 0.073045, Train Acc: 0.892308 | Val Loss: 0.105662, Val Acc: 0.793814\n",
      "Epoch 23038 - Train Loss: 0.073043, Train Acc: 0.892308 | Val Loss: 0.105661, Val Acc: 0.793814\n",
      "Epoch 23039 - Train Loss: 0.073042, Train Acc: 0.892308 | Val Loss: 0.105661, Val Acc: 0.793814\n",
      "Epoch 23040 - Train Loss: 0.073040, Train Acc: 0.892308 | Val Loss: 0.105660, Val Acc: 0.793814\n",
      "Epoch 23041 - Train Loss: 0.073038, Train Acc: 0.892308 | Val Loss: 0.105660, Val Acc: 0.793814\n",
      "Epoch 23042 - Train Loss: 0.073037, Train Acc: 0.892308 | Val Loss: 0.105659, Val Acc: 0.793814\n",
      "Epoch 23043 - Train Loss: 0.073035, Train Acc: 0.892308 | Val Loss: 0.105659, Val Acc: 0.793814\n",
      "Epoch 23044 - Train Loss: 0.073034, Train Acc: 0.892308 | Val Loss: 0.105659, Val Acc: 0.793814\n",
      "Epoch 23045 - Train Loss: 0.073032, Train Acc: 0.892308 | Val Loss: 0.105658, Val Acc: 0.793814\n",
      "Epoch 23046 - Train Loss: 0.073030, Train Acc: 0.892308 | Val Loss: 0.105658, Val Acc: 0.793814\n",
      "Epoch 23047 - Train Loss: 0.073029, Train Acc: 0.892308 | Val Loss: 0.105657, Val Acc: 0.793814\n",
      "Epoch 23048 - Train Loss: 0.073027, Train Acc: 0.892308 | Val Loss: 0.105657, Val Acc: 0.793814\n",
      "Epoch 23049 - Train Loss: 0.073025, Train Acc: 0.892308 | Val Loss: 0.105656, Val Acc: 0.793814\n",
      "Epoch 23050 - Train Loss: 0.073024, Train Acc: 0.892308 | Val Loss: 0.105656, Val Acc: 0.793814\n",
      "Epoch 23051 - Train Loss: 0.073022, Train Acc: 0.892308 | Val Loss: 0.105656, Val Acc: 0.793814\n",
      "Epoch 23052 - Train Loss: 0.073021, Train Acc: 0.892308 | Val Loss: 0.105655, Val Acc: 0.793814\n",
      "Epoch 23053 - Train Loss: 0.073019, Train Acc: 0.892308 | Val Loss: 0.105655, Val Acc: 0.793814\n",
      "Epoch 23054 - Train Loss: 0.073017, Train Acc: 0.892308 | Val Loss: 0.105654, Val Acc: 0.793814\n",
      "Epoch 23055 - Train Loss: 0.073016, Train Acc: 0.892308 | Val Loss: 0.105654, Val Acc: 0.793814\n",
      "Epoch 23056 - Train Loss: 0.073014, Train Acc: 0.892308 | Val Loss: 0.105654, Val Acc: 0.793814\n",
      "Epoch 23057 - Train Loss: 0.073012, Train Acc: 0.892308 | Val Loss: 0.105653, Val Acc: 0.793814\n",
      "Epoch 23058 - Train Loss: 0.073011, Train Acc: 0.892308 | Val Loss: 0.105653, Val Acc: 0.793814\n",
      "Epoch 23059 - Train Loss: 0.073009, Train Acc: 0.892308 | Val Loss: 0.105652, Val Acc: 0.793814\n",
      "Epoch 23060 - Train Loss: 0.073008, Train Acc: 0.892308 | Val Loss: 0.105652, Val Acc: 0.793814\n",
      "Epoch 23061 - Train Loss: 0.073006, Train Acc: 0.892308 | Val Loss: 0.105651, Val Acc: 0.793814\n",
      "Epoch 23062 - Train Loss: 0.073004, Train Acc: 0.892308 | Val Loss: 0.105651, Val Acc: 0.793814\n",
      "Epoch 23063 - Train Loss: 0.073003, Train Acc: 0.892308 | Val Loss: 0.105651, Val Acc: 0.793814\n",
      "Epoch 23064 - Train Loss: 0.073001, Train Acc: 0.892308 | Val Loss: 0.105650, Val Acc: 0.793814\n",
      "Epoch 23065 - Train Loss: 0.073000, Train Acc: 0.892308 | Val Loss: 0.105650, Val Acc: 0.793814\n",
      "Epoch 23066 - Train Loss: 0.072998, Train Acc: 0.892308 | Val Loss: 0.105649, Val Acc: 0.793814\n",
      "Epoch 23067 - Train Loss: 0.072996, Train Acc: 0.892308 | Val Loss: 0.105649, Val Acc: 0.793814\n",
      "Epoch 23068 - Train Loss: 0.072995, Train Acc: 0.892308 | Val Loss: 0.105649, Val Acc: 0.793814\n",
      "Epoch 23069 - Train Loss: 0.072993, Train Acc: 0.892308 | Val Loss: 0.105648, Val Acc: 0.793814\n",
      "Epoch 23070 - Train Loss: 0.072991, Train Acc: 0.892308 | Val Loss: 0.105648, Val Acc: 0.793814\n",
      "Epoch 23071 - Train Loss: 0.072990, Train Acc: 0.892308 | Val Loss: 0.105647, Val Acc: 0.793814\n",
      "Epoch 23072 - Train Loss: 0.072988, Train Acc: 0.892308 | Val Loss: 0.105647, Val Acc: 0.793814\n",
      "Epoch 23073 - Train Loss: 0.072987, Train Acc: 0.892308 | Val Loss: 0.105646, Val Acc: 0.793814\n",
      "Epoch 23074 - Train Loss: 0.072985, Train Acc: 0.892308 | Val Loss: 0.105646, Val Acc: 0.793814\n",
      "Epoch 23075 - Train Loss: 0.072983, Train Acc: 0.892308 | Val Loss: 0.105646, Val Acc: 0.793814\n",
      "Epoch 23076 - Train Loss: 0.072982, Train Acc: 0.892308 | Val Loss: 0.105645, Val Acc: 0.793814\n",
      "Epoch 23077 - Train Loss: 0.072980, Train Acc: 0.892308 | Val Loss: 0.105645, Val Acc: 0.793814\n",
      "Epoch 23078 - Train Loss: 0.072979, Train Acc: 0.892308 | Val Loss: 0.105644, Val Acc: 0.793814\n",
      "Epoch 23079 - Train Loss: 0.072977, Train Acc: 0.892308 | Val Loss: 0.105644, Val Acc: 0.793814\n",
      "Epoch 23080 - Train Loss: 0.072975, Train Acc: 0.892308 | Val Loss: 0.105643, Val Acc: 0.793814\n",
      "Epoch 23081 - Train Loss: 0.072974, Train Acc: 0.892308 | Val Loss: 0.105643, Val Acc: 0.793814\n",
      "Epoch 23082 - Train Loss: 0.072972, Train Acc: 0.893590 | Val Loss: 0.105643, Val Acc: 0.793814\n",
      "Epoch 23083 - Train Loss: 0.072971, Train Acc: 0.893590 | Val Loss: 0.105642, Val Acc: 0.793814\n",
      "Epoch 23084 - Train Loss: 0.072969, Train Acc: 0.893590 | Val Loss: 0.105642, Val Acc: 0.793814\n",
      "Epoch 23085 - Train Loss: 0.072967, Train Acc: 0.893590 | Val Loss: 0.105641, Val Acc: 0.793814\n",
      "Epoch 23086 - Train Loss: 0.072966, Train Acc: 0.893590 | Val Loss: 0.105641, Val Acc: 0.793814\n",
      "Epoch 23087 - Train Loss: 0.072964, Train Acc: 0.893590 | Val Loss: 0.105641, Val Acc: 0.793814\n",
      "Epoch 23088 - Train Loss: 0.072962, Train Acc: 0.893590 | Val Loss: 0.105640, Val Acc: 0.793814\n",
      "Epoch 23089 - Train Loss: 0.072961, Train Acc: 0.893590 | Val Loss: 0.105640, Val Acc: 0.793814\n",
      "Epoch 23090 - Train Loss: 0.072959, Train Acc: 0.893590 | Val Loss: 0.105639, Val Acc: 0.793814\n",
      "Epoch 23091 - Train Loss: 0.072958, Train Acc: 0.893590 | Val Loss: 0.105639, Val Acc: 0.793814\n",
      "Epoch 23092 - Train Loss: 0.072956, Train Acc: 0.893590 | Val Loss: 0.105639, Val Acc: 0.793814\n",
      "Epoch 23093 - Train Loss: 0.072954, Train Acc: 0.893590 | Val Loss: 0.105638, Val Acc: 0.793814\n",
      "Epoch 23094 - Train Loss: 0.072953, Train Acc: 0.893590 | Val Loss: 0.105638, Val Acc: 0.793814\n",
      "Epoch 23095 - Train Loss: 0.072951, Train Acc: 0.893590 | Val Loss: 0.105637, Val Acc: 0.793814\n",
      "Epoch 23096 - Train Loss: 0.072950, Train Acc: 0.893590 | Val Loss: 0.105637, Val Acc: 0.793814\n",
      "Epoch 23097 - Train Loss: 0.072948, Train Acc: 0.893590 | Val Loss: 0.105636, Val Acc: 0.793814\n",
      "Epoch 23098 - Train Loss: 0.072946, Train Acc: 0.893590 | Val Loss: 0.105636, Val Acc: 0.793814\n",
      "Epoch 23099 - Train Loss: 0.072945, Train Acc: 0.893590 | Val Loss: 0.105636, Val Acc: 0.793814\n",
      "Epoch 23100 - Train Loss: 0.072943, Train Acc: 0.893590 | Val Loss: 0.105635, Val Acc: 0.793814\n",
      "Epoch 23101 - Train Loss: 0.072941, Train Acc: 0.893590 | Val Loss: 0.105635, Val Acc: 0.793814\n",
      "Epoch 23102 - Train Loss: 0.072940, Train Acc: 0.893590 | Val Loss: 0.105634, Val Acc: 0.793814\n",
      "Epoch 23103 - Train Loss: 0.072938, Train Acc: 0.893590 | Val Loss: 0.105634, Val Acc: 0.793814\n",
      "Epoch 23104 - Train Loss: 0.072937, Train Acc: 0.893590 | Val Loss: 0.105633, Val Acc: 0.793814\n",
      "Epoch 23105 - Train Loss: 0.072935, Train Acc: 0.893590 | Val Loss: 0.105633, Val Acc: 0.793814\n",
      "Epoch 23106 - Train Loss: 0.072933, Train Acc: 0.893590 | Val Loss: 0.105633, Val Acc: 0.793814\n",
      "Epoch 23107 - Train Loss: 0.072932, Train Acc: 0.893590 | Val Loss: 0.105632, Val Acc: 0.793814\n",
      "Epoch 23108 - Train Loss: 0.072930, Train Acc: 0.893590 | Val Loss: 0.105632, Val Acc: 0.793814\n",
      "Epoch 23109 - Train Loss: 0.072929, Train Acc: 0.893590 | Val Loss: 0.105632, Val Acc: 0.793814\n",
      "Epoch 23110 - Train Loss: 0.072927, Train Acc: 0.893590 | Val Loss: 0.105631, Val Acc: 0.793814\n",
      "Epoch 23111 - Train Loss: 0.072925, Train Acc: 0.893590 | Val Loss: 0.105631, Val Acc: 0.793814\n",
      "Epoch 23112 - Train Loss: 0.072924, Train Acc: 0.893590 | Val Loss: 0.105630, Val Acc: 0.793814\n",
      "Epoch 23113 - Train Loss: 0.072922, Train Acc: 0.893590 | Val Loss: 0.105630, Val Acc: 0.793814\n",
      "Epoch 23114 - Train Loss: 0.072921, Train Acc: 0.893590 | Val Loss: 0.105629, Val Acc: 0.793814\n",
      "Epoch 23115 - Train Loss: 0.072919, Train Acc: 0.893590 | Val Loss: 0.105629, Val Acc: 0.793814\n",
      "Epoch 23116 - Train Loss: 0.072917, Train Acc: 0.893590 | Val Loss: 0.105629, Val Acc: 0.793814\n",
      "Epoch 23117 - Train Loss: 0.072916, Train Acc: 0.893590 | Val Loss: 0.105628, Val Acc: 0.793814\n",
      "Epoch 23118 - Train Loss: 0.072914, Train Acc: 0.893590 | Val Loss: 0.105628, Val Acc: 0.793814\n",
      "Epoch 23119 - Train Loss: 0.072913, Train Acc: 0.893590 | Val Loss: 0.105627, Val Acc: 0.793814\n",
      "Epoch 23120 - Train Loss: 0.072911, Train Acc: 0.893590 | Val Loss: 0.105627, Val Acc: 0.793814\n",
      "Epoch 23121 - Train Loss: 0.072909, Train Acc: 0.893590 | Val Loss: 0.105627, Val Acc: 0.793814\n",
      "Epoch 23122 - Train Loss: 0.072908, Train Acc: 0.893590 | Val Loss: 0.105626, Val Acc: 0.793814\n",
      "Epoch 23123 - Train Loss: 0.072906, Train Acc: 0.893590 | Val Loss: 0.105626, Val Acc: 0.793814\n",
      "Epoch 23124 - Train Loss: 0.072904, Train Acc: 0.893590 | Val Loss: 0.105625, Val Acc: 0.793814\n",
      "Epoch 23125 - Train Loss: 0.072903, Train Acc: 0.893590 | Val Loss: 0.105625, Val Acc: 0.793814\n",
      "Epoch 23126 - Train Loss: 0.072901, Train Acc: 0.893590 | Val Loss: 0.105624, Val Acc: 0.793814\n",
      "Epoch 23127 - Train Loss: 0.072900, Train Acc: 0.893590 | Val Loss: 0.105624, Val Acc: 0.793814\n",
      "Epoch 23128 - Train Loss: 0.072898, Train Acc: 0.893590 | Val Loss: 0.105624, Val Acc: 0.793814\n",
      "Epoch 23129 - Train Loss: 0.072896, Train Acc: 0.893590 | Val Loss: 0.105623, Val Acc: 0.793814\n",
      "Epoch 23130 - Train Loss: 0.072895, Train Acc: 0.893590 | Val Loss: 0.105623, Val Acc: 0.793814\n",
      "Epoch 23131 - Train Loss: 0.072893, Train Acc: 0.893590 | Val Loss: 0.105622, Val Acc: 0.793814\n",
      "Epoch 23132 - Train Loss: 0.072892, Train Acc: 0.893590 | Val Loss: 0.105622, Val Acc: 0.793814\n",
      "Epoch 23133 - Train Loss: 0.072890, Train Acc: 0.893590 | Val Loss: 0.105622, Val Acc: 0.793814\n",
      "Epoch 23134 - Train Loss: 0.072888, Train Acc: 0.893590 | Val Loss: 0.105621, Val Acc: 0.793814\n",
      "Epoch 23135 - Train Loss: 0.072887, Train Acc: 0.893590 | Val Loss: 0.105621, Val Acc: 0.793814\n",
      "Epoch 23136 - Train Loss: 0.072885, Train Acc: 0.893590 | Val Loss: 0.105620, Val Acc: 0.793814\n",
      "Epoch 23137 - Train Loss: 0.072884, Train Acc: 0.893590 | Val Loss: 0.105620, Val Acc: 0.793814\n",
      "Epoch 23138 - Train Loss: 0.072882, Train Acc: 0.893590 | Val Loss: 0.105619, Val Acc: 0.793814\n",
      "Epoch 23139 - Train Loss: 0.072880, Train Acc: 0.893590 | Val Loss: 0.105619, Val Acc: 0.793814\n",
      "Epoch 23140 - Train Loss: 0.072879, Train Acc: 0.893590 | Val Loss: 0.105619, Val Acc: 0.793814\n",
      "Epoch 23141 - Train Loss: 0.072877, Train Acc: 0.893590 | Val Loss: 0.105618, Val Acc: 0.793814\n",
      "Epoch 23142 - Train Loss: 0.072876, Train Acc: 0.893590 | Val Loss: 0.105618, Val Acc: 0.793814\n",
      "Epoch 23143 - Train Loss: 0.072874, Train Acc: 0.893590 | Val Loss: 0.105617, Val Acc: 0.793814\n",
      "Epoch 23144 - Train Loss: 0.072872, Train Acc: 0.893590 | Val Loss: 0.105617, Val Acc: 0.793814\n",
      "Epoch 23145 - Train Loss: 0.072871, Train Acc: 0.893590 | Val Loss: 0.105617, Val Acc: 0.793814\n",
      "Epoch 23146 - Train Loss: 0.072869, Train Acc: 0.893590 | Val Loss: 0.105616, Val Acc: 0.793814\n",
      "Epoch 23147 - Train Loss: 0.072868, Train Acc: 0.893590 | Val Loss: 0.105616, Val Acc: 0.793814\n",
      "Epoch 23148 - Train Loss: 0.072866, Train Acc: 0.893590 | Val Loss: 0.105615, Val Acc: 0.793814\n",
      "Epoch 23149 - Train Loss: 0.072864, Train Acc: 0.893590 | Val Loss: 0.105615, Val Acc: 0.793814\n",
      "Epoch 23150 - Train Loss: 0.072863, Train Acc: 0.893590 | Val Loss: 0.105615, Val Acc: 0.793814\n",
      "Epoch 23151 - Train Loss: 0.072861, Train Acc: 0.893590 | Val Loss: 0.105614, Val Acc: 0.793814\n",
      "Epoch 23152 - Train Loss: 0.072860, Train Acc: 0.893590 | Val Loss: 0.105614, Val Acc: 0.793814\n",
      "Epoch 23153 - Train Loss: 0.072858, Train Acc: 0.893590 | Val Loss: 0.105613, Val Acc: 0.793814\n",
      "Epoch 23154 - Train Loss: 0.072856, Train Acc: 0.893590 | Val Loss: 0.105613, Val Acc: 0.793814\n",
      "Epoch 23155 - Train Loss: 0.072855, Train Acc: 0.893590 | Val Loss: 0.105612, Val Acc: 0.793814\n",
      "Epoch 23156 - Train Loss: 0.072853, Train Acc: 0.893590 | Val Loss: 0.105612, Val Acc: 0.793814\n",
      "Epoch 23157 - Train Loss: 0.072852, Train Acc: 0.893590 | Val Loss: 0.105612, Val Acc: 0.793814\n",
      "Epoch 23158 - Train Loss: 0.072850, Train Acc: 0.893590 | Val Loss: 0.105611, Val Acc: 0.793814\n",
      "Epoch 23159 - Train Loss: 0.072848, Train Acc: 0.893590 | Val Loss: 0.105611, Val Acc: 0.793814\n",
      "Epoch 23160 - Train Loss: 0.072847, Train Acc: 0.893590 | Val Loss: 0.105610, Val Acc: 0.793814\n",
      "Epoch 23161 - Train Loss: 0.072845, Train Acc: 0.893590 | Val Loss: 0.105610, Val Acc: 0.793814\n",
      "Epoch 23162 - Train Loss: 0.072843, Train Acc: 0.893590 | Val Loss: 0.105610, Val Acc: 0.793814\n",
      "Epoch 23163 - Train Loss: 0.072842, Train Acc: 0.893590 | Val Loss: 0.105609, Val Acc: 0.793814\n",
      "Epoch 23164 - Train Loss: 0.072840, Train Acc: 0.893590 | Val Loss: 0.105609, Val Acc: 0.793814\n",
      "Epoch 23165 - Train Loss: 0.072839, Train Acc: 0.893590 | Val Loss: 0.105608, Val Acc: 0.793814\n",
      "Epoch 23166 - Train Loss: 0.072837, Train Acc: 0.893590 | Val Loss: 0.105608, Val Acc: 0.793814\n",
      "Epoch 23167 - Train Loss: 0.072835, Train Acc: 0.893590 | Val Loss: 0.105608, Val Acc: 0.793814\n",
      "Epoch 23168 - Train Loss: 0.072834, Train Acc: 0.893590 | Val Loss: 0.105607, Val Acc: 0.793814\n",
      "Epoch 23169 - Train Loss: 0.072832, Train Acc: 0.893590 | Val Loss: 0.105607, Val Acc: 0.793814\n",
      "Epoch 23170 - Train Loss: 0.072831, Train Acc: 0.893590 | Val Loss: 0.105606, Val Acc: 0.793814\n",
      "Epoch 23171 - Train Loss: 0.072829, Train Acc: 0.893590 | Val Loss: 0.105606, Val Acc: 0.793814\n",
      "Epoch 23172 - Train Loss: 0.072827, Train Acc: 0.893590 | Val Loss: 0.105606, Val Acc: 0.793814\n",
      "Epoch 23173 - Train Loss: 0.072826, Train Acc: 0.893590 | Val Loss: 0.105605, Val Acc: 0.793814\n",
      "Epoch 23174 - Train Loss: 0.072824, Train Acc: 0.893590 | Val Loss: 0.105605, Val Acc: 0.793814\n",
      "Epoch 23175 - Train Loss: 0.072823, Train Acc: 0.893590 | Val Loss: 0.105604, Val Acc: 0.793814\n",
      "Epoch 23176 - Train Loss: 0.072821, Train Acc: 0.893590 | Val Loss: 0.105604, Val Acc: 0.793814\n",
      "Epoch 23177 - Train Loss: 0.072819, Train Acc: 0.893590 | Val Loss: 0.105604, Val Acc: 0.793814\n",
      "Epoch 23178 - Train Loss: 0.072818, Train Acc: 0.893590 | Val Loss: 0.105603, Val Acc: 0.793814\n",
      "Epoch 23179 - Train Loss: 0.072816, Train Acc: 0.893590 | Val Loss: 0.105603, Val Acc: 0.793814\n",
      "Epoch 23180 - Train Loss: 0.072815, Train Acc: 0.893590 | Val Loss: 0.105602, Val Acc: 0.793814\n",
      "Epoch 23181 - Train Loss: 0.072813, Train Acc: 0.893590 | Val Loss: 0.105602, Val Acc: 0.793814\n",
      "Epoch 23182 - Train Loss: 0.072811, Train Acc: 0.893590 | Val Loss: 0.105602, Val Acc: 0.793814\n",
      "Epoch 23183 - Train Loss: 0.072810, Train Acc: 0.893590 | Val Loss: 0.105601, Val Acc: 0.793814\n",
      "Epoch 23184 - Train Loss: 0.072808, Train Acc: 0.893590 | Val Loss: 0.105601, Val Acc: 0.793814\n",
      "Epoch 23185 - Train Loss: 0.072807, Train Acc: 0.893590 | Val Loss: 0.105600, Val Acc: 0.793814\n",
      "Epoch 23186 - Train Loss: 0.072805, Train Acc: 0.893590 | Val Loss: 0.105600, Val Acc: 0.793814\n",
      "Epoch 23187 - Train Loss: 0.072803, Train Acc: 0.893590 | Val Loss: 0.105599, Val Acc: 0.793814\n",
      "Epoch 23188 - Train Loss: 0.072802, Train Acc: 0.893590 | Val Loss: 0.105599, Val Acc: 0.793814\n",
      "Epoch 23189 - Train Loss: 0.072800, Train Acc: 0.893590 | Val Loss: 0.105599, Val Acc: 0.793814\n",
      "Epoch 23190 - Train Loss: 0.072799, Train Acc: 0.893590 | Val Loss: 0.105598, Val Acc: 0.793814\n",
      "Epoch 23191 - Train Loss: 0.072797, Train Acc: 0.893590 | Val Loss: 0.105598, Val Acc: 0.793814\n",
      "Epoch 23192 - Train Loss: 0.072795, Train Acc: 0.893590 | Val Loss: 0.105597, Val Acc: 0.793814\n",
      "Epoch 23193 - Train Loss: 0.072794, Train Acc: 0.893590 | Val Loss: 0.105597, Val Acc: 0.793814\n",
      "Epoch 23194 - Train Loss: 0.072792, Train Acc: 0.893590 | Val Loss: 0.105597, Val Acc: 0.793814\n",
      "Epoch 23195 - Train Loss: 0.072791, Train Acc: 0.893590 | Val Loss: 0.105596, Val Acc: 0.793814\n",
      "Epoch 23196 - Train Loss: 0.072789, Train Acc: 0.893590 | Val Loss: 0.105596, Val Acc: 0.793814\n",
      "Epoch 23197 - Train Loss: 0.072787, Train Acc: 0.893590 | Val Loss: 0.105595, Val Acc: 0.793814\n",
      "Epoch 23198 - Train Loss: 0.072786, Train Acc: 0.893590 | Val Loss: 0.105595, Val Acc: 0.793814\n",
      "Epoch 23199 - Train Loss: 0.072784, Train Acc: 0.893590 | Val Loss: 0.105595, Val Acc: 0.793814\n",
      "Epoch 23200 - Train Loss: 0.072783, Train Acc: 0.893590 | Val Loss: 0.105594, Val Acc: 0.793814\n",
      "Epoch 23201 - Train Loss: 0.072781, Train Acc: 0.893590 | Val Loss: 0.105594, Val Acc: 0.793814\n",
      "Epoch 23202 - Train Loss: 0.072779, Train Acc: 0.893590 | Val Loss: 0.105593, Val Acc: 0.793814\n",
      "Epoch 23203 - Train Loss: 0.072778, Train Acc: 0.893590 | Val Loss: 0.105593, Val Acc: 0.793814\n",
      "Epoch 23204 - Train Loss: 0.072776, Train Acc: 0.893590 | Val Loss: 0.105593, Val Acc: 0.793814\n",
      "Epoch 23205 - Train Loss: 0.072775, Train Acc: 0.893590 | Val Loss: 0.105592, Val Acc: 0.793814\n",
      "Epoch 23206 - Train Loss: 0.072773, Train Acc: 0.893590 | Val Loss: 0.105592, Val Acc: 0.793814\n",
      "Epoch 23207 - Train Loss: 0.072771, Train Acc: 0.893590 | Val Loss: 0.105591, Val Acc: 0.793814\n",
      "Epoch 23208 - Train Loss: 0.072770, Train Acc: 0.893590 | Val Loss: 0.105591, Val Acc: 0.793814\n",
      "Epoch 23209 - Train Loss: 0.072768, Train Acc: 0.893590 | Val Loss: 0.105591, Val Acc: 0.793814\n",
      "Epoch 23210 - Train Loss: 0.072767, Train Acc: 0.893590 | Val Loss: 0.105590, Val Acc: 0.793814\n",
      "Epoch 23211 - Train Loss: 0.072765, Train Acc: 0.893590 | Val Loss: 0.105590, Val Acc: 0.793814\n",
      "Epoch 23212 - Train Loss: 0.072763, Train Acc: 0.893590 | Val Loss: 0.105589, Val Acc: 0.793814\n",
      "Epoch 23213 - Train Loss: 0.072762, Train Acc: 0.893590 | Val Loss: 0.105589, Val Acc: 0.793814\n",
      "Epoch 23214 - Train Loss: 0.072760, Train Acc: 0.893590 | Val Loss: 0.105589, Val Acc: 0.793814\n",
      "Epoch 23215 - Train Loss: 0.072759, Train Acc: 0.893590 | Val Loss: 0.105588, Val Acc: 0.793814\n",
      "Epoch 23216 - Train Loss: 0.072757, Train Acc: 0.893590 | Val Loss: 0.105588, Val Acc: 0.793814\n",
      "Epoch 23217 - Train Loss: 0.072756, Train Acc: 0.893590 | Val Loss: 0.105587, Val Acc: 0.793814\n",
      "Epoch 23218 - Train Loss: 0.072754, Train Acc: 0.893590 | Val Loss: 0.105587, Val Acc: 0.793814\n",
      "Epoch 23219 - Train Loss: 0.072752, Train Acc: 0.893590 | Val Loss: 0.105587, Val Acc: 0.793814\n",
      "Epoch 23220 - Train Loss: 0.072751, Train Acc: 0.893590 | Val Loss: 0.105586, Val Acc: 0.793814\n",
      "Epoch 23221 - Train Loss: 0.072749, Train Acc: 0.893590 | Val Loss: 0.105586, Val Acc: 0.793814\n",
      "Epoch 23222 - Train Loss: 0.072748, Train Acc: 0.893590 | Val Loss: 0.105585, Val Acc: 0.793814\n",
      "Epoch 23223 - Train Loss: 0.072746, Train Acc: 0.893590 | Val Loss: 0.105585, Val Acc: 0.793814\n",
      "Epoch 23224 - Train Loss: 0.072744, Train Acc: 0.893590 | Val Loss: 0.105585, Val Acc: 0.793814\n",
      "Epoch 23225 - Train Loss: 0.072743, Train Acc: 0.893590 | Val Loss: 0.105584, Val Acc: 0.793814\n",
      "Epoch 23226 - Train Loss: 0.072741, Train Acc: 0.893590 | Val Loss: 0.105584, Val Acc: 0.793814\n",
      "Epoch 23227 - Train Loss: 0.072740, Train Acc: 0.893590 | Val Loss: 0.105583, Val Acc: 0.793814\n",
      "Epoch 23228 - Train Loss: 0.072738, Train Acc: 0.893590 | Val Loss: 0.105583, Val Acc: 0.793814\n",
      "Epoch 23229 - Train Loss: 0.072736, Train Acc: 0.893590 | Val Loss: 0.105583, Val Acc: 0.793814\n",
      "Epoch 23230 - Train Loss: 0.072735, Train Acc: 0.893590 | Val Loss: 0.105582, Val Acc: 0.793814\n",
      "Epoch 23231 - Train Loss: 0.072733, Train Acc: 0.893590 | Val Loss: 0.105582, Val Acc: 0.793814\n",
      "Epoch 23232 - Train Loss: 0.072732, Train Acc: 0.893590 | Val Loss: 0.105581, Val Acc: 0.793814\n",
      "Epoch 23233 - Train Loss: 0.072730, Train Acc: 0.893590 | Val Loss: 0.105581, Val Acc: 0.793814\n",
      "Epoch 23234 - Train Loss: 0.072728, Train Acc: 0.893590 | Val Loss: 0.105581, Val Acc: 0.793814\n",
      "Epoch 23235 - Train Loss: 0.072727, Train Acc: 0.893590 | Val Loss: 0.105580, Val Acc: 0.793814\n",
      "Epoch 23236 - Train Loss: 0.072725, Train Acc: 0.893590 | Val Loss: 0.105580, Val Acc: 0.793814\n",
      "Epoch 23237 - Train Loss: 0.072724, Train Acc: 0.893590 | Val Loss: 0.105579, Val Acc: 0.793814\n",
      "Epoch 23238 - Train Loss: 0.072722, Train Acc: 0.893590 | Val Loss: 0.105579, Val Acc: 0.793814\n",
      "Epoch 23239 - Train Loss: 0.072720, Train Acc: 0.893590 | Val Loss: 0.105579, Val Acc: 0.793814\n",
      "Epoch 23240 - Train Loss: 0.072719, Train Acc: 0.893590 | Val Loss: 0.105578, Val Acc: 0.793814\n",
      "Epoch 23241 - Train Loss: 0.072717, Train Acc: 0.893590 | Val Loss: 0.105578, Val Acc: 0.793814\n",
      "Epoch 23242 - Train Loss: 0.072716, Train Acc: 0.893590 | Val Loss: 0.105577, Val Acc: 0.793814\n",
      "Epoch 23243 - Train Loss: 0.072714, Train Acc: 0.893590 | Val Loss: 0.105577, Val Acc: 0.793814\n",
      "Epoch 23244 - Train Loss: 0.072712, Train Acc: 0.893590 | Val Loss: 0.105577, Val Acc: 0.793814\n",
      "Epoch 23245 - Train Loss: 0.072711, Train Acc: 0.893590 | Val Loss: 0.105576, Val Acc: 0.793814\n",
      "Epoch 23246 - Train Loss: 0.072709, Train Acc: 0.893590 | Val Loss: 0.105576, Val Acc: 0.793814\n",
      "Epoch 23247 - Train Loss: 0.072708, Train Acc: 0.893590 | Val Loss: 0.105575, Val Acc: 0.793814\n",
      "Epoch 23248 - Train Loss: 0.072706, Train Acc: 0.893590 | Val Loss: 0.105575, Val Acc: 0.793814\n",
      "Epoch 23249 - Train Loss: 0.072705, Train Acc: 0.893590 | Val Loss: 0.105575, Val Acc: 0.793814\n",
      "Epoch 23250 - Train Loss: 0.072703, Train Acc: 0.893590 | Val Loss: 0.105574, Val Acc: 0.793814\n",
      "Epoch 23251 - Train Loss: 0.072701, Train Acc: 0.893590 | Val Loss: 0.105574, Val Acc: 0.793814\n",
      "Epoch 23252 - Train Loss: 0.072700, Train Acc: 0.893590 | Val Loss: 0.105573, Val Acc: 0.793814\n",
      "Epoch 23253 - Train Loss: 0.072698, Train Acc: 0.893590 | Val Loss: 0.105573, Val Acc: 0.793814\n",
      "Epoch 23254 - Train Loss: 0.072697, Train Acc: 0.893590 | Val Loss: 0.105573, Val Acc: 0.793814\n",
      "Epoch 23255 - Train Loss: 0.072695, Train Acc: 0.893590 | Val Loss: 0.105572, Val Acc: 0.793814\n",
      "Epoch 23256 - Train Loss: 0.072693, Train Acc: 0.893590 | Val Loss: 0.105572, Val Acc: 0.793814\n",
      "Epoch 23257 - Train Loss: 0.072692, Train Acc: 0.893590 | Val Loss: 0.105571, Val Acc: 0.793814\n",
      "Epoch 23258 - Train Loss: 0.072690, Train Acc: 0.893590 | Val Loss: 0.105571, Val Acc: 0.793814\n",
      "Epoch 23259 - Train Loss: 0.072689, Train Acc: 0.893590 | Val Loss: 0.105571, Val Acc: 0.793814\n",
      "Epoch 23260 - Train Loss: 0.072687, Train Acc: 0.893590 | Val Loss: 0.105570, Val Acc: 0.793814\n",
      "Epoch 23261 - Train Loss: 0.072685, Train Acc: 0.893590 | Val Loss: 0.105570, Val Acc: 0.793814\n",
      "Epoch 23262 - Train Loss: 0.072684, Train Acc: 0.893590 | Val Loss: 0.105569, Val Acc: 0.793814\n",
      "Epoch 23263 - Train Loss: 0.072682, Train Acc: 0.893590 | Val Loss: 0.105569, Val Acc: 0.793814\n",
      "Epoch 23264 - Train Loss: 0.072681, Train Acc: 0.893590 | Val Loss: 0.105569, Val Acc: 0.793814\n",
      "Epoch 23265 - Train Loss: 0.072679, Train Acc: 0.893590 | Val Loss: 0.105568, Val Acc: 0.793814\n",
      "Epoch 23266 - Train Loss: 0.072677, Train Acc: 0.893590 | Val Loss: 0.105568, Val Acc: 0.793814\n",
      "Epoch 23267 - Train Loss: 0.072676, Train Acc: 0.893590 | Val Loss: 0.105567, Val Acc: 0.793814\n",
      "Epoch 23268 - Train Loss: 0.072674, Train Acc: 0.893590 | Val Loss: 0.105567, Val Acc: 0.793814\n",
      "Epoch 23269 - Train Loss: 0.072673, Train Acc: 0.893590 | Val Loss: 0.105567, Val Acc: 0.793814\n",
      "Epoch 23270 - Train Loss: 0.072671, Train Acc: 0.893590 | Val Loss: 0.105566, Val Acc: 0.793814\n",
      "Epoch 23271 - Train Loss: 0.072670, Train Acc: 0.893590 | Val Loss: 0.105566, Val Acc: 0.793814\n",
      "Epoch 23272 - Train Loss: 0.072668, Train Acc: 0.893590 | Val Loss: 0.105566, Val Acc: 0.793814\n",
      "Epoch 23273 - Train Loss: 0.072666, Train Acc: 0.893590 | Val Loss: 0.105565, Val Acc: 0.793814\n",
      "Epoch 23274 - Train Loss: 0.072665, Train Acc: 0.893590 | Val Loss: 0.105565, Val Acc: 0.793814\n",
      "Epoch 23275 - Train Loss: 0.072663, Train Acc: 0.893590 | Val Loss: 0.105564, Val Acc: 0.793814\n",
      "Epoch 23276 - Train Loss: 0.072662, Train Acc: 0.893590 | Val Loss: 0.105564, Val Acc: 0.793814\n",
      "Epoch 23277 - Train Loss: 0.072660, Train Acc: 0.893590 | Val Loss: 0.105563, Val Acc: 0.793814\n",
      "Epoch 23278 - Train Loss: 0.072658, Train Acc: 0.893590 | Val Loss: 0.105563, Val Acc: 0.793814\n",
      "Epoch 23279 - Train Loss: 0.072657, Train Acc: 0.893590 | Val Loss: 0.105563, Val Acc: 0.793814\n",
      "Epoch 23280 - Train Loss: 0.072655, Train Acc: 0.893590 | Val Loss: 0.105562, Val Acc: 0.793814\n",
      "Epoch 23281 - Train Loss: 0.072654, Train Acc: 0.893590 | Val Loss: 0.105562, Val Acc: 0.793814\n",
      "Epoch 23282 - Train Loss: 0.072652, Train Acc: 0.893590 | Val Loss: 0.105561, Val Acc: 0.793814\n",
      "Epoch 23283 - Train Loss: 0.072650, Train Acc: 0.893590 | Val Loss: 0.105561, Val Acc: 0.793814\n",
      "Epoch 23284 - Train Loss: 0.072649, Train Acc: 0.893590 | Val Loss: 0.105561, Val Acc: 0.793814\n",
      "Epoch 23285 - Train Loss: 0.072647, Train Acc: 0.893590 | Val Loss: 0.105560, Val Acc: 0.793814\n",
      "Epoch 23286 - Train Loss: 0.072646, Train Acc: 0.893590 | Val Loss: 0.105560, Val Acc: 0.793814\n",
      "Epoch 23287 - Train Loss: 0.072644, Train Acc: 0.893590 | Val Loss: 0.105560, Val Acc: 0.793814\n",
      "Epoch 23288 - Train Loss: 0.072643, Train Acc: 0.893590 | Val Loss: 0.105559, Val Acc: 0.793814\n",
      "Epoch 23289 - Train Loss: 0.072641, Train Acc: 0.893590 | Val Loss: 0.105559, Val Acc: 0.793814\n",
      "Epoch 23290 - Train Loss: 0.072639, Train Acc: 0.893590 | Val Loss: 0.105558, Val Acc: 0.793814\n",
      "Epoch 23291 - Train Loss: 0.072638, Train Acc: 0.893590 | Val Loss: 0.105558, Val Acc: 0.793814\n",
      "Epoch 23292 - Train Loss: 0.072636, Train Acc: 0.893590 | Val Loss: 0.105558, Val Acc: 0.793814\n",
      "Epoch 23293 - Train Loss: 0.072635, Train Acc: 0.893590 | Val Loss: 0.105557, Val Acc: 0.793814\n",
      "Epoch 23294 - Train Loss: 0.072633, Train Acc: 0.893590 | Val Loss: 0.105557, Val Acc: 0.793814\n",
      "Epoch 23295 - Train Loss: 0.072631, Train Acc: 0.893590 | Val Loss: 0.105556, Val Acc: 0.793814\n",
      "Epoch 23296 - Train Loss: 0.072630, Train Acc: 0.893590 | Val Loss: 0.105556, Val Acc: 0.793814\n",
      "Epoch 23297 - Train Loss: 0.072628, Train Acc: 0.893590 | Val Loss: 0.105556, Val Acc: 0.793814\n",
      "Epoch 23298 - Train Loss: 0.072627, Train Acc: 0.893590 | Val Loss: 0.105555, Val Acc: 0.793814\n",
      "Epoch 23299 - Train Loss: 0.072625, Train Acc: 0.893590 | Val Loss: 0.105555, Val Acc: 0.793814\n",
      "Epoch 23300 - Train Loss: 0.072623, Train Acc: 0.893590 | Val Loss: 0.105554, Val Acc: 0.793814\n",
      "Epoch 23301 - Train Loss: 0.072622, Train Acc: 0.893590 | Val Loss: 0.105554, Val Acc: 0.793814\n",
      "Epoch 23302 - Train Loss: 0.072620, Train Acc: 0.893590 | Val Loss: 0.105554, Val Acc: 0.793814\n",
      "Epoch 23303 - Train Loss: 0.072619, Train Acc: 0.893590 | Val Loss: 0.105553, Val Acc: 0.793814\n",
      "Epoch 23304 - Train Loss: 0.072617, Train Acc: 0.893590 | Val Loss: 0.105553, Val Acc: 0.793814\n",
      "Epoch 23305 - Train Loss: 0.072616, Train Acc: 0.893590 | Val Loss: 0.105553, Val Acc: 0.793814\n",
      "Epoch 23306 - Train Loss: 0.072614, Train Acc: 0.893590 | Val Loss: 0.105552, Val Acc: 0.793814\n",
      "Epoch 23307 - Train Loss: 0.072612, Train Acc: 0.893590 | Val Loss: 0.105552, Val Acc: 0.793814\n",
      "Epoch 23308 - Train Loss: 0.072611, Train Acc: 0.893590 | Val Loss: 0.105551, Val Acc: 0.793814\n",
      "Epoch 23309 - Train Loss: 0.072609, Train Acc: 0.893590 | Val Loss: 0.105551, Val Acc: 0.793814\n",
      "Epoch 23310 - Train Loss: 0.072608, Train Acc: 0.893590 | Val Loss: 0.105551, Val Acc: 0.793814\n",
      "Epoch 23311 - Train Loss: 0.072606, Train Acc: 0.893590 | Val Loss: 0.105550, Val Acc: 0.793814\n",
      "Epoch 23312 - Train Loss: 0.072604, Train Acc: 0.893590 | Val Loss: 0.105550, Val Acc: 0.793814\n",
      "Epoch 23313 - Train Loss: 0.072603, Train Acc: 0.893590 | Val Loss: 0.105549, Val Acc: 0.793814\n",
      "Epoch 23314 - Train Loss: 0.072601, Train Acc: 0.893590 | Val Loss: 0.105549, Val Acc: 0.793814\n",
      "Epoch 23315 - Train Loss: 0.072600, Train Acc: 0.893590 | Val Loss: 0.105549, Val Acc: 0.793814\n",
      "Epoch 23316 - Train Loss: 0.072598, Train Acc: 0.893590 | Val Loss: 0.105548, Val Acc: 0.793814\n",
      "Epoch 23317 - Train Loss: 0.072597, Train Acc: 0.893590 | Val Loss: 0.105548, Val Acc: 0.793814\n",
      "Epoch 23318 - Train Loss: 0.072595, Train Acc: 0.893590 | Val Loss: 0.105547, Val Acc: 0.793814\n",
      "Epoch 23319 - Train Loss: 0.072593, Train Acc: 0.893590 | Val Loss: 0.105547, Val Acc: 0.793814\n",
      "Epoch 23320 - Train Loss: 0.072592, Train Acc: 0.893590 | Val Loss: 0.105547, Val Acc: 0.793814\n",
      "Epoch 23321 - Train Loss: 0.072590, Train Acc: 0.893590 | Val Loss: 0.105546, Val Acc: 0.793814\n",
      "Epoch 23322 - Train Loss: 0.072589, Train Acc: 0.893590 | Val Loss: 0.105546, Val Acc: 0.793814\n",
      "Epoch 23323 - Train Loss: 0.072587, Train Acc: 0.893590 | Val Loss: 0.105546, Val Acc: 0.793814\n",
      "Epoch 23324 - Train Loss: 0.072585, Train Acc: 0.893590 | Val Loss: 0.105545, Val Acc: 0.793814\n",
      "Epoch 23325 - Train Loss: 0.072584, Train Acc: 0.893590 | Val Loss: 0.105545, Val Acc: 0.793814\n",
      "Epoch 23326 - Train Loss: 0.072582, Train Acc: 0.893590 | Val Loss: 0.105544, Val Acc: 0.793814\n",
      "Epoch 23327 - Train Loss: 0.072581, Train Acc: 0.893590 | Val Loss: 0.105544, Val Acc: 0.793814\n",
      "Epoch 23328 - Train Loss: 0.072579, Train Acc: 0.893590 | Val Loss: 0.105544, Val Acc: 0.793814\n",
      "Epoch 23329 - Train Loss: 0.072578, Train Acc: 0.893590 | Val Loss: 0.105543, Val Acc: 0.793814\n",
      "Epoch 23330 - Train Loss: 0.072576, Train Acc: 0.893590 | Val Loss: 0.105543, Val Acc: 0.793814\n",
      "Epoch 23331 - Train Loss: 0.072574, Train Acc: 0.893590 | Val Loss: 0.105542, Val Acc: 0.793814\n",
      "Epoch 23332 - Train Loss: 0.072573, Train Acc: 0.893590 | Val Loss: 0.105542, Val Acc: 0.793814\n",
      "Epoch 23333 - Train Loss: 0.072571, Train Acc: 0.893590 | Val Loss: 0.105542, Val Acc: 0.793814\n",
      "Epoch 23334 - Train Loss: 0.072570, Train Acc: 0.893590 | Val Loss: 0.105541, Val Acc: 0.793814\n",
      "Epoch 23335 - Train Loss: 0.072568, Train Acc: 0.893590 | Val Loss: 0.105541, Val Acc: 0.793814\n",
      "Epoch 23336 - Train Loss: 0.072567, Train Acc: 0.893590 | Val Loss: 0.105541, Val Acc: 0.793814\n",
      "Epoch 23337 - Train Loss: 0.072565, Train Acc: 0.893590 | Val Loss: 0.105540, Val Acc: 0.793814\n",
      "Epoch 23338 - Train Loss: 0.072563, Train Acc: 0.893590 | Val Loss: 0.105540, Val Acc: 0.793814\n",
      "Epoch 23339 - Train Loss: 0.072562, Train Acc: 0.893590 | Val Loss: 0.105539, Val Acc: 0.793814\n",
      "Epoch 23340 - Train Loss: 0.072560, Train Acc: 0.893590 | Val Loss: 0.105539, Val Acc: 0.793814\n",
      "Epoch 23341 - Train Loss: 0.072559, Train Acc: 0.893590 | Val Loss: 0.105539, Val Acc: 0.793814\n",
      "Epoch 23342 - Train Loss: 0.072557, Train Acc: 0.893590 | Val Loss: 0.105538, Val Acc: 0.793814\n",
      "Epoch 23343 - Train Loss: 0.072555, Train Acc: 0.893590 | Val Loss: 0.105538, Val Acc: 0.793814\n",
      "Epoch 23344 - Train Loss: 0.072554, Train Acc: 0.893590 | Val Loss: 0.105537, Val Acc: 0.793814\n",
      "Epoch 23345 - Train Loss: 0.072552, Train Acc: 0.893590 | Val Loss: 0.105537, Val Acc: 0.793814\n",
      "Epoch 23346 - Train Loss: 0.072551, Train Acc: 0.893590 | Val Loss: 0.105537, Val Acc: 0.793814\n",
      "Epoch 23347 - Train Loss: 0.072549, Train Acc: 0.893590 | Val Loss: 0.105536, Val Acc: 0.793814\n",
      "Epoch 23348 - Train Loss: 0.072548, Train Acc: 0.893590 | Val Loss: 0.105536, Val Acc: 0.793814\n",
      "Epoch 23349 - Train Loss: 0.072546, Train Acc: 0.893590 | Val Loss: 0.105536, Val Acc: 0.793814\n",
      "Epoch 23350 - Train Loss: 0.072544, Train Acc: 0.893590 | Val Loss: 0.105535, Val Acc: 0.793814\n",
      "Epoch 23351 - Train Loss: 0.072543, Train Acc: 0.893590 | Val Loss: 0.105535, Val Acc: 0.793814\n",
      "Epoch 23352 - Train Loss: 0.072541, Train Acc: 0.893590 | Val Loss: 0.105534, Val Acc: 0.793814\n",
      "Epoch 23353 - Train Loss: 0.072540, Train Acc: 0.893590 | Val Loss: 0.105534, Val Acc: 0.793814\n",
      "Epoch 23354 - Train Loss: 0.072538, Train Acc: 0.893590 | Val Loss: 0.105534, Val Acc: 0.793814\n",
      "Epoch 23355 - Train Loss: 0.072537, Train Acc: 0.893590 | Val Loss: 0.105533, Val Acc: 0.793814\n",
      "Epoch 23356 - Train Loss: 0.072535, Train Acc: 0.893590 | Val Loss: 0.105533, Val Acc: 0.793814\n",
      "Epoch 23357 - Train Loss: 0.072533, Train Acc: 0.893590 | Val Loss: 0.105532, Val Acc: 0.793814\n",
      "Epoch 23358 - Train Loss: 0.072532, Train Acc: 0.893590 | Val Loss: 0.105532, Val Acc: 0.793814\n",
      "Epoch 23359 - Train Loss: 0.072530, Train Acc: 0.893590 | Val Loss: 0.105532, Val Acc: 0.793814\n",
      "Epoch 23360 - Train Loss: 0.072529, Train Acc: 0.893590 | Val Loss: 0.105531, Val Acc: 0.793814\n",
      "Epoch 23361 - Train Loss: 0.072527, Train Acc: 0.893590 | Val Loss: 0.105531, Val Acc: 0.793814\n",
      "Epoch 23362 - Train Loss: 0.072525, Train Acc: 0.893590 | Val Loss: 0.105530, Val Acc: 0.793814\n",
      "Epoch 23363 - Train Loss: 0.072524, Train Acc: 0.893590 | Val Loss: 0.105530, Val Acc: 0.793814\n",
      "Epoch 23364 - Train Loss: 0.072522, Train Acc: 0.893590 | Val Loss: 0.105530, Val Acc: 0.793814\n",
      "Epoch 23365 - Train Loss: 0.072521, Train Acc: 0.893590 | Val Loss: 0.105529, Val Acc: 0.793814\n",
      "Epoch 23366 - Train Loss: 0.072519, Train Acc: 0.893590 | Val Loss: 0.105529, Val Acc: 0.793814\n",
      "Epoch 23367 - Train Loss: 0.072518, Train Acc: 0.893590 | Val Loss: 0.105529, Val Acc: 0.793814\n",
      "Epoch 23368 - Train Loss: 0.072516, Train Acc: 0.893590 | Val Loss: 0.105528, Val Acc: 0.793814\n",
      "Epoch 23369 - Train Loss: 0.072514, Train Acc: 0.893590 | Val Loss: 0.105528, Val Acc: 0.793814\n",
      "Epoch 23370 - Train Loss: 0.072513, Train Acc: 0.893590 | Val Loss: 0.105527, Val Acc: 0.793814\n",
      "Epoch 23371 - Train Loss: 0.072511, Train Acc: 0.893590 | Val Loss: 0.105527, Val Acc: 0.793814\n",
      "Epoch 23372 - Train Loss: 0.072510, Train Acc: 0.893590 | Val Loss: 0.105527, Val Acc: 0.793814\n",
      "Epoch 23373 - Train Loss: 0.072508, Train Acc: 0.893590 | Val Loss: 0.105526, Val Acc: 0.793814\n",
      "Epoch 23374 - Train Loss: 0.072507, Train Acc: 0.893590 | Val Loss: 0.105526, Val Acc: 0.793814\n",
      "Epoch 23375 - Train Loss: 0.072505, Train Acc: 0.893590 | Val Loss: 0.105526, Val Acc: 0.793814\n",
      "Epoch 23376 - Train Loss: 0.072503, Train Acc: 0.893590 | Val Loss: 0.105525, Val Acc: 0.793814\n",
      "Epoch 23377 - Train Loss: 0.072502, Train Acc: 0.893590 | Val Loss: 0.105525, Val Acc: 0.793814\n",
      "Epoch 23378 - Train Loss: 0.072500, Train Acc: 0.893590 | Val Loss: 0.105524, Val Acc: 0.793814\n",
      "Epoch 23379 - Train Loss: 0.072499, Train Acc: 0.893590 | Val Loss: 0.105524, Val Acc: 0.793814\n",
      "Epoch 23380 - Train Loss: 0.072497, Train Acc: 0.893590 | Val Loss: 0.105524, Val Acc: 0.793814\n",
      "Epoch 23381 - Train Loss: 0.072496, Train Acc: 0.893590 | Val Loss: 0.105523, Val Acc: 0.793814\n",
      "Epoch 23382 - Train Loss: 0.072494, Train Acc: 0.893590 | Val Loss: 0.105523, Val Acc: 0.793814\n",
      "Epoch 23383 - Train Loss: 0.072492, Train Acc: 0.893590 | Val Loss: 0.105522, Val Acc: 0.793814\n",
      "Epoch 23384 - Train Loss: 0.072491, Train Acc: 0.893590 | Val Loss: 0.105522, Val Acc: 0.793814\n",
      "Epoch 23385 - Train Loss: 0.072489, Train Acc: 0.893590 | Val Loss: 0.105522, Val Acc: 0.793814\n",
      "Epoch 23386 - Train Loss: 0.072488, Train Acc: 0.893590 | Val Loss: 0.105521, Val Acc: 0.793814\n",
      "Epoch 23387 - Train Loss: 0.072486, Train Acc: 0.893590 | Val Loss: 0.105521, Val Acc: 0.793814\n",
      "Epoch 23388 - Train Loss: 0.072485, Train Acc: 0.893590 | Val Loss: 0.105521, Val Acc: 0.793814\n",
      "Epoch 23389 - Train Loss: 0.072483, Train Acc: 0.893590 | Val Loss: 0.105520, Val Acc: 0.793814\n",
      "Epoch 23390 - Train Loss: 0.072481, Train Acc: 0.893590 | Val Loss: 0.105520, Val Acc: 0.793814\n",
      "Epoch 23391 - Train Loss: 0.072480, Train Acc: 0.893590 | Val Loss: 0.105519, Val Acc: 0.793814\n",
      "Epoch 23392 - Train Loss: 0.072478, Train Acc: 0.893590 | Val Loss: 0.105519, Val Acc: 0.793814\n",
      "Epoch 23393 - Train Loss: 0.072477, Train Acc: 0.893590 | Val Loss: 0.105519, Val Acc: 0.793814\n",
      "Epoch 23394 - Train Loss: 0.072475, Train Acc: 0.893590 | Val Loss: 0.105518, Val Acc: 0.793814\n",
      "Epoch 23395 - Train Loss: 0.072473, Train Acc: 0.893590 | Val Loss: 0.105518, Val Acc: 0.793814\n",
      "Epoch 23396 - Train Loss: 0.072472, Train Acc: 0.893590 | Val Loss: 0.105517, Val Acc: 0.793814\n",
      "Epoch 23397 - Train Loss: 0.072470, Train Acc: 0.893590 | Val Loss: 0.105517, Val Acc: 0.793814\n",
      "Epoch 23398 - Train Loss: 0.072469, Train Acc: 0.893590 | Val Loss: 0.105517, Val Acc: 0.793814\n",
      "Epoch 23399 - Train Loss: 0.072467, Train Acc: 0.893590 | Val Loss: 0.105516, Val Acc: 0.793814\n",
      "Epoch 23400 - Train Loss: 0.072466, Train Acc: 0.893590 | Val Loss: 0.105516, Val Acc: 0.793814\n",
      "Epoch 23401 - Train Loss: 0.072464, Train Acc: 0.893590 | Val Loss: 0.105516, Val Acc: 0.793814\n",
      "Epoch 23402 - Train Loss: 0.072462, Train Acc: 0.893590 | Val Loss: 0.105515, Val Acc: 0.793814\n",
      "Epoch 23403 - Train Loss: 0.072461, Train Acc: 0.893590 | Val Loss: 0.105515, Val Acc: 0.793814\n",
      "Epoch 23404 - Train Loss: 0.072459, Train Acc: 0.893590 | Val Loss: 0.105514, Val Acc: 0.793814\n",
      "Epoch 23405 - Train Loss: 0.072458, Train Acc: 0.893590 | Val Loss: 0.105514, Val Acc: 0.793814\n",
      "Epoch 23406 - Train Loss: 0.072456, Train Acc: 0.893590 | Val Loss: 0.105514, Val Acc: 0.793814\n",
      "Epoch 23407 - Train Loss: 0.072455, Train Acc: 0.893590 | Val Loss: 0.105513, Val Acc: 0.793814\n",
      "Epoch 23408 - Train Loss: 0.072453, Train Acc: 0.893590 | Val Loss: 0.105513, Val Acc: 0.793814\n",
      "Epoch 23409 - Train Loss: 0.072451, Train Acc: 0.893590 | Val Loss: 0.105513, Val Acc: 0.793814\n",
      "Epoch 23410 - Train Loss: 0.072450, Train Acc: 0.893590 | Val Loss: 0.105512, Val Acc: 0.793814\n",
      "Epoch 23411 - Train Loss: 0.072448, Train Acc: 0.893590 | Val Loss: 0.105512, Val Acc: 0.793814\n",
      "Epoch 23412 - Train Loss: 0.072447, Train Acc: 0.893590 | Val Loss: 0.105511, Val Acc: 0.793814\n",
      "Epoch 23413 - Train Loss: 0.072445, Train Acc: 0.893590 | Val Loss: 0.105511, Val Acc: 0.793814\n",
      "Epoch 23414 - Train Loss: 0.072444, Train Acc: 0.893590 | Val Loss: 0.105511, Val Acc: 0.793814\n",
      "Epoch 23415 - Train Loss: 0.072442, Train Acc: 0.893590 | Val Loss: 0.105510, Val Acc: 0.793814\n",
      "Epoch 23416 - Train Loss: 0.072440, Train Acc: 0.893590 | Val Loss: 0.105510, Val Acc: 0.793814\n",
      "Epoch 23417 - Train Loss: 0.072439, Train Acc: 0.893590 | Val Loss: 0.105509, Val Acc: 0.793814\n",
      "Epoch 23418 - Train Loss: 0.072437, Train Acc: 0.893590 | Val Loss: 0.105509, Val Acc: 0.793814\n",
      "Epoch 23419 - Train Loss: 0.072436, Train Acc: 0.894872 | Val Loss: 0.105509, Val Acc: 0.793814\n",
      "Epoch 23420 - Train Loss: 0.072434, Train Acc: 0.894872 | Val Loss: 0.105508, Val Acc: 0.793814\n",
      "Epoch 23421 - Train Loss: 0.072433, Train Acc: 0.894872 | Val Loss: 0.105508, Val Acc: 0.793814\n",
      "Epoch 23422 - Train Loss: 0.072431, Train Acc: 0.894872 | Val Loss: 0.105508, Val Acc: 0.793814\n",
      "Epoch 23423 - Train Loss: 0.072429, Train Acc: 0.894872 | Val Loss: 0.105507, Val Acc: 0.793814\n",
      "Epoch 23424 - Train Loss: 0.072428, Train Acc: 0.894872 | Val Loss: 0.105507, Val Acc: 0.793814\n",
      "Epoch 23425 - Train Loss: 0.072426, Train Acc: 0.894872 | Val Loss: 0.105506, Val Acc: 0.793814\n",
      "Epoch 23426 - Train Loss: 0.072425, Train Acc: 0.894872 | Val Loss: 0.105506, Val Acc: 0.793814\n",
      "Epoch 23427 - Train Loss: 0.072423, Train Acc: 0.894872 | Val Loss: 0.105506, Val Acc: 0.793814\n",
      "Epoch 23428 - Train Loss: 0.072422, Train Acc: 0.894872 | Val Loss: 0.105505, Val Acc: 0.793814\n",
      "Epoch 23429 - Train Loss: 0.072420, Train Acc: 0.894872 | Val Loss: 0.105505, Val Acc: 0.793814\n",
      "Epoch 23430 - Train Loss: 0.072419, Train Acc: 0.894872 | Val Loss: 0.105505, Val Acc: 0.793814\n",
      "Epoch 23431 - Train Loss: 0.072417, Train Acc: 0.894872 | Val Loss: 0.105504, Val Acc: 0.793814\n",
      "Epoch 23432 - Train Loss: 0.072415, Train Acc: 0.894872 | Val Loss: 0.105504, Val Acc: 0.793814\n",
      "Epoch 23433 - Train Loss: 0.072414, Train Acc: 0.894872 | Val Loss: 0.105503, Val Acc: 0.793814\n",
      "Epoch 23434 - Train Loss: 0.072412, Train Acc: 0.894872 | Val Loss: 0.105503, Val Acc: 0.793814\n",
      "Epoch 23435 - Train Loss: 0.072411, Train Acc: 0.894872 | Val Loss: 0.105503, Val Acc: 0.793814\n",
      "Epoch 23436 - Train Loss: 0.072409, Train Acc: 0.894872 | Val Loss: 0.105502, Val Acc: 0.793814\n",
      "Epoch 23437 - Train Loss: 0.072408, Train Acc: 0.894872 | Val Loss: 0.105502, Val Acc: 0.793814\n",
      "Epoch 23438 - Train Loss: 0.072406, Train Acc: 0.894872 | Val Loss: 0.105502, Val Acc: 0.793814\n",
      "Epoch 23439 - Train Loss: 0.072404, Train Acc: 0.894872 | Val Loss: 0.105501, Val Acc: 0.793814\n",
      "Epoch 23440 - Train Loss: 0.072403, Train Acc: 0.894872 | Val Loss: 0.105501, Val Acc: 0.793814\n",
      "Epoch 23441 - Train Loss: 0.072401, Train Acc: 0.894872 | Val Loss: 0.105500, Val Acc: 0.793814\n",
      "Epoch 23442 - Train Loss: 0.072400, Train Acc: 0.894872 | Val Loss: 0.105500, Val Acc: 0.793814\n",
      "Epoch 23443 - Train Loss: 0.072398, Train Acc: 0.894872 | Val Loss: 0.105500, Val Acc: 0.793814\n",
      "Epoch 23444 - Train Loss: 0.072397, Train Acc: 0.894872 | Val Loss: 0.105499, Val Acc: 0.793814\n",
      "Epoch 23445 - Train Loss: 0.072395, Train Acc: 0.894872 | Val Loss: 0.105499, Val Acc: 0.793814\n",
      "Epoch 23446 - Train Loss: 0.072393, Train Acc: 0.894872 | Val Loss: 0.105499, Val Acc: 0.793814\n",
      "Epoch 23447 - Train Loss: 0.072392, Train Acc: 0.894872 | Val Loss: 0.105498, Val Acc: 0.793814\n",
      "Epoch 23448 - Train Loss: 0.072390, Train Acc: 0.894872 | Val Loss: 0.105498, Val Acc: 0.793814\n",
      "Epoch 23449 - Train Loss: 0.072389, Train Acc: 0.894872 | Val Loss: 0.105498, Val Acc: 0.793814\n",
      "Epoch 23450 - Train Loss: 0.072387, Train Acc: 0.894872 | Val Loss: 0.105497, Val Acc: 0.793814\n",
      "Epoch 23451 - Train Loss: 0.072386, Train Acc: 0.894872 | Val Loss: 0.105497, Val Acc: 0.793814\n",
      "Epoch 23452 - Train Loss: 0.072384, Train Acc: 0.894872 | Val Loss: 0.105496, Val Acc: 0.793814\n",
      "Epoch 23453 - Train Loss: 0.072382, Train Acc: 0.894872 | Val Loss: 0.105496, Val Acc: 0.793814\n",
      "Epoch 23454 - Train Loss: 0.072381, Train Acc: 0.894872 | Val Loss: 0.105496, Val Acc: 0.793814\n",
      "Epoch 23455 - Train Loss: 0.072379, Train Acc: 0.894872 | Val Loss: 0.105495, Val Acc: 0.793814\n",
      "Epoch 23456 - Train Loss: 0.072378, Train Acc: 0.894872 | Val Loss: 0.105495, Val Acc: 0.793814\n",
      "Epoch 23457 - Train Loss: 0.072376, Train Acc: 0.894872 | Val Loss: 0.105495, Val Acc: 0.793814\n",
      "Epoch 23458 - Train Loss: 0.072375, Train Acc: 0.894872 | Val Loss: 0.105494, Val Acc: 0.793814\n",
      "Epoch 23459 - Train Loss: 0.072373, Train Acc: 0.894872 | Val Loss: 0.105494, Val Acc: 0.793814\n",
      "Epoch 23460 - Train Loss: 0.072372, Train Acc: 0.894872 | Val Loss: 0.105493, Val Acc: 0.793814\n",
      "Epoch 23461 - Train Loss: 0.072370, Train Acc: 0.894872 | Val Loss: 0.105493, Val Acc: 0.793814\n",
      "Epoch 23462 - Train Loss: 0.072368, Train Acc: 0.894872 | Val Loss: 0.105493, Val Acc: 0.793814\n",
      "Epoch 23463 - Train Loss: 0.072367, Train Acc: 0.894872 | Val Loss: 0.105492, Val Acc: 0.793814\n",
      "Epoch 23464 - Train Loss: 0.072365, Train Acc: 0.894872 | Val Loss: 0.105492, Val Acc: 0.793814\n",
      "Epoch 23465 - Train Loss: 0.072364, Train Acc: 0.894872 | Val Loss: 0.105492, Val Acc: 0.793814\n",
      "Epoch 23466 - Train Loss: 0.072362, Train Acc: 0.894872 | Val Loss: 0.105491, Val Acc: 0.793814\n",
      "Epoch 23467 - Train Loss: 0.072361, Train Acc: 0.894872 | Val Loss: 0.105491, Val Acc: 0.793814\n",
      "Epoch 23468 - Train Loss: 0.072359, Train Acc: 0.894872 | Val Loss: 0.105490, Val Acc: 0.793814\n",
      "Epoch 23469 - Train Loss: 0.072357, Train Acc: 0.894872 | Val Loss: 0.105490, Val Acc: 0.793814\n",
      "Epoch 23470 - Train Loss: 0.072356, Train Acc: 0.894872 | Val Loss: 0.105490, Val Acc: 0.793814\n",
      "Epoch 23471 - Train Loss: 0.072354, Train Acc: 0.894872 | Val Loss: 0.105489, Val Acc: 0.793814\n",
      "Epoch 23472 - Train Loss: 0.072353, Train Acc: 0.894872 | Val Loss: 0.105489, Val Acc: 0.793814\n",
      "Epoch 23473 - Train Loss: 0.072351, Train Acc: 0.894872 | Val Loss: 0.105489, Val Acc: 0.793814\n",
      "Epoch 23474 - Train Loss: 0.072350, Train Acc: 0.894872 | Val Loss: 0.105488, Val Acc: 0.793814\n",
      "Epoch 23475 - Train Loss: 0.072348, Train Acc: 0.894872 | Val Loss: 0.105488, Val Acc: 0.793814\n",
      "Epoch 23476 - Train Loss: 0.072347, Train Acc: 0.894872 | Val Loss: 0.105487, Val Acc: 0.793814\n",
      "Epoch 23477 - Train Loss: 0.072345, Train Acc: 0.894872 | Val Loss: 0.105487, Val Acc: 0.793814\n",
      "Epoch 23478 - Train Loss: 0.072343, Train Acc: 0.894872 | Val Loss: 0.105487, Val Acc: 0.793814\n",
      "Epoch 23479 - Train Loss: 0.072342, Train Acc: 0.894872 | Val Loss: 0.105486, Val Acc: 0.793814\n",
      "Epoch 23480 - Train Loss: 0.072340, Train Acc: 0.894872 | Val Loss: 0.105486, Val Acc: 0.793814\n",
      "Epoch 23481 - Train Loss: 0.072339, Train Acc: 0.894872 | Val Loss: 0.105486, Val Acc: 0.793814\n",
      "Epoch 23482 - Train Loss: 0.072337, Train Acc: 0.894872 | Val Loss: 0.105485, Val Acc: 0.793814\n",
      "Epoch 23483 - Train Loss: 0.072336, Train Acc: 0.894872 | Val Loss: 0.105485, Val Acc: 0.793814\n",
      "Epoch 23484 - Train Loss: 0.072334, Train Acc: 0.894872 | Val Loss: 0.105484, Val Acc: 0.793814\n",
      "Epoch 23485 - Train Loss: 0.072332, Train Acc: 0.894872 | Val Loss: 0.105484, Val Acc: 0.793814\n",
      "Epoch 23486 - Train Loss: 0.072331, Train Acc: 0.894872 | Val Loss: 0.105484, Val Acc: 0.793814\n",
      "Epoch 23487 - Train Loss: 0.072329, Train Acc: 0.894872 | Val Loss: 0.105483, Val Acc: 0.793814\n",
      "Epoch 23488 - Train Loss: 0.072328, Train Acc: 0.894872 | Val Loss: 0.105483, Val Acc: 0.793814\n",
      "Epoch 23489 - Train Loss: 0.072326, Train Acc: 0.894872 | Val Loss: 0.105483, Val Acc: 0.793814\n",
      "Epoch 23490 - Train Loss: 0.072325, Train Acc: 0.894872 | Val Loss: 0.105482, Val Acc: 0.793814\n",
      "Epoch 23491 - Train Loss: 0.072323, Train Acc: 0.894872 | Val Loss: 0.105482, Val Acc: 0.793814\n",
      "Epoch 23492 - Train Loss: 0.072322, Train Acc: 0.894872 | Val Loss: 0.105482, Val Acc: 0.793814\n",
      "Epoch 23493 - Train Loss: 0.072320, Train Acc: 0.894872 | Val Loss: 0.105481, Val Acc: 0.793814\n",
      "Epoch 23494 - Train Loss: 0.072318, Train Acc: 0.894872 | Val Loss: 0.105481, Val Acc: 0.793814\n",
      "Epoch 23495 - Train Loss: 0.072317, Train Acc: 0.894872 | Val Loss: 0.105480, Val Acc: 0.793814\n",
      "Epoch 23496 - Train Loss: 0.072315, Train Acc: 0.894872 | Val Loss: 0.105480, Val Acc: 0.793814\n",
      "Epoch 23497 - Train Loss: 0.072314, Train Acc: 0.894872 | Val Loss: 0.105480, Val Acc: 0.793814\n",
      "Epoch 23498 - Train Loss: 0.072312, Train Acc: 0.894872 | Val Loss: 0.105479, Val Acc: 0.793814\n",
      "Epoch 23499 - Train Loss: 0.072311, Train Acc: 0.894872 | Val Loss: 0.105479, Val Acc: 0.793814\n",
      "Epoch 23500 - Train Loss: 0.072309, Train Acc: 0.894872 | Val Loss: 0.105479, Val Acc: 0.793814\n",
      "Epoch 23501 - Train Loss: 0.072307, Train Acc: 0.894872 | Val Loss: 0.105478, Val Acc: 0.793814\n",
      "Epoch 23502 - Train Loss: 0.072306, Train Acc: 0.894872 | Val Loss: 0.105478, Val Acc: 0.793814\n",
      "Epoch 23503 - Train Loss: 0.072304, Train Acc: 0.894872 | Val Loss: 0.105477, Val Acc: 0.793814\n",
      "Epoch 23504 - Train Loss: 0.072303, Train Acc: 0.894872 | Val Loss: 0.105477, Val Acc: 0.793814\n",
      "Epoch 23505 - Train Loss: 0.072301, Train Acc: 0.894872 | Val Loss: 0.105477, Val Acc: 0.793814\n",
      "Epoch 23506 - Train Loss: 0.072300, Train Acc: 0.894872 | Val Loss: 0.105476, Val Acc: 0.793814\n",
      "Epoch 23507 - Train Loss: 0.072298, Train Acc: 0.894872 | Val Loss: 0.105476, Val Acc: 0.793814\n",
      "Epoch 23508 - Train Loss: 0.072297, Train Acc: 0.894872 | Val Loss: 0.105476, Val Acc: 0.793814\n",
      "Epoch 23509 - Train Loss: 0.072295, Train Acc: 0.894872 | Val Loss: 0.105475, Val Acc: 0.793814\n",
      "Epoch 23510 - Train Loss: 0.072293, Train Acc: 0.894872 | Val Loss: 0.105475, Val Acc: 0.793814\n",
      "Epoch 23511 - Train Loss: 0.072292, Train Acc: 0.894872 | Val Loss: 0.105475, Val Acc: 0.793814\n",
      "Epoch 23512 - Train Loss: 0.072290, Train Acc: 0.894872 | Val Loss: 0.105474, Val Acc: 0.793814\n",
      "Epoch 23513 - Train Loss: 0.072289, Train Acc: 0.894872 | Val Loss: 0.105474, Val Acc: 0.793814\n",
      "Epoch 23514 - Train Loss: 0.072287, Train Acc: 0.894872 | Val Loss: 0.105474, Val Acc: 0.793814\n",
      "Epoch 23515 - Train Loss: 0.072286, Train Acc: 0.894872 | Val Loss: 0.105473, Val Acc: 0.793814\n",
      "Epoch 23516 - Train Loss: 0.072284, Train Acc: 0.894872 | Val Loss: 0.105473, Val Acc: 0.793814\n",
      "Epoch 23517 - Train Loss: 0.072283, Train Acc: 0.894872 | Val Loss: 0.105472, Val Acc: 0.793814\n",
      "Epoch 23518 - Train Loss: 0.072281, Train Acc: 0.894872 | Val Loss: 0.105472, Val Acc: 0.793814\n",
      "Epoch 23519 - Train Loss: 0.072279, Train Acc: 0.894872 | Val Loss: 0.105472, Val Acc: 0.793814\n",
      "Epoch 23520 - Train Loss: 0.072278, Train Acc: 0.894872 | Val Loss: 0.105471, Val Acc: 0.793814\n",
      "Epoch 23521 - Train Loss: 0.072276, Train Acc: 0.894872 | Val Loss: 0.105471, Val Acc: 0.793814\n",
      "Epoch 23522 - Train Loss: 0.072275, Train Acc: 0.894872 | Val Loss: 0.105471, Val Acc: 0.793814\n",
      "Epoch 23523 - Train Loss: 0.072273, Train Acc: 0.894872 | Val Loss: 0.105470, Val Acc: 0.793814\n",
      "Epoch 23524 - Train Loss: 0.072272, Train Acc: 0.894872 | Val Loss: 0.105470, Val Acc: 0.793814\n",
      "Epoch 23525 - Train Loss: 0.072270, Train Acc: 0.894872 | Val Loss: 0.105470, Val Acc: 0.793814\n",
      "Epoch 23526 - Train Loss: 0.072269, Train Acc: 0.894872 | Val Loss: 0.105469, Val Acc: 0.793814\n",
      "Epoch 23527 - Train Loss: 0.072267, Train Acc: 0.894872 | Val Loss: 0.105469, Val Acc: 0.793814\n",
      "Epoch 23528 - Train Loss: 0.072265, Train Acc: 0.894872 | Val Loss: 0.105468, Val Acc: 0.793814\n",
      "Epoch 23529 - Train Loss: 0.072264, Train Acc: 0.894872 | Val Loss: 0.105468, Val Acc: 0.793814\n",
      "Epoch 23530 - Train Loss: 0.072262, Train Acc: 0.894872 | Val Loss: 0.105468, Val Acc: 0.793814\n",
      "Epoch 23531 - Train Loss: 0.072261, Train Acc: 0.894872 | Val Loss: 0.105467, Val Acc: 0.793814\n",
      "Epoch 23532 - Train Loss: 0.072259, Train Acc: 0.894872 | Val Loss: 0.105467, Val Acc: 0.793814\n",
      "Epoch 23533 - Train Loss: 0.072258, Train Acc: 0.894872 | Val Loss: 0.105467, Val Acc: 0.793814\n",
      "Epoch 23534 - Train Loss: 0.072256, Train Acc: 0.894872 | Val Loss: 0.105466, Val Acc: 0.793814\n",
      "Epoch 23535 - Train Loss: 0.072255, Train Acc: 0.894872 | Val Loss: 0.105466, Val Acc: 0.793814\n",
      "Epoch 23536 - Train Loss: 0.072253, Train Acc: 0.894872 | Val Loss: 0.105466, Val Acc: 0.793814\n",
      "Epoch 23537 - Train Loss: 0.072251, Train Acc: 0.894872 | Val Loss: 0.105465, Val Acc: 0.793814\n",
      "Epoch 23538 - Train Loss: 0.072250, Train Acc: 0.894872 | Val Loss: 0.105465, Val Acc: 0.793814\n",
      "Epoch 23539 - Train Loss: 0.072248, Train Acc: 0.894872 | Val Loss: 0.105465, Val Acc: 0.793814\n",
      "Epoch 23540 - Train Loss: 0.072247, Train Acc: 0.894872 | Val Loss: 0.105464, Val Acc: 0.793814\n",
      "Epoch 23541 - Train Loss: 0.072245, Train Acc: 0.894872 | Val Loss: 0.105464, Val Acc: 0.793814\n",
      "Epoch 23542 - Train Loss: 0.072244, Train Acc: 0.894872 | Val Loss: 0.105463, Val Acc: 0.793814\n",
      "Epoch 23543 - Train Loss: 0.072242, Train Acc: 0.894872 | Val Loss: 0.105463, Val Acc: 0.793814\n",
      "Epoch 23544 - Train Loss: 0.072241, Train Acc: 0.894872 | Val Loss: 0.105463, Val Acc: 0.793814\n",
      "Epoch 23545 - Train Loss: 0.072239, Train Acc: 0.894872 | Val Loss: 0.105462, Val Acc: 0.793814\n",
      "Epoch 23546 - Train Loss: 0.072237, Train Acc: 0.894872 | Val Loss: 0.105462, Val Acc: 0.793814\n",
      "Epoch 23547 - Train Loss: 0.072236, Train Acc: 0.894872 | Val Loss: 0.105462, Val Acc: 0.793814\n",
      "Epoch 23548 - Train Loss: 0.072234, Train Acc: 0.894872 | Val Loss: 0.105461, Val Acc: 0.793814\n",
      "Epoch 23549 - Train Loss: 0.072233, Train Acc: 0.894872 | Val Loss: 0.105461, Val Acc: 0.793814\n",
      "Epoch 23550 - Train Loss: 0.072231, Train Acc: 0.894872 | Val Loss: 0.105460, Val Acc: 0.793814\n",
      "Epoch 23551 - Train Loss: 0.072230, Train Acc: 0.894872 | Val Loss: 0.105460, Val Acc: 0.793814\n",
      "Epoch 23552 - Train Loss: 0.072228, Train Acc: 0.894872 | Val Loss: 0.105460, Val Acc: 0.793814\n",
      "Epoch 23553 - Train Loss: 0.072227, Train Acc: 0.894872 | Val Loss: 0.105459, Val Acc: 0.793814\n",
      "Epoch 23554 - Train Loss: 0.072225, Train Acc: 0.894872 | Val Loss: 0.105459, Val Acc: 0.793814\n",
      "Epoch 23555 - Train Loss: 0.072223, Train Acc: 0.894872 | Val Loss: 0.105459, Val Acc: 0.793814\n",
      "Epoch 23556 - Train Loss: 0.072222, Train Acc: 0.894872 | Val Loss: 0.105458, Val Acc: 0.793814\n",
      "Epoch 23557 - Train Loss: 0.072220, Train Acc: 0.894872 | Val Loss: 0.105458, Val Acc: 0.793814\n",
      "Epoch 23558 - Train Loss: 0.072219, Train Acc: 0.894872 | Val Loss: 0.105457, Val Acc: 0.793814\n",
      "Epoch 23559 - Train Loss: 0.072217, Train Acc: 0.894872 | Val Loss: 0.105457, Val Acc: 0.793814\n",
      "Epoch 23560 - Train Loss: 0.072216, Train Acc: 0.894872 | Val Loss: 0.105457, Val Acc: 0.793814\n",
      "Epoch 23561 - Train Loss: 0.072214, Train Acc: 0.894872 | Val Loss: 0.105456, Val Acc: 0.793814\n",
      "Epoch 23562 - Train Loss: 0.072213, Train Acc: 0.894872 | Val Loss: 0.105456, Val Acc: 0.793814\n",
      "Epoch 23563 - Train Loss: 0.072211, Train Acc: 0.894872 | Val Loss: 0.105456, Val Acc: 0.793814\n",
      "Epoch 23564 - Train Loss: 0.072209, Train Acc: 0.894872 | Val Loss: 0.105455, Val Acc: 0.793814\n",
      "Epoch 23565 - Train Loss: 0.072208, Train Acc: 0.894872 | Val Loss: 0.105455, Val Acc: 0.793814\n",
      "Epoch 23566 - Train Loss: 0.072206, Train Acc: 0.894872 | Val Loss: 0.105454, Val Acc: 0.793814\n",
      "Epoch 23567 - Train Loss: 0.072205, Train Acc: 0.894872 | Val Loss: 0.105454, Val Acc: 0.793814\n",
      "Epoch 23568 - Train Loss: 0.072203, Train Acc: 0.894872 | Val Loss: 0.105454, Val Acc: 0.793814\n",
      "Epoch 23569 - Train Loss: 0.072202, Train Acc: 0.894872 | Val Loss: 0.105453, Val Acc: 0.793814\n",
      "Epoch 23570 - Train Loss: 0.072200, Train Acc: 0.894872 | Val Loss: 0.105453, Val Acc: 0.793814\n",
      "Epoch 23571 - Train Loss: 0.072199, Train Acc: 0.894872 | Val Loss: 0.105453, Val Acc: 0.793814\n",
      "Epoch 23572 - Train Loss: 0.072197, Train Acc: 0.894872 | Val Loss: 0.105452, Val Acc: 0.793814\n",
      "Epoch 23573 - Train Loss: 0.072196, Train Acc: 0.894872 | Val Loss: 0.105452, Val Acc: 0.793814\n",
      "Epoch 23574 - Train Loss: 0.072194, Train Acc: 0.894872 | Val Loss: 0.105451, Val Acc: 0.793814\n",
      "Epoch 23575 - Train Loss: 0.072192, Train Acc: 0.894872 | Val Loss: 0.105451, Val Acc: 0.793814\n",
      "Epoch 23576 - Train Loss: 0.072191, Train Acc: 0.894872 | Val Loss: 0.105451, Val Acc: 0.793814\n",
      "Epoch 23577 - Train Loss: 0.072189, Train Acc: 0.894872 | Val Loss: 0.105450, Val Acc: 0.793814\n",
      "Epoch 23578 - Train Loss: 0.072188, Train Acc: 0.894872 | Val Loss: 0.105450, Val Acc: 0.793814\n",
      "Epoch 23579 - Train Loss: 0.072186, Train Acc: 0.894872 | Val Loss: 0.105450, Val Acc: 0.793814\n",
      "Epoch 23580 - Train Loss: 0.072185, Train Acc: 0.894872 | Val Loss: 0.105449, Val Acc: 0.793814\n",
      "Epoch 23581 - Train Loss: 0.072183, Train Acc: 0.894872 | Val Loss: 0.105449, Val Acc: 0.793814\n",
      "Epoch 23582 - Train Loss: 0.072182, Train Acc: 0.894872 | Val Loss: 0.105448, Val Acc: 0.793814\n",
      "Epoch 23583 - Train Loss: 0.072180, Train Acc: 0.894872 | Val Loss: 0.105448, Val Acc: 0.793814\n",
      "Epoch 23584 - Train Loss: 0.072178, Train Acc: 0.894872 | Val Loss: 0.105448, Val Acc: 0.793814\n",
      "Epoch 23585 - Train Loss: 0.072177, Train Acc: 0.894872 | Val Loss: 0.105447, Val Acc: 0.793814\n",
      "Epoch 23586 - Train Loss: 0.072175, Train Acc: 0.894872 | Val Loss: 0.105447, Val Acc: 0.793814\n",
      "Epoch 23587 - Train Loss: 0.072174, Train Acc: 0.894872 | Val Loss: 0.105447, Val Acc: 0.793814\n",
      "Epoch 23588 - Train Loss: 0.072172, Train Acc: 0.894872 | Val Loss: 0.105446, Val Acc: 0.793814\n",
      "Epoch 23589 - Train Loss: 0.072171, Train Acc: 0.894872 | Val Loss: 0.105446, Val Acc: 0.793814\n",
      "Epoch 23590 - Train Loss: 0.072169, Train Acc: 0.894872 | Val Loss: 0.105446, Val Acc: 0.793814\n",
      "Epoch 23591 - Train Loss: 0.072168, Train Acc: 0.894872 | Val Loss: 0.105445, Val Acc: 0.793814\n",
      "Epoch 23592 - Train Loss: 0.072166, Train Acc: 0.894872 | Val Loss: 0.105445, Val Acc: 0.793814\n",
      "Epoch 23593 - Train Loss: 0.072165, Train Acc: 0.894872 | Val Loss: 0.105444, Val Acc: 0.793814\n",
      "Epoch 23594 - Train Loss: 0.072163, Train Acc: 0.894872 | Val Loss: 0.105444, Val Acc: 0.793814\n",
      "Epoch 23595 - Train Loss: 0.072161, Train Acc: 0.894872 | Val Loss: 0.105444, Val Acc: 0.793814\n",
      "Epoch 23596 - Train Loss: 0.072160, Train Acc: 0.894872 | Val Loss: 0.105443, Val Acc: 0.793814\n",
      "Epoch 23597 - Train Loss: 0.072158, Train Acc: 0.894872 | Val Loss: 0.105443, Val Acc: 0.793814\n",
      "Epoch 23598 - Train Loss: 0.072157, Train Acc: 0.894872 | Val Loss: 0.105443, Val Acc: 0.793814\n",
      "Epoch 23599 - Train Loss: 0.072155, Train Acc: 0.894872 | Val Loss: 0.105442, Val Acc: 0.793814\n",
      "Epoch 23600 - Train Loss: 0.072154, Train Acc: 0.894872 | Val Loss: 0.105442, Val Acc: 0.793814\n",
      "Epoch 23601 - Train Loss: 0.072152, Train Acc: 0.894872 | Val Loss: 0.105441, Val Acc: 0.793814\n",
      "Epoch 23602 - Train Loss: 0.072151, Train Acc: 0.894872 | Val Loss: 0.105441, Val Acc: 0.793814\n",
      "Epoch 23603 - Train Loss: 0.072149, Train Acc: 0.894872 | Val Loss: 0.105441, Val Acc: 0.793814\n",
      "Epoch 23604 - Train Loss: 0.072147, Train Acc: 0.894872 | Val Loss: 0.105440, Val Acc: 0.793814\n",
      "Epoch 23605 - Train Loss: 0.072146, Train Acc: 0.894872 | Val Loss: 0.105440, Val Acc: 0.793814\n",
      "Epoch 23606 - Train Loss: 0.072144, Train Acc: 0.894872 | Val Loss: 0.105440, Val Acc: 0.793814\n",
      "Epoch 23607 - Train Loss: 0.072143, Train Acc: 0.894872 | Val Loss: 0.105439, Val Acc: 0.793814\n",
      "Epoch 23608 - Train Loss: 0.072141, Train Acc: 0.894872 | Val Loss: 0.105439, Val Acc: 0.793814\n",
      "Epoch 23609 - Train Loss: 0.072140, Train Acc: 0.894872 | Val Loss: 0.105439, Val Acc: 0.793814\n",
      "Epoch 23610 - Train Loss: 0.072138, Train Acc: 0.894872 | Val Loss: 0.105438, Val Acc: 0.793814\n",
      "Epoch 23611 - Train Loss: 0.072137, Train Acc: 0.894872 | Val Loss: 0.105438, Val Acc: 0.793814\n",
      "Epoch 23612 - Train Loss: 0.072135, Train Acc: 0.894872 | Val Loss: 0.105437, Val Acc: 0.793814\n",
      "Epoch 23613 - Train Loss: 0.072134, Train Acc: 0.894872 | Val Loss: 0.105437, Val Acc: 0.793814\n",
      "Epoch 23614 - Train Loss: 0.072132, Train Acc: 0.894872 | Val Loss: 0.105437, Val Acc: 0.793814\n",
      "Epoch 23615 - Train Loss: 0.072130, Train Acc: 0.894872 | Val Loss: 0.105436, Val Acc: 0.793814\n",
      "Epoch 23616 - Train Loss: 0.072129, Train Acc: 0.894872 | Val Loss: 0.105436, Val Acc: 0.793814\n",
      "Epoch 23617 - Train Loss: 0.072127, Train Acc: 0.894872 | Val Loss: 0.105436, Val Acc: 0.793814\n",
      "Epoch 23618 - Train Loss: 0.072126, Train Acc: 0.894872 | Val Loss: 0.105435, Val Acc: 0.793814\n",
      "Epoch 23619 - Train Loss: 0.072124, Train Acc: 0.894872 | Val Loss: 0.105435, Val Acc: 0.793814\n",
      "Epoch 23620 - Train Loss: 0.072123, Train Acc: 0.894872 | Val Loss: 0.105435, Val Acc: 0.793814\n",
      "Epoch 23621 - Train Loss: 0.072121, Train Acc: 0.894872 | Val Loss: 0.105434, Val Acc: 0.793814\n",
      "Epoch 23622 - Train Loss: 0.072120, Train Acc: 0.894872 | Val Loss: 0.105434, Val Acc: 0.793814\n",
      "Epoch 23623 - Train Loss: 0.072118, Train Acc: 0.894872 | Val Loss: 0.105433, Val Acc: 0.793814\n",
      "Epoch 23624 - Train Loss: 0.072117, Train Acc: 0.894872 | Val Loss: 0.105433, Val Acc: 0.793814\n",
      "Epoch 23625 - Train Loss: 0.072115, Train Acc: 0.894872 | Val Loss: 0.105433, Val Acc: 0.793814\n",
      "Epoch 23626 - Train Loss: 0.072113, Train Acc: 0.894872 | Val Loss: 0.105432, Val Acc: 0.793814\n",
      "Epoch 23627 - Train Loss: 0.072112, Train Acc: 0.894872 | Val Loss: 0.105432, Val Acc: 0.793814\n",
      "Epoch 23628 - Train Loss: 0.072110, Train Acc: 0.894872 | Val Loss: 0.105432, Val Acc: 0.793814\n",
      "Epoch 23629 - Train Loss: 0.072109, Train Acc: 0.894872 | Val Loss: 0.105431, Val Acc: 0.793814\n",
      "Epoch 23630 - Train Loss: 0.072107, Train Acc: 0.894872 | Val Loss: 0.105431, Val Acc: 0.793814\n",
      "Epoch 23631 - Train Loss: 0.072106, Train Acc: 0.894872 | Val Loss: 0.105431, Val Acc: 0.793814\n",
      "Epoch 23632 - Train Loss: 0.072104, Train Acc: 0.894872 | Val Loss: 0.105430, Val Acc: 0.793814\n",
      "Epoch 23633 - Train Loss: 0.072103, Train Acc: 0.894872 | Val Loss: 0.105430, Val Acc: 0.793814\n",
      "Epoch 23634 - Train Loss: 0.072101, Train Acc: 0.894872 | Val Loss: 0.105430, Val Acc: 0.793814\n",
      "Epoch 23635 - Train Loss: 0.072100, Train Acc: 0.894872 | Val Loss: 0.105429, Val Acc: 0.793814\n",
      "Epoch 23636 - Train Loss: 0.072098, Train Acc: 0.894872 | Val Loss: 0.105429, Val Acc: 0.793814\n",
      "Epoch 23637 - Train Loss: 0.072096, Train Acc: 0.894872 | Val Loss: 0.105428, Val Acc: 0.793814\n",
      "Epoch 23638 - Train Loss: 0.072095, Train Acc: 0.894872 | Val Loss: 0.105428, Val Acc: 0.793814\n",
      "Epoch 23639 - Train Loss: 0.072093, Train Acc: 0.894872 | Val Loss: 0.105428, Val Acc: 0.793814\n",
      "Epoch 23640 - Train Loss: 0.072092, Train Acc: 0.894872 | Val Loss: 0.105427, Val Acc: 0.793814\n",
      "Epoch 23641 - Train Loss: 0.072090, Train Acc: 0.894872 | Val Loss: 0.105427, Val Acc: 0.793814\n",
      "Epoch 23642 - Train Loss: 0.072089, Train Acc: 0.894872 | Val Loss: 0.105427, Val Acc: 0.793814\n",
      "Epoch 23643 - Train Loss: 0.072087, Train Acc: 0.894872 | Val Loss: 0.105426, Val Acc: 0.793814\n",
      "Epoch 23644 - Train Loss: 0.072086, Train Acc: 0.894872 | Val Loss: 0.105426, Val Acc: 0.793814\n",
      "Epoch 23645 - Train Loss: 0.072084, Train Acc: 0.894872 | Val Loss: 0.105426, Val Acc: 0.793814\n",
      "Epoch 23646 - Train Loss: 0.072083, Train Acc: 0.894872 | Val Loss: 0.105425, Val Acc: 0.793814\n",
      "Epoch 23647 - Train Loss: 0.072081, Train Acc: 0.894872 | Val Loss: 0.105425, Val Acc: 0.793814\n",
      "Epoch 23648 - Train Loss: 0.072080, Train Acc: 0.894872 | Val Loss: 0.105424, Val Acc: 0.793814\n",
      "Epoch 23649 - Train Loss: 0.072078, Train Acc: 0.894872 | Val Loss: 0.105424, Val Acc: 0.793814\n",
      "Epoch 23650 - Train Loss: 0.072076, Train Acc: 0.894872 | Val Loss: 0.105424, Val Acc: 0.793814\n",
      "Epoch 23651 - Train Loss: 0.072075, Train Acc: 0.894872 | Val Loss: 0.105423, Val Acc: 0.793814\n",
      "Epoch 23652 - Train Loss: 0.072073, Train Acc: 0.894872 | Val Loss: 0.105423, Val Acc: 0.793814\n",
      "Epoch 23653 - Train Loss: 0.072072, Train Acc: 0.894872 | Val Loss: 0.105423, Val Acc: 0.793814\n",
      "Epoch 23654 - Train Loss: 0.072070, Train Acc: 0.894872 | Val Loss: 0.105422, Val Acc: 0.793814\n",
      "Epoch 23655 - Train Loss: 0.072069, Train Acc: 0.894872 | Val Loss: 0.105422, Val Acc: 0.793814\n",
      "Epoch 23656 - Train Loss: 0.072067, Train Acc: 0.894872 | Val Loss: 0.105422, Val Acc: 0.793814\n",
      "Epoch 23657 - Train Loss: 0.072066, Train Acc: 0.894872 | Val Loss: 0.105421, Val Acc: 0.793814\n",
      "Epoch 23658 - Train Loss: 0.072064, Train Acc: 0.894872 | Val Loss: 0.105421, Val Acc: 0.793814\n",
      "Epoch 23659 - Train Loss: 0.072063, Train Acc: 0.894872 | Val Loss: 0.105421, Val Acc: 0.793814\n",
      "Epoch 23660 - Train Loss: 0.072061, Train Acc: 0.894872 | Val Loss: 0.105420, Val Acc: 0.793814\n",
      "Epoch 23661 - Train Loss: 0.072059, Train Acc: 0.894872 | Val Loss: 0.105420, Val Acc: 0.793814\n",
      "Epoch 23662 - Train Loss: 0.072058, Train Acc: 0.894872 | Val Loss: 0.105420, Val Acc: 0.793814\n",
      "Epoch 23663 - Train Loss: 0.072056, Train Acc: 0.894872 | Val Loss: 0.105419, Val Acc: 0.793814\n",
      "Epoch 23664 - Train Loss: 0.072055, Train Acc: 0.894872 | Val Loss: 0.105419, Val Acc: 0.793814\n",
      "Epoch 23665 - Train Loss: 0.072053, Train Acc: 0.894872 | Val Loss: 0.105418, Val Acc: 0.793814\n",
      "Epoch 23666 - Train Loss: 0.072052, Train Acc: 0.894872 | Val Loss: 0.105418, Val Acc: 0.793814\n",
      "Epoch 23667 - Train Loss: 0.072050, Train Acc: 0.894872 | Val Loss: 0.105418, Val Acc: 0.793814\n",
      "Epoch 23668 - Train Loss: 0.072049, Train Acc: 0.894872 | Val Loss: 0.105417, Val Acc: 0.793814\n",
      "Epoch 23669 - Train Loss: 0.072047, Train Acc: 0.894872 | Val Loss: 0.105417, Val Acc: 0.793814\n",
      "Epoch 23670 - Train Loss: 0.072046, Train Acc: 0.894872 | Val Loss: 0.105417, Val Acc: 0.793814\n",
      "Epoch 23671 - Train Loss: 0.072044, Train Acc: 0.894872 | Val Loss: 0.105416, Val Acc: 0.793814\n",
      "Epoch 23672 - Train Loss: 0.072043, Train Acc: 0.894872 | Val Loss: 0.105416, Val Acc: 0.793814\n",
      "Epoch 23673 - Train Loss: 0.072041, Train Acc: 0.894872 | Val Loss: 0.105416, Val Acc: 0.793814\n",
      "Epoch 23674 - Train Loss: 0.072039, Train Acc: 0.894872 | Val Loss: 0.105415, Val Acc: 0.793814\n",
      "Epoch 23675 - Train Loss: 0.072038, Train Acc: 0.894872 | Val Loss: 0.105415, Val Acc: 0.793814\n",
      "Epoch 23676 - Train Loss: 0.072036, Train Acc: 0.894872 | Val Loss: 0.105415, Val Acc: 0.793814\n",
      "Epoch 23677 - Train Loss: 0.072035, Train Acc: 0.894872 | Val Loss: 0.105414, Val Acc: 0.793814\n",
      "Epoch 23678 - Train Loss: 0.072033, Train Acc: 0.894872 | Val Loss: 0.105414, Val Acc: 0.793814\n",
      "Epoch 23679 - Train Loss: 0.072032, Train Acc: 0.894872 | Val Loss: 0.105413, Val Acc: 0.793814\n",
      "Epoch 23680 - Train Loss: 0.072030, Train Acc: 0.894872 | Val Loss: 0.105413, Val Acc: 0.793814\n",
      "Epoch 23681 - Train Loss: 0.072029, Train Acc: 0.894872 | Val Loss: 0.105413, Val Acc: 0.793814\n",
      "Epoch 23682 - Train Loss: 0.072027, Train Acc: 0.894872 | Val Loss: 0.105412, Val Acc: 0.793814\n",
      "Epoch 23683 - Train Loss: 0.072026, Train Acc: 0.894872 | Val Loss: 0.105412, Val Acc: 0.793814\n",
      "Epoch 23684 - Train Loss: 0.072024, Train Acc: 0.894872 | Val Loss: 0.105412, Val Acc: 0.793814\n",
      "Epoch 23685 - Train Loss: 0.072023, Train Acc: 0.894872 | Val Loss: 0.105411, Val Acc: 0.793814\n",
      "Epoch 23686 - Train Loss: 0.072021, Train Acc: 0.894872 | Val Loss: 0.105411, Val Acc: 0.793814\n",
      "Epoch 23687 - Train Loss: 0.072019, Train Acc: 0.894872 | Val Loss: 0.105411, Val Acc: 0.793814\n",
      "Epoch 23688 - Train Loss: 0.072018, Train Acc: 0.894872 | Val Loss: 0.105410, Val Acc: 0.793814\n",
      "Epoch 23689 - Train Loss: 0.072016, Train Acc: 0.894872 | Val Loss: 0.105410, Val Acc: 0.793814\n",
      "Epoch 23690 - Train Loss: 0.072015, Train Acc: 0.894872 | Val Loss: 0.105410, Val Acc: 0.793814\n",
      "Epoch 23691 - Train Loss: 0.072013, Train Acc: 0.894872 | Val Loss: 0.105409, Val Acc: 0.793814\n",
      "Epoch 23692 - Train Loss: 0.072012, Train Acc: 0.894872 | Val Loss: 0.105409, Val Acc: 0.793814\n",
      "Epoch 23693 - Train Loss: 0.072010, Train Acc: 0.894872 | Val Loss: 0.105408, Val Acc: 0.793814\n",
      "Epoch 23694 - Train Loss: 0.072009, Train Acc: 0.894872 | Val Loss: 0.105408, Val Acc: 0.793814\n",
      "Epoch 23695 - Train Loss: 0.072007, Train Acc: 0.894872 | Val Loss: 0.105408, Val Acc: 0.793814\n",
      "Epoch 23696 - Train Loss: 0.072006, Train Acc: 0.894872 | Val Loss: 0.105407, Val Acc: 0.793814\n",
      "Epoch 23697 - Train Loss: 0.072004, Train Acc: 0.894872 | Val Loss: 0.105407, Val Acc: 0.793814\n",
      "Epoch 23698 - Train Loss: 0.072003, Train Acc: 0.894872 | Val Loss: 0.105407, Val Acc: 0.793814\n",
      "Epoch 23699 - Train Loss: 0.072001, Train Acc: 0.894872 | Val Loss: 0.105406, Val Acc: 0.793814\n",
      "Epoch 23700 - Train Loss: 0.071999, Train Acc: 0.894872 | Val Loss: 0.105406, Val Acc: 0.793814\n",
      "Epoch 23701 - Train Loss: 0.071998, Train Acc: 0.894872 | Val Loss: 0.105406, Val Acc: 0.793814\n",
      "Epoch 23702 - Train Loss: 0.071996, Train Acc: 0.894872 | Val Loss: 0.105405, Val Acc: 0.793814\n",
      "Epoch 23703 - Train Loss: 0.071995, Train Acc: 0.894872 | Val Loss: 0.105405, Val Acc: 0.793814\n",
      "Epoch 23704 - Train Loss: 0.071993, Train Acc: 0.894872 | Val Loss: 0.105405, Val Acc: 0.793814\n",
      "Epoch 23705 - Train Loss: 0.071992, Train Acc: 0.894872 | Val Loss: 0.105404, Val Acc: 0.793814\n",
      "Epoch 23706 - Train Loss: 0.071990, Train Acc: 0.894872 | Val Loss: 0.105404, Val Acc: 0.793814\n",
      "Epoch 23707 - Train Loss: 0.071989, Train Acc: 0.894872 | Val Loss: 0.105404, Val Acc: 0.793814\n",
      "Epoch 23708 - Train Loss: 0.071987, Train Acc: 0.894872 | Val Loss: 0.105403, Val Acc: 0.793814\n",
      "Epoch 23709 - Train Loss: 0.071986, Train Acc: 0.894872 | Val Loss: 0.105403, Val Acc: 0.793814\n",
      "Epoch 23710 - Train Loss: 0.071984, Train Acc: 0.894872 | Val Loss: 0.105403, Val Acc: 0.793814\n",
      "Epoch 23711 - Train Loss: 0.071983, Train Acc: 0.894872 | Val Loss: 0.105402, Val Acc: 0.793814\n",
      "Epoch 23712 - Train Loss: 0.071981, Train Acc: 0.894872 | Val Loss: 0.105402, Val Acc: 0.793814\n",
      "Epoch 23713 - Train Loss: 0.071980, Train Acc: 0.894872 | Val Loss: 0.105401, Val Acc: 0.793814\n",
      "Epoch 23714 - Train Loss: 0.071978, Train Acc: 0.894872 | Val Loss: 0.105401, Val Acc: 0.793814\n",
      "Epoch 23715 - Train Loss: 0.071976, Train Acc: 0.894872 | Val Loss: 0.105401, Val Acc: 0.793814\n",
      "Epoch 23716 - Train Loss: 0.071975, Train Acc: 0.894872 | Val Loss: 0.105400, Val Acc: 0.793814\n",
      "Epoch 23717 - Train Loss: 0.071973, Train Acc: 0.894872 | Val Loss: 0.105400, Val Acc: 0.793814\n",
      "Epoch 23718 - Train Loss: 0.071972, Train Acc: 0.894872 | Val Loss: 0.105400, Val Acc: 0.793814\n",
      "Epoch 23719 - Train Loss: 0.071970, Train Acc: 0.894872 | Val Loss: 0.105399, Val Acc: 0.793814\n",
      "Epoch 23720 - Train Loss: 0.071969, Train Acc: 0.894872 | Val Loss: 0.105399, Val Acc: 0.793814\n",
      "Epoch 23721 - Train Loss: 0.071967, Train Acc: 0.894872 | Val Loss: 0.105399, Val Acc: 0.793814\n",
      "Epoch 23722 - Train Loss: 0.071966, Train Acc: 0.894872 | Val Loss: 0.105398, Val Acc: 0.793814\n",
      "Epoch 23723 - Train Loss: 0.071964, Train Acc: 0.894872 | Val Loss: 0.105398, Val Acc: 0.793814\n",
      "Epoch 23724 - Train Loss: 0.071963, Train Acc: 0.894872 | Val Loss: 0.105398, Val Acc: 0.793814\n",
      "Epoch 23725 - Train Loss: 0.071961, Train Acc: 0.894872 | Val Loss: 0.105397, Val Acc: 0.793814\n",
      "Epoch 23726 - Train Loss: 0.071960, Train Acc: 0.894872 | Val Loss: 0.105397, Val Acc: 0.793814\n",
      "Epoch 23727 - Train Loss: 0.071958, Train Acc: 0.894872 | Val Loss: 0.105397, Val Acc: 0.793814\n",
      "Epoch 23728 - Train Loss: 0.071957, Train Acc: 0.894872 | Val Loss: 0.105396, Val Acc: 0.793814\n",
      "Epoch 23729 - Train Loss: 0.071955, Train Acc: 0.894872 | Val Loss: 0.105396, Val Acc: 0.793814\n",
      "Epoch 23730 - Train Loss: 0.071953, Train Acc: 0.894872 | Val Loss: 0.105396, Val Acc: 0.793814\n",
      "Epoch 23731 - Train Loss: 0.071952, Train Acc: 0.894872 | Val Loss: 0.105395, Val Acc: 0.793814\n",
      "Epoch 23732 - Train Loss: 0.071950, Train Acc: 0.894872 | Val Loss: 0.105395, Val Acc: 0.793814\n",
      "Epoch 23733 - Train Loss: 0.071949, Train Acc: 0.894872 | Val Loss: 0.105395, Val Acc: 0.793814\n",
      "Epoch 23734 - Train Loss: 0.071947, Train Acc: 0.894872 | Val Loss: 0.105394, Val Acc: 0.793814\n",
      "Epoch 23735 - Train Loss: 0.071946, Train Acc: 0.894872 | Val Loss: 0.105394, Val Acc: 0.793814\n",
      "Epoch 23736 - Train Loss: 0.071944, Train Acc: 0.894872 | Val Loss: 0.105393, Val Acc: 0.793814\n",
      "Epoch 23737 - Train Loss: 0.071943, Train Acc: 0.894872 | Val Loss: 0.105393, Val Acc: 0.793814\n",
      "Epoch 23738 - Train Loss: 0.071941, Train Acc: 0.894872 | Val Loss: 0.105393, Val Acc: 0.793814\n",
      "Epoch 23739 - Train Loss: 0.071940, Train Acc: 0.894872 | Val Loss: 0.105392, Val Acc: 0.793814\n",
      "Epoch 23740 - Train Loss: 0.071938, Train Acc: 0.894872 | Val Loss: 0.105392, Val Acc: 0.793814\n",
      "Epoch 23741 - Train Loss: 0.071937, Train Acc: 0.894872 | Val Loss: 0.105392, Val Acc: 0.793814\n",
      "Epoch 23742 - Train Loss: 0.071935, Train Acc: 0.894872 | Val Loss: 0.105391, Val Acc: 0.793814\n",
      "Epoch 23743 - Train Loss: 0.071934, Train Acc: 0.894872 | Val Loss: 0.105391, Val Acc: 0.793814\n",
      "Epoch 23744 - Train Loss: 0.071932, Train Acc: 0.894872 | Val Loss: 0.105391, Val Acc: 0.793814\n",
      "Epoch 23745 - Train Loss: 0.071931, Train Acc: 0.894872 | Val Loss: 0.105390, Val Acc: 0.793814\n",
      "Epoch 23746 - Train Loss: 0.071929, Train Acc: 0.894872 | Val Loss: 0.105390, Val Acc: 0.793814\n",
      "Epoch 23747 - Train Loss: 0.071927, Train Acc: 0.894872 | Val Loss: 0.105390, Val Acc: 0.793814\n",
      "Epoch 23748 - Train Loss: 0.071926, Train Acc: 0.894872 | Val Loss: 0.105389, Val Acc: 0.793814\n",
      "Epoch 23749 - Train Loss: 0.071924, Train Acc: 0.894872 | Val Loss: 0.105389, Val Acc: 0.793814\n",
      "Epoch 23750 - Train Loss: 0.071923, Train Acc: 0.894872 | Val Loss: 0.105389, Val Acc: 0.793814\n",
      "Epoch 23751 - Train Loss: 0.071921, Train Acc: 0.894872 | Val Loss: 0.105388, Val Acc: 0.793814\n",
      "Epoch 23752 - Train Loss: 0.071920, Train Acc: 0.894872 | Val Loss: 0.105388, Val Acc: 0.793814\n",
      "Epoch 23753 - Train Loss: 0.071918, Train Acc: 0.894872 | Val Loss: 0.105388, Val Acc: 0.793814\n",
      "Epoch 23754 - Train Loss: 0.071917, Train Acc: 0.894872 | Val Loss: 0.105387, Val Acc: 0.793814\n",
      "Epoch 23755 - Train Loss: 0.071915, Train Acc: 0.894872 | Val Loss: 0.105387, Val Acc: 0.793814\n",
      "Epoch 23756 - Train Loss: 0.071914, Train Acc: 0.894872 | Val Loss: 0.105387, Val Acc: 0.793814\n",
      "Epoch 23757 - Train Loss: 0.071912, Train Acc: 0.894872 | Val Loss: 0.105386, Val Acc: 0.793814\n",
      "Epoch 23758 - Train Loss: 0.071911, Train Acc: 0.894872 | Val Loss: 0.105386, Val Acc: 0.793814\n",
      "Epoch 23759 - Train Loss: 0.071909, Train Acc: 0.894872 | Val Loss: 0.105385, Val Acc: 0.793814\n",
      "Epoch 23760 - Train Loss: 0.071908, Train Acc: 0.894872 | Val Loss: 0.105385, Val Acc: 0.793814\n",
      "Epoch 23761 - Train Loss: 0.071906, Train Acc: 0.894872 | Val Loss: 0.105385, Val Acc: 0.793814\n",
      "Epoch 23762 - Train Loss: 0.071904, Train Acc: 0.894872 | Val Loss: 0.105384, Val Acc: 0.793814\n",
      "Epoch 23763 - Train Loss: 0.071903, Train Acc: 0.894872 | Val Loss: 0.105384, Val Acc: 0.793814\n",
      "Epoch 23764 - Train Loss: 0.071901, Train Acc: 0.894872 | Val Loss: 0.105384, Val Acc: 0.793814\n",
      "Epoch 23765 - Train Loss: 0.071900, Train Acc: 0.894872 | Val Loss: 0.105383, Val Acc: 0.793814\n",
      "Epoch 23766 - Train Loss: 0.071898, Train Acc: 0.894872 | Val Loss: 0.105383, Val Acc: 0.793814\n",
      "Epoch 23767 - Train Loss: 0.071897, Train Acc: 0.894872 | Val Loss: 0.105383, Val Acc: 0.793814\n",
      "Epoch 23768 - Train Loss: 0.071895, Train Acc: 0.894872 | Val Loss: 0.105382, Val Acc: 0.793814\n",
      "Epoch 23769 - Train Loss: 0.071894, Train Acc: 0.894872 | Val Loss: 0.105382, Val Acc: 0.793814\n",
      "Epoch 23770 - Train Loss: 0.071892, Train Acc: 0.894872 | Val Loss: 0.105382, Val Acc: 0.793814\n",
      "Epoch 23771 - Train Loss: 0.071891, Train Acc: 0.894872 | Val Loss: 0.105381, Val Acc: 0.793814\n",
      "Epoch 23772 - Train Loss: 0.071889, Train Acc: 0.894872 | Val Loss: 0.105381, Val Acc: 0.793814\n",
      "Epoch 23773 - Train Loss: 0.071888, Train Acc: 0.894872 | Val Loss: 0.105381, Val Acc: 0.793814\n",
      "Epoch 23774 - Train Loss: 0.071886, Train Acc: 0.894872 | Val Loss: 0.105380, Val Acc: 0.793814\n",
      "Epoch 23775 - Train Loss: 0.071885, Train Acc: 0.894872 | Val Loss: 0.105380, Val Acc: 0.793814\n",
      "Epoch 23776 - Train Loss: 0.071883, Train Acc: 0.894872 | Val Loss: 0.105380, Val Acc: 0.793814\n",
      "Epoch 23777 - Train Loss: 0.071882, Train Acc: 0.894872 | Val Loss: 0.105379, Val Acc: 0.793814\n",
      "Epoch 23778 - Train Loss: 0.071880, Train Acc: 0.894872 | Val Loss: 0.105379, Val Acc: 0.793814\n",
      "Epoch 23779 - Train Loss: 0.071879, Train Acc: 0.894872 | Val Loss: 0.105379, Val Acc: 0.793814\n",
      "Epoch 23780 - Train Loss: 0.071877, Train Acc: 0.894872 | Val Loss: 0.105378, Val Acc: 0.793814\n",
      "Epoch 23781 - Train Loss: 0.071875, Train Acc: 0.894872 | Val Loss: 0.105378, Val Acc: 0.793814\n",
      "Epoch 23782 - Train Loss: 0.071874, Train Acc: 0.894872 | Val Loss: 0.105378, Val Acc: 0.793814\n",
      "Epoch 23783 - Train Loss: 0.071872, Train Acc: 0.894872 | Val Loss: 0.105377, Val Acc: 0.793814\n",
      "Epoch 23784 - Train Loss: 0.071871, Train Acc: 0.894872 | Val Loss: 0.105377, Val Acc: 0.793814\n",
      "Epoch 23785 - Train Loss: 0.071869, Train Acc: 0.894872 | Val Loss: 0.105377, Val Acc: 0.793814\n",
      "Epoch 23786 - Train Loss: 0.071868, Train Acc: 0.894872 | Val Loss: 0.105376, Val Acc: 0.793814\n",
      "Epoch 23787 - Train Loss: 0.071866, Train Acc: 0.894872 | Val Loss: 0.105376, Val Acc: 0.793814\n",
      "Epoch 23788 - Train Loss: 0.071865, Train Acc: 0.894872 | Val Loss: 0.105376, Val Acc: 0.793814\n",
      "Epoch 23789 - Train Loss: 0.071863, Train Acc: 0.894872 | Val Loss: 0.105375, Val Acc: 0.793814\n",
      "Epoch 23790 - Train Loss: 0.071862, Train Acc: 0.894872 | Val Loss: 0.105375, Val Acc: 0.793814\n",
      "Epoch 23791 - Train Loss: 0.071860, Train Acc: 0.894872 | Val Loss: 0.105375, Val Acc: 0.793814\n",
      "Epoch 23792 - Train Loss: 0.071859, Train Acc: 0.894872 | Val Loss: 0.105374, Val Acc: 0.793814\n",
      "Epoch 23793 - Train Loss: 0.071857, Train Acc: 0.894872 | Val Loss: 0.105374, Val Acc: 0.793814\n",
      "Epoch 23794 - Train Loss: 0.071856, Train Acc: 0.894872 | Val Loss: 0.105373, Val Acc: 0.793814\n",
      "Epoch 23795 - Train Loss: 0.071854, Train Acc: 0.894872 | Val Loss: 0.105373, Val Acc: 0.793814\n",
      "Epoch 23796 - Train Loss: 0.071853, Train Acc: 0.894872 | Val Loss: 0.105373, Val Acc: 0.793814\n",
      "Epoch 23797 - Train Loss: 0.071851, Train Acc: 0.894872 | Val Loss: 0.105372, Val Acc: 0.793814\n",
      "Epoch 23798 - Train Loss: 0.071850, Train Acc: 0.894872 | Val Loss: 0.105372, Val Acc: 0.793814\n",
      "Epoch 23799 - Train Loss: 0.071848, Train Acc: 0.894872 | Val Loss: 0.105372, Val Acc: 0.793814\n",
      "Epoch 23800 - Train Loss: 0.071846, Train Acc: 0.894872 | Val Loss: 0.105371, Val Acc: 0.793814\n",
      "Epoch 23801 - Train Loss: 0.071845, Train Acc: 0.894872 | Val Loss: 0.105371, Val Acc: 0.793814\n",
      "Epoch 23802 - Train Loss: 0.071843, Train Acc: 0.894872 | Val Loss: 0.105371, Val Acc: 0.793814\n",
      "Epoch 23803 - Train Loss: 0.071842, Train Acc: 0.894872 | Val Loss: 0.105370, Val Acc: 0.793814\n",
      "Epoch 23804 - Train Loss: 0.071840, Train Acc: 0.894872 | Val Loss: 0.105370, Val Acc: 0.793814\n",
      "Epoch 23805 - Train Loss: 0.071839, Train Acc: 0.894872 | Val Loss: 0.105370, Val Acc: 0.793814\n",
      "Epoch 23806 - Train Loss: 0.071837, Train Acc: 0.894872 | Val Loss: 0.105369, Val Acc: 0.793814\n",
      "Epoch 23807 - Train Loss: 0.071836, Train Acc: 0.894872 | Val Loss: 0.105369, Val Acc: 0.793814\n",
      "Epoch 23808 - Train Loss: 0.071834, Train Acc: 0.894872 | Val Loss: 0.105369, Val Acc: 0.793814\n",
      "Epoch 23809 - Train Loss: 0.071833, Train Acc: 0.894872 | Val Loss: 0.105368, Val Acc: 0.793814\n",
      "Epoch 23810 - Train Loss: 0.071831, Train Acc: 0.894872 | Val Loss: 0.105368, Val Acc: 0.793814\n",
      "Epoch 23811 - Train Loss: 0.071830, Train Acc: 0.894872 | Val Loss: 0.105368, Val Acc: 0.793814\n",
      "Epoch 23812 - Train Loss: 0.071828, Train Acc: 0.894872 | Val Loss: 0.105367, Val Acc: 0.793814\n",
      "Epoch 23813 - Train Loss: 0.071827, Train Acc: 0.894872 | Val Loss: 0.105367, Val Acc: 0.793814\n",
      "Epoch 23814 - Train Loss: 0.071825, Train Acc: 0.894872 | Val Loss: 0.105367, Val Acc: 0.793814\n",
      "Epoch 23815 - Train Loss: 0.071824, Train Acc: 0.894872 | Val Loss: 0.105366, Val Acc: 0.793814\n",
      "Epoch 23816 - Train Loss: 0.071822, Train Acc: 0.894872 | Val Loss: 0.105366, Val Acc: 0.793814\n",
      "Epoch 23817 - Train Loss: 0.071821, Train Acc: 0.894872 | Val Loss: 0.105366, Val Acc: 0.793814\n",
      "Epoch 23818 - Train Loss: 0.071819, Train Acc: 0.894872 | Val Loss: 0.105365, Val Acc: 0.793814\n",
      "Epoch 23819 - Train Loss: 0.071818, Train Acc: 0.894872 | Val Loss: 0.105365, Val Acc: 0.793814\n",
      "Epoch 23820 - Train Loss: 0.071816, Train Acc: 0.894872 | Val Loss: 0.105365, Val Acc: 0.793814\n",
      "Epoch 23821 - Train Loss: 0.071814, Train Acc: 0.894872 | Val Loss: 0.105364, Val Acc: 0.793814\n",
      "Epoch 23822 - Train Loss: 0.071813, Train Acc: 0.894872 | Val Loss: 0.105364, Val Acc: 0.793814\n",
      "Epoch 23823 - Train Loss: 0.071811, Train Acc: 0.894872 | Val Loss: 0.105364, Val Acc: 0.793814\n",
      "Epoch 23824 - Train Loss: 0.071810, Train Acc: 0.894872 | Val Loss: 0.105363, Val Acc: 0.793814\n",
      "Epoch 23825 - Train Loss: 0.071808, Train Acc: 0.894872 | Val Loss: 0.105363, Val Acc: 0.793814\n",
      "Epoch 23826 - Train Loss: 0.071807, Train Acc: 0.894872 | Val Loss: 0.105363, Val Acc: 0.793814\n",
      "Epoch 23827 - Train Loss: 0.071805, Train Acc: 0.894872 | Val Loss: 0.105362, Val Acc: 0.793814\n",
      "Epoch 23828 - Train Loss: 0.071804, Train Acc: 0.894872 | Val Loss: 0.105362, Val Acc: 0.793814\n",
      "Epoch 23829 - Train Loss: 0.071802, Train Acc: 0.894872 | Val Loss: 0.105362, Val Acc: 0.793814\n",
      "Epoch 23830 - Train Loss: 0.071801, Train Acc: 0.894872 | Val Loss: 0.105361, Val Acc: 0.793814\n",
      "Epoch 23831 - Train Loss: 0.071799, Train Acc: 0.894872 | Val Loss: 0.105361, Val Acc: 0.793814\n",
      "Epoch 23832 - Train Loss: 0.071798, Train Acc: 0.894872 | Val Loss: 0.105361, Val Acc: 0.793814\n",
      "Epoch 23833 - Train Loss: 0.071796, Train Acc: 0.894872 | Val Loss: 0.105360, Val Acc: 0.793814\n",
      "Epoch 23834 - Train Loss: 0.071795, Train Acc: 0.894872 | Val Loss: 0.105360, Val Acc: 0.793814\n",
      "Epoch 23835 - Train Loss: 0.071793, Train Acc: 0.894872 | Val Loss: 0.105360, Val Acc: 0.793814\n",
      "Epoch 23836 - Train Loss: 0.071792, Train Acc: 0.894872 | Val Loss: 0.105359, Val Acc: 0.793814\n",
      "Epoch 23837 - Train Loss: 0.071790, Train Acc: 0.894872 | Val Loss: 0.105359, Val Acc: 0.793814\n",
      "Epoch 23838 - Train Loss: 0.071789, Train Acc: 0.894872 | Val Loss: 0.105359, Val Acc: 0.793814\n",
      "Epoch 23839 - Train Loss: 0.071787, Train Acc: 0.894872 | Val Loss: 0.105358, Val Acc: 0.793814\n",
      "Epoch 23840 - Train Loss: 0.071786, Train Acc: 0.894872 | Val Loss: 0.105358, Val Acc: 0.793814\n",
      "Epoch 23841 - Train Loss: 0.071784, Train Acc: 0.894872 | Val Loss: 0.105358, Val Acc: 0.793814\n",
      "Epoch 23842 - Train Loss: 0.071783, Train Acc: 0.894872 | Val Loss: 0.105358, Val Acc: 0.793814\n",
      "Epoch 23843 - Train Loss: 0.071781, Train Acc: 0.894872 | Val Loss: 0.105357, Val Acc: 0.793814\n",
      "Epoch 23844 - Train Loss: 0.071780, Train Acc: 0.894872 | Val Loss: 0.105357, Val Acc: 0.793814\n",
      "Epoch 23845 - Train Loss: 0.071778, Train Acc: 0.894872 | Val Loss: 0.105356, Val Acc: 0.793814\n",
      "Epoch 23846 - Train Loss: 0.071776, Train Acc: 0.894872 | Val Loss: 0.105356, Val Acc: 0.793814\n",
      "Epoch 23847 - Train Loss: 0.071775, Train Acc: 0.894872 | Val Loss: 0.105356, Val Acc: 0.793814\n",
      "Epoch 23848 - Train Loss: 0.071773, Train Acc: 0.894872 | Val Loss: 0.105356, Val Acc: 0.793814\n",
      "Epoch 23849 - Train Loss: 0.071772, Train Acc: 0.894872 | Val Loss: 0.105355, Val Acc: 0.793814\n",
      "Epoch 23850 - Train Loss: 0.071770, Train Acc: 0.894872 | Val Loss: 0.105355, Val Acc: 0.793814\n",
      "Epoch 23851 - Train Loss: 0.071769, Train Acc: 0.894872 | Val Loss: 0.105355, Val Acc: 0.793814\n",
      "Epoch 23852 - Train Loss: 0.071767, Train Acc: 0.894872 | Val Loss: 0.105354, Val Acc: 0.793814\n",
      "Epoch 23853 - Train Loss: 0.071766, Train Acc: 0.894872 | Val Loss: 0.105354, Val Acc: 0.793814\n",
      "Epoch 23854 - Train Loss: 0.071764, Train Acc: 0.894872 | Val Loss: 0.105353, Val Acc: 0.793814\n",
      "Epoch 23855 - Train Loss: 0.071763, Train Acc: 0.894872 | Val Loss: 0.105353, Val Acc: 0.793814\n",
      "Epoch 23856 - Train Loss: 0.071761, Train Acc: 0.894872 | Val Loss: 0.105353, Val Acc: 0.793814\n",
      "Epoch 23857 - Train Loss: 0.071760, Train Acc: 0.894872 | Val Loss: 0.105353, Val Acc: 0.793814\n",
      "Epoch 23858 - Train Loss: 0.071758, Train Acc: 0.894872 | Val Loss: 0.105352, Val Acc: 0.793814\n",
      "Epoch 23859 - Train Loss: 0.071757, Train Acc: 0.894872 | Val Loss: 0.105352, Val Acc: 0.793814\n",
      "Epoch 23860 - Train Loss: 0.071755, Train Acc: 0.894872 | Val Loss: 0.105352, Val Acc: 0.793814\n",
      "Epoch 23861 - Train Loss: 0.071754, Train Acc: 0.894872 | Val Loss: 0.105351, Val Acc: 0.793814\n",
      "Epoch 23862 - Train Loss: 0.071752, Train Acc: 0.894872 | Val Loss: 0.105351, Val Acc: 0.793814\n",
      "Epoch 23863 - Train Loss: 0.071751, Train Acc: 0.894872 | Val Loss: 0.105351, Val Acc: 0.793814\n",
      "Epoch 23864 - Train Loss: 0.071749, Train Acc: 0.894872 | Val Loss: 0.105350, Val Acc: 0.793814\n",
      "Epoch 23865 - Train Loss: 0.071748, Train Acc: 0.894872 | Val Loss: 0.105350, Val Acc: 0.793814\n",
      "Epoch 23866 - Train Loss: 0.071746, Train Acc: 0.894872 | Val Loss: 0.105350, Val Acc: 0.793814\n",
      "Epoch 23867 - Train Loss: 0.071745, Train Acc: 0.894872 | Val Loss: 0.105349, Val Acc: 0.793814\n",
      "Epoch 23868 - Train Loss: 0.071743, Train Acc: 0.894872 | Val Loss: 0.105349, Val Acc: 0.793814\n",
      "Epoch 23869 - Train Loss: 0.071742, Train Acc: 0.894872 | Val Loss: 0.105349, Val Acc: 0.793814\n",
      "Epoch 23870 - Train Loss: 0.071740, Train Acc: 0.894872 | Val Loss: 0.105348, Val Acc: 0.793814\n",
      "Epoch 23871 - Train Loss: 0.071739, Train Acc: 0.894872 | Val Loss: 0.105348, Val Acc: 0.793814\n",
      "Epoch 23872 - Train Loss: 0.071737, Train Acc: 0.894872 | Val Loss: 0.105348, Val Acc: 0.793814\n",
      "Epoch 23873 - Train Loss: 0.071736, Train Acc: 0.894872 | Val Loss: 0.105347, Val Acc: 0.793814\n",
      "Epoch 23874 - Train Loss: 0.071734, Train Acc: 0.894872 | Val Loss: 0.105347, Val Acc: 0.793814\n",
      "Epoch 23875 - Train Loss: 0.071732, Train Acc: 0.894872 | Val Loss: 0.105347, Val Acc: 0.793814\n",
      "Epoch 23876 - Train Loss: 0.071731, Train Acc: 0.894872 | Val Loss: 0.105346, Val Acc: 0.793814\n",
      "Epoch 23877 - Train Loss: 0.071729, Train Acc: 0.894872 | Val Loss: 0.105346, Val Acc: 0.793814\n",
      "Epoch 23878 - Train Loss: 0.071728, Train Acc: 0.894872 | Val Loss: 0.105346, Val Acc: 0.793814\n",
      "Epoch 23879 - Train Loss: 0.071726, Train Acc: 0.894872 | Val Loss: 0.105345, Val Acc: 0.793814\n",
      "Epoch 23880 - Train Loss: 0.071725, Train Acc: 0.894872 | Val Loss: 0.105345, Val Acc: 0.793814\n",
      "Epoch 23881 - Train Loss: 0.071723, Train Acc: 0.894872 | Val Loss: 0.105345, Val Acc: 0.793814\n",
      "Epoch 23882 - Train Loss: 0.071722, Train Acc: 0.894872 | Val Loss: 0.105344, Val Acc: 0.793814\n",
      "Epoch 23883 - Train Loss: 0.071720, Train Acc: 0.894872 | Val Loss: 0.105344, Val Acc: 0.793814\n",
      "Epoch 23884 - Train Loss: 0.071719, Train Acc: 0.894872 | Val Loss: 0.105344, Val Acc: 0.793814\n",
      "Epoch 23885 - Train Loss: 0.071717, Train Acc: 0.894872 | Val Loss: 0.105343, Val Acc: 0.793814\n",
      "Epoch 23886 - Train Loss: 0.071716, Train Acc: 0.894872 | Val Loss: 0.105343, Val Acc: 0.793814\n",
      "Epoch 23887 - Train Loss: 0.071714, Train Acc: 0.894872 | Val Loss: 0.105343, Val Acc: 0.793814\n",
      "Epoch 23888 - Train Loss: 0.071713, Train Acc: 0.894872 | Val Loss: 0.105342, Val Acc: 0.793814\n",
      "Epoch 23889 - Train Loss: 0.071711, Train Acc: 0.894872 | Val Loss: 0.105342, Val Acc: 0.793814\n",
      "Epoch 23890 - Train Loss: 0.071710, Train Acc: 0.894872 | Val Loss: 0.105342, Val Acc: 0.793814\n",
      "Epoch 23891 - Train Loss: 0.071708, Train Acc: 0.894872 | Val Loss: 0.105341, Val Acc: 0.793814\n",
      "Epoch 23892 - Train Loss: 0.071707, Train Acc: 0.894872 | Val Loss: 0.105341, Val Acc: 0.793814\n",
      "Epoch 23893 - Train Loss: 0.071705, Train Acc: 0.894872 | Val Loss: 0.105341, Val Acc: 0.793814\n",
      "Epoch 23894 - Train Loss: 0.071704, Train Acc: 0.894872 | Val Loss: 0.105340, Val Acc: 0.793814\n",
      "Epoch 23895 - Train Loss: 0.071702, Train Acc: 0.894872 | Val Loss: 0.105340, Val Acc: 0.793814\n",
      "Epoch 23896 - Train Loss: 0.071701, Train Acc: 0.894872 | Val Loss: 0.105340, Val Acc: 0.793814\n",
      "Epoch 23897 - Train Loss: 0.071699, Train Acc: 0.894872 | Val Loss: 0.105340, Val Acc: 0.793814\n",
      "Epoch 23898 - Train Loss: 0.071698, Train Acc: 0.894872 | Val Loss: 0.105339, Val Acc: 0.793814\n",
      "Epoch 23899 - Train Loss: 0.071696, Train Acc: 0.894872 | Val Loss: 0.105339, Val Acc: 0.793814\n",
      "Epoch 23900 - Train Loss: 0.071695, Train Acc: 0.894872 | Val Loss: 0.105339, Val Acc: 0.793814\n",
      "Epoch 23901 - Train Loss: 0.071693, Train Acc: 0.894872 | Val Loss: 0.105338, Val Acc: 0.793814\n",
      "Epoch 23902 - Train Loss: 0.071692, Train Acc: 0.894872 | Val Loss: 0.105338, Val Acc: 0.793814\n",
      "Epoch 23903 - Train Loss: 0.071690, Train Acc: 0.894872 | Val Loss: 0.105338, Val Acc: 0.793814\n",
      "Epoch 23904 - Train Loss: 0.071689, Train Acc: 0.894872 | Val Loss: 0.105337, Val Acc: 0.793814\n",
      "Epoch 23905 - Train Loss: 0.071687, Train Acc: 0.894872 | Val Loss: 0.105337, Val Acc: 0.793814\n",
      "Epoch 23906 - Train Loss: 0.071686, Train Acc: 0.894872 | Val Loss: 0.105337, Val Acc: 0.793814\n",
      "Epoch 23907 - Train Loss: 0.071684, Train Acc: 0.894872 | Val Loss: 0.105336, Val Acc: 0.793814\n",
      "Epoch 23908 - Train Loss: 0.071683, Train Acc: 0.894872 | Val Loss: 0.105336, Val Acc: 0.793814\n",
      "Epoch 23909 - Train Loss: 0.071681, Train Acc: 0.894872 | Val Loss: 0.105336, Val Acc: 0.793814\n",
      "Epoch 23910 - Train Loss: 0.071680, Train Acc: 0.894872 | Val Loss: 0.105335, Val Acc: 0.793814\n",
      "Epoch 23911 - Train Loss: 0.071678, Train Acc: 0.894872 | Val Loss: 0.105335, Val Acc: 0.793814\n",
      "Epoch 23912 - Train Loss: 0.071676, Train Acc: 0.894872 | Val Loss: 0.105335, Val Acc: 0.793814\n",
      "Epoch 23913 - Train Loss: 0.071675, Train Acc: 0.894872 | Val Loss: 0.105334, Val Acc: 0.793814\n",
      "Epoch 23914 - Train Loss: 0.071673, Train Acc: 0.894872 | Val Loss: 0.105334, Val Acc: 0.793814\n",
      "Epoch 23915 - Train Loss: 0.071672, Train Acc: 0.894872 | Val Loss: 0.105334, Val Acc: 0.793814\n",
      "Epoch 23916 - Train Loss: 0.071670, Train Acc: 0.894872 | Val Loss: 0.105333, Val Acc: 0.793814\n",
      "Epoch 23917 - Train Loss: 0.071669, Train Acc: 0.894872 | Val Loss: 0.105333, Val Acc: 0.793814\n",
      "Epoch 23918 - Train Loss: 0.071667, Train Acc: 0.894872 | Val Loss: 0.105333, Val Acc: 0.793814\n",
      "Epoch 23919 - Train Loss: 0.071666, Train Acc: 0.894872 | Val Loss: 0.105332, Val Acc: 0.793814\n",
      "Epoch 23920 - Train Loss: 0.071664, Train Acc: 0.894872 | Val Loss: 0.105332, Val Acc: 0.793814\n",
      "Epoch 23921 - Train Loss: 0.071663, Train Acc: 0.894872 | Val Loss: 0.105332, Val Acc: 0.793814\n",
      "Epoch 23922 - Train Loss: 0.071661, Train Acc: 0.894872 | Val Loss: 0.105331, Val Acc: 0.793814\n",
      "Epoch 23923 - Train Loss: 0.071660, Train Acc: 0.894872 | Val Loss: 0.105331, Val Acc: 0.793814\n",
      "Epoch 23924 - Train Loss: 0.071658, Train Acc: 0.894872 | Val Loss: 0.105331, Val Acc: 0.793814\n",
      "Epoch 23925 - Train Loss: 0.071657, Train Acc: 0.894872 | Val Loss: 0.105331, Val Acc: 0.793814\n",
      "Epoch 23926 - Train Loss: 0.071655, Train Acc: 0.894872 | Val Loss: 0.105330, Val Acc: 0.793814\n",
      "Epoch 23927 - Train Loss: 0.071654, Train Acc: 0.894872 | Val Loss: 0.105330, Val Acc: 0.793814\n",
      "Epoch 23928 - Train Loss: 0.071652, Train Acc: 0.894872 | Val Loss: 0.105330, Val Acc: 0.793814\n",
      "Epoch 23929 - Train Loss: 0.071651, Train Acc: 0.894872 | Val Loss: 0.105329, Val Acc: 0.793814\n",
      "Epoch 23930 - Train Loss: 0.071649, Train Acc: 0.894872 | Val Loss: 0.105329, Val Acc: 0.793814\n",
      "Epoch 23931 - Train Loss: 0.071648, Train Acc: 0.894872 | Val Loss: 0.105329, Val Acc: 0.793814\n",
      "Epoch 23932 - Train Loss: 0.071646, Train Acc: 0.894872 | Val Loss: 0.105328, Val Acc: 0.793814\n",
      "Epoch 23933 - Train Loss: 0.071645, Train Acc: 0.894872 | Val Loss: 0.105328, Val Acc: 0.793814\n",
      "Epoch 23934 - Train Loss: 0.071643, Train Acc: 0.894872 | Val Loss: 0.105328, Val Acc: 0.793814\n",
      "Epoch 23935 - Train Loss: 0.071642, Train Acc: 0.894872 | Val Loss: 0.105327, Val Acc: 0.793814\n",
      "Epoch 23936 - Train Loss: 0.071640, Train Acc: 0.894872 | Val Loss: 0.105327, Val Acc: 0.793814\n",
      "Epoch 23937 - Train Loss: 0.071639, Train Acc: 0.894872 | Val Loss: 0.105327, Val Acc: 0.793814\n",
      "Epoch 23938 - Train Loss: 0.071637, Train Acc: 0.894872 | Val Loss: 0.105326, Val Acc: 0.793814\n",
      "Epoch 23939 - Train Loss: 0.071636, Train Acc: 0.894872 | Val Loss: 0.105326, Val Acc: 0.793814\n",
      "Epoch 23940 - Train Loss: 0.071634, Train Acc: 0.894872 | Val Loss: 0.105326, Val Acc: 0.793814\n",
      "Epoch 23941 - Train Loss: 0.071633, Train Acc: 0.894872 | Val Loss: 0.105325, Val Acc: 0.793814\n",
      "Epoch 23942 - Train Loss: 0.071631, Train Acc: 0.894872 | Val Loss: 0.105325, Val Acc: 0.793814\n",
      "Epoch 23943 - Train Loss: 0.071630, Train Acc: 0.894872 | Val Loss: 0.105325, Val Acc: 0.793814\n",
      "Epoch 23944 - Train Loss: 0.071628, Train Acc: 0.894872 | Val Loss: 0.105324, Val Acc: 0.793814\n",
      "Epoch 23945 - Train Loss: 0.071627, Train Acc: 0.894872 | Val Loss: 0.105324, Val Acc: 0.793814\n",
      "Epoch 23946 - Train Loss: 0.071625, Train Acc: 0.894872 | Val Loss: 0.105324, Val Acc: 0.793814\n",
      "Epoch 23947 - Train Loss: 0.071624, Train Acc: 0.894872 | Val Loss: 0.105323, Val Acc: 0.793814\n",
      "Epoch 23948 - Train Loss: 0.071622, Train Acc: 0.894872 | Val Loss: 0.105323, Val Acc: 0.793814\n",
      "Epoch 23949 - Train Loss: 0.071621, Train Acc: 0.894872 | Val Loss: 0.105323, Val Acc: 0.793814\n",
      "Epoch 23950 - Train Loss: 0.071619, Train Acc: 0.894872 | Val Loss: 0.105323, Val Acc: 0.793814\n",
      "Epoch 23951 - Train Loss: 0.071618, Train Acc: 0.894872 | Val Loss: 0.105322, Val Acc: 0.793814\n",
      "Epoch 23952 - Train Loss: 0.071616, Train Acc: 0.894872 | Val Loss: 0.105322, Val Acc: 0.793814\n",
      "Epoch 23953 - Train Loss: 0.071615, Train Acc: 0.894872 | Val Loss: 0.105322, Val Acc: 0.793814\n",
      "Epoch 23954 - Train Loss: 0.071613, Train Acc: 0.894872 | Val Loss: 0.105321, Val Acc: 0.793814\n",
      "Epoch 23955 - Train Loss: 0.071612, Train Acc: 0.894872 | Val Loss: 0.105321, Val Acc: 0.793814\n",
      "Epoch 23956 - Train Loss: 0.071610, Train Acc: 0.894872 | Val Loss: 0.105321, Val Acc: 0.793814\n",
      "Epoch 23957 - Train Loss: 0.071609, Train Acc: 0.894872 | Val Loss: 0.105320, Val Acc: 0.793814\n",
      "Epoch 23958 - Train Loss: 0.071607, Train Acc: 0.894872 | Val Loss: 0.105320, Val Acc: 0.793814\n",
      "Epoch 23959 - Train Loss: 0.071606, Train Acc: 0.894872 | Val Loss: 0.105320, Val Acc: 0.793814\n",
      "Epoch 23960 - Train Loss: 0.071604, Train Acc: 0.894872 | Val Loss: 0.105319, Val Acc: 0.793814\n",
      "Epoch 23961 - Train Loss: 0.071603, Train Acc: 0.894872 | Val Loss: 0.105319, Val Acc: 0.793814\n",
      "Epoch 23962 - Train Loss: 0.071601, Train Acc: 0.894872 | Val Loss: 0.105319, Val Acc: 0.793814\n",
      "Epoch 23963 - Train Loss: 0.071600, Train Acc: 0.894872 | Val Loss: 0.105318, Val Acc: 0.793814\n",
      "Epoch 23964 - Train Loss: 0.071598, Train Acc: 0.894872 | Val Loss: 0.105318, Val Acc: 0.793814\n",
      "Epoch 23965 - Train Loss: 0.071597, Train Acc: 0.894872 | Val Loss: 0.105318, Val Acc: 0.793814\n",
      "Epoch 23966 - Train Loss: 0.071595, Train Acc: 0.894872 | Val Loss: 0.105317, Val Acc: 0.793814\n",
      "Epoch 23967 - Train Loss: 0.071594, Train Acc: 0.894872 | Val Loss: 0.105317, Val Acc: 0.793814\n",
      "Epoch 23968 - Train Loss: 0.071592, Train Acc: 0.894872 | Val Loss: 0.105317, Val Acc: 0.793814\n",
      "Epoch 23969 - Train Loss: 0.071591, Train Acc: 0.894872 | Val Loss: 0.105316, Val Acc: 0.793814\n",
      "Epoch 23970 - Train Loss: 0.071589, Train Acc: 0.894872 | Val Loss: 0.105316, Val Acc: 0.793814\n",
      "Epoch 23971 - Train Loss: 0.071588, Train Acc: 0.894872 | Val Loss: 0.105316, Val Acc: 0.793814\n",
      "Epoch 23972 - Train Loss: 0.071586, Train Acc: 0.894872 | Val Loss: 0.105316, Val Acc: 0.793814\n",
      "Epoch 23973 - Train Loss: 0.071585, Train Acc: 0.894872 | Val Loss: 0.105315, Val Acc: 0.793814\n",
      "Epoch 23974 - Train Loss: 0.071583, Train Acc: 0.894872 | Val Loss: 0.105315, Val Acc: 0.793814\n",
      "Epoch 23975 - Train Loss: 0.071582, Train Acc: 0.894872 | Val Loss: 0.105315, Val Acc: 0.793814\n",
      "Epoch 23976 - Train Loss: 0.071580, Train Acc: 0.894872 | Val Loss: 0.105314, Val Acc: 0.793814\n",
      "Epoch 23977 - Train Loss: 0.071578, Train Acc: 0.894872 | Val Loss: 0.105314, Val Acc: 0.793814\n",
      "Epoch 23978 - Train Loss: 0.071577, Train Acc: 0.894872 | Val Loss: 0.105314, Val Acc: 0.793814\n",
      "Epoch 23979 - Train Loss: 0.071575, Train Acc: 0.894872 | Val Loss: 0.105313, Val Acc: 0.793814\n",
      "Epoch 23980 - Train Loss: 0.071574, Train Acc: 0.894872 | Val Loss: 0.105313, Val Acc: 0.793814\n",
      "Epoch 23981 - Train Loss: 0.071572, Train Acc: 0.894872 | Val Loss: 0.105313, Val Acc: 0.793814\n",
      "Epoch 23982 - Train Loss: 0.071571, Train Acc: 0.894872 | Val Loss: 0.105312, Val Acc: 0.793814\n",
      "Epoch 23983 - Train Loss: 0.071569, Train Acc: 0.894872 | Val Loss: 0.105312, Val Acc: 0.793814\n",
      "Epoch 23984 - Train Loss: 0.071568, Train Acc: 0.894872 | Val Loss: 0.105312, Val Acc: 0.793814\n",
      "Epoch 23985 - Train Loss: 0.071566, Train Acc: 0.894872 | Val Loss: 0.105311, Val Acc: 0.793814\n",
      "Epoch 23986 - Train Loss: 0.071565, Train Acc: 0.894872 | Val Loss: 0.105311, Val Acc: 0.793814\n",
      "Epoch 23987 - Train Loss: 0.071563, Train Acc: 0.894872 | Val Loss: 0.105311, Val Acc: 0.793814\n",
      "Epoch 23988 - Train Loss: 0.071562, Train Acc: 0.894872 | Val Loss: 0.105310, Val Acc: 0.793814\n",
      "Epoch 23989 - Train Loss: 0.071560, Train Acc: 0.894872 | Val Loss: 0.105310, Val Acc: 0.793814\n",
      "Epoch 23990 - Train Loss: 0.071559, Train Acc: 0.894872 | Val Loss: 0.105310, Val Acc: 0.793814\n",
      "Epoch 23991 - Train Loss: 0.071557, Train Acc: 0.894872 | Val Loss: 0.105310, Val Acc: 0.793814\n",
      "Epoch 23992 - Train Loss: 0.071556, Train Acc: 0.894872 | Val Loss: 0.105309, Val Acc: 0.793814\n",
      "Epoch 23993 - Train Loss: 0.071554, Train Acc: 0.894872 | Val Loss: 0.105309, Val Acc: 0.793814\n",
      "Epoch 23994 - Train Loss: 0.071553, Train Acc: 0.894872 | Val Loss: 0.105309, Val Acc: 0.793814\n",
      "Epoch 23995 - Train Loss: 0.071551, Train Acc: 0.894872 | Val Loss: 0.105308, Val Acc: 0.793814\n",
      "Epoch 23996 - Train Loss: 0.071550, Train Acc: 0.894872 | Val Loss: 0.105308, Val Acc: 0.793814\n",
      "Epoch 23997 - Train Loss: 0.071548, Train Acc: 0.894872 | Val Loss: 0.105308, Val Acc: 0.793814\n",
      "Epoch 23998 - Train Loss: 0.071547, Train Acc: 0.894872 | Val Loss: 0.105307, Val Acc: 0.793814\n",
      "Epoch 23999 - Train Loss: 0.071545, Train Acc: 0.894872 | Val Loss: 0.105307, Val Acc: 0.793814\n",
      "Epoch 24000 - Train Loss: 0.071544, Train Acc: 0.894872 | Val Loss: 0.105307, Val Acc: 0.793814\n",
      "Epoch 24001 - Train Loss: 0.071542, Train Acc: 0.894872 | Val Loss: 0.105306, Val Acc: 0.793814\n",
      "Epoch 24002 - Train Loss: 0.071541, Train Acc: 0.894872 | Val Loss: 0.105306, Val Acc: 0.793814\n",
      "Epoch 24003 - Train Loss: 0.071539, Train Acc: 0.894872 | Val Loss: 0.105306, Val Acc: 0.793814\n",
      "Epoch 24004 - Train Loss: 0.071538, Train Acc: 0.894872 | Val Loss: 0.105305, Val Acc: 0.793814\n",
      "Epoch 24005 - Train Loss: 0.071536, Train Acc: 0.894872 | Val Loss: 0.105305, Val Acc: 0.793814\n",
      "Epoch 24006 - Train Loss: 0.071535, Train Acc: 0.894872 | Val Loss: 0.105305, Val Acc: 0.793814\n",
      "Epoch 24007 - Train Loss: 0.071533, Train Acc: 0.894872 | Val Loss: 0.105305, Val Acc: 0.793814\n",
      "Epoch 24008 - Train Loss: 0.071532, Train Acc: 0.894872 | Val Loss: 0.105304, Val Acc: 0.793814\n",
      "Epoch 24009 - Train Loss: 0.071530, Train Acc: 0.894872 | Val Loss: 0.105304, Val Acc: 0.793814\n",
      "Epoch 24010 - Train Loss: 0.071529, Train Acc: 0.894872 | Val Loss: 0.105304, Val Acc: 0.793814\n",
      "Epoch 24011 - Train Loss: 0.071527, Train Acc: 0.894872 | Val Loss: 0.105303, Val Acc: 0.793814\n",
      "Epoch 24012 - Train Loss: 0.071526, Train Acc: 0.894872 | Val Loss: 0.105303, Val Acc: 0.793814\n",
      "Epoch 24013 - Train Loss: 0.071524, Train Acc: 0.894872 | Val Loss: 0.105303, Val Acc: 0.793814\n",
      "Epoch 24014 - Train Loss: 0.071523, Train Acc: 0.894872 | Val Loss: 0.105302, Val Acc: 0.793814\n",
      "Epoch 24015 - Train Loss: 0.071521, Train Acc: 0.894872 | Val Loss: 0.105302, Val Acc: 0.793814\n",
      "Epoch 24016 - Train Loss: 0.071520, Train Acc: 0.894872 | Val Loss: 0.105302, Val Acc: 0.793814\n",
      "Epoch 24017 - Train Loss: 0.071518, Train Acc: 0.894872 | Val Loss: 0.105301, Val Acc: 0.793814\n",
      "Epoch 24018 - Train Loss: 0.071517, Train Acc: 0.894872 | Val Loss: 0.105301, Val Acc: 0.793814\n",
      "Epoch 24019 - Train Loss: 0.071515, Train Acc: 0.894872 | Val Loss: 0.105301, Val Acc: 0.793814\n",
      "Epoch 24020 - Train Loss: 0.071514, Train Acc: 0.894872 | Val Loss: 0.105300, Val Acc: 0.793814\n",
      "Epoch 24021 - Train Loss: 0.071512, Train Acc: 0.894872 | Val Loss: 0.105300, Val Acc: 0.793814\n",
      "Epoch 24022 - Train Loss: 0.071511, Train Acc: 0.894872 | Val Loss: 0.105300, Val Acc: 0.793814\n",
      "Epoch 24023 - Train Loss: 0.071509, Train Acc: 0.894872 | Val Loss: 0.105300, Val Acc: 0.793814\n",
      "Epoch 24024 - Train Loss: 0.071508, Train Acc: 0.894872 | Val Loss: 0.105299, Val Acc: 0.793814\n",
      "Epoch 24025 - Train Loss: 0.071506, Train Acc: 0.894872 | Val Loss: 0.105299, Val Acc: 0.793814\n",
      "Epoch 24026 - Train Loss: 0.071505, Train Acc: 0.894872 | Val Loss: 0.105299, Val Acc: 0.793814\n",
      "Epoch 24027 - Train Loss: 0.071503, Train Acc: 0.894872 | Val Loss: 0.105298, Val Acc: 0.793814\n",
      "Epoch 24028 - Train Loss: 0.071502, Train Acc: 0.894872 | Val Loss: 0.105298, Val Acc: 0.793814\n",
      "Epoch 24029 - Train Loss: 0.071500, Train Acc: 0.894872 | Val Loss: 0.105298, Val Acc: 0.793814\n",
      "Epoch 24030 - Train Loss: 0.071499, Train Acc: 0.894872 | Val Loss: 0.105297, Val Acc: 0.793814\n",
      "Epoch 24031 - Train Loss: 0.071497, Train Acc: 0.894872 | Val Loss: 0.105297, Val Acc: 0.793814\n",
      "Epoch 24032 - Train Loss: 0.071496, Train Acc: 0.894872 | Val Loss: 0.105297, Val Acc: 0.793814\n",
      "Epoch 24033 - Train Loss: 0.071494, Train Acc: 0.894872 | Val Loss: 0.105296, Val Acc: 0.793814\n",
      "Epoch 24034 - Train Loss: 0.071493, Train Acc: 0.894872 | Val Loss: 0.105296, Val Acc: 0.793814\n",
      "Epoch 24035 - Train Loss: 0.071491, Train Acc: 0.894872 | Val Loss: 0.105296, Val Acc: 0.793814\n",
      "Epoch 24036 - Train Loss: 0.071490, Train Acc: 0.894872 | Val Loss: 0.105295, Val Acc: 0.793814\n",
      "Epoch 24037 - Train Loss: 0.071488, Train Acc: 0.894872 | Val Loss: 0.105295, Val Acc: 0.793814\n",
      "Epoch 24038 - Train Loss: 0.071487, Train Acc: 0.894872 | Val Loss: 0.105295, Val Acc: 0.793814\n",
      "Epoch 24039 - Train Loss: 0.071485, Train Acc: 0.894872 | Val Loss: 0.105295, Val Acc: 0.793814\n",
      "Epoch 24040 - Train Loss: 0.071484, Train Acc: 0.894872 | Val Loss: 0.105294, Val Acc: 0.793814\n",
      "Epoch 24041 - Train Loss: 0.071482, Train Acc: 0.894872 | Val Loss: 0.105294, Val Acc: 0.793814\n",
      "Epoch 24042 - Train Loss: 0.071481, Train Acc: 0.894872 | Val Loss: 0.105294, Val Acc: 0.793814\n",
      "Epoch 24043 - Train Loss: 0.071479, Train Acc: 0.894872 | Val Loss: 0.105293, Val Acc: 0.793814\n",
      "Epoch 24044 - Train Loss: 0.071478, Train Acc: 0.894872 | Val Loss: 0.105293, Val Acc: 0.793814\n",
      "Epoch 24045 - Train Loss: 0.071476, Train Acc: 0.894872 | Val Loss: 0.105293, Val Acc: 0.793814\n",
      "Epoch 24046 - Train Loss: 0.071475, Train Acc: 0.894872 | Val Loss: 0.105292, Val Acc: 0.793814\n",
      "Epoch 24047 - Train Loss: 0.071474, Train Acc: 0.894872 | Val Loss: 0.105292, Val Acc: 0.793814\n",
      "Epoch 24048 - Train Loss: 0.071472, Train Acc: 0.894872 | Val Loss: 0.105292, Val Acc: 0.793814\n",
      "Epoch 24049 - Train Loss: 0.071471, Train Acc: 0.894872 | Val Loss: 0.105291, Val Acc: 0.793814\n",
      "Epoch 24050 - Train Loss: 0.071469, Train Acc: 0.894872 | Val Loss: 0.105291, Val Acc: 0.793814\n",
      "Epoch 24051 - Train Loss: 0.071468, Train Acc: 0.894872 | Val Loss: 0.105291, Val Acc: 0.793814\n",
      "Epoch 24052 - Train Loss: 0.071466, Train Acc: 0.894872 | Val Loss: 0.105291, Val Acc: 0.793814\n",
      "Epoch 24053 - Train Loss: 0.071465, Train Acc: 0.894872 | Val Loss: 0.105290, Val Acc: 0.793814\n",
      "Epoch 24054 - Train Loss: 0.071463, Train Acc: 0.894872 | Val Loss: 0.105290, Val Acc: 0.793814\n",
      "Epoch 24055 - Train Loss: 0.071462, Train Acc: 0.894872 | Val Loss: 0.105290, Val Acc: 0.793814\n",
      "Epoch 24056 - Train Loss: 0.071460, Train Acc: 0.894872 | Val Loss: 0.105289, Val Acc: 0.793814\n",
      "Epoch 24057 - Train Loss: 0.071459, Train Acc: 0.894872 | Val Loss: 0.105289, Val Acc: 0.793814\n",
      "Epoch 24058 - Train Loss: 0.071457, Train Acc: 0.894872 | Val Loss: 0.105289, Val Acc: 0.793814\n",
      "Epoch 24059 - Train Loss: 0.071456, Train Acc: 0.894872 | Val Loss: 0.105288, Val Acc: 0.793814\n",
      "Epoch 24060 - Train Loss: 0.071454, Train Acc: 0.894872 | Val Loss: 0.105288, Val Acc: 0.793814\n",
      "Epoch 24061 - Train Loss: 0.071453, Train Acc: 0.894872 | Val Loss: 0.105288, Val Acc: 0.793814\n",
      "Epoch 24062 - Train Loss: 0.071451, Train Acc: 0.894872 | Val Loss: 0.105287, Val Acc: 0.793814\n",
      "Epoch 24063 - Train Loss: 0.071450, Train Acc: 0.894872 | Val Loss: 0.105287, Val Acc: 0.793814\n",
      "Epoch 24064 - Train Loss: 0.071448, Train Acc: 0.894872 | Val Loss: 0.105287, Val Acc: 0.793814\n",
      "Epoch 24065 - Train Loss: 0.071447, Train Acc: 0.894872 | Val Loss: 0.105287, Val Acc: 0.793814\n",
      "Epoch 24066 - Train Loss: 0.071445, Train Acc: 0.894872 | Val Loss: 0.105286, Val Acc: 0.793814\n",
      "Epoch 24067 - Train Loss: 0.071444, Train Acc: 0.894872 | Val Loss: 0.105286, Val Acc: 0.793814\n",
      "Epoch 24068 - Train Loss: 0.071442, Train Acc: 0.894872 | Val Loss: 0.105286, Val Acc: 0.793814\n",
      "Epoch 24069 - Train Loss: 0.071441, Train Acc: 0.894872 | Val Loss: 0.105285, Val Acc: 0.793814\n",
      "Epoch 24070 - Train Loss: 0.071439, Train Acc: 0.894872 | Val Loss: 0.105285, Val Acc: 0.793814\n",
      "Epoch 24071 - Train Loss: 0.071438, Train Acc: 0.894872 | Val Loss: 0.105285, Val Acc: 0.793814\n",
      "Epoch 24072 - Train Loss: 0.071436, Train Acc: 0.894872 | Val Loss: 0.105284, Val Acc: 0.793814\n",
      "Epoch 24073 - Train Loss: 0.071435, Train Acc: 0.894872 | Val Loss: 0.105284, Val Acc: 0.793814\n",
      "Epoch 24074 - Train Loss: 0.071433, Train Acc: 0.894872 | Val Loss: 0.105284, Val Acc: 0.793814\n",
      "Epoch 24075 - Train Loss: 0.071432, Train Acc: 0.894872 | Val Loss: 0.105284, Val Acc: 0.793814\n",
      "Epoch 24076 - Train Loss: 0.071430, Train Acc: 0.894872 | Val Loss: 0.105283, Val Acc: 0.793814\n",
      "Epoch 24077 - Train Loss: 0.071429, Train Acc: 0.894872 | Val Loss: 0.105283, Val Acc: 0.793814\n",
      "Epoch 24078 - Train Loss: 0.071427, Train Acc: 0.894872 | Val Loss: 0.105283, Val Acc: 0.793814\n",
      "Epoch 24079 - Train Loss: 0.071426, Train Acc: 0.894872 | Val Loss: 0.105282, Val Acc: 0.793814\n",
      "Epoch 24080 - Train Loss: 0.071424, Train Acc: 0.894872 | Val Loss: 0.105282, Val Acc: 0.793814\n",
      "Epoch 24081 - Train Loss: 0.071423, Train Acc: 0.894872 | Val Loss: 0.105282, Val Acc: 0.793814\n",
      "Epoch 24082 - Train Loss: 0.071421, Train Acc: 0.894872 | Val Loss: 0.105281, Val Acc: 0.793814\n",
      "Epoch 24083 - Train Loss: 0.071420, Train Acc: 0.894872 | Val Loss: 0.105281, Val Acc: 0.793814\n",
      "Epoch 24084 - Train Loss: 0.071418, Train Acc: 0.894872 | Val Loss: 0.105281, Val Acc: 0.793814\n",
      "Epoch 24085 - Train Loss: 0.071417, Train Acc: 0.894872 | Val Loss: 0.105280, Val Acc: 0.793814\n",
      "Epoch 24086 - Train Loss: 0.071415, Train Acc: 0.894872 | Val Loss: 0.105280, Val Acc: 0.793814\n",
      "Epoch 24087 - Train Loss: 0.071414, Train Acc: 0.894872 | Val Loss: 0.105280, Val Acc: 0.793814\n",
      "Epoch 24088 - Train Loss: 0.071412, Train Acc: 0.894872 | Val Loss: 0.105280, Val Acc: 0.793814\n",
      "Epoch 24089 - Train Loss: 0.071411, Train Acc: 0.894872 | Val Loss: 0.105279, Val Acc: 0.793814\n",
      "Epoch 24090 - Train Loss: 0.071409, Train Acc: 0.894872 | Val Loss: 0.105279, Val Acc: 0.793814\n",
      "Epoch 24091 - Train Loss: 0.071408, Train Acc: 0.894872 | Val Loss: 0.105279, Val Acc: 0.793814\n",
      "Epoch 24092 - Train Loss: 0.071406, Train Acc: 0.894872 | Val Loss: 0.105278, Val Acc: 0.793814\n",
      "Epoch 24093 - Train Loss: 0.071405, Train Acc: 0.894872 | Val Loss: 0.105278, Val Acc: 0.793814\n",
      "Epoch 24094 - Train Loss: 0.071403, Train Acc: 0.894872 | Val Loss: 0.105278, Val Acc: 0.793814\n",
      "Epoch 24095 - Train Loss: 0.071402, Train Acc: 0.894872 | Val Loss: 0.105277, Val Acc: 0.793814\n",
      "Epoch 24096 - Train Loss: 0.071400, Train Acc: 0.894872 | Val Loss: 0.105277, Val Acc: 0.793814\n",
      "Epoch 24097 - Train Loss: 0.071399, Train Acc: 0.894872 | Val Loss: 0.105277, Val Acc: 0.793814\n",
      "Epoch 24098 - Train Loss: 0.071397, Train Acc: 0.894872 | Val Loss: 0.105276, Val Acc: 0.793814\n",
      "Epoch 24099 - Train Loss: 0.071396, Train Acc: 0.894872 | Val Loss: 0.105276, Val Acc: 0.793814\n",
      "Epoch 24100 - Train Loss: 0.071394, Train Acc: 0.894872 | Val Loss: 0.105276, Val Acc: 0.793814\n",
      "Epoch 24101 - Train Loss: 0.071393, Train Acc: 0.894872 | Val Loss: 0.105276, Val Acc: 0.793814\n",
      "Epoch 24102 - Train Loss: 0.071391, Train Acc: 0.894872 | Val Loss: 0.105275, Val Acc: 0.793814\n",
      "Epoch 24103 - Train Loss: 0.071390, Train Acc: 0.894872 | Val Loss: 0.105275, Val Acc: 0.793814\n",
      "Epoch 24104 - Train Loss: 0.071388, Train Acc: 0.894872 | Val Loss: 0.105275, Val Acc: 0.793814\n",
      "Epoch 24105 - Train Loss: 0.071387, Train Acc: 0.894872 | Val Loss: 0.105274, Val Acc: 0.793814\n",
      "Epoch 24106 - Train Loss: 0.071385, Train Acc: 0.894872 | Val Loss: 0.105274, Val Acc: 0.793814\n",
      "Epoch 24107 - Train Loss: 0.071384, Train Acc: 0.894872 | Val Loss: 0.105274, Val Acc: 0.793814\n",
      "Epoch 24108 - Train Loss: 0.071382, Train Acc: 0.894872 | Val Loss: 0.105273, Val Acc: 0.793814\n",
      "Epoch 24109 - Train Loss: 0.071381, Train Acc: 0.894872 | Val Loss: 0.105273, Val Acc: 0.793814\n",
      "Epoch 24110 - Train Loss: 0.071379, Train Acc: 0.894872 | Val Loss: 0.105273, Val Acc: 0.793814\n",
      "Epoch 24111 - Train Loss: 0.071378, Train Acc: 0.894872 | Val Loss: 0.105273, Val Acc: 0.793814\n",
      "Epoch 24112 - Train Loss: 0.071376, Train Acc: 0.894872 | Val Loss: 0.105272, Val Acc: 0.793814\n",
      "Epoch 24113 - Train Loss: 0.071375, Train Acc: 0.894872 | Val Loss: 0.105272, Val Acc: 0.793814\n",
      "Epoch 24114 - Train Loss: 0.071374, Train Acc: 0.894872 | Val Loss: 0.105272, Val Acc: 0.793814\n",
      "Epoch 24115 - Train Loss: 0.071372, Train Acc: 0.894872 | Val Loss: 0.105271, Val Acc: 0.793814\n",
      "Epoch 24116 - Train Loss: 0.071371, Train Acc: 0.894872 | Val Loss: 0.105271, Val Acc: 0.793814\n",
      "Epoch 24117 - Train Loss: 0.071369, Train Acc: 0.894872 | Val Loss: 0.105271, Val Acc: 0.793814\n",
      "Epoch 24118 - Train Loss: 0.071368, Train Acc: 0.894872 | Val Loss: 0.105270, Val Acc: 0.793814\n",
      "Epoch 24119 - Train Loss: 0.071366, Train Acc: 0.894872 | Val Loss: 0.105270, Val Acc: 0.793814\n",
      "Epoch 24120 - Train Loss: 0.071365, Train Acc: 0.894872 | Val Loss: 0.105270, Val Acc: 0.793814\n",
      "Epoch 24121 - Train Loss: 0.071363, Train Acc: 0.894872 | Val Loss: 0.105270, Val Acc: 0.793814\n",
      "Epoch 24122 - Train Loss: 0.071362, Train Acc: 0.894872 | Val Loss: 0.105269, Val Acc: 0.793814\n",
      "Epoch 24123 - Train Loss: 0.071360, Train Acc: 0.894872 | Val Loss: 0.105269, Val Acc: 0.793814\n",
      "Epoch 24124 - Train Loss: 0.071359, Train Acc: 0.894872 | Val Loss: 0.105269, Val Acc: 0.793814\n",
      "Epoch 24125 - Train Loss: 0.071357, Train Acc: 0.894872 | Val Loss: 0.105268, Val Acc: 0.793814\n",
      "Epoch 24126 - Train Loss: 0.071356, Train Acc: 0.894872 | Val Loss: 0.105268, Val Acc: 0.793814\n",
      "Epoch 24127 - Train Loss: 0.071354, Train Acc: 0.894872 | Val Loss: 0.105268, Val Acc: 0.793814\n",
      "Epoch 24128 - Train Loss: 0.071353, Train Acc: 0.894872 | Val Loss: 0.105268, Val Acc: 0.793814\n",
      "Epoch 24129 - Train Loss: 0.071351, Train Acc: 0.894872 | Val Loss: 0.105267, Val Acc: 0.793814\n",
      "Epoch 24130 - Train Loss: 0.071350, Train Acc: 0.894872 | Val Loss: 0.105267, Val Acc: 0.793814\n",
      "Epoch 24131 - Train Loss: 0.071348, Train Acc: 0.894872 | Val Loss: 0.105267, Val Acc: 0.793814\n",
      "Epoch 24132 - Train Loss: 0.071347, Train Acc: 0.894872 | Val Loss: 0.105266, Val Acc: 0.793814\n",
      "Epoch 24133 - Train Loss: 0.071345, Train Acc: 0.894872 | Val Loss: 0.105266, Val Acc: 0.793814\n",
      "Epoch 24134 - Train Loss: 0.071344, Train Acc: 0.894872 | Val Loss: 0.105266, Val Acc: 0.793814\n",
      "Epoch 24135 - Train Loss: 0.071342, Train Acc: 0.894872 | Val Loss: 0.105265, Val Acc: 0.793814\n",
      "Epoch 24136 - Train Loss: 0.071341, Train Acc: 0.894872 | Val Loss: 0.105265, Val Acc: 0.793814\n",
      "Epoch 24137 - Train Loss: 0.071339, Train Acc: 0.894872 | Val Loss: 0.105265, Val Acc: 0.793814\n",
      "Epoch 24138 - Train Loss: 0.071338, Train Acc: 0.894872 | Val Loss: 0.105264, Val Acc: 0.793814\n",
      "Epoch 24139 - Train Loss: 0.071336, Train Acc: 0.894872 | Val Loss: 0.105264, Val Acc: 0.793814\n",
      "Epoch 24140 - Train Loss: 0.071335, Train Acc: 0.894872 | Val Loss: 0.105264, Val Acc: 0.793814\n",
      "Epoch 24141 - Train Loss: 0.071333, Train Acc: 0.894872 | Val Loss: 0.105264, Val Acc: 0.793814\n",
      "Epoch 24142 - Train Loss: 0.071332, Train Acc: 0.894872 | Val Loss: 0.105263, Val Acc: 0.793814\n",
      "Epoch 24143 - Train Loss: 0.071330, Train Acc: 0.894872 | Val Loss: 0.105263, Val Acc: 0.793814\n",
      "Epoch 24144 - Train Loss: 0.071329, Train Acc: 0.894872 | Val Loss: 0.105263, Val Acc: 0.793814\n",
      "Epoch 24145 - Train Loss: 0.071327, Train Acc: 0.894872 | Val Loss: 0.105262, Val Acc: 0.793814\n",
      "Epoch 24146 - Train Loss: 0.071326, Train Acc: 0.894872 | Val Loss: 0.105262, Val Acc: 0.793814\n",
      "Epoch 24147 - Train Loss: 0.071324, Train Acc: 0.894872 | Val Loss: 0.105262, Val Acc: 0.793814\n",
      "Epoch 24148 - Train Loss: 0.071323, Train Acc: 0.894872 | Val Loss: 0.105261, Val Acc: 0.793814\n",
      "Epoch 24149 - Train Loss: 0.071322, Train Acc: 0.894872 | Val Loss: 0.105261, Val Acc: 0.793814\n",
      "Epoch 24150 - Train Loss: 0.071320, Train Acc: 0.894872 | Val Loss: 0.105261, Val Acc: 0.793814\n",
      "Epoch 24151 - Train Loss: 0.071319, Train Acc: 0.894872 | Val Loss: 0.105261, Val Acc: 0.793814\n",
      "Epoch 24152 - Train Loss: 0.071317, Train Acc: 0.894872 | Val Loss: 0.105260, Val Acc: 0.793814\n",
      "Epoch 24153 - Train Loss: 0.071316, Train Acc: 0.894872 | Val Loss: 0.105260, Val Acc: 0.793814\n",
      "Epoch 24154 - Train Loss: 0.071314, Train Acc: 0.894872 | Val Loss: 0.105260, Val Acc: 0.793814\n",
      "Epoch 24155 - Train Loss: 0.071313, Train Acc: 0.894872 | Val Loss: 0.105259, Val Acc: 0.793814\n",
      "Epoch 24156 - Train Loss: 0.071311, Train Acc: 0.894872 | Val Loss: 0.105259, Val Acc: 0.793814\n",
      "Epoch 24157 - Train Loss: 0.071310, Train Acc: 0.894872 | Val Loss: 0.105259, Val Acc: 0.793814\n",
      "Epoch 24158 - Train Loss: 0.071308, Train Acc: 0.894872 | Val Loss: 0.105258, Val Acc: 0.793814\n",
      "Epoch 24159 - Train Loss: 0.071307, Train Acc: 0.894872 | Val Loss: 0.105258, Val Acc: 0.793814\n",
      "Epoch 24160 - Train Loss: 0.071305, Train Acc: 0.894872 | Val Loss: 0.105258, Val Acc: 0.793814\n",
      "Epoch 24161 - Train Loss: 0.071304, Train Acc: 0.894872 | Val Loss: 0.105258, Val Acc: 0.793814\n",
      "Epoch 24162 - Train Loss: 0.071302, Train Acc: 0.894872 | Val Loss: 0.105257, Val Acc: 0.793814\n",
      "Epoch 24163 - Train Loss: 0.071301, Train Acc: 0.894872 | Val Loss: 0.105257, Val Acc: 0.793814\n",
      "Epoch 24164 - Train Loss: 0.071299, Train Acc: 0.894872 | Val Loss: 0.105257, Val Acc: 0.793814\n",
      "Epoch 24165 - Train Loss: 0.071298, Train Acc: 0.894872 | Val Loss: 0.105256, Val Acc: 0.793814\n",
      "Epoch 24166 - Train Loss: 0.071296, Train Acc: 0.894872 | Val Loss: 0.105256, Val Acc: 0.793814\n",
      "Epoch 24167 - Train Loss: 0.071295, Train Acc: 0.894872 | Val Loss: 0.105256, Val Acc: 0.793814\n",
      "Epoch 24168 - Train Loss: 0.071293, Train Acc: 0.894872 | Val Loss: 0.105256, Val Acc: 0.793814\n",
      "Epoch 24169 - Train Loss: 0.071292, Train Acc: 0.894872 | Val Loss: 0.105255, Val Acc: 0.793814\n",
      "Epoch 24170 - Train Loss: 0.071290, Train Acc: 0.894872 | Val Loss: 0.105255, Val Acc: 0.793814\n",
      "Epoch 24171 - Train Loss: 0.071289, Train Acc: 0.894872 | Val Loss: 0.105255, Val Acc: 0.793814\n",
      "Epoch 24172 - Train Loss: 0.071287, Train Acc: 0.894872 | Val Loss: 0.105254, Val Acc: 0.793814\n",
      "Epoch 24173 - Train Loss: 0.071286, Train Acc: 0.894872 | Val Loss: 0.105254, Val Acc: 0.793814\n",
      "Epoch 24174 - Train Loss: 0.071284, Train Acc: 0.894872 | Val Loss: 0.105254, Val Acc: 0.793814\n",
      "Epoch 24175 - Train Loss: 0.071283, Train Acc: 0.894872 | Val Loss: 0.105253, Val Acc: 0.793814\n",
      "Epoch 24176 - Train Loss: 0.071281, Train Acc: 0.894872 | Val Loss: 0.105253, Val Acc: 0.793814\n",
      "Epoch 24177 - Train Loss: 0.071280, Train Acc: 0.894872 | Val Loss: 0.105253, Val Acc: 0.793814\n",
      "Epoch 24178 - Train Loss: 0.071278, Train Acc: 0.894872 | Val Loss: 0.105253, Val Acc: 0.793814\n",
      "Epoch 24179 - Train Loss: 0.071277, Train Acc: 0.894872 | Val Loss: 0.105252, Val Acc: 0.793814\n",
      "Epoch 24180 - Train Loss: 0.071276, Train Acc: 0.894872 | Val Loss: 0.105252, Val Acc: 0.793814\n",
      "Epoch 24181 - Train Loss: 0.071274, Train Acc: 0.894872 | Val Loss: 0.105252, Val Acc: 0.793814\n",
      "Epoch 24182 - Train Loss: 0.071273, Train Acc: 0.894872 | Val Loss: 0.105251, Val Acc: 0.793814\n",
      "Epoch 24183 - Train Loss: 0.071271, Train Acc: 0.894872 | Val Loss: 0.105251, Val Acc: 0.793814\n",
      "Epoch 24184 - Train Loss: 0.071270, Train Acc: 0.894872 | Val Loss: 0.105251, Val Acc: 0.793814\n",
      "Epoch 24185 - Train Loss: 0.071268, Train Acc: 0.894872 | Val Loss: 0.105251, Val Acc: 0.793814\n",
      "Epoch 24186 - Train Loss: 0.071267, Train Acc: 0.894872 | Val Loss: 0.105250, Val Acc: 0.793814\n",
      "Epoch 24187 - Train Loss: 0.071265, Train Acc: 0.894872 | Val Loss: 0.105250, Val Acc: 0.793814\n",
      "Epoch 24188 - Train Loss: 0.071264, Train Acc: 0.894872 | Val Loss: 0.105250, Val Acc: 0.793814\n",
      "Epoch 24189 - Train Loss: 0.071262, Train Acc: 0.894872 | Val Loss: 0.105249, Val Acc: 0.793814\n",
      "Epoch 24190 - Train Loss: 0.071261, Train Acc: 0.894872 | Val Loss: 0.105249, Val Acc: 0.793814\n",
      "Epoch 24191 - Train Loss: 0.071259, Train Acc: 0.894872 | Val Loss: 0.105249, Val Acc: 0.793814\n",
      "Epoch 24192 - Train Loss: 0.071258, Train Acc: 0.894872 | Val Loss: 0.105249, Val Acc: 0.793814\n",
      "Epoch 24193 - Train Loss: 0.071256, Train Acc: 0.894872 | Val Loss: 0.105248, Val Acc: 0.793814\n",
      "Epoch 24194 - Train Loss: 0.071255, Train Acc: 0.894872 | Val Loss: 0.105248, Val Acc: 0.793814\n",
      "Epoch 24195 - Train Loss: 0.071253, Train Acc: 0.894872 | Val Loss: 0.105248, Val Acc: 0.793814\n",
      "Epoch 24196 - Train Loss: 0.071252, Train Acc: 0.894872 | Val Loss: 0.105247, Val Acc: 0.793814\n",
      "Epoch 24197 - Train Loss: 0.071250, Train Acc: 0.894872 | Val Loss: 0.105247, Val Acc: 0.793814\n",
      "Epoch 24198 - Train Loss: 0.071249, Train Acc: 0.894872 | Val Loss: 0.105247, Val Acc: 0.793814\n",
      "Epoch 24199 - Train Loss: 0.071247, Train Acc: 0.894872 | Val Loss: 0.105246, Val Acc: 0.793814\n",
      "Epoch 24200 - Train Loss: 0.071246, Train Acc: 0.894872 | Val Loss: 0.105246, Val Acc: 0.793814\n",
      "Epoch 24201 - Train Loss: 0.071244, Train Acc: 0.894872 | Val Loss: 0.105246, Val Acc: 0.793814\n",
      "Epoch 24202 - Train Loss: 0.071243, Train Acc: 0.894872 | Val Loss: 0.105246, Val Acc: 0.793814\n",
      "Epoch 24203 - Train Loss: 0.071241, Train Acc: 0.894872 | Val Loss: 0.105245, Val Acc: 0.793814\n",
      "Epoch 24204 - Train Loss: 0.071240, Train Acc: 0.894872 | Val Loss: 0.105245, Val Acc: 0.793814\n",
      "Epoch 24205 - Train Loss: 0.071239, Train Acc: 0.894872 | Val Loss: 0.105245, Val Acc: 0.793814\n",
      "Epoch 24206 - Train Loss: 0.071237, Train Acc: 0.894872 | Val Loss: 0.105244, Val Acc: 0.793814\n",
      "Epoch 24207 - Train Loss: 0.071236, Train Acc: 0.894872 | Val Loss: 0.105244, Val Acc: 0.793814\n",
      "Epoch 24208 - Train Loss: 0.071234, Train Acc: 0.894872 | Val Loss: 0.105244, Val Acc: 0.793814\n",
      "Epoch 24209 - Train Loss: 0.071233, Train Acc: 0.894872 | Val Loss: 0.105243, Val Acc: 0.793814\n",
      "Epoch 24210 - Train Loss: 0.071231, Train Acc: 0.894872 | Val Loss: 0.105243, Val Acc: 0.793814\n",
      "Epoch 24211 - Train Loss: 0.071230, Train Acc: 0.894872 | Val Loss: 0.105243, Val Acc: 0.793814\n",
      "Epoch 24212 - Train Loss: 0.071228, Train Acc: 0.894872 | Val Loss: 0.105243, Val Acc: 0.793814\n",
      "Epoch 24213 - Train Loss: 0.071227, Train Acc: 0.894872 | Val Loss: 0.105242, Val Acc: 0.793814\n",
      "Epoch 24214 - Train Loss: 0.071225, Train Acc: 0.894872 | Val Loss: 0.105242, Val Acc: 0.793814\n",
      "Epoch 24215 - Train Loss: 0.071224, Train Acc: 0.894872 | Val Loss: 0.105242, Val Acc: 0.793814\n",
      "Epoch 24216 - Train Loss: 0.071222, Train Acc: 0.894872 | Val Loss: 0.105241, Val Acc: 0.793814\n",
      "Epoch 24217 - Train Loss: 0.071221, Train Acc: 0.894872 | Val Loss: 0.105241, Val Acc: 0.793814\n",
      "Epoch 24218 - Train Loss: 0.071219, Train Acc: 0.894872 | Val Loss: 0.105241, Val Acc: 0.793814\n",
      "Epoch 24219 - Train Loss: 0.071218, Train Acc: 0.894872 | Val Loss: 0.105241, Val Acc: 0.793814\n",
      "Epoch 24220 - Train Loss: 0.071216, Train Acc: 0.894872 | Val Loss: 0.105240, Val Acc: 0.793814\n",
      "Epoch 24221 - Train Loss: 0.071215, Train Acc: 0.894872 | Val Loss: 0.105240, Val Acc: 0.793814\n",
      "Epoch 24222 - Train Loss: 0.071213, Train Acc: 0.894872 | Val Loss: 0.105240, Val Acc: 0.793814\n",
      "Epoch 24223 - Train Loss: 0.071212, Train Acc: 0.894872 | Val Loss: 0.105239, Val Acc: 0.793814\n",
      "Epoch 24224 - Train Loss: 0.071210, Train Acc: 0.894872 | Val Loss: 0.105239, Val Acc: 0.793814\n",
      "Epoch 24225 - Train Loss: 0.071209, Train Acc: 0.894872 | Val Loss: 0.105239, Val Acc: 0.793814\n",
      "Epoch 24226 - Train Loss: 0.071208, Train Acc: 0.894872 | Val Loss: 0.105239, Val Acc: 0.793814\n",
      "Epoch 24227 - Train Loss: 0.071206, Train Acc: 0.894872 | Val Loss: 0.105238, Val Acc: 0.793814\n",
      "Epoch 24228 - Train Loss: 0.071205, Train Acc: 0.894872 | Val Loss: 0.105238, Val Acc: 0.793814\n",
      "Epoch 24229 - Train Loss: 0.071203, Train Acc: 0.894872 | Val Loss: 0.105238, Val Acc: 0.793814\n",
      "Epoch 24230 - Train Loss: 0.071202, Train Acc: 0.894872 | Val Loss: 0.105237, Val Acc: 0.793814\n",
      "Epoch 24231 - Train Loss: 0.071200, Train Acc: 0.894872 | Val Loss: 0.105237, Val Acc: 0.793814\n",
      "Epoch 24232 - Train Loss: 0.071199, Train Acc: 0.894872 | Val Loss: 0.105237, Val Acc: 0.793814\n",
      "Epoch 24233 - Train Loss: 0.071197, Train Acc: 0.894872 | Val Loss: 0.105237, Val Acc: 0.793814\n",
      "Epoch 24234 - Train Loss: 0.071196, Train Acc: 0.894872 | Val Loss: 0.105236, Val Acc: 0.793814\n",
      "Epoch 24235 - Train Loss: 0.071194, Train Acc: 0.894872 | Val Loss: 0.105236, Val Acc: 0.793814\n",
      "Epoch 24236 - Train Loss: 0.071193, Train Acc: 0.894872 | Val Loss: 0.105236, Val Acc: 0.793814\n",
      "Epoch 24237 - Train Loss: 0.071191, Train Acc: 0.894872 | Val Loss: 0.105235, Val Acc: 0.793814\n",
      "Epoch 24238 - Train Loss: 0.071190, Train Acc: 0.894872 | Val Loss: 0.105235, Val Acc: 0.793814\n",
      "Epoch 24239 - Train Loss: 0.071188, Train Acc: 0.894872 | Val Loss: 0.105235, Val Acc: 0.793814\n",
      "Epoch 24240 - Train Loss: 0.071187, Train Acc: 0.894872 | Val Loss: 0.105235, Val Acc: 0.793814\n",
      "Epoch 24241 - Train Loss: 0.071185, Train Acc: 0.894872 | Val Loss: 0.105234, Val Acc: 0.793814\n",
      "Epoch 24242 - Train Loss: 0.071184, Train Acc: 0.894872 | Val Loss: 0.105234, Val Acc: 0.793814\n",
      "Epoch 24243 - Train Loss: 0.071182, Train Acc: 0.894872 | Val Loss: 0.105234, Val Acc: 0.793814\n",
      "Epoch 24244 - Train Loss: 0.071181, Train Acc: 0.894872 | Val Loss: 0.105233, Val Acc: 0.793814\n",
      "Epoch 24245 - Train Loss: 0.071180, Train Acc: 0.894872 | Val Loss: 0.105233, Val Acc: 0.793814\n",
      "Epoch 24246 - Train Loss: 0.071178, Train Acc: 0.894872 | Val Loss: 0.105233, Val Acc: 0.793814\n",
      "Epoch 24247 - Train Loss: 0.071177, Train Acc: 0.894872 | Val Loss: 0.105232, Val Acc: 0.793814\n",
      "Epoch 24248 - Train Loss: 0.071175, Train Acc: 0.894872 | Val Loss: 0.105232, Val Acc: 0.793814\n",
      "Epoch 24249 - Train Loss: 0.071174, Train Acc: 0.894872 | Val Loss: 0.105232, Val Acc: 0.793814\n",
      "Epoch 24250 - Train Loss: 0.071172, Train Acc: 0.894872 | Val Loss: 0.105232, Val Acc: 0.793814\n",
      "Epoch 24251 - Train Loss: 0.071171, Train Acc: 0.894872 | Val Loss: 0.105231, Val Acc: 0.793814\n",
      "Epoch 24252 - Train Loss: 0.071169, Train Acc: 0.894872 | Val Loss: 0.105231, Val Acc: 0.793814\n",
      "Epoch 24253 - Train Loss: 0.071168, Train Acc: 0.894872 | Val Loss: 0.105231, Val Acc: 0.793814\n",
      "Epoch 24254 - Train Loss: 0.071166, Train Acc: 0.894872 | Val Loss: 0.105230, Val Acc: 0.793814\n",
      "Epoch 24255 - Train Loss: 0.071165, Train Acc: 0.894872 | Val Loss: 0.105230, Val Acc: 0.793814\n",
      "Epoch 24256 - Train Loss: 0.071163, Train Acc: 0.894872 | Val Loss: 0.105230, Val Acc: 0.793814\n",
      "Epoch 24257 - Train Loss: 0.071162, Train Acc: 0.894872 | Val Loss: 0.105230, Val Acc: 0.793814\n",
      "Epoch 24258 - Train Loss: 0.071160, Train Acc: 0.894872 | Val Loss: 0.105229, Val Acc: 0.793814\n",
      "Epoch 24259 - Train Loss: 0.071159, Train Acc: 0.894872 | Val Loss: 0.105229, Val Acc: 0.793814\n",
      "Epoch 24260 - Train Loss: 0.071157, Train Acc: 0.894872 | Val Loss: 0.105229, Val Acc: 0.793814\n",
      "Epoch 24261 - Train Loss: 0.071156, Train Acc: 0.894872 | Val Loss: 0.105229, Val Acc: 0.793814\n",
      "Epoch 24262 - Train Loss: 0.071154, Train Acc: 0.894872 | Val Loss: 0.105228, Val Acc: 0.793814\n",
      "Epoch 24263 - Train Loss: 0.071153, Train Acc: 0.894872 | Val Loss: 0.105228, Val Acc: 0.793814\n",
      "Epoch 24264 - Train Loss: 0.071152, Train Acc: 0.894872 | Val Loss: 0.105228, Val Acc: 0.793814\n",
      "Epoch 24265 - Train Loss: 0.071150, Train Acc: 0.894872 | Val Loss: 0.105227, Val Acc: 0.793814\n",
      "Epoch 24266 - Train Loss: 0.071149, Train Acc: 0.894872 | Val Loss: 0.105227, Val Acc: 0.793814\n",
      "Epoch 24267 - Train Loss: 0.071147, Train Acc: 0.894872 | Val Loss: 0.105227, Val Acc: 0.793814\n",
      "Epoch 24268 - Train Loss: 0.071146, Train Acc: 0.894872 | Val Loss: 0.105226, Val Acc: 0.793814\n",
      "Epoch 24269 - Train Loss: 0.071144, Train Acc: 0.894872 | Val Loss: 0.105226, Val Acc: 0.793814\n",
      "Epoch 24270 - Train Loss: 0.071143, Train Acc: 0.894872 | Val Loss: 0.105226, Val Acc: 0.793814\n",
      "Epoch 24271 - Train Loss: 0.071141, Train Acc: 0.894872 | Val Loss: 0.105226, Val Acc: 0.793814\n",
      "Epoch 24272 - Train Loss: 0.071140, Train Acc: 0.894872 | Val Loss: 0.105225, Val Acc: 0.793814\n",
      "Epoch 24273 - Train Loss: 0.071138, Train Acc: 0.894872 | Val Loss: 0.105225, Val Acc: 0.793814\n",
      "Epoch 24274 - Train Loss: 0.071137, Train Acc: 0.894872 | Val Loss: 0.105225, Val Acc: 0.793814\n",
      "Epoch 24275 - Train Loss: 0.071135, Train Acc: 0.894872 | Val Loss: 0.105224, Val Acc: 0.793814\n",
      "Epoch 24276 - Train Loss: 0.071134, Train Acc: 0.894872 | Val Loss: 0.105224, Val Acc: 0.793814\n",
      "Epoch 24277 - Train Loss: 0.071132, Train Acc: 0.894872 | Val Loss: 0.105224, Val Acc: 0.793814\n",
      "Epoch 24278 - Train Loss: 0.071131, Train Acc: 0.894872 | Val Loss: 0.105224, Val Acc: 0.793814\n",
      "Epoch 24279 - Train Loss: 0.071129, Train Acc: 0.894872 | Val Loss: 0.105223, Val Acc: 0.793814\n",
      "Epoch 24280 - Train Loss: 0.071128, Train Acc: 0.894872 | Val Loss: 0.105223, Val Acc: 0.793814\n",
      "Epoch 24281 - Train Loss: 0.071127, Train Acc: 0.894872 | Val Loss: 0.105223, Val Acc: 0.793814\n",
      "Epoch 24282 - Train Loss: 0.071125, Train Acc: 0.894872 | Val Loss: 0.105222, Val Acc: 0.793814\n",
      "Epoch 24283 - Train Loss: 0.071124, Train Acc: 0.894872 | Val Loss: 0.105222, Val Acc: 0.793814\n",
      "Epoch 24284 - Train Loss: 0.071122, Train Acc: 0.894872 | Val Loss: 0.105222, Val Acc: 0.793814\n",
      "Epoch 24285 - Train Loss: 0.071121, Train Acc: 0.894872 | Val Loss: 0.105222, Val Acc: 0.793814\n",
      "Epoch 24286 - Train Loss: 0.071119, Train Acc: 0.894872 | Val Loss: 0.105221, Val Acc: 0.793814\n",
      "Epoch 24287 - Train Loss: 0.071118, Train Acc: 0.894872 | Val Loss: 0.105221, Val Acc: 0.793814\n",
      "Epoch 24288 - Train Loss: 0.071116, Train Acc: 0.894872 | Val Loss: 0.105221, Val Acc: 0.793814\n",
      "Epoch 24289 - Train Loss: 0.071115, Train Acc: 0.894872 | Val Loss: 0.105220, Val Acc: 0.793814\n",
      "Epoch 24290 - Train Loss: 0.071113, Train Acc: 0.894872 | Val Loss: 0.105220, Val Acc: 0.793814\n",
      "Epoch 24291 - Train Loss: 0.071112, Train Acc: 0.894872 | Val Loss: 0.105220, Val Acc: 0.793814\n",
      "Epoch 24292 - Train Loss: 0.071110, Train Acc: 0.894872 | Val Loss: 0.105220, Val Acc: 0.793814\n",
      "Epoch 24293 - Train Loss: 0.071109, Train Acc: 0.894872 | Val Loss: 0.105219, Val Acc: 0.793814\n",
      "Epoch 24294 - Train Loss: 0.071107, Train Acc: 0.894872 | Val Loss: 0.105219, Val Acc: 0.793814\n",
      "Epoch 24295 - Train Loss: 0.071106, Train Acc: 0.894872 | Val Loss: 0.105219, Val Acc: 0.793814\n",
      "Epoch 24296 - Train Loss: 0.071104, Train Acc: 0.894872 | Val Loss: 0.105219, Val Acc: 0.793814\n",
      "Epoch 24297 - Train Loss: 0.071103, Train Acc: 0.894872 | Val Loss: 0.105218, Val Acc: 0.793814\n",
      "Epoch 24298 - Train Loss: 0.071102, Train Acc: 0.894872 | Val Loss: 0.105218, Val Acc: 0.793814\n",
      "Epoch 24299 - Train Loss: 0.071100, Train Acc: 0.894872 | Val Loss: 0.105218, Val Acc: 0.793814\n",
      "Epoch 24300 - Train Loss: 0.071099, Train Acc: 0.894872 | Val Loss: 0.105217, Val Acc: 0.793814\n",
      "Epoch 24301 - Train Loss: 0.071097, Train Acc: 0.894872 | Val Loss: 0.105217, Val Acc: 0.793814\n",
      "Epoch 24302 - Train Loss: 0.071096, Train Acc: 0.894872 | Val Loss: 0.105217, Val Acc: 0.793814\n",
      "Epoch 24303 - Train Loss: 0.071094, Train Acc: 0.894872 | Val Loss: 0.105217, Val Acc: 0.793814\n",
      "Epoch 24304 - Train Loss: 0.071093, Train Acc: 0.894872 | Val Loss: 0.105216, Val Acc: 0.793814\n",
      "Epoch 24305 - Train Loss: 0.071091, Train Acc: 0.894872 | Val Loss: 0.105216, Val Acc: 0.793814\n",
      "Epoch 24306 - Train Loss: 0.071090, Train Acc: 0.894872 | Val Loss: 0.105216, Val Acc: 0.793814\n",
      "Epoch 24307 - Train Loss: 0.071088, Train Acc: 0.894872 | Val Loss: 0.105215, Val Acc: 0.793814\n",
      "Epoch 24308 - Train Loss: 0.071087, Train Acc: 0.894872 | Val Loss: 0.105215, Val Acc: 0.793814\n",
      "Epoch 24309 - Train Loss: 0.071085, Train Acc: 0.894872 | Val Loss: 0.105215, Val Acc: 0.793814\n",
      "Epoch 24310 - Train Loss: 0.071084, Train Acc: 0.894872 | Val Loss: 0.105215, Val Acc: 0.793814\n",
      "Epoch 24311 - Train Loss: 0.071082, Train Acc: 0.894872 | Val Loss: 0.105214, Val Acc: 0.793814\n",
      "Epoch 24312 - Train Loss: 0.071081, Train Acc: 0.894872 | Val Loss: 0.105214, Val Acc: 0.793814\n",
      "Epoch 24313 - Train Loss: 0.071079, Train Acc: 0.894872 | Val Loss: 0.105214, Val Acc: 0.793814\n",
      "Epoch 24314 - Train Loss: 0.071078, Train Acc: 0.894872 | Val Loss: 0.105213, Val Acc: 0.793814\n",
      "Epoch 24315 - Train Loss: 0.071077, Train Acc: 0.894872 | Val Loss: 0.105213, Val Acc: 0.793814\n",
      "Epoch 24316 - Train Loss: 0.071075, Train Acc: 0.894872 | Val Loss: 0.105213, Val Acc: 0.793814\n",
      "Epoch 24317 - Train Loss: 0.071074, Train Acc: 0.894872 | Val Loss: 0.105213, Val Acc: 0.793814\n",
      "Epoch 24318 - Train Loss: 0.071072, Train Acc: 0.894872 | Val Loss: 0.105212, Val Acc: 0.793814\n",
      "Epoch 24319 - Train Loss: 0.071071, Train Acc: 0.894872 | Val Loss: 0.105212, Val Acc: 0.793814\n",
      "Epoch 24320 - Train Loss: 0.071069, Train Acc: 0.894872 | Val Loss: 0.105212, Val Acc: 0.793814\n",
      "Epoch 24321 - Train Loss: 0.071068, Train Acc: 0.894872 | Val Loss: 0.105211, Val Acc: 0.793814\n",
      "Epoch 24322 - Train Loss: 0.071066, Train Acc: 0.894872 | Val Loss: 0.105211, Val Acc: 0.793814\n",
      "Epoch 24323 - Train Loss: 0.071065, Train Acc: 0.894872 | Val Loss: 0.105211, Val Acc: 0.793814\n",
      "Epoch 24324 - Train Loss: 0.071063, Train Acc: 0.894872 | Val Loss: 0.105211, Val Acc: 0.793814\n",
      "Epoch 24325 - Train Loss: 0.071062, Train Acc: 0.894872 | Val Loss: 0.105210, Val Acc: 0.793814\n",
      "Epoch 24326 - Train Loss: 0.071060, Train Acc: 0.894872 | Val Loss: 0.105210, Val Acc: 0.793814\n",
      "Epoch 24327 - Train Loss: 0.071059, Train Acc: 0.894872 | Val Loss: 0.105210, Val Acc: 0.793814\n",
      "Epoch 24328 - Train Loss: 0.071057, Train Acc: 0.894872 | Val Loss: 0.105209, Val Acc: 0.793814\n",
      "Epoch 24329 - Train Loss: 0.071056, Train Acc: 0.894872 | Val Loss: 0.105209, Val Acc: 0.793814\n",
      "Epoch 24330 - Train Loss: 0.071055, Train Acc: 0.894872 | Val Loss: 0.105209, Val Acc: 0.793814\n",
      "Epoch 24331 - Train Loss: 0.071053, Train Acc: 0.894872 | Val Loss: 0.105209, Val Acc: 0.793814\n",
      "Epoch 24332 - Train Loss: 0.071052, Train Acc: 0.894872 | Val Loss: 0.105208, Val Acc: 0.793814\n",
      "Epoch 24333 - Train Loss: 0.071050, Train Acc: 0.894872 | Val Loss: 0.105208, Val Acc: 0.793814\n",
      "Epoch 24334 - Train Loss: 0.071049, Train Acc: 0.894872 | Val Loss: 0.105208, Val Acc: 0.793814\n",
      "Epoch 24335 - Train Loss: 0.071047, Train Acc: 0.894872 | Val Loss: 0.105207, Val Acc: 0.793814\n",
      "Epoch 24336 - Train Loss: 0.071046, Train Acc: 0.894872 | Val Loss: 0.105207, Val Acc: 0.793814\n",
      "Epoch 24337 - Train Loss: 0.071044, Train Acc: 0.894872 | Val Loss: 0.105207, Val Acc: 0.793814\n",
      "Epoch 24338 - Train Loss: 0.071043, Train Acc: 0.894872 | Val Loss: 0.105207, Val Acc: 0.793814\n",
      "Epoch 24339 - Train Loss: 0.071041, Train Acc: 0.894872 | Val Loss: 0.105206, Val Acc: 0.793814\n",
      "Epoch 24340 - Train Loss: 0.071040, Train Acc: 0.894872 | Val Loss: 0.105206, Val Acc: 0.793814\n",
      "Epoch 24341 - Train Loss: 0.071038, Train Acc: 0.894872 | Val Loss: 0.105206, Val Acc: 0.793814\n",
      "Epoch 24342 - Train Loss: 0.071037, Train Acc: 0.894872 | Val Loss: 0.105206, Val Acc: 0.793814\n",
      "Epoch 24343 - Train Loss: 0.071035, Train Acc: 0.894872 | Val Loss: 0.105205, Val Acc: 0.793814\n",
      "Epoch 24344 - Train Loss: 0.071034, Train Acc: 0.894872 | Val Loss: 0.105205, Val Acc: 0.793814\n",
      "Epoch 24345 - Train Loss: 0.071033, Train Acc: 0.894872 | Val Loss: 0.105205, Val Acc: 0.793814\n",
      "Epoch 24346 - Train Loss: 0.071031, Train Acc: 0.894872 | Val Loss: 0.105204, Val Acc: 0.793814\n",
      "Epoch 24347 - Train Loss: 0.071030, Train Acc: 0.894872 | Val Loss: 0.105204, Val Acc: 0.793814\n",
      "Epoch 24348 - Train Loss: 0.071028, Train Acc: 0.894872 | Val Loss: 0.105204, Val Acc: 0.793814\n",
      "Epoch 24349 - Train Loss: 0.071027, Train Acc: 0.894872 | Val Loss: 0.105204, Val Acc: 0.793814\n",
      "Epoch 24350 - Train Loss: 0.071025, Train Acc: 0.894872 | Val Loss: 0.105203, Val Acc: 0.793814\n",
      "Epoch 24351 - Train Loss: 0.071024, Train Acc: 0.894872 | Val Loss: 0.105203, Val Acc: 0.793814\n",
      "Epoch 24352 - Train Loss: 0.071022, Train Acc: 0.894872 | Val Loss: 0.105203, Val Acc: 0.793814\n",
      "Epoch 24353 - Train Loss: 0.071021, Train Acc: 0.894872 | Val Loss: 0.105203, Val Acc: 0.793814\n",
      "Epoch 24354 - Train Loss: 0.071019, Train Acc: 0.894872 | Val Loss: 0.105202, Val Acc: 0.793814\n",
      "Epoch 24355 - Train Loss: 0.071018, Train Acc: 0.894872 | Val Loss: 0.105202, Val Acc: 0.793814\n",
      "Epoch 24356 - Train Loss: 0.071016, Train Acc: 0.894872 | Val Loss: 0.105202, Val Acc: 0.793814\n",
      "Epoch 24357 - Train Loss: 0.071015, Train Acc: 0.894872 | Val Loss: 0.105202, Val Acc: 0.793814\n",
      "Epoch 24358 - Train Loss: 0.071014, Train Acc: 0.894872 | Val Loss: 0.105201, Val Acc: 0.793814\n",
      "Epoch 24359 - Train Loss: 0.071012, Train Acc: 0.894872 | Val Loss: 0.105201, Val Acc: 0.793814\n",
      "Epoch 24360 - Train Loss: 0.071011, Train Acc: 0.894872 | Val Loss: 0.105201, Val Acc: 0.793814\n",
      "Epoch 24361 - Train Loss: 0.071009, Train Acc: 0.894872 | Val Loss: 0.105200, Val Acc: 0.793814\n",
      "Epoch 24362 - Train Loss: 0.071008, Train Acc: 0.894872 | Val Loss: 0.105200, Val Acc: 0.793814\n",
      "Epoch 24363 - Train Loss: 0.071006, Train Acc: 0.894872 | Val Loss: 0.105200, Val Acc: 0.793814\n",
      "Epoch 24364 - Train Loss: 0.071005, Train Acc: 0.894872 | Val Loss: 0.105200, Val Acc: 0.793814\n",
      "Epoch 24365 - Train Loss: 0.071003, Train Acc: 0.894872 | Val Loss: 0.105199, Val Acc: 0.793814\n",
      "Epoch 24366 - Train Loss: 0.071002, Train Acc: 0.894872 | Val Loss: 0.105199, Val Acc: 0.793814\n",
      "Epoch 24367 - Train Loss: 0.071000, Train Acc: 0.894872 | Val Loss: 0.105199, Val Acc: 0.793814\n",
      "Epoch 24368 - Train Loss: 0.070999, Train Acc: 0.894872 | Val Loss: 0.105198, Val Acc: 0.793814\n",
      "Epoch 24369 - Train Loss: 0.070997, Train Acc: 0.894872 | Val Loss: 0.105198, Val Acc: 0.793814\n",
      "Epoch 24370 - Train Loss: 0.070996, Train Acc: 0.894872 | Val Loss: 0.105198, Val Acc: 0.793814\n",
      "Epoch 24371 - Train Loss: 0.070994, Train Acc: 0.894872 | Val Loss: 0.105198, Val Acc: 0.793814\n",
      "Epoch 24372 - Train Loss: 0.070993, Train Acc: 0.894872 | Val Loss: 0.105197, Val Acc: 0.793814\n",
      "Epoch 24373 - Train Loss: 0.070992, Train Acc: 0.894872 | Val Loss: 0.105197, Val Acc: 0.793814\n",
      "Epoch 24374 - Train Loss: 0.070990, Train Acc: 0.894872 | Val Loss: 0.105197, Val Acc: 0.793814\n",
      "Epoch 24375 - Train Loss: 0.070989, Train Acc: 0.894872 | Val Loss: 0.105197, Val Acc: 0.793814\n",
      "Epoch 24376 - Train Loss: 0.070987, Train Acc: 0.894872 | Val Loss: 0.105196, Val Acc: 0.793814\n",
      "Epoch 24377 - Train Loss: 0.070986, Train Acc: 0.894872 | Val Loss: 0.105196, Val Acc: 0.793814\n",
      "Epoch 24378 - Train Loss: 0.070984, Train Acc: 0.894872 | Val Loss: 0.105196, Val Acc: 0.793814\n",
      "Epoch 24379 - Train Loss: 0.070983, Train Acc: 0.894872 | Val Loss: 0.105195, Val Acc: 0.793814\n",
      "Epoch 24380 - Train Loss: 0.070981, Train Acc: 0.894872 | Val Loss: 0.105195, Val Acc: 0.793814\n",
      "Epoch 24381 - Train Loss: 0.070980, Train Acc: 0.894872 | Val Loss: 0.105195, Val Acc: 0.793814\n",
      "Epoch 24382 - Train Loss: 0.070978, Train Acc: 0.894872 | Val Loss: 0.105195, Val Acc: 0.793814\n",
      "Epoch 24383 - Train Loss: 0.070977, Train Acc: 0.894872 | Val Loss: 0.105194, Val Acc: 0.793814\n",
      "Epoch 24384 - Train Loss: 0.070975, Train Acc: 0.894872 | Val Loss: 0.105194, Val Acc: 0.793814\n",
      "Epoch 24385 - Train Loss: 0.070974, Train Acc: 0.894872 | Val Loss: 0.105194, Val Acc: 0.793814\n",
      "Epoch 24386 - Train Loss: 0.070973, Train Acc: 0.894872 | Val Loss: 0.105194, Val Acc: 0.793814\n",
      "Epoch 24387 - Train Loss: 0.070971, Train Acc: 0.894872 | Val Loss: 0.105193, Val Acc: 0.793814\n",
      "Epoch 24388 - Train Loss: 0.070970, Train Acc: 0.894872 | Val Loss: 0.105193, Val Acc: 0.793814\n",
      "Epoch 24389 - Train Loss: 0.070968, Train Acc: 0.894872 | Val Loss: 0.105193, Val Acc: 0.793814\n",
      "Epoch 24390 - Train Loss: 0.070967, Train Acc: 0.894872 | Val Loss: 0.105192, Val Acc: 0.793814\n",
      "Epoch 24391 - Train Loss: 0.070965, Train Acc: 0.894872 | Val Loss: 0.105192, Val Acc: 0.793814\n",
      "Epoch 24392 - Train Loss: 0.070964, Train Acc: 0.894872 | Val Loss: 0.105192, Val Acc: 0.793814\n",
      "Epoch 24393 - Train Loss: 0.070962, Train Acc: 0.894872 | Val Loss: 0.105192, Val Acc: 0.793814\n",
      "Epoch 24394 - Train Loss: 0.070961, Train Acc: 0.894872 | Val Loss: 0.105191, Val Acc: 0.793814\n",
      "Epoch 24395 - Train Loss: 0.070959, Train Acc: 0.894872 | Val Loss: 0.105191, Val Acc: 0.793814\n",
      "Epoch 24396 - Train Loss: 0.070958, Train Acc: 0.894872 | Val Loss: 0.105191, Val Acc: 0.793814\n",
      "Epoch 24397 - Train Loss: 0.070957, Train Acc: 0.894872 | Val Loss: 0.105191, Val Acc: 0.793814\n",
      "Epoch 24398 - Train Loss: 0.070955, Train Acc: 0.894872 | Val Loss: 0.105190, Val Acc: 0.793814\n",
      "Epoch 24399 - Train Loss: 0.070954, Train Acc: 0.894872 | Val Loss: 0.105190, Val Acc: 0.793814\n",
      "Epoch 24400 - Train Loss: 0.070952, Train Acc: 0.894872 | Val Loss: 0.105190, Val Acc: 0.793814\n",
      "Epoch 24401 - Train Loss: 0.070951, Train Acc: 0.894872 | Val Loss: 0.105189, Val Acc: 0.793814\n",
      "Epoch 24402 - Train Loss: 0.070949, Train Acc: 0.894872 | Val Loss: 0.105189, Val Acc: 0.793814\n",
      "Epoch 24403 - Train Loss: 0.070948, Train Acc: 0.894872 | Val Loss: 0.105189, Val Acc: 0.793814\n",
      "Epoch 24404 - Train Loss: 0.070946, Train Acc: 0.894872 | Val Loss: 0.105189, Val Acc: 0.793814\n",
      "Epoch 24405 - Train Loss: 0.070945, Train Acc: 0.894872 | Val Loss: 0.105188, Val Acc: 0.793814\n",
      "Epoch 24406 - Train Loss: 0.070943, Train Acc: 0.894872 | Val Loss: 0.105188, Val Acc: 0.793814\n",
      "Epoch 24407 - Train Loss: 0.070942, Train Acc: 0.894872 | Val Loss: 0.105188, Val Acc: 0.793814\n",
      "Epoch 24408 - Train Loss: 0.070940, Train Acc: 0.894872 | Val Loss: 0.105188, Val Acc: 0.793814\n",
      "Epoch 24409 - Train Loss: 0.070939, Train Acc: 0.894872 | Val Loss: 0.105187, Val Acc: 0.793814\n",
      "Epoch 24410 - Train Loss: 0.070938, Train Acc: 0.894872 | Val Loss: 0.105187, Val Acc: 0.793814\n",
      "Epoch 24411 - Train Loss: 0.070936, Train Acc: 0.894872 | Val Loss: 0.105187, Val Acc: 0.793814\n",
      "Epoch 24412 - Train Loss: 0.070935, Train Acc: 0.894872 | Val Loss: 0.105187, Val Acc: 0.793814\n",
      "Epoch 24413 - Train Loss: 0.070933, Train Acc: 0.894872 | Val Loss: 0.105186, Val Acc: 0.793814\n",
      "Epoch 24414 - Train Loss: 0.070932, Train Acc: 0.894872 | Val Loss: 0.105186, Val Acc: 0.793814\n",
      "Epoch 24415 - Train Loss: 0.070930, Train Acc: 0.894872 | Val Loss: 0.105186, Val Acc: 0.793814\n",
      "Epoch 24416 - Train Loss: 0.070929, Train Acc: 0.894872 | Val Loss: 0.105185, Val Acc: 0.793814\n",
      "Epoch 24417 - Train Loss: 0.070927, Train Acc: 0.894872 | Val Loss: 0.105185, Val Acc: 0.793814\n",
      "Epoch 24418 - Train Loss: 0.070926, Train Acc: 0.894872 | Val Loss: 0.105185, Val Acc: 0.793814\n",
      "Epoch 24419 - Train Loss: 0.070924, Train Acc: 0.894872 | Val Loss: 0.105185, Val Acc: 0.793814\n",
      "Epoch 24420 - Train Loss: 0.070923, Train Acc: 0.894872 | Val Loss: 0.105184, Val Acc: 0.793814\n",
      "Epoch 24421 - Train Loss: 0.070922, Train Acc: 0.894872 | Val Loss: 0.105184, Val Acc: 0.793814\n",
      "Epoch 24422 - Train Loss: 0.070920, Train Acc: 0.894872 | Val Loss: 0.105184, Val Acc: 0.793814\n",
      "Epoch 24423 - Train Loss: 0.070919, Train Acc: 0.894872 | Val Loss: 0.105183, Val Acc: 0.793814\n",
      "Epoch 24424 - Train Loss: 0.070917, Train Acc: 0.894872 | Val Loss: 0.105183, Val Acc: 0.793814\n",
      "Epoch 24425 - Train Loss: 0.070916, Train Acc: 0.894872 | Val Loss: 0.105183, Val Acc: 0.793814\n",
      "Epoch 24426 - Train Loss: 0.070914, Train Acc: 0.894872 | Val Loss: 0.105183, Val Acc: 0.793814\n",
      "Epoch 24427 - Train Loss: 0.070913, Train Acc: 0.894872 | Val Loss: 0.105182, Val Acc: 0.793814\n",
      "Epoch 24428 - Train Loss: 0.070911, Train Acc: 0.894872 | Val Loss: 0.105182, Val Acc: 0.793814\n",
      "Epoch 24429 - Train Loss: 0.070910, Train Acc: 0.894872 | Val Loss: 0.105182, Val Acc: 0.793814\n",
      "Epoch 24430 - Train Loss: 0.070908, Train Acc: 0.894872 | Val Loss: 0.105182, Val Acc: 0.793814\n",
      "Epoch 24431 - Train Loss: 0.070907, Train Acc: 0.894872 | Val Loss: 0.105181, Val Acc: 0.793814\n",
      "Epoch 24432 - Train Loss: 0.070906, Train Acc: 0.894872 | Val Loss: 0.105181, Val Acc: 0.793814\n",
      "Epoch 24433 - Train Loss: 0.070904, Train Acc: 0.894872 | Val Loss: 0.105181, Val Acc: 0.793814\n",
      "Epoch 24434 - Train Loss: 0.070903, Train Acc: 0.894872 | Val Loss: 0.105181, Val Acc: 0.793814\n",
      "Epoch 24435 - Train Loss: 0.070901, Train Acc: 0.894872 | Val Loss: 0.105180, Val Acc: 0.793814\n",
      "Epoch 24436 - Train Loss: 0.070900, Train Acc: 0.894872 | Val Loss: 0.105180, Val Acc: 0.793814\n",
      "Epoch 24437 - Train Loss: 0.070898, Train Acc: 0.894872 | Val Loss: 0.105180, Val Acc: 0.793814\n",
      "Epoch 24438 - Train Loss: 0.070897, Train Acc: 0.894872 | Val Loss: 0.105180, Val Acc: 0.793814\n",
      "Epoch 24439 - Train Loss: 0.070895, Train Acc: 0.894872 | Val Loss: 0.105179, Val Acc: 0.793814\n",
      "Epoch 24440 - Train Loss: 0.070894, Train Acc: 0.894872 | Val Loss: 0.105179, Val Acc: 0.793814\n",
      "Epoch 24441 - Train Loss: 0.070892, Train Acc: 0.894872 | Val Loss: 0.105179, Val Acc: 0.793814\n",
      "Epoch 24442 - Train Loss: 0.070891, Train Acc: 0.894872 | Val Loss: 0.105178, Val Acc: 0.793814\n",
      "Epoch 24443 - Train Loss: 0.070890, Train Acc: 0.894872 | Val Loss: 0.105178, Val Acc: 0.793814\n",
      "Epoch 24444 - Train Loss: 0.070888, Train Acc: 0.894872 | Val Loss: 0.105178, Val Acc: 0.793814\n",
      "Epoch 24445 - Train Loss: 0.070887, Train Acc: 0.894872 | Val Loss: 0.105178, Val Acc: 0.793814\n",
      "Epoch 24446 - Train Loss: 0.070885, Train Acc: 0.894872 | Val Loss: 0.105178, Val Acc: 0.793814\n",
      "Epoch 24447 - Train Loss: 0.070884, Train Acc: 0.894872 | Val Loss: 0.105177, Val Acc: 0.793814\n",
      "Epoch 24448 - Train Loss: 0.070882, Train Acc: 0.894872 | Val Loss: 0.105177, Val Acc: 0.793814\n",
      "Epoch 24449 - Train Loss: 0.070881, Train Acc: 0.894872 | Val Loss: 0.105177, Val Acc: 0.793814\n",
      "Epoch 24450 - Train Loss: 0.070879, Train Acc: 0.894872 | Val Loss: 0.105176, Val Acc: 0.793814\n",
      "Epoch 24451 - Train Loss: 0.070878, Train Acc: 0.894872 | Val Loss: 0.105176, Val Acc: 0.793814\n",
      "Epoch 24452 - Train Loss: 0.070876, Train Acc: 0.894872 | Val Loss: 0.105176, Val Acc: 0.793814\n",
      "Epoch 24453 - Train Loss: 0.070875, Train Acc: 0.894872 | Val Loss: 0.105176, Val Acc: 0.793814\n",
      "Epoch 24454 - Train Loss: 0.070874, Train Acc: 0.894872 | Val Loss: 0.105175, Val Acc: 0.793814\n",
      "Epoch 24455 - Train Loss: 0.070872, Train Acc: 0.894872 | Val Loss: 0.105175, Val Acc: 0.793814\n",
      "Epoch 24456 - Train Loss: 0.070871, Train Acc: 0.894872 | Val Loss: 0.105175, Val Acc: 0.793814\n",
      "Epoch 24457 - Train Loss: 0.070869, Train Acc: 0.894872 | Val Loss: 0.105174, Val Acc: 0.793814\n",
      "Epoch 24458 - Train Loss: 0.070868, Train Acc: 0.894872 | Val Loss: 0.105174, Val Acc: 0.793814\n",
      "Epoch 24459 - Train Loss: 0.070866, Train Acc: 0.894872 | Val Loss: 0.105174, Val Acc: 0.793814\n",
      "Epoch 24460 - Train Loss: 0.070865, Train Acc: 0.894872 | Val Loss: 0.105174, Val Acc: 0.793814\n",
      "Epoch 24461 - Train Loss: 0.070863, Train Acc: 0.894872 | Val Loss: 0.105173, Val Acc: 0.793814\n",
      "Epoch 24462 - Train Loss: 0.070862, Train Acc: 0.894872 | Val Loss: 0.105173, Val Acc: 0.793814\n",
      "Epoch 24463 - Train Loss: 0.070860, Train Acc: 0.894872 | Val Loss: 0.105173, Val Acc: 0.793814\n",
      "Epoch 24464 - Train Loss: 0.070859, Train Acc: 0.894872 | Val Loss: 0.105173, Val Acc: 0.793814\n",
      "Epoch 24465 - Train Loss: 0.070858, Train Acc: 0.894872 | Val Loss: 0.105173, Val Acc: 0.793814\n",
      "Epoch 24466 - Train Loss: 0.070856, Train Acc: 0.894872 | Val Loss: 0.105172, Val Acc: 0.793814\n",
      "Epoch 24467 - Train Loss: 0.070855, Train Acc: 0.894872 | Val Loss: 0.105172, Val Acc: 0.793814\n",
      "Epoch 24468 - Train Loss: 0.070853, Train Acc: 0.894872 | Val Loss: 0.105172, Val Acc: 0.793814\n",
      "Epoch 24469 - Train Loss: 0.070852, Train Acc: 0.894872 | Val Loss: 0.105171, Val Acc: 0.793814\n",
      "Epoch 24470 - Train Loss: 0.070850, Train Acc: 0.894872 | Val Loss: 0.105171, Val Acc: 0.793814\n",
      "Epoch 24471 - Train Loss: 0.070849, Train Acc: 0.894872 | Val Loss: 0.105171, Val Acc: 0.793814\n",
      "Epoch 24472 - Train Loss: 0.070847, Train Acc: 0.894872 | Val Loss: 0.105171, Val Acc: 0.793814\n",
      "Epoch 24473 - Train Loss: 0.070846, Train Acc: 0.894872 | Val Loss: 0.105170, Val Acc: 0.793814\n",
      "Epoch 24474 - Train Loss: 0.070845, Train Acc: 0.894872 | Val Loss: 0.105170, Val Acc: 0.793814\n",
      "Epoch 24475 - Train Loss: 0.070843, Train Acc: 0.894872 | Val Loss: 0.105170, Val Acc: 0.793814\n",
      "Epoch 24476 - Train Loss: 0.070842, Train Acc: 0.894872 | Val Loss: 0.105170, Val Acc: 0.793814\n",
      "Epoch 24477 - Train Loss: 0.070840, Train Acc: 0.894872 | Val Loss: 0.105169, Val Acc: 0.793814\n",
      "Epoch 24478 - Train Loss: 0.070839, Train Acc: 0.894872 | Val Loss: 0.105169, Val Acc: 0.793814\n",
      "Epoch 24479 - Train Loss: 0.070837, Train Acc: 0.894872 | Val Loss: 0.105169, Val Acc: 0.793814\n",
      "Epoch 24480 - Train Loss: 0.070836, Train Acc: 0.894872 | Val Loss: 0.105168, Val Acc: 0.793814\n",
      "Epoch 24481 - Train Loss: 0.070834, Train Acc: 0.894872 | Val Loss: 0.105168, Val Acc: 0.793814\n",
      "Epoch 24482 - Train Loss: 0.070833, Train Acc: 0.894872 | Val Loss: 0.105168, Val Acc: 0.793814\n",
      "Epoch 24483 - Train Loss: 0.070831, Train Acc: 0.894872 | Val Loss: 0.105168, Val Acc: 0.793814\n",
      "Epoch 24484 - Train Loss: 0.070830, Train Acc: 0.894872 | Val Loss: 0.105168, Val Acc: 0.793814\n",
      "Epoch 24485 - Train Loss: 0.070829, Train Acc: 0.894872 | Val Loss: 0.105167, Val Acc: 0.793814\n",
      "Epoch 24486 - Train Loss: 0.070827, Train Acc: 0.894872 | Val Loss: 0.105167, Val Acc: 0.793814\n",
      "Epoch 24487 - Train Loss: 0.070826, Train Acc: 0.894872 | Val Loss: 0.105167, Val Acc: 0.793814\n",
      "Epoch 24488 - Train Loss: 0.070824, Train Acc: 0.894872 | Val Loss: 0.105166, Val Acc: 0.793814\n",
      "Epoch 24489 - Train Loss: 0.070823, Train Acc: 0.894872 | Val Loss: 0.105166, Val Acc: 0.793814\n",
      "Epoch 24490 - Train Loss: 0.070821, Train Acc: 0.894872 | Val Loss: 0.105166, Val Acc: 0.793814\n",
      "Epoch 24491 - Train Loss: 0.070820, Train Acc: 0.894872 | Val Loss: 0.105166, Val Acc: 0.793814\n",
      "Epoch 24492 - Train Loss: 0.070818, Train Acc: 0.894872 | Val Loss: 0.105165, Val Acc: 0.793814\n",
      "Epoch 24493 - Train Loss: 0.070817, Train Acc: 0.894872 | Val Loss: 0.105165, Val Acc: 0.793814\n",
      "Epoch 24494 - Train Loss: 0.070816, Train Acc: 0.894872 | Val Loss: 0.105165, Val Acc: 0.793814\n",
      "Epoch 24495 - Train Loss: 0.070814, Train Acc: 0.894872 | Val Loss: 0.105165, Val Acc: 0.793814\n",
      "Epoch 24496 - Train Loss: 0.070813, Train Acc: 0.894872 | Val Loss: 0.105164, Val Acc: 0.793814\n",
      "Epoch 24497 - Train Loss: 0.070811, Train Acc: 0.894872 | Val Loss: 0.105164, Val Acc: 0.793814\n",
      "Epoch 24498 - Train Loss: 0.070810, Train Acc: 0.894872 | Val Loss: 0.105164, Val Acc: 0.793814\n",
      "Epoch 24499 - Train Loss: 0.070808, Train Acc: 0.894872 | Val Loss: 0.105164, Val Acc: 0.793814\n",
      "Epoch 24500 - Train Loss: 0.070807, Train Acc: 0.894872 | Val Loss: 0.105163, Val Acc: 0.793814\n",
      "Epoch 24501 - Train Loss: 0.070805, Train Acc: 0.894872 | Val Loss: 0.105163, Val Acc: 0.793814\n",
      "Epoch 24502 - Train Loss: 0.070804, Train Acc: 0.894872 | Val Loss: 0.105163, Val Acc: 0.793814\n",
      "Epoch 24503 - Train Loss: 0.070802, Train Acc: 0.894872 | Val Loss: 0.105163, Val Acc: 0.793814\n",
      "Epoch 24504 - Train Loss: 0.070801, Train Acc: 0.894872 | Val Loss: 0.105162, Val Acc: 0.793814\n",
      "Epoch 24505 - Train Loss: 0.070800, Train Acc: 0.894872 | Val Loss: 0.105162, Val Acc: 0.793814\n",
      "Epoch 24506 - Train Loss: 0.070798, Train Acc: 0.894872 | Val Loss: 0.105162, Val Acc: 0.793814\n",
      "Epoch 24507 - Train Loss: 0.070797, Train Acc: 0.894872 | Val Loss: 0.105162, Val Acc: 0.793814\n",
      "Epoch 24508 - Train Loss: 0.070795, Train Acc: 0.894872 | Val Loss: 0.105161, Val Acc: 0.793814\n",
      "Epoch 24509 - Train Loss: 0.070794, Train Acc: 0.894872 | Val Loss: 0.105161, Val Acc: 0.793814\n",
      "Epoch 24510 - Train Loss: 0.070792, Train Acc: 0.894872 | Val Loss: 0.105161, Val Acc: 0.793814\n",
      "Epoch 24511 - Train Loss: 0.070791, Train Acc: 0.894872 | Val Loss: 0.105160, Val Acc: 0.793814\n",
      "Epoch 24512 - Train Loss: 0.070789, Train Acc: 0.894872 | Val Loss: 0.105160, Val Acc: 0.793814\n",
      "Epoch 24513 - Train Loss: 0.070788, Train Acc: 0.894872 | Val Loss: 0.105160, Val Acc: 0.793814\n",
      "Epoch 24514 - Train Loss: 0.070787, Train Acc: 0.894872 | Val Loss: 0.105160, Val Acc: 0.793814\n",
      "Epoch 24515 - Train Loss: 0.070785, Train Acc: 0.894872 | Val Loss: 0.105160, Val Acc: 0.793814\n",
      "Epoch 24516 - Train Loss: 0.070784, Train Acc: 0.894872 | Val Loss: 0.105159, Val Acc: 0.793814\n",
      "Epoch 24517 - Train Loss: 0.070782, Train Acc: 0.894872 | Val Loss: 0.105159, Val Acc: 0.793814\n",
      "Epoch 24518 - Train Loss: 0.070781, Train Acc: 0.894872 | Val Loss: 0.105159, Val Acc: 0.793814\n",
      "Epoch 24519 - Train Loss: 0.070779, Train Acc: 0.894872 | Val Loss: 0.105158, Val Acc: 0.793814\n",
      "Epoch 24520 - Train Loss: 0.070778, Train Acc: 0.894872 | Val Loss: 0.105158, Val Acc: 0.793814\n",
      "Epoch 24521 - Train Loss: 0.070776, Train Acc: 0.894872 | Val Loss: 0.105158, Val Acc: 0.793814\n",
      "Epoch 24522 - Train Loss: 0.070775, Train Acc: 0.894872 | Val Loss: 0.105158, Val Acc: 0.793814\n",
      "Epoch 24523 - Train Loss: 0.070774, Train Acc: 0.894872 | Val Loss: 0.105157, Val Acc: 0.793814\n",
      "Epoch 24524 - Train Loss: 0.070772, Train Acc: 0.894872 | Val Loss: 0.105157, Val Acc: 0.793814\n",
      "Epoch 24525 - Train Loss: 0.070771, Train Acc: 0.894872 | Val Loss: 0.105157, Val Acc: 0.793814\n",
      "Epoch 24526 - Train Loss: 0.070769, Train Acc: 0.894872 | Val Loss: 0.105157, Val Acc: 0.793814\n",
      "Epoch 24527 - Train Loss: 0.070768, Train Acc: 0.894872 | Val Loss: 0.105156, Val Acc: 0.793814\n",
      "Epoch 24528 - Train Loss: 0.070766, Train Acc: 0.894872 | Val Loss: 0.105156, Val Acc: 0.793814\n",
      "Epoch 24529 - Train Loss: 0.070765, Train Acc: 0.894872 | Val Loss: 0.105156, Val Acc: 0.793814\n",
      "Epoch 24530 - Train Loss: 0.070763, Train Acc: 0.894872 | Val Loss: 0.105156, Val Acc: 0.793814\n",
      "Epoch 24531 - Train Loss: 0.070762, Train Acc: 0.894872 | Val Loss: 0.105155, Val Acc: 0.793814\n",
      "Epoch 24532 - Train Loss: 0.070761, Train Acc: 0.894872 | Val Loss: 0.105155, Val Acc: 0.793814\n",
      "Epoch 24533 - Train Loss: 0.070759, Train Acc: 0.894872 | Val Loss: 0.105155, Val Acc: 0.793814\n",
      "Epoch 24534 - Train Loss: 0.070758, Train Acc: 0.894872 | Val Loss: 0.105155, Val Acc: 0.793814\n",
      "Epoch 24535 - Train Loss: 0.070756, Train Acc: 0.894872 | Val Loss: 0.105154, Val Acc: 0.793814\n",
      "Epoch 24536 - Train Loss: 0.070755, Train Acc: 0.894872 | Val Loss: 0.105154, Val Acc: 0.793814\n",
      "Epoch 24537 - Train Loss: 0.070753, Train Acc: 0.894872 | Val Loss: 0.105154, Val Acc: 0.793814\n",
      "Epoch 24538 - Train Loss: 0.070752, Train Acc: 0.894872 | Val Loss: 0.105154, Val Acc: 0.793814\n",
      "Epoch 24539 - Train Loss: 0.070750, Train Acc: 0.894872 | Val Loss: 0.105153, Val Acc: 0.793814\n",
      "Epoch 24540 - Train Loss: 0.070749, Train Acc: 0.894872 | Val Loss: 0.105153, Val Acc: 0.793814\n",
      "Epoch 24541 - Train Loss: 0.070748, Train Acc: 0.894872 | Val Loss: 0.105153, Val Acc: 0.793814\n",
      "Epoch 24542 - Train Loss: 0.070746, Train Acc: 0.894872 | Val Loss: 0.105153, Val Acc: 0.793814\n",
      "Epoch 24543 - Train Loss: 0.070745, Train Acc: 0.894872 | Val Loss: 0.105152, Val Acc: 0.793814\n",
      "Epoch 24544 - Train Loss: 0.070743, Train Acc: 0.894872 | Val Loss: 0.105152, Val Acc: 0.793814\n",
      "Epoch 24545 - Train Loss: 0.070742, Train Acc: 0.894872 | Val Loss: 0.105152, Val Acc: 0.793814\n",
      "Epoch 24546 - Train Loss: 0.070740, Train Acc: 0.894872 | Val Loss: 0.105151, Val Acc: 0.793814\n",
      "Epoch 24547 - Train Loss: 0.070739, Train Acc: 0.894872 | Val Loss: 0.105151, Val Acc: 0.793814\n",
      "Epoch 24548 - Train Loss: 0.070737, Train Acc: 0.894872 | Val Loss: 0.105151, Val Acc: 0.793814\n",
      "Epoch 24549 - Train Loss: 0.070736, Train Acc: 0.894872 | Val Loss: 0.105151, Val Acc: 0.793814\n",
      "Epoch 24550 - Train Loss: 0.070735, Train Acc: 0.894872 | Val Loss: 0.105150, Val Acc: 0.793814\n",
      "Epoch 24551 - Train Loss: 0.070733, Train Acc: 0.894872 | Val Loss: 0.105150, Val Acc: 0.793814\n",
      "Epoch 24552 - Train Loss: 0.070732, Train Acc: 0.894872 | Val Loss: 0.105150, Val Acc: 0.793814\n",
      "Epoch 24553 - Train Loss: 0.070730, Train Acc: 0.894872 | Val Loss: 0.105150, Val Acc: 0.793814\n",
      "Epoch 24554 - Train Loss: 0.070729, Train Acc: 0.894872 | Val Loss: 0.105150, Val Acc: 0.793814\n",
      "Epoch 24555 - Train Loss: 0.070727, Train Acc: 0.894872 | Val Loss: 0.105149, Val Acc: 0.793814\n",
      "Epoch 24556 - Train Loss: 0.070726, Train Acc: 0.894872 | Val Loss: 0.105149, Val Acc: 0.793814\n",
      "Epoch 24557 - Train Loss: 0.070724, Train Acc: 0.894872 | Val Loss: 0.105149, Val Acc: 0.793814\n",
      "Epoch 24558 - Train Loss: 0.070723, Train Acc: 0.894872 | Val Loss: 0.105148, Val Acc: 0.793814\n",
      "Epoch 24559 - Train Loss: 0.070722, Train Acc: 0.894872 | Val Loss: 0.105148, Val Acc: 0.793814\n",
      "Epoch 24560 - Train Loss: 0.070720, Train Acc: 0.894872 | Val Loss: 0.105148, Val Acc: 0.793814\n",
      "Epoch 24561 - Train Loss: 0.070719, Train Acc: 0.894872 | Val Loss: 0.105148, Val Acc: 0.793814\n",
      "Epoch 24562 - Train Loss: 0.070717, Train Acc: 0.894872 | Val Loss: 0.105147, Val Acc: 0.793814\n",
      "Epoch 24563 - Train Loss: 0.070716, Train Acc: 0.894872 | Val Loss: 0.105147, Val Acc: 0.793814\n",
      "Epoch 24564 - Train Loss: 0.070714, Train Acc: 0.894872 | Val Loss: 0.105147, Val Acc: 0.793814\n",
      "Epoch 24565 - Train Loss: 0.070713, Train Acc: 0.894872 | Val Loss: 0.105147, Val Acc: 0.793814\n",
      "Epoch 24566 - Train Loss: 0.070712, Train Acc: 0.894872 | Val Loss: 0.105146, Val Acc: 0.793814\n",
      "Epoch 24567 - Train Loss: 0.070710, Train Acc: 0.894872 | Val Loss: 0.105146, Val Acc: 0.793814\n",
      "Epoch 24568 - Train Loss: 0.070709, Train Acc: 0.894872 | Val Loss: 0.105146, Val Acc: 0.793814\n",
      "Epoch 24569 - Train Loss: 0.070707, Train Acc: 0.894872 | Val Loss: 0.105146, Val Acc: 0.793814\n",
      "Epoch 24570 - Train Loss: 0.070706, Train Acc: 0.894872 | Val Loss: 0.105145, Val Acc: 0.793814\n",
      "Epoch 24571 - Train Loss: 0.070704, Train Acc: 0.894872 | Val Loss: 0.105145, Val Acc: 0.793814\n",
      "Epoch 24572 - Train Loss: 0.070703, Train Acc: 0.894872 | Val Loss: 0.105145, Val Acc: 0.793814\n",
      "Epoch 24573 - Train Loss: 0.070701, Train Acc: 0.894872 | Val Loss: 0.105145, Val Acc: 0.793814\n",
      "Epoch 24574 - Train Loss: 0.070700, Train Acc: 0.894872 | Val Loss: 0.105144, Val Acc: 0.793814\n",
      "Epoch 24575 - Train Loss: 0.070699, Train Acc: 0.894872 | Val Loss: 0.105144, Val Acc: 0.793814\n",
      "Epoch 24576 - Train Loss: 0.070697, Train Acc: 0.894872 | Val Loss: 0.105144, Val Acc: 0.793814\n",
      "Epoch 24577 - Train Loss: 0.070696, Train Acc: 0.894872 | Val Loss: 0.105144, Val Acc: 0.793814\n",
      "Epoch 24578 - Train Loss: 0.070694, Train Acc: 0.894872 | Val Loss: 0.105143, Val Acc: 0.793814\n",
      "Epoch 24579 - Train Loss: 0.070693, Train Acc: 0.894872 | Val Loss: 0.105143, Val Acc: 0.793814\n",
      "Epoch 24580 - Train Loss: 0.070691, Train Acc: 0.894872 | Val Loss: 0.105143, Val Acc: 0.793814\n",
      "Epoch 24581 - Train Loss: 0.070690, Train Acc: 0.894872 | Val Loss: 0.105143, Val Acc: 0.793814\n",
      "Epoch 24582 - Train Loss: 0.070688, Train Acc: 0.894872 | Val Loss: 0.105142, Val Acc: 0.793814\n",
      "Epoch 24583 - Train Loss: 0.070687, Train Acc: 0.894872 | Val Loss: 0.105142, Val Acc: 0.793814\n",
      "Epoch 24584 - Train Loss: 0.070686, Train Acc: 0.894872 | Val Loss: 0.105142, Val Acc: 0.793814\n",
      "Epoch 24585 - Train Loss: 0.070684, Train Acc: 0.894872 | Val Loss: 0.105142, Val Acc: 0.793814\n",
      "Epoch 24586 - Train Loss: 0.070683, Train Acc: 0.894872 | Val Loss: 0.105141, Val Acc: 0.793814\n",
      "Epoch 24587 - Train Loss: 0.070681, Train Acc: 0.894872 | Val Loss: 0.105141, Val Acc: 0.793814\n",
      "Epoch 24588 - Train Loss: 0.070680, Train Acc: 0.894872 | Val Loss: 0.105141, Val Acc: 0.793814\n",
      "Epoch 24589 - Train Loss: 0.070678, Train Acc: 0.894872 | Val Loss: 0.105141, Val Acc: 0.793814\n",
      "Epoch 24590 - Train Loss: 0.070677, Train Acc: 0.894872 | Val Loss: 0.105140, Val Acc: 0.793814\n",
      "Epoch 24591 - Train Loss: 0.070676, Train Acc: 0.894872 | Val Loss: 0.105140, Val Acc: 0.793814\n",
      "Epoch 24592 - Train Loss: 0.070674, Train Acc: 0.894872 | Val Loss: 0.105140, Val Acc: 0.793814\n",
      "Epoch 24593 - Train Loss: 0.070673, Train Acc: 0.894872 | Val Loss: 0.105140, Val Acc: 0.793814\n",
      "Epoch 24594 - Train Loss: 0.070671, Train Acc: 0.894872 | Val Loss: 0.105139, Val Acc: 0.793814\n",
      "Epoch 24595 - Train Loss: 0.070670, Train Acc: 0.894872 | Val Loss: 0.105139, Val Acc: 0.793814\n",
      "Epoch 24596 - Train Loss: 0.070668, Train Acc: 0.894872 | Val Loss: 0.105139, Val Acc: 0.793814\n",
      "Epoch 24597 - Train Loss: 0.070667, Train Acc: 0.894872 | Val Loss: 0.105139, Val Acc: 0.793814\n",
      "Epoch 24598 - Train Loss: 0.070665, Train Acc: 0.894872 | Val Loss: 0.105138, Val Acc: 0.793814\n",
      "Epoch 24599 - Train Loss: 0.070664, Train Acc: 0.894872 | Val Loss: 0.105138, Val Acc: 0.793814\n",
      "Epoch 24600 - Train Loss: 0.070663, Train Acc: 0.894872 | Val Loss: 0.105138, Val Acc: 0.793814\n",
      "Epoch 24601 - Train Loss: 0.070661, Train Acc: 0.894872 | Val Loss: 0.105138, Val Acc: 0.793814\n",
      "Epoch 24602 - Train Loss: 0.070660, Train Acc: 0.894872 | Val Loss: 0.105137, Val Acc: 0.793814\n",
      "Epoch 24603 - Train Loss: 0.070658, Train Acc: 0.894872 | Val Loss: 0.105137, Val Acc: 0.793814\n",
      "Epoch 24604 - Train Loss: 0.070657, Train Acc: 0.894872 | Val Loss: 0.105137, Val Acc: 0.793814\n",
      "Epoch 24605 - Train Loss: 0.070655, Train Acc: 0.894872 | Val Loss: 0.105137, Val Acc: 0.793814\n",
      "Epoch 24606 - Train Loss: 0.070654, Train Acc: 0.894872 | Val Loss: 0.105136, Val Acc: 0.793814\n",
      "Epoch 24607 - Train Loss: 0.070653, Train Acc: 0.894872 | Val Loss: 0.105136, Val Acc: 0.793814\n",
      "Epoch 24608 - Train Loss: 0.070651, Train Acc: 0.894872 | Val Loss: 0.105136, Val Acc: 0.793814\n",
      "Epoch 24609 - Train Loss: 0.070650, Train Acc: 0.894872 | Val Loss: 0.105136, Val Acc: 0.793814\n",
      "Epoch 24610 - Train Loss: 0.070648, Train Acc: 0.894872 | Val Loss: 0.105135, Val Acc: 0.793814\n",
      "Epoch 24611 - Train Loss: 0.070647, Train Acc: 0.894872 | Val Loss: 0.105135, Val Acc: 0.793814\n",
      "Epoch 24612 - Train Loss: 0.070645, Train Acc: 0.894872 | Val Loss: 0.105135, Val Acc: 0.793814\n",
      "Epoch 24613 - Train Loss: 0.070644, Train Acc: 0.894872 | Val Loss: 0.105135, Val Acc: 0.793814\n",
      "Epoch 24614 - Train Loss: 0.070642, Train Acc: 0.894872 | Val Loss: 0.105134, Val Acc: 0.793814\n",
      "Epoch 24615 - Train Loss: 0.070641, Train Acc: 0.894872 | Val Loss: 0.105134, Val Acc: 0.793814\n",
      "Epoch 24616 - Train Loss: 0.070640, Train Acc: 0.894872 | Val Loss: 0.105134, Val Acc: 0.793814\n",
      "Epoch 24617 - Train Loss: 0.070638, Train Acc: 0.894872 | Val Loss: 0.105134, Val Acc: 0.793814\n",
      "Epoch 24618 - Train Loss: 0.070637, Train Acc: 0.894872 | Val Loss: 0.105133, Val Acc: 0.793814\n",
      "Epoch 24619 - Train Loss: 0.070635, Train Acc: 0.894872 | Val Loss: 0.105133, Val Acc: 0.793814\n",
      "Epoch 24620 - Train Loss: 0.070634, Train Acc: 0.894872 | Val Loss: 0.105133, Val Acc: 0.793814\n",
      "Epoch 24621 - Train Loss: 0.070632, Train Acc: 0.894872 | Val Loss: 0.105133, Val Acc: 0.793814\n",
      "Epoch 24622 - Train Loss: 0.070631, Train Acc: 0.894872 | Val Loss: 0.105133, Val Acc: 0.793814\n",
      "Epoch 24623 - Train Loss: 0.070630, Train Acc: 0.894872 | Val Loss: 0.105132, Val Acc: 0.793814\n",
      "Epoch 24624 - Train Loss: 0.070628, Train Acc: 0.894872 | Val Loss: 0.105132, Val Acc: 0.793814\n",
      "Epoch 24625 - Train Loss: 0.070627, Train Acc: 0.894872 | Val Loss: 0.105132, Val Acc: 0.793814\n",
      "Epoch 24626 - Train Loss: 0.070625, Train Acc: 0.894872 | Val Loss: 0.105132, Val Acc: 0.793814\n",
      "Epoch 24627 - Train Loss: 0.070624, Train Acc: 0.894872 | Val Loss: 0.105131, Val Acc: 0.793814\n",
      "Epoch 24628 - Train Loss: 0.070622, Train Acc: 0.894872 | Val Loss: 0.105131, Val Acc: 0.793814\n",
      "Epoch 24629 - Train Loss: 0.070621, Train Acc: 0.893590 | Val Loss: 0.105131, Val Acc: 0.793814\n",
      "Epoch 24630 - Train Loss: 0.070620, Train Acc: 0.893590 | Val Loss: 0.105130, Val Acc: 0.793814\n",
      "Epoch 24631 - Train Loss: 0.070618, Train Acc: 0.893590 | Val Loss: 0.105130, Val Acc: 0.793814\n",
      "Epoch 24632 - Train Loss: 0.070617, Train Acc: 0.893590 | Val Loss: 0.105130, Val Acc: 0.793814\n",
      "Epoch 24633 - Train Loss: 0.070615, Train Acc: 0.893590 | Val Loss: 0.105130, Val Acc: 0.793814\n",
      "Epoch 24634 - Train Loss: 0.070614, Train Acc: 0.893590 | Val Loss: 0.105130, Val Acc: 0.793814\n",
      "Epoch 24635 - Train Loss: 0.070612, Train Acc: 0.893590 | Val Loss: 0.105129, Val Acc: 0.793814\n",
      "Epoch 24636 - Train Loss: 0.070611, Train Acc: 0.893590 | Val Loss: 0.105129, Val Acc: 0.793814\n",
      "Epoch 24637 - Train Loss: 0.070609, Train Acc: 0.893590 | Val Loss: 0.105129, Val Acc: 0.793814\n",
      "Epoch 24638 - Train Loss: 0.070608, Train Acc: 0.893590 | Val Loss: 0.105129, Val Acc: 0.793814\n",
      "Epoch 24639 - Train Loss: 0.070607, Train Acc: 0.893590 | Val Loss: 0.105128, Val Acc: 0.793814\n",
      "Epoch 24640 - Train Loss: 0.070605, Train Acc: 0.893590 | Val Loss: 0.105128, Val Acc: 0.793814\n",
      "Epoch 24641 - Train Loss: 0.070604, Train Acc: 0.892308 | Val Loss: 0.105128, Val Acc: 0.793814\n",
      "Epoch 24642 - Train Loss: 0.070602, Train Acc: 0.892308 | Val Loss: 0.105128, Val Acc: 0.793814\n",
      "Epoch 24643 - Train Loss: 0.070601, Train Acc: 0.892308 | Val Loss: 0.105127, Val Acc: 0.793814\n",
      "Epoch 24644 - Train Loss: 0.070599, Train Acc: 0.892308 | Val Loss: 0.105127, Val Acc: 0.793814\n",
      "Epoch 24645 - Train Loss: 0.070598, Train Acc: 0.892308 | Val Loss: 0.105127, Val Acc: 0.793814\n",
      "Epoch 24646 - Train Loss: 0.070597, Train Acc: 0.892308 | Val Loss: 0.105127, Val Acc: 0.793814\n",
      "Epoch 24647 - Train Loss: 0.070595, Train Acc: 0.892308 | Val Loss: 0.105126, Val Acc: 0.793814\n",
      "Epoch 24648 - Train Loss: 0.070594, Train Acc: 0.892308 | Val Loss: 0.105126, Val Acc: 0.793814\n",
      "Epoch 24649 - Train Loss: 0.070592, Train Acc: 0.892308 | Val Loss: 0.105126, Val Acc: 0.793814\n",
      "Epoch 24650 - Train Loss: 0.070591, Train Acc: 0.892308 | Val Loss: 0.105126, Val Acc: 0.793814\n",
      "Epoch 24651 - Train Loss: 0.070589, Train Acc: 0.892308 | Val Loss: 0.105125, Val Acc: 0.793814\n",
      "Epoch 24652 - Train Loss: 0.070588, Train Acc: 0.892308 | Val Loss: 0.105125, Val Acc: 0.793814\n",
      "Epoch 24653 - Train Loss: 0.070587, Train Acc: 0.892308 | Val Loss: 0.105125, Val Acc: 0.793814\n",
      "Epoch 24654 - Train Loss: 0.070585, Train Acc: 0.892308 | Val Loss: 0.105125, Val Acc: 0.793814\n",
      "Epoch 24655 - Train Loss: 0.070584, Train Acc: 0.892308 | Val Loss: 0.105124, Val Acc: 0.793814\n",
      "Epoch 24656 - Train Loss: 0.070582, Train Acc: 0.892308 | Val Loss: 0.105124, Val Acc: 0.793814\n",
      "Epoch 24657 - Train Loss: 0.070581, Train Acc: 0.892308 | Val Loss: 0.105124, Val Acc: 0.793814\n",
      "Epoch 24658 - Train Loss: 0.070579, Train Acc: 0.892308 | Val Loss: 0.105124, Val Acc: 0.793814\n",
      "Epoch 24659 - Train Loss: 0.070578, Train Acc: 0.892308 | Val Loss: 0.105123, Val Acc: 0.793814\n",
      "Epoch 24660 - Train Loss: 0.070577, Train Acc: 0.892308 | Val Loss: 0.105123, Val Acc: 0.793814\n",
      "Epoch 24661 - Train Loss: 0.070575, Train Acc: 0.892308 | Val Loss: 0.105123, Val Acc: 0.793814\n",
      "Epoch 24662 - Train Loss: 0.070574, Train Acc: 0.892308 | Val Loss: 0.105123, Val Acc: 0.793814\n",
      "Epoch 24663 - Train Loss: 0.070572, Train Acc: 0.892308 | Val Loss: 0.105122, Val Acc: 0.793814\n",
      "Epoch 24664 - Train Loss: 0.070571, Train Acc: 0.892308 | Val Loss: 0.105122, Val Acc: 0.793814\n",
      "Epoch 24665 - Train Loss: 0.070569, Train Acc: 0.892308 | Val Loss: 0.105122, Val Acc: 0.793814\n",
      "Epoch 24666 - Train Loss: 0.070568, Train Acc: 0.892308 | Val Loss: 0.105122, Val Acc: 0.793814\n",
      "Epoch 24667 - Train Loss: 0.070567, Train Acc: 0.892308 | Val Loss: 0.105122, Val Acc: 0.793814\n",
      "Epoch 24668 - Train Loss: 0.070565, Train Acc: 0.892308 | Val Loss: 0.105121, Val Acc: 0.793814\n",
      "Epoch 24669 - Train Loss: 0.070564, Train Acc: 0.892308 | Val Loss: 0.105121, Val Acc: 0.793814\n",
      "Epoch 24670 - Train Loss: 0.070562, Train Acc: 0.892308 | Val Loss: 0.105121, Val Acc: 0.793814\n",
      "Epoch 24671 - Train Loss: 0.070561, Train Acc: 0.892308 | Val Loss: 0.105120, Val Acc: 0.793814\n",
      "Epoch 24672 - Train Loss: 0.070559, Train Acc: 0.892308 | Val Loss: 0.105120, Val Acc: 0.793814\n",
      "Epoch 24673 - Train Loss: 0.070558, Train Acc: 0.892308 | Val Loss: 0.105120, Val Acc: 0.793814\n",
      "Epoch 24674 - Train Loss: 0.070557, Train Acc: 0.892308 | Val Loss: 0.105120, Val Acc: 0.793814\n",
      "Epoch 24675 - Train Loss: 0.070555, Train Acc: 0.892308 | Val Loss: 0.105120, Val Acc: 0.793814\n",
      "Epoch 24676 - Train Loss: 0.070554, Train Acc: 0.892308 | Val Loss: 0.105119, Val Acc: 0.793814\n",
      "Epoch 24677 - Train Loss: 0.070552, Train Acc: 0.892308 | Val Loss: 0.105119, Val Acc: 0.793814\n",
      "Epoch 24678 - Train Loss: 0.070551, Train Acc: 0.892308 | Val Loss: 0.105119, Val Acc: 0.793814\n",
      "Epoch 24679 - Train Loss: 0.070549, Train Acc: 0.892308 | Val Loss: 0.105119, Val Acc: 0.793814\n",
      "Epoch 24680 - Train Loss: 0.070548, Train Acc: 0.892308 | Val Loss: 0.105118, Val Acc: 0.793814\n",
      "Epoch 24681 - Train Loss: 0.070547, Train Acc: 0.892308 | Val Loss: 0.105118, Val Acc: 0.793814\n",
      "Epoch 24682 - Train Loss: 0.070545, Train Acc: 0.892308 | Val Loss: 0.105118, Val Acc: 0.793814\n",
      "Epoch 24683 - Train Loss: 0.070544, Train Acc: 0.892308 | Val Loss: 0.105118, Val Acc: 0.793814\n",
      "Epoch 24684 - Train Loss: 0.070542, Train Acc: 0.892308 | Val Loss: 0.105117, Val Acc: 0.793814\n",
      "Epoch 24685 - Train Loss: 0.070541, Train Acc: 0.892308 | Val Loss: 0.105117, Val Acc: 0.793814\n",
      "Epoch 24686 - Train Loss: 0.070539, Train Acc: 0.892308 | Val Loss: 0.105117, Val Acc: 0.793814\n",
      "Epoch 24687 - Train Loss: 0.070538, Train Acc: 0.892308 | Val Loss: 0.105117, Val Acc: 0.793814\n",
      "Epoch 24688 - Train Loss: 0.070537, Train Acc: 0.892308 | Val Loss: 0.105116, Val Acc: 0.793814\n",
      "Epoch 24689 - Train Loss: 0.070535, Train Acc: 0.892308 | Val Loss: 0.105116, Val Acc: 0.793814\n",
      "Epoch 24690 - Train Loss: 0.070534, Train Acc: 0.892308 | Val Loss: 0.105116, Val Acc: 0.793814\n",
      "Epoch 24691 - Train Loss: 0.070532, Train Acc: 0.892308 | Val Loss: 0.105116, Val Acc: 0.793814\n",
      "Epoch 24692 - Train Loss: 0.070531, Train Acc: 0.892308 | Val Loss: 0.105115, Val Acc: 0.793814\n",
      "Epoch 24693 - Train Loss: 0.070529, Train Acc: 0.892308 | Val Loss: 0.105115, Val Acc: 0.793814\n",
      "Epoch 24694 - Train Loss: 0.070528, Train Acc: 0.892308 | Val Loss: 0.105115, Val Acc: 0.793814\n",
      "Epoch 24695 - Train Loss: 0.070527, Train Acc: 0.892308 | Val Loss: 0.105115, Val Acc: 0.793814\n",
      "Epoch 24696 - Train Loss: 0.070525, Train Acc: 0.892308 | Val Loss: 0.105115, Val Acc: 0.793814\n",
      "Epoch 24697 - Train Loss: 0.070524, Train Acc: 0.892308 | Val Loss: 0.105114, Val Acc: 0.793814\n",
      "Epoch 24698 - Train Loss: 0.070522, Train Acc: 0.892308 | Val Loss: 0.105114, Val Acc: 0.793814\n",
      "Epoch 24699 - Train Loss: 0.070521, Train Acc: 0.892308 | Val Loss: 0.105114, Val Acc: 0.793814\n",
      "Epoch 24700 - Train Loss: 0.070519, Train Acc: 0.892308 | Val Loss: 0.105114, Val Acc: 0.793814\n",
      "Epoch 24701 - Train Loss: 0.070518, Train Acc: 0.892308 | Val Loss: 0.105113, Val Acc: 0.793814\n",
      "Epoch 24702 - Train Loss: 0.070517, Train Acc: 0.892308 | Val Loss: 0.105113, Val Acc: 0.793814\n",
      "Epoch 24703 - Train Loss: 0.070515, Train Acc: 0.892308 | Val Loss: 0.105113, Val Acc: 0.793814\n",
      "Epoch 24704 - Train Loss: 0.070514, Train Acc: 0.892308 | Val Loss: 0.105113, Val Acc: 0.793814\n",
      "Epoch 24705 - Train Loss: 0.070512, Train Acc: 0.892308 | Val Loss: 0.105112, Val Acc: 0.793814\n",
      "Epoch 24706 - Train Loss: 0.070511, Train Acc: 0.892308 | Val Loss: 0.105112, Val Acc: 0.793814\n",
      "Epoch 24707 - Train Loss: 0.070509, Train Acc: 0.892308 | Val Loss: 0.105112, Val Acc: 0.793814\n",
      "Epoch 24708 - Train Loss: 0.070508, Train Acc: 0.892308 | Val Loss: 0.105112, Val Acc: 0.793814\n",
      "Epoch 24709 - Train Loss: 0.070507, Train Acc: 0.892308 | Val Loss: 0.105111, Val Acc: 0.793814\n",
      "Epoch 24710 - Train Loss: 0.070505, Train Acc: 0.892308 | Val Loss: 0.105111, Val Acc: 0.793814\n",
      "Epoch 24711 - Train Loss: 0.070504, Train Acc: 0.892308 | Val Loss: 0.105111, Val Acc: 0.793814\n",
      "Epoch 24712 - Train Loss: 0.070502, Train Acc: 0.892308 | Val Loss: 0.105111, Val Acc: 0.793814\n",
      "Epoch 24713 - Train Loss: 0.070501, Train Acc: 0.892308 | Val Loss: 0.105110, Val Acc: 0.793814\n",
      "Epoch 24714 - Train Loss: 0.070499, Train Acc: 0.892308 | Val Loss: 0.105110, Val Acc: 0.793814\n",
      "Epoch 24715 - Train Loss: 0.070498, Train Acc: 0.892308 | Val Loss: 0.105110, Val Acc: 0.793814\n",
      "Epoch 24716 - Train Loss: 0.070497, Train Acc: 0.892308 | Val Loss: 0.105110, Val Acc: 0.793814\n",
      "Epoch 24717 - Train Loss: 0.070495, Train Acc: 0.892308 | Val Loss: 0.105109, Val Acc: 0.793814\n",
      "Epoch 24718 - Train Loss: 0.070494, Train Acc: 0.892308 | Val Loss: 0.105109, Val Acc: 0.793814\n",
      "Epoch 24719 - Train Loss: 0.070492, Train Acc: 0.892308 | Val Loss: 0.105109, Val Acc: 0.793814\n",
      "Epoch 24720 - Train Loss: 0.070491, Train Acc: 0.892308 | Val Loss: 0.105109, Val Acc: 0.793814\n",
      "Epoch 24721 - Train Loss: 0.070489, Train Acc: 0.892308 | Val Loss: 0.105109, Val Acc: 0.793814\n",
      "Epoch 24722 - Train Loss: 0.070488, Train Acc: 0.892308 | Val Loss: 0.105108, Val Acc: 0.793814\n",
      "Epoch 24723 - Train Loss: 0.070487, Train Acc: 0.892308 | Val Loss: 0.105108, Val Acc: 0.793814\n",
      "Epoch 24724 - Train Loss: 0.070485, Train Acc: 0.892308 | Val Loss: 0.105108, Val Acc: 0.793814\n",
      "Epoch 24725 - Train Loss: 0.070484, Train Acc: 0.892308 | Val Loss: 0.105108, Val Acc: 0.793814\n",
      "Epoch 24726 - Train Loss: 0.070482, Train Acc: 0.892308 | Val Loss: 0.105107, Val Acc: 0.793814\n",
      "Epoch 24727 - Train Loss: 0.070481, Train Acc: 0.892308 | Val Loss: 0.105107, Val Acc: 0.793814\n",
      "Epoch 24728 - Train Loss: 0.070479, Train Acc: 0.892308 | Val Loss: 0.105107, Val Acc: 0.793814\n",
      "Epoch 24729 - Train Loss: 0.070478, Train Acc: 0.892308 | Val Loss: 0.105107, Val Acc: 0.793814\n",
      "Epoch 24730 - Train Loss: 0.070477, Train Acc: 0.892308 | Val Loss: 0.105106, Val Acc: 0.793814\n",
      "Epoch 24731 - Train Loss: 0.070475, Train Acc: 0.892308 | Val Loss: 0.105106, Val Acc: 0.793814\n",
      "Epoch 24732 - Train Loss: 0.070474, Train Acc: 0.892308 | Val Loss: 0.105106, Val Acc: 0.793814\n",
      "Epoch 24733 - Train Loss: 0.070472, Train Acc: 0.892308 | Val Loss: 0.105106, Val Acc: 0.793814\n",
      "Epoch 24734 - Train Loss: 0.070471, Train Acc: 0.892308 | Val Loss: 0.105105, Val Acc: 0.793814\n",
      "Epoch 24735 - Train Loss: 0.070469, Train Acc: 0.892308 | Val Loss: 0.105105, Val Acc: 0.793814\n",
      "Epoch 24736 - Train Loss: 0.070468, Train Acc: 0.892308 | Val Loss: 0.105105, Val Acc: 0.793814\n",
      "Epoch 24737 - Train Loss: 0.070467, Train Acc: 0.892308 | Val Loss: 0.105105, Val Acc: 0.793814\n",
      "Epoch 24738 - Train Loss: 0.070465, Train Acc: 0.892308 | Val Loss: 0.105104, Val Acc: 0.793814\n",
      "Epoch 24739 - Train Loss: 0.070464, Train Acc: 0.892308 | Val Loss: 0.105104, Val Acc: 0.793814\n",
      "Epoch 24740 - Train Loss: 0.070462, Train Acc: 0.892308 | Val Loss: 0.105104, Val Acc: 0.793814\n",
      "Epoch 24741 - Train Loss: 0.070461, Train Acc: 0.892308 | Val Loss: 0.105104, Val Acc: 0.793814\n",
      "Epoch 24742 - Train Loss: 0.070460, Train Acc: 0.892308 | Val Loss: 0.105103, Val Acc: 0.793814\n",
      "Epoch 24743 - Train Loss: 0.070458, Train Acc: 0.892308 | Val Loss: 0.105103, Val Acc: 0.793814\n",
      "Epoch 24744 - Train Loss: 0.070457, Train Acc: 0.892308 | Val Loss: 0.105103, Val Acc: 0.793814\n",
      "Epoch 24745 - Train Loss: 0.070455, Train Acc: 0.892308 | Val Loss: 0.105103, Val Acc: 0.793814\n",
      "Epoch 24746 - Train Loss: 0.070454, Train Acc: 0.892308 | Val Loss: 0.105103, Val Acc: 0.793814\n",
      "Epoch 24747 - Train Loss: 0.070452, Train Acc: 0.892308 | Val Loss: 0.105102, Val Acc: 0.793814\n",
      "Epoch 24748 - Train Loss: 0.070451, Train Acc: 0.892308 | Val Loss: 0.105102, Val Acc: 0.793814\n",
      "Epoch 24749 - Train Loss: 0.070450, Train Acc: 0.892308 | Val Loss: 0.105102, Val Acc: 0.793814\n",
      "Epoch 24750 - Train Loss: 0.070448, Train Acc: 0.892308 | Val Loss: 0.105102, Val Acc: 0.793814\n",
      "Epoch 24751 - Train Loss: 0.070447, Train Acc: 0.892308 | Val Loss: 0.105101, Val Acc: 0.793814\n",
      "Epoch 24752 - Train Loss: 0.070445, Train Acc: 0.892308 | Val Loss: 0.105101, Val Acc: 0.793814\n",
      "Epoch 24753 - Train Loss: 0.070444, Train Acc: 0.892308 | Val Loss: 0.105101, Val Acc: 0.793814\n",
      "Epoch 24754 - Train Loss: 0.070442, Train Acc: 0.892308 | Val Loss: 0.105101, Val Acc: 0.793814\n",
      "Epoch 24755 - Train Loss: 0.070441, Train Acc: 0.892308 | Val Loss: 0.105100, Val Acc: 0.793814\n",
      "Epoch 24756 - Train Loss: 0.070440, Train Acc: 0.892308 | Val Loss: 0.105100, Val Acc: 0.793814\n",
      "Epoch 24757 - Train Loss: 0.070438, Train Acc: 0.892308 | Val Loss: 0.105100, Val Acc: 0.793814\n",
      "Epoch 24758 - Train Loss: 0.070437, Train Acc: 0.892308 | Val Loss: 0.105100, Val Acc: 0.793814\n",
      "Epoch 24759 - Train Loss: 0.070435, Train Acc: 0.892308 | Val Loss: 0.105099, Val Acc: 0.793814\n",
      "Epoch 24760 - Train Loss: 0.070434, Train Acc: 0.892308 | Val Loss: 0.105099, Val Acc: 0.793814\n",
      "Epoch 24761 - Train Loss: 0.070433, Train Acc: 0.892308 | Val Loss: 0.105099, Val Acc: 0.793814\n",
      "Epoch 24762 - Train Loss: 0.070431, Train Acc: 0.892308 | Val Loss: 0.105099, Val Acc: 0.793814\n",
      "Epoch 24763 - Train Loss: 0.070430, Train Acc: 0.892308 | Val Loss: 0.105099, Val Acc: 0.793814\n",
      "Epoch 24764 - Train Loss: 0.070428, Train Acc: 0.892308 | Val Loss: 0.105098, Val Acc: 0.793814\n",
      "Epoch 24765 - Train Loss: 0.070427, Train Acc: 0.892308 | Val Loss: 0.105098, Val Acc: 0.793814\n",
      "Epoch 24766 - Train Loss: 0.070425, Train Acc: 0.892308 | Val Loss: 0.105098, Val Acc: 0.793814\n",
      "Epoch 24767 - Train Loss: 0.070424, Train Acc: 0.892308 | Val Loss: 0.105098, Val Acc: 0.793814\n",
      "Epoch 24768 - Train Loss: 0.070423, Train Acc: 0.892308 | Val Loss: 0.105097, Val Acc: 0.793814\n",
      "Epoch 24769 - Train Loss: 0.070421, Train Acc: 0.892308 | Val Loss: 0.105097, Val Acc: 0.793814\n",
      "Epoch 24770 - Train Loss: 0.070420, Train Acc: 0.892308 | Val Loss: 0.105097, Val Acc: 0.793814\n",
      "Epoch 24771 - Train Loss: 0.070418, Train Acc: 0.892308 | Val Loss: 0.105097, Val Acc: 0.793814\n",
      "Epoch 24772 - Train Loss: 0.070417, Train Acc: 0.892308 | Val Loss: 0.105097, Val Acc: 0.793814\n",
      "Epoch 24773 - Train Loss: 0.070415, Train Acc: 0.892308 | Val Loss: 0.105096, Val Acc: 0.793814\n",
      "Epoch 24774 - Train Loss: 0.070414, Train Acc: 0.892308 | Val Loss: 0.105096, Val Acc: 0.793814\n",
      "Epoch 24775 - Train Loss: 0.070413, Train Acc: 0.892308 | Val Loss: 0.105096, Val Acc: 0.793814\n",
      "Epoch 24776 - Train Loss: 0.070411, Train Acc: 0.892308 | Val Loss: 0.105096, Val Acc: 0.793814\n",
      "Epoch 24777 - Train Loss: 0.070410, Train Acc: 0.892308 | Val Loss: 0.105095, Val Acc: 0.793814\n",
      "Epoch 24778 - Train Loss: 0.070408, Train Acc: 0.892308 | Val Loss: 0.105095, Val Acc: 0.793814\n",
      "Epoch 24779 - Train Loss: 0.070407, Train Acc: 0.892308 | Val Loss: 0.105095, Val Acc: 0.793814\n",
      "Epoch 24780 - Train Loss: 0.070406, Train Acc: 0.892308 | Val Loss: 0.105095, Val Acc: 0.793814\n",
      "Epoch 24781 - Train Loss: 0.070404, Train Acc: 0.892308 | Val Loss: 0.105094, Val Acc: 0.793814\n",
      "Epoch 24782 - Train Loss: 0.070403, Train Acc: 0.892308 | Val Loss: 0.105094, Val Acc: 0.793814\n",
      "Epoch 24783 - Train Loss: 0.070401, Train Acc: 0.892308 | Val Loss: 0.105094, Val Acc: 0.793814\n",
      "Epoch 24784 - Train Loss: 0.070400, Train Acc: 0.892308 | Val Loss: 0.105094, Val Acc: 0.793814\n",
      "Epoch 24785 - Train Loss: 0.070398, Train Acc: 0.892308 | Val Loss: 0.105093, Val Acc: 0.793814\n",
      "Epoch 24786 - Train Loss: 0.070397, Train Acc: 0.892308 | Val Loss: 0.105093, Val Acc: 0.793814\n",
      "Epoch 24787 - Train Loss: 0.070396, Train Acc: 0.892308 | Val Loss: 0.105093, Val Acc: 0.793814\n",
      "Epoch 24788 - Train Loss: 0.070394, Train Acc: 0.892308 | Val Loss: 0.105093, Val Acc: 0.793814\n",
      "Epoch 24789 - Train Loss: 0.070393, Train Acc: 0.892308 | Val Loss: 0.105093, Val Acc: 0.793814\n",
      "Epoch 24790 - Train Loss: 0.070391, Train Acc: 0.892308 | Val Loss: 0.105092, Val Acc: 0.793814\n",
      "Epoch 24791 - Train Loss: 0.070390, Train Acc: 0.892308 | Val Loss: 0.105092, Val Acc: 0.793814\n",
      "Epoch 24792 - Train Loss: 0.070389, Train Acc: 0.892308 | Val Loss: 0.105092, Val Acc: 0.793814\n",
      "Epoch 24793 - Train Loss: 0.070387, Train Acc: 0.892308 | Val Loss: 0.105092, Val Acc: 0.793814\n",
      "Epoch 24794 - Train Loss: 0.070386, Train Acc: 0.892308 | Val Loss: 0.105091, Val Acc: 0.793814\n",
      "Epoch 24795 - Train Loss: 0.070384, Train Acc: 0.892308 | Val Loss: 0.105091, Val Acc: 0.793814\n",
      "Epoch 24796 - Train Loss: 0.070383, Train Acc: 0.892308 | Val Loss: 0.105091, Val Acc: 0.793814\n",
      "Epoch 24797 - Train Loss: 0.070381, Train Acc: 0.892308 | Val Loss: 0.105091, Val Acc: 0.793814\n",
      "Epoch 24798 - Train Loss: 0.070380, Train Acc: 0.892308 | Val Loss: 0.105091, Val Acc: 0.793814\n",
      "Epoch 24799 - Train Loss: 0.070379, Train Acc: 0.892308 | Val Loss: 0.105090, Val Acc: 0.793814\n",
      "Epoch 24800 - Train Loss: 0.070377, Train Acc: 0.892308 | Val Loss: 0.105090, Val Acc: 0.793814\n",
      "Epoch 24801 - Train Loss: 0.070376, Train Acc: 0.892308 | Val Loss: 0.105090, Val Acc: 0.793814\n",
      "Epoch 24802 - Train Loss: 0.070374, Train Acc: 0.892308 | Val Loss: 0.105090, Val Acc: 0.793814\n",
      "Epoch 24803 - Train Loss: 0.070373, Train Acc: 0.892308 | Val Loss: 0.105089, Val Acc: 0.793814\n",
      "Epoch 24804 - Train Loss: 0.070372, Train Acc: 0.892308 | Val Loss: 0.105089, Val Acc: 0.793814\n",
      "Epoch 24805 - Train Loss: 0.070370, Train Acc: 0.892308 | Val Loss: 0.105089, Val Acc: 0.793814\n",
      "Epoch 24806 - Train Loss: 0.070369, Train Acc: 0.892308 | Val Loss: 0.105089, Val Acc: 0.793814\n",
      "Epoch 24807 - Train Loss: 0.070367, Train Acc: 0.892308 | Val Loss: 0.105088, Val Acc: 0.793814\n",
      "Epoch 24808 - Train Loss: 0.070366, Train Acc: 0.892308 | Val Loss: 0.105088, Val Acc: 0.793814\n",
      "Epoch 24809 - Train Loss: 0.070364, Train Acc: 0.892308 | Val Loss: 0.105088, Val Acc: 0.793814\n",
      "Epoch 24810 - Train Loss: 0.070363, Train Acc: 0.892308 | Val Loss: 0.105088, Val Acc: 0.793814\n",
      "Epoch 24811 - Train Loss: 0.070362, Train Acc: 0.892308 | Val Loss: 0.105087, Val Acc: 0.793814\n",
      "Epoch 24812 - Train Loss: 0.070360, Train Acc: 0.892308 | Val Loss: 0.105087, Val Acc: 0.793814\n",
      "Epoch 24813 - Train Loss: 0.070359, Train Acc: 0.892308 | Val Loss: 0.105087, Val Acc: 0.793814\n",
      "Epoch 24814 - Train Loss: 0.070357, Train Acc: 0.892308 | Val Loss: 0.105087, Val Acc: 0.793814\n",
      "Epoch 24815 - Train Loss: 0.070356, Train Acc: 0.892308 | Val Loss: 0.105087, Val Acc: 0.793814\n",
      "Epoch 24816 - Train Loss: 0.070355, Train Acc: 0.892308 | Val Loss: 0.105086, Val Acc: 0.793814\n",
      "Epoch 24817 - Train Loss: 0.070353, Train Acc: 0.892308 | Val Loss: 0.105086, Val Acc: 0.793814\n",
      "Epoch 24818 - Train Loss: 0.070352, Train Acc: 0.892308 | Val Loss: 0.105086, Val Acc: 0.793814\n",
      "Epoch 24819 - Train Loss: 0.070350, Train Acc: 0.892308 | Val Loss: 0.105086, Val Acc: 0.793814\n",
      "Epoch 24820 - Train Loss: 0.070349, Train Acc: 0.892308 | Val Loss: 0.105085, Val Acc: 0.793814\n",
      "Epoch 24821 - Train Loss: 0.070347, Train Acc: 0.892308 | Val Loss: 0.105085, Val Acc: 0.793814\n",
      "Epoch 24822 - Train Loss: 0.070346, Train Acc: 0.892308 | Val Loss: 0.105085, Val Acc: 0.793814\n",
      "Epoch 24823 - Train Loss: 0.070345, Train Acc: 0.892308 | Val Loss: 0.105085, Val Acc: 0.793814\n",
      "Epoch 24824 - Train Loss: 0.070343, Train Acc: 0.892308 | Val Loss: 0.105085, Val Acc: 0.793814\n",
      "Epoch 24825 - Train Loss: 0.070342, Train Acc: 0.892308 | Val Loss: 0.105084, Val Acc: 0.793814\n",
      "Epoch 24826 - Train Loss: 0.070340, Train Acc: 0.892308 | Val Loss: 0.105084, Val Acc: 0.793814\n",
      "Epoch 24827 - Train Loss: 0.070339, Train Acc: 0.892308 | Val Loss: 0.105084, Val Acc: 0.793814\n",
      "Epoch 24828 - Train Loss: 0.070338, Train Acc: 0.892308 | Val Loss: 0.105084, Val Acc: 0.793814\n",
      "Epoch 24829 - Train Loss: 0.070336, Train Acc: 0.892308 | Val Loss: 0.105083, Val Acc: 0.793814\n",
      "Epoch 24830 - Train Loss: 0.070335, Train Acc: 0.892308 | Val Loss: 0.105083, Val Acc: 0.793814\n",
      "Epoch 24831 - Train Loss: 0.070333, Train Acc: 0.892308 | Val Loss: 0.105083, Val Acc: 0.793814\n",
      "Epoch 24832 - Train Loss: 0.070332, Train Acc: 0.892308 | Val Loss: 0.105083, Val Acc: 0.793814\n",
      "Epoch 24833 - Train Loss: 0.070331, Train Acc: 0.892308 | Val Loss: 0.105083, Val Acc: 0.793814\n",
      "Epoch 24834 - Train Loss: 0.070329, Train Acc: 0.892308 | Val Loss: 0.105082, Val Acc: 0.793814\n",
      "Epoch 24835 - Train Loss: 0.070328, Train Acc: 0.892308 | Val Loss: 0.105082, Val Acc: 0.793814\n",
      "Epoch 24836 - Train Loss: 0.070326, Train Acc: 0.892308 | Val Loss: 0.105082, Val Acc: 0.793814\n",
      "Epoch 24837 - Train Loss: 0.070325, Train Acc: 0.892308 | Val Loss: 0.105082, Val Acc: 0.793814\n",
      "Epoch 24838 - Train Loss: 0.070323, Train Acc: 0.892308 | Val Loss: 0.105081, Val Acc: 0.793814\n",
      "Epoch 24839 - Train Loss: 0.070322, Train Acc: 0.892308 | Val Loss: 0.105081, Val Acc: 0.793814\n",
      "Epoch 24840 - Train Loss: 0.070321, Train Acc: 0.892308 | Val Loss: 0.105081, Val Acc: 0.793814\n",
      "Epoch 24841 - Train Loss: 0.070319, Train Acc: 0.892308 | Val Loss: 0.105081, Val Acc: 0.793814\n",
      "Epoch 24842 - Train Loss: 0.070318, Train Acc: 0.892308 | Val Loss: 0.105080, Val Acc: 0.793814\n",
      "Epoch 24843 - Train Loss: 0.070316, Train Acc: 0.892308 | Val Loss: 0.105080, Val Acc: 0.793814\n",
      "Epoch 24844 - Train Loss: 0.070315, Train Acc: 0.892308 | Val Loss: 0.105080, Val Acc: 0.793814\n",
      "Epoch 24845 - Train Loss: 0.070314, Train Acc: 0.892308 | Val Loss: 0.105080, Val Acc: 0.793814\n",
      "Epoch 24846 - Train Loss: 0.070312, Train Acc: 0.892308 | Val Loss: 0.105080, Val Acc: 0.793814\n",
      "Epoch 24847 - Train Loss: 0.070311, Train Acc: 0.892308 | Val Loss: 0.105079, Val Acc: 0.793814\n",
      "Epoch 24848 - Train Loss: 0.070309, Train Acc: 0.892308 | Val Loss: 0.105079, Val Acc: 0.793814\n",
      "Epoch 24849 - Train Loss: 0.070308, Train Acc: 0.892308 | Val Loss: 0.105079, Val Acc: 0.793814\n",
      "Epoch 24850 - Train Loss: 0.070306, Train Acc: 0.892308 | Val Loss: 0.105079, Val Acc: 0.793814\n",
      "Epoch 24851 - Train Loss: 0.070305, Train Acc: 0.892308 | Val Loss: 0.105078, Val Acc: 0.793814\n",
      "Epoch 24852 - Train Loss: 0.070304, Train Acc: 0.892308 | Val Loss: 0.105078, Val Acc: 0.793814\n",
      "Epoch 24853 - Train Loss: 0.070302, Train Acc: 0.892308 | Val Loss: 0.105078, Val Acc: 0.793814\n",
      "Epoch 24854 - Train Loss: 0.070301, Train Acc: 0.892308 | Val Loss: 0.105078, Val Acc: 0.793814\n",
      "Epoch 24855 - Train Loss: 0.070299, Train Acc: 0.892308 | Val Loss: 0.105078, Val Acc: 0.793814\n",
      "Epoch 24856 - Train Loss: 0.070298, Train Acc: 0.892308 | Val Loss: 0.105077, Val Acc: 0.793814\n",
      "Epoch 24857 - Train Loss: 0.070297, Train Acc: 0.892308 | Val Loss: 0.105077, Val Acc: 0.793814\n",
      "Epoch 24858 - Train Loss: 0.070295, Train Acc: 0.892308 | Val Loss: 0.105077, Val Acc: 0.793814\n",
      "Epoch 24859 - Train Loss: 0.070294, Train Acc: 0.892308 | Val Loss: 0.105077, Val Acc: 0.793814\n",
      "Epoch 24860 - Train Loss: 0.070292, Train Acc: 0.892308 | Val Loss: 0.105076, Val Acc: 0.793814\n",
      "Epoch 24861 - Train Loss: 0.070291, Train Acc: 0.892308 | Val Loss: 0.105076, Val Acc: 0.793814\n",
      "Epoch 24862 - Train Loss: 0.070290, Train Acc: 0.892308 | Val Loss: 0.105076, Val Acc: 0.793814\n",
      "Epoch 24863 - Train Loss: 0.070288, Train Acc: 0.892308 | Val Loss: 0.105076, Val Acc: 0.793814\n",
      "Epoch 24864 - Train Loss: 0.070287, Train Acc: 0.892308 | Val Loss: 0.105076, Val Acc: 0.793814\n",
      "Epoch 24865 - Train Loss: 0.070285, Train Acc: 0.892308 | Val Loss: 0.105075, Val Acc: 0.793814\n",
      "Epoch 24866 - Train Loss: 0.070284, Train Acc: 0.892308 | Val Loss: 0.105075, Val Acc: 0.793814\n",
      "Epoch 24867 - Train Loss: 0.070283, Train Acc: 0.892308 | Val Loss: 0.105075, Val Acc: 0.793814\n",
      "Epoch 24868 - Train Loss: 0.070281, Train Acc: 0.892308 | Val Loss: 0.105075, Val Acc: 0.793814\n",
      "Epoch 24869 - Train Loss: 0.070280, Train Acc: 0.892308 | Val Loss: 0.105074, Val Acc: 0.793814\n",
      "Epoch 24870 - Train Loss: 0.070278, Train Acc: 0.892308 | Val Loss: 0.105074, Val Acc: 0.793814\n",
      "Epoch 24871 - Train Loss: 0.070277, Train Acc: 0.892308 | Val Loss: 0.105074, Val Acc: 0.793814\n",
      "Epoch 24872 - Train Loss: 0.070275, Train Acc: 0.892308 | Val Loss: 0.105074, Val Acc: 0.793814\n",
      "Epoch 24873 - Train Loss: 0.070274, Train Acc: 0.892308 | Val Loss: 0.105074, Val Acc: 0.793814\n",
      "Epoch 24874 - Train Loss: 0.070273, Train Acc: 0.892308 | Val Loss: 0.105073, Val Acc: 0.793814\n",
      "Epoch 24875 - Train Loss: 0.070271, Train Acc: 0.892308 | Val Loss: 0.105073, Val Acc: 0.793814\n",
      "Epoch 24876 - Train Loss: 0.070270, Train Acc: 0.892308 | Val Loss: 0.105073, Val Acc: 0.793814\n",
      "Epoch 24877 - Train Loss: 0.070268, Train Acc: 0.892308 | Val Loss: 0.105073, Val Acc: 0.793814\n",
      "Epoch 24878 - Train Loss: 0.070267, Train Acc: 0.892308 | Val Loss: 0.105072, Val Acc: 0.793814\n",
      "Epoch 24879 - Train Loss: 0.070266, Train Acc: 0.892308 | Val Loss: 0.105072, Val Acc: 0.793814\n",
      "Epoch 24880 - Train Loss: 0.070264, Train Acc: 0.892308 | Val Loss: 0.105072, Val Acc: 0.793814\n",
      "Epoch 24881 - Train Loss: 0.070263, Train Acc: 0.892308 | Val Loss: 0.105072, Val Acc: 0.793814\n",
      "Epoch 24882 - Train Loss: 0.070261, Train Acc: 0.892308 | Val Loss: 0.105072, Val Acc: 0.793814\n",
      "Epoch 24883 - Train Loss: 0.070260, Train Acc: 0.892308 | Val Loss: 0.105071, Val Acc: 0.793814\n",
      "Epoch 24884 - Train Loss: 0.070259, Train Acc: 0.892308 | Val Loss: 0.105071, Val Acc: 0.793814\n",
      "Epoch 24885 - Train Loss: 0.070257, Train Acc: 0.892308 | Val Loss: 0.105071, Val Acc: 0.793814\n",
      "Epoch 24886 - Train Loss: 0.070256, Train Acc: 0.892308 | Val Loss: 0.105071, Val Acc: 0.793814\n",
      "Epoch 24887 - Train Loss: 0.070254, Train Acc: 0.892308 | Val Loss: 0.105070, Val Acc: 0.793814\n",
      "Epoch 24888 - Train Loss: 0.070253, Train Acc: 0.892308 | Val Loss: 0.105070, Val Acc: 0.793814\n",
      "Epoch 24889 - Train Loss: 0.070252, Train Acc: 0.892308 | Val Loss: 0.105070, Val Acc: 0.793814\n",
      "Epoch 24890 - Train Loss: 0.070250, Train Acc: 0.892308 | Val Loss: 0.105070, Val Acc: 0.793814\n",
      "Epoch 24891 - Train Loss: 0.070249, Train Acc: 0.892308 | Val Loss: 0.105070, Val Acc: 0.793814\n",
      "Epoch 24892 - Train Loss: 0.070247, Train Acc: 0.892308 | Val Loss: 0.105069, Val Acc: 0.793814\n",
      "Epoch 24893 - Train Loss: 0.070246, Train Acc: 0.892308 | Val Loss: 0.105069, Val Acc: 0.793814\n",
      "Epoch 24894 - Train Loss: 0.070244, Train Acc: 0.892308 | Val Loss: 0.105069, Val Acc: 0.793814\n",
      "Epoch 24895 - Train Loss: 0.070243, Train Acc: 0.892308 | Val Loss: 0.105069, Val Acc: 0.793814\n",
      "Epoch 24896 - Train Loss: 0.070242, Train Acc: 0.892308 | Val Loss: 0.105069, Val Acc: 0.793814\n",
      "Epoch 24897 - Train Loss: 0.070240, Train Acc: 0.892308 | Val Loss: 0.105068, Val Acc: 0.793814\n",
      "Epoch 24898 - Train Loss: 0.070239, Train Acc: 0.892308 | Val Loss: 0.105068, Val Acc: 0.793814\n",
      "Epoch 24899 - Train Loss: 0.070237, Train Acc: 0.892308 | Val Loss: 0.105068, Val Acc: 0.793814\n",
      "Epoch 24900 - Train Loss: 0.070236, Train Acc: 0.892308 | Val Loss: 0.105068, Val Acc: 0.793814\n",
      "Epoch 24901 - Train Loss: 0.070235, Train Acc: 0.892308 | Val Loss: 0.105067, Val Acc: 0.793814\n",
      "Epoch 24902 - Train Loss: 0.070233, Train Acc: 0.892308 | Val Loss: 0.105067, Val Acc: 0.793814\n",
      "Epoch 24903 - Train Loss: 0.070232, Train Acc: 0.892308 | Val Loss: 0.105067, Val Acc: 0.793814\n",
      "Epoch 24904 - Train Loss: 0.070230, Train Acc: 0.892308 | Val Loss: 0.105067, Val Acc: 0.793814\n",
      "Epoch 24905 - Train Loss: 0.070229, Train Acc: 0.892308 | Val Loss: 0.105066, Val Acc: 0.793814\n",
      "Epoch 24906 - Train Loss: 0.070228, Train Acc: 0.892308 | Val Loss: 0.105066, Val Acc: 0.793814\n",
      "Epoch 24907 - Train Loss: 0.070226, Train Acc: 0.892308 | Val Loss: 0.105066, Val Acc: 0.793814\n",
      "Epoch 24908 - Train Loss: 0.070225, Train Acc: 0.892308 | Val Loss: 0.105066, Val Acc: 0.793814\n",
      "Epoch 24909 - Train Loss: 0.070223, Train Acc: 0.892308 | Val Loss: 0.105066, Val Acc: 0.793814\n",
      "Epoch 24910 - Train Loss: 0.070222, Train Acc: 0.892308 | Val Loss: 0.105066, Val Acc: 0.793814\n",
      "Epoch 24911 - Train Loss: 0.070221, Train Acc: 0.892308 | Val Loss: 0.105065, Val Acc: 0.793814\n",
      "Epoch 24912 - Train Loss: 0.070219, Train Acc: 0.892308 | Val Loss: 0.105065, Val Acc: 0.793814\n",
      "Epoch 24913 - Train Loss: 0.070218, Train Acc: 0.892308 | Val Loss: 0.105065, Val Acc: 0.793814\n",
      "Epoch 24914 - Train Loss: 0.070216, Train Acc: 0.892308 | Val Loss: 0.105065, Val Acc: 0.793814\n",
      "Epoch 24915 - Train Loss: 0.070215, Train Acc: 0.892308 | Val Loss: 0.105064, Val Acc: 0.793814\n",
      "Epoch 24916 - Train Loss: 0.070214, Train Acc: 0.892308 | Val Loss: 0.105064, Val Acc: 0.793814\n",
      "Epoch 24917 - Train Loss: 0.070212, Train Acc: 0.892308 | Val Loss: 0.105064, Val Acc: 0.793814\n",
      "Epoch 24918 - Train Loss: 0.070211, Train Acc: 0.892308 | Val Loss: 0.105064, Val Acc: 0.793814\n",
      "Epoch 24919 - Train Loss: 0.070209, Train Acc: 0.892308 | Val Loss: 0.105064, Val Acc: 0.793814\n",
      "Epoch 24920 - Train Loss: 0.070208, Train Acc: 0.892308 | Val Loss: 0.105063, Val Acc: 0.793814\n",
      "Epoch 24921 - Train Loss: 0.070207, Train Acc: 0.892308 | Val Loss: 0.105063, Val Acc: 0.793814\n",
      "Epoch 24922 - Train Loss: 0.070205, Train Acc: 0.892308 | Val Loss: 0.105063, Val Acc: 0.793814\n",
      "Epoch 24923 - Train Loss: 0.070204, Train Acc: 0.892308 | Val Loss: 0.105063, Val Acc: 0.793814\n",
      "Epoch 24924 - Train Loss: 0.070202, Train Acc: 0.892308 | Val Loss: 0.105062, Val Acc: 0.793814\n",
      "Epoch 24925 - Train Loss: 0.070201, Train Acc: 0.892308 | Val Loss: 0.105062, Val Acc: 0.793814\n",
      "Epoch 24926 - Train Loss: 0.070200, Train Acc: 0.892308 | Val Loss: 0.105062, Val Acc: 0.793814\n",
      "Epoch 24927 - Train Loss: 0.070198, Train Acc: 0.892308 | Val Loss: 0.105062, Val Acc: 0.793814\n",
      "Epoch 24928 - Train Loss: 0.070197, Train Acc: 0.892308 | Val Loss: 0.105061, Val Acc: 0.793814\n",
      "Epoch 24929 - Train Loss: 0.070195, Train Acc: 0.892308 | Val Loss: 0.105061, Val Acc: 0.793814\n",
      "Epoch 24930 - Train Loss: 0.070194, Train Acc: 0.892308 | Val Loss: 0.105061, Val Acc: 0.793814\n",
      "Epoch 24931 - Train Loss: 0.070193, Train Acc: 0.892308 | Val Loss: 0.105061, Val Acc: 0.793814\n",
      "Epoch 24932 - Train Loss: 0.070191, Train Acc: 0.892308 | Val Loss: 0.105061, Val Acc: 0.793814\n",
      "Epoch 24933 - Train Loss: 0.070190, Train Acc: 0.892308 | Val Loss: 0.105060, Val Acc: 0.793814\n",
      "Epoch 24934 - Train Loss: 0.070188, Train Acc: 0.892308 | Val Loss: 0.105060, Val Acc: 0.793814\n",
      "Epoch 24935 - Train Loss: 0.070187, Train Acc: 0.892308 | Val Loss: 0.105060, Val Acc: 0.793814\n",
      "Epoch 24936 - Train Loss: 0.070185, Train Acc: 0.892308 | Val Loss: 0.105060, Val Acc: 0.793814\n",
      "Epoch 24937 - Train Loss: 0.070184, Train Acc: 0.892308 | Val Loss: 0.105060, Val Acc: 0.793814\n",
      "Epoch 24938 - Train Loss: 0.070183, Train Acc: 0.892308 | Val Loss: 0.105059, Val Acc: 0.793814\n",
      "Epoch 24939 - Train Loss: 0.070181, Train Acc: 0.892308 | Val Loss: 0.105059, Val Acc: 0.793814\n",
      "Epoch 24940 - Train Loss: 0.070180, Train Acc: 0.892308 | Val Loss: 0.105059, Val Acc: 0.793814\n",
      "Epoch 24941 - Train Loss: 0.070178, Train Acc: 0.892308 | Val Loss: 0.105059, Val Acc: 0.793814\n",
      "Epoch 24942 - Train Loss: 0.070177, Train Acc: 0.892308 | Val Loss: 0.105059, Val Acc: 0.793814\n",
      "Epoch 24943 - Train Loss: 0.070176, Train Acc: 0.892308 | Val Loss: 0.105058, Val Acc: 0.793814\n",
      "Epoch 24944 - Train Loss: 0.070174, Train Acc: 0.892308 | Val Loss: 0.105058, Val Acc: 0.793814\n",
      "Epoch 24945 - Train Loss: 0.070173, Train Acc: 0.892308 | Val Loss: 0.105058, Val Acc: 0.793814\n",
      "Epoch 24946 - Train Loss: 0.070171, Train Acc: 0.892308 | Val Loss: 0.105058, Val Acc: 0.793814\n",
      "Epoch 24947 - Train Loss: 0.070170, Train Acc: 0.892308 | Val Loss: 0.105057, Val Acc: 0.793814\n",
      "Epoch 24948 - Train Loss: 0.070169, Train Acc: 0.892308 | Val Loss: 0.105057, Val Acc: 0.793814\n",
      "Epoch 24949 - Train Loss: 0.070167, Train Acc: 0.892308 | Val Loss: 0.105057, Val Acc: 0.793814\n",
      "Epoch 24950 - Train Loss: 0.070166, Train Acc: 0.892308 | Val Loss: 0.105057, Val Acc: 0.793814\n",
      "Epoch 24951 - Train Loss: 0.070164, Train Acc: 0.892308 | Val Loss: 0.105057, Val Acc: 0.793814\n",
      "Epoch 24952 - Train Loss: 0.070163, Train Acc: 0.892308 | Val Loss: 0.105056, Val Acc: 0.793814\n",
      "Epoch 24953 - Train Loss: 0.070162, Train Acc: 0.892308 | Val Loss: 0.105056, Val Acc: 0.793814\n",
      "Epoch 24954 - Train Loss: 0.070160, Train Acc: 0.892308 | Val Loss: 0.105056, Val Acc: 0.793814\n",
      "Epoch 24955 - Train Loss: 0.070159, Train Acc: 0.892308 | Val Loss: 0.105056, Val Acc: 0.793814\n",
      "Epoch 24956 - Train Loss: 0.070157, Train Acc: 0.892308 | Val Loss: 0.105056, Val Acc: 0.793814\n",
      "Epoch 24957 - Train Loss: 0.070156, Train Acc: 0.892308 | Val Loss: 0.105055, Val Acc: 0.793814\n",
      "Epoch 24958 - Train Loss: 0.070155, Train Acc: 0.892308 | Val Loss: 0.105055, Val Acc: 0.793814\n",
      "Epoch 24959 - Train Loss: 0.070153, Train Acc: 0.892308 | Val Loss: 0.105055, Val Acc: 0.793814\n",
      "Epoch 24960 - Train Loss: 0.070152, Train Acc: 0.892308 | Val Loss: 0.105055, Val Acc: 0.793814\n",
      "Epoch 24961 - Train Loss: 0.070150, Train Acc: 0.892308 | Val Loss: 0.105055, Val Acc: 0.793814\n",
      "Epoch 24962 - Train Loss: 0.070149, Train Acc: 0.892308 | Val Loss: 0.105054, Val Acc: 0.793814\n",
      "Epoch 24963 - Train Loss: 0.070148, Train Acc: 0.892308 | Val Loss: 0.105054, Val Acc: 0.793814\n",
      "Epoch 24964 - Train Loss: 0.070146, Train Acc: 0.892308 | Val Loss: 0.105054, Val Acc: 0.793814\n",
      "Epoch 24965 - Train Loss: 0.070145, Train Acc: 0.892308 | Val Loss: 0.105054, Val Acc: 0.793814\n",
      "Epoch 24966 - Train Loss: 0.070143, Train Acc: 0.892308 | Val Loss: 0.105053, Val Acc: 0.793814\n",
      "Epoch 24967 - Train Loss: 0.070142, Train Acc: 0.892308 | Val Loss: 0.105053, Val Acc: 0.793814\n",
      "Epoch 24968 - Train Loss: 0.070141, Train Acc: 0.892308 | Val Loss: 0.105053, Val Acc: 0.793814\n",
      "Epoch 24969 - Train Loss: 0.070139, Train Acc: 0.892308 | Val Loss: 0.105053, Val Acc: 0.793814\n",
      "Epoch 24970 - Train Loss: 0.070138, Train Acc: 0.892308 | Val Loss: 0.105053, Val Acc: 0.793814\n",
      "Epoch 24971 - Train Loss: 0.070136, Train Acc: 0.892308 | Val Loss: 0.105052, Val Acc: 0.793814\n",
      "Epoch 24972 - Train Loss: 0.070135, Train Acc: 0.892308 | Val Loss: 0.105052, Val Acc: 0.793814\n",
      "Epoch 24973 - Train Loss: 0.070134, Train Acc: 0.892308 | Val Loss: 0.105052, Val Acc: 0.793814\n",
      "Epoch 24974 - Train Loss: 0.070132, Train Acc: 0.892308 | Val Loss: 0.105052, Val Acc: 0.793814\n",
      "Epoch 24975 - Train Loss: 0.070131, Train Acc: 0.892308 | Val Loss: 0.105052, Val Acc: 0.793814\n",
      "Epoch 24976 - Train Loss: 0.070129, Train Acc: 0.892308 | Val Loss: 0.105051, Val Acc: 0.793814\n",
      "Epoch 24977 - Train Loss: 0.070128, Train Acc: 0.892308 | Val Loss: 0.105051, Val Acc: 0.793814\n",
      "Epoch 24978 - Train Loss: 0.070127, Train Acc: 0.892308 | Val Loss: 0.105051, Val Acc: 0.793814\n",
      "Epoch 24979 - Train Loss: 0.070125, Train Acc: 0.892308 | Val Loss: 0.105051, Val Acc: 0.793814\n",
      "Epoch 24980 - Train Loss: 0.070124, Train Acc: 0.892308 | Val Loss: 0.105050, Val Acc: 0.793814\n",
      "Epoch 24981 - Train Loss: 0.070122, Train Acc: 0.892308 | Val Loss: 0.105050, Val Acc: 0.793814\n",
      "Epoch 24982 - Train Loss: 0.070121, Train Acc: 0.892308 | Val Loss: 0.105050, Val Acc: 0.793814\n",
      "Epoch 24983 - Train Loss: 0.070120, Train Acc: 0.892308 | Val Loss: 0.105050, Val Acc: 0.793814\n",
      "Epoch 24984 - Train Loss: 0.070118, Train Acc: 0.892308 | Val Loss: 0.105050, Val Acc: 0.793814\n",
      "Epoch 24985 - Train Loss: 0.070117, Train Acc: 0.892308 | Val Loss: 0.105049, Val Acc: 0.793814\n",
      "Epoch 24986 - Train Loss: 0.070115, Train Acc: 0.892308 | Val Loss: 0.105049, Val Acc: 0.793814\n",
      "Epoch 24987 - Train Loss: 0.070114, Train Acc: 0.892308 | Val Loss: 0.105049, Val Acc: 0.793814\n",
      "Epoch 24988 - Train Loss: 0.070113, Train Acc: 0.892308 | Val Loss: 0.105049, Val Acc: 0.793814\n",
      "Epoch 24989 - Train Loss: 0.070111, Train Acc: 0.892308 | Val Loss: 0.105049, Val Acc: 0.793814\n",
      "Epoch 24990 - Train Loss: 0.070110, Train Acc: 0.892308 | Val Loss: 0.105048, Val Acc: 0.793814\n",
      "Epoch 24991 - Train Loss: 0.070109, Train Acc: 0.892308 | Val Loss: 0.105048, Val Acc: 0.793814\n",
      "Epoch 24992 - Train Loss: 0.070107, Train Acc: 0.892308 | Val Loss: 0.105048, Val Acc: 0.793814\n",
      "Epoch 24993 - Train Loss: 0.070106, Train Acc: 0.892308 | Val Loss: 0.105048, Val Acc: 0.793814\n",
      "Epoch 24994 - Train Loss: 0.070104, Train Acc: 0.892308 | Val Loss: 0.105048, Val Acc: 0.793814\n",
      "Epoch 24995 - Train Loss: 0.070103, Train Acc: 0.892308 | Val Loss: 0.105047, Val Acc: 0.793814\n",
      "Epoch 24996 - Train Loss: 0.070102, Train Acc: 0.892308 | Val Loss: 0.105047, Val Acc: 0.793814\n",
      "Epoch 24997 - Train Loss: 0.070100, Train Acc: 0.892308 | Val Loss: 0.105047, Val Acc: 0.793814\n",
      "Epoch 24998 - Train Loss: 0.070099, Train Acc: 0.892308 | Val Loss: 0.105047, Val Acc: 0.793814\n",
      "Epoch 24999 - Train Loss: 0.070097, Train Acc: 0.892308 | Val Loss: 0.105046, Val Acc: 0.793814\n",
      "Epoch 25000 - Train Loss: 0.070096, Train Acc: 0.892308 | Val Loss: 0.105046, Val Acc: 0.793814\n",
      "Epoch 25001 - Train Loss: 0.070095, Train Acc: 0.892308 | Val Loss: 0.105046, Val Acc: 0.793814\n",
      "Epoch 25002 - Train Loss: 0.070093, Train Acc: 0.892308 | Val Loss: 0.105046, Val Acc: 0.793814\n",
      "Epoch 25003 - Train Loss: 0.070092, Train Acc: 0.892308 | Val Loss: 0.105046, Val Acc: 0.793814\n",
      "Epoch 25004 - Train Loss: 0.070090, Train Acc: 0.892308 | Val Loss: 0.105045, Val Acc: 0.793814\n",
      "Epoch 25005 - Train Loss: 0.070089, Train Acc: 0.892308 | Val Loss: 0.105045, Val Acc: 0.793814\n",
      "Epoch 25006 - Train Loss: 0.070088, Train Acc: 0.892308 | Val Loss: 0.105045, Val Acc: 0.793814\n",
      "Epoch 25007 - Train Loss: 0.070086, Train Acc: 0.892308 | Val Loss: 0.105045, Val Acc: 0.793814\n",
      "Epoch 25008 - Train Loss: 0.070085, Train Acc: 0.892308 | Val Loss: 0.105045, Val Acc: 0.793814\n",
      "Epoch 25009 - Train Loss: 0.070083, Train Acc: 0.892308 | Val Loss: 0.105044, Val Acc: 0.793814\n",
      "Epoch 25010 - Train Loss: 0.070082, Train Acc: 0.892308 | Val Loss: 0.105044, Val Acc: 0.793814\n",
      "Epoch 25011 - Train Loss: 0.070081, Train Acc: 0.892308 | Val Loss: 0.105044, Val Acc: 0.793814\n",
      "Epoch 25012 - Train Loss: 0.070079, Train Acc: 0.892308 | Val Loss: 0.105044, Val Acc: 0.793814\n",
      "Epoch 25013 - Train Loss: 0.070078, Train Acc: 0.892308 | Val Loss: 0.105044, Val Acc: 0.793814\n",
      "Epoch 25014 - Train Loss: 0.070076, Train Acc: 0.892308 | Val Loss: 0.105043, Val Acc: 0.793814\n",
      "Epoch 25015 - Train Loss: 0.070075, Train Acc: 0.892308 | Val Loss: 0.105043, Val Acc: 0.793814\n",
      "Epoch 25016 - Train Loss: 0.070074, Train Acc: 0.892308 | Val Loss: 0.105043, Val Acc: 0.793814\n",
      "Epoch 25017 - Train Loss: 0.070072, Train Acc: 0.892308 | Val Loss: 0.105043, Val Acc: 0.793814\n",
      "Epoch 25018 - Train Loss: 0.070071, Train Acc: 0.892308 | Val Loss: 0.105042, Val Acc: 0.793814\n",
      "Epoch 25019 - Train Loss: 0.070069, Train Acc: 0.892308 | Val Loss: 0.105042, Val Acc: 0.793814\n",
      "Epoch 25020 - Train Loss: 0.070068, Train Acc: 0.892308 | Val Loss: 0.105042, Val Acc: 0.793814\n",
      "Epoch 25021 - Train Loss: 0.070067, Train Acc: 0.892308 | Val Loss: 0.105042, Val Acc: 0.793814\n",
      "Epoch 25022 - Train Loss: 0.070065, Train Acc: 0.892308 | Val Loss: 0.105042, Val Acc: 0.793814\n",
      "Epoch 25023 - Train Loss: 0.070064, Train Acc: 0.892308 | Val Loss: 0.105041, Val Acc: 0.793814\n",
      "Epoch 25024 - Train Loss: 0.070062, Train Acc: 0.892308 | Val Loss: 0.105041, Val Acc: 0.793814\n",
      "Epoch 25025 - Train Loss: 0.070061, Train Acc: 0.892308 | Val Loss: 0.105041, Val Acc: 0.793814\n",
      "Epoch 25026 - Train Loss: 0.070060, Train Acc: 0.892308 | Val Loss: 0.105041, Val Acc: 0.793814\n",
      "Epoch 25027 - Train Loss: 0.070058, Train Acc: 0.892308 | Val Loss: 0.105041, Val Acc: 0.793814\n",
      "Epoch 25028 - Train Loss: 0.070057, Train Acc: 0.892308 | Val Loss: 0.105040, Val Acc: 0.793814\n",
      "Epoch 25029 - Train Loss: 0.070055, Train Acc: 0.892308 | Val Loss: 0.105040, Val Acc: 0.793814\n",
      "Epoch 25030 - Train Loss: 0.070054, Train Acc: 0.892308 | Val Loss: 0.105040, Val Acc: 0.793814\n",
      "Epoch 25031 - Train Loss: 0.070053, Train Acc: 0.892308 | Val Loss: 0.105040, Val Acc: 0.793814\n",
      "Epoch 25032 - Train Loss: 0.070051, Train Acc: 0.892308 | Val Loss: 0.105040, Val Acc: 0.793814\n",
      "Epoch 25033 - Train Loss: 0.070050, Train Acc: 0.892308 | Val Loss: 0.105039, Val Acc: 0.793814\n",
      "Epoch 25034 - Train Loss: 0.070049, Train Acc: 0.892308 | Val Loss: 0.105039, Val Acc: 0.793814\n",
      "Epoch 25035 - Train Loss: 0.070047, Train Acc: 0.892308 | Val Loss: 0.105039, Val Acc: 0.793814\n",
      "Epoch 25036 - Train Loss: 0.070046, Train Acc: 0.892308 | Val Loss: 0.105039, Val Acc: 0.793814\n",
      "Epoch 25037 - Train Loss: 0.070044, Train Acc: 0.892308 | Val Loss: 0.105039, Val Acc: 0.793814\n",
      "Epoch 25038 - Train Loss: 0.070043, Train Acc: 0.892308 | Val Loss: 0.105038, Val Acc: 0.793814\n",
      "Epoch 25039 - Train Loss: 0.070042, Train Acc: 0.892308 | Val Loss: 0.105038, Val Acc: 0.793814\n",
      "Epoch 25040 - Train Loss: 0.070040, Train Acc: 0.892308 | Val Loss: 0.105038, Val Acc: 0.793814\n",
      "Epoch 25041 - Train Loss: 0.070039, Train Acc: 0.892308 | Val Loss: 0.105038, Val Acc: 0.793814\n",
      "Epoch 25042 - Train Loss: 0.070037, Train Acc: 0.892308 | Val Loss: 0.105037, Val Acc: 0.793814\n",
      "Epoch 25043 - Train Loss: 0.070036, Train Acc: 0.892308 | Val Loss: 0.105037, Val Acc: 0.793814\n",
      "Epoch 25044 - Train Loss: 0.070035, Train Acc: 0.892308 | Val Loss: 0.105037, Val Acc: 0.793814\n",
      "Epoch 25045 - Train Loss: 0.070033, Train Acc: 0.892308 | Val Loss: 0.105037, Val Acc: 0.793814\n",
      "Epoch 25046 - Train Loss: 0.070032, Train Acc: 0.892308 | Val Loss: 0.105037, Val Acc: 0.793814\n",
      "Epoch 25047 - Train Loss: 0.070030, Train Acc: 0.892308 | Val Loss: 0.105037, Val Acc: 0.793814\n",
      "Epoch 25048 - Train Loss: 0.070029, Train Acc: 0.892308 | Val Loss: 0.105036, Val Acc: 0.793814\n",
      "Epoch 25049 - Train Loss: 0.070028, Train Acc: 0.892308 | Val Loss: 0.105036, Val Acc: 0.793814\n",
      "Epoch 25050 - Train Loss: 0.070026, Train Acc: 0.892308 | Val Loss: 0.105036, Val Acc: 0.793814\n",
      "Epoch 25051 - Train Loss: 0.070025, Train Acc: 0.892308 | Val Loss: 0.105036, Val Acc: 0.793814\n",
      "Epoch 25052 - Train Loss: 0.070023, Train Acc: 0.892308 | Val Loss: 0.105035, Val Acc: 0.793814\n",
      "Epoch 25053 - Train Loss: 0.070022, Train Acc: 0.892308 | Val Loss: 0.105035, Val Acc: 0.793814\n",
      "Epoch 25054 - Train Loss: 0.070021, Train Acc: 0.892308 | Val Loss: 0.105035, Val Acc: 0.793814\n",
      "Epoch 25055 - Train Loss: 0.070019, Train Acc: 0.892308 | Val Loss: 0.105035, Val Acc: 0.793814\n",
      "Epoch 25056 - Train Loss: 0.070018, Train Acc: 0.892308 | Val Loss: 0.105035, Val Acc: 0.793814\n",
      "Epoch 25057 - Train Loss: 0.070017, Train Acc: 0.892308 | Val Loss: 0.105034, Val Acc: 0.793814\n",
      "Epoch 25058 - Train Loss: 0.070015, Train Acc: 0.892308 | Val Loss: 0.105034, Val Acc: 0.793814\n",
      "Epoch 25059 - Train Loss: 0.070014, Train Acc: 0.892308 | Val Loss: 0.105034, Val Acc: 0.793814\n",
      "Epoch 25060 - Train Loss: 0.070012, Train Acc: 0.892308 | Val Loss: 0.105034, Val Acc: 0.793814\n",
      "Epoch 25061 - Train Loss: 0.070011, Train Acc: 0.892308 | Val Loss: 0.105034, Val Acc: 0.793814\n",
      "Epoch 25062 - Train Loss: 0.070010, Train Acc: 0.892308 | Val Loss: 0.105033, Val Acc: 0.793814\n",
      "Epoch 25063 - Train Loss: 0.070008, Train Acc: 0.892308 | Val Loss: 0.105033, Val Acc: 0.793814\n",
      "Epoch 25064 - Train Loss: 0.070007, Train Acc: 0.892308 | Val Loss: 0.105033, Val Acc: 0.793814\n",
      "Epoch 25065 - Train Loss: 0.070005, Train Acc: 0.892308 | Val Loss: 0.105033, Val Acc: 0.793814\n",
      "Epoch 25066 - Train Loss: 0.070004, Train Acc: 0.892308 | Val Loss: 0.105033, Val Acc: 0.793814\n",
      "Epoch 25067 - Train Loss: 0.070003, Train Acc: 0.892308 | Val Loss: 0.105032, Val Acc: 0.793814\n",
      "Epoch 25068 - Train Loss: 0.070001, Train Acc: 0.892308 | Val Loss: 0.105032, Val Acc: 0.793814\n",
      "Epoch 25069 - Train Loss: 0.070000, Train Acc: 0.892308 | Val Loss: 0.105032, Val Acc: 0.793814\n",
      "Epoch 25070 - Train Loss: 0.069998, Train Acc: 0.892308 | Val Loss: 0.105032, Val Acc: 0.793814\n",
      "Epoch 25071 - Train Loss: 0.069997, Train Acc: 0.892308 | Val Loss: 0.105032, Val Acc: 0.793814\n",
      "Epoch 25072 - Train Loss: 0.069996, Train Acc: 0.892308 | Val Loss: 0.105031, Val Acc: 0.793814\n",
      "Epoch 25073 - Train Loss: 0.069994, Train Acc: 0.892308 | Val Loss: 0.105031, Val Acc: 0.793814\n",
      "Epoch 25074 - Train Loss: 0.069993, Train Acc: 0.892308 | Val Loss: 0.105031, Val Acc: 0.793814\n",
      "Epoch 25075 - Train Loss: 0.069991, Train Acc: 0.892308 | Val Loss: 0.105031, Val Acc: 0.793814\n",
      "Epoch 25076 - Train Loss: 0.069990, Train Acc: 0.892308 | Val Loss: 0.105031, Val Acc: 0.793814\n",
      "Epoch 25077 - Train Loss: 0.069989, Train Acc: 0.892308 | Val Loss: 0.105030, Val Acc: 0.793814\n",
      "Epoch 25078 - Train Loss: 0.069987, Train Acc: 0.892308 | Val Loss: 0.105030, Val Acc: 0.793814\n",
      "Epoch 25079 - Train Loss: 0.069986, Train Acc: 0.892308 | Val Loss: 0.105030, Val Acc: 0.793814\n",
      "Epoch 25080 - Train Loss: 0.069985, Train Acc: 0.892308 | Val Loss: 0.105030, Val Acc: 0.793814\n",
      "Epoch 25081 - Train Loss: 0.069983, Train Acc: 0.892308 | Val Loss: 0.105030, Val Acc: 0.793814\n",
      "Epoch 25082 - Train Loss: 0.069982, Train Acc: 0.892308 | Val Loss: 0.105029, Val Acc: 0.793814\n",
      "Epoch 25083 - Train Loss: 0.069980, Train Acc: 0.892308 | Val Loss: 0.105029, Val Acc: 0.793814\n",
      "Epoch 25084 - Train Loss: 0.069979, Train Acc: 0.892308 | Val Loss: 0.105029, Val Acc: 0.793814\n",
      "Epoch 25085 - Train Loss: 0.069978, Train Acc: 0.892308 | Val Loss: 0.105029, Val Acc: 0.793814\n",
      "Epoch 25086 - Train Loss: 0.069976, Train Acc: 0.892308 | Val Loss: 0.105029, Val Acc: 0.793814\n",
      "Epoch 25087 - Train Loss: 0.069975, Train Acc: 0.892308 | Val Loss: 0.105028, Val Acc: 0.793814\n",
      "Epoch 25088 - Train Loss: 0.069973, Train Acc: 0.892308 | Val Loss: 0.105028, Val Acc: 0.793814\n",
      "Epoch 25089 - Train Loss: 0.069972, Train Acc: 0.892308 | Val Loss: 0.105028, Val Acc: 0.793814\n",
      "Epoch 25090 - Train Loss: 0.069971, Train Acc: 0.892308 | Val Loss: 0.105028, Val Acc: 0.793814\n",
      "Epoch 25091 - Train Loss: 0.069969, Train Acc: 0.892308 | Val Loss: 0.105028, Val Acc: 0.793814\n",
      "Epoch 25092 - Train Loss: 0.069968, Train Acc: 0.892308 | Val Loss: 0.105027, Val Acc: 0.793814\n",
      "Epoch 25093 - Train Loss: 0.069967, Train Acc: 0.892308 | Val Loss: 0.105027, Val Acc: 0.793814\n",
      "Epoch 25094 - Train Loss: 0.069965, Train Acc: 0.892308 | Val Loss: 0.105027, Val Acc: 0.793814\n",
      "Epoch 25095 - Train Loss: 0.069964, Train Acc: 0.892308 | Val Loss: 0.105027, Val Acc: 0.793814\n",
      "Epoch 25096 - Train Loss: 0.069962, Train Acc: 0.892308 | Val Loss: 0.105027, Val Acc: 0.793814\n",
      "Epoch 25097 - Train Loss: 0.069961, Train Acc: 0.892308 | Val Loss: 0.105026, Val Acc: 0.793814\n",
      "Epoch 25098 - Train Loss: 0.069960, Train Acc: 0.892308 | Val Loss: 0.105026, Val Acc: 0.793814\n",
      "Epoch 25099 - Train Loss: 0.069958, Train Acc: 0.892308 | Val Loss: 0.105026, Val Acc: 0.793814\n",
      "Epoch 25100 - Train Loss: 0.069957, Train Acc: 0.892308 | Val Loss: 0.105026, Val Acc: 0.793814\n",
      "Epoch 25101 - Train Loss: 0.069955, Train Acc: 0.892308 | Val Loss: 0.105026, Val Acc: 0.793814\n",
      "Epoch 25102 - Train Loss: 0.069954, Train Acc: 0.892308 | Val Loss: 0.105025, Val Acc: 0.793814\n",
      "Epoch 25103 - Train Loss: 0.069953, Train Acc: 0.892308 | Val Loss: 0.105025, Val Acc: 0.793814\n",
      "Epoch 25104 - Train Loss: 0.069951, Train Acc: 0.892308 | Val Loss: 0.105025, Val Acc: 0.793814\n",
      "Epoch 25105 - Train Loss: 0.069950, Train Acc: 0.892308 | Val Loss: 0.105025, Val Acc: 0.793814\n",
      "Epoch 25106 - Train Loss: 0.069948, Train Acc: 0.892308 | Val Loss: 0.105025, Val Acc: 0.793814\n",
      "Epoch 25107 - Train Loss: 0.069947, Train Acc: 0.892308 | Val Loss: 0.105024, Val Acc: 0.793814\n",
      "Epoch 25108 - Train Loss: 0.069946, Train Acc: 0.892308 | Val Loss: 0.105024, Val Acc: 0.793814\n",
      "Epoch 25109 - Train Loss: 0.069944, Train Acc: 0.892308 | Val Loss: 0.105024, Val Acc: 0.793814\n",
      "Epoch 25110 - Train Loss: 0.069943, Train Acc: 0.892308 | Val Loss: 0.105024, Val Acc: 0.793814\n",
      "Epoch 25111 - Train Loss: 0.069942, Train Acc: 0.892308 | Val Loss: 0.105024, Val Acc: 0.793814\n",
      "Epoch 25112 - Train Loss: 0.069940, Train Acc: 0.892308 | Val Loss: 0.105023, Val Acc: 0.793814\n",
      "Epoch 25113 - Train Loss: 0.069939, Train Acc: 0.892308 | Val Loss: 0.105023, Val Acc: 0.793814\n",
      "Epoch 25114 - Train Loss: 0.069937, Train Acc: 0.892308 | Val Loss: 0.105023, Val Acc: 0.793814\n",
      "Epoch 25115 - Train Loss: 0.069936, Train Acc: 0.892308 | Val Loss: 0.105023, Val Acc: 0.793814\n",
      "Epoch 25116 - Train Loss: 0.069935, Train Acc: 0.892308 | Val Loss: 0.105022, Val Acc: 0.793814\n",
      "Epoch 25117 - Train Loss: 0.069933, Train Acc: 0.892308 | Val Loss: 0.105022, Val Acc: 0.793814\n",
      "Epoch 25118 - Train Loss: 0.069932, Train Acc: 0.892308 | Val Loss: 0.105022, Val Acc: 0.793814\n",
      "Epoch 25119 - Train Loss: 0.069930, Train Acc: 0.892308 | Val Loss: 0.105022, Val Acc: 0.793814\n",
      "Epoch 25120 - Train Loss: 0.069929, Train Acc: 0.892308 | Val Loss: 0.105022, Val Acc: 0.793814\n",
      "Epoch 25121 - Train Loss: 0.069928, Train Acc: 0.892308 | Val Loss: 0.105022, Val Acc: 0.793814\n",
      "Epoch 25122 - Train Loss: 0.069926, Train Acc: 0.892308 | Val Loss: 0.105021, Val Acc: 0.793814\n",
      "Epoch 25123 - Train Loss: 0.069925, Train Acc: 0.892308 | Val Loss: 0.105021, Val Acc: 0.793814\n",
      "Epoch 25124 - Train Loss: 0.069924, Train Acc: 0.892308 | Val Loss: 0.105021, Val Acc: 0.793814\n",
      "Epoch 25125 - Train Loss: 0.069922, Train Acc: 0.892308 | Val Loss: 0.105021, Val Acc: 0.793814\n",
      "Epoch 25126 - Train Loss: 0.069921, Train Acc: 0.892308 | Val Loss: 0.105020, Val Acc: 0.793814\n",
      "Epoch 25127 - Train Loss: 0.069919, Train Acc: 0.892308 | Val Loss: 0.105020, Val Acc: 0.793814\n",
      "Epoch 25128 - Train Loss: 0.069918, Train Acc: 0.892308 | Val Loss: 0.105020, Val Acc: 0.793814\n",
      "Epoch 25129 - Train Loss: 0.069917, Train Acc: 0.892308 | Val Loss: 0.105020, Val Acc: 0.793814\n",
      "Epoch 25130 - Train Loss: 0.069915, Train Acc: 0.892308 | Val Loss: 0.105020, Val Acc: 0.793814\n",
      "Epoch 25131 - Train Loss: 0.069914, Train Acc: 0.892308 | Val Loss: 0.105020, Val Acc: 0.793814\n",
      "Epoch 25132 - Train Loss: 0.069912, Train Acc: 0.892308 | Val Loss: 0.105019, Val Acc: 0.793814\n",
      "Epoch 25133 - Train Loss: 0.069911, Train Acc: 0.892308 | Val Loss: 0.105019, Val Acc: 0.793814\n",
      "Epoch 25134 - Train Loss: 0.069910, Train Acc: 0.892308 | Val Loss: 0.105019, Val Acc: 0.793814\n",
      "Epoch 25135 - Train Loss: 0.069908, Train Acc: 0.892308 | Val Loss: 0.105019, Val Acc: 0.793814\n",
      "Epoch 25136 - Train Loss: 0.069907, Train Acc: 0.892308 | Val Loss: 0.105019, Val Acc: 0.793814\n",
      "Epoch 25137 - Train Loss: 0.069906, Train Acc: 0.892308 | Val Loss: 0.105018, Val Acc: 0.793814\n",
      "Epoch 25138 - Train Loss: 0.069904, Train Acc: 0.892308 | Val Loss: 0.105018, Val Acc: 0.793814\n",
      "Epoch 25139 - Train Loss: 0.069903, Train Acc: 0.892308 | Val Loss: 0.105018, Val Acc: 0.793814\n",
      "Epoch 25140 - Train Loss: 0.069901, Train Acc: 0.892308 | Val Loss: 0.105018, Val Acc: 0.793814\n",
      "Epoch 25141 - Train Loss: 0.069900, Train Acc: 0.892308 | Val Loss: 0.105018, Val Acc: 0.793814\n",
      "Epoch 25142 - Train Loss: 0.069899, Train Acc: 0.892308 | Val Loss: 0.105017, Val Acc: 0.793814\n",
      "Epoch 25143 - Train Loss: 0.069897, Train Acc: 0.892308 | Val Loss: 0.105017, Val Acc: 0.793814\n",
      "Epoch 25144 - Train Loss: 0.069896, Train Acc: 0.892308 | Val Loss: 0.105017, Val Acc: 0.793814\n",
      "Epoch 25145 - Train Loss: 0.069895, Train Acc: 0.892308 | Val Loss: 0.105017, Val Acc: 0.793814\n",
      "Epoch 25146 - Train Loss: 0.069893, Train Acc: 0.892308 | Val Loss: 0.105017, Val Acc: 0.793814\n",
      "Epoch 25147 - Train Loss: 0.069892, Train Acc: 0.892308 | Val Loss: 0.105016, Val Acc: 0.793814\n",
      "Epoch 25148 - Train Loss: 0.069890, Train Acc: 0.892308 | Val Loss: 0.105016, Val Acc: 0.793814\n",
      "Epoch 25149 - Train Loss: 0.069889, Train Acc: 0.892308 | Val Loss: 0.105016, Val Acc: 0.793814\n",
      "Epoch 25150 - Train Loss: 0.069888, Train Acc: 0.892308 | Val Loss: 0.105016, Val Acc: 0.793814\n",
      "Epoch 25151 - Train Loss: 0.069886, Train Acc: 0.892308 | Val Loss: 0.105016, Val Acc: 0.793814\n",
      "Epoch 25152 - Train Loss: 0.069885, Train Acc: 0.892308 | Val Loss: 0.105015, Val Acc: 0.793814\n",
      "Epoch 25153 - Train Loss: 0.069883, Train Acc: 0.892308 | Val Loss: 0.105015, Val Acc: 0.793814\n",
      "Epoch 25154 - Train Loss: 0.069882, Train Acc: 0.892308 | Val Loss: 0.105015, Val Acc: 0.793814\n",
      "Epoch 25155 - Train Loss: 0.069881, Train Acc: 0.892308 | Val Loss: 0.105015, Val Acc: 0.793814\n",
      "Epoch 25156 - Train Loss: 0.069879, Train Acc: 0.892308 | Val Loss: 0.105015, Val Acc: 0.793814\n",
      "Epoch 25157 - Train Loss: 0.069878, Train Acc: 0.892308 | Val Loss: 0.105014, Val Acc: 0.793814\n",
      "Epoch 25158 - Train Loss: 0.069877, Train Acc: 0.892308 | Val Loss: 0.105014, Val Acc: 0.793814\n",
      "Epoch 25159 - Train Loss: 0.069875, Train Acc: 0.892308 | Val Loss: 0.105014, Val Acc: 0.793814\n",
      "Epoch 25160 - Train Loss: 0.069874, Train Acc: 0.892308 | Val Loss: 0.105014, Val Acc: 0.793814\n",
      "Epoch 25161 - Train Loss: 0.069872, Train Acc: 0.892308 | Val Loss: 0.105014, Val Acc: 0.793814\n",
      "Epoch 25162 - Train Loss: 0.069871, Train Acc: 0.892308 | Val Loss: 0.105013, Val Acc: 0.793814\n",
      "Epoch 25163 - Train Loss: 0.069870, Train Acc: 0.892308 | Val Loss: 0.105013, Val Acc: 0.793814\n",
      "Epoch 25164 - Train Loss: 0.069868, Train Acc: 0.892308 | Val Loss: 0.105013, Val Acc: 0.793814\n",
      "Epoch 25165 - Train Loss: 0.069867, Train Acc: 0.892308 | Val Loss: 0.105013, Val Acc: 0.793814\n",
      "Epoch 25166 - Train Loss: 0.069866, Train Acc: 0.892308 | Val Loss: 0.105013, Val Acc: 0.793814\n",
      "Epoch 25167 - Train Loss: 0.069864, Train Acc: 0.892308 | Val Loss: 0.105012, Val Acc: 0.793814\n",
      "Epoch 25168 - Train Loss: 0.069863, Train Acc: 0.892308 | Val Loss: 0.105012, Val Acc: 0.793814\n",
      "Epoch 25169 - Train Loss: 0.069861, Train Acc: 0.892308 | Val Loss: 0.105012, Val Acc: 0.793814\n",
      "Epoch 25170 - Train Loss: 0.069860, Train Acc: 0.892308 | Val Loss: 0.105012, Val Acc: 0.793814\n",
      "Epoch 25171 - Train Loss: 0.069859, Train Acc: 0.892308 | Val Loss: 0.105012, Val Acc: 0.793814\n",
      "Epoch 25172 - Train Loss: 0.069857, Train Acc: 0.892308 | Val Loss: 0.105011, Val Acc: 0.793814\n",
      "Epoch 25173 - Train Loss: 0.069856, Train Acc: 0.892308 | Val Loss: 0.105011, Val Acc: 0.793814\n",
      "Epoch 25174 - Train Loss: 0.069854, Train Acc: 0.892308 | Val Loss: 0.105011, Val Acc: 0.793814\n",
      "Epoch 25175 - Train Loss: 0.069853, Train Acc: 0.892308 | Val Loss: 0.105011, Val Acc: 0.793814\n",
      "Epoch 25176 - Train Loss: 0.069852, Train Acc: 0.892308 | Val Loss: 0.105011, Val Acc: 0.793814\n",
      "Epoch 25177 - Train Loss: 0.069850, Train Acc: 0.892308 | Val Loss: 0.105010, Val Acc: 0.793814\n",
      "Epoch 25178 - Train Loss: 0.069849, Train Acc: 0.892308 | Val Loss: 0.105010, Val Acc: 0.793814\n",
      "Epoch 25179 - Train Loss: 0.069848, Train Acc: 0.892308 | Val Loss: 0.105010, Val Acc: 0.793814\n",
      "Epoch 25180 - Train Loss: 0.069846, Train Acc: 0.892308 | Val Loss: 0.105010, Val Acc: 0.793814\n",
      "Epoch 25181 - Train Loss: 0.069845, Train Acc: 0.892308 | Val Loss: 0.105010, Val Acc: 0.793814\n",
      "Epoch 25182 - Train Loss: 0.069843, Train Acc: 0.892308 | Val Loss: 0.105010, Val Acc: 0.793814\n",
      "Epoch 25183 - Train Loss: 0.069842, Train Acc: 0.892308 | Val Loss: 0.105009, Val Acc: 0.793814\n",
      "Epoch 25184 - Train Loss: 0.069841, Train Acc: 0.892308 | Val Loss: 0.105009, Val Acc: 0.793814\n",
      "Epoch 25185 - Train Loss: 0.069839, Train Acc: 0.892308 | Val Loss: 0.105009, Val Acc: 0.793814\n",
      "Epoch 25186 - Train Loss: 0.069838, Train Acc: 0.892308 | Val Loss: 0.105009, Val Acc: 0.793814\n",
      "Epoch 25187 - Train Loss: 0.069837, Train Acc: 0.892308 | Val Loss: 0.105009, Val Acc: 0.793814\n",
      "Epoch 25188 - Train Loss: 0.069835, Train Acc: 0.892308 | Val Loss: 0.105008, Val Acc: 0.793814\n",
      "Epoch 25189 - Train Loss: 0.069834, Train Acc: 0.892308 | Val Loss: 0.105008, Val Acc: 0.793814\n",
      "Epoch 25190 - Train Loss: 0.069832, Train Acc: 0.892308 | Val Loss: 0.105008, Val Acc: 0.793814\n",
      "Epoch 25191 - Train Loss: 0.069831, Train Acc: 0.892308 | Val Loss: 0.105008, Val Acc: 0.793814\n",
      "Epoch 25192 - Train Loss: 0.069830, Train Acc: 0.892308 | Val Loss: 0.105008, Val Acc: 0.793814\n",
      "Epoch 25193 - Train Loss: 0.069828, Train Acc: 0.892308 | Val Loss: 0.105007, Val Acc: 0.793814\n",
      "Epoch 25194 - Train Loss: 0.069827, Train Acc: 0.892308 | Val Loss: 0.105007, Val Acc: 0.793814\n",
      "Epoch 25195 - Train Loss: 0.069826, Train Acc: 0.892308 | Val Loss: 0.105007, Val Acc: 0.793814\n",
      "Epoch 25196 - Train Loss: 0.069824, Train Acc: 0.892308 | Val Loss: 0.105007, Val Acc: 0.793814\n",
      "Epoch 25197 - Train Loss: 0.069823, Train Acc: 0.892308 | Val Loss: 0.105007, Val Acc: 0.793814\n",
      "Epoch 25198 - Train Loss: 0.069821, Train Acc: 0.892308 | Val Loss: 0.105006, Val Acc: 0.793814\n",
      "Epoch 25199 - Train Loss: 0.069820, Train Acc: 0.892308 | Val Loss: 0.105006, Val Acc: 0.793814\n",
      "Epoch 25200 - Train Loss: 0.069819, Train Acc: 0.892308 | Val Loss: 0.105006, Val Acc: 0.793814\n",
      "Epoch 25201 - Train Loss: 0.069817, Train Acc: 0.892308 | Val Loss: 0.105006, Val Acc: 0.793814\n",
      "Epoch 25202 - Train Loss: 0.069816, Train Acc: 0.892308 | Val Loss: 0.105006, Val Acc: 0.793814\n",
      "Epoch 25203 - Train Loss: 0.069815, Train Acc: 0.892308 | Val Loss: 0.105006, Val Acc: 0.793814\n",
      "Epoch 25204 - Train Loss: 0.069813, Train Acc: 0.892308 | Val Loss: 0.105005, Val Acc: 0.793814\n",
      "Epoch 25205 - Train Loss: 0.069812, Train Acc: 0.892308 | Val Loss: 0.105005, Val Acc: 0.793814\n",
      "Epoch 25206 - Train Loss: 0.069810, Train Acc: 0.892308 | Val Loss: 0.105005, Val Acc: 0.793814\n",
      "Epoch 25207 - Train Loss: 0.069809, Train Acc: 0.892308 | Val Loss: 0.105005, Val Acc: 0.793814\n",
      "Epoch 25208 - Train Loss: 0.069808, Train Acc: 0.892308 | Val Loss: 0.105005, Val Acc: 0.793814\n",
      "Epoch 25209 - Train Loss: 0.069806, Train Acc: 0.892308 | Val Loss: 0.105004, Val Acc: 0.793814\n",
      "Epoch 25210 - Train Loss: 0.069805, Train Acc: 0.892308 | Val Loss: 0.105004, Val Acc: 0.793814\n",
      "Epoch 25211 - Train Loss: 0.069804, Train Acc: 0.892308 | Val Loss: 0.105004, Val Acc: 0.793814\n",
      "Epoch 25212 - Train Loss: 0.069802, Train Acc: 0.892308 | Val Loss: 0.105004, Val Acc: 0.793814\n",
      "Epoch 25213 - Train Loss: 0.069801, Train Acc: 0.892308 | Val Loss: 0.105004, Val Acc: 0.793814\n",
      "Epoch 25214 - Train Loss: 0.069799, Train Acc: 0.892308 | Val Loss: 0.105003, Val Acc: 0.793814\n",
      "Epoch 25215 - Train Loss: 0.069798, Train Acc: 0.892308 | Val Loss: 0.105003, Val Acc: 0.793814\n",
      "Epoch 25216 - Train Loss: 0.069797, Train Acc: 0.892308 | Val Loss: 0.105003, Val Acc: 0.793814\n",
      "Epoch 25217 - Train Loss: 0.069795, Train Acc: 0.892308 | Val Loss: 0.105003, Val Acc: 0.793814\n",
      "Epoch 25218 - Train Loss: 0.069794, Train Acc: 0.892308 | Val Loss: 0.105003, Val Acc: 0.793814\n",
      "Epoch 25219 - Train Loss: 0.069793, Train Acc: 0.892308 | Val Loss: 0.105002, Val Acc: 0.793814\n",
      "Epoch 25220 - Train Loss: 0.069791, Train Acc: 0.892308 | Val Loss: 0.105002, Val Acc: 0.793814\n",
      "Epoch 25221 - Train Loss: 0.069790, Train Acc: 0.892308 | Val Loss: 0.105002, Val Acc: 0.793814\n",
      "Epoch 25222 - Train Loss: 0.069788, Train Acc: 0.892308 | Val Loss: 0.105002, Val Acc: 0.793814\n",
      "Epoch 25223 - Train Loss: 0.069787, Train Acc: 0.892308 | Val Loss: 0.105002, Val Acc: 0.793814\n",
      "Epoch 25224 - Train Loss: 0.069786, Train Acc: 0.892308 | Val Loss: 0.105002, Val Acc: 0.793814\n",
      "Epoch 25225 - Train Loss: 0.069784, Train Acc: 0.892308 | Val Loss: 0.105001, Val Acc: 0.793814\n",
      "Epoch 25226 - Train Loss: 0.069783, Train Acc: 0.892308 | Val Loss: 0.105001, Val Acc: 0.793814\n",
      "Epoch 25227 - Train Loss: 0.069782, Train Acc: 0.892308 | Val Loss: 0.105001, Val Acc: 0.793814\n",
      "Epoch 25228 - Train Loss: 0.069780, Train Acc: 0.892308 | Val Loss: 0.105001, Val Acc: 0.793814\n",
      "Epoch 25229 - Train Loss: 0.069779, Train Acc: 0.892308 | Val Loss: 0.105001, Val Acc: 0.793814\n",
      "Epoch 25230 - Train Loss: 0.069777, Train Acc: 0.892308 | Val Loss: 0.105000, Val Acc: 0.793814\n",
      "Epoch 25231 - Train Loss: 0.069776, Train Acc: 0.892308 | Val Loss: 0.105000, Val Acc: 0.793814\n",
      "Epoch 25232 - Train Loss: 0.069775, Train Acc: 0.892308 | Val Loss: 0.105000, Val Acc: 0.793814\n",
      "Epoch 25233 - Train Loss: 0.069773, Train Acc: 0.892308 | Val Loss: 0.105000, Val Acc: 0.793814\n",
      "Epoch 25234 - Train Loss: 0.069772, Train Acc: 0.892308 | Val Loss: 0.105000, Val Acc: 0.793814\n",
      "Epoch 25235 - Train Loss: 0.069771, Train Acc: 0.892308 | Val Loss: 0.104999, Val Acc: 0.793814\n",
      "Epoch 25236 - Train Loss: 0.069769, Train Acc: 0.892308 | Val Loss: 0.104999, Val Acc: 0.793814\n",
      "Epoch 25237 - Train Loss: 0.069768, Train Acc: 0.892308 | Val Loss: 0.104999, Val Acc: 0.793814\n",
      "Epoch 25238 - Train Loss: 0.069766, Train Acc: 0.892308 | Val Loss: 0.104999, Val Acc: 0.793814\n",
      "Epoch 25239 - Train Loss: 0.069765, Train Acc: 0.892308 | Val Loss: 0.104999, Val Acc: 0.793814\n",
      "Epoch 25240 - Train Loss: 0.069764, Train Acc: 0.892308 | Val Loss: 0.104998, Val Acc: 0.793814\n",
      "Epoch 25241 - Train Loss: 0.069762, Train Acc: 0.892308 | Val Loss: 0.104998, Val Acc: 0.793814\n",
      "Epoch 25242 - Train Loss: 0.069761, Train Acc: 0.892308 | Val Loss: 0.104998, Val Acc: 0.793814\n",
      "Epoch 25243 - Train Loss: 0.069760, Train Acc: 0.892308 | Val Loss: 0.104998, Val Acc: 0.793814\n",
      "Epoch 25244 - Train Loss: 0.069758, Train Acc: 0.892308 | Val Loss: 0.104998, Val Acc: 0.793814\n",
      "Epoch 25245 - Train Loss: 0.069757, Train Acc: 0.892308 | Val Loss: 0.104998, Val Acc: 0.793814\n",
      "Epoch 25246 - Train Loss: 0.069755, Train Acc: 0.892308 | Val Loss: 0.104997, Val Acc: 0.793814\n",
      "Epoch 25247 - Train Loss: 0.069754, Train Acc: 0.892308 | Val Loss: 0.104997, Val Acc: 0.793814\n",
      "Epoch 25248 - Train Loss: 0.069753, Train Acc: 0.892308 | Val Loss: 0.104997, Val Acc: 0.793814\n",
      "Epoch 25249 - Train Loss: 0.069751, Train Acc: 0.892308 | Val Loss: 0.104997, Val Acc: 0.793814\n",
      "Epoch 25250 - Train Loss: 0.069750, Train Acc: 0.892308 | Val Loss: 0.104997, Val Acc: 0.793814\n",
      "Epoch 25251 - Train Loss: 0.069749, Train Acc: 0.892308 | Val Loss: 0.104996, Val Acc: 0.793814\n",
      "Epoch 25252 - Train Loss: 0.069747, Train Acc: 0.892308 | Val Loss: 0.104996, Val Acc: 0.793814\n",
      "Epoch 25253 - Train Loss: 0.069746, Train Acc: 0.892308 | Val Loss: 0.104996, Val Acc: 0.793814\n",
      "Epoch 25254 - Train Loss: 0.069744, Train Acc: 0.892308 | Val Loss: 0.104996, Val Acc: 0.793814\n",
      "Epoch 25255 - Train Loss: 0.069743, Train Acc: 0.892308 | Val Loss: 0.104996, Val Acc: 0.793814\n",
      "Epoch 25256 - Train Loss: 0.069742, Train Acc: 0.892308 | Val Loss: 0.104996, Val Acc: 0.793814\n",
      "Epoch 25257 - Train Loss: 0.069740, Train Acc: 0.892308 | Val Loss: 0.104995, Val Acc: 0.793814\n",
      "Epoch 25258 - Train Loss: 0.069739, Train Acc: 0.892308 | Val Loss: 0.104995, Val Acc: 0.793814\n",
      "Epoch 25259 - Train Loss: 0.069738, Train Acc: 0.892308 | Val Loss: 0.104995, Val Acc: 0.793814\n",
      "Epoch 25260 - Train Loss: 0.069736, Train Acc: 0.892308 | Val Loss: 0.104995, Val Acc: 0.793814\n",
      "Epoch 25261 - Train Loss: 0.069735, Train Acc: 0.892308 | Val Loss: 0.104995, Val Acc: 0.793814\n",
      "Epoch 25262 - Train Loss: 0.069733, Train Acc: 0.892308 | Val Loss: 0.104994, Val Acc: 0.793814\n",
      "Epoch 25263 - Train Loss: 0.069732, Train Acc: 0.892308 | Val Loss: 0.104994, Val Acc: 0.793814\n",
      "Epoch 25264 - Train Loss: 0.069731, Train Acc: 0.892308 | Val Loss: 0.104994, Val Acc: 0.793814\n",
      "Epoch 25265 - Train Loss: 0.069729, Train Acc: 0.892308 | Val Loss: 0.104994, Val Acc: 0.793814\n",
      "Epoch 25266 - Train Loss: 0.069728, Train Acc: 0.892308 | Val Loss: 0.104994, Val Acc: 0.793814\n",
      "Epoch 25267 - Train Loss: 0.069727, Train Acc: 0.892308 | Val Loss: 0.104993, Val Acc: 0.793814\n",
      "Epoch 25268 - Train Loss: 0.069725, Train Acc: 0.892308 | Val Loss: 0.104993, Val Acc: 0.793814\n",
      "Epoch 25269 - Train Loss: 0.069724, Train Acc: 0.892308 | Val Loss: 0.104993, Val Acc: 0.793814\n",
      "Epoch 25270 - Train Loss: 0.069723, Train Acc: 0.892308 | Val Loss: 0.104993, Val Acc: 0.793814\n",
      "Epoch 25271 - Train Loss: 0.069721, Train Acc: 0.892308 | Val Loss: 0.104993, Val Acc: 0.793814\n",
      "Epoch 25272 - Train Loss: 0.069720, Train Acc: 0.892308 | Val Loss: 0.104992, Val Acc: 0.793814\n",
      "Epoch 25273 - Train Loss: 0.069718, Train Acc: 0.892308 | Val Loss: 0.104992, Val Acc: 0.793814\n",
      "Epoch 25274 - Train Loss: 0.069717, Train Acc: 0.892308 | Val Loss: 0.104992, Val Acc: 0.793814\n",
      "Epoch 25275 - Train Loss: 0.069716, Train Acc: 0.892308 | Val Loss: 0.104992, Val Acc: 0.793814\n",
      "Epoch 25276 - Train Loss: 0.069714, Train Acc: 0.892308 | Val Loss: 0.104992, Val Acc: 0.793814\n",
      "Epoch 25277 - Train Loss: 0.069713, Train Acc: 0.892308 | Val Loss: 0.104992, Val Acc: 0.793814\n",
      "Epoch 25278 - Train Loss: 0.069712, Train Acc: 0.892308 | Val Loss: 0.104991, Val Acc: 0.793814\n",
      "Epoch 25279 - Train Loss: 0.069710, Train Acc: 0.892308 | Val Loss: 0.104991, Val Acc: 0.793814\n",
      "Epoch 25280 - Train Loss: 0.069709, Train Acc: 0.892308 | Val Loss: 0.104991, Val Acc: 0.793814\n",
      "Epoch 25281 - Train Loss: 0.069707, Train Acc: 0.892308 | Val Loss: 0.104991, Val Acc: 0.793814\n",
      "Epoch 25282 - Train Loss: 0.069706, Train Acc: 0.892308 | Val Loss: 0.104991, Val Acc: 0.793814\n",
      "Epoch 25283 - Train Loss: 0.069705, Train Acc: 0.892308 | Val Loss: 0.104990, Val Acc: 0.793814\n",
      "Epoch 25284 - Train Loss: 0.069703, Train Acc: 0.892308 | Val Loss: 0.104990, Val Acc: 0.793814\n",
      "Epoch 25285 - Train Loss: 0.069702, Train Acc: 0.892308 | Val Loss: 0.104990, Val Acc: 0.793814\n",
      "Epoch 25286 - Train Loss: 0.069701, Train Acc: 0.892308 | Val Loss: 0.104990, Val Acc: 0.793814\n",
      "Epoch 25287 - Train Loss: 0.069699, Train Acc: 0.892308 | Val Loss: 0.104990, Val Acc: 0.793814\n",
      "Epoch 25288 - Train Loss: 0.069698, Train Acc: 0.892308 | Val Loss: 0.104990, Val Acc: 0.793814\n",
      "Epoch 25289 - Train Loss: 0.069696, Train Acc: 0.892308 | Val Loss: 0.104989, Val Acc: 0.793814\n",
      "Epoch 25290 - Train Loss: 0.069695, Train Acc: 0.892308 | Val Loss: 0.104989, Val Acc: 0.793814\n",
      "Epoch 25291 - Train Loss: 0.069694, Train Acc: 0.892308 | Val Loss: 0.104989, Val Acc: 0.793814\n",
      "Epoch 25292 - Train Loss: 0.069692, Train Acc: 0.892308 | Val Loss: 0.104989, Val Acc: 0.793814\n",
      "Epoch 25293 - Train Loss: 0.069691, Train Acc: 0.892308 | Val Loss: 0.104989, Val Acc: 0.793814\n",
      "Epoch 25294 - Train Loss: 0.069690, Train Acc: 0.892308 | Val Loss: 0.104988, Val Acc: 0.793814\n",
      "Epoch 25295 - Train Loss: 0.069688, Train Acc: 0.892308 | Val Loss: 0.104988, Val Acc: 0.793814\n",
      "Epoch 25296 - Train Loss: 0.069687, Train Acc: 0.892308 | Val Loss: 0.104988, Val Acc: 0.793814\n",
      "Epoch 25297 - Train Loss: 0.069686, Train Acc: 0.892308 | Val Loss: 0.104988, Val Acc: 0.793814\n",
      "Epoch 25298 - Train Loss: 0.069684, Train Acc: 0.892308 | Val Loss: 0.104988, Val Acc: 0.793814\n",
      "Epoch 25299 - Train Loss: 0.069683, Train Acc: 0.892308 | Val Loss: 0.104988, Val Acc: 0.793814\n",
      "Epoch 25300 - Train Loss: 0.069681, Train Acc: 0.892308 | Val Loss: 0.104987, Val Acc: 0.793814\n",
      "Epoch 25301 - Train Loss: 0.069680, Train Acc: 0.892308 | Val Loss: 0.104987, Val Acc: 0.793814\n",
      "Epoch 25302 - Train Loss: 0.069679, Train Acc: 0.892308 | Val Loss: 0.104987, Val Acc: 0.793814\n",
      "Epoch 25303 - Train Loss: 0.069677, Train Acc: 0.892308 | Val Loss: 0.104987, Val Acc: 0.793814\n",
      "Epoch 25304 - Train Loss: 0.069676, Train Acc: 0.892308 | Val Loss: 0.104987, Val Acc: 0.793814\n",
      "Epoch 25305 - Train Loss: 0.069675, Train Acc: 0.892308 | Val Loss: 0.104986, Val Acc: 0.793814\n",
      "Epoch 25306 - Train Loss: 0.069673, Train Acc: 0.892308 | Val Loss: 0.104986, Val Acc: 0.793814\n",
      "Epoch 25307 - Train Loss: 0.069672, Train Acc: 0.892308 | Val Loss: 0.104986, Val Acc: 0.793814\n",
      "Epoch 25308 - Train Loss: 0.069671, Train Acc: 0.892308 | Val Loss: 0.104986, Val Acc: 0.793814\n",
      "Epoch 25309 - Train Loss: 0.069669, Train Acc: 0.892308 | Val Loss: 0.104986, Val Acc: 0.793814\n",
      "Epoch 25310 - Train Loss: 0.069668, Train Acc: 0.892308 | Val Loss: 0.104985, Val Acc: 0.793814\n",
      "Epoch 25311 - Train Loss: 0.069666, Train Acc: 0.892308 | Val Loss: 0.104985, Val Acc: 0.793814\n",
      "Epoch 25312 - Train Loss: 0.069665, Train Acc: 0.892308 | Val Loss: 0.104985, Val Acc: 0.793814\n",
      "Epoch 25313 - Train Loss: 0.069664, Train Acc: 0.892308 | Val Loss: 0.104985, Val Acc: 0.793814\n",
      "Epoch 25314 - Train Loss: 0.069662, Train Acc: 0.892308 | Val Loss: 0.104985, Val Acc: 0.793814\n",
      "Epoch 25315 - Train Loss: 0.069661, Train Acc: 0.892308 | Val Loss: 0.104985, Val Acc: 0.793814\n",
      "Epoch 25316 - Train Loss: 0.069660, Train Acc: 0.892308 | Val Loss: 0.104984, Val Acc: 0.793814\n",
      "Epoch 25317 - Train Loss: 0.069658, Train Acc: 0.892308 | Val Loss: 0.104984, Val Acc: 0.793814\n",
      "Epoch 25318 - Train Loss: 0.069657, Train Acc: 0.892308 | Val Loss: 0.104984, Val Acc: 0.793814\n",
      "Epoch 25319 - Train Loss: 0.069655, Train Acc: 0.892308 | Val Loss: 0.104984, Val Acc: 0.793814\n",
      "Epoch 25320 - Train Loss: 0.069654, Train Acc: 0.892308 | Val Loss: 0.104984, Val Acc: 0.793814\n",
      "Epoch 25321 - Train Loss: 0.069653, Train Acc: 0.892308 | Val Loss: 0.104984, Val Acc: 0.793814\n",
      "Epoch 25322 - Train Loss: 0.069651, Train Acc: 0.892308 | Val Loss: 0.104983, Val Acc: 0.793814\n",
      "Epoch 25323 - Train Loss: 0.069650, Train Acc: 0.892308 | Val Loss: 0.104983, Val Acc: 0.793814\n",
      "Epoch 25324 - Train Loss: 0.069649, Train Acc: 0.892308 | Val Loss: 0.104983, Val Acc: 0.793814\n",
      "Epoch 25325 - Train Loss: 0.069647, Train Acc: 0.892308 | Val Loss: 0.104983, Val Acc: 0.793814\n",
      "Epoch 25326 - Train Loss: 0.069646, Train Acc: 0.892308 | Val Loss: 0.104983, Val Acc: 0.793814\n",
      "Epoch 25327 - Train Loss: 0.069645, Train Acc: 0.892308 | Val Loss: 0.104982, Val Acc: 0.793814\n",
      "Epoch 25328 - Train Loss: 0.069643, Train Acc: 0.892308 | Val Loss: 0.104982, Val Acc: 0.793814\n",
      "Epoch 25329 - Train Loss: 0.069642, Train Acc: 0.892308 | Val Loss: 0.104982, Val Acc: 0.793814\n",
      "Epoch 25330 - Train Loss: 0.069640, Train Acc: 0.892308 | Val Loss: 0.104982, Val Acc: 0.793814\n",
      "Epoch 25331 - Train Loss: 0.069639, Train Acc: 0.892308 | Val Loss: 0.104982, Val Acc: 0.793814\n",
      "Epoch 25332 - Train Loss: 0.069638, Train Acc: 0.892308 | Val Loss: 0.104982, Val Acc: 0.793814\n",
      "Epoch 25333 - Train Loss: 0.069636, Train Acc: 0.892308 | Val Loss: 0.104981, Val Acc: 0.793814\n",
      "Epoch 25334 - Train Loss: 0.069635, Train Acc: 0.892308 | Val Loss: 0.104981, Val Acc: 0.793814\n",
      "Epoch 25335 - Train Loss: 0.069634, Train Acc: 0.892308 | Val Loss: 0.104981, Val Acc: 0.793814\n",
      "Epoch 25336 - Train Loss: 0.069632, Train Acc: 0.892308 | Val Loss: 0.104981, Val Acc: 0.793814\n",
      "Epoch 25337 - Train Loss: 0.069631, Train Acc: 0.892308 | Val Loss: 0.104981, Val Acc: 0.793814\n",
      "Epoch 25338 - Train Loss: 0.069630, Train Acc: 0.892308 | Val Loss: 0.104980, Val Acc: 0.793814\n",
      "Epoch 25339 - Train Loss: 0.069628, Train Acc: 0.892308 | Val Loss: 0.104980, Val Acc: 0.793814\n",
      "Epoch 25340 - Train Loss: 0.069627, Train Acc: 0.892308 | Val Loss: 0.104980, Val Acc: 0.793814\n",
      "Epoch 25341 - Train Loss: 0.069625, Train Acc: 0.892308 | Val Loss: 0.104980, Val Acc: 0.793814\n",
      "Epoch 25342 - Train Loss: 0.069624, Train Acc: 0.892308 | Val Loss: 0.104980, Val Acc: 0.793814\n",
      "Epoch 25343 - Train Loss: 0.069623, Train Acc: 0.892308 | Val Loss: 0.104980, Val Acc: 0.793814\n",
      "Epoch 25344 - Train Loss: 0.069621, Train Acc: 0.892308 | Val Loss: 0.104979, Val Acc: 0.793814\n",
      "Epoch 25345 - Train Loss: 0.069620, Train Acc: 0.892308 | Val Loss: 0.104979, Val Acc: 0.793814\n",
      "Epoch 25346 - Train Loss: 0.069619, Train Acc: 0.892308 | Val Loss: 0.104979, Val Acc: 0.793814\n",
      "Epoch 25347 - Train Loss: 0.069617, Train Acc: 0.892308 | Val Loss: 0.104979, Val Acc: 0.793814\n",
      "Epoch 25348 - Train Loss: 0.069616, Train Acc: 0.892308 | Val Loss: 0.104979, Val Acc: 0.793814\n",
      "Epoch 25349 - Train Loss: 0.069615, Train Acc: 0.892308 | Val Loss: 0.104979, Val Acc: 0.793814\n",
      "Epoch 25350 - Train Loss: 0.069613, Train Acc: 0.892308 | Val Loss: 0.104978, Val Acc: 0.793814\n",
      "Epoch 25351 - Train Loss: 0.069612, Train Acc: 0.892308 | Val Loss: 0.104978, Val Acc: 0.793814\n",
      "Epoch 25352 - Train Loss: 0.069610, Train Acc: 0.892308 | Val Loss: 0.104978, Val Acc: 0.793814\n",
      "Epoch 25353 - Train Loss: 0.069609, Train Acc: 0.892308 | Val Loss: 0.104978, Val Acc: 0.793814\n",
      "Epoch 25354 - Train Loss: 0.069608, Train Acc: 0.892308 | Val Loss: 0.104978, Val Acc: 0.793814\n",
      "Epoch 25355 - Train Loss: 0.069606, Train Acc: 0.892308 | Val Loss: 0.104977, Val Acc: 0.793814\n",
      "Epoch 25356 - Train Loss: 0.069605, Train Acc: 0.892308 | Val Loss: 0.104977, Val Acc: 0.793814\n",
      "Epoch 25357 - Train Loss: 0.069604, Train Acc: 0.892308 | Val Loss: 0.104977, Val Acc: 0.793814\n",
      "Epoch 25358 - Train Loss: 0.069602, Train Acc: 0.892308 | Val Loss: 0.104977, Val Acc: 0.793814\n",
      "Epoch 25359 - Train Loss: 0.069601, Train Acc: 0.892308 | Val Loss: 0.104977, Val Acc: 0.793814\n",
      "Epoch 25360 - Train Loss: 0.069600, Train Acc: 0.892308 | Val Loss: 0.104977, Val Acc: 0.793814\n",
      "Epoch 25361 - Train Loss: 0.069598, Train Acc: 0.892308 | Val Loss: 0.104976, Val Acc: 0.793814\n",
      "Epoch 25362 - Train Loss: 0.069597, Train Acc: 0.892308 | Val Loss: 0.104976, Val Acc: 0.793814\n",
      "Epoch 25363 - Train Loss: 0.069595, Train Acc: 0.892308 | Val Loss: 0.104976, Val Acc: 0.793814\n",
      "Epoch 25364 - Train Loss: 0.069594, Train Acc: 0.892308 | Val Loss: 0.104976, Val Acc: 0.793814\n",
      "Epoch 25365 - Train Loss: 0.069593, Train Acc: 0.892308 | Val Loss: 0.104976, Val Acc: 0.793814\n",
      "Epoch 25366 - Train Loss: 0.069591, Train Acc: 0.892308 | Val Loss: 0.104975, Val Acc: 0.793814\n",
      "Epoch 25367 - Train Loss: 0.069590, Train Acc: 0.892308 | Val Loss: 0.104975, Val Acc: 0.793814\n",
      "Epoch 25368 - Train Loss: 0.069589, Train Acc: 0.892308 | Val Loss: 0.104975, Val Acc: 0.793814\n",
      "Epoch 25369 - Train Loss: 0.069587, Train Acc: 0.892308 | Val Loss: 0.104975, Val Acc: 0.793814\n",
      "Epoch 25370 - Train Loss: 0.069586, Train Acc: 0.892308 | Val Loss: 0.104975, Val Acc: 0.793814\n",
      "Epoch 25371 - Train Loss: 0.069585, Train Acc: 0.892308 | Val Loss: 0.104975, Val Acc: 0.793814\n",
      "Epoch 25372 - Train Loss: 0.069583, Train Acc: 0.892308 | Val Loss: 0.104974, Val Acc: 0.793814\n",
      "Epoch 25373 - Train Loss: 0.069582, Train Acc: 0.892308 | Val Loss: 0.104974, Val Acc: 0.793814\n",
      "Epoch 25374 - Train Loss: 0.069581, Train Acc: 0.892308 | Val Loss: 0.104974, Val Acc: 0.793814\n",
      "Epoch 25375 - Train Loss: 0.069579, Train Acc: 0.892308 | Val Loss: 0.104974, Val Acc: 0.793814\n",
      "Epoch 25376 - Train Loss: 0.069578, Train Acc: 0.892308 | Val Loss: 0.104974, Val Acc: 0.793814\n",
      "Epoch 25377 - Train Loss: 0.069576, Train Acc: 0.892308 | Val Loss: 0.104974, Val Acc: 0.793814\n",
      "Epoch 25378 - Train Loss: 0.069575, Train Acc: 0.892308 | Val Loss: 0.104973, Val Acc: 0.793814\n",
      "Epoch 25379 - Train Loss: 0.069574, Train Acc: 0.892308 | Val Loss: 0.104973, Val Acc: 0.793814\n",
      "Epoch 25380 - Train Loss: 0.069572, Train Acc: 0.892308 | Val Loss: 0.104973, Val Acc: 0.793814\n",
      "Epoch 25381 - Train Loss: 0.069571, Train Acc: 0.892308 | Val Loss: 0.104973, Val Acc: 0.793814\n",
      "Epoch 25382 - Train Loss: 0.069570, Train Acc: 0.892308 | Val Loss: 0.104973, Val Acc: 0.793814\n",
      "Epoch 25383 - Train Loss: 0.069568, Train Acc: 0.892308 | Val Loss: 0.104973, Val Acc: 0.793814\n",
      "Epoch 25384 - Train Loss: 0.069567, Train Acc: 0.892308 | Val Loss: 0.104972, Val Acc: 0.793814\n",
      "Epoch 25385 - Train Loss: 0.069566, Train Acc: 0.892308 | Val Loss: 0.104972, Val Acc: 0.793814\n",
      "Epoch 25386 - Train Loss: 0.069564, Train Acc: 0.892308 | Val Loss: 0.104972, Val Acc: 0.793814\n",
      "Epoch 25387 - Train Loss: 0.069563, Train Acc: 0.892308 | Val Loss: 0.104972, Val Acc: 0.793814\n",
      "Epoch 25388 - Train Loss: 0.069561, Train Acc: 0.892308 | Val Loss: 0.104972, Val Acc: 0.793814\n",
      "Epoch 25389 - Train Loss: 0.069560, Train Acc: 0.892308 | Val Loss: 0.104971, Val Acc: 0.793814\n",
      "Epoch 25390 - Train Loss: 0.069559, Train Acc: 0.892308 | Val Loss: 0.104971, Val Acc: 0.793814\n",
      "Epoch 25391 - Train Loss: 0.069557, Train Acc: 0.892308 | Val Loss: 0.104971, Val Acc: 0.793814\n",
      "Epoch 25392 - Train Loss: 0.069556, Train Acc: 0.892308 | Val Loss: 0.104971, Val Acc: 0.793814\n",
      "Epoch 25393 - Train Loss: 0.069555, Train Acc: 0.892308 | Val Loss: 0.104971, Val Acc: 0.793814\n",
      "Epoch 25394 - Train Loss: 0.069553, Train Acc: 0.892308 | Val Loss: 0.104971, Val Acc: 0.793814\n",
      "Epoch 25395 - Train Loss: 0.069552, Train Acc: 0.892308 | Val Loss: 0.104970, Val Acc: 0.793814\n",
      "Epoch 25396 - Train Loss: 0.069551, Train Acc: 0.892308 | Val Loss: 0.104970, Val Acc: 0.793814\n",
      "Epoch 25397 - Train Loss: 0.069549, Train Acc: 0.892308 | Val Loss: 0.104970, Val Acc: 0.793814\n",
      "Epoch 25398 - Train Loss: 0.069548, Train Acc: 0.892308 | Val Loss: 0.104970, Val Acc: 0.793814\n",
      "Epoch 25399 - Train Loss: 0.069547, Train Acc: 0.892308 | Val Loss: 0.104970, Val Acc: 0.793814\n",
      "Epoch 25400 - Train Loss: 0.069545, Train Acc: 0.892308 | Val Loss: 0.104970, Val Acc: 0.793814\n",
      "Epoch 25401 - Train Loss: 0.069544, Train Acc: 0.892308 | Val Loss: 0.104969, Val Acc: 0.793814\n",
      "Epoch 25402 - Train Loss: 0.069542, Train Acc: 0.892308 | Val Loss: 0.104969, Val Acc: 0.793814\n",
      "Epoch 25403 - Train Loss: 0.069541, Train Acc: 0.892308 | Val Loss: 0.104969, Val Acc: 0.793814\n",
      "Epoch 25404 - Train Loss: 0.069540, Train Acc: 0.892308 | Val Loss: 0.104969, Val Acc: 0.793814\n",
      "Epoch 25405 - Train Loss: 0.069538, Train Acc: 0.892308 | Val Loss: 0.104969, Val Acc: 0.793814\n",
      "Epoch 25406 - Train Loss: 0.069537, Train Acc: 0.892308 | Val Loss: 0.104968, Val Acc: 0.793814\n",
      "Epoch 25407 - Train Loss: 0.069536, Train Acc: 0.892308 | Val Loss: 0.104968, Val Acc: 0.793814\n",
      "Epoch 25408 - Train Loss: 0.069534, Train Acc: 0.892308 | Val Loss: 0.104968, Val Acc: 0.793814\n",
      "Epoch 25409 - Train Loss: 0.069533, Train Acc: 0.892308 | Val Loss: 0.104968, Val Acc: 0.793814\n",
      "Epoch 25410 - Train Loss: 0.069532, Train Acc: 0.892308 | Val Loss: 0.104968, Val Acc: 0.793814\n",
      "Epoch 25411 - Train Loss: 0.069530, Train Acc: 0.892308 | Val Loss: 0.104968, Val Acc: 0.793814\n",
      "Epoch 25412 - Train Loss: 0.069529, Train Acc: 0.892308 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 25413 - Train Loss: 0.069528, Train Acc: 0.892308 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 25414 - Train Loss: 0.069526, Train Acc: 0.892308 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 25415 - Train Loss: 0.069525, Train Acc: 0.892308 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 25416 - Train Loss: 0.069523, Train Acc: 0.892308 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 25417 - Train Loss: 0.069522, Train Acc: 0.892308 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 25418 - Train Loss: 0.069521, Train Acc: 0.892308 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 25419 - Train Loss: 0.069519, Train Acc: 0.892308 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 25420 - Train Loss: 0.069518, Train Acc: 0.892308 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 25421 - Train Loss: 0.069517, Train Acc: 0.892308 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 25422 - Train Loss: 0.069515, Train Acc: 0.892308 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 25423 - Train Loss: 0.069514, Train Acc: 0.892308 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 25424 - Train Loss: 0.069513, Train Acc: 0.892308 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 25425 - Train Loss: 0.069511, Train Acc: 0.892308 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 25426 - Train Loss: 0.069510, Train Acc: 0.892308 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 25427 - Train Loss: 0.069509, Train Acc: 0.892308 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 25428 - Train Loss: 0.069507, Train Acc: 0.892308 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 25429 - Train Loss: 0.069506, Train Acc: 0.892308 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 25430 - Train Loss: 0.069504, Train Acc: 0.892308 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 25431 - Train Loss: 0.069503, Train Acc: 0.892308 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 25432 - Train Loss: 0.069502, Train Acc: 0.892308 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 25433 - Train Loss: 0.069500, Train Acc: 0.892308 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 25434 - Train Loss: 0.069499, Train Acc: 0.892308 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 25435 - Train Loss: 0.069498, Train Acc: 0.892308 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 25436 - Train Loss: 0.069496, Train Acc: 0.892308 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 25437 - Train Loss: 0.069495, Train Acc: 0.892308 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 25438 - Train Loss: 0.069494, Train Acc: 0.892308 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 25439 - Train Loss: 0.069492, Train Acc: 0.892308 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 25440 - Train Loss: 0.069491, Train Acc: 0.892308 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 25441 - Train Loss: 0.069490, Train Acc: 0.892308 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 25442 - Train Loss: 0.069488, Train Acc: 0.892308 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 25443 - Train Loss: 0.069487, Train Acc: 0.892308 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 25444 - Train Loss: 0.069486, Train Acc: 0.892308 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 25445 - Train Loss: 0.069484, Train Acc: 0.892308 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 25446 - Train Loss: 0.069483, Train Acc: 0.892308 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 25447 - Train Loss: 0.069481, Train Acc: 0.892308 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 25448 - Train Loss: 0.069480, Train Acc: 0.892308 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 25449 - Train Loss: 0.069479, Train Acc: 0.892308 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 25450 - Train Loss: 0.069477, Train Acc: 0.892308 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 25451 - Train Loss: 0.069476, Train Acc: 0.892308 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 25452 - Train Loss: 0.069475, Train Acc: 0.892308 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 25453 - Train Loss: 0.069473, Train Acc: 0.892308 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 25454 - Train Loss: 0.069472, Train Acc: 0.892308 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 25455 - Train Loss: 0.069471, Train Acc: 0.892308 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 25456 - Train Loss: 0.069469, Train Acc: 0.892308 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 25457 - Train Loss: 0.069468, Train Acc: 0.892308 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 25458 - Train Loss: 0.069467, Train Acc: 0.892308 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 25459 - Train Loss: 0.069465, Train Acc: 0.892308 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 25460 - Train Loss: 0.069464, Train Acc: 0.892308 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 25461 - Train Loss: 0.069463, Train Acc: 0.892308 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 25462 - Train Loss: 0.069461, Train Acc: 0.892308 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 25463 - Train Loss: 0.069460, Train Acc: 0.892308 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 25464 - Train Loss: 0.069458, Train Acc: 0.892308 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 25465 - Train Loss: 0.069457, Train Acc: 0.892308 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 25466 - Train Loss: 0.069456, Train Acc: 0.892308 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 25467 - Train Loss: 0.069454, Train Acc: 0.892308 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 25468 - Train Loss: 0.069453, Train Acc: 0.892308 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 25469 - Train Loss: 0.069452, Train Acc: 0.892308 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 25470 - Train Loss: 0.069450, Train Acc: 0.892308 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 25471 - Train Loss: 0.069449, Train Acc: 0.892308 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 25472 - Train Loss: 0.069448, Train Acc: 0.892308 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 25473 - Train Loss: 0.069446, Train Acc: 0.892308 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 25474 - Train Loss: 0.069445, Train Acc: 0.892308 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 25475 - Train Loss: 0.069444, Train Acc: 0.892308 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 25476 - Train Loss: 0.069442, Train Acc: 0.892308 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 25477 - Train Loss: 0.069441, Train Acc: 0.892308 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 25478 - Train Loss: 0.069440, Train Acc: 0.892308 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 25479 - Train Loss: 0.069438, Train Acc: 0.892308 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 25480 - Train Loss: 0.069437, Train Acc: 0.892308 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 25481 - Train Loss: 0.069435, Train Acc: 0.892308 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 25482 - Train Loss: 0.069434, Train Acc: 0.892308 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 25483 - Train Loss: 0.069433, Train Acc: 0.892308 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 25484 - Train Loss: 0.069431, Train Acc: 0.892308 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 25485 - Train Loss: 0.069430, Train Acc: 0.892308 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 25486 - Train Loss: 0.069429, Train Acc: 0.892308 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 25487 - Train Loss: 0.069427, Train Acc: 0.892308 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 25488 - Train Loss: 0.069426, Train Acc: 0.892308 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 25489 - Train Loss: 0.069425, Train Acc: 0.892308 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 25490 - Train Loss: 0.069423, Train Acc: 0.892308 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 25491 - Train Loss: 0.069422, Train Acc: 0.892308 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 25492 - Train Loss: 0.069421, Train Acc: 0.892308 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 25493 - Train Loss: 0.069419, Train Acc: 0.892308 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 25494 - Train Loss: 0.069418, Train Acc: 0.892308 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 25495 - Train Loss: 0.069417, Train Acc: 0.892308 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 25496 - Train Loss: 0.069415, Train Acc: 0.892308 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 25497 - Train Loss: 0.069414, Train Acc: 0.892308 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 25498 - Train Loss: 0.069413, Train Acc: 0.892308 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 25499 - Train Loss: 0.069411, Train Acc: 0.892308 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 25500 - Train Loss: 0.069410, Train Acc: 0.892308 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 25501 - Train Loss: 0.069408, Train Acc: 0.892308 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 25502 - Train Loss: 0.069407, Train Acc: 0.892308 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 25503 - Train Loss: 0.069406, Train Acc: 0.892308 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 25504 - Train Loss: 0.069404, Train Acc: 0.892308 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 25505 - Train Loss: 0.069403, Train Acc: 0.892308 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 25506 - Train Loss: 0.069402, Train Acc: 0.892308 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 25507 - Train Loss: 0.069400, Train Acc: 0.892308 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 25508 - Train Loss: 0.069399, Train Acc: 0.892308 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 25509 - Train Loss: 0.069398, Train Acc: 0.892308 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 25510 - Train Loss: 0.069396, Train Acc: 0.892308 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 25511 - Train Loss: 0.069395, Train Acc: 0.892308 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 25512 - Train Loss: 0.069394, Train Acc: 0.892308 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 25513 - Train Loss: 0.069392, Train Acc: 0.892308 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 25514 - Train Loss: 0.069391, Train Acc: 0.892308 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 25515 - Train Loss: 0.069390, Train Acc: 0.892308 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 25516 - Train Loss: 0.069388, Train Acc: 0.892308 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 25517 - Train Loss: 0.069387, Train Acc: 0.892308 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 25518 - Train Loss: 0.069386, Train Acc: 0.892308 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 25519 - Train Loss: 0.069384, Train Acc: 0.892308 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 25520 - Train Loss: 0.069383, Train Acc: 0.892308 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 25521 - Train Loss: 0.069382, Train Acc: 0.892308 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 25522 - Train Loss: 0.069380, Train Acc: 0.892308 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 25523 - Train Loss: 0.069379, Train Acc: 0.892308 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 25524 - Train Loss: 0.069377, Train Acc: 0.892308 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 25525 - Train Loss: 0.069376, Train Acc: 0.892308 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 25526 - Train Loss: 0.069375, Train Acc: 0.892308 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 25527 - Train Loss: 0.069373, Train Acc: 0.892308 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 25528 - Train Loss: 0.069372, Train Acc: 0.892308 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 25529 - Train Loss: 0.069371, Train Acc: 0.892308 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 25530 - Train Loss: 0.069369, Train Acc: 0.892308 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 25531 - Train Loss: 0.069368, Train Acc: 0.892308 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 25532 - Train Loss: 0.069367, Train Acc: 0.892308 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 25533 - Train Loss: 0.069365, Train Acc: 0.892308 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 25534 - Train Loss: 0.069364, Train Acc: 0.892308 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 25535 - Train Loss: 0.069363, Train Acc: 0.892308 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 25536 - Train Loss: 0.069361, Train Acc: 0.892308 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 25537 - Train Loss: 0.069360, Train Acc: 0.892308 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 25538 - Train Loss: 0.069359, Train Acc: 0.892308 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 25539 - Train Loss: 0.069357, Train Acc: 0.892308 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 25540 - Train Loss: 0.069356, Train Acc: 0.892308 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 25541 - Train Loss: 0.069355, Train Acc: 0.892308 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 25542 - Train Loss: 0.069353, Train Acc: 0.892308 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 25543 - Train Loss: 0.069352, Train Acc: 0.892308 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 25544 - Train Loss: 0.069351, Train Acc: 0.892308 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 25545 - Train Loss: 0.069349, Train Acc: 0.892308 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 25546 - Train Loss: 0.069348, Train Acc: 0.893590 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 25547 - Train Loss: 0.069347, Train Acc: 0.893590 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 25548 - Train Loss: 0.069345, Train Acc: 0.893590 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 25549 - Train Loss: 0.069344, Train Acc: 0.893590 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 25550 - Train Loss: 0.069342, Train Acc: 0.893590 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 25551 - Train Loss: 0.069341, Train Acc: 0.893590 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 25552 - Train Loss: 0.069340, Train Acc: 0.893590 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 25553 - Train Loss: 0.069338, Train Acc: 0.893590 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 25554 - Train Loss: 0.069337, Train Acc: 0.893590 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 25555 - Train Loss: 0.069336, Train Acc: 0.893590 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 25556 - Train Loss: 0.069334, Train Acc: 0.893590 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 25557 - Train Loss: 0.069333, Train Acc: 0.893590 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 25558 - Train Loss: 0.069332, Train Acc: 0.893590 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 25559 - Train Loss: 0.069330, Train Acc: 0.893590 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 25560 - Train Loss: 0.069329, Train Acc: 0.893590 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 25561 - Train Loss: 0.069328, Train Acc: 0.893590 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 25562 - Train Loss: 0.069326, Train Acc: 0.893590 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 25563 - Train Loss: 0.069325, Train Acc: 0.893590 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 25564 - Train Loss: 0.069324, Train Acc: 0.893590 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 25565 - Train Loss: 0.069322, Train Acc: 0.893590 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 25566 - Train Loss: 0.069321, Train Acc: 0.893590 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 25567 - Train Loss: 0.069320, Train Acc: 0.893590 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 25568 - Train Loss: 0.069318, Train Acc: 0.893590 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 25569 - Train Loss: 0.069317, Train Acc: 0.893590 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 25570 - Train Loss: 0.069316, Train Acc: 0.893590 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 25571 - Train Loss: 0.069314, Train Acc: 0.893590 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 25572 - Train Loss: 0.069313, Train Acc: 0.893590 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 25573 - Train Loss: 0.069312, Train Acc: 0.893590 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 25574 - Train Loss: 0.069310, Train Acc: 0.893590 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 25575 - Train Loss: 0.069309, Train Acc: 0.893590 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 25576 - Train Loss: 0.069308, Train Acc: 0.893590 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 25577 - Train Loss: 0.069306, Train Acc: 0.893590 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 25578 - Train Loss: 0.069305, Train Acc: 0.893590 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 25579 - Train Loss: 0.069304, Train Acc: 0.893590 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 25580 - Train Loss: 0.069302, Train Acc: 0.893590 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 25581 - Train Loss: 0.069301, Train Acc: 0.893590 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 25582 - Train Loss: 0.069300, Train Acc: 0.893590 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 25583 - Train Loss: 0.069298, Train Acc: 0.893590 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 25584 - Train Loss: 0.069297, Train Acc: 0.893590 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 25585 - Train Loss: 0.069296, Train Acc: 0.893590 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 25586 - Train Loss: 0.069294, Train Acc: 0.893590 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 25587 - Train Loss: 0.069293, Train Acc: 0.893590 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 25588 - Train Loss: 0.069291, Train Acc: 0.893590 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 25589 - Train Loss: 0.069290, Train Acc: 0.893590 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 25590 - Train Loss: 0.069289, Train Acc: 0.893590 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 25591 - Train Loss: 0.069287, Train Acc: 0.893590 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 25592 - Train Loss: 0.069286, Train Acc: 0.893590 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 25593 - Train Loss: 0.069285, Train Acc: 0.893590 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 25594 - Train Loss: 0.069283, Train Acc: 0.893590 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 25595 - Train Loss: 0.069282, Train Acc: 0.893590 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 25596 - Train Loss: 0.069281, Train Acc: 0.893590 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 25597 - Train Loss: 0.069279, Train Acc: 0.893590 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 25598 - Train Loss: 0.069278, Train Acc: 0.893590 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 25599 - Train Loss: 0.069277, Train Acc: 0.893590 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 25600 - Train Loss: 0.069275, Train Acc: 0.893590 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 25601 - Train Loss: 0.069274, Train Acc: 0.893590 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 25602 - Train Loss: 0.069273, Train Acc: 0.893590 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 25603 - Train Loss: 0.069271, Train Acc: 0.893590 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 25604 - Train Loss: 0.069270, Train Acc: 0.893590 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 25605 - Train Loss: 0.069269, Train Acc: 0.893590 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 25606 - Train Loss: 0.069267, Train Acc: 0.893590 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 25607 - Train Loss: 0.069266, Train Acc: 0.893590 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 25608 - Train Loss: 0.069265, Train Acc: 0.893590 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 25609 - Train Loss: 0.069263, Train Acc: 0.893590 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 25610 - Train Loss: 0.069262, Train Acc: 0.893590 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 25611 - Train Loss: 0.069261, Train Acc: 0.893590 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 25612 - Train Loss: 0.069259, Train Acc: 0.893590 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 25613 - Train Loss: 0.069258, Train Acc: 0.893590 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 25614 - Train Loss: 0.069257, Train Acc: 0.893590 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 25615 - Train Loss: 0.069255, Train Acc: 0.893590 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 25616 - Train Loss: 0.069254, Train Acc: 0.893590 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 25617 - Train Loss: 0.069253, Train Acc: 0.893590 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 25618 - Train Loss: 0.069251, Train Acc: 0.893590 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 25619 - Train Loss: 0.069250, Train Acc: 0.893590 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 25620 - Train Loss: 0.069249, Train Acc: 0.893590 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 25621 - Train Loss: 0.069247, Train Acc: 0.893590 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 25622 - Train Loss: 0.069246, Train Acc: 0.893590 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 25623 - Train Loss: 0.069245, Train Acc: 0.893590 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 25624 - Train Loss: 0.069243, Train Acc: 0.893590 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 25625 - Train Loss: 0.069242, Train Acc: 0.893590 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 25626 - Train Loss: 0.069241, Train Acc: 0.893590 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 25627 - Train Loss: 0.069239, Train Acc: 0.893590 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 25628 - Train Loss: 0.069238, Train Acc: 0.893590 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 25629 - Train Loss: 0.069237, Train Acc: 0.893590 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 25630 - Train Loss: 0.069235, Train Acc: 0.893590 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 25631 - Train Loss: 0.069234, Train Acc: 0.893590 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 25632 - Train Loss: 0.069233, Train Acc: 0.893590 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 25633 - Train Loss: 0.069231, Train Acc: 0.893590 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 25634 - Train Loss: 0.069230, Train Acc: 0.893590 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 25635 - Train Loss: 0.069229, Train Acc: 0.893590 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 25636 - Train Loss: 0.069227, Train Acc: 0.893590 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 25637 - Train Loss: 0.069226, Train Acc: 0.893590 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 25638 - Train Loss: 0.069225, Train Acc: 0.893590 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 25639 - Train Loss: 0.069223, Train Acc: 0.893590 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 25640 - Train Loss: 0.069222, Train Acc: 0.893590 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 25641 - Train Loss: 0.069221, Train Acc: 0.893590 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 25642 - Train Loss: 0.069219, Train Acc: 0.893590 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 25643 - Train Loss: 0.069218, Train Acc: 0.893590 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 25644 - Train Loss: 0.069217, Train Acc: 0.893590 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 25645 - Train Loss: 0.069215, Train Acc: 0.893590 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 25646 - Train Loss: 0.069214, Train Acc: 0.893590 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 25647 - Train Loss: 0.069213, Train Acc: 0.893590 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 25648 - Train Loss: 0.069211, Train Acc: 0.893590 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 25649 - Train Loss: 0.069210, Train Acc: 0.893590 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 25650 - Train Loss: 0.069209, Train Acc: 0.893590 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 25651 - Train Loss: 0.069207, Train Acc: 0.893590 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 25652 - Train Loss: 0.069206, Train Acc: 0.893590 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 25653 - Train Loss: 0.069205, Train Acc: 0.893590 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 25654 - Train Loss: 0.069203, Train Acc: 0.893590 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 25655 - Train Loss: 0.069202, Train Acc: 0.893590 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 25656 - Train Loss: 0.069201, Train Acc: 0.893590 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 25657 - Train Loss: 0.069199, Train Acc: 0.893590 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 25658 - Train Loss: 0.069198, Train Acc: 0.893590 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 25659 - Train Loss: 0.069197, Train Acc: 0.893590 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 25660 - Train Loss: 0.069195, Train Acc: 0.893590 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 25661 - Train Loss: 0.069194, Train Acc: 0.893590 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 25662 - Train Loss: 0.069193, Train Acc: 0.893590 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 25663 - Train Loss: 0.069191, Train Acc: 0.893590 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 25664 - Train Loss: 0.069190, Train Acc: 0.893590 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 25665 - Train Loss: 0.069189, Train Acc: 0.893590 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 25666 - Train Loss: 0.069187, Train Acc: 0.893590 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 25667 - Train Loss: 0.069186, Train Acc: 0.893590 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 25668 - Train Loss: 0.069185, Train Acc: 0.893590 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 25669 - Train Loss: 0.069183, Train Acc: 0.893590 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 25670 - Train Loss: 0.069182, Train Acc: 0.893590 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 25671 - Train Loss: 0.069181, Train Acc: 0.893590 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 25672 - Train Loss: 0.069179, Train Acc: 0.893590 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 25673 - Train Loss: 0.069178, Train Acc: 0.893590 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 25674 - Train Loss: 0.069177, Train Acc: 0.893590 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 25675 - Train Loss: 0.069175, Train Acc: 0.893590 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 25676 - Train Loss: 0.069174, Train Acc: 0.893590 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 25677 - Train Loss: 0.069173, Train Acc: 0.893590 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 25678 - Train Loss: 0.069171, Train Acc: 0.893590 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 25679 - Train Loss: 0.069170, Train Acc: 0.893590 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 25680 - Train Loss: 0.069169, Train Acc: 0.893590 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 25681 - Train Loss: 0.069167, Train Acc: 0.893590 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 25682 - Train Loss: 0.069166, Train Acc: 0.893590 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 25683 - Train Loss: 0.069165, Train Acc: 0.893590 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 25684 - Train Loss: 0.069163, Train Acc: 0.893590 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 25685 - Train Loss: 0.069162, Train Acc: 0.893590 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 25686 - Train Loss: 0.069161, Train Acc: 0.893590 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 25687 - Train Loss: 0.069159, Train Acc: 0.893590 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 25688 - Train Loss: 0.069158, Train Acc: 0.893590 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 25689 - Train Loss: 0.069157, Train Acc: 0.893590 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 25690 - Train Loss: 0.069155, Train Acc: 0.893590 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 25691 - Train Loss: 0.069154, Train Acc: 0.893590 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 25692 - Train Loss: 0.069153, Train Acc: 0.893590 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 25693 - Train Loss: 0.069151, Train Acc: 0.893590 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 25694 - Train Loss: 0.069150, Train Acc: 0.893590 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 25695 - Train Loss: 0.069149, Train Acc: 0.893590 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 25696 - Train Loss: 0.069147, Train Acc: 0.893590 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 25697 - Train Loss: 0.069146, Train Acc: 0.893590 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 25698 - Train Loss: 0.069145, Train Acc: 0.893590 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 25699 - Train Loss: 0.069143, Train Acc: 0.893590 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 25700 - Train Loss: 0.069142, Train Acc: 0.893590 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 25701 - Train Loss: 0.069141, Train Acc: 0.893590 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 25702 - Train Loss: 0.069139, Train Acc: 0.893590 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 25703 - Train Loss: 0.069138, Train Acc: 0.893590 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 25704 - Train Loss: 0.069137, Train Acc: 0.893590 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 25705 - Train Loss: 0.069135, Train Acc: 0.893590 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 25706 - Train Loss: 0.069134, Train Acc: 0.893590 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 25707 - Train Loss: 0.069133, Train Acc: 0.893590 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 25708 - Train Loss: 0.069131, Train Acc: 0.893590 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 25709 - Train Loss: 0.069130, Train Acc: 0.893590 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 25710 - Train Loss: 0.069129, Train Acc: 0.893590 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 25711 - Train Loss: 0.069127, Train Acc: 0.893590 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 25712 - Train Loss: 0.069126, Train Acc: 0.893590 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 25713 - Train Loss: 0.069125, Train Acc: 0.893590 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 25714 - Train Loss: 0.069123, Train Acc: 0.893590 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 25715 - Train Loss: 0.069122, Train Acc: 0.893590 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 25716 - Train Loss: 0.069121, Train Acc: 0.893590 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 25717 - Train Loss: 0.069119, Train Acc: 0.893590 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 25718 - Train Loss: 0.069118, Train Acc: 0.893590 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 25719 - Train Loss: 0.069117, Train Acc: 0.893590 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 25720 - Train Loss: 0.069115, Train Acc: 0.893590 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 25721 - Train Loss: 0.069114, Train Acc: 0.893590 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 25722 - Train Loss: 0.069113, Train Acc: 0.893590 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 25723 - Train Loss: 0.069111, Train Acc: 0.893590 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 25724 - Train Loss: 0.069110, Train Acc: 0.893590 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 25725 - Train Loss: 0.069109, Train Acc: 0.893590 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 25726 - Train Loss: 0.069107, Train Acc: 0.893590 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 25727 - Train Loss: 0.069106, Train Acc: 0.893590 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 25728 - Train Loss: 0.069105, Train Acc: 0.893590 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 25729 - Train Loss: 0.069103, Train Acc: 0.893590 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 25730 - Train Loss: 0.069102, Train Acc: 0.893590 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 25731 - Train Loss: 0.069101, Train Acc: 0.893590 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 25732 - Train Loss: 0.069099, Train Acc: 0.893590 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 25733 - Train Loss: 0.069098, Train Acc: 0.893590 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 25734 - Train Loss: 0.069097, Train Acc: 0.893590 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 25735 - Train Loss: 0.069095, Train Acc: 0.893590 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 25736 - Train Loss: 0.069094, Train Acc: 0.893590 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 25737 - Train Loss: 0.069093, Train Acc: 0.893590 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 25738 - Train Loss: 0.069091, Train Acc: 0.893590 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 25739 - Train Loss: 0.069090, Train Acc: 0.893590 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 25740 - Train Loss: 0.069089, Train Acc: 0.893590 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 25741 - Train Loss: 0.069087, Train Acc: 0.893590 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 25742 - Train Loss: 0.069086, Train Acc: 0.893590 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 25743 - Train Loss: 0.069085, Train Acc: 0.893590 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 25744 - Train Loss: 0.069083, Train Acc: 0.893590 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 25745 - Train Loss: 0.069082, Train Acc: 0.893590 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 25746 - Train Loss: 0.069081, Train Acc: 0.893590 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 25747 - Train Loss: 0.069079, Train Acc: 0.893590 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 25748 - Train Loss: 0.069078, Train Acc: 0.893590 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 25749 - Train Loss: 0.069077, Train Acc: 0.893590 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 25750 - Train Loss: 0.069075, Train Acc: 0.893590 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 25751 - Train Loss: 0.069074, Train Acc: 0.893590 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 25752 - Train Loss: 0.069073, Train Acc: 0.893590 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 25753 - Train Loss: 0.069071, Train Acc: 0.893590 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 25754 - Train Loss: 0.069070, Train Acc: 0.893590 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 25755 - Train Loss: 0.069069, Train Acc: 0.893590 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 25756 - Train Loss: 0.069067, Train Acc: 0.893590 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 25757 - Train Loss: 0.069066, Train Acc: 0.893590 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 25758 - Train Loss: 0.069065, Train Acc: 0.893590 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 25759 - Train Loss: 0.069064, Train Acc: 0.893590 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 25760 - Train Loss: 0.069062, Train Acc: 0.893590 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 25761 - Train Loss: 0.069061, Train Acc: 0.893590 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 25762 - Train Loss: 0.069060, Train Acc: 0.893590 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 25763 - Train Loss: 0.069058, Train Acc: 0.893590 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 25764 - Train Loss: 0.069057, Train Acc: 0.893590 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 25765 - Train Loss: 0.069056, Train Acc: 0.893590 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 25766 - Train Loss: 0.069054, Train Acc: 0.893590 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 25767 - Train Loss: 0.069053, Train Acc: 0.893590 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 25768 - Train Loss: 0.069052, Train Acc: 0.893590 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 25769 - Train Loss: 0.069050, Train Acc: 0.893590 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 25770 - Train Loss: 0.069049, Train Acc: 0.893590 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 25771 - Train Loss: 0.069048, Train Acc: 0.893590 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 25772 - Train Loss: 0.069046, Train Acc: 0.893590 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 25773 - Train Loss: 0.069045, Train Acc: 0.893590 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 25774 - Train Loss: 0.069044, Train Acc: 0.893590 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 25775 - Train Loss: 0.069042, Train Acc: 0.893590 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 25776 - Train Loss: 0.069041, Train Acc: 0.893590 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 25777 - Train Loss: 0.069040, Train Acc: 0.893590 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 25778 - Train Loss: 0.069038, Train Acc: 0.893590 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 25779 - Train Loss: 0.069037, Train Acc: 0.893590 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 25780 - Train Loss: 0.069036, Train Acc: 0.893590 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 25781 - Train Loss: 0.069034, Train Acc: 0.893590 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 25782 - Train Loss: 0.069033, Train Acc: 0.893590 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 25783 - Train Loss: 0.069032, Train Acc: 0.893590 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 25784 - Train Loss: 0.069030, Train Acc: 0.893590 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 25785 - Train Loss: 0.069029, Train Acc: 0.893590 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 25786 - Train Loss: 0.069028, Train Acc: 0.893590 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 25787 - Train Loss: 0.069026, Train Acc: 0.893590 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 25788 - Train Loss: 0.069025, Train Acc: 0.893590 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 25789 - Train Loss: 0.069024, Train Acc: 0.893590 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 25790 - Train Loss: 0.069022, Train Acc: 0.893590 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 25791 - Train Loss: 0.069021, Train Acc: 0.893590 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 25792 - Train Loss: 0.069020, Train Acc: 0.893590 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 25793 - Train Loss: 0.069018, Train Acc: 0.893590 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 25794 - Train Loss: 0.069017, Train Acc: 0.893590 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 25795 - Train Loss: 0.069016, Train Acc: 0.893590 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 25796 - Train Loss: 0.069015, Train Acc: 0.893590 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 25797 - Train Loss: 0.069013, Train Acc: 0.893590 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 25798 - Train Loss: 0.069012, Train Acc: 0.893590 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 25799 - Train Loss: 0.069011, Train Acc: 0.893590 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 25800 - Train Loss: 0.069009, Train Acc: 0.893590 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 25801 - Train Loss: 0.069008, Train Acc: 0.893590 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 25802 - Train Loss: 0.069007, Train Acc: 0.893590 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 25803 - Train Loss: 0.069005, Train Acc: 0.893590 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 25804 - Train Loss: 0.069004, Train Acc: 0.893590 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 25805 - Train Loss: 0.069003, Train Acc: 0.893590 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 25806 - Train Loss: 0.069001, Train Acc: 0.893590 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 25807 - Train Loss: 0.069000, Train Acc: 0.893590 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 25808 - Train Loss: 0.068999, Train Acc: 0.893590 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 25809 - Train Loss: 0.068997, Train Acc: 0.893590 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 25810 - Train Loss: 0.068996, Train Acc: 0.893590 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 25811 - Train Loss: 0.068995, Train Acc: 0.893590 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 25812 - Train Loss: 0.068993, Train Acc: 0.893590 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 25813 - Train Loss: 0.068992, Train Acc: 0.893590 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 25814 - Train Loss: 0.068991, Train Acc: 0.893590 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 25815 - Train Loss: 0.068989, Train Acc: 0.893590 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 25816 - Train Loss: 0.068988, Train Acc: 0.893590 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 25817 - Train Loss: 0.068987, Train Acc: 0.893590 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 25818 - Train Loss: 0.068985, Train Acc: 0.893590 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 25819 - Train Loss: 0.068984, Train Acc: 0.893590 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 25820 - Train Loss: 0.068983, Train Acc: 0.893590 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 25821 - Train Loss: 0.068981, Train Acc: 0.893590 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 25822 - Train Loss: 0.068980, Train Acc: 0.893590 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 25823 - Train Loss: 0.068979, Train Acc: 0.893590 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 25824 - Train Loss: 0.068978, Train Acc: 0.893590 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 25825 - Train Loss: 0.068976, Train Acc: 0.893590 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 25826 - Train Loss: 0.068975, Train Acc: 0.893590 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 25827 - Train Loss: 0.068974, Train Acc: 0.893590 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 25828 - Train Loss: 0.068972, Train Acc: 0.893590 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 25829 - Train Loss: 0.068971, Train Acc: 0.893590 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 25830 - Train Loss: 0.068970, Train Acc: 0.893590 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 25831 - Train Loss: 0.068968, Train Acc: 0.893590 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 25832 - Train Loss: 0.068967, Train Acc: 0.893590 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 25833 - Train Loss: 0.068966, Train Acc: 0.893590 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 25834 - Train Loss: 0.068964, Train Acc: 0.893590 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 25835 - Train Loss: 0.068963, Train Acc: 0.893590 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 25836 - Train Loss: 0.068962, Train Acc: 0.893590 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 25837 - Train Loss: 0.068960, Train Acc: 0.893590 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 25838 - Train Loss: 0.068959, Train Acc: 0.893590 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 25839 - Train Loss: 0.068958, Train Acc: 0.893590 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 25840 - Train Loss: 0.068956, Train Acc: 0.893590 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 25841 - Train Loss: 0.068955, Train Acc: 0.893590 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 25842 - Train Loss: 0.068954, Train Acc: 0.893590 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 25843 - Train Loss: 0.068952, Train Acc: 0.893590 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 25844 - Train Loss: 0.068951, Train Acc: 0.893590 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 25845 - Train Loss: 0.068950, Train Acc: 0.893590 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 25846 - Train Loss: 0.068948, Train Acc: 0.893590 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 25847 - Train Loss: 0.068947, Train Acc: 0.893590 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 25848 - Train Loss: 0.068946, Train Acc: 0.893590 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 25849 - Train Loss: 0.068945, Train Acc: 0.893590 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 25850 - Train Loss: 0.068943, Train Acc: 0.893590 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 25851 - Train Loss: 0.068942, Train Acc: 0.893590 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 25852 - Train Loss: 0.068941, Train Acc: 0.893590 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 25853 - Train Loss: 0.068939, Train Acc: 0.893590 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 25854 - Train Loss: 0.068938, Train Acc: 0.893590 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 25855 - Train Loss: 0.068937, Train Acc: 0.893590 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 25856 - Train Loss: 0.068935, Train Acc: 0.893590 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 25857 - Train Loss: 0.068934, Train Acc: 0.893590 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 25858 - Train Loss: 0.068933, Train Acc: 0.893590 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 25859 - Train Loss: 0.068931, Train Acc: 0.893590 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 25860 - Train Loss: 0.068930, Train Acc: 0.893590 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 25861 - Train Loss: 0.068929, Train Acc: 0.893590 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 25862 - Train Loss: 0.068927, Train Acc: 0.893590 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 25863 - Train Loss: 0.068926, Train Acc: 0.893590 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 25864 - Train Loss: 0.068925, Train Acc: 0.893590 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 25865 - Train Loss: 0.068923, Train Acc: 0.893590 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 25866 - Train Loss: 0.068922, Train Acc: 0.893590 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 25867 - Train Loss: 0.068921, Train Acc: 0.893590 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 25868 - Train Loss: 0.068920, Train Acc: 0.893590 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 25869 - Train Loss: 0.068918, Train Acc: 0.893590 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 25870 - Train Loss: 0.068917, Train Acc: 0.893590 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 25871 - Train Loss: 0.068916, Train Acc: 0.893590 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 25872 - Train Loss: 0.068914, Train Acc: 0.893590 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 25873 - Train Loss: 0.068913, Train Acc: 0.893590 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 25874 - Train Loss: 0.068912, Train Acc: 0.893590 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 25875 - Train Loss: 0.068910, Train Acc: 0.893590 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 25876 - Train Loss: 0.068909, Train Acc: 0.893590 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 25877 - Train Loss: 0.068908, Train Acc: 0.893590 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 25878 - Train Loss: 0.068906, Train Acc: 0.893590 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 25879 - Train Loss: 0.068905, Train Acc: 0.893590 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 25880 - Train Loss: 0.068904, Train Acc: 0.893590 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 25881 - Train Loss: 0.068902, Train Acc: 0.893590 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 25882 - Train Loss: 0.068901, Train Acc: 0.893590 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 25883 - Train Loss: 0.068900, Train Acc: 0.893590 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 25884 - Train Loss: 0.068898, Train Acc: 0.893590 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 25885 - Train Loss: 0.068897, Train Acc: 0.893590 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 25886 - Train Loss: 0.068896, Train Acc: 0.893590 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 25887 - Train Loss: 0.068895, Train Acc: 0.893590 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 25888 - Train Loss: 0.068893, Train Acc: 0.893590 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 25889 - Train Loss: 0.068892, Train Acc: 0.893590 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 25890 - Train Loss: 0.068891, Train Acc: 0.893590 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 25891 - Train Loss: 0.068889, Train Acc: 0.893590 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 25892 - Train Loss: 0.068888, Train Acc: 0.893590 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 25893 - Train Loss: 0.068887, Train Acc: 0.893590 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 25894 - Train Loss: 0.068885, Train Acc: 0.893590 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 25895 - Train Loss: 0.068884, Train Acc: 0.893590 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 25896 - Train Loss: 0.068883, Train Acc: 0.893590 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 25897 - Train Loss: 0.068881, Train Acc: 0.893590 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 25898 - Train Loss: 0.068880, Train Acc: 0.893590 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 25899 - Train Loss: 0.068879, Train Acc: 0.893590 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 25900 - Train Loss: 0.068877, Train Acc: 0.893590 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 25901 - Train Loss: 0.068876, Train Acc: 0.893590 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 25902 - Train Loss: 0.068875, Train Acc: 0.893590 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 25903 - Train Loss: 0.068873, Train Acc: 0.893590 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 25904 - Train Loss: 0.068872, Train Acc: 0.893590 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 25905 - Train Loss: 0.068871, Train Acc: 0.893590 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 25906 - Train Loss: 0.068870, Train Acc: 0.893590 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 25907 - Train Loss: 0.068868, Train Acc: 0.893590 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 25908 - Train Loss: 0.068867, Train Acc: 0.893590 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 25909 - Train Loss: 0.068866, Train Acc: 0.893590 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 25910 - Train Loss: 0.068864, Train Acc: 0.893590 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 25911 - Train Loss: 0.068863, Train Acc: 0.893590 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 25912 - Train Loss: 0.068862, Train Acc: 0.893590 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 25913 - Train Loss: 0.068860, Train Acc: 0.893590 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 25914 - Train Loss: 0.068859, Train Acc: 0.893590 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 25915 - Train Loss: 0.068858, Train Acc: 0.893590 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 25916 - Train Loss: 0.068856, Train Acc: 0.893590 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 25917 - Train Loss: 0.068855, Train Acc: 0.893590 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 25918 - Train Loss: 0.068854, Train Acc: 0.893590 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 25919 - Train Loss: 0.068852, Train Acc: 0.893590 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 25920 - Train Loss: 0.068851, Train Acc: 0.893590 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 25921 - Train Loss: 0.068850, Train Acc: 0.893590 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 25922 - Train Loss: 0.068849, Train Acc: 0.893590 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 25923 - Train Loss: 0.068847, Train Acc: 0.893590 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 25924 - Train Loss: 0.068846, Train Acc: 0.893590 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 25925 - Train Loss: 0.068845, Train Acc: 0.893590 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 25926 - Train Loss: 0.068843, Train Acc: 0.893590 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 25927 - Train Loss: 0.068842, Train Acc: 0.893590 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 25928 - Train Loss: 0.068841, Train Acc: 0.893590 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 25929 - Train Loss: 0.068839, Train Acc: 0.893590 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 25930 - Train Loss: 0.068838, Train Acc: 0.893590 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 25931 - Train Loss: 0.068837, Train Acc: 0.893590 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 25932 - Train Loss: 0.068835, Train Acc: 0.893590 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 25933 - Train Loss: 0.068834, Train Acc: 0.893590 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 25934 - Train Loss: 0.068833, Train Acc: 0.893590 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 25935 - Train Loss: 0.068831, Train Acc: 0.893590 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 25936 - Train Loss: 0.068830, Train Acc: 0.893590 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 25937 - Train Loss: 0.068829, Train Acc: 0.893590 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 25938 - Train Loss: 0.068828, Train Acc: 0.893590 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 25939 - Train Loss: 0.068826, Train Acc: 0.893590 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 25940 - Train Loss: 0.068825, Train Acc: 0.893590 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 25941 - Train Loss: 0.068824, Train Acc: 0.893590 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 25942 - Train Loss: 0.068822, Train Acc: 0.893590 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 25943 - Train Loss: 0.068821, Train Acc: 0.893590 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 25944 - Train Loss: 0.068820, Train Acc: 0.893590 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 25945 - Train Loss: 0.068818, Train Acc: 0.893590 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 25946 - Train Loss: 0.068817, Train Acc: 0.893590 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 25947 - Train Loss: 0.068816, Train Acc: 0.893590 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 25948 - Train Loss: 0.068814, Train Acc: 0.893590 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 25949 - Train Loss: 0.068813, Train Acc: 0.893590 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 25950 - Train Loss: 0.068812, Train Acc: 0.893590 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 25951 - Train Loss: 0.068811, Train Acc: 0.893590 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 25952 - Train Loss: 0.068809, Train Acc: 0.893590 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 25953 - Train Loss: 0.068808, Train Acc: 0.893590 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 25954 - Train Loss: 0.068807, Train Acc: 0.893590 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 25955 - Train Loss: 0.068805, Train Acc: 0.893590 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 25956 - Train Loss: 0.068804, Train Acc: 0.893590 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 25957 - Train Loss: 0.068803, Train Acc: 0.893590 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 25958 - Train Loss: 0.068801, Train Acc: 0.893590 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 25959 - Train Loss: 0.068800, Train Acc: 0.893590 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 25960 - Train Loss: 0.068799, Train Acc: 0.893590 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 25961 - Train Loss: 0.068797, Train Acc: 0.893590 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 25962 - Train Loss: 0.068796, Train Acc: 0.893590 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 25963 - Train Loss: 0.068795, Train Acc: 0.893590 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 25964 - Train Loss: 0.068794, Train Acc: 0.893590 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 25965 - Train Loss: 0.068792, Train Acc: 0.893590 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 25966 - Train Loss: 0.068791, Train Acc: 0.893590 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 25967 - Train Loss: 0.068790, Train Acc: 0.893590 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 25968 - Train Loss: 0.068788, Train Acc: 0.893590 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 25969 - Train Loss: 0.068787, Train Acc: 0.893590 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 25970 - Train Loss: 0.068786, Train Acc: 0.893590 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 25971 - Train Loss: 0.068784, Train Acc: 0.893590 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 25972 - Train Loss: 0.068783, Train Acc: 0.893590 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 25973 - Train Loss: 0.068782, Train Acc: 0.893590 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 25974 - Train Loss: 0.068780, Train Acc: 0.893590 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 25975 - Train Loss: 0.068779, Train Acc: 0.893590 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 25976 - Train Loss: 0.068778, Train Acc: 0.893590 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 25977 - Train Loss: 0.068777, Train Acc: 0.893590 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 25978 - Train Loss: 0.068775, Train Acc: 0.893590 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 25979 - Train Loss: 0.068774, Train Acc: 0.893590 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 25980 - Train Loss: 0.068773, Train Acc: 0.893590 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 25981 - Train Loss: 0.068771, Train Acc: 0.893590 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 25982 - Train Loss: 0.068770, Train Acc: 0.893590 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 25983 - Train Loss: 0.068769, Train Acc: 0.893590 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 25984 - Train Loss: 0.068767, Train Acc: 0.893590 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 25985 - Train Loss: 0.068766, Train Acc: 0.893590 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 25986 - Train Loss: 0.068765, Train Acc: 0.893590 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 25987 - Train Loss: 0.068763, Train Acc: 0.893590 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 25988 - Train Loss: 0.068762, Train Acc: 0.893590 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 25989 - Train Loss: 0.068761, Train Acc: 0.893590 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 25990 - Train Loss: 0.068760, Train Acc: 0.893590 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 25991 - Train Loss: 0.068758, Train Acc: 0.893590 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 25992 - Train Loss: 0.068757, Train Acc: 0.893590 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 25993 - Train Loss: 0.068756, Train Acc: 0.893590 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 25994 - Train Loss: 0.068754, Train Acc: 0.893590 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 25995 - Train Loss: 0.068753, Train Acc: 0.893590 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 25996 - Train Loss: 0.068752, Train Acc: 0.893590 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 25997 - Train Loss: 0.068750, Train Acc: 0.893590 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 25998 - Train Loss: 0.068749, Train Acc: 0.893590 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 25999 - Train Loss: 0.068748, Train Acc: 0.893590 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 26000 - Train Loss: 0.068746, Train Acc: 0.893590 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 26001 - Train Loss: 0.068745, Train Acc: 0.893590 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 26002 - Train Loss: 0.068744, Train Acc: 0.893590 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 26003 - Train Loss: 0.068743, Train Acc: 0.893590 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 26004 - Train Loss: 0.068741, Train Acc: 0.893590 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 26005 - Train Loss: 0.068740, Train Acc: 0.893590 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 26006 - Train Loss: 0.068739, Train Acc: 0.893590 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 26007 - Train Loss: 0.068737, Train Acc: 0.893590 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 26008 - Train Loss: 0.068736, Train Acc: 0.893590 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 26009 - Train Loss: 0.068735, Train Acc: 0.893590 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 26010 - Train Loss: 0.068733, Train Acc: 0.893590 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 26011 - Train Loss: 0.068732, Train Acc: 0.893590 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 26012 - Train Loss: 0.068731, Train Acc: 0.893590 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 26013 - Train Loss: 0.068730, Train Acc: 0.893590 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 26014 - Train Loss: 0.068728, Train Acc: 0.893590 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 26015 - Train Loss: 0.068727, Train Acc: 0.893590 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 26016 - Train Loss: 0.068726, Train Acc: 0.893590 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 26017 - Train Loss: 0.068724, Train Acc: 0.893590 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 26018 - Train Loss: 0.068723, Train Acc: 0.893590 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 26019 - Train Loss: 0.068722, Train Acc: 0.893590 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 26020 - Train Loss: 0.068720, Train Acc: 0.893590 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 26021 - Train Loss: 0.068719, Train Acc: 0.893590 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 26022 - Train Loss: 0.068718, Train Acc: 0.893590 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 26023 - Train Loss: 0.068716, Train Acc: 0.893590 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 26024 - Train Loss: 0.068715, Train Acc: 0.893590 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 26025 - Train Loss: 0.068714, Train Acc: 0.893590 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 26026 - Train Loss: 0.068713, Train Acc: 0.893590 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 26027 - Train Loss: 0.068711, Train Acc: 0.893590 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 26028 - Train Loss: 0.068710, Train Acc: 0.893590 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 26029 - Train Loss: 0.068709, Train Acc: 0.893590 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 26030 - Train Loss: 0.068707, Train Acc: 0.893590 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 26031 - Train Loss: 0.068706, Train Acc: 0.893590 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 26032 - Train Loss: 0.068705, Train Acc: 0.893590 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 26033 - Train Loss: 0.068703, Train Acc: 0.893590 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 26034 - Train Loss: 0.068702, Train Acc: 0.893590 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 26035 - Train Loss: 0.068701, Train Acc: 0.893590 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 26036 - Train Loss: 0.068700, Train Acc: 0.893590 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 26037 - Train Loss: 0.068698, Train Acc: 0.893590 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 26038 - Train Loss: 0.068697, Train Acc: 0.893590 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 26039 - Train Loss: 0.068696, Train Acc: 0.893590 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 26040 - Train Loss: 0.068694, Train Acc: 0.893590 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 26041 - Train Loss: 0.068693, Train Acc: 0.893590 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 26042 - Train Loss: 0.068692, Train Acc: 0.893590 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 26043 - Train Loss: 0.068690, Train Acc: 0.893590 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 26044 - Train Loss: 0.068689, Train Acc: 0.893590 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 26045 - Train Loss: 0.068688, Train Acc: 0.893590 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 26046 - Train Loss: 0.068687, Train Acc: 0.893590 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 26047 - Train Loss: 0.068685, Train Acc: 0.893590 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 26048 - Train Loss: 0.068684, Train Acc: 0.893590 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 26049 - Train Loss: 0.068683, Train Acc: 0.893590 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 26050 - Train Loss: 0.068681, Train Acc: 0.893590 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 26051 - Train Loss: 0.068680, Train Acc: 0.893590 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 26052 - Train Loss: 0.068679, Train Acc: 0.893590 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 26053 - Train Loss: 0.068677, Train Acc: 0.893590 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 26054 - Train Loss: 0.068676, Train Acc: 0.893590 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 26055 - Train Loss: 0.068675, Train Acc: 0.893590 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 26056 - Train Loss: 0.068674, Train Acc: 0.893590 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 26057 - Train Loss: 0.068672, Train Acc: 0.893590 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 26058 - Train Loss: 0.068671, Train Acc: 0.893590 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 26059 - Train Loss: 0.068670, Train Acc: 0.893590 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 26060 - Train Loss: 0.068668, Train Acc: 0.893590 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 26061 - Train Loss: 0.068667, Train Acc: 0.893590 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 26062 - Train Loss: 0.068666, Train Acc: 0.893590 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 26063 - Train Loss: 0.068664, Train Acc: 0.893590 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 26064 - Train Loss: 0.068663, Train Acc: 0.893590 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 26065 - Train Loss: 0.068662, Train Acc: 0.893590 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 26066 - Train Loss: 0.068661, Train Acc: 0.893590 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 26067 - Train Loss: 0.068659, Train Acc: 0.893590 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 26068 - Train Loss: 0.068658, Train Acc: 0.893590 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 26069 - Train Loss: 0.068657, Train Acc: 0.893590 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 26070 - Train Loss: 0.068655, Train Acc: 0.893590 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 26071 - Train Loss: 0.068654, Train Acc: 0.893590 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 26072 - Train Loss: 0.068653, Train Acc: 0.893590 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 26073 - Train Loss: 0.068651, Train Acc: 0.893590 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 26074 - Train Loss: 0.068650, Train Acc: 0.893590 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 26075 - Train Loss: 0.068649, Train Acc: 0.893590 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 26076 - Train Loss: 0.068648, Train Acc: 0.893590 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 26077 - Train Loss: 0.068646, Train Acc: 0.893590 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 26078 - Train Loss: 0.068645, Train Acc: 0.893590 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 26079 - Train Loss: 0.068644, Train Acc: 0.893590 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 26080 - Train Loss: 0.068642, Train Acc: 0.893590 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 26081 - Train Loss: 0.068641, Train Acc: 0.893590 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 26082 - Train Loss: 0.068640, Train Acc: 0.893590 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 26083 - Train Loss: 0.068638, Train Acc: 0.893590 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 26084 - Train Loss: 0.068637, Train Acc: 0.893590 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 26085 - Train Loss: 0.068636, Train Acc: 0.893590 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 26086 - Train Loss: 0.068635, Train Acc: 0.893590 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 26087 - Train Loss: 0.068633, Train Acc: 0.893590 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 26088 - Train Loss: 0.068632, Train Acc: 0.893590 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 26089 - Train Loss: 0.068631, Train Acc: 0.893590 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 26090 - Train Loss: 0.068629, Train Acc: 0.893590 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 26091 - Train Loss: 0.068628, Train Acc: 0.893590 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 26092 - Train Loss: 0.068627, Train Acc: 0.893590 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 26093 - Train Loss: 0.068625, Train Acc: 0.893590 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 26094 - Train Loss: 0.068624, Train Acc: 0.893590 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 26095 - Train Loss: 0.068623, Train Acc: 0.893590 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 26096 - Train Loss: 0.068622, Train Acc: 0.893590 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 26097 - Train Loss: 0.068620, Train Acc: 0.893590 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 26098 - Train Loss: 0.068619, Train Acc: 0.893590 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 26099 - Train Loss: 0.068618, Train Acc: 0.893590 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 26100 - Train Loss: 0.068616, Train Acc: 0.893590 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 26101 - Train Loss: 0.068615, Train Acc: 0.893590 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 26102 - Train Loss: 0.068614, Train Acc: 0.893590 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 26103 - Train Loss: 0.068612, Train Acc: 0.893590 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 26104 - Train Loss: 0.068611, Train Acc: 0.893590 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 26105 - Train Loss: 0.068610, Train Acc: 0.893590 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 26106 - Train Loss: 0.068609, Train Acc: 0.893590 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 26107 - Train Loss: 0.068607, Train Acc: 0.893590 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 26108 - Train Loss: 0.068606, Train Acc: 0.893590 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 26109 - Train Loss: 0.068605, Train Acc: 0.893590 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 26110 - Train Loss: 0.068603, Train Acc: 0.893590 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 26111 - Train Loss: 0.068602, Train Acc: 0.893590 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 26112 - Train Loss: 0.068601, Train Acc: 0.893590 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 26113 - Train Loss: 0.068600, Train Acc: 0.893590 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 26114 - Train Loss: 0.068598, Train Acc: 0.893590 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 26115 - Train Loss: 0.068597, Train Acc: 0.893590 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 26116 - Train Loss: 0.068596, Train Acc: 0.893590 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 26117 - Train Loss: 0.068594, Train Acc: 0.893590 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 26118 - Train Loss: 0.068593, Train Acc: 0.893590 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 26119 - Train Loss: 0.068592, Train Acc: 0.893590 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 26120 - Train Loss: 0.068590, Train Acc: 0.893590 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 26121 - Train Loss: 0.068589, Train Acc: 0.893590 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 26122 - Train Loss: 0.068588, Train Acc: 0.893590 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 26123 - Train Loss: 0.068587, Train Acc: 0.893590 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 26124 - Train Loss: 0.068585, Train Acc: 0.893590 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 26125 - Train Loss: 0.068584, Train Acc: 0.893590 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 26126 - Train Loss: 0.068583, Train Acc: 0.893590 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 26127 - Train Loss: 0.068581, Train Acc: 0.893590 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 26128 - Train Loss: 0.068580, Train Acc: 0.893590 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 26129 - Train Loss: 0.068579, Train Acc: 0.893590 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 26130 - Train Loss: 0.068578, Train Acc: 0.893590 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 26131 - Train Loss: 0.068576, Train Acc: 0.893590 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 26132 - Train Loss: 0.068575, Train Acc: 0.893590 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 26133 - Train Loss: 0.068574, Train Acc: 0.893590 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 26134 - Train Loss: 0.068572, Train Acc: 0.893590 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 26135 - Train Loss: 0.068571, Train Acc: 0.893590 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 26136 - Train Loss: 0.068570, Train Acc: 0.893590 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 26137 - Train Loss: 0.068568, Train Acc: 0.893590 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 26138 - Train Loss: 0.068567, Train Acc: 0.893590 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 26139 - Train Loss: 0.068566, Train Acc: 0.893590 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 26140 - Train Loss: 0.068565, Train Acc: 0.893590 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 26141 - Train Loss: 0.068563, Train Acc: 0.893590 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 26142 - Train Loss: 0.068562, Train Acc: 0.893590 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 26143 - Train Loss: 0.068561, Train Acc: 0.893590 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 26144 - Train Loss: 0.068559, Train Acc: 0.893590 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 26145 - Train Loss: 0.068558, Train Acc: 0.893590 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 26146 - Train Loss: 0.068557, Train Acc: 0.893590 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 26147 - Train Loss: 0.068556, Train Acc: 0.893590 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 26148 - Train Loss: 0.068554, Train Acc: 0.893590 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 26149 - Train Loss: 0.068553, Train Acc: 0.893590 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 26150 - Train Loss: 0.068552, Train Acc: 0.893590 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 26151 - Train Loss: 0.068550, Train Acc: 0.893590 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 26152 - Train Loss: 0.068549, Train Acc: 0.893590 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 26153 - Train Loss: 0.068548, Train Acc: 0.893590 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 26154 - Train Loss: 0.068546, Train Acc: 0.893590 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 26155 - Train Loss: 0.068545, Train Acc: 0.893590 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 26156 - Train Loss: 0.068544, Train Acc: 0.893590 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 26157 - Train Loss: 0.068543, Train Acc: 0.893590 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 26158 - Train Loss: 0.068541, Train Acc: 0.893590 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 26159 - Train Loss: 0.068540, Train Acc: 0.893590 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 26160 - Train Loss: 0.068539, Train Acc: 0.893590 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 26161 - Train Loss: 0.068537, Train Acc: 0.893590 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 26162 - Train Loss: 0.068536, Train Acc: 0.893590 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 26163 - Train Loss: 0.068535, Train Acc: 0.893590 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 26164 - Train Loss: 0.068534, Train Acc: 0.893590 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 26165 - Train Loss: 0.068532, Train Acc: 0.893590 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 26166 - Train Loss: 0.068531, Train Acc: 0.893590 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 26167 - Train Loss: 0.068530, Train Acc: 0.893590 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 26168 - Train Loss: 0.068528, Train Acc: 0.893590 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 26169 - Train Loss: 0.068527, Train Acc: 0.893590 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 26170 - Train Loss: 0.068526, Train Acc: 0.893590 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 26171 - Train Loss: 0.068525, Train Acc: 0.893590 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 26172 - Train Loss: 0.068523, Train Acc: 0.893590 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 26173 - Train Loss: 0.068522, Train Acc: 0.893590 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 26174 - Train Loss: 0.068521, Train Acc: 0.893590 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 26175 - Train Loss: 0.068519, Train Acc: 0.893590 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 26176 - Train Loss: 0.068518, Train Acc: 0.893590 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 26177 - Train Loss: 0.068517, Train Acc: 0.893590 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 26178 - Train Loss: 0.068515, Train Acc: 0.893590 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 26179 - Train Loss: 0.068514, Train Acc: 0.893590 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 26180 - Train Loss: 0.068513, Train Acc: 0.893590 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 26181 - Train Loss: 0.068512, Train Acc: 0.893590 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 26182 - Train Loss: 0.068510, Train Acc: 0.893590 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 26183 - Train Loss: 0.068509, Train Acc: 0.893590 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 26184 - Train Loss: 0.068508, Train Acc: 0.893590 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 26185 - Train Loss: 0.068506, Train Acc: 0.893590 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 26186 - Train Loss: 0.068505, Train Acc: 0.893590 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 26187 - Train Loss: 0.068504, Train Acc: 0.893590 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 26188 - Train Loss: 0.068503, Train Acc: 0.893590 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 26189 - Train Loss: 0.068501, Train Acc: 0.893590 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 26190 - Train Loss: 0.068500, Train Acc: 0.893590 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 26191 - Train Loss: 0.068499, Train Acc: 0.893590 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 26192 - Train Loss: 0.068497, Train Acc: 0.893590 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 26193 - Train Loss: 0.068496, Train Acc: 0.893590 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 26194 - Train Loss: 0.068495, Train Acc: 0.893590 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 26195 - Train Loss: 0.068494, Train Acc: 0.893590 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 26196 - Train Loss: 0.068492, Train Acc: 0.893590 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 26197 - Train Loss: 0.068491, Train Acc: 0.893590 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 26198 - Train Loss: 0.068490, Train Acc: 0.893590 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 26199 - Train Loss: 0.068488, Train Acc: 0.893590 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 26200 - Train Loss: 0.068487, Train Acc: 0.893590 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 26201 - Train Loss: 0.068486, Train Acc: 0.893590 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 26202 - Train Loss: 0.068485, Train Acc: 0.893590 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 26203 - Train Loss: 0.068483, Train Acc: 0.893590 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 26204 - Train Loss: 0.068482, Train Acc: 0.893590 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 26205 - Train Loss: 0.068481, Train Acc: 0.893590 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 26206 - Train Loss: 0.068479, Train Acc: 0.893590 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 26207 - Train Loss: 0.068478, Train Acc: 0.893590 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 26208 - Train Loss: 0.068477, Train Acc: 0.893590 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 26209 - Train Loss: 0.068476, Train Acc: 0.893590 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 26210 - Train Loss: 0.068474, Train Acc: 0.893590 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 26211 - Train Loss: 0.068473, Train Acc: 0.893590 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 26212 - Train Loss: 0.068472, Train Acc: 0.893590 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 26213 - Train Loss: 0.068470, Train Acc: 0.893590 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 26214 - Train Loss: 0.068469, Train Acc: 0.893590 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 26215 - Train Loss: 0.068468, Train Acc: 0.893590 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 26216 - Train Loss: 0.068467, Train Acc: 0.893590 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 26217 - Train Loss: 0.068465, Train Acc: 0.893590 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 26218 - Train Loss: 0.068464, Train Acc: 0.893590 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 26219 - Train Loss: 0.068463, Train Acc: 0.893590 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 26220 - Train Loss: 0.068461, Train Acc: 0.893590 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 26221 - Train Loss: 0.068460, Train Acc: 0.893590 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 26222 - Train Loss: 0.068459, Train Acc: 0.893590 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 26223 - Train Loss: 0.068458, Train Acc: 0.893590 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 26224 - Train Loss: 0.068456, Train Acc: 0.893590 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 26225 - Train Loss: 0.068455, Train Acc: 0.893590 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 26226 - Train Loss: 0.068454, Train Acc: 0.893590 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 26227 - Train Loss: 0.068452, Train Acc: 0.893590 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 26228 - Train Loss: 0.068451, Train Acc: 0.893590 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 26229 - Train Loss: 0.068450, Train Acc: 0.893590 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 26230 - Train Loss: 0.068449, Train Acc: 0.893590 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 26231 - Train Loss: 0.068447, Train Acc: 0.893590 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 26232 - Train Loss: 0.068446, Train Acc: 0.893590 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 26233 - Train Loss: 0.068445, Train Acc: 0.893590 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 26234 - Train Loss: 0.068443, Train Acc: 0.893590 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 26235 - Train Loss: 0.068442, Train Acc: 0.893590 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 26236 - Train Loss: 0.068441, Train Acc: 0.893590 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 26237 - Train Loss: 0.068440, Train Acc: 0.893590 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 26238 - Train Loss: 0.068438, Train Acc: 0.893590 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 26239 - Train Loss: 0.068437, Train Acc: 0.893590 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 26240 - Train Loss: 0.068436, Train Acc: 0.893590 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 26241 - Train Loss: 0.068434, Train Acc: 0.893590 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 26242 - Train Loss: 0.068433, Train Acc: 0.893590 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 26243 - Train Loss: 0.068432, Train Acc: 0.893590 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 26244 - Train Loss: 0.068431, Train Acc: 0.893590 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 26245 - Train Loss: 0.068429, Train Acc: 0.893590 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 26246 - Train Loss: 0.068428, Train Acc: 0.893590 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 26247 - Train Loss: 0.068427, Train Acc: 0.893590 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 26248 - Train Loss: 0.068425, Train Acc: 0.893590 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 26249 - Train Loss: 0.068424, Train Acc: 0.893590 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 26250 - Train Loss: 0.068423, Train Acc: 0.893590 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 26251 - Train Loss: 0.068422, Train Acc: 0.893590 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 26252 - Train Loss: 0.068420, Train Acc: 0.893590 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 26253 - Train Loss: 0.068419, Train Acc: 0.893590 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 26254 - Train Loss: 0.068418, Train Acc: 0.893590 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 26255 - Train Loss: 0.068416, Train Acc: 0.893590 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 26256 - Train Loss: 0.068415, Train Acc: 0.893590 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 26257 - Train Loss: 0.068414, Train Acc: 0.893590 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 26258 - Train Loss: 0.068413, Train Acc: 0.893590 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 26259 - Train Loss: 0.068411, Train Acc: 0.893590 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 26260 - Train Loss: 0.068410, Train Acc: 0.893590 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 26261 - Train Loss: 0.068409, Train Acc: 0.893590 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 26262 - Train Loss: 0.068407, Train Acc: 0.893590 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 26263 - Train Loss: 0.068406, Train Acc: 0.893590 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 26264 - Train Loss: 0.068405, Train Acc: 0.893590 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 26265 - Train Loss: 0.068404, Train Acc: 0.893590 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 26266 - Train Loss: 0.068402, Train Acc: 0.893590 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 26267 - Train Loss: 0.068401, Train Acc: 0.893590 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 26268 - Train Loss: 0.068400, Train Acc: 0.893590 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 26269 - Train Loss: 0.068398, Train Acc: 0.893590 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 26270 - Train Loss: 0.068397, Train Acc: 0.893590 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 26271 - Train Loss: 0.068396, Train Acc: 0.893590 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 26272 - Train Loss: 0.068395, Train Acc: 0.893590 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 26273 - Train Loss: 0.068393, Train Acc: 0.893590 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 26274 - Train Loss: 0.068392, Train Acc: 0.893590 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 26275 - Train Loss: 0.068391, Train Acc: 0.893590 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 26276 - Train Loss: 0.068389, Train Acc: 0.893590 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 26277 - Train Loss: 0.068388, Train Acc: 0.893590 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 26278 - Train Loss: 0.068387, Train Acc: 0.893590 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 26279 - Train Loss: 0.068386, Train Acc: 0.893590 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 26280 - Train Loss: 0.068384, Train Acc: 0.893590 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 26281 - Train Loss: 0.068383, Train Acc: 0.893590 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 26282 - Train Loss: 0.068382, Train Acc: 0.893590 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 26283 - Train Loss: 0.068380, Train Acc: 0.893590 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 26284 - Train Loss: 0.068379, Train Acc: 0.893590 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 26285 - Train Loss: 0.068378, Train Acc: 0.893590 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 26286 - Train Loss: 0.068377, Train Acc: 0.893590 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 26287 - Train Loss: 0.068375, Train Acc: 0.893590 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 26288 - Train Loss: 0.068374, Train Acc: 0.893590 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 26289 - Train Loss: 0.068373, Train Acc: 0.893590 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 26290 - Train Loss: 0.068372, Train Acc: 0.893590 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 26291 - Train Loss: 0.068370, Train Acc: 0.893590 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 26292 - Train Loss: 0.068369, Train Acc: 0.893590 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 26293 - Train Loss: 0.068368, Train Acc: 0.893590 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 26294 - Train Loss: 0.068366, Train Acc: 0.893590 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 26295 - Train Loss: 0.068365, Train Acc: 0.893590 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 26296 - Train Loss: 0.068364, Train Acc: 0.893590 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 26297 - Train Loss: 0.068363, Train Acc: 0.893590 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 26298 - Train Loss: 0.068361, Train Acc: 0.893590 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 26299 - Train Loss: 0.068360, Train Acc: 0.893590 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 26300 - Train Loss: 0.068359, Train Acc: 0.893590 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 26301 - Train Loss: 0.068357, Train Acc: 0.893590 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 26302 - Train Loss: 0.068356, Train Acc: 0.893590 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 26303 - Train Loss: 0.068355, Train Acc: 0.893590 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 26304 - Train Loss: 0.068354, Train Acc: 0.893590 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 26305 - Train Loss: 0.068352, Train Acc: 0.893590 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 26306 - Train Loss: 0.068351, Train Acc: 0.893590 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 26307 - Train Loss: 0.068350, Train Acc: 0.893590 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 26308 - Train Loss: 0.068348, Train Acc: 0.893590 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 26309 - Train Loss: 0.068347, Train Acc: 0.893590 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 26310 - Train Loss: 0.068346, Train Acc: 0.893590 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 26311 - Train Loss: 0.068345, Train Acc: 0.893590 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 26312 - Train Loss: 0.068343, Train Acc: 0.893590 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 26313 - Train Loss: 0.068342, Train Acc: 0.893590 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 26314 - Train Loss: 0.068341, Train Acc: 0.893590 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 26315 - Train Loss: 0.068340, Train Acc: 0.893590 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 26316 - Train Loss: 0.068338, Train Acc: 0.893590 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 26317 - Train Loss: 0.068337, Train Acc: 0.893590 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 26318 - Train Loss: 0.068336, Train Acc: 0.893590 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 26319 - Train Loss: 0.068334, Train Acc: 0.893590 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 26320 - Train Loss: 0.068333, Train Acc: 0.893590 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 26321 - Train Loss: 0.068332, Train Acc: 0.893590 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 26322 - Train Loss: 0.068331, Train Acc: 0.893590 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 26323 - Train Loss: 0.068329, Train Acc: 0.893590 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 26324 - Train Loss: 0.068328, Train Acc: 0.893590 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 26325 - Train Loss: 0.068327, Train Acc: 0.893590 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 26326 - Train Loss: 0.068325, Train Acc: 0.893590 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 26327 - Train Loss: 0.068324, Train Acc: 0.893590 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 26328 - Train Loss: 0.068323, Train Acc: 0.893590 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 26329 - Train Loss: 0.068322, Train Acc: 0.893590 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 26330 - Train Loss: 0.068320, Train Acc: 0.893590 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 26331 - Train Loss: 0.068319, Train Acc: 0.893590 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 26332 - Train Loss: 0.068318, Train Acc: 0.893590 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 26333 - Train Loss: 0.068317, Train Acc: 0.893590 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 26334 - Train Loss: 0.068315, Train Acc: 0.893590 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 26335 - Train Loss: 0.068314, Train Acc: 0.893590 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 26336 - Train Loss: 0.068313, Train Acc: 0.893590 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 26337 - Train Loss: 0.068311, Train Acc: 0.893590 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 26338 - Train Loss: 0.068310, Train Acc: 0.893590 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 26339 - Train Loss: 0.068309, Train Acc: 0.893590 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 26340 - Train Loss: 0.068308, Train Acc: 0.893590 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 26341 - Train Loss: 0.068306, Train Acc: 0.893590 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 26342 - Train Loss: 0.068305, Train Acc: 0.893590 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 26343 - Train Loss: 0.068304, Train Acc: 0.893590 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 26344 - Train Loss: 0.068302, Train Acc: 0.893590 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 26345 - Train Loss: 0.068301, Train Acc: 0.893590 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 26346 - Train Loss: 0.068300, Train Acc: 0.893590 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 26347 - Train Loss: 0.068299, Train Acc: 0.893590 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 26348 - Train Loss: 0.068297, Train Acc: 0.893590 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 26349 - Train Loss: 0.068296, Train Acc: 0.893590 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 26350 - Train Loss: 0.068295, Train Acc: 0.893590 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 26351 - Train Loss: 0.068294, Train Acc: 0.893590 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 26352 - Train Loss: 0.068292, Train Acc: 0.893590 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 26353 - Train Loss: 0.068291, Train Acc: 0.893590 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 26354 - Train Loss: 0.068290, Train Acc: 0.893590 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 26355 - Train Loss: 0.068288, Train Acc: 0.893590 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 26356 - Train Loss: 0.068287, Train Acc: 0.893590 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 26357 - Train Loss: 0.068286, Train Acc: 0.893590 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 26358 - Train Loss: 0.068285, Train Acc: 0.893590 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 26359 - Train Loss: 0.068283, Train Acc: 0.893590 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 26360 - Train Loss: 0.068282, Train Acc: 0.893590 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 26361 - Train Loss: 0.068281, Train Acc: 0.893590 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 26362 - Train Loss: 0.068280, Train Acc: 0.893590 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 26363 - Train Loss: 0.068278, Train Acc: 0.893590 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 26364 - Train Loss: 0.068277, Train Acc: 0.893590 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 26365 - Train Loss: 0.068276, Train Acc: 0.893590 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 26366 - Train Loss: 0.068274, Train Acc: 0.893590 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 26367 - Train Loss: 0.068273, Train Acc: 0.893590 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 26368 - Train Loss: 0.068272, Train Acc: 0.893590 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 26369 - Train Loss: 0.068271, Train Acc: 0.893590 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 26370 - Train Loss: 0.068269, Train Acc: 0.893590 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 26371 - Train Loss: 0.068268, Train Acc: 0.893590 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 26372 - Train Loss: 0.068267, Train Acc: 0.893590 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 26373 - Train Loss: 0.068266, Train Acc: 0.893590 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 26374 - Train Loss: 0.068264, Train Acc: 0.893590 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 26375 - Train Loss: 0.068263, Train Acc: 0.893590 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 26376 - Train Loss: 0.068262, Train Acc: 0.893590 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 26377 - Train Loss: 0.068260, Train Acc: 0.893590 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 26378 - Train Loss: 0.068259, Train Acc: 0.893590 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 26379 - Train Loss: 0.068258, Train Acc: 0.893590 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 26380 - Train Loss: 0.068257, Train Acc: 0.893590 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 26381 - Train Loss: 0.068255, Train Acc: 0.893590 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 26382 - Train Loss: 0.068254, Train Acc: 0.893590 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 26383 - Train Loss: 0.068253, Train Acc: 0.893590 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 26384 - Train Loss: 0.068252, Train Acc: 0.893590 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 26385 - Train Loss: 0.068250, Train Acc: 0.893590 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 26386 - Train Loss: 0.068249, Train Acc: 0.893590 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 26387 - Train Loss: 0.068248, Train Acc: 0.893590 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 26388 - Train Loss: 0.068246, Train Acc: 0.893590 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 26389 - Train Loss: 0.068245, Train Acc: 0.893590 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 26390 - Train Loss: 0.068244, Train Acc: 0.893590 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 26391 - Train Loss: 0.068243, Train Acc: 0.893590 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 26392 - Train Loss: 0.068241, Train Acc: 0.893590 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 26393 - Train Loss: 0.068240, Train Acc: 0.893590 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 26394 - Train Loss: 0.068239, Train Acc: 0.893590 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 26395 - Train Loss: 0.068238, Train Acc: 0.893590 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 26396 - Train Loss: 0.068236, Train Acc: 0.893590 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 26397 - Train Loss: 0.068235, Train Acc: 0.893590 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 26398 - Train Loss: 0.068234, Train Acc: 0.893590 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 26399 - Train Loss: 0.068232, Train Acc: 0.893590 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 26400 - Train Loss: 0.068231, Train Acc: 0.893590 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 26401 - Train Loss: 0.068230, Train Acc: 0.893590 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 26402 - Train Loss: 0.068229, Train Acc: 0.893590 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 26403 - Train Loss: 0.068227, Train Acc: 0.893590 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 26404 - Train Loss: 0.068226, Train Acc: 0.893590 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 26405 - Train Loss: 0.068225, Train Acc: 0.893590 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 26406 - Train Loss: 0.068224, Train Acc: 0.893590 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 26407 - Train Loss: 0.068222, Train Acc: 0.893590 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 26408 - Train Loss: 0.068221, Train Acc: 0.893590 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 26409 - Train Loss: 0.068220, Train Acc: 0.893590 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 26410 - Train Loss: 0.068218, Train Acc: 0.893590 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 26411 - Train Loss: 0.068217, Train Acc: 0.893590 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 26412 - Train Loss: 0.068216, Train Acc: 0.893590 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 26413 - Train Loss: 0.068215, Train Acc: 0.893590 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 26414 - Train Loss: 0.068213, Train Acc: 0.893590 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 26415 - Train Loss: 0.068212, Train Acc: 0.893590 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 26416 - Train Loss: 0.068211, Train Acc: 0.893590 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 26417 - Train Loss: 0.068210, Train Acc: 0.893590 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 26418 - Train Loss: 0.068208, Train Acc: 0.893590 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 26419 - Train Loss: 0.068207, Train Acc: 0.893590 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 26420 - Train Loss: 0.068206, Train Acc: 0.893590 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 26421 - Train Loss: 0.068204, Train Acc: 0.893590 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 26422 - Train Loss: 0.068203, Train Acc: 0.893590 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 26423 - Train Loss: 0.068202, Train Acc: 0.893590 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 26424 - Train Loss: 0.068201, Train Acc: 0.893590 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 26425 - Train Loss: 0.068199, Train Acc: 0.893590 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 26426 - Train Loss: 0.068198, Train Acc: 0.893590 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 26427 - Train Loss: 0.068197, Train Acc: 0.893590 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 26428 - Train Loss: 0.068196, Train Acc: 0.893590 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 26429 - Train Loss: 0.068194, Train Acc: 0.893590 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 26430 - Train Loss: 0.068193, Train Acc: 0.893590 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 26431 - Train Loss: 0.068192, Train Acc: 0.893590 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 26432 - Train Loss: 0.068190, Train Acc: 0.893590 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 26433 - Train Loss: 0.068189, Train Acc: 0.893590 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 26434 - Train Loss: 0.068188, Train Acc: 0.893590 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 26435 - Train Loss: 0.068187, Train Acc: 0.893590 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 26436 - Train Loss: 0.068185, Train Acc: 0.893590 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 26437 - Train Loss: 0.068184, Train Acc: 0.893590 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 26438 - Train Loss: 0.068183, Train Acc: 0.893590 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 26439 - Train Loss: 0.068182, Train Acc: 0.893590 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 26440 - Train Loss: 0.068180, Train Acc: 0.893590 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 26441 - Train Loss: 0.068179, Train Acc: 0.893590 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 26442 - Train Loss: 0.068178, Train Acc: 0.893590 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 26443 - Train Loss: 0.068177, Train Acc: 0.893590 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 26444 - Train Loss: 0.068175, Train Acc: 0.893590 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 26445 - Train Loss: 0.068174, Train Acc: 0.893590 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 26446 - Train Loss: 0.068173, Train Acc: 0.893590 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 26447 - Train Loss: 0.068171, Train Acc: 0.893590 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 26448 - Train Loss: 0.068170, Train Acc: 0.893590 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 26449 - Train Loss: 0.068169, Train Acc: 0.893590 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 26450 - Train Loss: 0.068168, Train Acc: 0.893590 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 26451 - Train Loss: 0.068166, Train Acc: 0.893590 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 26452 - Train Loss: 0.068165, Train Acc: 0.893590 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 26453 - Train Loss: 0.068164, Train Acc: 0.893590 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 26454 - Train Loss: 0.068163, Train Acc: 0.893590 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 26455 - Train Loss: 0.068161, Train Acc: 0.893590 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 26456 - Train Loss: 0.068160, Train Acc: 0.893590 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 26457 - Train Loss: 0.068159, Train Acc: 0.893590 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 26458 - Train Loss: 0.068158, Train Acc: 0.893590 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 26459 - Train Loss: 0.068156, Train Acc: 0.893590 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 26460 - Train Loss: 0.068155, Train Acc: 0.893590 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 26461 - Train Loss: 0.068154, Train Acc: 0.893590 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 26462 - Train Loss: 0.068152, Train Acc: 0.893590 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 26463 - Train Loss: 0.068151, Train Acc: 0.893590 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 26464 - Train Loss: 0.068150, Train Acc: 0.893590 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 26465 - Train Loss: 0.068149, Train Acc: 0.893590 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 26466 - Train Loss: 0.068147, Train Acc: 0.893590 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 26467 - Train Loss: 0.068146, Train Acc: 0.893590 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 26468 - Train Loss: 0.068145, Train Acc: 0.893590 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 26469 - Train Loss: 0.068144, Train Acc: 0.893590 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 26470 - Train Loss: 0.068142, Train Acc: 0.893590 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 26471 - Train Loss: 0.068141, Train Acc: 0.893590 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 26472 - Train Loss: 0.068140, Train Acc: 0.893590 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 26473 - Train Loss: 0.068139, Train Acc: 0.893590 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 26474 - Train Loss: 0.068137, Train Acc: 0.893590 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 26475 - Train Loss: 0.068136, Train Acc: 0.893590 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 26476 - Train Loss: 0.068135, Train Acc: 0.893590 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 26477 - Train Loss: 0.068133, Train Acc: 0.893590 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 26478 - Train Loss: 0.068132, Train Acc: 0.893590 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 26479 - Train Loss: 0.068131, Train Acc: 0.893590 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 26480 - Train Loss: 0.068130, Train Acc: 0.893590 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 26481 - Train Loss: 0.068128, Train Acc: 0.893590 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 26482 - Train Loss: 0.068127, Train Acc: 0.893590 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 26483 - Train Loss: 0.068126, Train Acc: 0.893590 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 26484 - Train Loss: 0.068125, Train Acc: 0.893590 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 26485 - Train Loss: 0.068123, Train Acc: 0.893590 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 26486 - Train Loss: 0.068122, Train Acc: 0.893590 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 26487 - Train Loss: 0.068121, Train Acc: 0.893590 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 26488 - Train Loss: 0.068120, Train Acc: 0.893590 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 26489 - Train Loss: 0.068118, Train Acc: 0.893590 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 26490 - Train Loss: 0.068117, Train Acc: 0.893590 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 26491 - Train Loss: 0.068116, Train Acc: 0.893590 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 26492 - Train Loss: 0.068114, Train Acc: 0.893590 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 26493 - Train Loss: 0.068113, Train Acc: 0.893590 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 26494 - Train Loss: 0.068112, Train Acc: 0.893590 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 26495 - Train Loss: 0.068111, Train Acc: 0.893590 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 26496 - Train Loss: 0.068109, Train Acc: 0.893590 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 26497 - Train Loss: 0.068108, Train Acc: 0.893590 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 26498 - Train Loss: 0.068107, Train Acc: 0.893590 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 26499 - Train Loss: 0.068106, Train Acc: 0.893590 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 26500 - Train Loss: 0.068104, Train Acc: 0.893590 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 26501 - Train Loss: 0.068103, Train Acc: 0.893590 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 26502 - Train Loss: 0.068102, Train Acc: 0.893590 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 26503 - Train Loss: 0.068101, Train Acc: 0.893590 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 26504 - Train Loss: 0.068099, Train Acc: 0.893590 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 26505 - Train Loss: 0.068098, Train Acc: 0.893590 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 26506 - Train Loss: 0.068097, Train Acc: 0.893590 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 26507 - Train Loss: 0.068096, Train Acc: 0.893590 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 26508 - Train Loss: 0.068094, Train Acc: 0.893590 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 26509 - Train Loss: 0.068093, Train Acc: 0.893590 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 26510 - Train Loss: 0.068092, Train Acc: 0.893590 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 26511 - Train Loss: 0.068090, Train Acc: 0.893590 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 26512 - Train Loss: 0.068089, Train Acc: 0.893590 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 26513 - Train Loss: 0.068088, Train Acc: 0.893590 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 26514 - Train Loss: 0.068087, Train Acc: 0.893590 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 26515 - Train Loss: 0.068085, Train Acc: 0.893590 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 26516 - Train Loss: 0.068084, Train Acc: 0.893590 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 26517 - Train Loss: 0.068083, Train Acc: 0.893590 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 26518 - Train Loss: 0.068082, Train Acc: 0.893590 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 26519 - Train Loss: 0.068080, Train Acc: 0.893590 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 26520 - Train Loss: 0.068079, Train Acc: 0.893590 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 26521 - Train Loss: 0.068078, Train Acc: 0.893590 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 26522 - Train Loss: 0.068077, Train Acc: 0.893590 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 26523 - Train Loss: 0.068075, Train Acc: 0.893590 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 26524 - Train Loss: 0.068074, Train Acc: 0.893590 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 26525 - Train Loss: 0.068073, Train Acc: 0.893590 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 26526 - Train Loss: 0.068072, Train Acc: 0.893590 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 26527 - Train Loss: 0.068070, Train Acc: 0.893590 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 26528 - Train Loss: 0.068069, Train Acc: 0.893590 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 26529 - Train Loss: 0.068068, Train Acc: 0.893590 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 26530 - Train Loss: 0.068067, Train Acc: 0.893590 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 26531 - Train Loss: 0.068065, Train Acc: 0.893590 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 26532 - Train Loss: 0.068064, Train Acc: 0.893590 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 26533 - Train Loss: 0.068063, Train Acc: 0.893590 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 26534 - Train Loss: 0.068061, Train Acc: 0.893590 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 26535 - Train Loss: 0.068060, Train Acc: 0.893590 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 26536 - Train Loss: 0.068059, Train Acc: 0.893590 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 26537 - Train Loss: 0.068058, Train Acc: 0.893590 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 26538 - Train Loss: 0.068056, Train Acc: 0.893590 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 26539 - Train Loss: 0.068055, Train Acc: 0.893590 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 26540 - Train Loss: 0.068054, Train Acc: 0.893590 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 26541 - Train Loss: 0.068053, Train Acc: 0.893590 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 26542 - Train Loss: 0.068051, Train Acc: 0.893590 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 26543 - Train Loss: 0.068050, Train Acc: 0.893590 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 26544 - Train Loss: 0.068049, Train Acc: 0.893590 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 26545 - Train Loss: 0.068048, Train Acc: 0.893590 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 26546 - Train Loss: 0.068046, Train Acc: 0.893590 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 26547 - Train Loss: 0.068045, Train Acc: 0.893590 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 26548 - Train Loss: 0.068044, Train Acc: 0.893590 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 26549 - Train Loss: 0.068043, Train Acc: 0.893590 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 26550 - Train Loss: 0.068041, Train Acc: 0.893590 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 26551 - Train Loss: 0.068040, Train Acc: 0.893590 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 26552 - Train Loss: 0.068039, Train Acc: 0.893590 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 26553 - Train Loss: 0.068038, Train Acc: 0.893590 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 26554 - Train Loss: 0.068036, Train Acc: 0.893590 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 26555 - Train Loss: 0.068035, Train Acc: 0.893590 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 26556 - Train Loss: 0.068034, Train Acc: 0.893590 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 26557 - Train Loss: 0.068032, Train Acc: 0.893590 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 26558 - Train Loss: 0.068031, Train Acc: 0.893590 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 26559 - Train Loss: 0.068030, Train Acc: 0.893590 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 26560 - Train Loss: 0.068029, Train Acc: 0.893590 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 26561 - Train Loss: 0.068027, Train Acc: 0.893590 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 26562 - Train Loss: 0.068026, Train Acc: 0.893590 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 26563 - Train Loss: 0.068025, Train Acc: 0.893590 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 26564 - Train Loss: 0.068024, Train Acc: 0.893590 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 26565 - Train Loss: 0.068022, Train Acc: 0.893590 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 26566 - Train Loss: 0.068021, Train Acc: 0.893590 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 26567 - Train Loss: 0.068020, Train Acc: 0.893590 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 26568 - Train Loss: 0.068019, Train Acc: 0.893590 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 26569 - Train Loss: 0.068017, Train Acc: 0.893590 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 26570 - Train Loss: 0.068016, Train Acc: 0.893590 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 26571 - Train Loss: 0.068015, Train Acc: 0.893590 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 26572 - Train Loss: 0.068014, Train Acc: 0.893590 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 26573 - Train Loss: 0.068012, Train Acc: 0.893590 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 26574 - Train Loss: 0.068011, Train Acc: 0.893590 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 26575 - Train Loss: 0.068010, Train Acc: 0.893590 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 26576 - Train Loss: 0.068009, Train Acc: 0.893590 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 26577 - Train Loss: 0.068007, Train Acc: 0.893590 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 26578 - Train Loss: 0.068006, Train Acc: 0.893590 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 26579 - Train Loss: 0.068005, Train Acc: 0.893590 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 26580 - Train Loss: 0.068004, Train Acc: 0.893590 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 26581 - Train Loss: 0.068002, Train Acc: 0.893590 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 26582 - Train Loss: 0.068001, Train Acc: 0.893590 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 26583 - Train Loss: 0.068000, Train Acc: 0.893590 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 26584 - Train Loss: 0.067999, Train Acc: 0.893590 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 26585 - Train Loss: 0.067997, Train Acc: 0.893590 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 26586 - Train Loss: 0.067996, Train Acc: 0.893590 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 26587 - Train Loss: 0.067995, Train Acc: 0.893590 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 26588 - Train Loss: 0.067993, Train Acc: 0.893590 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 26589 - Train Loss: 0.067992, Train Acc: 0.893590 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 26590 - Train Loss: 0.067991, Train Acc: 0.893590 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 26591 - Train Loss: 0.067990, Train Acc: 0.893590 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 26592 - Train Loss: 0.067988, Train Acc: 0.893590 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 26593 - Train Loss: 0.067987, Train Acc: 0.893590 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 26594 - Train Loss: 0.067986, Train Acc: 0.893590 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 26595 - Train Loss: 0.067985, Train Acc: 0.893590 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 26596 - Train Loss: 0.067983, Train Acc: 0.893590 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 26597 - Train Loss: 0.067982, Train Acc: 0.893590 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 26598 - Train Loss: 0.067981, Train Acc: 0.893590 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 26599 - Train Loss: 0.067980, Train Acc: 0.893590 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 26600 - Train Loss: 0.067978, Train Acc: 0.893590 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 26601 - Train Loss: 0.067977, Train Acc: 0.893590 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 26602 - Train Loss: 0.067976, Train Acc: 0.893590 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 26603 - Train Loss: 0.067975, Train Acc: 0.893590 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 26604 - Train Loss: 0.067973, Train Acc: 0.893590 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 26605 - Train Loss: 0.067972, Train Acc: 0.893590 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 26606 - Train Loss: 0.067971, Train Acc: 0.893590 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 26607 - Train Loss: 0.067970, Train Acc: 0.893590 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 26608 - Train Loss: 0.067968, Train Acc: 0.893590 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 26609 - Train Loss: 0.067967, Train Acc: 0.893590 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 26610 - Train Loss: 0.067966, Train Acc: 0.893590 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 26611 - Train Loss: 0.067965, Train Acc: 0.893590 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 26612 - Train Loss: 0.067963, Train Acc: 0.893590 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 26613 - Train Loss: 0.067962, Train Acc: 0.893590 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 26614 - Train Loss: 0.067961, Train Acc: 0.893590 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 26615 - Train Loss: 0.067960, Train Acc: 0.893590 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 26616 - Train Loss: 0.067958, Train Acc: 0.893590 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 26617 - Train Loss: 0.067957, Train Acc: 0.893590 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 26618 - Train Loss: 0.067956, Train Acc: 0.893590 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 26619 - Train Loss: 0.067955, Train Acc: 0.894872 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 26620 - Train Loss: 0.067953, Train Acc: 0.894872 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 26621 - Train Loss: 0.067952, Train Acc: 0.894872 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 26622 - Train Loss: 0.067951, Train Acc: 0.894872 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 26623 - Train Loss: 0.067950, Train Acc: 0.894872 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 26624 - Train Loss: 0.067948, Train Acc: 0.894872 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 26625 - Train Loss: 0.067947, Train Acc: 0.894872 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 26626 - Train Loss: 0.067946, Train Acc: 0.894872 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 26627 - Train Loss: 0.067945, Train Acc: 0.894872 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 26628 - Train Loss: 0.067943, Train Acc: 0.894872 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 26629 - Train Loss: 0.067942, Train Acc: 0.894872 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 26630 - Train Loss: 0.067941, Train Acc: 0.894872 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 26631 - Train Loss: 0.067940, Train Acc: 0.894872 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 26632 - Train Loss: 0.067938, Train Acc: 0.894872 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 26633 - Train Loss: 0.067937, Train Acc: 0.894872 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 26634 - Train Loss: 0.067936, Train Acc: 0.894872 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 26635 - Train Loss: 0.067935, Train Acc: 0.894872 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 26636 - Train Loss: 0.067933, Train Acc: 0.894872 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 26637 - Train Loss: 0.067932, Train Acc: 0.894872 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 26638 - Train Loss: 0.067931, Train Acc: 0.894872 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 26639 - Train Loss: 0.067930, Train Acc: 0.894872 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 26640 - Train Loss: 0.067928, Train Acc: 0.894872 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 26641 - Train Loss: 0.067927, Train Acc: 0.894872 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 26642 - Train Loss: 0.067926, Train Acc: 0.894872 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 26643 - Train Loss: 0.067925, Train Acc: 0.894872 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 26644 - Train Loss: 0.067923, Train Acc: 0.894872 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 26645 - Train Loss: 0.067922, Train Acc: 0.894872 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 26646 - Train Loss: 0.067921, Train Acc: 0.894872 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 26647 - Train Loss: 0.067920, Train Acc: 0.894872 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 26648 - Train Loss: 0.067918, Train Acc: 0.894872 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 26649 - Train Loss: 0.067917, Train Acc: 0.894872 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 26650 - Train Loss: 0.067916, Train Acc: 0.894872 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 26651 - Train Loss: 0.067914, Train Acc: 0.894872 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 26652 - Train Loss: 0.067913, Train Acc: 0.894872 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 26653 - Train Loss: 0.067912, Train Acc: 0.894872 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 26654 - Train Loss: 0.067911, Train Acc: 0.894872 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 26655 - Train Loss: 0.067909, Train Acc: 0.894872 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 26656 - Train Loss: 0.067908, Train Acc: 0.894872 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 26657 - Train Loss: 0.067907, Train Acc: 0.894872 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 26658 - Train Loss: 0.067906, Train Acc: 0.894872 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 26659 - Train Loss: 0.067904, Train Acc: 0.894872 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 26660 - Train Loss: 0.067903, Train Acc: 0.894872 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 26661 - Train Loss: 0.067902, Train Acc: 0.894872 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 26662 - Train Loss: 0.067901, Train Acc: 0.894872 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 26663 - Train Loss: 0.067899, Train Acc: 0.894872 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 26664 - Train Loss: 0.067898, Train Acc: 0.894872 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 26665 - Train Loss: 0.067897, Train Acc: 0.894872 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 26666 - Train Loss: 0.067896, Train Acc: 0.894872 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 26667 - Train Loss: 0.067894, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26668 - Train Loss: 0.067893, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26669 - Train Loss: 0.067892, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26670 - Train Loss: 0.067891, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26671 - Train Loss: 0.067889, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26672 - Train Loss: 0.067888, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26673 - Train Loss: 0.067887, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26674 - Train Loss: 0.067886, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26675 - Train Loss: 0.067884, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26676 - Train Loss: 0.067883, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26677 - Train Loss: 0.067882, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26678 - Train Loss: 0.067881, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26679 - Train Loss: 0.067879, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26680 - Train Loss: 0.067878, Train Acc: 0.894872 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 26681 - Train Loss: 0.067877, Train Acc: 0.894872 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 26682 - Train Loss: 0.067876, Train Acc: 0.894872 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 26683 - Train Loss: 0.067874, Train Acc: 0.894872 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 26684 - Train Loss: 0.067873, Train Acc: 0.894872 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 26685 - Train Loss: 0.067872, Train Acc: 0.894872 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 26686 - Train Loss: 0.067871, Train Acc: 0.894872 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 26687 - Train Loss: 0.067869, Train Acc: 0.894872 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 26688 - Train Loss: 0.067868, Train Acc: 0.894872 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 26689 - Train Loss: 0.067867, Train Acc: 0.894872 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 26690 - Train Loss: 0.067866, Train Acc: 0.894872 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 26691 - Train Loss: 0.067865, Train Acc: 0.894872 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 26692 - Train Loss: 0.067863, Train Acc: 0.894872 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 26693 - Train Loss: 0.067862, Train Acc: 0.894872 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 26694 - Train Loss: 0.067861, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26695 - Train Loss: 0.067860, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26696 - Train Loss: 0.067858, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26697 - Train Loss: 0.067857, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26698 - Train Loss: 0.067856, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26699 - Train Loss: 0.067855, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26700 - Train Loss: 0.067853, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26701 - Train Loss: 0.067852, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26702 - Train Loss: 0.067851, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26703 - Train Loss: 0.067850, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26704 - Train Loss: 0.067848, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26705 - Train Loss: 0.067847, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26706 - Train Loss: 0.067846, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26707 - Train Loss: 0.067845, Train Acc: 0.894872 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 26708 - Train Loss: 0.067843, Train Acc: 0.894872 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 26709 - Train Loss: 0.067842, Train Acc: 0.894872 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 26710 - Train Loss: 0.067841, Train Acc: 0.894872 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 26711 - Train Loss: 0.067840, Train Acc: 0.894872 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 26712 - Train Loss: 0.067838, Train Acc: 0.894872 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 26713 - Train Loss: 0.067837, Train Acc: 0.894872 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 26714 - Train Loss: 0.067836, Train Acc: 0.894872 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 26715 - Train Loss: 0.067835, Train Acc: 0.894872 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 26716 - Train Loss: 0.067833, Train Acc: 0.894872 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 26717 - Train Loss: 0.067832, Train Acc: 0.894872 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 26718 - Train Loss: 0.067831, Train Acc: 0.894872 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 26719 - Train Loss: 0.067830, Train Acc: 0.894872 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 26720 - Train Loss: 0.067828, Train Acc: 0.894872 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 26721 - Train Loss: 0.067827, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26722 - Train Loss: 0.067826, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26723 - Train Loss: 0.067825, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26724 - Train Loss: 0.067823, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26725 - Train Loss: 0.067822, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26726 - Train Loss: 0.067821, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26727 - Train Loss: 0.067820, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26728 - Train Loss: 0.067818, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26729 - Train Loss: 0.067817, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26730 - Train Loss: 0.067816, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26731 - Train Loss: 0.067815, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26732 - Train Loss: 0.067813, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26733 - Train Loss: 0.067812, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26734 - Train Loss: 0.067811, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26735 - Train Loss: 0.067810, Train Acc: 0.894872 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 26736 - Train Loss: 0.067808, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26737 - Train Loss: 0.067807, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26738 - Train Loss: 0.067806, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26739 - Train Loss: 0.067805, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26740 - Train Loss: 0.067803, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26741 - Train Loss: 0.067802, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26742 - Train Loss: 0.067801, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26743 - Train Loss: 0.067800, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26744 - Train Loss: 0.067798, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26745 - Train Loss: 0.067797, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26746 - Train Loss: 0.067796, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26747 - Train Loss: 0.067795, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26748 - Train Loss: 0.067793, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26749 - Train Loss: 0.067792, Train Acc: 0.894872 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 26750 - Train Loss: 0.067791, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26751 - Train Loss: 0.067790, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26752 - Train Loss: 0.067788, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26753 - Train Loss: 0.067787, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26754 - Train Loss: 0.067786, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26755 - Train Loss: 0.067785, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26756 - Train Loss: 0.067784, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26757 - Train Loss: 0.067782, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26758 - Train Loss: 0.067781, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26759 - Train Loss: 0.067780, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26760 - Train Loss: 0.067779, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26761 - Train Loss: 0.067777, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26762 - Train Loss: 0.067776, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26763 - Train Loss: 0.067775, Train Acc: 0.894872 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 26764 - Train Loss: 0.067774, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26765 - Train Loss: 0.067772, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26766 - Train Loss: 0.067771, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26767 - Train Loss: 0.067770, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26768 - Train Loss: 0.067769, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26769 - Train Loss: 0.067767, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26770 - Train Loss: 0.067766, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26771 - Train Loss: 0.067765, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26772 - Train Loss: 0.067764, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26773 - Train Loss: 0.067762, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26774 - Train Loss: 0.067761, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26775 - Train Loss: 0.067760, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26776 - Train Loss: 0.067759, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26777 - Train Loss: 0.067757, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26778 - Train Loss: 0.067756, Train Acc: 0.894872 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 26779 - Train Loss: 0.067755, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26780 - Train Loss: 0.067754, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26781 - Train Loss: 0.067752, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26782 - Train Loss: 0.067751, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26783 - Train Loss: 0.067750, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26784 - Train Loss: 0.067749, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26785 - Train Loss: 0.067747, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26786 - Train Loss: 0.067746, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26787 - Train Loss: 0.067745, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26788 - Train Loss: 0.067744, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26789 - Train Loss: 0.067743, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26790 - Train Loss: 0.067741, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26791 - Train Loss: 0.067740, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26792 - Train Loss: 0.067739, Train Acc: 0.894872 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 26793 - Train Loss: 0.067738, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26794 - Train Loss: 0.067736, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26795 - Train Loss: 0.067735, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26796 - Train Loss: 0.067734, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26797 - Train Loss: 0.067733, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26798 - Train Loss: 0.067731, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26799 - Train Loss: 0.067730, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26800 - Train Loss: 0.067729, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26801 - Train Loss: 0.067728, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26802 - Train Loss: 0.067726, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26803 - Train Loss: 0.067725, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26804 - Train Loss: 0.067724, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26805 - Train Loss: 0.067723, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26806 - Train Loss: 0.067721, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26807 - Train Loss: 0.067720, Train Acc: 0.894872 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 26808 - Train Loss: 0.067719, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26809 - Train Loss: 0.067718, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26810 - Train Loss: 0.067716, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26811 - Train Loss: 0.067715, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26812 - Train Loss: 0.067714, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26813 - Train Loss: 0.067713, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26814 - Train Loss: 0.067712, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26815 - Train Loss: 0.067710, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26816 - Train Loss: 0.067709, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26817 - Train Loss: 0.067708, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26818 - Train Loss: 0.067707, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26819 - Train Loss: 0.067705, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26820 - Train Loss: 0.067704, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26821 - Train Loss: 0.067703, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26822 - Train Loss: 0.067702, Train Acc: 0.894872 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 26823 - Train Loss: 0.067700, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26824 - Train Loss: 0.067699, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26825 - Train Loss: 0.067698, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26826 - Train Loss: 0.067697, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26827 - Train Loss: 0.067695, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26828 - Train Loss: 0.067694, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26829 - Train Loss: 0.067693, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26830 - Train Loss: 0.067692, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26831 - Train Loss: 0.067690, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26832 - Train Loss: 0.067689, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26833 - Train Loss: 0.067688, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26834 - Train Loss: 0.067687, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26835 - Train Loss: 0.067686, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26836 - Train Loss: 0.067684, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26837 - Train Loss: 0.067683, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26838 - Train Loss: 0.067682, Train Acc: 0.894872 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 26839 - Train Loss: 0.067681, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26840 - Train Loss: 0.067679, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26841 - Train Loss: 0.067678, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26842 - Train Loss: 0.067677, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26843 - Train Loss: 0.067676, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26844 - Train Loss: 0.067674, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26845 - Train Loss: 0.067673, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26846 - Train Loss: 0.067672, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26847 - Train Loss: 0.067671, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26848 - Train Loss: 0.067669, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26849 - Train Loss: 0.067668, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26850 - Train Loss: 0.067667, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26851 - Train Loss: 0.067666, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26852 - Train Loss: 0.067665, Train Acc: 0.894872 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 26853 - Train Loss: 0.067663, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26854 - Train Loss: 0.067662, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26855 - Train Loss: 0.067661, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26856 - Train Loss: 0.067660, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26857 - Train Loss: 0.067658, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26858 - Train Loss: 0.067657, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26859 - Train Loss: 0.067656, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26860 - Train Loss: 0.067655, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26861 - Train Loss: 0.067653, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26862 - Train Loss: 0.067652, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26863 - Train Loss: 0.067651, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26864 - Train Loss: 0.067650, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26865 - Train Loss: 0.067648, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26866 - Train Loss: 0.067647, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26867 - Train Loss: 0.067646, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26868 - Train Loss: 0.067645, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26869 - Train Loss: 0.067644, Train Acc: 0.894872 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 26870 - Train Loss: 0.067642, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26871 - Train Loss: 0.067641, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26872 - Train Loss: 0.067640, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26873 - Train Loss: 0.067639, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26874 - Train Loss: 0.067637, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26875 - Train Loss: 0.067636, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26876 - Train Loss: 0.067635, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26877 - Train Loss: 0.067634, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26878 - Train Loss: 0.067632, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26879 - Train Loss: 0.067631, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26880 - Train Loss: 0.067630, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26881 - Train Loss: 0.067629, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26882 - Train Loss: 0.067627, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26883 - Train Loss: 0.067626, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26884 - Train Loss: 0.067625, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26885 - Train Loss: 0.067624, Train Acc: 0.894872 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 26886 - Train Loss: 0.067623, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26887 - Train Loss: 0.067621, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26888 - Train Loss: 0.067620, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26889 - Train Loss: 0.067619, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26890 - Train Loss: 0.067618, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26891 - Train Loss: 0.067616, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26892 - Train Loss: 0.067615, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26893 - Train Loss: 0.067614, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26894 - Train Loss: 0.067613, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26895 - Train Loss: 0.067611, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26896 - Train Loss: 0.067610, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26897 - Train Loss: 0.067609, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26898 - Train Loss: 0.067608, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26899 - Train Loss: 0.067607, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26900 - Train Loss: 0.067605, Train Acc: 0.894872 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 26901 - Train Loss: 0.067604, Train Acc: 0.894872 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26902 - Train Loss: 0.067603, Train Acc: 0.894872 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26903 - Train Loss: 0.067602, Train Acc: 0.894872 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26904 - Train Loss: 0.067600, Train Acc: 0.894872 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26905 - Train Loss: 0.067599, Train Acc: 0.894872 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26906 - Train Loss: 0.067598, Train Acc: 0.894872 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26907 - Train Loss: 0.067597, Train Acc: 0.894872 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26908 - Train Loss: 0.067595, Train Acc: 0.894872 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26909 - Train Loss: 0.067594, Train Acc: 0.894872 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26910 - Train Loss: 0.067593, Train Acc: 0.894872 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26911 - Train Loss: 0.067592, Train Acc: 0.894872 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26912 - Train Loss: 0.067591, Train Acc: 0.896154 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26913 - Train Loss: 0.067589, Train Acc: 0.896154 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26914 - Train Loss: 0.067588, Train Acc: 0.896154 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26915 - Train Loss: 0.067587, Train Acc: 0.896154 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26916 - Train Loss: 0.067586, Train Acc: 0.896154 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26917 - Train Loss: 0.067584, Train Acc: 0.896154 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 26918 - Train Loss: 0.067583, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26919 - Train Loss: 0.067582, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26920 - Train Loss: 0.067581, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26921 - Train Loss: 0.067579, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26922 - Train Loss: 0.067578, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26923 - Train Loss: 0.067577, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26924 - Train Loss: 0.067576, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26925 - Train Loss: 0.067575, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26926 - Train Loss: 0.067573, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26927 - Train Loss: 0.067572, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26928 - Train Loss: 0.067571, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26929 - Train Loss: 0.067570, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26930 - Train Loss: 0.067568, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26931 - Train Loss: 0.067567, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26932 - Train Loss: 0.067566, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26933 - Train Loss: 0.067565, Train Acc: 0.896154 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 26934 - Train Loss: 0.067563, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26935 - Train Loss: 0.067562, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26936 - Train Loss: 0.067561, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26937 - Train Loss: 0.067560, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26938 - Train Loss: 0.067559, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26939 - Train Loss: 0.067557, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26940 - Train Loss: 0.067556, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26941 - Train Loss: 0.067555, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26942 - Train Loss: 0.067554, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26943 - Train Loss: 0.067552, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26944 - Train Loss: 0.067551, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26945 - Train Loss: 0.067550, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26946 - Train Loss: 0.067549, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26947 - Train Loss: 0.067547, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26948 - Train Loss: 0.067546, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26949 - Train Loss: 0.067545, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26950 - Train Loss: 0.067544, Train Acc: 0.896154 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 26951 - Train Loss: 0.067543, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26952 - Train Loss: 0.067541, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26953 - Train Loss: 0.067540, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26954 - Train Loss: 0.067539, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26955 - Train Loss: 0.067538, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26956 - Train Loss: 0.067536, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26957 - Train Loss: 0.067535, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26958 - Train Loss: 0.067534, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26959 - Train Loss: 0.067533, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26960 - Train Loss: 0.067532, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26961 - Train Loss: 0.067530, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26962 - Train Loss: 0.067529, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26963 - Train Loss: 0.067528, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26964 - Train Loss: 0.067527, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26965 - Train Loss: 0.067525, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26966 - Train Loss: 0.067524, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26967 - Train Loss: 0.067523, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26968 - Train Loss: 0.067522, Train Acc: 0.896154 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 26969 - Train Loss: 0.067520, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26970 - Train Loss: 0.067519, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26971 - Train Loss: 0.067518, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26972 - Train Loss: 0.067517, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26973 - Train Loss: 0.067516, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26974 - Train Loss: 0.067514, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26975 - Train Loss: 0.067513, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26976 - Train Loss: 0.067512, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26977 - Train Loss: 0.067511, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26978 - Train Loss: 0.067509, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26979 - Train Loss: 0.067508, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26980 - Train Loss: 0.067507, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26981 - Train Loss: 0.067506, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26982 - Train Loss: 0.067505, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26983 - Train Loss: 0.067503, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26984 - Train Loss: 0.067502, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26985 - Train Loss: 0.067501, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26986 - Train Loss: 0.067500, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26987 - Train Loss: 0.067498, Train Acc: 0.896154 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 26988 - Train Loss: 0.067497, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 26989 - Train Loss: 0.067496, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 26990 - Train Loss: 0.067495, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 26991 - Train Loss: 0.067494, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 26992 - Train Loss: 0.067492, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 26993 - Train Loss: 0.067491, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 26994 - Train Loss: 0.067490, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 26995 - Train Loss: 0.067489, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 26996 - Train Loss: 0.067487, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 26997 - Train Loss: 0.067486, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 26998 - Train Loss: 0.067485, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 26999 - Train Loss: 0.067484, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 27000 - Train Loss: 0.067482, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 27001 - Train Loss: 0.067481, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 27002 - Train Loss: 0.067480, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 27003 - Train Loss: 0.067479, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 27004 - Train Loss: 0.067478, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27005 - Train Loss: 0.067476, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27006 - Train Loss: 0.067475, Train Acc: 0.896154 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 27007 - Train Loss: 0.067474, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27008 - Train Loss: 0.067473, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27009 - Train Loss: 0.067471, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27010 - Train Loss: 0.067470, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27011 - Train Loss: 0.067469, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27012 - Train Loss: 0.067468, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27013 - Train Loss: 0.067467, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27014 - Train Loss: 0.067465, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27015 - Train Loss: 0.067464, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27016 - Train Loss: 0.067463, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27017 - Train Loss: 0.067462, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27018 - Train Loss: 0.067460, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27019 - Train Loss: 0.067459, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27020 - Train Loss: 0.067458, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27021 - Train Loss: 0.067457, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27022 - Train Loss: 0.067456, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27023 - Train Loss: 0.067454, Train Acc: 0.896154 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 27024 - Train Loss: 0.067453, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27025 - Train Loss: 0.067452, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27026 - Train Loss: 0.067451, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27027 - Train Loss: 0.067449, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27028 - Train Loss: 0.067448, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27029 - Train Loss: 0.067447, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27030 - Train Loss: 0.067446, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27031 - Train Loss: 0.067445, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27032 - Train Loss: 0.067443, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27033 - Train Loss: 0.067442, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27034 - Train Loss: 0.067441, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27035 - Train Loss: 0.067440, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27036 - Train Loss: 0.067438, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27037 - Train Loss: 0.067437, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27038 - Train Loss: 0.067436, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27039 - Train Loss: 0.067435, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27040 - Train Loss: 0.067434, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27041 - Train Loss: 0.067432, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27042 - Train Loss: 0.067431, Train Acc: 0.896154 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 27043 - Train Loss: 0.067430, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27044 - Train Loss: 0.067429, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27045 - Train Loss: 0.067427, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27046 - Train Loss: 0.067426, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27047 - Train Loss: 0.067425, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27048 - Train Loss: 0.067424, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27049 - Train Loss: 0.067423, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27050 - Train Loss: 0.067421, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27051 - Train Loss: 0.067420, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27052 - Train Loss: 0.067419, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27053 - Train Loss: 0.067418, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27054 - Train Loss: 0.067416, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27055 - Train Loss: 0.067415, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27056 - Train Loss: 0.067414, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27057 - Train Loss: 0.067413, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27058 - Train Loss: 0.067412, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27059 - Train Loss: 0.067410, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27060 - Train Loss: 0.067409, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27061 - Train Loss: 0.067408, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27062 - Train Loss: 0.067407, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27063 - Train Loss: 0.067405, Train Acc: 0.896154 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 27064 - Train Loss: 0.067404, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27065 - Train Loss: 0.067403, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27066 - Train Loss: 0.067402, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27067 - Train Loss: 0.067401, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27068 - Train Loss: 0.067399, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27069 - Train Loss: 0.067398, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27070 - Train Loss: 0.067397, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27071 - Train Loss: 0.067396, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27072 - Train Loss: 0.067395, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27073 - Train Loss: 0.067393, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27074 - Train Loss: 0.067392, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27075 - Train Loss: 0.067391, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27076 - Train Loss: 0.067390, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27077 - Train Loss: 0.067388, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27078 - Train Loss: 0.067387, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27079 - Train Loss: 0.067386, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27080 - Train Loss: 0.067385, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27081 - Train Loss: 0.067384, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27082 - Train Loss: 0.067382, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27083 - Train Loss: 0.067381, Train Acc: 0.896154 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 27084 - Train Loss: 0.067380, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27085 - Train Loss: 0.067379, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27086 - Train Loss: 0.067377, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27087 - Train Loss: 0.067376, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27088 - Train Loss: 0.067375, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27089 - Train Loss: 0.067374, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27090 - Train Loss: 0.067373, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27091 - Train Loss: 0.067371, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27092 - Train Loss: 0.067370, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27093 - Train Loss: 0.067369, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27094 - Train Loss: 0.067368, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27095 - Train Loss: 0.067367, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27096 - Train Loss: 0.067365, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27097 - Train Loss: 0.067364, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27098 - Train Loss: 0.067363, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27099 - Train Loss: 0.067362, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27100 - Train Loss: 0.067360, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27101 - Train Loss: 0.067359, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27102 - Train Loss: 0.067358, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27103 - Train Loss: 0.067357, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27104 - Train Loss: 0.067356, Train Acc: 0.896154 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 27105 - Train Loss: 0.067354, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27106 - Train Loss: 0.067353, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27107 - Train Loss: 0.067352, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27108 - Train Loss: 0.067351, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27109 - Train Loss: 0.067349, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27110 - Train Loss: 0.067348, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27111 - Train Loss: 0.067347, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27112 - Train Loss: 0.067346, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27113 - Train Loss: 0.067345, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27114 - Train Loss: 0.067343, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27115 - Train Loss: 0.067342, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27116 - Train Loss: 0.067341, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27117 - Train Loss: 0.067340, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27118 - Train Loss: 0.067339, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27119 - Train Loss: 0.067337, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27120 - Train Loss: 0.067336, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27121 - Train Loss: 0.067335, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27122 - Train Loss: 0.067334, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27123 - Train Loss: 0.067332, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27124 - Train Loss: 0.067331, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27125 - Train Loss: 0.067330, Train Acc: 0.896154 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 27126 - Train Loss: 0.067329, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27127 - Train Loss: 0.067328, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27128 - Train Loss: 0.067326, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27129 - Train Loss: 0.067325, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27130 - Train Loss: 0.067324, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27131 - Train Loss: 0.067323, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27132 - Train Loss: 0.067322, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27133 - Train Loss: 0.067320, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27134 - Train Loss: 0.067319, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27135 - Train Loss: 0.067318, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27136 - Train Loss: 0.067317, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27137 - Train Loss: 0.067315, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27138 - Train Loss: 0.067314, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27139 - Train Loss: 0.067313, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27140 - Train Loss: 0.067312, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27141 - Train Loss: 0.067311, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27142 - Train Loss: 0.067309, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27143 - Train Loss: 0.067308, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27144 - Train Loss: 0.067307, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27145 - Train Loss: 0.067306, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27146 - Train Loss: 0.067305, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27147 - Train Loss: 0.067303, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27148 - Train Loss: 0.067302, Train Acc: 0.896154 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 27149 - Train Loss: 0.067301, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27150 - Train Loss: 0.067300, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27151 - Train Loss: 0.067298, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27152 - Train Loss: 0.067297, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27153 - Train Loss: 0.067296, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27154 - Train Loss: 0.067295, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27155 - Train Loss: 0.067294, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27156 - Train Loss: 0.067292, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27157 - Train Loss: 0.067291, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27158 - Train Loss: 0.067290, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27159 - Train Loss: 0.067289, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27160 - Train Loss: 0.067288, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27161 - Train Loss: 0.067286, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27162 - Train Loss: 0.067285, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27163 - Train Loss: 0.067284, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27164 - Train Loss: 0.067283, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27165 - Train Loss: 0.067281, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27166 - Train Loss: 0.067280, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27167 - Train Loss: 0.067279, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27168 - Train Loss: 0.067278, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27169 - Train Loss: 0.067277, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27170 - Train Loss: 0.067275, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27171 - Train Loss: 0.067274, Train Acc: 0.896154 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 27172 - Train Loss: 0.067273, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27173 - Train Loss: 0.067272, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27174 - Train Loss: 0.067271, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27175 - Train Loss: 0.067269, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27176 - Train Loss: 0.067268, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27177 - Train Loss: 0.067267, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27178 - Train Loss: 0.067266, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27179 - Train Loss: 0.067265, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27180 - Train Loss: 0.067263, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27181 - Train Loss: 0.067262, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27182 - Train Loss: 0.067261, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27183 - Train Loss: 0.067260, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27184 - Train Loss: 0.067258, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27185 - Train Loss: 0.067257, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27186 - Train Loss: 0.067256, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27187 - Train Loss: 0.067255, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27188 - Train Loss: 0.067254, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27189 - Train Loss: 0.067252, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27190 - Train Loss: 0.067251, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27191 - Train Loss: 0.067250, Train Acc: 0.896154 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27192 - Train Loss: 0.067249, Train Acc: 0.897436 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27193 - Train Loss: 0.067248, Train Acc: 0.897436 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27194 - Train Loss: 0.067246, Train Acc: 0.897436 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27195 - Train Loss: 0.067245, Train Acc: 0.897436 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 27196 - Train Loss: 0.067244, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27197 - Train Loss: 0.067243, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27198 - Train Loss: 0.067242, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27199 - Train Loss: 0.067240, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27200 - Train Loss: 0.067239, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27201 - Train Loss: 0.067238, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27202 - Train Loss: 0.067237, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27203 - Train Loss: 0.067235, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27204 - Train Loss: 0.067234, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27205 - Train Loss: 0.067233, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27206 - Train Loss: 0.067232, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27207 - Train Loss: 0.067231, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27208 - Train Loss: 0.067229, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27209 - Train Loss: 0.067228, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27210 - Train Loss: 0.067227, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27211 - Train Loss: 0.067226, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27212 - Train Loss: 0.067225, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27213 - Train Loss: 0.067223, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27214 - Train Loss: 0.067222, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27215 - Train Loss: 0.067221, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27216 - Train Loss: 0.067220, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27217 - Train Loss: 0.067219, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27218 - Train Loss: 0.067217, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27219 - Train Loss: 0.067216, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27220 - Train Loss: 0.067215, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27221 - Train Loss: 0.067214, Train Acc: 0.897436 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 27222 - Train Loss: 0.067212, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27223 - Train Loss: 0.067211, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27224 - Train Loss: 0.067210, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27225 - Train Loss: 0.067209, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27226 - Train Loss: 0.067208, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27227 - Train Loss: 0.067206, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27228 - Train Loss: 0.067205, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27229 - Train Loss: 0.067204, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27230 - Train Loss: 0.067203, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27231 - Train Loss: 0.067202, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27232 - Train Loss: 0.067200, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27233 - Train Loss: 0.067199, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27234 - Train Loss: 0.067198, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27235 - Train Loss: 0.067197, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27236 - Train Loss: 0.067196, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27237 - Train Loss: 0.067194, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27238 - Train Loss: 0.067193, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27239 - Train Loss: 0.067192, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27240 - Train Loss: 0.067191, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27241 - Train Loss: 0.067190, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27242 - Train Loss: 0.067188, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27243 - Train Loss: 0.067187, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27244 - Train Loss: 0.067186, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27245 - Train Loss: 0.067185, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27246 - Train Loss: 0.067184, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27247 - Train Loss: 0.067182, Train Acc: 0.897436 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 27248 - Train Loss: 0.067181, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27249 - Train Loss: 0.067180, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27250 - Train Loss: 0.067179, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27251 - Train Loss: 0.067177, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27252 - Train Loss: 0.067176, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27253 - Train Loss: 0.067175, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27254 - Train Loss: 0.067174, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27255 - Train Loss: 0.067173, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27256 - Train Loss: 0.067171, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27257 - Train Loss: 0.067170, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27258 - Train Loss: 0.067169, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27259 - Train Loss: 0.067168, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27260 - Train Loss: 0.067167, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27261 - Train Loss: 0.067165, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27262 - Train Loss: 0.067164, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27263 - Train Loss: 0.067163, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27264 - Train Loss: 0.067162, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27265 - Train Loss: 0.067161, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27266 - Train Loss: 0.067159, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27267 - Train Loss: 0.067158, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27268 - Train Loss: 0.067157, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27269 - Train Loss: 0.067156, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27270 - Train Loss: 0.067155, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27271 - Train Loss: 0.067153, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27272 - Train Loss: 0.067152, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27273 - Train Loss: 0.067151, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27274 - Train Loss: 0.067150, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27275 - Train Loss: 0.067149, Train Acc: 0.897436 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 27276 - Train Loss: 0.067147, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27277 - Train Loss: 0.067146, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27278 - Train Loss: 0.067145, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27279 - Train Loss: 0.067144, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27280 - Train Loss: 0.067143, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27281 - Train Loss: 0.067141, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27282 - Train Loss: 0.067140, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27283 - Train Loss: 0.067139, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27284 - Train Loss: 0.067138, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27285 - Train Loss: 0.067137, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27286 - Train Loss: 0.067135, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27287 - Train Loss: 0.067134, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27288 - Train Loss: 0.067133, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27289 - Train Loss: 0.067132, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27290 - Train Loss: 0.067131, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27291 - Train Loss: 0.067129, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27292 - Train Loss: 0.067128, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27293 - Train Loss: 0.067127, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27294 - Train Loss: 0.067126, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27295 - Train Loss: 0.067125, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27296 - Train Loss: 0.067123, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27297 - Train Loss: 0.067122, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27298 - Train Loss: 0.067121, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27299 - Train Loss: 0.067120, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27300 - Train Loss: 0.067118, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27301 - Train Loss: 0.067117, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27302 - Train Loss: 0.067116, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27303 - Train Loss: 0.067115, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27304 - Train Loss: 0.067114, Train Acc: 0.897436 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 27305 - Train Loss: 0.067112, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27306 - Train Loss: 0.067111, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27307 - Train Loss: 0.067110, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27308 - Train Loss: 0.067109, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27309 - Train Loss: 0.067108, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27310 - Train Loss: 0.067106, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27311 - Train Loss: 0.067105, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27312 - Train Loss: 0.067104, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27313 - Train Loss: 0.067103, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27314 - Train Loss: 0.067102, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27315 - Train Loss: 0.067100, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27316 - Train Loss: 0.067099, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27317 - Train Loss: 0.067098, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27318 - Train Loss: 0.067097, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27319 - Train Loss: 0.067096, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27320 - Train Loss: 0.067094, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27321 - Train Loss: 0.067093, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27322 - Train Loss: 0.067092, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27323 - Train Loss: 0.067091, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27324 - Train Loss: 0.067090, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27325 - Train Loss: 0.067088, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27326 - Train Loss: 0.067087, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27327 - Train Loss: 0.067086, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27328 - Train Loss: 0.067085, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27329 - Train Loss: 0.067084, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27330 - Train Loss: 0.067082, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27331 - Train Loss: 0.067081, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27332 - Train Loss: 0.067080, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27333 - Train Loss: 0.067079, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27334 - Train Loss: 0.067078, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27335 - Train Loss: 0.067076, Train Acc: 0.897436 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 27336 - Train Loss: 0.067075, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27337 - Train Loss: 0.067074, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27338 - Train Loss: 0.067073, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27339 - Train Loss: 0.067072, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27340 - Train Loss: 0.067070, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27341 - Train Loss: 0.067069, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27342 - Train Loss: 0.067068, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27343 - Train Loss: 0.067067, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27344 - Train Loss: 0.067066, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27345 - Train Loss: 0.067064, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27346 - Train Loss: 0.067063, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27347 - Train Loss: 0.067062, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27348 - Train Loss: 0.067061, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27349 - Train Loss: 0.067060, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27350 - Train Loss: 0.067058, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27351 - Train Loss: 0.067057, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27352 - Train Loss: 0.067056, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27353 - Train Loss: 0.067055, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27354 - Train Loss: 0.067054, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27355 - Train Loss: 0.067052, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27356 - Train Loss: 0.067051, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27357 - Train Loss: 0.067050, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27358 - Train Loss: 0.067049, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27359 - Train Loss: 0.067048, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27360 - Train Loss: 0.067046, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27361 - Train Loss: 0.067045, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27362 - Train Loss: 0.067044, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27363 - Train Loss: 0.067043, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27364 - Train Loss: 0.067042, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27365 - Train Loss: 0.067040, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27366 - Train Loss: 0.067039, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27367 - Train Loss: 0.067038, Train Acc: 0.897436 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27368 - Train Loss: 0.067037, Train Acc: 0.897436 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 27369 - Train Loss: 0.067036, Train Acc: 0.897436 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27370 - Train Loss: 0.067035, Train Acc: 0.897436 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27371 - Train Loss: 0.067033, Train Acc: 0.897436 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27372 - Train Loss: 0.067032, Train Acc: 0.897436 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27373 - Train Loss: 0.067031, Train Acc: 0.897436 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27374 - Train Loss: 0.067030, Train Acc: 0.897436 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27375 - Train Loss: 0.067029, Train Acc: 0.897436 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27376 - Train Loss: 0.067027, Train Acc: 0.897436 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27377 - Train Loss: 0.067026, Train Acc: 0.897436 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27378 - Train Loss: 0.067025, Train Acc: 0.897436 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27379 - Train Loss: 0.067024, Train Acc: 0.897436 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27380 - Train Loss: 0.067023, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27381 - Train Loss: 0.067021, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27382 - Train Loss: 0.067020, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27383 - Train Loss: 0.067019, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27384 - Train Loss: 0.067018, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27385 - Train Loss: 0.067017, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27386 - Train Loss: 0.067015, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27387 - Train Loss: 0.067014, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27388 - Train Loss: 0.067013, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27389 - Train Loss: 0.067012, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27390 - Train Loss: 0.067011, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27391 - Train Loss: 0.067009, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27392 - Train Loss: 0.067008, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27393 - Train Loss: 0.067007, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27394 - Train Loss: 0.067006, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27395 - Train Loss: 0.067005, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27396 - Train Loss: 0.067003, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27397 - Train Loss: 0.067002, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27398 - Train Loss: 0.067001, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27399 - Train Loss: 0.067000, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27400 - Train Loss: 0.066999, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27401 - Train Loss: 0.066997, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 27402 - Train Loss: 0.066996, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27403 - Train Loss: 0.066995, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27404 - Train Loss: 0.066994, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27405 - Train Loss: 0.066993, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27406 - Train Loss: 0.066991, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27407 - Train Loss: 0.066990, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27408 - Train Loss: 0.066989, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27409 - Train Loss: 0.066988, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27410 - Train Loss: 0.066987, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27411 - Train Loss: 0.066985, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27412 - Train Loss: 0.066984, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27413 - Train Loss: 0.066983, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27414 - Train Loss: 0.066982, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27415 - Train Loss: 0.066981, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27416 - Train Loss: 0.066979, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27417 - Train Loss: 0.066978, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27418 - Train Loss: 0.066977, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27419 - Train Loss: 0.066976, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27420 - Train Loss: 0.066975, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27421 - Train Loss: 0.066973, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27422 - Train Loss: 0.066972, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27423 - Train Loss: 0.066971, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27424 - Train Loss: 0.066970, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27425 - Train Loss: 0.066969, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27426 - Train Loss: 0.066967, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27427 - Train Loss: 0.066966, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27428 - Train Loss: 0.066965, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27429 - Train Loss: 0.066964, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27430 - Train Loss: 0.066963, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27431 - Train Loss: 0.066962, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27432 - Train Loss: 0.066960, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27433 - Train Loss: 0.066959, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27434 - Train Loss: 0.066958, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27435 - Train Loss: 0.066957, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27436 - Train Loss: 0.066956, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27437 - Train Loss: 0.066954, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27438 - Train Loss: 0.066953, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27439 - Train Loss: 0.066952, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27440 - Train Loss: 0.066951, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 27441 - Train Loss: 0.066950, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27442 - Train Loss: 0.066948, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27443 - Train Loss: 0.066947, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27444 - Train Loss: 0.066946, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27445 - Train Loss: 0.066945, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27446 - Train Loss: 0.066944, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27447 - Train Loss: 0.066942, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27448 - Train Loss: 0.066941, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27449 - Train Loss: 0.066940, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27450 - Train Loss: 0.066939, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27451 - Train Loss: 0.066938, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27452 - Train Loss: 0.066936, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27453 - Train Loss: 0.066935, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27454 - Train Loss: 0.066934, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27455 - Train Loss: 0.066933, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27456 - Train Loss: 0.066932, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27457 - Train Loss: 0.066930, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27458 - Train Loss: 0.066929, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27459 - Train Loss: 0.066928, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27460 - Train Loss: 0.066927, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27461 - Train Loss: 0.066926, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27462 - Train Loss: 0.066925, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27463 - Train Loss: 0.066923, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27464 - Train Loss: 0.066922, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27465 - Train Loss: 0.066921, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27466 - Train Loss: 0.066920, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27467 - Train Loss: 0.066919, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27468 - Train Loss: 0.066917, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27469 - Train Loss: 0.066916, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27470 - Train Loss: 0.066915, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27471 - Train Loss: 0.066914, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27472 - Train Loss: 0.066913, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27473 - Train Loss: 0.066911, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27474 - Train Loss: 0.066910, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27475 - Train Loss: 0.066909, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27476 - Train Loss: 0.066908, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27477 - Train Loss: 0.066907, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27478 - Train Loss: 0.066905, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27479 - Train Loss: 0.066904, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27480 - Train Loss: 0.066903, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 27481 - Train Loss: 0.066902, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27482 - Train Loss: 0.066901, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27483 - Train Loss: 0.066899, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27484 - Train Loss: 0.066898, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27485 - Train Loss: 0.066897, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27486 - Train Loss: 0.066896, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27487 - Train Loss: 0.066895, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27488 - Train Loss: 0.066894, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27489 - Train Loss: 0.066892, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27490 - Train Loss: 0.066891, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27491 - Train Loss: 0.066890, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27492 - Train Loss: 0.066889, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27493 - Train Loss: 0.066888, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27494 - Train Loss: 0.066886, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27495 - Train Loss: 0.066885, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27496 - Train Loss: 0.066884, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27497 - Train Loss: 0.066883, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27498 - Train Loss: 0.066882, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27499 - Train Loss: 0.066880, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27500 - Train Loss: 0.066879, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27501 - Train Loss: 0.066878, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27502 - Train Loss: 0.066877, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27503 - Train Loss: 0.066876, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27504 - Train Loss: 0.066874, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27505 - Train Loss: 0.066873, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27506 - Train Loss: 0.066872, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27507 - Train Loss: 0.066871, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27508 - Train Loss: 0.066870, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27509 - Train Loss: 0.066869, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27510 - Train Loss: 0.066867, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27511 - Train Loss: 0.066866, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27512 - Train Loss: 0.066865, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27513 - Train Loss: 0.066864, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27514 - Train Loss: 0.066863, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27515 - Train Loss: 0.066861, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27516 - Train Loss: 0.066860, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27517 - Train Loss: 0.066859, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27518 - Train Loss: 0.066858, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27519 - Train Loss: 0.066857, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27520 - Train Loss: 0.066855, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27521 - Train Loss: 0.066854, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27522 - Train Loss: 0.066853, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27523 - Train Loss: 0.066852, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27524 - Train Loss: 0.066851, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27525 - Train Loss: 0.066850, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27526 - Train Loss: 0.066848, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27527 - Train Loss: 0.066847, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27528 - Train Loss: 0.066846, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27529 - Train Loss: 0.066845, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27530 - Train Loss: 0.066844, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 27531 - Train Loss: 0.066842, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27532 - Train Loss: 0.066841, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27533 - Train Loss: 0.066840, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27534 - Train Loss: 0.066839, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27535 - Train Loss: 0.066838, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27536 - Train Loss: 0.066836, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27537 - Train Loss: 0.066835, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27538 - Train Loss: 0.066834, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27539 - Train Loss: 0.066833, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27540 - Train Loss: 0.066832, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27541 - Train Loss: 0.066831, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27542 - Train Loss: 0.066829, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27543 - Train Loss: 0.066828, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27544 - Train Loss: 0.066827, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27545 - Train Loss: 0.066826, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27546 - Train Loss: 0.066825, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27547 - Train Loss: 0.066823, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27548 - Train Loss: 0.066822, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27549 - Train Loss: 0.066821, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27550 - Train Loss: 0.066820, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27551 - Train Loss: 0.066819, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27552 - Train Loss: 0.066817, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27553 - Train Loss: 0.066816, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27554 - Train Loss: 0.066815, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27555 - Train Loss: 0.066814, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27556 - Train Loss: 0.066813, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27557 - Train Loss: 0.066812, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27558 - Train Loss: 0.066810, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27559 - Train Loss: 0.066809, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27560 - Train Loss: 0.066808, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27561 - Train Loss: 0.066807, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27562 - Train Loss: 0.066806, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27563 - Train Loss: 0.066804, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27564 - Train Loss: 0.066803, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27565 - Train Loss: 0.066802, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27566 - Train Loss: 0.066801, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27567 - Train Loss: 0.066800, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27568 - Train Loss: 0.066799, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27569 - Train Loss: 0.066797, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27570 - Train Loss: 0.066796, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27571 - Train Loss: 0.066795, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27572 - Train Loss: 0.066794, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27573 - Train Loss: 0.066793, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27574 - Train Loss: 0.066791, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27575 - Train Loss: 0.066790, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27576 - Train Loss: 0.066789, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27577 - Train Loss: 0.066788, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27578 - Train Loss: 0.066787, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27579 - Train Loss: 0.066785, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27580 - Train Loss: 0.066784, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27581 - Train Loss: 0.066783, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27582 - Train Loss: 0.066782, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27583 - Train Loss: 0.066781, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27584 - Train Loss: 0.066780, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27585 - Train Loss: 0.066778, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27586 - Train Loss: 0.066777, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27587 - Train Loss: 0.066776, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27588 - Train Loss: 0.066775, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27589 - Train Loss: 0.066774, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27590 - Train Loss: 0.066772, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27591 - Train Loss: 0.066771, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 27592 - Train Loss: 0.066770, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27593 - Train Loss: 0.066769, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27594 - Train Loss: 0.066768, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27595 - Train Loss: 0.066767, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27596 - Train Loss: 0.066765, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27597 - Train Loss: 0.066764, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27598 - Train Loss: 0.066763, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27599 - Train Loss: 0.066762, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27600 - Train Loss: 0.066761, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27601 - Train Loss: 0.066759, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27602 - Train Loss: 0.066758, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27603 - Train Loss: 0.066757, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27604 - Train Loss: 0.066756, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27605 - Train Loss: 0.066755, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27606 - Train Loss: 0.066754, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27607 - Train Loss: 0.066752, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27608 - Train Loss: 0.066751, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27609 - Train Loss: 0.066750, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27610 - Train Loss: 0.066749, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27611 - Train Loss: 0.066748, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27612 - Train Loss: 0.066746, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27613 - Train Loss: 0.066745, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27614 - Train Loss: 0.066744, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27615 - Train Loss: 0.066743, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27616 - Train Loss: 0.066742, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27617 - Train Loss: 0.066741, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27618 - Train Loss: 0.066739, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27619 - Train Loss: 0.066738, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27620 - Train Loss: 0.066737, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27621 - Train Loss: 0.066736, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27622 - Train Loss: 0.066735, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27623 - Train Loss: 0.066733, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27624 - Train Loss: 0.066732, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27625 - Train Loss: 0.066731, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27626 - Train Loss: 0.066730, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27627 - Train Loss: 0.066729, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27628 - Train Loss: 0.066728, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27629 - Train Loss: 0.066726, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27630 - Train Loss: 0.066725, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27631 - Train Loss: 0.066724, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27632 - Train Loss: 0.066723, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27633 - Train Loss: 0.066722, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27634 - Train Loss: 0.066720, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27635 - Train Loss: 0.066719, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27636 - Train Loss: 0.066718, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27637 - Train Loss: 0.066717, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27638 - Train Loss: 0.066716, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27639 - Train Loss: 0.066715, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27640 - Train Loss: 0.066713, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27641 - Train Loss: 0.066712, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27642 - Train Loss: 0.066711, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27643 - Train Loss: 0.066710, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27644 - Train Loss: 0.066709, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27645 - Train Loss: 0.066707, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27646 - Train Loss: 0.066706, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27647 - Train Loss: 0.066705, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27648 - Train Loss: 0.066704, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27649 - Train Loss: 0.066703, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27650 - Train Loss: 0.066702, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27651 - Train Loss: 0.066700, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27652 - Train Loss: 0.066699, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27653 - Train Loss: 0.066698, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27654 - Train Loss: 0.066697, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27655 - Train Loss: 0.066696, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27656 - Train Loss: 0.066695, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27657 - Train Loss: 0.066693, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27658 - Train Loss: 0.066692, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27659 - Train Loss: 0.066691, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27660 - Train Loss: 0.066690, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27661 - Train Loss: 0.066689, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27662 - Train Loss: 0.066687, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27663 - Train Loss: 0.066686, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27664 - Train Loss: 0.066685, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27665 - Train Loss: 0.066684, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27666 - Train Loss: 0.066683, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27667 - Train Loss: 0.066682, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27668 - Train Loss: 0.066680, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27669 - Train Loss: 0.066679, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27670 - Train Loss: 0.066678, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27671 - Train Loss: 0.066677, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27672 - Train Loss: 0.066676, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27673 - Train Loss: 0.066674, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27674 - Train Loss: 0.066673, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27675 - Train Loss: 0.066672, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27676 - Train Loss: 0.066671, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27677 - Train Loss: 0.066670, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27678 - Train Loss: 0.066669, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27679 - Train Loss: 0.066667, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27680 - Train Loss: 0.066666, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27681 - Train Loss: 0.066665, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27682 - Train Loss: 0.066664, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27683 - Train Loss: 0.066663, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27684 - Train Loss: 0.066662, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27685 - Train Loss: 0.066660, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27686 - Train Loss: 0.066659, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27687 - Train Loss: 0.066658, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27688 - Train Loss: 0.066657, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27689 - Train Loss: 0.066656, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27690 - Train Loss: 0.066654, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27691 - Train Loss: 0.066653, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27692 - Train Loss: 0.066652, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27693 - Train Loss: 0.066651, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27694 - Train Loss: 0.066650, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27695 - Train Loss: 0.066649, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27696 - Train Loss: 0.066647, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27697 - Train Loss: 0.066646, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27698 - Train Loss: 0.066645, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27699 - Train Loss: 0.066644, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27700 - Train Loss: 0.066643, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27701 - Train Loss: 0.066642, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27702 - Train Loss: 0.066640, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27703 - Train Loss: 0.066639, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27704 - Train Loss: 0.066638, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27705 - Train Loss: 0.066637, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27706 - Train Loss: 0.066636, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27707 - Train Loss: 0.066635, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27708 - Train Loss: 0.066633, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27709 - Train Loss: 0.066632, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27710 - Train Loss: 0.066631, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27711 - Train Loss: 0.066630, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27712 - Train Loss: 0.066629, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27713 - Train Loss: 0.066627, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27714 - Train Loss: 0.066626, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27715 - Train Loss: 0.066625, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27716 - Train Loss: 0.066624, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27717 - Train Loss: 0.066623, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27718 - Train Loss: 0.066622, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27719 - Train Loss: 0.066620, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27720 - Train Loss: 0.066619, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27721 - Train Loss: 0.066618, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27722 - Train Loss: 0.066617, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27723 - Train Loss: 0.066616, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27724 - Train Loss: 0.066615, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27725 - Train Loss: 0.066613, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27726 - Train Loss: 0.066612, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27727 - Train Loss: 0.066611, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27728 - Train Loss: 0.066610, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27729 - Train Loss: 0.066609, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27730 - Train Loss: 0.066607, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27731 - Train Loss: 0.066606, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27732 - Train Loss: 0.066605, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27733 - Train Loss: 0.066604, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27734 - Train Loss: 0.066603, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27735 - Train Loss: 0.066602, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27736 - Train Loss: 0.066600, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27737 - Train Loss: 0.066599, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27738 - Train Loss: 0.066598, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27739 - Train Loss: 0.066597, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27740 - Train Loss: 0.066596, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27741 - Train Loss: 0.066595, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27742 - Train Loss: 0.066593, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27743 - Train Loss: 0.066592, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27744 - Train Loss: 0.066591, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27745 - Train Loss: 0.066590, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27746 - Train Loss: 0.066589, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27747 - Train Loss: 0.066588, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27748 - Train Loss: 0.066586, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27749 - Train Loss: 0.066585, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27750 - Train Loss: 0.066584, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27751 - Train Loss: 0.066583, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27752 - Train Loss: 0.066582, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27753 - Train Loss: 0.066581, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27754 - Train Loss: 0.066579, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27755 - Train Loss: 0.066578, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27756 - Train Loss: 0.066577, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27757 - Train Loss: 0.066576, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27758 - Train Loss: 0.066575, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27759 - Train Loss: 0.066573, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27760 - Train Loss: 0.066572, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27761 - Train Loss: 0.066571, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27762 - Train Loss: 0.066570, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27763 - Train Loss: 0.066569, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27764 - Train Loss: 0.066568, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27765 - Train Loss: 0.066566, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27766 - Train Loss: 0.066565, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27767 - Train Loss: 0.066564, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27768 - Train Loss: 0.066563, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27769 - Train Loss: 0.066562, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27770 - Train Loss: 0.066561, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27771 - Train Loss: 0.066559, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27772 - Train Loss: 0.066558, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27773 - Train Loss: 0.066557, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27774 - Train Loss: 0.066556, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27775 - Train Loss: 0.066555, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27776 - Train Loss: 0.066554, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27777 - Train Loss: 0.066552, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27778 - Train Loss: 0.066551, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27779 - Train Loss: 0.066550, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27780 - Train Loss: 0.066549, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27781 - Train Loss: 0.066548, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27782 - Train Loss: 0.066547, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27783 - Train Loss: 0.066545, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27784 - Train Loss: 0.066544, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27785 - Train Loss: 0.066543, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27786 - Train Loss: 0.066542, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27787 - Train Loss: 0.066541, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27788 - Train Loss: 0.066540, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27789 - Train Loss: 0.066538, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27790 - Train Loss: 0.066537, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27791 - Train Loss: 0.066536, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27792 - Train Loss: 0.066535, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27793 - Train Loss: 0.066534, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27794 - Train Loss: 0.066533, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27795 - Train Loss: 0.066531, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27796 - Train Loss: 0.066530, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27797 - Train Loss: 0.066529, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27798 - Train Loss: 0.066528, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27799 - Train Loss: 0.066527, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27800 - Train Loss: 0.066526, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27801 - Train Loss: 0.066524, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27802 - Train Loss: 0.066523, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27803 - Train Loss: 0.066522, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27804 - Train Loss: 0.066521, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27805 - Train Loss: 0.066520, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27806 - Train Loss: 0.066518, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27807 - Train Loss: 0.066517, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27808 - Train Loss: 0.066516, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27809 - Train Loss: 0.066515, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27810 - Train Loss: 0.066514, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27811 - Train Loss: 0.066513, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27812 - Train Loss: 0.066511, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27813 - Train Loss: 0.066510, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27814 - Train Loss: 0.066509, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27815 - Train Loss: 0.066508, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27816 - Train Loss: 0.066507, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27817 - Train Loss: 0.066506, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27818 - Train Loss: 0.066504, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27819 - Train Loss: 0.066503, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27820 - Train Loss: 0.066502, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27821 - Train Loss: 0.066501, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27822 - Train Loss: 0.066500, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27823 - Train Loss: 0.066499, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27824 - Train Loss: 0.066497, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27825 - Train Loss: 0.066496, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27826 - Train Loss: 0.066495, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27827 - Train Loss: 0.066494, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27828 - Train Loss: 0.066493, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27829 - Train Loss: 0.066492, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27830 - Train Loss: 0.066490, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27831 - Train Loss: 0.066489, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27832 - Train Loss: 0.066488, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27833 - Train Loss: 0.066487, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27834 - Train Loss: 0.066486, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27835 - Train Loss: 0.066485, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27836 - Train Loss: 0.066483, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27837 - Train Loss: 0.066482, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27838 - Train Loss: 0.066481, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27839 - Train Loss: 0.066480, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27840 - Train Loss: 0.066479, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27841 - Train Loss: 0.066478, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27842 - Train Loss: 0.066476, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27843 - Train Loss: 0.066475, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27844 - Train Loss: 0.066474, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27845 - Train Loss: 0.066473, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27846 - Train Loss: 0.066472, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27847 - Train Loss: 0.066471, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27848 - Train Loss: 0.066469, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27849 - Train Loss: 0.066468, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27850 - Train Loss: 0.066467, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27851 - Train Loss: 0.066466, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27852 - Train Loss: 0.066465, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27853 - Train Loss: 0.066464, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27854 - Train Loss: 0.066463, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27855 - Train Loss: 0.066461, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27856 - Train Loss: 0.066460, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27857 - Train Loss: 0.066459, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27858 - Train Loss: 0.066458, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27859 - Train Loss: 0.066457, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27860 - Train Loss: 0.066456, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27861 - Train Loss: 0.066454, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27862 - Train Loss: 0.066453, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27863 - Train Loss: 0.066452, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27864 - Train Loss: 0.066451, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27865 - Train Loss: 0.066450, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27866 - Train Loss: 0.066449, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27867 - Train Loss: 0.066447, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27868 - Train Loss: 0.066446, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27869 - Train Loss: 0.066445, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27870 - Train Loss: 0.066444, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27871 - Train Loss: 0.066443, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27872 - Train Loss: 0.066442, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27873 - Train Loss: 0.066440, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27874 - Train Loss: 0.066439, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27875 - Train Loss: 0.066438, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27876 - Train Loss: 0.066437, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27877 - Train Loss: 0.066436, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27878 - Train Loss: 0.066435, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27879 - Train Loss: 0.066433, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27880 - Train Loss: 0.066432, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27881 - Train Loss: 0.066431, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27882 - Train Loss: 0.066430, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27883 - Train Loss: 0.066429, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27884 - Train Loss: 0.066428, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27885 - Train Loss: 0.066426, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27886 - Train Loss: 0.066425, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27887 - Train Loss: 0.066424, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27888 - Train Loss: 0.066423, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27889 - Train Loss: 0.066422, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27890 - Train Loss: 0.066421, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27891 - Train Loss: 0.066419, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27892 - Train Loss: 0.066418, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27893 - Train Loss: 0.066417, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27894 - Train Loss: 0.066416, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27895 - Train Loss: 0.066415, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27896 - Train Loss: 0.066414, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27897 - Train Loss: 0.066412, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27898 - Train Loss: 0.066411, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27899 - Train Loss: 0.066410, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27900 - Train Loss: 0.066409, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27901 - Train Loss: 0.066408, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27902 - Train Loss: 0.066407, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27903 - Train Loss: 0.066405, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27904 - Train Loss: 0.066404, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27905 - Train Loss: 0.066403, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27906 - Train Loss: 0.066402, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27907 - Train Loss: 0.066401, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27908 - Train Loss: 0.066400, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27909 - Train Loss: 0.066399, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27910 - Train Loss: 0.066397, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27911 - Train Loss: 0.066396, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27912 - Train Loss: 0.066395, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27913 - Train Loss: 0.066394, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27914 - Train Loss: 0.066393, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27915 - Train Loss: 0.066392, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27916 - Train Loss: 0.066390, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27917 - Train Loss: 0.066389, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27918 - Train Loss: 0.066388, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27919 - Train Loss: 0.066387, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27920 - Train Loss: 0.066386, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27921 - Train Loss: 0.066385, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27922 - Train Loss: 0.066383, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27923 - Train Loss: 0.066382, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27924 - Train Loss: 0.066381, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27925 - Train Loss: 0.066380, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27926 - Train Loss: 0.066379, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27927 - Train Loss: 0.066378, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27928 - Train Loss: 0.066376, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27929 - Train Loss: 0.066375, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27930 - Train Loss: 0.066374, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27931 - Train Loss: 0.066373, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27932 - Train Loss: 0.066372, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27933 - Train Loss: 0.066371, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27934 - Train Loss: 0.066370, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27935 - Train Loss: 0.066368, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27936 - Train Loss: 0.066367, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27937 - Train Loss: 0.066366, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27938 - Train Loss: 0.066365, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27939 - Train Loss: 0.066364, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27940 - Train Loss: 0.066363, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27941 - Train Loss: 0.066361, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27942 - Train Loss: 0.066360, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27943 - Train Loss: 0.066359, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27944 - Train Loss: 0.066358, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27945 - Train Loss: 0.066357, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27946 - Train Loss: 0.066356, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27947 - Train Loss: 0.066354, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27948 - Train Loss: 0.066353, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27949 - Train Loss: 0.066352, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27950 - Train Loss: 0.066351, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27951 - Train Loss: 0.066350, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27952 - Train Loss: 0.066349, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27953 - Train Loss: 0.066347, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27954 - Train Loss: 0.066346, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27955 - Train Loss: 0.066345, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27956 - Train Loss: 0.066344, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27957 - Train Loss: 0.066343, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27958 - Train Loss: 0.066342, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27959 - Train Loss: 0.066341, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27960 - Train Loss: 0.066339, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27961 - Train Loss: 0.066338, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27962 - Train Loss: 0.066337, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27963 - Train Loss: 0.066336, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27964 - Train Loss: 0.066335, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27965 - Train Loss: 0.066333, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27966 - Train Loss: 0.066332, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27967 - Train Loss: 0.066331, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27968 - Train Loss: 0.066330, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27969 - Train Loss: 0.066329, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27970 - Train Loss: 0.066328, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27971 - Train Loss: 0.066326, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27972 - Train Loss: 0.066325, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27973 - Train Loss: 0.066324, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27974 - Train Loss: 0.066323, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27975 - Train Loss: 0.066322, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27976 - Train Loss: 0.066320, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27977 - Train Loss: 0.066319, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27978 - Train Loss: 0.066318, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27979 - Train Loss: 0.066317, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27980 - Train Loss: 0.066316, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27981 - Train Loss: 0.066315, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27982 - Train Loss: 0.066313, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27983 - Train Loss: 0.066312, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27984 - Train Loss: 0.066311, Train Acc: 0.898718 | Val Loss: 0.104771, Val Acc: 0.793814\n",
      "Epoch 27985 - Train Loss: 0.066310, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27986 - Train Loss: 0.066309, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27987 - Train Loss: 0.066308, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27988 - Train Loss: 0.066306, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27989 - Train Loss: 0.066305, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27990 - Train Loss: 0.066304, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27991 - Train Loss: 0.066303, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27992 - Train Loss: 0.066302, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27993 - Train Loss: 0.066300, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27994 - Train Loss: 0.066299, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27995 - Train Loss: 0.066298, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27996 - Train Loss: 0.066297, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27997 - Train Loss: 0.066296, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27998 - Train Loss: 0.066295, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 27999 - Train Loss: 0.066293, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 28000 - Train Loss: 0.066292, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 28001 - Train Loss: 0.066291, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 28002 - Train Loss: 0.066290, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 28003 - Train Loss: 0.066289, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 28004 - Train Loss: 0.066287, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 28005 - Train Loss: 0.066286, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 28006 - Train Loss: 0.066285, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 28007 - Train Loss: 0.066284, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 28008 - Train Loss: 0.066283, Train Acc: 0.898718 | Val Loss: 0.104772, Val Acc: 0.793814\n",
      "Epoch 28009 - Train Loss: 0.066282, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28010 - Train Loss: 0.066280, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28011 - Train Loss: 0.066279, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28012 - Train Loss: 0.066278, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28013 - Train Loss: 0.066277, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28014 - Train Loss: 0.066276, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28015 - Train Loss: 0.066274, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28016 - Train Loss: 0.066273, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28017 - Train Loss: 0.066272, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28018 - Train Loss: 0.066271, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28019 - Train Loss: 0.066270, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28020 - Train Loss: 0.066269, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28021 - Train Loss: 0.066267, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28022 - Train Loss: 0.066266, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28023 - Train Loss: 0.066265, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28024 - Train Loss: 0.066264, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28025 - Train Loss: 0.066263, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28026 - Train Loss: 0.066262, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28027 - Train Loss: 0.066260, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28028 - Train Loss: 0.066259, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28029 - Train Loss: 0.066258, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28030 - Train Loss: 0.066257, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28031 - Train Loss: 0.066256, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28032 - Train Loss: 0.066254, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28033 - Train Loss: 0.066253, Train Acc: 0.898718 | Val Loss: 0.104773, Val Acc: 0.793814\n",
      "Epoch 28034 - Train Loss: 0.066252, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28035 - Train Loss: 0.066251, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28036 - Train Loss: 0.066250, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28037 - Train Loss: 0.066249, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28038 - Train Loss: 0.066247, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28039 - Train Loss: 0.066246, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28040 - Train Loss: 0.066245, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28041 - Train Loss: 0.066244, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28042 - Train Loss: 0.066243, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28043 - Train Loss: 0.066242, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28044 - Train Loss: 0.066240, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28045 - Train Loss: 0.066239, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28046 - Train Loss: 0.066238, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28047 - Train Loss: 0.066237, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28048 - Train Loss: 0.066236, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28049 - Train Loss: 0.066234, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28050 - Train Loss: 0.066233, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28051 - Train Loss: 0.066232, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28052 - Train Loss: 0.066231, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28053 - Train Loss: 0.066230, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28054 - Train Loss: 0.066229, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28055 - Train Loss: 0.066227, Train Acc: 0.898718 | Val Loss: 0.104774, Val Acc: 0.793814\n",
      "Epoch 28056 - Train Loss: 0.066226, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28057 - Train Loss: 0.066225, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28058 - Train Loss: 0.066224, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28059 - Train Loss: 0.066223, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28060 - Train Loss: 0.066222, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28061 - Train Loss: 0.066220, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28062 - Train Loss: 0.066219, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28063 - Train Loss: 0.066218, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28064 - Train Loss: 0.066217, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28065 - Train Loss: 0.066216, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28066 - Train Loss: 0.066214, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28067 - Train Loss: 0.066213, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28068 - Train Loss: 0.066212, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28069 - Train Loss: 0.066211, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28070 - Train Loss: 0.066210, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28071 - Train Loss: 0.066209, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28072 - Train Loss: 0.066207, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28073 - Train Loss: 0.066206, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28074 - Train Loss: 0.066205, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28075 - Train Loss: 0.066204, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28076 - Train Loss: 0.066203, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28077 - Train Loss: 0.066202, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28078 - Train Loss: 0.066200, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28079 - Train Loss: 0.066199, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28080 - Train Loss: 0.066198, Train Acc: 0.898718 | Val Loss: 0.104775, Val Acc: 0.793814\n",
      "Epoch 28081 - Train Loss: 0.066197, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28082 - Train Loss: 0.066196, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28083 - Train Loss: 0.066195, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28084 - Train Loss: 0.066193, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28085 - Train Loss: 0.066192, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28086 - Train Loss: 0.066191, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28087 - Train Loss: 0.066190, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28088 - Train Loss: 0.066189, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28089 - Train Loss: 0.066187, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28090 - Train Loss: 0.066186, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28091 - Train Loss: 0.066185, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28092 - Train Loss: 0.066184, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28093 - Train Loss: 0.066183, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28094 - Train Loss: 0.066182, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28095 - Train Loss: 0.066180, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28096 - Train Loss: 0.066179, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28097 - Train Loss: 0.066178, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28098 - Train Loss: 0.066177, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28099 - Train Loss: 0.066176, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28100 - Train Loss: 0.066175, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28101 - Train Loss: 0.066173, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28102 - Train Loss: 0.066172, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28103 - Train Loss: 0.066171, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28104 - Train Loss: 0.066170, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28105 - Train Loss: 0.066169, Train Acc: 0.898718 | Val Loss: 0.104776, Val Acc: 0.793814\n",
      "Epoch 28106 - Train Loss: 0.066168, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28107 - Train Loss: 0.066166, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28108 - Train Loss: 0.066165, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28109 - Train Loss: 0.066164, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28110 - Train Loss: 0.066163, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28111 - Train Loss: 0.066162, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28112 - Train Loss: 0.066160, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28113 - Train Loss: 0.066159, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28114 - Train Loss: 0.066158, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28115 - Train Loss: 0.066157, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28116 - Train Loss: 0.066156, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28117 - Train Loss: 0.066155, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28118 - Train Loss: 0.066153, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28119 - Train Loss: 0.066152, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28120 - Train Loss: 0.066151, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28121 - Train Loss: 0.066150, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28122 - Train Loss: 0.066149, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28123 - Train Loss: 0.066148, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28124 - Train Loss: 0.066146, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28125 - Train Loss: 0.066145, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28126 - Train Loss: 0.066144, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28127 - Train Loss: 0.066143, Train Acc: 0.898718 | Val Loss: 0.104777, Val Acc: 0.793814\n",
      "Epoch 28128 - Train Loss: 0.066142, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28129 - Train Loss: 0.066141, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28130 - Train Loss: 0.066139, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28131 - Train Loss: 0.066138, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28132 - Train Loss: 0.066137, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28133 - Train Loss: 0.066136, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28134 - Train Loss: 0.066135, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28135 - Train Loss: 0.066134, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28136 - Train Loss: 0.066132, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28137 - Train Loss: 0.066131, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28138 - Train Loss: 0.066130, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28139 - Train Loss: 0.066129, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28140 - Train Loss: 0.066128, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28141 - Train Loss: 0.066127, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28142 - Train Loss: 0.066125, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28143 - Train Loss: 0.066124, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28144 - Train Loss: 0.066123, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28145 - Train Loss: 0.066122, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28146 - Train Loss: 0.066121, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28147 - Train Loss: 0.066120, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28148 - Train Loss: 0.066118, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28149 - Train Loss: 0.066117, Train Acc: 0.898718 | Val Loss: 0.104778, Val Acc: 0.793814\n",
      "Epoch 28150 - Train Loss: 0.066116, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28151 - Train Loss: 0.066115, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28152 - Train Loss: 0.066114, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28153 - Train Loss: 0.066113, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28154 - Train Loss: 0.066111, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28155 - Train Loss: 0.066110, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28156 - Train Loss: 0.066109, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28157 - Train Loss: 0.066108, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28158 - Train Loss: 0.066107, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28159 - Train Loss: 0.066106, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28160 - Train Loss: 0.066104, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28161 - Train Loss: 0.066103, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28162 - Train Loss: 0.066102, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28163 - Train Loss: 0.066101, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28164 - Train Loss: 0.066100, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28165 - Train Loss: 0.066099, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28166 - Train Loss: 0.066097, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28167 - Train Loss: 0.066096, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28168 - Train Loss: 0.066095, Train Acc: 0.898718 | Val Loss: 0.104779, Val Acc: 0.793814\n",
      "Epoch 28169 - Train Loss: 0.066094, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28170 - Train Loss: 0.066093, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28171 - Train Loss: 0.066092, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28172 - Train Loss: 0.066090, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28173 - Train Loss: 0.066089, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28174 - Train Loss: 0.066088, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28175 - Train Loss: 0.066087, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28176 - Train Loss: 0.066086, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28177 - Train Loss: 0.066085, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28178 - Train Loss: 0.066083, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28179 - Train Loss: 0.066082, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28180 - Train Loss: 0.066081, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28181 - Train Loss: 0.066080, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28182 - Train Loss: 0.066079, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28183 - Train Loss: 0.066078, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28184 - Train Loss: 0.066076, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28185 - Train Loss: 0.066075, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28186 - Train Loss: 0.066074, Train Acc: 0.900000 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28187 - Train Loss: 0.066073, Train Acc: 0.898718 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28188 - Train Loss: 0.066072, Train Acc: 0.900000 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28189 - Train Loss: 0.066071, Train Acc: 0.900000 | Val Loss: 0.104780, Val Acc: 0.793814\n",
      "Epoch 28190 - Train Loss: 0.066069, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28191 - Train Loss: 0.066068, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28192 - Train Loss: 0.066067, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28193 - Train Loss: 0.066066, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28194 - Train Loss: 0.066065, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28195 - Train Loss: 0.066064, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28196 - Train Loss: 0.066062, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28197 - Train Loss: 0.066061, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28198 - Train Loss: 0.066060, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28199 - Train Loss: 0.066059, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28200 - Train Loss: 0.066058, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28201 - Train Loss: 0.066057, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28202 - Train Loss: 0.066055, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28203 - Train Loss: 0.066054, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28204 - Train Loss: 0.066053, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28205 - Train Loss: 0.066052, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28206 - Train Loss: 0.066051, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28207 - Train Loss: 0.066050, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28208 - Train Loss: 0.066048, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28209 - Train Loss: 0.066047, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28210 - Train Loss: 0.066046, Train Acc: 0.900000 | Val Loss: 0.104781, Val Acc: 0.793814\n",
      "Epoch 28211 - Train Loss: 0.066045, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28212 - Train Loss: 0.066044, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28213 - Train Loss: 0.066043, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28214 - Train Loss: 0.066041, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28215 - Train Loss: 0.066040, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28216 - Train Loss: 0.066039, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28217 - Train Loss: 0.066038, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28218 - Train Loss: 0.066037, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28219 - Train Loss: 0.066036, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28220 - Train Loss: 0.066034, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28221 - Train Loss: 0.066033, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28222 - Train Loss: 0.066032, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28223 - Train Loss: 0.066031, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28224 - Train Loss: 0.066030, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28225 - Train Loss: 0.066029, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28226 - Train Loss: 0.066028, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28227 - Train Loss: 0.066026, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28228 - Train Loss: 0.066025, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28229 - Train Loss: 0.066024, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28230 - Train Loss: 0.066023, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28231 - Train Loss: 0.066022, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28232 - Train Loss: 0.066021, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28233 - Train Loss: 0.066019, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28234 - Train Loss: 0.066018, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28235 - Train Loss: 0.066017, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28236 - Train Loss: 0.066016, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28237 - Train Loss: 0.066015, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28238 - Train Loss: 0.066014, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28239 - Train Loss: 0.066012, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28240 - Train Loss: 0.066011, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28241 - Train Loss: 0.066010, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28242 - Train Loss: 0.066009, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28243 - Train Loss: 0.066008, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28244 - Train Loss: 0.066007, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28245 - Train Loss: 0.066005, Train Acc: 0.900000 | Val Loss: 0.104782, Val Acc: 0.793814\n",
      "Epoch 28246 - Train Loss: 0.066004, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28247 - Train Loss: 0.066003, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28248 - Train Loss: 0.066002, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28249 - Train Loss: 0.066001, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28250 - Train Loss: 0.066000, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28251 - Train Loss: 0.065998, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28252 - Train Loss: 0.065997, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28253 - Train Loss: 0.065996, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28254 - Train Loss: 0.065995, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28255 - Train Loss: 0.065994, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28256 - Train Loss: 0.065993, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28257 - Train Loss: 0.065992, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28258 - Train Loss: 0.065990, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28259 - Train Loss: 0.065989, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28260 - Train Loss: 0.065988, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28261 - Train Loss: 0.065987, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28262 - Train Loss: 0.065986, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28263 - Train Loss: 0.065985, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28264 - Train Loss: 0.065983, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28265 - Train Loss: 0.065982, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28266 - Train Loss: 0.065981, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28267 - Train Loss: 0.065980, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28268 - Train Loss: 0.065979, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28269 - Train Loss: 0.065978, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28270 - Train Loss: 0.065976, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28271 - Train Loss: 0.065975, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28272 - Train Loss: 0.065974, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28273 - Train Loss: 0.065973, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28274 - Train Loss: 0.065972, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28275 - Train Loss: 0.065971, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28276 - Train Loss: 0.065970, Train Acc: 0.900000 | Val Loss: 0.104783, Val Acc: 0.793814\n",
      "Epoch 28277 - Train Loss: 0.065968, Train Acc: 0.900000 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28278 - Train Loss: 0.065967, Train Acc: 0.900000 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28279 - Train Loss: 0.065966, Train Acc: 0.900000 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28280 - Train Loss: 0.065965, Train Acc: 0.900000 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28281 - Train Loss: 0.065964, Train Acc: 0.900000 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28282 - Train Loss: 0.065963, Train Acc: 0.900000 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28283 - Train Loss: 0.065961, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28284 - Train Loss: 0.065960, Train Acc: 0.900000 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28285 - Train Loss: 0.065959, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28286 - Train Loss: 0.065958, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28287 - Train Loss: 0.065957, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28288 - Train Loss: 0.065956, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28289 - Train Loss: 0.065954, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28290 - Train Loss: 0.065953, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28291 - Train Loss: 0.065952, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28292 - Train Loss: 0.065951, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28293 - Train Loss: 0.065950, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28294 - Train Loss: 0.065949, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28295 - Train Loss: 0.065948, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28296 - Train Loss: 0.065946, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28297 - Train Loss: 0.065945, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28298 - Train Loss: 0.065944, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28299 - Train Loss: 0.065943, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28300 - Train Loss: 0.065942, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28301 - Train Loss: 0.065941, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28302 - Train Loss: 0.065939, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28303 - Train Loss: 0.065938, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28304 - Train Loss: 0.065937, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28305 - Train Loss: 0.065936, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28306 - Train Loss: 0.065935, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28307 - Train Loss: 0.065934, Train Acc: 0.898718 | Val Loss: 0.104784, Val Acc: 0.793814\n",
      "Epoch 28308 - Train Loss: 0.065933, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28309 - Train Loss: 0.065931, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28310 - Train Loss: 0.065930, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28311 - Train Loss: 0.065929, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28312 - Train Loss: 0.065928, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28313 - Train Loss: 0.065927, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28314 - Train Loss: 0.065926, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28315 - Train Loss: 0.065924, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28316 - Train Loss: 0.065923, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28317 - Train Loss: 0.065922, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28318 - Train Loss: 0.065921, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28319 - Train Loss: 0.065920, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28320 - Train Loss: 0.065919, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28321 - Train Loss: 0.065918, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28322 - Train Loss: 0.065916, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28323 - Train Loss: 0.065915, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28324 - Train Loss: 0.065914, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28325 - Train Loss: 0.065913, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28326 - Train Loss: 0.065912, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28327 - Train Loss: 0.065911, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28328 - Train Loss: 0.065909, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28329 - Train Loss: 0.065908, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28330 - Train Loss: 0.065907, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28331 - Train Loss: 0.065906, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28332 - Train Loss: 0.065905, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28333 - Train Loss: 0.065904, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28334 - Train Loss: 0.065903, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28335 - Train Loss: 0.065901, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28336 - Train Loss: 0.065900, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28337 - Train Loss: 0.065899, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28338 - Train Loss: 0.065898, Train Acc: 0.898718 | Val Loss: 0.104785, Val Acc: 0.793814\n",
      "Epoch 28339 - Train Loss: 0.065897, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28340 - Train Loss: 0.065896, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28341 - Train Loss: 0.065894, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28342 - Train Loss: 0.065893, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28343 - Train Loss: 0.065892, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28344 - Train Loss: 0.065891, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28345 - Train Loss: 0.065890, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28346 - Train Loss: 0.065889, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28347 - Train Loss: 0.065888, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28348 - Train Loss: 0.065886, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28349 - Train Loss: 0.065885, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28350 - Train Loss: 0.065884, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28351 - Train Loss: 0.065883, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28352 - Train Loss: 0.065882, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28353 - Train Loss: 0.065881, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28354 - Train Loss: 0.065879, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28355 - Train Loss: 0.065878, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28356 - Train Loss: 0.065877, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28357 - Train Loss: 0.065876, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28358 - Train Loss: 0.065875, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28359 - Train Loss: 0.065874, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28360 - Train Loss: 0.065873, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28361 - Train Loss: 0.065871, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28362 - Train Loss: 0.065870, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28363 - Train Loss: 0.065869, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28364 - Train Loss: 0.065868, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28365 - Train Loss: 0.065867, Train Acc: 0.898718 | Val Loss: 0.104786, Val Acc: 0.793814\n",
      "Epoch 28366 - Train Loss: 0.065866, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28367 - Train Loss: 0.065865, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28368 - Train Loss: 0.065863, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28369 - Train Loss: 0.065862, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28370 - Train Loss: 0.065861, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28371 - Train Loss: 0.065860, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28372 - Train Loss: 0.065859, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28373 - Train Loss: 0.065858, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28374 - Train Loss: 0.065856, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28375 - Train Loss: 0.065855, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28376 - Train Loss: 0.065854, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28377 - Train Loss: 0.065853, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28378 - Train Loss: 0.065852, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28379 - Train Loss: 0.065851, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28380 - Train Loss: 0.065850, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28381 - Train Loss: 0.065848, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28382 - Train Loss: 0.065847, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28383 - Train Loss: 0.065846, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28384 - Train Loss: 0.065845, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28385 - Train Loss: 0.065844, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28386 - Train Loss: 0.065843, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28387 - Train Loss: 0.065842, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28388 - Train Loss: 0.065840, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28389 - Train Loss: 0.065839, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28390 - Train Loss: 0.065838, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28391 - Train Loss: 0.065837, Train Acc: 0.898718 | Val Loss: 0.104787, Val Acc: 0.793814\n",
      "Epoch 28392 - Train Loss: 0.065836, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28393 - Train Loss: 0.065835, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28394 - Train Loss: 0.065834, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28395 - Train Loss: 0.065832, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28396 - Train Loss: 0.065831, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28397 - Train Loss: 0.065830, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28398 - Train Loss: 0.065829, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28399 - Train Loss: 0.065828, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28400 - Train Loss: 0.065827, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28401 - Train Loss: 0.065825, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28402 - Train Loss: 0.065824, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28403 - Train Loss: 0.065823, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28404 - Train Loss: 0.065822, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28405 - Train Loss: 0.065821, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28406 - Train Loss: 0.065820, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28407 - Train Loss: 0.065819, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28408 - Train Loss: 0.065817, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28409 - Train Loss: 0.065816, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28410 - Train Loss: 0.065815, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28411 - Train Loss: 0.065814, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28412 - Train Loss: 0.065813, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28413 - Train Loss: 0.065812, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28414 - Train Loss: 0.065811, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28415 - Train Loss: 0.065809, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28416 - Train Loss: 0.065808, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28417 - Train Loss: 0.065807, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28418 - Train Loss: 0.065806, Train Acc: 0.898718 | Val Loss: 0.104788, Val Acc: 0.793814\n",
      "Epoch 28419 - Train Loss: 0.065805, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28420 - Train Loss: 0.065804, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28421 - Train Loss: 0.065803, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28422 - Train Loss: 0.065801, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28423 - Train Loss: 0.065800, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28424 - Train Loss: 0.065799, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28425 - Train Loss: 0.065798, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28426 - Train Loss: 0.065797, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28427 - Train Loss: 0.065796, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28428 - Train Loss: 0.065795, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28429 - Train Loss: 0.065793, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28430 - Train Loss: 0.065792, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28431 - Train Loss: 0.065791, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28432 - Train Loss: 0.065790, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28433 - Train Loss: 0.065789, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28434 - Train Loss: 0.065788, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28435 - Train Loss: 0.065787, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28436 - Train Loss: 0.065785, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28437 - Train Loss: 0.065784, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28438 - Train Loss: 0.065783, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28439 - Train Loss: 0.065782, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28440 - Train Loss: 0.065781, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28441 - Train Loss: 0.065780, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28442 - Train Loss: 0.065779, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28443 - Train Loss: 0.065777, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28444 - Train Loss: 0.065776, Train Acc: 0.898718 | Val Loss: 0.104789, Val Acc: 0.793814\n",
      "Epoch 28445 - Train Loss: 0.065775, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28446 - Train Loss: 0.065774, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28447 - Train Loss: 0.065773, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28448 - Train Loss: 0.065772, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28449 - Train Loss: 0.065771, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28450 - Train Loss: 0.065769, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28451 - Train Loss: 0.065768, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28452 - Train Loss: 0.065767, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28453 - Train Loss: 0.065766, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28454 - Train Loss: 0.065765, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28455 - Train Loss: 0.065764, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28456 - Train Loss: 0.065763, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28457 - Train Loss: 0.065761, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28458 - Train Loss: 0.065760, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28459 - Train Loss: 0.065759, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28460 - Train Loss: 0.065758, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28461 - Train Loss: 0.065757, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28462 - Train Loss: 0.065756, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28463 - Train Loss: 0.065755, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28464 - Train Loss: 0.065753, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28465 - Train Loss: 0.065752, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28466 - Train Loss: 0.065751, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28467 - Train Loss: 0.065750, Train Acc: 0.898718 | Val Loss: 0.104790, Val Acc: 0.793814\n",
      "Epoch 28468 - Train Loss: 0.065749, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28469 - Train Loss: 0.065748, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28470 - Train Loss: 0.065747, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28471 - Train Loss: 0.065745, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28472 - Train Loss: 0.065744, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28473 - Train Loss: 0.065743, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28474 - Train Loss: 0.065742, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28475 - Train Loss: 0.065741, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28476 - Train Loss: 0.065740, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28477 - Train Loss: 0.065739, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28478 - Train Loss: 0.065737, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28479 - Train Loss: 0.065736, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28480 - Train Loss: 0.065735, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28481 - Train Loss: 0.065734, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28482 - Train Loss: 0.065733, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28483 - Train Loss: 0.065732, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28484 - Train Loss: 0.065731, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28485 - Train Loss: 0.065729, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28486 - Train Loss: 0.065728, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28487 - Train Loss: 0.065727, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28488 - Train Loss: 0.065726, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28489 - Train Loss: 0.065725, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28490 - Train Loss: 0.065724, Train Acc: 0.898718 | Val Loss: 0.104791, Val Acc: 0.793814\n",
      "Epoch 28491 - Train Loss: 0.065723, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28492 - Train Loss: 0.065721, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28493 - Train Loss: 0.065720, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28494 - Train Loss: 0.065719, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28495 - Train Loss: 0.065718, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28496 - Train Loss: 0.065717, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28497 - Train Loss: 0.065716, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28498 - Train Loss: 0.065715, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28499 - Train Loss: 0.065713, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28500 - Train Loss: 0.065712, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28501 - Train Loss: 0.065711, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28502 - Train Loss: 0.065710, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28503 - Train Loss: 0.065709, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28504 - Train Loss: 0.065708, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28505 - Train Loss: 0.065707, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28506 - Train Loss: 0.065705, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28507 - Train Loss: 0.065704, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28508 - Train Loss: 0.065703, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28509 - Train Loss: 0.065702, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28510 - Train Loss: 0.065701, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28511 - Train Loss: 0.065700, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28512 - Train Loss: 0.065699, Train Acc: 0.898718 | Val Loss: 0.104792, Val Acc: 0.793814\n",
      "Epoch 28513 - Train Loss: 0.065697, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28514 - Train Loss: 0.065696, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28515 - Train Loss: 0.065695, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28516 - Train Loss: 0.065694, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28517 - Train Loss: 0.065693, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28518 - Train Loss: 0.065692, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28519 - Train Loss: 0.065691, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28520 - Train Loss: 0.065689, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28521 - Train Loss: 0.065688, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28522 - Train Loss: 0.065687, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28523 - Train Loss: 0.065686, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28524 - Train Loss: 0.065685, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28525 - Train Loss: 0.065684, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28526 - Train Loss: 0.065683, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28527 - Train Loss: 0.065682, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28528 - Train Loss: 0.065680, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28529 - Train Loss: 0.065679, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28530 - Train Loss: 0.065678, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28531 - Train Loss: 0.065677, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28532 - Train Loss: 0.065676, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28533 - Train Loss: 0.065675, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28534 - Train Loss: 0.065674, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28535 - Train Loss: 0.065672, Train Acc: 0.898718 | Val Loss: 0.104793, Val Acc: 0.793814\n",
      "Epoch 28536 - Train Loss: 0.065671, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28537 - Train Loss: 0.065670, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28538 - Train Loss: 0.065669, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28539 - Train Loss: 0.065668, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28540 - Train Loss: 0.065667, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28541 - Train Loss: 0.065666, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28542 - Train Loss: 0.065664, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28543 - Train Loss: 0.065663, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28544 - Train Loss: 0.065662, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28545 - Train Loss: 0.065661, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28546 - Train Loss: 0.065660, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28547 - Train Loss: 0.065659, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28548 - Train Loss: 0.065658, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28549 - Train Loss: 0.065656, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28550 - Train Loss: 0.065655, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28551 - Train Loss: 0.065654, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28552 - Train Loss: 0.065653, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28553 - Train Loss: 0.065652, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28554 - Train Loss: 0.065651, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28555 - Train Loss: 0.065650, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28556 - Train Loss: 0.065649, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28557 - Train Loss: 0.065647, Train Acc: 0.898718 | Val Loss: 0.104794, Val Acc: 0.793814\n",
      "Epoch 28558 - Train Loss: 0.065646, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28559 - Train Loss: 0.065645, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28560 - Train Loss: 0.065644, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28561 - Train Loss: 0.065643, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28562 - Train Loss: 0.065642, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28563 - Train Loss: 0.065641, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28564 - Train Loss: 0.065639, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28565 - Train Loss: 0.065638, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28566 - Train Loss: 0.065637, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28567 - Train Loss: 0.065636, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28568 - Train Loss: 0.065635, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28569 - Train Loss: 0.065634, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28570 - Train Loss: 0.065633, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28571 - Train Loss: 0.065631, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28572 - Train Loss: 0.065630, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28573 - Train Loss: 0.065629, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28574 - Train Loss: 0.065628, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28575 - Train Loss: 0.065627, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28576 - Train Loss: 0.065626, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28577 - Train Loss: 0.065625, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28578 - Train Loss: 0.065624, Train Acc: 0.898718 | Val Loss: 0.104795, Val Acc: 0.793814\n",
      "Epoch 28579 - Train Loss: 0.065622, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28580 - Train Loss: 0.065621, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28581 - Train Loss: 0.065620, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28582 - Train Loss: 0.065619, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28583 - Train Loss: 0.065618, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28584 - Train Loss: 0.065617, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28585 - Train Loss: 0.065616, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28586 - Train Loss: 0.065614, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28587 - Train Loss: 0.065613, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28588 - Train Loss: 0.065612, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28589 - Train Loss: 0.065611, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28590 - Train Loss: 0.065610, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28591 - Train Loss: 0.065609, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28592 - Train Loss: 0.065608, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28593 - Train Loss: 0.065607, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28594 - Train Loss: 0.065605, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28595 - Train Loss: 0.065604, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28596 - Train Loss: 0.065603, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28597 - Train Loss: 0.065602, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28598 - Train Loss: 0.065601, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28599 - Train Loss: 0.065600, Train Acc: 0.898718 | Val Loss: 0.104796, Val Acc: 0.793814\n",
      "Epoch 28600 - Train Loss: 0.065599, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28601 - Train Loss: 0.065597, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28602 - Train Loss: 0.065596, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28603 - Train Loss: 0.065595, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28604 - Train Loss: 0.065594, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28605 - Train Loss: 0.065593, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28606 - Train Loss: 0.065592, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28607 - Train Loss: 0.065591, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28608 - Train Loss: 0.065589, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28609 - Train Loss: 0.065588, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28610 - Train Loss: 0.065587, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28611 - Train Loss: 0.065586, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28612 - Train Loss: 0.065585, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28613 - Train Loss: 0.065584, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28614 - Train Loss: 0.065583, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28615 - Train Loss: 0.065582, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28616 - Train Loss: 0.065580, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28617 - Train Loss: 0.065579, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28618 - Train Loss: 0.065578, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28619 - Train Loss: 0.065577, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28620 - Train Loss: 0.065576, Train Acc: 0.898718 | Val Loss: 0.104797, Val Acc: 0.793814\n",
      "Epoch 28621 - Train Loss: 0.065575, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28622 - Train Loss: 0.065574, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28623 - Train Loss: 0.065573, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28624 - Train Loss: 0.065571, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28625 - Train Loss: 0.065570, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28626 - Train Loss: 0.065569, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28627 - Train Loss: 0.065568, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28628 - Train Loss: 0.065567, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28629 - Train Loss: 0.065566, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28630 - Train Loss: 0.065565, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28631 - Train Loss: 0.065563, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28632 - Train Loss: 0.065562, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28633 - Train Loss: 0.065561, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28634 - Train Loss: 0.065560, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28635 - Train Loss: 0.065559, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28636 - Train Loss: 0.065558, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28637 - Train Loss: 0.065557, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28638 - Train Loss: 0.065556, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28639 - Train Loss: 0.065554, Train Acc: 0.898718 | Val Loss: 0.104798, Val Acc: 0.793814\n",
      "Epoch 28640 - Train Loss: 0.065553, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28641 - Train Loss: 0.065552, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28642 - Train Loss: 0.065551, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28643 - Train Loss: 0.065550, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28644 - Train Loss: 0.065549, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28645 - Train Loss: 0.065548, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28646 - Train Loss: 0.065546, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28647 - Train Loss: 0.065545, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28648 - Train Loss: 0.065544, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28649 - Train Loss: 0.065543, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28650 - Train Loss: 0.065542, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28651 - Train Loss: 0.065541, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28652 - Train Loss: 0.065540, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28653 - Train Loss: 0.065539, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28654 - Train Loss: 0.065537, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28655 - Train Loss: 0.065536, Train Acc: 0.898718 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28656 - Train Loss: 0.065535, Train Acc: 0.897436 | Val Loss: 0.104799, Val Acc: 0.793814\n",
      "Epoch 28657 - Train Loss: 0.065534, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28658 - Train Loss: 0.065533, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28659 - Train Loss: 0.065532, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28660 - Train Loss: 0.065531, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28661 - Train Loss: 0.065530, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28662 - Train Loss: 0.065528, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28663 - Train Loss: 0.065527, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28664 - Train Loss: 0.065526, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28665 - Train Loss: 0.065525, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28666 - Train Loss: 0.065524, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28667 - Train Loss: 0.065523, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28668 - Train Loss: 0.065522, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28669 - Train Loss: 0.065520, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28670 - Train Loss: 0.065519, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28671 - Train Loss: 0.065518, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28672 - Train Loss: 0.065517, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28673 - Train Loss: 0.065516, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28674 - Train Loss: 0.065515, Train Acc: 0.897436 | Val Loss: 0.104800, Val Acc: 0.793814\n",
      "Epoch 28675 - Train Loss: 0.065514, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28676 - Train Loss: 0.065513, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28677 - Train Loss: 0.065511, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28678 - Train Loss: 0.065510, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28679 - Train Loss: 0.065509, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28680 - Train Loss: 0.065508, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28681 - Train Loss: 0.065507, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28682 - Train Loss: 0.065506, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28683 - Train Loss: 0.065505, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28684 - Train Loss: 0.065504, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28685 - Train Loss: 0.065502, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28686 - Train Loss: 0.065501, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28687 - Train Loss: 0.065500, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28688 - Train Loss: 0.065499, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28689 - Train Loss: 0.065498, Train Acc: 0.897436 | Val Loss: 0.104801, Val Acc: 0.793814\n",
      "Epoch 28690 - Train Loss: 0.065497, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28691 - Train Loss: 0.065496, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28692 - Train Loss: 0.065495, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28693 - Train Loss: 0.065493, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28694 - Train Loss: 0.065492, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28695 - Train Loss: 0.065491, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28696 - Train Loss: 0.065490, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28697 - Train Loss: 0.065489, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28698 - Train Loss: 0.065488, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28699 - Train Loss: 0.065487, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28700 - Train Loss: 0.065485, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28701 - Train Loss: 0.065484, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28702 - Train Loss: 0.065483, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28703 - Train Loss: 0.065482, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28704 - Train Loss: 0.065481, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28705 - Train Loss: 0.065480, Train Acc: 0.897436 | Val Loss: 0.104802, Val Acc: 0.793814\n",
      "Epoch 28706 - Train Loss: 0.065479, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28707 - Train Loss: 0.065478, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28708 - Train Loss: 0.065476, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28709 - Train Loss: 0.065475, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28710 - Train Loss: 0.065474, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28711 - Train Loss: 0.065473, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28712 - Train Loss: 0.065472, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28713 - Train Loss: 0.065471, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28714 - Train Loss: 0.065470, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28715 - Train Loss: 0.065469, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28716 - Train Loss: 0.065467, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28717 - Train Loss: 0.065466, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28718 - Train Loss: 0.065465, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28719 - Train Loss: 0.065464, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28720 - Train Loss: 0.065463, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28721 - Train Loss: 0.065462, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28722 - Train Loss: 0.065461, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28723 - Train Loss: 0.065460, Train Acc: 0.897436 | Val Loss: 0.104803, Val Acc: 0.793814\n",
      "Epoch 28724 - Train Loss: 0.065458, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28725 - Train Loss: 0.065457, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28726 - Train Loss: 0.065456, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28727 - Train Loss: 0.065455, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28728 - Train Loss: 0.065454, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28729 - Train Loss: 0.065453, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28730 - Train Loss: 0.065452, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28731 - Train Loss: 0.065451, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28732 - Train Loss: 0.065449, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28733 - Train Loss: 0.065448, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28734 - Train Loss: 0.065447, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28735 - Train Loss: 0.065446, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28736 - Train Loss: 0.065445, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28737 - Train Loss: 0.065444, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28738 - Train Loss: 0.065443, Train Acc: 0.897436 | Val Loss: 0.104804, Val Acc: 0.793814\n",
      "Epoch 28739 - Train Loss: 0.065442, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28740 - Train Loss: 0.065441, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28741 - Train Loss: 0.065439, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28742 - Train Loss: 0.065438, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28743 - Train Loss: 0.065437, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28744 - Train Loss: 0.065436, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28745 - Train Loss: 0.065435, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28746 - Train Loss: 0.065434, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28747 - Train Loss: 0.065433, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28748 - Train Loss: 0.065432, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28749 - Train Loss: 0.065430, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28750 - Train Loss: 0.065429, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28751 - Train Loss: 0.065428, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28752 - Train Loss: 0.065427, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28753 - Train Loss: 0.065426, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28754 - Train Loss: 0.065425, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28755 - Train Loss: 0.065424, Train Acc: 0.897436 | Val Loss: 0.104805, Val Acc: 0.793814\n",
      "Epoch 28756 - Train Loss: 0.065423, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28757 - Train Loss: 0.065421, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28758 - Train Loss: 0.065420, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28759 - Train Loss: 0.065419, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28760 - Train Loss: 0.065418, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28761 - Train Loss: 0.065417, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28762 - Train Loss: 0.065416, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28763 - Train Loss: 0.065415, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28764 - Train Loss: 0.065414, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28765 - Train Loss: 0.065412, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28766 - Train Loss: 0.065411, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28767 - Train Loss: 0.065410, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28768 - Train Loss: 0.065409, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28769 - Train Loss: 0.065408, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28770 - Train Loss: 0.065407, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28771 - Train Loss: 0.065406, Train Acc: 0.897436 | Val Loss: 0.104806, Val Acc: 0.793814\n",
      "Epoch 28772 - Train Loss: 0.065405, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28773 - Train Loss: 0.065403, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28774 - Train Loss: 0.065402, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28775 - Train Loss: 0.065401, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28776 - Train Loss: 0.065400, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28777 - Train Loss: 0.065399, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28778 - Train Loss: 0.065398, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28779 - Train Loss: 0.065397, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28780 - Train Loss: 0.065396, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28781 - Train Loss: 0.065395, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28782 - Train Loss: 0.065393, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28783 - Train Loss: 0.065392, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28784 - Train Loss: 0.065391, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28785 - Train Loss: 0.065390, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28786 - Train Loss: 0.065389, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28787 - Train Loss: 0.065388, Train Acc: 0.897436 | Val Loss: 0.104807, Val Acc: 0.793814\n",
      "Epoch 28788 - Train Loss: 0.065387, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28789 - Train Loss: 0.065386, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28790 - Train Loss: 0.065384, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28791 - Train Loss: 0.065383, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28792 - Train Loss: 0.065382, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28793 - Train Loss: 0.065381, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28794 - Train Loss: 0.065380, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28795 - Train Loss: 0.065379, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28796 - Train Loss: 0.065378, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28797 - Train Loss: 0.065377, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28798 - Train Loss: 0.065375, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28799 - Train Loss: 0.065374, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28800 - Train Loss: 0.065373, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28801 - Train Loss: 0.065372, Train Acc: 0.897436 | Val Loss: 0.104808, Val Acc: 0.793814\n",
      "Epoch 28802 - Train Loss: 0.065371, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28803 - Train Loss: 0.065370, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28804 - Train Loss: 0.065369, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28805 - Train Loss: 0.065368, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28806 - Train Loss: 0.065366, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28807 - Train Loss: 0.065365, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28808 - Train Loss: 0.065364, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28809 - Train Loss: 0.065363, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28810 - Train Loss: 0.065362, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28811 - Train Loss: 0.065361, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28812 - Train Loss: 0.065360, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28813 - Train Loss: 0.065359, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28814 - Train Loss: 0.065357, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28815 - Train Loss: 0.065356, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28816 - Train Loss: 0.065355, Train Acc: 0.897436 | Val Loss: 0.104809, Val Acc: 0.793814\n",
      "Epoch 28817 - Train Loss: 0.065354, Train Acc: 0.897436 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 28818 - Train Loss: 0.065353, Train Acc: 0.897436 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 28819 - Train Loss: 0.065352, Train Acc: 0.897436 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 28820 - Train Loss: 0.065351, Train Acc: 0.897436 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 28821 - Train Loss: 0.065350, Train Acc: 0.897436 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 28822 - Train Loss: 0.065348, Train Acc: 0.897436 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 28823 - Train Loss: 0.065347, Train Acc: 0.897436 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 28824 - Train Loss: 0.065346, Train Acc: 0.897436 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 28825 - Train Loss: 0.065345, Train Acc: 0.897436 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 28826 - Train Loss: 0.065344, Train Acc: 0.897436 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 28827 - Train Loss: 0.065343, Train Acc: 0.897436 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 28828 - Train Loss: 0.065342, Train Acc: 0.897436 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 28829 - Train Loss: 0.065341, Train Acc: 0.897436 | Val Loss: 0.104810, Val Acc: 0.793814\n",
      "Epoch 28830 - Train Loss: 0.065339, Train Acc: 0.897436 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 28831 - Train Loss: 0.065338, Train Acc: 0.897436 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 28832 - Train Loss: 0.065337, Train Acc: 0.897436 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 28833 - Train Loss: 0.065336, Train Acc: 0.897436 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 28834 - Train Loss: 0.065335, Train Acc: 0.897436 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 28835 - Train Loss: 0.065334, Train Acc: 0.897436 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 28836 - Train Loss: 0.065333, Train Acc: 0.897436 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 28837 - Train Loss: 0.065332, Train Acc: 0.897436 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 28838 - Train Loss: 0.065331, Train Acc: 0.897436 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 28839 - Train Loss: 0.065329, Train Acc: 0.897436 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 28840 - Train Loss: 0.065328, Train Acc: 0.897436 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 28841 - Train Loss: 0.065327, Train Acc: 0.897436 | Val Loss: 0.104811, Val Acc: 0.793814\n",
      "Epoch 28842 - Train Loss: 0.065326, Train Acc: 0.897436 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 28843 - Train Loss: 0.065325, Train Acc: 0.897436 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 28844 - Train Loss: 0.065324, Train Acc: 0.897436 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 28845 - Train Loss: 0.065323, Train Acc: 0.897436 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 28846 - Train Loss: 0.065322, Train Acc: 0.897436 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 28847 - Train Loss: 0.065320, Train Acc: 0.897436 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 28848 - Train Loss: 0.065319, Train Acc: 0.897436 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 28849 - Train Loss: 0.065318, Train Acc: 0.897436 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 28850 - Train Loss: 0.065317, Train Acc: 0.897436 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 28851 - Train Loss: 0.065316, Train Acc: 0.897436 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 28852 - Train Loss: 0.065315, Train Acc: 0.898718 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 28853 - Train Loss: 0.065314, Train Acc: 0.898718 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 28854 - Train Loss: 0.065313, Train Acc: 0.898718 | Val Loss: 0.104812, Val Acc: 0.793814\n",
      "Epoch 28855 - Train Loss: 0.065311, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28856 - Train Loss: 0.065310, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28857 - Train Loss: 0.065309, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28858 - Train Loss: 0.065308, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28859 - Train Loss: 0.065307, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28860 - Train Loss: 0.065306, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28861 - Train Loss: 0.065305, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28862 - Train Loss: 0.065304, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28863 - Train Loss: 0.065303, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28864 - Train Loss: 0.065301, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28865 - Train Loss: 0.065300, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28866 - Train Loss: 0.065299, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28867 - Train Loss: 0.065298, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28868 - Train Loss: 0.065297, Train Acc: 0.898718 | Val Loss: 0.104813, Val Acc: 0.793814\n",
      "Epoch 28869 - Train Loss: 0.065296, Train Acc: 0.898718 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 28870 - Train Loss: 0.065295, Train Acc: 0.898718 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 28871 - Train Loss: 0.065294, Train Acc: 0.898718 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 28872 - Train Loss: 0.065292, Train Acc: 0.898718 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 28873 - Train Loss: 0.065291, Train Acc: 0.898718 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 28874 - Train Loss: 0.065290, Train Acc: 0.898718 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 28875 - Train Loss: 0.065289, Train Acc: 0.898718 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 28876 - Train Loss: 0.065288, Train Acc: 0.898718 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 28877 - Train Loss: 0.065287, Train Acc: 0.898718 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 28878 - Train Loss: 0.065286, Train Acc: 0.898718 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 28879 - Train Loss: 0.065285, Train Acc: 0.898718 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 28880 - Train Loss: 0.065284, Train Acc: 0.898718 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 28881 - Train Loss: 0.065282, Train Acc: 0.898718 | Val Loss: 0.104814, Val Acc: 0.793814\n",
      "Epoch 28882 - Train Loss: 0.065281, Train Acc: 0.898718 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 28883 - Train Loss: 0.065280, Train Acc: 0.898718 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 28884 - Train Loss: 0.065279, Train Acc: 0.898718 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 28885 - Train Loss: 0.065278, Train Acc: 0.898718 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 28886 - Train Loss: 0.065277, Train Acc: 0.898718 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 28887 - Train Loss: 0.065276, Train Acc: 0.898718 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 28888 - Train Loss: 0.065275, Train Acc: 0.898718 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 28889 - Train Loss: 0.065273, Train Acc: 0.898718 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 28890 - Train Loss: 0.065272, Train Acc: 0.898718 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 28891 - Train Loss: 0.065271, Train Acc: 0.898718 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 28892 - Train Loss: 0.065270, Train Acc: 0.898718 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 28893 - Train Loss: 0.065269, Train Acc: 0.898718 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 28894 - Train Loss: 0.065268, Train Acc: 0.898718 | Val Loss: 0.104815, Val Acc: 0.793814\n",
      "Epoch 28895 - Train Loss: 0.065267, Train Acc: 0.898718 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 28896 - Train Loss: 0.065266, Train Acc: 0.898718 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 28897 - Train Loss: 0.065265, Train Acc: 0.898718 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 28898 - Train Loss: 0.065263, Train Acc: 0.898718 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 28899 - Train Loss: 0.065262, Train Acc: 0.898718 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 28900 - Train Loss: 0.065261, Train Acc: 0.898718 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 28901 - Train Loss: 0.065260, Train Acc: 0.898718 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 28902 - Train Loss: 0.065259, Train Acc: 0.898718 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 28903 - Train Loss: 0.065258, Train Acc: 0.898718 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 28904 - Train Loss: 0.065257, Train Acc: 0.898718 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 28905 - Train Loss: 0.065256, Train Acc: 0.898718 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 28906 - Train Loss: 0.065254, Train Acc: 0.898718 | Val Loss: 0.104816, Val Acc: 0.793814\n",
      "Epoch 28907 - Train Loss: 0.065253, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28908 - Train Loss: 0.065252, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28909 - Train Loss: 0.065251, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28910 - Train Loss: 0.065250, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28911 - Train Loss: 0.065249, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28912 - Train Loss: 0.065248, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28913 - Train Loss: 0.065247, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28914 - Train Loss: 0.065246, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28915 - Train Loss: 0.065244, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28916 - Train Loss: 0.065243, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28917 - Train Loss: 0.065242, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28918 - Train Loss: 0.065241, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28919 - Train Loss: 0.065240, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28920 - Train Loss: 0.065239, Train Acc: 0.898718 | Val Loss: 0.104817, Val Acc: 0.793814\n",
      "Epoch 28921 - Train Loss: 0.065238, Train Acc: 0.898718 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 28922 - Train Loss: 0.065237, Train Acc: 0.898718 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 28923 - Train Loss: 0.065235, Train Acc: 0.898718 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 28924 - Train Loss: 0.065234, Train Acc: 0.898718 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 28925 - Train Loss: 0.065233, Train Acc: 0.898718 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 28926 - Train Loss: 0.065232, Train Acc: 0.898718 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 28927 - Train Loss: 0.065231, Train Acc: 0.898718 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 28928 - Train Loss: 0.065230, Train Acc: 0.898718 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 28929 - Train Loss: 0.065229, Train Acc: 0.898718 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 28930 - Train Loss: 0.065228, Train Acc: 0.898718 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 28931 - Train Loss: 0.065227, Train Acc: 0.898718 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 28932 - Train Loss: 0.065225, Train Acc: 0.898718 | Val Loss: 0.104818, Val Acc: 0.793814\n",
      "Epoch 28933 - Train Loss: 0.065224, Train Acc: 0.898718 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 28934 - Train Loss: 0.065223, Train Acc: 0.898718 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 28935 - Train Loss: 0.065222, Train Acc: 0.898718 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 28936 - Train Loss: 0.065221, Train Acc: 0.898718 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 28937 - Train Loss: 0.065220, Train Acc: 0.898718 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 28938 - Train Loss: 0.065219, Train Acc: 0.898718 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 28939 - Train Loss: 0.065218, Train Acc: 0.898718 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 28940 - Train Loss: 0.065217, Train Acc: 0.898718 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 28941 - Train Loss: 0.065215, Train Acc: 0.898718 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 28942 - Train Loss: 0.065214, Train Acc: 0.898718 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 28943 - Train Loss: 0.065213, Train Acc: 0.898718 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 28944 - Train Loss: 0.065212, Train Acc: 0.898718 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 28945 - Train Loss: 0.065211, Train Acc: 0.898718 | Val Loss: 0.104819, Val Acc: 0.793814\n",
      "Epoch 28946 - Train Loss: 0.065210, Train Acc: 0.898718 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 28947 - Train Loss: 0.065209, Train Acc: 0.898718 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 28948 - Train Loss: 0.065208, Train Acc: 0.898718 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 28949 - Train Loss: 0.065206, Train Acc: 0.898718 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 28950 - Train Loss: 0.065205, Train Acc: 0.898718 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 28951 - Train Loss: 0.065204, Train Acc: 0.898718 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 28952 - Train Loss: 0.065203, Train Acc: 0.898718 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 28953 - Train Loss: 0.065202, Train Acc: 0.898718 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 28954 - Train Loss: 0.065201, Train Acc: 0.898718 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 28955 - Train Loss: 0.065200, Train Acc: 0.898718 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 28956 - Train Loss: 0.065199, Train Acc: 0.898718 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 28957 - Train Loss: 0.065198, Train Acc: 0.898718 | Val Loss: 0.104820, Val Acc: 0.793814\n",
      "Epoch 28958 - Train Loss: 0.065196, Train Acc: 0.898718 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 28959 - Train Loss: 0.065195, Train Acc: 0.898718 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 28960 - Train Loss: 0.065194, Train Acc: 0.898718 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 28961 - Train Loss: 0.065193, Train Acc: 0.898718 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 28962 - Train Loss: 0.065192, Train Acc: 0.898718 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 28963 - Train Loss: 0.065191, Train Acc: 0.898718 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 28964 - Train Loss: 0.065190, Train Acc: 0.898718 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 28965 - Train Loss: 0.065189, Train Acc: 0.898718 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 28966 - Train Loss: 0.065188, Train Acc: 0.898718 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 28967 - Train Loss: 0.065186, Train Acc: 0.898718 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 28968 - Train Loss: 0.065185, Train Acc: 0.898718 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 28969 - Train Loss: 0.065184, Train Acc: 0.898718 | Val Loss: 0.104821, Val Acc: 0.793814\n",
      "Epoch 28970 - Train Loss: 0.065183, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28971 - Train Loss: 0.065182, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28972 - Train Loss: 0.065181, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28973 - Train Loss: 0.065180, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28974 - Train Loss: 0.065179, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28975 - Train Loss: 0.065178, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28976 - Train Loss: 0.065176, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28977 - Train Loss: 0.065175, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28978 - Train Loss: 0.065174, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28979 - Train Loss: 0.065173, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28980 - Train Loss: 0.065172, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28981 - Train Loss: 0.065171, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28982 - Train Loss: 0.065170, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28983 - Train Loss: 0.065169, Train Acc: 0.898718 | Val Loss: 0.104822, Val Acc: 0.793814\n",
      "Epoch 28984 - Train Loss: 0.065168, Train Acc: 0.898718 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 28985 - Train Loss: 0.065166, Train Acc: 0.898718 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 28986 - Train Loss: 0.065165, Train Acc: 0.898718 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 28987 - Train Loss: 0.065164, Train Acc: 0.898718 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 28988 - Train Loss: 0.065163, Train Acc: 0.898718 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 28989 - Train Loss: 0.065162, Train Acc: 0.898718 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 28990 - Train Loss: 0.065161, Train Acc: 0.898718 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 28991 - Train Loss: 0.065160, Train Acc: 0.898718 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 28992 - Train Loss: 0.065159, Train Acc: 0.898718 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 28993 - Train Loss: 0.065157, Train Acc: 0.898718 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 28994 - Train Loss: 0.065156, Train Acc: 0.898718 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 28995 - Train Loss: 0.065155, Train Acc: 0.898718 | Val Loss: 0.104823, Val Acc: 0.793814\n",
      "Epoch 28996 - Train Loss: 0.065154, Train Acc: 0.898718 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 28997 - Train Loss: 0.065153, Train Acc: 0.898718 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 28998 - Train Loss: 0.065152, Train Acc: 0.898718 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 28999 - Train Loss: 0.065151, Train Acc: 0.898718 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 29000 - Train Loss: 0.065150, Train Acc: 0.898718 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 29001 - Train Loss: 0.065149, Train Acc: 0.898718 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 29002 - Train Loss: 0.065147, Train Acc: 0.898718 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 29003 - Train Loss: 0.065146, Train Acc: 0.898718 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 29004 - Train Loss: 0.065145, Train Acc: 0.898718 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 29005 - Train Loss: 0.065144, Train Acc: 0.898718 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 29006 - Train Loss: 0.065143, Train Acc: 0.898718 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 29007 - Train Loss: 0.065142, Train Acc: 0.898718 | Val Loss: 0.104824, Val Acc: 0.793814\n",
      "Epoch 29008 - Train Loss: 0.065141, Train Acc: 0.898718 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 29009 - Train Loss: 0.065140, Train Acc: 0.898718 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 29010 - Train Loss: 0.065139, Train Acc: 0.898718 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 29011 - Train Loss: 0.065137, Train Acc: 0.898718 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 29012 - Train Loss: 0.065136, Train Acc: 0.898718 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 29013 - Train Loss: 0.065135, Train Acc: 0.898718 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 29014 - Train Loss: 0.065134, Train Acc: 0.898718 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 29015 - Train Loss: 0.065133, Train Acc: 0.898718 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 29016 - Train Loss: 0.065132, Train Acc: 0.898718 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 29017 - Train Loss: 0.065131, Train Acc: 0.898718 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 29018 - Train Loss: 0.065130, Train Acc: 0.898718 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 29019 - Train Loss: 0.065129, Train Acc: 0.898718 | Val Loss: 0.104825, Val Acc: 0.793814\n",
      "Epoch 29020 - Train Loss: 0.065127, Train Acc: 0.898718 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 29021 - Train Loss: 0.065126, Train Acc: 0.898718 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 29022 - Train Loss: 0.065125, Train Acc: 0.898718 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 29023 - Train Loss: 0.065124, Train Acc: 0.898718 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 29024 - Train Loss: 0.065123, Train Acc: 0.898718 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 29025 - Train Loss: 0.065122, Train Acc: 0.898718 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 29026 - Train Loss: 0.065121, Train Acc: 0.898718 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 29027 - Train Loss: 0.065120, Train Acc: 0.898718 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 29028 - Train Loss: 0.065119, Train Acc: 0.898718 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 29029 - Train Loss: 0.065117, Train Acc: 0.898718 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 29030 - Train Loss: 0.065116, Train Acc: 0.898718 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 29031 - Train Loss: 0.065115, Train Acc: 0.898718 | Val Loss: 0.104826, Val Acc: 0.793814\n",
      "Epoch 29032 - Train Loss: 0.065114, Train Acc: 0.898718 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 29033 - Train Loss: 0.065113, Train Acc: 0.898718 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 29034 - Train Loss: 0.065112, Train Acc: 0.898718 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 29035 - Train Loss: 0.065111, Train Acc: 0.898718 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 29036 - Train Loss: 0.065110, Train Acc: 0.898718 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 29037 - Train Loss: 0.065109, Train Acc: 0.898718 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 29038 - Train Loss: 0.065107, Train Acc: 0.898718 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 29039 - Train Loss: 0.065106, Train Acc: 0.898718 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 29040 - Train Loss: 0.065105, Train Acc: 0.898718 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 29041 - Train Loss: 0.065104, Train Acc: 0.898718 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 29042 - Train Loss: 0.065103, Train Acc: 0.898718 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 29043 - Train Loss: 0.065102, Train Acc: 0.898718 | Val Loss: 0.104827, Val Acc: 0.793814\n",
      "Epoch 29044 - Train Loss: 0.065101, Train Acc: 0.898718 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 29045 - Train Loss: 0.065100, Train Acc: 0.898718 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 29046 - Train Loss: 0.065099, Train Acc: 0.898718 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 29047 - Train Loss: 0.065098, Train Acc: 0.898718 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 29048 - Train Loss: 0.065096, Train Acc: 0.898718 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 29049 - Train Loss: 0.065095, Train Acc: 0.898718 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 29050 - Train Loss: 0.065094, Train Acc: 0.898718 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 29051 - Train Loss: 0.065093, Train Acc: 0.898718 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 29052 - Train Loss: 0.065092, Train Acc: 0.898718 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 29053 - Train Loss: 0.065091, Train Acc: 0.898718 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 29054 - Train Loss: 0.065090, Train Acc: 0.898718 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 29055 - Train Loss: 0.065089, Train Acc: 0.898718 | Val Loss: 0.104828, Val Acc: 0.793814\n",
      "Epoch 29056 - Train Loss: 0.065088, Train Acc: 0.898718 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 29057 - Train Loss: 0.065086, Train Acc: 0.898718 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 29058 - Train Loss: 0.065085, Train Acc: 0.898718 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 29059 - Train Loss: 0.065084, Train Acc: 0.898718 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 29060 - Train Loss: 0.065083, Train Acc: 0.898718 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 29061 - Train Loss: 0.065082, Train Acc: 0.898718 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 29062 - Train Loss: 0.065081, Train Acc: 0.898718 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 29063 - Train Loss: 0.065080, Train Acc: 0.898718 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 29064 - Train Loss: 0.065079, Train Acc: 0.898718 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 29065 - Train Loss: 0.065078, Train Acc: 0.898718 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 29066 - Train Loss: 0.065076, Train Acc: 0.898718 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 29067 - Train Loss: 0.065075, Train Acc: 0.898718 | Val Loss: 0.104829, Val Acc: 0.793814\n",
      "Epoch 29068 - Train Loss: 0.065074, Train Acc: 0.898718 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 29069 - Train Loss: 0.065073, Train Acc: 0.898718 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 29070 - Train Loss: 0.065072, Train Acc: 0.898718 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 29071 - Train Loss: 0.065071, Train Acc: 0.898718 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 29072 - Train Loss: 0.065070, Train Acc: 0.898718 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 29073 - Train Loss: 0.065069, Train Acc: 0.898718 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 29074 - Train Loss: 0.065068, Train Acc: 0.898718 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 29075 - Train Loss: 0.065066, Train Acc: 0.898718 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 29076 - Train Loss: 0.065065, Train Acc: 0.898718 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 29077 - Train Loss: 0.065064, Train Acc: 0.898718 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 29078 - Train Loss: 0.065063, Train Acc: 0.898718 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 29079 - Train Loss: 0.065062, Train Acc: 0.898718 | Val Loss: 0.104830, Val Acc: 0.793814\n",
      "Epoch 29080 - Train Loss: 0.065061, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29081 - Train Loss: 0.065060, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29082 - Train Loss: 0.065059, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29083 - Train Loss: 0.065058, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29084 - Train Loss: 0.065057, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29085 - Train Loss: 0.065055, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29086 - Train Loss: 0.065054, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29087 - Train Loss: 0.065053, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29088 - Train Loss: 0.065052, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29089 - Train Loss: 0.065051, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29090 - Train Loss: 0.065050, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29091 - Train Loss: 0.065049, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29092 - Train Loss: 0.065048, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29093 - Train Loss: 0.065046, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29094 - Train Loss: 0.065045, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29095 - Train Loss: 0.065044, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29096 - Train Loss: 0.065043, Train Acc: 0.898718 | Val Loss: 0.104831, Val Acc: 0.793814\n",
      "Epoch 29097 - Train Loss: 0.065042, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29098 - Train Loss: 0.065041, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29099 - Train Loss: 0.065040, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29100 - Train Loss: 0.065039, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29101 - Train Loss: 0.065038, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29102 - Train Loss: 0.065036, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29103 - Train Loss: 0.065035, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29104 - Train Loss: 0.065034, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29105 - Train Loss: 0.065033, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29106 - Train Loss: 0.065032, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29107 - Train Loss: 0.065031, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29108 - Train Loss: 0.065030, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29109 - Train Loss: 0.065029, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29110 - Train Loss: 0.065027, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29111 - Train Loss: 0.065026, Train Acc: 0.898718 | Val Loss: 0.104832, Val Acc: 0.793814\n",
      "Epoch 29112 - Train Loss: 0.065025, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29113 - Train Loss: 0.065024, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29114 - Train Loss: 0.065023, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29115 - Train Loss: 0.065022, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29116 - Train Loss: 0.065021, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29117 - Train Loss: 0.065020, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29118 - Train Loss: 0.065019, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29119 - Train Loss: 0.065017, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29120 - Train Loss: 0.065016, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29121 - Train Loss: 0.065015, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29122 - Train Loss: 0.065014, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29123 - Train Loss: 0.065013, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29124 - Train Loss: 0.065012, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29125 - Train Loss: 0.065011, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29126 - Train Loss: 0.065010, Train Acc: 0.898718 | Val Loss: 0.104833, Val Acc: 0.793814\n",
      "Epoch 29127 - Train Loss: 0.065009, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29128 - Train Loss: 0.065007, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29129 - Train Loss: 0.065006, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29130 - Train Loss: 0.065005, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29131 - Train Loss: 0.065004, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29132 - Train Loss: 0.065003, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29133 - Train Loss: 0.065002, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29134 - Train Loss: 0.065001, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29135 - Train Loss: 0.065000, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29136 - Train Loss: 0.064998, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29137 - Train Loss: 0.064997, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29138 - Train Loss: 0.064996, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29139 - Train Loss: 0.064995, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29140 - Train Loss: 0.064994, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29141 - Train Loss: 0.064993, Train Acc: 0.898718 | Val Loss: 0.104834, Val Acc: 0.793814\n",
      "Epoch 29142 - Train Loss: 0.064992, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29143 - Train Loss: 0.064991, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29144 - Train Loss: 0.064990, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29145 - Train Loss: 0.064988, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29146 - Train Loss: 0.064987, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29147 - Train Loss: 0.064986, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29148 - Train Loss: 0.064985, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29149 - Train Loss: 0.064984, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29150 - Train Loss: 0.064983, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29151 - Train Loss: 0.064982, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29152 - Train Loss: 0.064981, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29153 - Train Loss: 0.064980, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29154 - Train Loss: 0.064978, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29155 - Train Loss: 0.064977, Train Acc: 0.898718 | Val Loss: 0.104835, Val Acc: 0.793814\n",
      "Epoch 29156 - Train Loss: 0.064976, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29157 - Train Loss: 0.064975, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29158 - Train Loss: 0.064974, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29159 - Train Loss: 0.064973, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29160 - Train Loss: 0.064972, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29161 - Train Loss: 0.064971, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29162 - Train Loss: 0.064970, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29163 - Train Loss: 0.064968, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29164 - Train Loss: 0.064967, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29165 - Train Loss: 0.064966, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29166 - Train Loss: 0.064965, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29167 - Train Loss: 0.064964, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29168 - Train Loss: 0.064963, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29169 - Train Loss: 0.064962, Train Acc: 0.898718 | Val Loss: 0.104836, Val Acc: 0.793814\n",
      "Epoch 29170 - Train Loss: 0.064961, Train Acc: 0.898718 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 29171 - Train Loss: 0.064960, Train Acc: 0.898718 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 29172 - Train Loss: 0.064958, Train Acc: 0.898718 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 29173 - Train Loss: 0.064957, Train Acc: 0.898718 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 29174 - Train Loss: 0.064956, Train Acc: 0.898718 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 29175 - Train Loss: 0.064955, Train Acc: 0.898718 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 29176 - Train Loss: 0.064954, Train Acc: 0.898718 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 29177 - Train Loss: 0.064953, Train Acc: 0.898718 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 29178 - Train Loss: 0.064952, Train Acc: 0.898718 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 29179 - Train Loss: 0.064951, Train Acc: 0.898718 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 29180 - Train Loss: 0.064949, Train Acc: 0.898718 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 29181 - Train Loss: 0.064948, Train Acc: 0.898718 | Val Loss: 0.104837, Val Acc: 0.793814\n",
      "Epoch 29182 - Train Loss: 0.064947, Train Acc: 0.898718 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 29183 - Train Loss: 0.064946, Train Acc: 0.898718 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 29184 - Train Loss: 0.064945, Train Acc: 0.898718 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 29185 - Train Loss: 0.064944, Train Acc: 0.898718 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 29186 - Train Loss: 0.064943, Train Acc: 0.898718 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 29187 - Train Loss: 0.064942, Train Acc: 0.898718 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 29188 - Train Loss: 0.064940, Train Acc: 0.898718 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 29189 - Train Loss: 0.064939, Train Acc: 0.898718 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 29190 - Train Loss: 0.064938, Train Acc: 0.898718 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 29191 - Train Loss: 0.064937, Train Acc: 0.898718 | Val Loss: 0.104838, Val Acc: 0.793814\n",
      "Epoch 29192 - Train Loss: 0.064936, Train Acc: 0.898718 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 29193 - Train Loss: 0.064935, Train Acc: 0.898718 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 29194 - Train Loss: 0.064934, Train Acc: 0.898718 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 29195 - Train Loss: 0.064933, Train Acc: 0.898718 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 29196 - Train Loss: 0.064931, Train Acc: 0.898718 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 29197 - Train Loss: 0.064930, Train Acc: 0.898718 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 29198 - Train Loss: 0.064929, Train Acc: 0.898718 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 29199 - Train Loss: 0.064928, Train Acc: 0.898718 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 29200 - Train Loss: 0.064927, Train Acc: 0.898718 | Val Loss: 0.104839, Val Acc: 0.793814\n",
      "Epoch 29201 - Train Loss: 0.064926, Train Acc: 0.898718 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 29202 - Train Loss: 0.064925, Train Acc: 0.898718 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 29203 - Train Loss: 0.064924, Train Acc: 0.898718 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 29204 - Train Loss: 0.064923, Train Acc: 0.898718 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 29205 - Train Loss: 0.064921, Train Acc: 0.898718 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 29206 - Train Loss: 0.064920, Train Acc: 0.898718 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 29207 - Train Loss: 0.064919, Train Acc: 0.898718 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 29208 - Train Loss: 0.064918, Train Acc: 0.898718 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 29209 - Train Loss: 0.064917, Train Acc: 0.898718 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 29210 - Train Loss: 0.064916, Train Acc: 0.898718 | Val Loss: 0.104840, Val Acc: 0.793814\n",
      "Epoch 29211 - Train Loss: 0.064915, Train Acc: 0.898718 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 29212 - Train Loss: 0.064914, Train Acc: 0.898718 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 29213 - Train Loss: 0.064912, Train Acc: 0.898718 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 29214 - Train Loss: 0.064911, Train Acc: 0.898718 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 29215 - Train Loss: 0.064910, Train Acc: 0.898718 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 29216 - Train Loss: 0.064909, Train Acc: 0.898718 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 29217 - Train Loss: 0.064908, Train Acc: 0.898718 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 29218 - Train Loss: 0.064907, Train Acc: 0.898718 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 29219 - Train Loss: 0.064906, Train Acc: 0.898718 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 29220 - Train Loss: 0.064905, Train Acc: 0.898718 | Val Loss: 0.104841, Val Acc: 0.793814\n",
      "Epoch 29221 - Train Loss: 0.064904, Train Acc: 0.900000 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 29222 - Train Loss: 0.064902, Train Acc: 0.900000 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 29223 - Train Loss: 0.064901, Train Acc: 0.900000 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 29224 - Train Loss: 0.064900, Train Acc: 0.900000 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 29225 - Train Loss: 0.064899, Train Acc: 0.900000 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 29226 - Train Loss: 0.064898, Train Acc: 0.901282 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 29227 - Train Loss: 0.064897, Train Acc: 0.901282 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 29228 - Train Loss: 0.064896, Train Acc: 0.901282 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 29229 - Train Loss: 0.064895, Train Acc: 0.901282 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 29230 - Train Loss: 0.064894, Train Acc: 0.901282 | Val Loss: 0.104842, Val Acc: 0.793814\n",
      "Epoch 29231 - Train Loss: 0.064892, Train Acc: 0.901282 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 29232 - Train Loss: 0.064891, Train Acc: 0.901282 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 29233 - Train Loss: 0.064890, Train Acc: 0.901282 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 29234 - Train Loss: 0.064889, Train Acc: 0.901282 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 29235 - Train Loss: 0.064888, Train Acc: 0.901282 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 29236 - Train Loss: 0.064887, Train Acc: 0.901282 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 29237 - Train Loss: 0.064886, Train Acc: 0.901282 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 29238 - Train Loss: 0.064885, Train Acc: 0.901282 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 29239 - Train Loss: 0.064884, Train Acc: 0.901282 | Val Loss: 0.104843, Val Acc: 0.793814\n",
      "Epoch 29240 - Train Loss: 0.064883, Train Acc: 0.901282 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 29241 - Train Loss: 0.064881, Train Acc: 0.901282 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 29242 - Train Loss: 0.064880, Train Acc: 0.901282 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 29243 - Train Loss: 0.064879, Train Acc: 0.901282 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 29244 - Train Loss: 0.064878, Train Acc: 0.901282 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 29245 - Train Loss: 0.064877, Train Acc: 0.901282 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 29246 - Train Loss: 0.064876, Train Acc: 0.901282 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 29247 - Train Loss: 0.064875, Train Acc: 0.901282 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 29248 - Train Loss: 0.064874, Train Acc: 0.901282 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 29249 - Train Loss: 0.064873, Train Acc: 0.901282 | Val Loss: 0.104844, Val Acc: 0.793814\n",
      "Epoch 29250 - Train Loss: 0.064872, Train Acc: 0.901282 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 29251 - Train Loss: 0.064870, Train Acc: 0.901282 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 29252 - Train Loss: 0.064869, Train Acc: 0.901282 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 29253 - Train Loss: 0.064868, Train Acc: 0.901282 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 29254 - Train Loss: 0.064867, Train Acc: 0.901282 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 29255 - Train Loss: 0.064866, Train Acc: 0.901282 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 29256 - Train Loss: 0.064865, Train Acc: 0.901282 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 29257 - Train Loss: 0.064864, Train Acc: 0.901282 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 29258 - Train Loss: 0.064863, Train Acc: 0.901282 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 29259 - Train Loss: 0.064862, Train Acc: 0.901282 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 29260 - Train Loss: 0.064861, Train Acc: 0.901282 | Val Loss: 0.104845, Val Acc: 0.793814\n",
      "Epoch 29261 - Train Loss: 0.064859, Train Acc: 0.901282 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 29262 - Train Loss: 0.064858, Train Acc: 0.901282 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 29263 - Train Loss: 0.064857, Train Acc: 0.901282 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 29264 - Train Loss: 0.064856, Train Acc: 0.901282 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 29265 - Train Loss: 0.064855, Train Acc: 0.901282 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 29266 - Train Loss: 0.064854, Train Acc: 0.901282 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 29267 - Train Loss: 0.064853, Train Acc: 0.901282 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 29268 - Train Loss: 0.064852, Train Acc: 0.901282 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 29269 - Train Loss: 0.064851, Train Acc: 0.901282 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 29270 - Train Loss: 0.064850, Train Acc: 0.901282 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 29271 - Train Loss: 0.064849, Train Acc: 0.901282 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 29272 - Train Loss: 0.064847, Train Acc: 0.901282 | Val Loss: 0.104846, Val Acc: 0.793814\n",
      "Epoch 29273 - Train Loss: 0.064846, Train Acc: 0.901282 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 29274 - Train Loss: 0.064845, Train Acc: 0.901282 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 29275 - Train Loss: 0.064844, Train Acc: 0.901282 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 29276 - Train Loss: 0.064843, Train Acc: 0.901282 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 29277 - Train Loss: 0.064842, Train Acc: 0.901282 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 29278 - Train Loss: 0.064841, Train Acc: 0.901282 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 29279 - Train Loss: 0.064840, Train Acc: 0.901282 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 29280 - Train Loss: 0.064839, Train Acc: 0.901282 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 29281 - Train Loss: 0.064838, Train Acc: 0.901282 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 29282 - Train Loss: 0.064837, Train Acc: 0.901282 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 29283 - Train Loss: 0.064835, Train Acc: 0.901282 | Val Loss: 0.104847, Val Acc: 0.793814\n",
      "Epoch 29284 - Train Loss: 0.064834, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29285 - Train Loss: 0.064833, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29286 - Train Loss: 0.064832, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29287 - Train Loss: 0.064831, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29288 - Train Loss: 0.064830, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29289 - Train Loss: 0.064829, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29290 - Train Loss: 0.064828, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29291 - Train Loss: 0.064827, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29292 - Train Loss: 0.064826, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29293 - Train Loss: 0.064825, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29294 - Train Loss: 0.064823, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29295 - Train Loss: 0.064822, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29296 - Train Loss: 0.064821, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29297 - Train Loss: 0.064820, Train Acc: 0.901282 | Val Loss: 0.104848, Val Acc: 0.793814\n",
      "Epoch 29298 - Train Loss: 0.064819, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29299 - Train Loss: 0.064818, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29300 - Train Loss: 0.064817, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29301 - Train Loss: 0.064816, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29302 - Train Loss: 0.064815, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29303 - Train Loss: 0.064814, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29304 - Train Loss: 0.064813, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29305 - Train Loss: 0.064811, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29306 - Train Loss: 0.064810, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29307 - Train Loss: 0.064809, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29308 - Train Loss: 0.064808, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29309 - Train Loss: 0.064807, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29310 - Train Loss: 0.064806, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29311 - Train Loss: 0.064805, Train Acc: 0.901282 | Val Loss: 0.104849, Val Acc: 0.793814\n",
      "Epoch 29312 - Train Loss: 0.064804, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29313 - Train Loss: 0.064803, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29314 - Train Loss: 0.064802, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29315 - Train Loss: 0.064801, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29316 - Train Loss: 0.064799, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29317 - Train Loss: 0.064798, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29318 - Train Loss: 0.064797, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29319 - Train Loss: 0.064796, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29320 - Train Loss: 0.064795, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29321 - Train Loss: 0.064794, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29322 - Train Loss: 0.064793, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29323 - Train Loss: 0.064792, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29324 - Train Loss: 0.064791, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29325 - Train Loss: 0.064790, Train Acc: 0.901282 | Val Loss: 0.104850, Val Acc: 0.793814\n",
      "Epoch 29326 - Train Loss: 0.064789, Train Acc: 0.901282 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 29327 - Train Loss: 0.064787, Train Acc: 0.901282 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 29328 - Train Loss: 0.064786, Train Acc: 0.901282 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 29329 - Train Loss: 0.064785, Train Acc: 0.901282 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 29330 - Train Loss: 0.064784, Train Acc: 0.901282 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 29331 - Train Loss: 0.064783, Train Acc: 0.901282 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 29332 - Train Loss: 0.064782, Train Acc: 0.901282 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 29333 - Train Loss: 0.064781, Train Acc: 0.901282 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 29334 - Train Loss: 0.064780, Train Acc: 0.901282 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 29335 - Train Loss: 0.064779, Train Acc: 0.901282 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 29336 - Train Loss: 0.064778, Train Acc: 0.901282 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 29337 - Train Loss: 0.064777, Train Acc: 0.901282 | Val Loss: 0.104851, Val Acc: 0.793814\n",
      "Epoch 29338 - Train Loss: 0.064776, Train Acc: 0.901282 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 29339 - Train Loss: 0.064774, Train Acc: 0.901282 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 29340 - Train Loss: 0.064773, Train Acc: 0.901282 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 29341 - Train Loss: 0.064772, Train Acc: 0.901282 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 29342 - Train Loss: 0.064771, Train Acc: 0.901282 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 29343 - Train Loss: 0.064770, Train Acc: 0.901282 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 29344 - Train Loss: 0.064769, Train Acc: 0.901282 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 29345 - Train Loss: 0.064768, Train Acc: 0.901282 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 29346 - Train Loss: 0.064767, Train Acc: 0.901282 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 29347 - Train Loss: 0.064766, Train Acc: 0.901282 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 29348 - Train Loss: 0.064765, Train Acc: 0.901282 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 29349 - Train Loss: 0.064764, Train Acc: 0.901282 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 29350 - Train Loss: 0.064762, Train Acc: 0.901282 | Val Loss: 0.104852, Val Acc: 0.793814\n",
      "Epoch 29351 - Train Loss: 0.064761, Train Acc: 0.901282 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 29352 - Train Loss: 0.064760, Train Acc: 0.901282 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 29353 - Train Loss: 0.064759, Train Acc: 0.901282 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 29354 - Train Loss: 0.064758, Train Acc: 0.901282 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 29355 - Train Loss: 0.064757, Train Acc: 0.901282 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 29356 - Train Loss: 0.064756, Train Acc: 0.901282 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 29357 - Train Loss: 0.064755, Train Acc: 0.901282 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 29358 - Train Loss: 0.064754, Train Acc: 0.901282 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 29359 - Train Loss: 0.064753, Train Acc: 0.901282 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 29360 - Train Loss: 0.064752, Train Acc: 0.901282 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 29361 - Train Loss: 0.064751, Train Acc: 0.901282 | Val Loss: 0.104853, Val Acc: 0.793814\n",
      "Epoch 29362 - Train Loss: 0.064749, Train Acc: 0.901282 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29363 - Train Loss: 0.064748, Train Acc: 0.901282 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29364 - Train Loss: 0.064747, Train Acc: 0.901282 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29365 - Train Loss: 0.064746, Train Acc: 0.901282 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29366 - Train Loss: 0.064745, Train Acc: 0.901282 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29367 - Train Loss: 0.064744, Train Acc: 0.901282 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29368 - Train Loss: 0.064743, Train Acc: 0.901282 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29369 - Train Loss: 0.064742, Train Acc: 0.901282 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29370 - Train Loss: 0.064741, Train Acc: 0.901282 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29371 - Train Loss: 0.064740, Train Acc: 0.901282 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29372 - Train Loss: 0.064739, Train Acc: 0.901282 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29373 - Train Loss: 0.064738, Train Acc: 0.902564 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29374 - Train Loss: 0.064736, Train Acc: 0.902564 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29375 - Train Loss: 0.064735, Train Acc: 0.902564 | Val Loss: 0.104854, Val Acc: 0.793814\n",
      "Epoch 29376 - Train Loss: 0.064734, Train Acc: 0.902564 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 29377 - Train Loss: 0.064733, Train Acc: 0.902564 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 29378 - Train Loss: 0.064732, Train Acc: 0.902564 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 29379 - Train Loss: 0.064731, Train Acc: 0.902564 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 29380 - Train Loss: 0.064730, Train Acc: 0.902564 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 29381 - Train Loss: 0.064729, Train Acc: 0.902564 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 29382 - Train Loss: 0.064728, Train Acc: 0.902564 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 29383 - Train Loss: 0.064727, Train Acc: 0.902564 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 29384 - Train Loss: 0.064726, Train Acc: 0.902564 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 29385 - Train Loss: 0.064725, Train Acc: 0.902564 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 29386 - Train Loss: 0.064723, Train Acc: 0.902564 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 29387 - Train Loss: 0.064722, Train Acc: 0.902564 | Val Loss: 0.104855, Val Acc: 0.793814\n",
      "Epoch 29388 - Train Loss: 0.064721, Train Acc: 0.902564 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 29389 - Train Loss: 0.064720, Train Acc: 0.902564 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 29390 - Train Loss: 0.064719, Train Acc: 0.902564 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 29391 - Train Loss: 0.064718, Train Acc: 0.902564 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 29392 - Train Loss: 0.064717, Train Acc: 0.902564 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 29393 - Train Loss: 0.064716, Train Acc: 0.902564 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 29394 - Train Loss: 0.064715, Train Acc: 0.902564 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 29395 - Train Loss: 0.064714, Train Acc: 0.902564 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 29396 - Train Loss: 0.064713, Train Acc: 0.902564 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 29397 - Train Loss: 0.064712, Train Acc: 0.902564 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 29398 - Train Loss: 0.064710, Train Acc: 0.902564 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 29399 - Train Loss: 0.064709, Train Acc: 0.902564 | Val Loss: 0.104856, Val Acc: 0.793814\n",
      "Epoch 29400 - Train Loss: 0.064708, Train Acc: 0.902564 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 29401 - Train Loss: 0.064707, Train Acc: 0.902564 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 29402 - Train Loss: 0.064706, Train Acc: 0.902564 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 29403 - Train Loss: 0.064705, Train Acc: 0.902564 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 29404 - Train Loss: 0.064704, Train Acc: 0.902564 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 29405 - Train Loss: 0.064703, Train Acc: 0.902564 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 29406 - Train Loss: 0.064702, Train Acc: 0.902564 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 29407 - Train Loss: 0.064701, Train Acc: 0.902564 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 29408 - Train Loss: 0.064700, Train Acc: 0.902564 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 29409 - Train Loss: 0.064699, Train Acc: 0.902564 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 29410 - Train Loss: 0.064697, Train Acc: 0.902564 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 29411 - Train Loss: 0.064696, Train Acc: 0.902564 | Val Loss: 0.104857, Val Acc: 0.793814\n",
      "Epoch 29412 - Train Loss: 0.064695, Train Acc: 0.902564 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 29413 - Train Loss: 0.064694, Train Acc: 0.902564 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 29414 - Train Loss: 0.064693, Train Acc: 0.902564 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 29415 - Train Loss: 0.064692, Train Acc: 0.902564 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 29416 - Train Loss: 0.064691, Train Acc: 0.902564 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 29417 - Train Loss: 0.064690, Train Acc: 0.902564 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 29418 - Train Loss: 0.064689, Train Acc: 0.902564 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 29419 - Train Loss: 0.064688, Train Acc: 0.902564 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 29420 - Train Loss: 0.064687, Train Acc: 0.902564 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 29421 - Train Loss: 0.064686, Train Acc: 0.902564 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 29422 - Train Loss: 0.064684, Train Acc: 0.902564 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 29423 - Train Loss: 0.064683, Train Acc: 0.902564 | Val Loss: 0.104858, Val Acc: 0.793814\n",
      "Epoch 29424 - Train Loss: 0.064682, Train Acc: 0.902564 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 29425 - Train Loss: 0.064681, Train Acc: 0.902564 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 29426 - Train Loss: 0.064680, Train Acc: 0.902564 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 29427 - Train Loss: 0.064679, Train Acc: 0.902564 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 29428 - Train Loss: 0.064678, Train Acc: 0.902564 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 29429 - Train Loss: 0.064677, Train Acc: 0.902564 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 29430 - Train Loss: 0.064676, Train Acc: 0.902564 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 29431 - Train Loss: 0.064675, Train Acc: 0.902564 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 29432 - Train Loss: 0.064674, Train Acc: 0.902564 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 29433 - Train Loss: 0.064673, Train Acc: 0.902564 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 29434 - Train Loss: 0.064671, Train Acc: 0.902564 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 29435 - Train Loss: 0.064670, Train Acc: 0.902564 | Val Loss: 0.104859, Val Acc: 0.793814\n",
      "Epoch 29436 - Train Loss: 0.064669, Train Acc: 0.902564 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 29437 - Train Loss: 0.064668, Train Acc: 0.902564 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 29438 - Train Loss: 0.064667, Train Acc: 0.902564 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 29439 - Train Loss: 0.064666, Train Acc: 0.902564 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 29440 - Train Loss: 0.064665, Train Acc: 0.902564 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 29441 - Train Loss: 0.064664, Train Acc: 0.902564 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 29442 - Train Loss: 0.064663, Train Acc: 0.902564 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 29443 - Train Loss: 0.064662, Train Acc: 0.902564 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 29444 - Train Loss: 0.064661, Train Acc: 0.902564 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 29445 - Train Loss: 0.064660, Train Acc: 0.902564 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 29446 - Train Loss: 0.064659, Train Acc: 0.902564 | Val Loss: 0.104860, Val Acc: 0.793814\n",
      "Epoch 29447 - Train Loss: 0.064657, Train Acc: 0.902564 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 29448 - Train Loss: 0.064656, Train Acc: 0.902564 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 29449 - Train Loss: 0.064655, Train Acc: 0.902564 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 29450 - Train Loss: 0.064654, Train Acc: 0.902564 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 29451 - Train Loss: 0.064653, Train Acc: 0.902564 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 29452 - Train Loss: 0.064652, Train Acc: 0.902564 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 29453 - Train Loss: 0.064651, Train Acc: 0.902564 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 29454 - Train Loss: 0.064650, Train Acc: 0.902564 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 29455 - Train Loss: 0.064649, Train Acc: 0.902564 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 29456 - Train Loss: 0.064648, Train Acc: 0.902564 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 29457 - Train Loss: 0.064647, Train Acc: 0.902564 | Val Loss: 0.104861, Val Acc: 0.793814\n",
      "Epoch 29458 - Train Loss: 0.064646, Train Acc: 0.902564 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 29459 - Train Loss: 0.064644, Train Acc: 0.902564 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 29460 - Train Loss: 0.064643, Train Acc: 0.902564 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 29461 - Train Loss: 0.064642, Train Acc: 0.902564 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 29462 - Train Loss: 0.064641, Train Acc: 0.902564 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 29463 - Train Loss: 0.064640, Train Acc: 0.902564 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 29464 - Train Loss: 0.064639, Train Acc: 0.902564 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 29465 - Train Loss: 0.064638, Train Acc: 0.902564 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 29466 - Train Loss: 0.064637, Train Acc: 0.902564 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 29467 - Train Loss: 0.064636, Train Acc: 0.902564 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 29468 - Train Loss: 0.064635, Train Acc: 0.902564 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 29469 - Train Loss: 0.064634, Train Acc: 0.902564 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 29470 - Train Loss: 0.064633, Train Acc: 0.902564 | Val Loss: 0.104862, Val Acc: 0.793814\n",
      "Epoch 29471 - Train Loss: 0.064632, Train Acc: 0.902564 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 29472 - Train Loss: 0.064630, Train Acc: 0.902564 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 29473 - Train Loss: 0.064629, Train Acc: 0.902564 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 29474 - Train Loss: 0.064628, Train Acc: 0.902564 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 29475 - Train Loss: 0.064627, Train Acc: 0.902564 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 29476 - Train Loss: 0.064626, Train Acc: 0.902564 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 29477 - Train Loss: 0.064625, Train Acc: 0.902564 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 29478 - Train Loss: 0.064624, Train Acc: 0.902564 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 29479 - Train Loss: 0.064623, Train Acc: 0.902564 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 29480 - Train Loss: 0.064622, Train Acc: 0.902564 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 29481 - Train Loss: 0.064621, Train Acc: 0.902564 | Val Loss: 0.104863, Val Acc: 0.793814\n",
      "Epoch 29482 - Train Loss: 0.064620, Train Acc: 0.902564 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 29483 - Train Loss: 0.064619, Train Acc: 0.902564 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 29484 - Train Loss: 0.064617, Train Acc: 0.902564 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 29485 - Train Loss: 0.064616, Train Acc: 0.902564 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 29486 - Train Loss: 0.064615, Train Acc: 0.902564 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 29487 - Train Loss: 0.064614, Train Acc: 0.902564 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 29488 - Train Loss: 0.064613, Train Acc: 0.902564 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 29489 - Train Loss: 0.064612, Train Acc: 0.902564 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 29490 - Train Loss: 0.064611, Train Acc: 0.902564 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 29491 - Train Loss: 0.064610, Train Acc: 0.902564 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 29492 - Train Loss: 0.064609, Train Acc: 0.902564 | Val Loss: 0.104864, Val Acc: 0.793814\n",
      "Epoch 29493 - Train Loss: 0.064608, Train Acc: 0.902564 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 29494 - Train Loss: 0.064607, Train Acc: 0.902564 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 29495 - Train Loss: 0.064606, Train Acc: 0.902564 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 29496 - Train Loss: 0.064605, Train Acc: 0.902564 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 29497 - Train Loss: 0.064603, Train Acc: 0.902564 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 29498 - Train Loss: 0.064602, Train Acc: 0.902564 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 29499 - Train Loss: 0.064601, Train Acc: 0.902564 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 29500 - Train Loss: 0.064600, Train Acc: 0.902564 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 29501 - Train Loss: 0.064599, Train Acc: 0.902564 | Val Loss: 0.104865, Val Acc: 0.793814\n",
      "Epoch 29502 - Train Loss: 0.064598, Train Acc: 0.902564 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 29503 - Train Loss: 0.064597, Train Acc: 0.902564 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 29504 - Train Loss: 0.064596, Train Acc: 0.903846 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 29505 - Train Loss: 0.064595, Train Acc: 0.903846 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 29506 - Train Loss: 0.064594, Train Acc: 0.903846 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 29507 - Train Loss: 0.064593, Train Acc: 0.903846 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 29508 - Train Loss: 0.064592, Train Acc: 0.903846 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 29509 - Train Loss: 0.064591, Train Acc: 0.903846 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 29510 - Train Loss: 0.064589, Train Acc: 0.903846 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 29511 - Train Loss: 0.064588, Train Acc: 0.903846 | Val Loss: 0.104866, Val Acc: 0.793814\n",
      "Epoch 29512 - Train Loss: 0.064587, Train Acc: 0.903846 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 29513 - Train Loss: 0.064586, Train Acc: 0.903846 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 29514 - Train Loss: 0.064585, Train Acc: 0.903846 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 29515 - Train Loss: 0.064584, Train Acc: 0.903846 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 29516 - Train Loss: 0.064583, Train Acc: 0.903846 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 29517 - Train Loss: 0.064582, Train Acc: 0.903846 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 29518 - Train Loss: 0.064581, Train Acc: 0.903846 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 29519 - Train Loss: 0.064580, Train Acc: 0.903846 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 29520 - Train Loss: 0.064579, Train Acc: 0.903846 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 29521 - Train Loss: 0.064578, Train Acc: 0.903846 | Val Loss: 0.104867, Val Acc: 0.793814\n",
      "Epoch 29522 - Train Loss: 0.064577, Train Acc: 0.903846 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 29523 - Train Loss: 0.064575, Train Acc: 0.903846 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 29524 - Train Loss: 0.064574, Train Acc: 0.903846 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 29525 - Train Loss: 0.064573, Train Acc: 0.903846 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 29526 - Train Loss: 0.064572, Train Acc: 0.903846 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 29527 - Train Loss: 0.064571, Train Acc: 0.903846 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 29528 - Train Loss: 0.064570, Train Acc: 0.903846 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 29529 - Train Loss: 0.064569, Train Acc: 0.903846 | Val Loss: 0.104868, Val Acc: 0.793814\n",
      "Epoch 29530 - Train Loss: 0.064568, Train Acc: 0.903846 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 29531 - Train Loss: 0.064567, Train Acc: 0.903846 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 29532 - Train Loss: 0.064566, Train Acc: 0.903846 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 29533 - Train Loss: 0.064565, Train Acc: 0.903846 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 29534 - Train Loss: 0.064564, Train Acc: 0.903846 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 29535 - Train Loss: 0.064563, Train Acc: 0.903846 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 29536 - Train Loss: 0.064561, Train Acc: 0.903846 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 29537 - Train Loss: 0.064560, Train Acc: 0.903846 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 29538 - Train Loss: 0.064559, Train Acc: 0.903846 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 29539 - Train Loss: 0.064558, Train Acc: 0.903846 | Val Loss: 0.104869, Val Acc: 0.793814\n",
      "Epoch 29540 - Train Loss: 0.064557, Train Acc: 0.903846 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 29541 - Train Loss: 0.064556, Train Acc: 0.903846 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 29542 - Train Loss: 0.064555, Train Acc: 0.903846 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 29543 - Train Loss: 0.064554, Train Acc: 0.903846 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 29544 - Train Loss: 0.064553, Train Acc: 0.903846 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 29545 - Train Loss: 0.064552, Train Acc: 0.903846 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 29546 - Train Loss: 0.064551, Train Acc: 0.903846 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 29547 - Train Loss: 0.064550, Train Acc: 0.903846 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 29548 - Train Loss: 0.064549, Train Acc: 0.903846 | Val Loss: 0.104870, Val Acc: 0.793814\n",
      "Epoch 29549 - Train Loss: 0.064547, Train Acc: 0.903846 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 29550 - Train Loss: 0.064546, Train Acc: 0.903846 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 29551 - Train Loss: 0.064545, Train Acc: 0.903846 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 29552 - Train Loss: 0.064544, Train Acc: 0.903846 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 29553 - Train Loss: 0.064543, Train Acc: 0.903846 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 29554 - Train Loss: 0.064542, Train Acc: 0.903846 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 29555 - Train Loss: 0.064541, Train Acc: 0.903846 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 29556 - Train Loss: 0.064540, Train Acc: 0.903846 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 29557 - Train Loss: 0.064539, Train Acc: 0.903846 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 29558 - Train Loss: 0.064538, Train Acc: 0.903846 | Val Loss: 0.104871, Val Acc: 0.793814\n",
      "Epoch 29559 - Train Loss: 0.064537, Train Acc: 0.903846 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 29560 - Train Loss: 0.064536, Train Acc: 0.903846 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 29561 - Train Loss: 0.064535, Train Acc: 0.903846 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 29562 - Train Loss: 0.064534, Train Acc: 0.903846 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 29563 - Train Loss: 0.064532, Train Acc: 0.903846 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 29564 - Train Loss: 0.064531, Train Acc: 0.903846 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 29565 - Train Loss: 0.064530, Train Acc: 0.903846 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 29566 - Train Loss: 0.064529, Train Acc: 0.903846 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 29567 - Train Loss: 0.064528, Train Acc: 0.903846 | Val Loss: 0.104872, Val Acc: 0.793814\n",
      "Epoch 29568 - Train Loss: 0.064527, Train Acc: 0.903846 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 29569 - Train Loss: 0.064526, Train Acc: 0.903846 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 29570 - Train Loss: 0.064525, Train Acc: 0.903846 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 29571 - Train Loss: 0.064524, Train Acc: 0.903846 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 29572 - Train Loss: 0.064523, Train Acc: 0.903846 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 29573 - Train Loss: 0.064522, Train Acc: 0.903846 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 29574 - Train Loss: 0.064521, Train Acc: 0.903846 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 29575 - Train Loss: 0.064520, Train Acc: 0.903846 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 29576 - Train Loss: 0.064518, Train Acc: 0.903846 | Val Loss: 0.104873, Val Acc: 0.793814\n",
      "Epoch 29577 - Train Loss: 0.064517, Train Acc: 0.903846 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 29578 - Train Loss: 0.064516, Train Acc: 0.903846 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 29579 - Train Loss: 0.064515, Train Acc: 0.903846 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 29580 - Train Loss: 0.064514, Train Acc: 0.903846 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 29581 - Train Loss: 0.064513, Train Acc: 0.903846 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 29582 - Train Loss: 0.064512, Train Acc: 0.903846 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 29583 - Train Loss: 0.064511, Train Acc: 0.903846 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 29584 - Train Loss: 0.064510, Train Acc: 0.903846 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 29585 - Train Loss: 0.064509, Train Acc: 0.903846 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 29586 - Train Loss: 0.064508, Train Acc: 0.903846 | Val Loss: 0.104874, Val Acc: 0.793814\n",
      "Epoch 29587 - Train Loss: 0.064507, Train Acc: 0.903846 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 29588 - Train Loss: 0.064506, Train Acc: 0.903846 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 29589 - Train Loss: 0.064505, Train Acc: 0.903846 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 29590 - Train Loss: 0.064503, Train Acc: 0.903846 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 29591 - Train Loss: 0.064502, Train Acc: 0.903846 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 29592 - Train Loss: 0.064501, Train Acc: 0.903846 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 29593 - Train Loss: 0.064500, Train Acc: 0.903846 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 29594 - Train Loss: 0.064499, Train Acc: 0.903846 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 29595 - Train Loss: 0.064498, Train Acc: 0.903846 | Val Loss: 0.104875, Val Acc: 0.793814\n",
      "Epoch 29596 - Train Loss: 0.064497, Train Acc: 0.903846 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 29597 - Train Loss: 0.064496, Train Acc: 0.903846 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 29598 - Train Loss: 0.064495, Train Acc: 0.903846 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 29599 - Train Loss: 0.064494, Train Acc: 0.903846 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 29600 - Train Loss: 0.064493, Train Acc: 0.903846 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 29601 - Train Loss: 0.064492, Train Acc: 0.903846 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 29602 - Train Loss: 0.064491, Train Acc: 0.903846 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 29603 - Train Loss: 0.064490, Train Acc: 0.903846 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 29604 - Train Loss: 0.064488, Train Acc: 0.903846 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 29605 - Train Loss: 0.064487, Train Acc: 0.903846 | Val Loss: 0.104876, Val Acc: 0.793814\n",
      "Epoch 29606 - Train Loss: 0.064486, Train Acc: 0.903846 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 29607 - Train Loss: 0.064485, Train Acc: 0.903846 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 29608 - Train Loss: 0.064484, Train Acc: 0.903846 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 29609 - Train Loss: 0.064483, Train Acc: 0.903846 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 29610 - Train Loss: 0.064482, Train Acc: 0.903846 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 29611 - Train Loss: 0.064481, Train Acc: 0.903846 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 29612 - Train Loss: 0.064480, Train Acc: 0.903846 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 29613 - Train Loss: 0.064479, Train Acc: 0.903846 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 29614 - Train Loss: 0.064478, Train Acc: 0.903846 | Val Loss: 0.104877, Val Acc: 0.793814\n",
      "Epoch 29615 - Train Loss: 0.064477, Train Acc: 0.903846 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 29616 - Train Loss: 0.064476, Train Acc: 0.903846 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 29617 - Train Loss: 0.064475, Train Acc: 0.903846 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 29618 - Train Loss: 0.064473, Train Acc: 0.903846 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 29619 - Train Loss: 0.064472, Train Acc: 0.903846 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 29620 - Train Loss: 0.064471, Train Acc: 0.903846 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 29621 - Train Loss: 0.064470, Train Acc: 0.903846 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 29622 - Train Loss: 0.064469, Train Acc: 0.903846 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 29623 - Train Loss: 0.064468, Train Acc: 0.903846 | Val Loss: 0.104878, Val Acc: 0.793814\n",
      "Epoch 29624 - Train Loss: 0.064467, Train Acc: 0.903846 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 29625 - Train Loss: 0.064466, Train Acc: 0.903846 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 29626 - Train Loss: 0.064465, Train Acc: 0.903846 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 29627 - Train Loss: 0.064464, Train Acc: 0.903846 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 29628 - Train Loss: 0.064463, Train Acc: 0.903846 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 29629 - Train Loss: 0.064462, Train Acc: 0.903846 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 29630 - Train Loss: 0.064461, Train Acc: 0.903846 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 29631 - Train Loss: 0.064460, Train Acc: 0.903846 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 29632 - Train Loss: 0.064458, Train Acc: 0.903846 | Val Loss: 0.104879, Val Acc: 0.793814\n",
      "Epoch 29633 - Train Loss: 0.064457, Train Acc: 0.903846 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 29634 - Train Loss: 0.064456, Train Acc: 0.903846 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 29635 - Train Loss: 0.064455, Train Acc: 0.903846 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 29636 - Train Loss: 0.064454, Train Acc: 0.903846 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 29637 - Train Loss: 0.064453, Train Acc: 0.903846 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 29638 - Train Loss: 0.064452, Train Acc: 0.903846 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 29639 - Train Loss: 0.064451, Train Acc: 0.903846 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 29640 - Train Loss: 0.064450, Train Acc: 0.903846 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 29641 - Train Loss: 0.064449, Train Acc: 0.903846 | Val Loss: 0.104880, Val Acc: 0.793814\n",
      "Epoch 29642 - Train Loss: 0.064448, Train Acc: 0.903846 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 29643 - Train Loss: 0.064447, Train Acc: 0.903846 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 29644 - Train Loss: 0.064446, Train Acc: 0.903846 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 29645 - Train Loss: 0.064445, Train Acc: 0.903846 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 29646 - Train Loss: 0.064443, Train Acc: 0.903846 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 29647 - Train Loss: 0.064442, Train Acc: 0.903846 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 29648 - Train Loss: 0.064441, Train Acc: 0.903846 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 29649 - Train Loss: 0.064440, Train Acc: 0.903846 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 29650 - Train Loss: 0.064439, Train Acc: 0.903846 | Val Loss: 0.104881, Val Acc: 0.793814\n",
      "Epoch 29651 - Train Loss: 0.064438, Train Acc: 0.903846 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 29652 - Train Loss: 0.064437, Train Acc: 0.903846 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 29653 - Train Loss: 0.064436, Train Acc: 0.903846 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 29654 - Train Loss: 0.064435, Train Acc: 0.903846 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 29655 - Train Loss: 0.064434, Train Acc: 0.903846 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 29656 - Train Loss: 0.064433, Train Acc: 0.903846 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 29657 - Train Loss: 0.064432, Train Acc: 0.903846 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 29658 - Train Loss: 0.064431, Train Acc: 0.903846 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 29659 - Train Loss: 0.064430, Train Acc: 0.903846 | Val Loss: 0.104882, Val Acc: 0.793814\n",
      "Epoch 29660 - Train Loss: 0.064429, Train Acc: 0.903846 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 29661 - Train Loss: 0.064427, Train Acc: 0.903846 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 29662 - Train Loss: 0.064426, Train Acc: 0.903846 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 29663 - Train Loss: 0.064425, Train Acc: 0.903846 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 29664 - Train Loss: 0.064424, Train Acc: 0.903846 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 29665 - Train Loss: 0.064423, Train Acc: 0.903846 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 29666 - Train Loss: 0.064422, Train Acc: 0.903846 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 29667 - Train Loss: 0.064421, Train Acc: 0.903846 | Val Loss: 0.104883, Val Acc: 0.793814\n",
      "Epoch 29668 - Train Loss: 0.064420, Train Acc: 0.903846 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 29669 - Train Loss: 0.064419, Train Acc: 0.903846 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 29670 - Train Loss: 0.064418, Train Acc: 0.903846 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 29671 - Train Loss: 0.064417, Train Acc: 0.903846 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 29672 - Train Loss: 0.064416, Train Acc: 0.903846 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 29673 - Train Loss: 0.064415, Train Acc: 0.903846 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 29674 - Train Loss: 0.064414, Train Acc: 0.903846 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 29675 - Train Loss: 0.064412, Train Acc: 0.903846 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 29676 - Train Loss: 0.064411, Train Acc: 0.903846 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 29677 - Train Loss: 0.064410, Train Acc: 0.903846 | Val Loss: 0.104884, Val Acc: 0.793814\n",
      "Epoch 29678 - Train Loss: 0.064409, Train Acc: 0.903846 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 29679 - Train Loss: 0.064408, Train Acc: 0.903846 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 29680 - Train Loss: 0.064407, Train Acc: 0.903846 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 29681 - Train Loss: 0.064406, Train Acc: 0.903846 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 29682 - Train Loss: 0.064405, Train Acc: 0.903846 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 29683 - Train Loss: 0.064404, Train Acc: 0.903846 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 29684 - Train Loss: 0.064403, Train Acc: 0.903846 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 29685 - Train Loss: 0.064402, Train Acc: 0.903846 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 29686 - Train Loss: 0.064401, Train Acc: 0.903846 | Val Loss: 0.104885, Val Acc: 0.793814\n",
      "Epoch 29687 - Train Loss: 0.064400, Train Acc: 0.903846 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 29688 - Train Loss: 0.064399, Train Acc: 0.903846 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 29689 - Train Loss: 0.064398, Train Acc: 0.903846 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 29690 - Train Loss: 0.064396, Train Acc: 0.903846 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 29691 - Train Loss: 0.064395, Train Acc: 0.903846 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 29692 - Train Loss: 0.064394, Train Acc: 0.903846 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 29693 - Train Loss: 0.064393, Train Acc: 0.903846 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 29694 - Train Loss: 0.064392, Train Acc: 0.903846 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 29695 - Train Loss: 0.064391, Train Acc: 0.903846 | Val Loss: 0.104886, Val Acc: 0.793814\n",
      "Epoch 29696 - Train Loss: 0.064390, Train Acc: 0.903846 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 29697 - Train Loss: 0.064389, Train Acc: 0.903846 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 29698 - Train Loss: 0.064388, Train Acc: 0.903846 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 29699 - Train Loss: 0.064387, Train Acc: 0.903846 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 29700 - Train Loss: 0.064386, Train Acc: 0.903846 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 29701 - Train Loss: 0.064385, Train Acc: 0.903846 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 29702 - Train Loss: 0.064384, Train Acc: 0.903846 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 29703 - Train Loss: 0.064383, Train Acc: 0.903846 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 29704 - Train Loss: 0.064382, Train Acc: 0.903846 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 29705 - Train Loss: 0.064380, Train Acc: 0.903846 | Val Loss: 0.104887, Val Acc: 0.793814\n",
      "Epoch 29706 - Train Loss: 0.064379, Train Acc: 0.903846 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 29707 - Train Loss: 0.064378, Train Acc: 0.903846 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 29708 - Train Loss: 0.064377, Train Acc: 0.903846 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 29709 - Train Loss: 0.064376, Train Acc: 0.903846 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 29710 - Train Loss: 0.064375, Train Acc: 0.903846 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 29711 - Train Loss: 0.064374, Train Acc: 0.903846 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 29712 - Train Loss: 0.064373, Train Acc: 0.903846 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 29713 - Train Loss: 0.064372, Train Acc: 0.903846 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 29714 - Train Loss: 0.064371, Train Acc: 0.903846 | Val Loss: 0.104888, Val Acc: 0.793814\n",
      "Epoch 29715 - Train Loss: 0.064370, Train Acc: 0.903846 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 29716 - Train Loss: 0.064369, Train Acc: 0.903846 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 29717 - Train Loss: 0.064368, Train Acc: 0.903846 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 29718 - Train Loss: 0.064367, Train Acc: 0.903846 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 29719 - Train Loss: 0.064366, Train Acc: 0.903846 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 29720 - Train Loss: 0.064364, Train Acc: 0.903846 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 29721 - Train Loss: 0.064363, Train Acc: 0.903846 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 29722 - Train Loss: 0.064362, Train Acc: 0.903846 | Val Loss: 0.104889, Val Acc: 0.793814\n",
      "Epoch 29723 - Train Loss: 0.064361, Train Acc: 0.903846 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 29724 - Train Loss: 0.064360, Train Acc: 0.903846 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 29725 - Train Loss: 0.064359, Train Acc: 0.903846 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 29726 - Train Loss: 0.064358, Train Acc: 0.903846 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 29727 - Train Loss: 0.064357, Train Acc: 0.903846 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 29728 - Train Loss: 0.064356, Train Acc: 0.903846 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 29729 - Train Loss: 0.064355, Train Acc: 0.903846 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 29730 - Train Loss: 0.064354, Train Acc: 0.903846 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 29731 - Train Loss: 0.064353, Train Acc: 0.903846 | Val Loss: 0.104890, Val Acc: 0.793814\n",
      "Epoch 29732 - Train Loss: 0.064352, Train Acc: 0.903846 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 29733 - Train Loss: 0.064351, Train Acc: 0.903846 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 29734 - Train Loss: 0.064350, Train Acc: 0.903846 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 29735 - Train Loss: 0.064348, Train Acc: 0.903846 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 29736 - Train Loss: 0.064347, Train Acc: 0.903846 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 29737 - Train Loss: 0.064346, Train Acc: 0.903846 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 29738 - Train Loss: 0.064345, Train Acc: 0.903846 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 29739 - Train Loss: 0.064344, Train Acc: 0.903846 | Val Loss: 0.104891, Val Acc: 0.793814\n",
      "Epoch 29740 - Train Loss: 0.064343, Train Acc: 0.903846 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 29741 - Train Loss: 0.064342, Train Acc: 0.903846 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 29742 - Train Loss: 0.064341, Train Acc: 0.903846 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 29743 - Train Loss: 0.064340, Train Acc: 0.903846 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 29744 - Train Loss: 0.064339, Train Acc: 0.903846 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 29745 - Train Loss: 0.064338, Train Acc: 0.903846 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 29746 - Train Loss: 0.064337, Train Acc: 0.903846 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 29747 - Train Loss: 0.064336, Train Acc: 0.903846 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 29748 - Train Loss: 0.064335, Train Acc: 0.903846 | Val Loss: 0.104892, Val Acc: 0.793814\n",
      "Epoch 29749 - Train Loss: 0.064334, Train Acc: 0.903846 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 29750 - Train Loss: 0.064332, Train Acc: 0.903846 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 29751 - Train Loss: 0.064331, Train Acc: 0.903846 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 29752 - Train Loss: 0.064330, Train Acc: 0.903846 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 29753 - Train Loss: 0.064329, Train Acc: 0.903846 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 29754 - Train Loss: 0.064328, Train Acc: 0.903846 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 29755 - Train Loss: 0.064327, Train Acc: 0.903846 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 29756 - Train Loss: 0.064326, Train Acc: 0.903846 | Val Loss: 0.104893, Val Acc: 0.793814\n",
      "Epoch 29757 - Train Loss: 0.064325, Train Acc: 0.903846 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 29758 - Train Loss: 0.064324, Train Acc: 0.903846 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 29759 - Train Loss: 0.064323, Train Acc: 0.903846 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 29760 - Train Loss: 0.064322, Train Acc: 0.903846 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 29761 - Train Loss: 0.064321, Train Acc: 0.903846 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 29762 - Train Loss: 0.064320, Train Acc: 0.903846 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 29763 - Train Loss: 0.064319, Train Acc: 0.903846 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 29764 - Train Loss: 0.064318, Train Acc: 0.903846 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 29765 - Train Loss: 0.064317, Train Acc: 0.903846 | Val Loss: 0.104894, Val Acc: 0.793814\n",
      "Epoch 29766 - Train Loss: 0.064315, Train Acc: 0.903846 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 29767 - Train Loss: 0.064314, Train Acc: 0.903846 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 29768 - Train Loss: 0.064313, Train Acc: 0.903846 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 29769 - Train Loss: 0.064312, Train Acc: 0.903846 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 29770 - Train Loss: 0.064311, Train Acc: 0.903846 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 29771 - Train Loss: 0.064310, Train Acc: 0.903846 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 29772 - Train Loss: 0.064309, Train Acc: 0.903846 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 29773 - Train Loss: 0.064308, Train Acc: 0.903846 | Val Loss: 0.104895, Val Acc: 0.793814\n",
      "Epoch 29774 - Train Loss: 0.064307, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29775 - Train Loss: 0.064306, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29776 - Train Loss: 0.064305, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29777 - Train Loss: 0.064304, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29778 - Train Loss: 0.064303, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29779 - Train Loss: 0.064302, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29780 - Train Loss: 0.064301, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29781 - Train Loss: 0.064299, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29782 - Train Loss: 0.064298, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29783 - Train Loss: 0.064297, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29784 - Train Loss: 0.064296, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29785 - Train Loss: 0.064295, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29786 - Train Loss: 0.064294, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29787 - Train Loss: 0.064293, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29788 - Train Loss: 0.064292, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29789 - Train Loss: 0.064291, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29790 - Train Loss: 0.064290, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29791 - Train Loss: 0.064289, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29792 - Train Loss: 0.064288, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29793 - Train Loss: 0.064287, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29794 - Train Loss: 0.064286, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29795 - Train Loss: 0.064285, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29796 - Train Loss: 0.064284, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29797 - Train Loss: 0.064282, Train Acc: 0.903846 | Val Loss: 0.104896, Val Acc: 0.793814\n",
      "Epoch 29798 - Train Loss: 0.064281, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29799 - Train Loss: 0.064280, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29800 - Train Loss: 0.064279, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29801 - Train Loss: 0.064278, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29802 - Train Loss: 0.064277, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29803 - Train Loss: 0.064276, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29804 - Train Loss: 0.064275, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29805 - Train Loss: 0.064274, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29806 - Train Loss: 0.064273, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29807 - Train Loss: 0.064272, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29808 - Train Loss: 0.064271, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29809 - Train Loss: 0.064270, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29810 - Train Loss: 0.064269, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29811 - Train Loss: 0.064268, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29812 - Train Loss: 0.064267, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29813 - Train Loss: 0.064265, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29814 - Train Loss: 0.064264, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29815 - Train Loss: 0.064263, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29816 - Train Loss: 0.064262, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29817 - Train Loss: 0.064261, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29818 - Train Loss: 0.064260, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29819 - Train Loss: 0.064259, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29820 - Train Loss: 0.064258, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29821 - Train Loss: 0.064257, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29822 - Train Loss: 0.064256, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29823 - Train Loss: 0.064255, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29824 - Train Loss: 0.064254, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29825 - Train Loss: 0.064253, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29826 - Train Loss: 0.064252, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29827 - Train Loss: 0.064251, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29828 - Train Loss: 0.064250, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29829 - Train Loss: 0.064249, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29830 - Train Loss: 0.064247, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29831 - Train Loss: 0.064246, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29832 - Train Loss: 0.064245, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29833 - Train Loss: 0.064244, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29834 - Train Loss: 0.064243, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29835 - Train Loss: 0.064242, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29836 - Train Loss: 0.064241, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29837 - Train Loss: 0.064240, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29838 - Train Loss: 0.064239, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29839 - Train Loss: 0.064238, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29840 - Train Loss: 0.064237, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29841 - Train Loss: 0.064236, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29842 - Train Loss: 0.064235, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29843 - Train Loss: 0.064234, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29844 - Train Loss: 0.064233, Train Acc: 0.903846 | Val Loss: 0.104897, Val Acc: 0.793814\n",
      "Epoch 29845 - Train Loss: 0.064232, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29846 - Train Loss: 0.064230, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29847 - Train Loss: 0.064229, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29848 - Train Loss: 0.064228, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29849 - Train Loss: 0.064227, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29850 - Train Loss: 0.064226, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29851 - Train Loss: 0.064225, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29852 - Train Loss: 0.064224, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29853 - Train Loss: 0.064223, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29854 - Train Loss: 0.064222, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29855 - Train Loss: 0.064221, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29856 - Train Loss: 0.064220, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29857 - Train Loss: 0.064219, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29858 - Train Loss: 0.064218, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29859 - Train Loss: 0.064217, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29860 - Train Loss: 0.064216, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29861 - Train Loss: 0.064215, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29862 - Train Loss: 0.064214, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29863 - Train Loss: 0.064212, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29864 - Train Loss: 0.064211, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29865 - Train Loss: 0.064210, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29866 - Train Loss: 0.064209, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29867 - Train Loss: 0.064208, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29868 - Train Loss: 0.064207, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29869 - Train Loss: 0.064206, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29870 - Train Loss: 0.064205, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29871 - Train Loss: 0.064204, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29872 - Train Loss: 0.064203, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29873 - Train Loss: 0.064202, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29874 - Train Loss: 0.064201, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29875 - Train Loss: 0.064200, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29876 - Train Loss: 0.064199, Train Acc: 0.903846 | Val Loss: 0.104898, Val Acc: 0.793814\n",
      "Epoch 29877 - Train Loss: 0.064198, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29878 - Train Loss: 0.064197, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29879 - Train Loss: 0.064196, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29880 - Train Loss: 0.064195, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29881 - Train Loss: 0.064193, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29882 - Train Loss: 0.064192, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29883 - Train Loss: 0.064191, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29884 - Train Loss: 0.064190, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29885 - Train Loss: 0.064189, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29886 - Train Loss: 0.064188, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29887 - Train Loss: 0.064187, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29888 - Train Loss: 0.064186, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29889 - Train Loss: 0.064185, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29890 - Train Loss: 0.064184, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29891 - Train Loss: 0.064183, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29892 - Train Loss: 0.064182, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29893 - Train Loss: 0.064181, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29894 - Train Loss: 0.064180, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29895 - Train Loss: 0.064179, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29896 - Train Loss: 0.064178, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29897 - Train Loss: 0.064177, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29898 - Train Loss: 0.064176, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29899 - Train Loss: 0.064174, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29900 - Train Loss: 0.064173, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29901 - Train Loss: 0.064172, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29902 - Train Loss: 0.064171, Train Acc: 0.903846 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29903 - Train Loss: 0.064170, Train Acc: 0.905128 | Val Loss: 0.104899, Val Acc: 0.793814\n",
      "Epoch 29904 - Train Loss: 0.064169, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29905 - Train Loss: 0.064168, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29906 - Train Loss: 0.064167, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29907 - Train Loss: 0.064166, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29908 - Train Loss: 0.064165, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29909 - Train Loss: 0.064164, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29910 - Train Loss: 0.064163, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29911 - Train Loss: 0.064162, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29912 - Train Loss: 0.064161, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29913 - Train Loss: 0.064160, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29914 - Train Loss: 0.064159, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29915 - Train Loss: 0.064158, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29916 - Train Loss: 0.064157, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29917 - Train Loss: 0.064155, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29918 - Train Loss: 0.064154, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29919 - Train Loss: 0.064153, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29920 - Train Loss: 0.064152, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29921 - Train Loss: 0.064151, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29922 - Train Loss: 0.064150, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29923 - Train Loss: 0.064149, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29924 - Train Loss: 0.064148, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29925 - Train Loss: 0.064147, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29926 - Train Loss: 0.064146, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29927 - Train Loss: 0.064145, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29928 - Train Loss: 0.064144, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29929 - Train Loss: 0.064143, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29930 - Train Loss: 0.064142, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29931 - Train Loss: 0.064141, Train Acc: 0.905128 | Val Loss: 0.104900, Val Acc: 0.793814\n",
      "Epoch 29932 - Train Loss: 0.064140, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29933 - Train Loss: 0.064139, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29934 - Train Loss: 0.064138, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29935 - Train Loss: 0.064137, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29936 - Train Loss: 0.064135, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29937 - Train Loss: 0.064134, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29938 - Train Loss: 0.064133, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29939 - Train Loss: 0.064132, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29940 - Train Loss: 0.064131, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29941 - Train Loss: 0.064130, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29942 - Train Loss: 0.064129, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29943 - Train Loss: 0.064128, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29944 - Train Loss: 0.064127, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29945 - Train Loss: 0.064126, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29946 - Train Loss: 0.064125, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29947 - Train Loss: 0.064124, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29948 - Train Loss: 0.064123, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29949 - Train Loss: 0.064122, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29950 - Train Loss: 0.064121, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29951 - Train Loss: 0.064120, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29952 - Train Loss: 0.064119, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29953 - Train Loss: 0.064118, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29954 - Train Loss: 0.064117, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29955 - Train Loss: 0.064115, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29956 - Train Loss: 0.064114, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29957 - Train Loss: 0.064113, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29958 - Train Loss: 0.064112, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29959 - Train Loss: 0.064111, Train Acc: 0.905128 | Val Loss: 0.104901, Val Acc: 0.793814\n",
      "Epoch 29960 - Train Loss: 0.064110, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29961 - Train Loss: 0.064109, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29962 - Train Loss: 0.064108, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29963 - Train Loss: 0.064107, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29964 - Train Loss: 0.064106, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29965 - Train Loss: 0.064105, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29966 - Train Loss: 0.064104, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29967 - Train Loss: 0.064103, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29968 - Train Loss: 0.064102, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29969 - Train Loss: 0.064101, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29970 - Train Loss: 0.064100, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29971 - Train Loss: 0.064099, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29972 - Train Loss: 0.064098, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29973 - Train Loss: 0.064097, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29974 - Train Loss: 0.064095, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29975 - Train Loss: 0.064094, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29976 - Train Loss: 0.064093, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29977 - Train Loss: 0.064092, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29978 - Train Loss: 0.064091, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29979 - Train Loss: 0.064090, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29980 - Train Loss: 0.064089, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29981 - Train Loss: 0.064088, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29982 - Train Loss: 0.064087, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29983 - Train Loss: 0.064086, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29984 - Train Loss: 0.064085, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29985 - Train Loss: 0.064084, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 29986 - Train Loss: 0.064083, Train Acc: 0.905128 | Val Loss: 0.104902, Val Acc: 0.793814\n",
      "Epoch 29987 - Train Loss: 0.064082, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 29988 - Train Loss: 0.064081, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 29989 - Train Loss: 0.064080, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 29990 - Train Loss: 0.064079, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 29991 - Train Loss: 0.064078, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 29992 - Train Loss: 0.064077, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 29993 - Train Loss: 0.064076, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 29994 - Train Loss: 0.064074, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 29995 - Train Loss: 0.064073, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 29996 - Train Loss: 0.064072, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 29997 - Train Loss: 0.064071, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 29998 - Train Loss: 0.064070, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 29999 - Train Loss: 0.064069, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 30000 - Train Loss: 0.064068, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 30001 - Train Loss: 0.064067, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 30002 - Train Loss: 0.064066, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 30003 - Train Loss: 0.064065, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 30004 - Train Loss: 0.064064, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 30005 - Train Loss: 0.064063, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 30006 - Train Loss: 0.064062, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 30007 - Train Loss: 0.064061, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 30008 - Train Loss: 0.064060, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 30009 - Train Loss: 0.064059, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 30010 - Train Loss: 0.064058, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 30011 - Train Loss: 0.064057, Train Acc: 0.905128 | Val Loss: 0.104903, Val Acc: 0.793814\n",
      "Epoch 30012 - Train Loss: 0.064056, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30013 - Train Loss: 0.064055, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30014 - Train Loss: 0.064053, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30015 - Train Loss: 0.064052, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30016 - Train Loss: 0.064051, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30017 - Train Loss: 0.064050, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30018 - Train Loss: 0.064049, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30019 - Train Loss: 0.064048, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30020 - Train Loss: 0.064047, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30021 - Train Loss: 0.064046, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30022 - Train Loss: 0.064045, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30023 - Train Loss: 0.064044, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30024 - Train Loss: 0.064043, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30025 - Train Loss: 0.064042, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30026 - Train Loss: 0.064041, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30027 - Train Loss: 0.064040, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30028 - Train Loss: 0.064039, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30029 - Train Loss: 0.064038, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30030 - Train Loss: 0.064037, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30031 - Train Loss: 0.064036, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30032 - Train Loss: 0.064035, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30033 - Train Loss: 0.064034, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30034 - Train Loss: 0.064032, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30035 - Train Loss: 0.064031, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30036 - Train Loss: 0.064030, Train Acc: 0.905128 | Val Loss: 0.104904, Val Acc: 0.793814\n",
      "Epoch 30037 - Train Loss: 0.064029, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30038 - Train Loss: 0.064028, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30039 - Train Loss: 0.064027, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30040 - Train Loss: 0.064026, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30041 - Train Loss: 0.064025, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30042 - Train Loss: 0.064024, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30043 - Train Loss: 0.064023, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30044 - Train Loss: 0.064022, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30045 - Train Loss: 0.064021, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30046 - Train Loss: 0.064020, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30047 - Train Loss: 0.064019, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30048 - Train Loss: 0.064018, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30049 - Train Loss: 0.064017, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30050 - Train Loss: 0.064016, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30051 - Train Loss: 0.064015, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30052 - Train Loss: 0.064014, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30053 - Train Loss: 0.064013, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30054 - Train Loss: 0.064012, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30055 - Train Loss: 0.064010, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30056 - Train Loss: 0.064009, Train Acc: 0.905128 | Val Loss: 0.104905, Val Acc: 0.793814\n",
      "Epoch 30057 - Train Loss: 0.064008, Train Acc: 0.905128 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 30058 - Train Loss: 0.064007, Train Acc: 0.905128 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 30059 - Train Loss: 0.064006, Train Acc: 0.905128 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 30060 - Train Loss: 0.064005, Train Acc: 0.905128 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 30061 - Train Loss: 0.064004, Train Acc: 0.905128 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 30062 - Train Loss: 0.064003, Train Acc: 0.905128 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 30063 - Train Loss: 0.064002, Train Acc: 0.905128 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 30064 - Train Loss: 0.064001, Train Acc: 0.905128 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 30065 - Train Loss: 0.064000, Train Acc: 0.905128 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 30066 - Train Loss: 0.063999, Train Acc: 0.905128 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 30067 - Train Loss: 0.063998, Train Acc: 0.905128 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 30068 - Train Loss: 0.063997, Train Acc: 0.905128 | Val Loss: 0.104906, Val Acc: 0.793814\n",
      "Epoch 30069 - Train Loss: 0.063996, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30070 - Train Loss: 0.063995, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30071 - Train Loss: 0.063994, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30072 - Train Loss: 0.063993, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30073 - Train Loss: 0.063992, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30074 - Train Loss: 0.063991, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30075 - Train Loss: 0.063990, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30076 - Train Loss: 0.063989, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30077 - Train Loss: 0.063988, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30078 - Train Loss: 0.063986, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30079 - Train Loss: 0.063985, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30080 - Train Loss: 0.063984, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30081 - Train Loss: 0.063983, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30082 - Train Loss: 0.063982, Train Acc: 0.905128 | Val Loss: 0.104907, Val Acc: 0.793814\n",
      "Epoch 30083 - Train Loss: 0.063981, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30084 - Train Loss: 0.063980, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30085 - Train Loss: 0.063979, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30086 - Train Loss: 0.063978, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30087 - Train Loss: 0.063977, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30088 - Train Loss: 0.063976, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30089 - Train Loss: 0.063975, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30090 - Train Loss: 0.063974, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30091 - Train Loss: 0.063973, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30092 - Train Loss: 0.063972, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30093 - Train Loss: 0.063971, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30094 - Train Loss: 0.063970, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30095 - Train Loss: 0.063969, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30096 - Train Loss: 0.063968, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30097 - Train Loss: 0.063967, Train Acc: 0.905128 | Val Loss: 0.104908, Val Acc: 0.793814\n",
      "Epoch 30098 - Train Loss: 0.063966, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30099 - Train Loss: 0.063965, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30100 - Train Loss: 0.063964, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30101 - Train Loss: 0.063963, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30102 - Train Loss: 0.063961, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30103 - Train Loss: 0.063960, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30104 - Train Loss: 0.063959, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30105 - Train Loss: 0.063958, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30106 - Train Loss: 0.063957, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30107 - Train Loss: 0.063956, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30108 - Train Loss: 0.063955, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30109 - Train Loss: 0.063954, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30110 - Train Loss: 0.063953, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30111 - Train Loss: 0.063952, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30112 - Train Loss: 0.063951, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30113 - Train Loss: 0.063950, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30114 - Train Loss: 0.063949, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30115 - Train Loss: 0.063948, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30116 - Train Loss: 0.063947, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30117 - Train Loss: 0.063946, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30118 - Train Loss: 0.063945, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30119 - Train Loss: 0.063944, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30120 - Train Loss: 0.063943, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30121 - Train Loss: 0.063942, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30122 - Train Loss: 0.063941, Train Acc: 0.905128 | Val Loss: 0.104909, Val Acc: 0.793814\n",
      "Epoch 30123 - Train Loss: 0.063940, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30124 - Train Loss: 0.063939, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30125 - Train Loss: 0.063938, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30126 - Train Loss: 0.063936, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30127 - Train Loss: 0.063935, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30128 - Train Loss: 0.063934, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30129 - Train Loss: 0.063933, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30130 - Train Loss: 0.063932, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30131 - Train Loss: 0.063931, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30132 - Train Loss: 0.063930, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30133 - Train Loss: 0.063929, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30134 - Train Loss: 0.063928, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30135 - Train Loss: 0.063927, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30136 - Train Loss: 0.063926, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30137 - Train Loss: 0.063925, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30138 - Train Loss: 0.063924, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30139 - Train Loss: 0.063923, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30140 - Train Loss: 0.063922, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30141 - Train Loss: 0.063921, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30142 - Train Loss: 0.063920, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30143 - Train Loss: 0.063919, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30144 - Train Loss: 0.063918, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30145 - Train Loss: 0.063917, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30146 - Train Loss: 0.063916, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30147 - Train Loss: 0.063915, Train Acc: 0.905128 | Val Loss: 0.104910, Val Acc: 0.793814\n",
      "Epoch 30148 - Train Loss: 0.063914, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30149 - Train Loss: 0.063913, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30150 - Train Loss: 0.063912, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30151 - Train Loss: 0.063910, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30152 - Train Loss: 0.063909, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30153 - Train Loss: 0.063908, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30154 - Train Loss: 0.063907, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30155 - Train Loss: 0.063906, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30156 - Train Loss: 0.063905, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30157 - Train Loss: 0.063904, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30158 - Train Loss: 0.063903, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30159 - Train Loss: 0.063902, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30160 - Train Loss: 0.063901, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30161 - Train Loss: 0.063900, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30162 - Train Loss: 0.063899, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30163 - Train Loss: 0.063898, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30164 - Train Loss: 0.063897, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30165 - Train Loss: 0.063896, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30166 - Train Loss: 0.063895, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30167 - Train Loss: 0.063894, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30168 - Train Loss: 0.063893, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30169 - Train Loss: 0.063892, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30170 - Train Loss: 0.063891, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30171 - Train Loss: 0.063890, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30172 - Train Loss: 0.063889, Train Acc: 0.905128 | Val Loss: 0.104911, Val Acc: 0.793814\n",
      "Epoch 30173 - Train Loss: 0.063888, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30174 - Train Loss: 0.063887, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30175 - Train Loss: 0.063886, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30176 - Train Loss: 0.063884, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30177 - Train Loss: 0.063883, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30178 - Train Loss: 0.063882, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30179 - Train Loss: 0.063881, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30180 - Train Loss: 0.063880, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30181 - Train Loss: 0.063879, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30182 - Train Loss: 0.063878, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30183 - Train Loss: 0.063877, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30184 - Train Loss: 0.063876, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30185 - Train Loss: 0.063875, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30186 - Train Loss: 0.063874, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30187 - Train Loss: 0.063873, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30188 - Train Loss: 0.063872, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30189 - Train Loss: 0.063871, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30190 - Train Loss: 0.063870, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30191 - Train Loss: 0.063869, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30192 - Train Loss: 0.063868, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30193 - Train Loss: 0.063867, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30194 - Train Loss: 0.063866, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30195 - Train Loss: 0.063865, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30196 - Train Loss: 0.063864, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30197 - Train Loss: 0.063863, Train Acc: 0.905128 | Val Loss: 0.104912, Val Acc: 0.793814\n",
      "Epoch 30198 - Train Loss: 0.063862, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30199 - Train Loss: 0.063861, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30200 - Train Loss: 0.063860, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30201 - Train Loss: 0.063859, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30202 - Train Loss: 0.063858, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30203 - Train Loss: 0.063856, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30204 - Train Loss: 0.063855, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30205 - Train Loss: 0.063854, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30206 - Train Loss: 0.063853, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30207 - Train Loss: 0.063852, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30208 - Train Loss: 0.063851, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30209 - Train Loss: 0.063850, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30210 - Train Loss: 0.063849, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30211 - Train Loss: 0.063848, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30212 - Train Loss: 0.063847, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30213 - Train Loss: 0.063846, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30214 - Train Loss: 0.063845, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30215 - Train Loss: 0.063844, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30216 - Train Loss: 0.063843, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30217 - Train Loss: 0.063842, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30218 - Train Loss: 0.063841, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30219 - Train Loss: 0.063840, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30220 - Train Loss: 0.063839, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30221 - Train Loss: 0.063838, Train Acc: 0.905128 | Val Loss: 0.104913, Val Acc: 0.793814\n",
      "Epoch 30222 - Train Loss: 0.063837, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30223 - Train Loss: 0.063836, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30224 - Train Loss: 0.063835, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30225 - Train Loss: 0.063834, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30226 - Train Loss: 0.063833, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30227 - Train Loss: 0.063832, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30228 - Train Loss: 0.063831, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30229 - Train Loss: 0.063830, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30230 - Train Loss: 0.063829, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30231 - Train Loss: 0.063827, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30232 - Train Loss: 0.063826, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30233 - Train Loss: 0.063825, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30234 - Train Loss: 0.063824, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30235 - Train Loss: 0.063823, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30236 - Train Loss: 0.063822, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30237 - Train Loss: 0.063821, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30238 - Train Loss: 0.063820, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30239 - Train Loss: 0.063819, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30240 - Train Loss: 0.063818, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30241 - Train Loss: 0.063817, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30242 - Train Loss: 0.063816, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30243 - Train Loss: 0.063815, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30244 - Train Loss: 0.063814, Train Acc: 0.905128 | Val Loss: 0.104914, Val Acc: 0.793814\n",
      "Epoch 30245 - Train Loss: 0.063813, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30246 - Train Loss: 0.063812, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30247 - Train Loss: 0.063811, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30248 - Train Loss: 0.063810, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30249 - Train Loss: 0.063809, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30250 - Train Loss: 0.063808, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30251 - Train Loss: 0.063807, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30252 - Train Loss: 0.063806, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30253 - Train Loss: 0.063805, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30254 - Train Loss: 0.063804, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30255 - Train Loss: 0.063803, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30256 - Train Loss: 0.063802, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30257 - Train Loss: 0.063801, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30258 - Train Loss: 0.063800, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30259 - Train Loss: 0.063799, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30260 - Train Loss: 0.063797, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30261 - Train Loss: 0.063796, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30262 - Train Loss: 0.063795, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30263 - Train Loss: 0.063794, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30264 - Train Loss: 0.063793, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30265 - Train Loss: 0.063792, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30266 - Train Loss: 0.063791, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30267 - Train Loss: 0.063790, Train Acc: 0.905128 | Val Loss: 0.104915, Val Acc: 0.793814\n",
      "Epoch 30268 - Train Loss: 0.063789, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30269 - Train Loss: 0.063788, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30270 - Train Loss: 0.063787, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30271 - Train Loss: 0.063786, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30272 - Train Loss: 0.063785, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30273 - Train Loss: 0.063784, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30274 - Train Loss: 0.063783, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30275 - Train Loss: 0.063782, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30276 - Train Loss: 0.063781, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30277 - Train Loss: 0.063780, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30278 - Train Loss: 0.063779, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30279 - Train Loss: 0.063778, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30280 - Train Loss: 0.063777, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30281 - Train Loss: 0.063776, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30282 - Train Loss: 0.063775, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30283 - Train Loss: 0.063774, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30284 - Train Loss: 0.063773, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30285 - Train Loss: 0.063772, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30286 - Train Loss: 0.063771, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30287 - Train Loss: 0.063770, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30288 - Train Loss: 0.063769, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30289 - Train Loss: 0.063768, Train Acc: 0.905128 | Val Loss: 0.104916, Val Acc: 0.793814\n",
      "Epoch 30290 - Train Loss: 0.063766, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30291 - Train Loss: 0.063765, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30292 - Train Loss: 0.063764, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30293 - Train Loss: 0.063763, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30294 - Train Loss: 0.063762, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30295 - Train Loss: 0.063761, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30296 - Train Loss: 0.063760, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30297 - Train Loss: 0.063759, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30298 - Train Loss: 0.063758, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30299 - Train Loss: 0.063757, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30300 - Train Loss: 0.063756, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30301 - Train Loss: 0.063755, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30302 - Train Loss: 0.063754, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30303 - Train Loss: 0.063753, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30304 - Train Loss: 0.063752, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30305 - Train Loss: 0.063751, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30306 - Train Loss: 0.063750, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30307 - Train Loss: 0.063749, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30308 - Train Loss: 0.063748, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30309 - Train Loss: 0.063747, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30310 - Train Loss: 0.063746, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30311 - Train Loss: 0.063745, Train Acc: 0.905128 | Val Loss: 0.104917, Val Acc: 0.793814\n",
      "Epoch 30312 - Train Loss: 0.063744, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30313 - Train Loss: 0.063743, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30314 - Train Loss: 0.063742, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30315 - Train Loss: 0.063741, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30316 - Train Loss: 0.063740, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30317 - Train Loss: 0.063739, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30318 - Train Loss: 0.063738, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30319 - Train Loss: 0.063737, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30320 - Train Loss: 0.063736, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30321 - Train Loss: 0.063734, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30322 - Train Loss: 0.063733, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30323 - Train Loss: 0.063732, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30324 - Train Loss: 0.063731, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30325 - Train Loss: 0.063730, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30326 - Train Loss: 0.063729, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30327 - Train Loss: 0.063728, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30328 - Train Loss: 0.063727, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30329 - Train Loss: 0.063726, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30330 - Train Loss: 0.063725, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30331 - Train Loss: 0.063724, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30332 - Train Loss: 0.063723, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30333 - Train Loss: 0.063722, Train Acc: 0.905128 | Val Loss: 0.104918, Val Acc: 0.793814\n",
      "Epoch 30334 - Train Loss: 0.063721, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30335 - Train Loss: 0.063720, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30336 - Train Loss: 0.063719, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30337 - Train Loss: 0.063718, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30338 - Train Loss: 0.063717, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30339 - Train Loss: 0.063716, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30340 - Train Loss: 0.063715, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30341 - Train Loss: 0.063714, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30342 - Train Loss: 0.063713, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30343 - Train Loss: 0.063712, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30344 - Train Loss: 0.063711, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30345 - Train Loss: 0.063710, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30346 - Train Loss: 0.063709, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30347 - Train Loss: 0.063708, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30348 - Train Loss: 0.063707, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30349 - Train Loss: 0.063706, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30350 - Train Loss: 0.063705, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30351 - Train Loss: 0.063704, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30352 - Train Loss: 0.063703, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30353 - Train Loss: 0.063702, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30354 - Train Loss: 0.063701, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30355 - Train Loss: 0.063699, Train Acc: 0.905128 | Val Loss: 0.104919, Val Acc: 0.793814\n",
      "Epoch 30356 - Train Loss: 0.063698, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30357 - Train Loss: 0.063697, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30358 - Train Loss: 0.063696, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30359 - Train Loss: 0.063695, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30360 - Train Loss: 0.063694, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30361 - Train Loss: 0.063693, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30362 - Train Loss: 0.063692, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30363 - Train Loss: 0.063691, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30364 - Train Loss: 0.063690, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30365 - Train Loss: 0.063689, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30366 - Train Loss: 0.063688, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30367 - Train Loss: 0.063687, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30368 - Train Loss: 0.063686, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30369 - Train Loss: 0.063685, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30370 - Train Loss: 0.063684, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30371 - Train Loss: 0.063683, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30372 - Train Loss: 0.063682, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30373 - Train Loss: 0.063681, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30374 - Train Loss: 0.063680, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30375 - Train Loss: 0.063679, Train Acc: 0.905128 | Val Loss: 0.104920, Val Acc: 0.793814\n",
      "Epoch 30376 - Train Loss: 0.063678, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30377 - Train Loss: 0.063677, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30378 - Train Loss: 0.063676, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30379 - Train Loss: 0.063675, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30380 - Train Loss: 0.063674, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30381 - Train Loss: 0.063673, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30382 - Train Loss: 0.063672, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30383 - Train Loss: 0.063671, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30384 - Train Loss: 0.063670, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30385 - Train Loss: 0.063669, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30386 - Train Loss: 0.063668, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30387 - Train Loss: 0.063667, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30388 - Train Loss: 0.063666, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30389 - Train Loss: 0.063665, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30390 - Train Loss: 0.063663, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30391 - Train Loss: 0.063662, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30392 - Train Loss: 0.063661, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30393 - Train Loss: 0.063660, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30394 - Train Loss: 0.063659, Train Acc: 0.905128 | Val Loss: 0.104921, Val Acc: 0.793814\n",
      "Epoch 30395 - Train Loss: 0.063658, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30396 - Train Loss: 0.063657, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30397 - Train Loss: 0.063656, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30398 - Train Loss: 0.063655, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30399 - Train Loss: 0.063654, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30400 - Train Loss: 0.063653, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30401 - Train Loss: 0.063652, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30402 - Train Loss: 0.063651, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30403 - Train Loss: 0.063650, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30404 - Train Loss: 0.063649, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30405 - Train Loss: 0.063648, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30406 - Train Loss: 0.063647, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30407 - Train Loss: 0.063646, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30408 - Train Loss: 0.063645, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30409 - Train Loss: 0.063644, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30410 - Train Loss: 0.063643, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30411 - Train Loss: 0.063642, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30412 - Train Loss: 0.063641, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30413 - Train Loss: 0.063640, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30414 - Train Loss: 0.063639, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30415 - Train Loss: 0.063638, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30416 - Train Loss: 0.063637, Train Acc: 0.905128 | Val Loss: 0.104922, Val Acc: 0.793814\n",
      "Epoch 30417 - Train Loss: 0.063636, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30418 - Train Loss: 0.063635, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30419 - Train Loss: 0.063634, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30420 - Train Loss: 0.063633, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30421 - Train Loss: 0.063632, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30422 - Train Loss: 0.063631, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30423 - Train Loss: 0.063630, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30424 - Train Loss: 0.063629, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30425 - Train Loss: 0.063628, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30426 - Train Loss: 0.063627, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30427 - Train Loss: 0.063626, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30428 - Train Loss: 0.063624, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30429 - Train Loss: 0.063623, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30430 - Train Loss: 0.063622, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30431 - Train Loss: 0.063621, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30432 - Train Loss: 0.063620, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30433 - Train Loss: 0.063619, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30434 - Train Loss: 0.063618, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30435 - Train Loss: 0.063617, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30436 - Train Loss: 0.063616, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30437 - Train Loss: 0.063615, Train Acc: 0.905128 | Val Loss: 0.104923, Val Acc: 0.793814\n",
      "Epoch 30438 - Train Loss: 0.063614, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30439 - Train Loss: 0.063613, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30440 - Train Loss: 0.063612, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30441 - Train Loss: 0.063611, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30442 - Train Loss: 0.063610, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30443 - Train Loss: 0.063609, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30444 - Train Loss: 0.063608, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30445 - Train Loss: 0.063607, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30446 - Train Loss: 0.063606, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30447 - Train Loss: 0.063605, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30448 - Train Loss: 0.063604, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30449 - Train Loss: 0.063603, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30450 - Train Loss: 0.063602, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30451 - Train Loss: 0.063601, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30452 - Train Loss: 0.063600, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30453 - Train Loss: 0.063599, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30454 - Train Loss: 0.063598, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30455 - Train Loss: 0.063597, Train Acc: 0.905128 | Val Loss: 0.104924, Val Acc: 0.793814\n",
      "Epoch 30456 - Train Loss: 0.063596, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30457 - Train Loss: 0.063595, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30458 - Train Loss: 0.063594, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30459 - Train Loss: 0.063593, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30460 - Train Loss: 0.063592, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30461 - Train Loss: 0.063591, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30462 - Train Loss: 0.063590, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30463 - Train Loss: 0.063589, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30464 - Train Loss: 0.063588, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30465 - Train Loss: 0.063587, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30466 - Train Loss: 0.063586, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30467 - Train Loss: 0.063585, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30468 - Train Loss: 0.063583, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30469 - Train Loss: 0.063582, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30470 - Train Loss: 0.063581, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30471 - Train Loss: 0.063580, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30472 - Train Loss: 0.063579, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30473 - Train Loss: 0.063578, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30474 - Train Loss: 0.063577, Train Acc: 0.905128 | Val Loss: 0.104925, Val Acc: 0.793814\n",
      "Epoch 30475 - Train Loss: 0.063576, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30476 - Train Loss: 0.063575, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30477 - Train Loss: 0.063574, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30478 - Train Loss: 0.063573, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30479 - Train Loss: 0.063572, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30480 - Train Loss: 0.063571, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30481 - Train Loss: 0.063570, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30482 - Train Loss: 0.063569, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30483 - Train Loss: 0.063568, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30484 - Train Loss: 0.063567, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30485 - Train Loss: 0.063566, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30486 - Train Loss: 0.063565, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30487 - Train Loss: 0.063564, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30488 - Train Loss: 0.063563, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30489 - Train Loss: 0.063562, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30490 - Train Loss: 0.063561, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30491 - Train Loss: 0.063560, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30492 - Train Loss: 0.063559, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30493 - Train Loss: 0.063558, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30494 - Train Loss: 0.063557, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30495 - Train Loss: 0.063556, Train Acc: 0.905128 | Val Loss: 0.104926, Val Acc: 0.793814\n",
      "Epoch 30496 - Train Loss: 0.063555, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30497 - Train Loss: 0.063554, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30498 - Train Loss: 0.063553, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30499 - Train Loss: 0.063552, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30500 - Train Loss: 0.063551, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30501 - Train Loss: 0.063550, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30502 - Train Loss: 0.063549, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30503 - Train Loss: 0.063548, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30504 - Train Loss: 0.063547, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30505 - Train Loss: 0.063546, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30506 - Train Loss: 0.063545, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30507 - Train Loss: 0.063544, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30508 - Train Loss: 0.063543, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30509 - Train Loss: 0.063542, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30510 - Train Loss: 0.063541, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30511 - Train Loss: 0.063540, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30512 - Train Loss: 0.063538, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30513 - Train Loss: 0.063537, Train Acc: 0.905128 | Val Loss: 0.104927, Val Acc: 0.793814\n",
      "Epoch 30514 - Train Loss: 0.063536, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30515 - Train Loss: 0.063535, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30516 - Train Loss: 0.063534, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30517 - Train Loss: 0.063533, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30518 - Train Loss: 0.063532, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30519 - Train Loss: 0.063531, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30520 - Train Loss: 0.063530, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30521 - Train Loss: 0.063529, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30522 - Train Loss: 0.063528, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30523 - Train Loss: 0.063527, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30524 - Train Loss: 0.063526, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30525 - Train Loss: 0.063525, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30526 - Train Loss: 0.063524, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30527 - Train Loss: 0.063523, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30528 - Train Loss: 0.063522, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30529 - Train Loss: 0.063521, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30530 - Train Loss: 0.063520, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30531 - Train Loss: 0.063519, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30532 - Train Loss: 0.063518, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30533 - Train Loss: 0.063517, Train Acc: 0.905128 | Val Loss: 0.104928, Val Acc: 0.793814\n",
      "Epoch 30534 - Train Loss: 0.063516, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30535 - Train Loss: 0.063515, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30536 - Train Loss: 0.063514, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30537 - Train Loss: 0.063513, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30538 - Train Loss: 0.063512, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30539 - Train Loss: 0.063511, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30540 - Train Loss: 0.063510, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30541 - Train Loss: 0.063509, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30542 - Train Loss: 0.063508, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30543 - Train Loss: 0.063507, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30544 - Train Loss: 0.063506, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30545 - Train Loss: 0.063505, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30546 - Train Loss: 0.063504, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30547 - Train Loss: 0.063503, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30548 - Train Loss: 0.063502, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30549 - Train Loss: 0.063501, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30550 - Train Loss: 0.063500, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30551 - Train Loss: 0.063499, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30552 - Train Loss: 0.063498, Train Acc: 0.905128 | Val Loss: 0.104929, Val Acc: 0.793814\n",
      "Epoch 30553 - Train Loss: 0.063497, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30554 - Train Loss: 0.063496, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30555 - Train Loss: 0.063495, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30556 - Train Loss: 0.063494, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30557 - Train Loss: 0.063493, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30558 - Train Loss: 0.063492, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30559 - Train Loss: 0.063491, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30560 - Train Loss: 0.063490, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30561 - Train Loss: 0.063488, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30562 - Train Loss: 0.063487, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30563 - Train Loss: 0.063486, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30564 - Train Loss: 0.063485, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30565 - Train Loss: 0.063484, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30566 - Train Loss: 0.063483, Train Acc: 0.905128 | Val Loss: 0.104930, Val Acc: 0.793814\n",
      "Epoch 30567 - Train Loss: 0.063482, Train Acc: 0.905128 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 30568 - Train Loss: 0.063481, Train Acc: 0.905128 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 30569 - Train Loss: 0.063480, Train Acc: 0.905128 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 30570 - Train Loss: 0.063479, Train Acc: 0.905128 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 30571 - Train Loss: 0.063478, Train Acc: 0.905128 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 30572 - Train Loss: 0.063477, Train Acc: 0.905128 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 30573 - Train Loss: 0.063476, Train Acc: 0.905128 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 30574 - Train Loss: 0.063475, Train Acc: 0.905128 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 30575 - Train Loss: 0.063474, Train Acc: 0.905128 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 30576 - Train Loss: 0.063473, Train Acc: 0.905128 | Val Loss: 0.104931, Val Acc: 0.793814\n",
      "Epoch 30577 - Train Loss: 0.063472, Train Acc: 0.905128 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 30578 - Train Loss: 0.063471, Train Acc: 0.905128 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 30579 - Train Loss: 0.063470, Train Acc: 0.905128 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 30580 - Train Loss: 0.063469, Train Acc: 0.905128 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 30581 - Train Loss: 0.063468, Train Acc: 0.905128 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 30582 - Train Loss: 0.063467, Train Acc: 0.905128 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 30583 - Train Loss: 0.063466, Train Acc: 0.905128 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 30584 - Train Loss: 0.063465, Train Acc: 0.905128 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 30585 - Train Loss: 0.063464, Train Acc: 0.905128 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 30586 - Train Loss: 0.063463, Train Acc: 0.905128 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 30587 - Train Loss: 0.063462, Train Acc: 0.905128 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 30588 - Train Loss: 0.063461, Train Acc: 0.905128 | Val Loss: 0.104932, Val Acc: 0.793814\n",
      "Epoch 30589 - Train Loss: 0.063460, Train Acc: 0.905128 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 30590 - Train Loss: 0.063459, Train Acc: 0.905128 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 30591 - Train Loss: 0.063458, Train Acc: 0.905128 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 30592 - Train Loss: 0.063457, Train Acc: 0.905128 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 30593 - Train Loss: 0.063456, Train Acc: 0.905128 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 30594 - Train Loss: 0.063455, Train Acc: 0.905128 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 30595 - Train Loss: 0.063454, Train Acc: 0.905128 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 30596 - Train Loss: 0.063453, Train Acc: 0.905128 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 30597 - Train Loss: 0.063452, Train Acc: 0.905128 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 30598 - Train Loss: 0.063451, Train Acc: 0.905128 | Val Loss: 0.104933, Val Acc: 0.793814\n",
      "Epoch 30599 - Train Loss: 0.063450, Train Acc: 0.905128 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 30600 - Train Loss: 0.063449, Train Acc: 0.905128 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 30601 - Train Loss: 0.063448, Train Acc: 0.905128 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 30602 - Train Loss: 0.063447, Train Acc: 0.905128 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 30603 - Train Loss: 0.063446, Train Acc: 0.905128 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 30604 - Train Loss: 0.063445, Train Acc: 0.905128 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 30605 - Train Loss: 0.063444, Train Acc: 0.905128 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 30606 - Train Loss: 0.063443, Train Acc: 0.905128 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 30607 - Train Loss: 0.063442, Train Acc: 0.905128 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 30608 - Train Loss: 0.063441, Train Acc: 0.905128 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 30609 - Train Loss: 0.063440, Train Acc: 0.905128 | Val Loss: 0.104934, Val Acc: 0.793814\n",
      "Epoch 30610 - Train Loss: 0.063439, Train Acc: 0.905128 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 30611 - Train Loss: 0.063438, Train Acc: 0.905128 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 30612 - Train Loss: 0.063437, Train Acc: 0.905128 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 30613 - Train Loss: 0.063436, Train Acc: 0.905128 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 30614 - Train Loss: 0.063435, Train Acc: 0.905128 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 30615 - Train Loss: 0.063434, Train Acc: 0.905128 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 30616 - Train Loss: 0.063433, Train Acc: 0.905128 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 30617 - Train Loss: 0.063432, Train Acc: 0.905128 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 30618 - Train Loss: 0.063431, Train Acc: 0.905128 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 30619 - Train Loss: 0.063430, Train Acc: 0.905128 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 30620 - Train Loss: 0.063429, Train Acc: 0.906410 | Val Loss: 0.104935, Val Acc: 0.793814\n",
      "Epoch 30621 - Train Loss: 0.063428, Train Acc: 0.906410 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 30622 - Train Loss: 0.063426, Train Acc: 0.906410 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 30623 - Train Loss: 0.063425, Train Acc: 0.906410 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 30624 - Train Loss: 0.063424, Train Acc: 0.906410 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 30625 - Train Loss: 0.063423, Train Acc: 0.906410 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 30626 - Train Loss: 0.063422, Train Acc: 0.906410 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 30627 - Train Loss: 0.063421, Train Acc: 0.906410 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 30628 - Train Loss: 0.063420, Train Acc: 0.906410 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 30629 - Train Loss: 0.063419, Train Acc: 0.906410 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 30630 - Train Loss: 0.063418, Train Acc: 0.906410 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 30631 - Train Loss: 0.063417, Train Acc: 0.906410 | Val Loss: 0.104936, Val Acc: 0.793814\n",
      "Epoch 30632 - Train Loss: 0.063416, Train Acc: 0.906410 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 30633 - Train Loss: 0.063415, Train Acc: 0.906410 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 30634 - Train Loss: 0.063414, Train Acc: 0.906410 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 30635 - Train Loss: 0.063413, Train Acc: 0.906410 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 30636 - Train Loss: 0.063412, Train Acc: 0.906410 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 30637 - Train Loss: 0.063411, Train Acc: 0.906410 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 30638 - Train Loss: 0.063410, Train Acc: 0.906410 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 30639 - Train Loss: 0.063409, Train Acc: 0.906410 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 30640 - Train Loss: 0.063408, Train Acc: 0.906410 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 30641 - Train Loss: 0.063407, Train Acc: 0.906410 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 30642 - Train Loss: 0.063406, Train Acc: 0.906410 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 30643 - Train Loss: 0.063405, Train Acc: 0.906410 | Val Loss: 0.104937, Val Acc: 0.793814\n",
      "Epoch 30644 - Train Loss: 0.063404, Train Acc: 0.906410 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 30645 - Train Loss: 0.063403, Train Acc: 0.906410 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 30646 - Train Loss: 0.063402, Train Acc: 0.906410 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 30647 - Train Loss: 0.063401, Train Acc: 0.906410 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 30648 - Train Loss: 0.063400, Train Acc: 0.906410 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 30649 - Train Loss: 0.063399, Train Acc: 0.906410 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 30650 - Train Loss: 0.063398, Train Acc: 0.906410 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 30651 - Train Loss: 0.063397, Train Acc: 0.906410 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 30652 - Train Loss: 0.063396, Train Acc: 0.906410 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 30653 - Train Loss: 0.063395, Train Acc: 0.906410 | Val Loss: 0.104938, Val Acc: 0.793814\n",
      "Epoch 30654 - Train Loss: 0.063394, Train Acc: 0.906410 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 30655 - Train Loss: 0.063393, Train Acc: 0.906410 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 30656 - Train Loss: 0.063392, Train Acc: 0.906410 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 30657 - Train Loss: 0.063391, Train Acc: 0.906410 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 30658 - Train Loss: 0.063390, Train Acc: 0.906410 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 30659 - Train Loss: 0.063389, Train Acc: 0.906410 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 30660 - Train Loss: 0.063388, Train Acc: 0.906410 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 30661 - Train Loss: 0.063387, Train Acc: 0.906410 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 30662 - Train Loss: 0.063386, Train Acc: 0.906410 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 30663 - Train Loss: 0.063385, Train Acc: 0.906410 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 30664 - Train Loss: 0.063384, Train Acc: 0.906410 | Val Loss: 0.104939, Val Acc: 0.793814\n",
      "Epoch 30665 - Train Loss: 0.063383, Train Acc: 0.906410 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 30666 - Train Loss: 0.063382, Train Acc: 0.906410 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 30667 - Train Loss: 0.063381, Train Acc: 0.906410 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 30668 - Train Loss: 0.063380, Train Acc: 0.906410 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 30669 - Train Loss: 0.063379, Train Acc: 0.906410 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 30670 - Train Loss: 0.063378, Train Acc: 0.906410 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 30671 - Train Loss: 0.063377, Train Acc: 0.906410 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 30672 - Train Loss: 0.063376, Train Acc: 0.906410 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 30673 - Train Loss: 0.063375, Train Acc: 0.906410 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 30674 - Train Loss: 0.063374, Train Acc: 0.906410 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 30675 - Train Loss: 0.063373, Train Acc: 0.906410 | Val Loss: 0.104940, Val Acc: 0.793814\n",
      "Epoch 30676 - Train Loss: 0.063372, Train Acc: 0.906410 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 30677 - Train Loss: 0.063371, Train Acc: 0.906410 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 30678 - Train Loss: 0.063370, Train Acc: 0.906410 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 30679 - Train Loss: 0.063369, Train Acc: 0.906410 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 30680 - Train Loss: 0.063368, Train Acc: 0.906410 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 30681 - Train Loss: 0.063367, Train Acc: 0.906410 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 30682 - Train Loss: 0.063366, Train Acc: 0.906410 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 30683 - Train Loss: 0.063365, Train Acc: 0.906410 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 30684 - Train Loss: 0.063364, Train Acc: 0.906410 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 30685 - Train Loss: 0.063363, Train Acc: 0.906410 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 30686 - Train Loss: 0.063362, Train Acc: 0.906410 | Val Loss: 0.104941, Val Acc: 0.793814\n",
      "Epoch 30687 - Train Loss: 0.063361, Train Acc: 0.906410 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 30688 - Train Loss: 0.063360, Train Acc: 0.906410 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 30689 - Train Loss: 0.063359, Train Acc: 0.906410 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 30690 - Train Loss: 0.063358, Train Acc: 0.906410 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 30691 - Train Loss: 0.063357, Train Acc: 0.906410 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 30692 - Train Loss: 0.063356, Train Acc: 0.906410 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 30693 - Train Loss: 0.063355, Train Acc: 0.906410 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 30694 - Train Loss: 0.063354, Train Acc: 0.906410 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 30695 - Train Loss: 0.063353, Train Acc: 0.906410 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 30696 - Train Loss: 0.063352, Train Acc: 0.906410 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 30697 - Train Loss: 0.063351, Train Acc: 0.906410 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 30698 - Train Loss: 0.063350, Train Acc: 0.906410 | Val Loss: 0.104942, Val Acc: 0.793814\n",
      "Epoch 30699 - Train Loss: 0.063348, Train Acc: 0.906410 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 30700 - Train Loss: 0.063347, Train Acc: 0.906410 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 30701 - Train Loss: 0.063346, Train Acc: 0.906410 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 30702 - Train Loss: 0.063345, Train Acc: 0.906410 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 30703 - Train Loss: 0.063344, Train Acc: 0.906410 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 30704 - Train Loss: 0.063343, Train Acc: 0.906410 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 30705 - Train Loss: 0.063342, Train Acc: 0.906410 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 30706 - Train Loss: 0.063341, Train Acc: 0.906410 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 30707 - Train Loss: 0.063340, Train Acc: 0.906410 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 30708 - Train Loss: 0.063339, Train Acc: 0.906410 | Val Loss: 0.104943, Val Acc: 0.793814\n",
      "Epoch 30709 - Train Loss: 0.063338, Train Acc: 0.906410 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 30710 - Train Loss: 0.063337, Train Acc: 0.906410 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 30711 - Train Loss: 0.063336, Train Acc: 0.906410 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 30712 - Train Loss: 0.063335, Train Acc: 0.906410 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 30713 - Train Loss: 0.063334, Train Acc: 0.906410 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 30714 - Train Loss: 0.063333, Train Acc: 0.906410 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 30715 - Train Loss: 0.063332, Train Acc: 0.906410 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 30716 - Train Loss: 0.063331, Train Acc: 0.906410 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 30717 - Train Loss: 0.063330, Train Acc: 0.906410 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 30718 - Train Loss: 0.063329, Train Acc: 0.906410 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 30719 - Train Loss: 0.063328, Train Acc: 0.906410 | Val Loss: 0.104944, Val Acc: 0.793814\n",
      "Epoch 30720 - Train Loss: 0.063327, Train Acc: 0.906410 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 30721 - Train Loss: 0.063326, Train Acc: 0.906410 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 30722 - Train Loss: 0.063325, Train Acc: 0.906410 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 30723 - Train Loss: 0.063324, Train Acc: 0.906410 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 30724 - Train Loss: 0.063323, Train Acc: 0.906410 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 30725 - Train Loss: 0.063322, Train Acc: 0.906410 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 30726 - Train Loss: 0.063321, Train Acc: 0.906410 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 30727 - Train Loss: 0.063320, Train Acc: 0.906410 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 30728 - Train Loss: 0.063319, Train Acc: 0.906410 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 30729 - Train Loss: 0.063318, Train Acc: 0.906410 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 30730 - Train Loss: 0.063317, Train Acc: 0.906410 | Val Loss: 0.104945, Val Acc: 0.793814\n",
      "Epoch 30731 - Train Loss: 0.063316, Train Acc: 0.906410 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 30732 - Train Loss: 0.063315, Train Acc: 0.906410 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 30733 - Train Loss: 0.063314, Train Acc: 0.906410 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 30734 - Train Loss: 0.063313, Train Acc: 0.906410 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 30735 - Train Loss: 0.063312, Train Acc: 0.906410 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 30736 - Train Loss: 0.063311, Train Acc: 0.906410 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 30737 - Train Loss: 0.063310, Train Acc: 0.906410 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 30738 - Train Loss: 0.063309, Train Acc: 0.906410 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 30739 - Train Loss: 0.063308, Train Acc: 0.906410 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 30740 - Train Loss: 0.063307, Train Acc: 0.906410 | Val Loss: 0.104946, Val Acc: 0.793814\n",
      "Epoch 30741 - Train Loss: 0.063306, Train Acc: 0.906410 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 30742 - Train Loss: 0.063305, Train Acc: 0.906410 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 30743 - Train Loss: 0.063304, Train Acc: 0.906410 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 30744 - Train Loss: 0.063303, Train Acc: 0.906410 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 30745 - Train Loss: 0.063302, Train Acc: 0.906410 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 30746 - Train Loss: 0.063301, Train Acc: 0.906410 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 30747 - Train Loss: 0.063300, Train Acc: 0.906410 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 30748 - Train Loss: 0.063299, Train Acc: 0.906410 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 30749 - Train Loss: 0.063298, Train Acc: 0.906410 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 30750 - Train Loss: 0.063297, Train Acc: 0.906410 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 30751 - Train Loss: 0.063296, Train Acc: 0.906410 | Val Loss: 0.104947, Val Acc: 0.793814\n",
      "Epoch 30752 - Train Loss: 0.063295, Train Acc: 0.906410 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 30753 - Train Loss: 0.063294, Train Acc: 0.906410 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 30754 - Train Loss: 0.063293, Train Acc: 0.906410 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 30755 - Train Loss: 0.063292, Train Acc: 0.906410 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 30756 - Train Loss: 0.063291, Train Acc: 0.906410 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 30757 - Train Loss: 0.063290, Train Acc: 0.906410 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 30758 - Train Loss: 0.063289, Train Acc: 0.906410 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 30759 - Train Loss: 0.063288, Train Acc: 0.906410 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 30760 - Train Loss: 0.063287, Train Acc: 0.906410 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 30761 - Train Loss: 0.063286, Train Acc: 0.906410 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 30762 - Train Loss: 0.063285, Train Acc: 0.906410 | Val Loss: 0.104948, Val Acc: 0.793814\n",
      "Epoch 30763 - Train Loss: 0.063284, Train Acc: 0.906410 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 30764 - Train Loss: 0.063283, Train Acc: 0.906410 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 30765 - Train Loss: 0.063282, Train Acc: 0.906410 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 30766 - Train Loss: 0.063281, Train Acc: 0.906410 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 30767 - Train Loss: 0.063280, Train Acc: 0.906410 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 30768 - Train Loss: 0.063279, Train Acc: 0.906410 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 30769 - Train Loss: 0.063278, Train Acc: 0.906410 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 30770 - Train Loss: 0.063277, Train Acc: 0.906410 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 30771 - Train Loss: 0.063276, Train Acc: 0.906410 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 30772 - Train Loss: 0.063275, Train Acc: 0.906410 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 30773 - Train Loss: 0.063274, Train Acc: 0.906410 | Val Loss: 0.104949, Val Acc: 0.793814\n",
      "Epoch 30774 - Train Loss: 0.063273, Train Acc: 0.906410 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 30775 - Train Loss: 0.063272, Train Acc: 0.906410 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 30776 - Train Loss: 0.063271, Train Acc: 0.906410 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 30777 - Train Loss: 0.063270, Train Acc: 0.906410 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 30778 - Train Loss: 0.063269, Train Acc: 0.906410 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 30779 - Train Loss: 0.063268, Train Acc: 0.906410 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 30780 - Train Loss: 0.063267, Train Acc: 0.906410 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 30781 - Train Loss: 0.063266, Train Acc: 0.906410 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 30782 - Train Loss: 0.063265, Train Acc: 0.906410 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 30783 - Train Loss: 0.063264, Train Acc: 0.906410 | Val Loss: 0.104950, Val Acc: 0.793814\n",
      "Epoch 30784 - Train Loss: 0.063263, Train Acc: 0.906410 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 30785 - Train Loss: 0.063262, Train Acc: 0.906410 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 30786 - Train Loss: 0.063261, Train Acc: 0.906410 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 30787 - Train Loss: 0.063260, Train Acc: 0.906410 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 30788 - Train Loss: 0.063259, Train Acc: 0.906410 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 30789 - Train Loss: 0.063258, Train Acc: 0.906410 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 30790 - Train Loss: 0.063257, Train Acc: 0.906410 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 30791 - Train Loss: 0.063256, Train Acc: 0.906410 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 30792 - Train Loss: 0.063255, Train Acc: 0.906410 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 30793 - Train Loss: 0.063254, Train Acc: 0.906410 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 30794 - Train Loss: 0.063253, Train Acc: 0.906410 | Val Loss: 0.104951, Val Acc: 0.793814\n",
      "Epoch 30795 - Train Loss: 0.063252, Train Acc: 0.906410 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 30796 - Train Loss: 0.063251, Train Acc: 0.906410 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 30797 - Train Loss: 0.063250, Train Acc: 0.906410 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 30798 - Train Loss: 0.063249, Train Acc: 0.906410 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 30799 - Train Loss: 0.063248, Train Acc: 0.906410 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 30800 - Train Loss: 0.063247, Train Acc: 0.906410 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 30801 - Train Loss: 0.063246, Train Acc: 0.906410 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 30802 - Train Loss: 0.063245, Train Acc: 0.906410 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 30803 - Train Loss: 0.063244, Train Acc: 0.906410 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 30804 - Train Loss: 0.063243, Train Acc: 0.906410 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 30805 - Train Loss: 0.063242, Train Acc: 0.906410 | Val Loss: 0.104952, Val Acc: 0.793814\n",
      "Epoch 30806 - Train Loss: 0.063241, Train Acc: 0.906410 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 30807 - Train Loss: 0.063240, Train Acc: 0.906410 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 30808 - Train Loss: 0.063239, Train Acc: 0.906410 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 30809 - Train Loss: 0.063238, Train Acc: 0.906410 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 30810 - Train Loss: 0.063237, Train Acc: 0.906410 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 30811 - Train Loss: 0.063236, Train Acc: 0.906410 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 30812 - Train Loss: 0.063235, Train Acc: 0.906410 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 30813 - Train Loss: 0.063234, Train Acc: 0.906410 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 30814 - Train Loss: 0.063233, Train Acc: 0.906410 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 30815 - Train Loss: 0.063232, Train Acc: 0.906410 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 30816 - Train Loss: 0.063231, Train Acc: 0.906410 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 30817 - Train Loss: 0.063229, Train Acc: 0.906410 | Val Loss: 0.104953, Val Acc: 0.793814\n",
      "Epoch 30818 - Train Loss: 0.063228, Train Acc: 0.906410 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 30819 - Train Loss: 0.063227, Train Acc: 0.906410 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 30820 - Train Loss: 0.063226, Train Acc: 0.906410 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 30821 - Train Loss: 0.063225, Train Acc: 0.906410 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 30822 - Train Loss: 0.063224, Train Acc: 0.906410 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 30823 - Train Loss: 0.063223, Train Acc: 0.906410 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 30824 - Train Loss: 0.063222, Train Acc: 0.906410 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 30825 - Train Loss: 0.063221, Train Acc: 0.906410 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 30826 - Train Loss: 0.063220, Train Acc: 0.906410 | Val Loss: 0.104954, Val Acc: 0.793814\n",
      "Epoch 30827 - Train Loss: 0.063219, Train Acc: 0.906410 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 30828 - Train Loss: 0.063218, Train Acc: 0.906410 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 30829 - Train Loss: 0.063217, Train Acc: 0.906410 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 30830 - Train Loss: 0.063216, Train Acc: 0.906410 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 30831 - Train Loss: 0.063215, Train Acc: 0.906410 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 30832 - Train Loss: 0.063214, Train Acc: 0.906410 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 30833 - Train Loss: 0.063213, Train Acc: 0.906410 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 30834 - Train Loss: 0.063212, Train Acc: 0.906410 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 30835 - Train Loss: 0.063211, Train Acc: 0.906410 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 30836 - Train Loss: 0.063210, Train Acc: 0.906410 | Val Loss: 0.104955, Val Acc: 0.793814\n",
      "Epoch 30837 - Train Loss: 0.063209, Train Acc: 0.906410 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 30838 - Train Loss: 0.063208, Train Acc: 0.906410 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 30839 - Train Loss: 0.063207, Train Acc: 0.906410 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 30840 - Train Loss: 0.063206, Train Acc: 0.906410 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 30841 - Train Loss: 0.063205, Train Acc: 0.906410 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 30842 - Train Loss: 0.063204, Train Acc: 0.906410 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 30843 - Train Loss: 0.063203, Train Acc: 0.906410 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 30844 - Train Loss: 0.063202, Train Acc: 0.906410 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 30845 - Train Loss: 0.063201, Train Acc: 0.906410 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 30846 - Train Loss: 0.063200, Train Acc: 0.906410 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 30847 - Train Loss: 0.063199, Train Acc: 0.906410 | Val Loss: 0.104956, Val Acc: 0.793814\n",
      "Epoch 30848 - Train Loss: 0.063198, Train Acc: 0.906410 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 30849 - Train Loss: 0.063197, Train Acc: 0.906410 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 30850 - Train Loss: 0.063196, Train Acc: 0.906410 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 30851 - Train Loss: 0.063195, Train Acc: 0.906410 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 30852 - Train Loss: 0.063194, Train Acc: 0.906410 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 30853 - Train Loss: 0.063193, Train Acc: 0.906410 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 30854 - Train Loss: 0.063192, Train Acc: 0.906410 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 30855 - Train Loss: 0.063191, Train Acc: 0.906410 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 30856 - Train Loss: 0.063190, Train Acc: 0.906410 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 30857 - Train Loss: 0.063189, Train Acc: 0.906410 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 30858 - Train Loss: 0.063188, Train Acc: 0.906410 | Val Loss: 0.104957, Val Acc: 0.793814\n",
      "Epoch 30859 - Train Loss: 0.063187, Train Acc: 0.906410 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 30860 - Train Loss: 0.063186, Train Acc: 0.906410 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 30861 - Train Loss: 0.063185, Train Acc: 0.906410 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 30862 - Train Loss: 0.063184, Train Acc: 0.906410 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 30863 - Train Loss: 0.063183, Train Acc: 0.906410 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 30864 - Train Loss: 0.063182, Train Acc: 0.906410 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 30865 - Train Loss: 0.063181, Train Acc: 0.906410 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 30866 - Train Loss: 0.063180, Train Acc: 0.906410 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 30867 - Train Loss: 0.063179, Train Acc: 0.906410 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 30868 - Train Loss: 0.063178, Train Acc: 0.906410 | Val Loss: 0.104958, Val Acc: 0.793814\n",
      "Epoch 30869 - Train Loss: 0.063177, Train Acc: 0.906410 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 30870 - Train Loss: 0.063176, Train Acc: 0.906410 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 30871 - Train Loss: 0.063175, Train Acc: 0.906410 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 30872 - Train Loss: 0.063174, Train Acc: 0.906410 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 30873 - Train Loss: 0.063173, Train Acc: 0.906410 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 30874 - Train Loss: 0.063172, Train Acc: 0.906410 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 30875 - Train Loss: 0.063171, Train Acc: 0.906410 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 30876 - Train Loss: 0.063170, Train Acc: 0.906410 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 30877 - Train Loss: 0.063169, Train Acc: 0.906410 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 30878 - Train Loss: 0.063168, Train Acc: 0.906410 | Val Loss: 0.104959, Val Acc: 0.793814\n",
      "Epoch 30879 - Train Loss: 0.063167, Train Acc: 0.906410 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 30880 - Train Loss: 0.063166, Train Acc: 0.906410 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 30881 - Train Loss: 0.063165, Train Acc: 0.906410 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 30882 - Train Loss: 0.063164, Train Acc: 0.906410 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 30883 - Train Loss: 0.063163, Train Acc: 0.906410 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 30884 - Train Loss: 0.063162, Train Acc: 0.906410 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 30885 - Train Loss: 0.063161, Train Acc: 0.906410 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 30886 - Train Loss: 0.063160, Train Acc: 0.906410 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 30887 - Train Loss: 0.063159, Train Acc: 0.906410 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 30888 - Train Loss: 0.063158, Train Acc: 0.906410 | Val Loss: 0.104960, Val Acc: 0.793814\n",
      "Epoch 30889 - Train Loss: 0.063157, Train Acc: 0.906410 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 30890 - Train Loss: 0.063156, Train Acc: 0.906410 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 30891 - Train Loss: 0.063155, Train Acc: 0.906410 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 30892 - Train Loss: 0.063154, Train Acc: 0.906410 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 30893 - Train Loss: 0.063153, Train Acc: 0.907692 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 30894 - Train Loss: 0.063152, Train Acc: 0.906410 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 30895 - Train Loss: 0.063151, Train Acc: 0.907692 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 30896 - Train Loss: 0.063150, Train Acc: 0.907692 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 30897 - Train Loss: 0.063149, Train Acc: 0.907692 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 30898 - Train Loss: 0.063148, Train Acc: 0.907692 | Val Loss: 0.104961, Val Acc: 0.793814\n",
      "Epoch 30899 - Train Loss: 0.063147, Train Acc: 0.907692 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 30900 - Train Loss: 0.063146, Train Acc: 0.907692 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 30901 - Train Loss: 0.063145, Train Acc: 0.907692 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 30902 - Train Loss: 0.063144, Train Acc: 0.907692 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 30903 - Train Loss: 0.063143, Train Acc: 0.907692 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 30904 - Train Loss: 0.063142, Train Acc: 0.907692 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 30905 - Train Loss: 0.063141, Train Acc: 0.907692 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 30906 - Train Loss: 0.063140, Train Acc: 0.907692 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 30907 - Train Loss: 0.063139, Train Acc: 0.907692 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 30908 - Train Loss: 0.063138, Train Acc: 0.907692 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 30909 - Train Loss: 0.063137, Train Acc: 0.907692 | Val Loss: 0.104962, Val Acc: 0.793814\n",
      "Epoch 30910 - Train Loss: 0.063136, Train Acc: 0.907692 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 30911 - Train Loss: 0.063135, Train Acc: 0.907692 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 30912 - Train Loss: 0.063134, Train Acc: 0.907692 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 30913 - Train Loss: 0.063133, Train Acc: 0.907692 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 30914 - Train Loss: 0.063132, Train Acc: 0.907692 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 30915 - Train Loss: 0.063131, Train Acc: 0.907692 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 30916 - Train Loss: 0.063130, Train Acc: 0.907692 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 30917 - Train Loss: 0.063129, Train Acc: 0.907692 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 30918 - Train Loss: 0.063128, Train Acc: 0.907692 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 30919 - Train Loss: 0.063127, Train Acc: 0.907692 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 30920 - Train Loss: 0.063126, Train Acc: 0.907692 | Val Loss: 0.104963, Val Acc: 0.793814\n",
      "Epoch 30921 - Train Loss: 0.063125, Train Acc: 0.907692 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 30922 - Train Loss: 0.063124, Train Acc: 0.907692 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 30923 - Train Loss: 0.063123, Train Acc: 0.907692 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 30924 - Train Loss: 0.063122, Train Acc: 0.907692 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 30925 - Train Loss: 0.063121, Train Acc: 0.907692 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 30926 - Train Loss: 0.063120, Train Acc: 0.907692 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 30927 - Train Loss: 0.063119, Train Acc: 0.907692 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 30928 - Train Loss: 0.063118, Train Acc: 0.907692 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 30929 - Train Loss: 0.063117, Train Acc: 0.907692 | Val Loss: 0.104964, Val Acc: 0.793814\n",
      "Epoch 30930 - Train Loss: 0.063116, Train Acc: 0.907692 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 30931 - Train Loss: 0.063115, Train Acc: 0.907692 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 30932 - Train Loss: 0.063114, Train Acc: 0.907692 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 30933 - Train Loss: 0.063113, Train Acc: 0.907692 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 30934 - Train Loss: 0.063112, Train Acc: 0.907692 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 30935 - Train Loss: 0.063111, Train Acc: 0.907692 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 30936 - Train Loss: 0.063110, Train Acc: 0.907692 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 30937 - Train Loss: 0.063109, Train Acc: 0.907692 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 30938 - Train Loss: 0.063108, Train Acc: 0.907692 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 30939 - Train Loss: 0.063107, Train Acc: 0.907692 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 30940 - Train Loss: 0.063106, Train Acc: 0.907692 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 30941 - Train Loss: 0.063105, Train Acc: 0.907692 | Val Loss: 0.104965, Val Acc: 0.793814\n",
      "Epoch 30942 - Train Loss: 0.063104, Train Acc: 0.907692 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 30943 - Train Loss: 0.063103, Train Acc: 0.907692 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 30944 - Train Loss: 0.063102, Train Acc: 0.907692 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 30945 - Train Loss: 0.063101, Train Acc: 0.907692 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 30946 - Train Loss: 0.063100, Train Acc: 0.907692 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 30947 - Train Loss: 0.063099, Train Acc: 0.907692 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 30948 - Train Loss: 0.063098, Train Acc: 0.907692 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 30949 - Train Loss: 0.063097, Train Acc: 0.907692 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 30950 - Train Loss: 0.063096, Train Acc: 0.907692 | Val Loss: 0.104966, Val Acc: 0.793814\n",
      "Epoch 30951 - Train Loss: 0.063095, Train Acc: 0.907692 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 30952 - Train Loss: 0.063094, Train Acc: 0.907692 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 30953 - Train Loss: 0.063093, Train Acc: 0.907692 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 30954 - Train Loss: 0.063092, Train Acc: 0.907692 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 30955 - Train Loss: 0.063091, Train Acc: 0.907692 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 30956 - Train Loss: 0.063090, Train Acc: 0.907692 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 30957 - Train Loss: 0.063089, Train Acc: 0.907692 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 30958 - Train Loss: 0.063088, Train Acc: 0.907692 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 30959 - Train Loss: 0.063087, Train Acc: 0.907692 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Epoch 30960 - Train Loss: 0.063086, Train Acc: 0.907692 | Val Loss: 0.104967, Val Acc: 0.793814\n",
      "Cost has not changed for 10 epochs, stopping training.\n",
      "--- 115.01325535774231 seconds ---\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(X_train.shape[0], 60, 5)\n",
    "\n",
    "# init time for training\n",
    "import time\n",
    "start_time = time.time()\n",
    "history_cost, history_acc, val_cost, val_acc = model.train_until_cost_doesnt_change(\n",
    "    X_train, y_train, 0.005, X_val, y_val\n",
    ")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2677d483b80>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the cost and accuracy in one graph\n",
    "plt.plot(history_cost, label='Train Loss')\n",
    "plt.plot(val_cost, label='Validation Loss')\n",
    "plt.plot(history_acc, label='Train Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.text(len(history_cost) - 50, history_cost[-1] + 0.01, str(round(history_cost[-1], 3)))\n",
    "plt.text(len(history_acc) - 50, history_acc[-1] - 0.03, str(round(history_acc[-1], 3)))\n",
    "plt.text(len(val_cost) - 50, val_cost[-1] + 0.01, str(round(val_cost[-1], 3)))\n",
    "plt.text(len(val_acc) - 50, val_acc[-1] - 0.03, str(round(val_acc[-1], 3)))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss / Accuracy')\n",
    "plt.title('Train and Validation Metrics for Model ' + model_name)\n",
    "plt.legend(fontsize=8)  # Ukuran font legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model and the cost and accuracy\n",
    "file_name = 'NeuralNetwork_Model_' + model_name + '.pkl'\n",
    "file_name_cost_acc = 'Cost_Accuracy_Model_' + model_name + '.csv'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save cost & accuracy\n",
    "cost_acc = pd.DataFrame({\n",
    "    'train_cost': history_cost,\n",
    "    'train_acc': history_acc,\n",
    "    'val_cost': val_cost,\n",
    "    'val_acc': val_acc\n",
    "})\n",
    "cost_acc.to_csv(file_name_cost_acc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 0, 3, 0, 4, 2, 0, 0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3,\n",
      "       3, 4, 0, 2, 4, 0, 0, 3, 1, 4, 0, 0, 3, 0, 3, 1, 1, 0, 1, 4, 0, 4,\n",
      "       2, 0, 3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 4, 0, 0, 2, 0, 0, 3, 0, 0, 4,\n",
      "       1, 3, 3, 0, 0, 3, 0, 0, 3, 0, 4, 1, 0, 3, 4, 0, 0, 1, 0, 0, 4, 0,\n",
      "       4, 1, 3, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 2, 0, 3,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 0, 3, 4, 0, 4, 0, 0, 3, 0, 1, 0, 0, 3, 4,\n",
      "       4, 2, 0, 3, 3, 3, 0, 0, 4, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 4, 0,\n",
      "       0, 4, 2, 0, 4, 3, 4, 3, 0, 0, 0, 3, 2, 0, 4, 0, 0, 0, 0, 1, 4, 4,\n",
      "       0, 3, 0, 4, 1, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 4, 4, 1,\n",
      "       4, 1, 0, 4, 3, 0, 2, 3, 2, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0,\n",
      "       4, 0, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 4, 2, 0, 0, 0, 4, 0, 4, 2, 0,\n",
      "       3, 4, 4, 0, 3, 0, 0, 4, 4, 0, 0, 0, 2, 3, 0, 0, 4, 4, 4, 1, 0, 3,\n",
      "       0, 4, 0, 0, 0, 4, 2, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 3, 0, 0, 0, 3,\n",
      "       3, 0, 0, 0, 0, 4, 0, 3, 3, 3, 3, 2, 0, 4, 0, 3, 0, 0, 0, 4, 0, 3,\n",
      "       0, 4, 0, 1, 0, 0, 4, 4, 0, 0, 4, 0, 4, 0, 3, 0, 0, 4, 0, 0, 4, 1,\n",
      "       3, 0, 0, 2, 0, 4, 4, 0, 3, 0, 0, 1, 0, 3, 2, 4, 3, 0, 4, 0, 3, 0,\n",
      "       4, 2, 3, 4, 0, 3, 0, 3, 0, 4, 0, 3, 0, 2, 3, 4, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 3, 4, 0, 2, 0, 0, 0, 3, 0,\n",
      "       0, 0, 4, 3, 0, 0, 0, 1, 0, 0, 3, 0, 0, 2, 0, 4, 1, 0, 0, 2, 2, 0,\n",
      "       1, 3, 2, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 4, 1, 0, 0, 0, 0, 4, 0, 0,\n",
      "       0, 1, 0, 4, 2, 0, 0, 4, 1, 4, 0, 1, 2, 3, 2, 4, 4, 0, 0, 0, 4, 3,\n",
      "       0, 3, 0, 0, 0, 1, 4, 0, 1, 0, 0, 0, 4, 0, 3, 0, 0, 2, 3, 3, 4, 0,\n",
      "       3, 0, 4, 0, 0, 0, 2, 0, 1, 0, 4, 4, 0, 4, 1, 4, 2, 3, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 4, 0, 0, 3, 2, 3, 2, 0, 4, 0, 3,\n",
      "       3, 3, 1, 0, 3, 3, 0, 2, 0, 4, 0, 4, 0, 3, 4, 3, 4, 0, 3, 4, 0, 3,\n",
      "       0, 3, 2, 4, 0, 4, 2, 0, 0, 0, 4, 0, 0, 0, 0, 1, 4, 0, 0, 4, 4, 0,\n",
      "       3, 2, 0, 4, 2, 3, 3, 0, 0, 0, 1, 0, 0, 0, 4, 0, 2, 4, 0, 3, 0, 2,\n",
      "       0, 0, 2, 2, 1, 1, 0, 0, 4, 4, 0, 1, 0, 1, 2, 0, 0, 1, 4, 2, 0, 3,\n",
      "       0, 4, 3, 4, 0, 0, 0, 4, 3, 0, 0, 0, 4, 1, 0, 4, 4, 0, 0, 4, 1, 0,\n",
      "       3, 2, 4, 1, 0, 0, 4, 0, 0, 4, 4, 4, 4, 4, 0, 4, 3, 3, 4, 4, 0, 0,\n",
      "       3, 0, 2, 4, 0, 1, 3, 3, 3, 3, 3, 3, 1, 1, 0, 0, 0, 1, 3, 0, 0, 0,\n",
      "       3, 4, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 1, 4, 3,\n",
      "       0, 0, 0, 0, 4, 3, 0, 0, 0, 3, 0, 3, 4, 0, 4, 3, 0, 1, 0, 0, 4, 0,\n",
      "       4, 2, 0, 2, 0, 2, 0, 1, 3, 0, 0, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0, 0,\n",
      "       3, 2, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 4, 0,\n",
      "       0, 0, 0, 0, 0, 0, 2, 2, 0, 3], dtype=int64), array([0, 4, 3, 0, 4, 2, 0, 0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3,\n",
      "       3, 3, 0, 2, 4, 0, 0, 3, 1, 4, 0, 0, 3, 2, 3, 1, 1, 0, 1, 4, 0, 4,\n",
      "       2, 0, 3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 4,\n",
      "       1, 3, 3, 0, 0, 3, 0, 0, 3, 0, 4, 1, 0, 3, 4, 4, 0, 1, 0, 0, 3, 0,\n",
      "       4, 1, 3, 0, 0, 0, 2, 3, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 2, 0, 3,\n",
      "       2, 0, 0, 0, 3, 0, 0, 0, 0, 3, 4, 0, 4, 0, 0, 3, 0, 1, 0, 0, 3, 4,\n",
      "       4, 2, 0, 3, 3, 3, 0, 0, 4, 1, 0, 0, 0, 4, 0, 0, 0, 0, 0, 3, 4, 0,\n",
      "       0, 4, 2, 0, 4, 3, 4, 3, 0, 0, 0, 3, 2, 0, 2, 0, 0, 0, 0, 1, 4, 3,\n",
      "       0, 3, 2, 0, 1, 0, 3, 3, 0, 1, 0, 0, 0, 0, 0, 3, 3, 0, 0, 4, 4, 1,\n",
      "       4, 1, 1, 4, 3, 0, 2, 4, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0,\n",
      "       4, 0, 0, 0, 0, 0, 4, 3, 1, 1, 0, 0, 3, 2, 0, 4, 0, 4, 0, 4, 2, 0,\n",
      "       3, 4, 1, 0, 3, 0, 0, 4, 4, 0, 4, 0, 2, 3, 4, 0, 4, 4, 2, 0, 0, 3,\n",
      "       0, 4, 0, 0, 0, 4, 4, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 3, 0, 0, 0, 3,\n",
      "       3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 0, 4, 0, 3, 0, 0, 0, 4, 0, 3,\n",
      "       1, 4, 0, 1, 0, 0, 4, 4, 0, 0, 2, 0, 0, 0, 3, 0, 0, 4, 0, 0, 3, 1,\n",
      "       3, 0, 2, 2, 0, 4, 4, 0, 3, 0, 0, 1, 0, 3, 2, 4, 3, 0, 4, 0, 1, 0,\n",
      "       4, 2, 3, 4, 0, 3, 0, 2, 0, 4, 0, 3, 0, 1, 3, 4, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 3, 4, 0, 2, 0, 0, 0, 3, 0,\n",
      "       0, 0, 4, 3, 0, 0, 0, 1, 3, 0, 3, 0, 0, 2, 0, 4, 1, 4, 0, 2, 2, 0,\n",
      "       1, 3, 2, 0, 1, 2, 2, 0, 0, 3, 0, 0, 0, 4, 1, 0, 0, 0, 0, 2, 0, 0,\n",
      "       4, 1, 0, 4, 2, 0, 0, 4, 1, 4, 0, 1, 2, 4, 2, 4, 4, 0, 0, 4, 4, 3,\n",
      "       0, 3, 0, 0, 0, 1, 4, 0, 1, 0, 0, 0, 4, 0, 4, 0, 0, 2, 3, 3, 4, 0,\n",
      "       0, 0, 4, 4, 0, 0, 2, 0, 1, 0, 4, 4, 4, 0, 1, 4, 2, 3, 0, 1, 0, 0,\n",
      "       0, 1, 1, 0, 0, 3, 0, 0, 0, 0, 0, 4, 0, 0, 3, 2, 3, 2, 0, 4, 0, 3,\n",
      "       3, 3, 1, 0, 3, 3, 0, 2, 0, 4, 0, 4, 0, 3, 4, 3, 4, 0, 3, 4, 0, 3,\n",
      "       0, 3, 2, 4, 0, 4, 2, 0, 0, 0, 3, 0, 0, 4, 0, 1, 4, 0, 0, 0, 4, 4,\n",
      "       4, 2, 0, 3, 2, 3, 4, 0, 1, 0, 1, 0, 0, 0, 4, 0, 2, 0, 0, 3, 0, 2,\n",
      "       0, 0, 4, 2, 1, 1, 0, 0, 4, 0, 0, 1, 0, 1, 2, 0, 0, 1, 4, 2, 0, 3,\n",
      "       0, 4, 3, 4, 0, 0, 0, 3, 3, 0, 0, 0, 4, 1, 0, 3, 4, 0, 0, 4, 1, 0,\n",
      "       3, 2, 4, 1, 0, 0, 4, 0, 0, 4, 4, 4, 4, 3, 0, 3, 4, 3, 4, 4, 0, 0,\n",
      "       3, 0, 2, 3, 0, 1, 3, 3, 3, 3, 0, 3, 0, 1, 0, 0, 0, 1, 3, 0, 0, 0,\n",
      "       3, 4, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 4, 3,\n",
      "       0, 0, 0, 0, 4, 3, 0, 0, 0, 3, 0, 3, 4, 0, 4, 3, 0, 1, 0, 0, 4, 3,\n",
      "       4, 2, 0, 2, 0, 2, 0, 1, 3, 0, 0, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0, 0,\n",
      "       3, 0, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 0, 3, 0, 4, 0, 0, 3, 0, 4, 4,\n",
      "       0, 0, 0, 4, 0, 0, 2, 2, 0, 3], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_train, y_train)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
